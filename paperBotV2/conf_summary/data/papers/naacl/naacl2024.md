# NAACL2024

## 会议论文列表

本会议共有 954 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Systematic Analysis for Pretrained Language Model Priming for Parameter-Efficient Fine-tuning](https://doi.org/10.18653/v1/2024.naacl-srw.1) |  | 0 | Parameter-efficient (PE) methods (like Prompts or Adapters) for adapting pre-trained language models (PLM) to downstream tasks have been popular recently. However, hindrances still prevent these methods from reaching their full potential. For example, two significant challenges are few-shot adaptation and cross-task generalization. To tackle these issues, we propose a general PE priming framework to enhance and explore the few-shot adaptation and... | ShihCheng Huang, ShihHeng Wang, MinHan Shih, Saurav Sahay, Hungyi Lee |  |
| 2 |  |  [Rephrasing Invokes Better Generations for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.2) |  | 0 | In the realm of emerging multitasking abilities of Large language models (LLMs), methodologies like prompt tuning enable low-cost adaptation to downstream tasks without retraining the model. However, automatic input pre-processing when LLMs are unavailable is currently under-studied. This paper proposes ReLLM (Rephrasing for LLMs), a method that automatically paraphrases input content for better output generations. ReLLM replaces low-frequency lexical items... | Haoran Yang, Hongyuan Lu, Wai Lam |  |
| 3 |  |  [Exploring Compositional Generalization of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.3) |  | 0 | In this paper, we study the generalization ability of large language models (LLMs) with respect to compositional instructions, which are instructions that can be decomposed into several sub-instructions. We argue that the ability to generalize from simple instructions to more intricate compositional instructions represents a key aspect of the out-of-distribution generalization for LLMs. Since there are no specialized datasets for studying this phenomenon, we... | Haoran Yang, Hongyuan Lu, Wai Lam, Deng Cai |  |
| 4 |  |  [Explainable CED: A Dataset for Explainable Critical Error Detection in Machine Translation](https://doi.org/10.18653/v1/2024.naacl-srw.4) |  | 0 | Critical error detection (CED) in machine translation is a task that aims to detect errors that significantly distort the intended meaning. However, the existing study of CED lacks explainability due to the absence of content addressing the reasons for catastrophic errors. To address this limitation, we propose Explainable CED, a dataset that introduces the attributes of error explanation and correction regarding critical errors. Considering the advantage of... | Dahyun Jung, Sugyeong Eo, Chanjun Park, Heuiseok Lim |  |
| 5 |  |  [SMARTR: A Framework for Early Detection using Survival Analysis of Longitudinal Texts](https://doi.org/10.18653/v1/2024.naacl-srw.5) |  | 0 | This paper presents an innovative approach to the early detection of expensive insurance claims by leveraging survival analysis concepts within a deep learning framework exploiting textual information from claims notes. Our proposed SMARTR model addresses limitations of state-of-the-art models, such as handling data-label mismatches and non-uniform data frequency, to enhance a posteriori classification and early detection. Our results suggest that... | JeanThomas Baillargeon, Luc Lamontagne |  |
| 6 |  |  [Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)](https://doi.org/10.18653/v1/2024.naacl-srw.6) |  | 0 | Exact nearest neighbor search is a computationally intensive process, and even its simpler sibling — vector retrieval — can be computationally complex. This is exacerbated when retrieving vectors which have high-dimension d relative to the number of vectors, N, in the database. Exact nearest neighbor retrieval has been generally acknowledged to be a O(Nd) problem with no sub-linear solutions. Attention has instead shifted towards Approximate Nearest-Neighbor... | Richard Zhu |  |
| 7 |  |  [Start Simple: Progressive Difficulty Multitask Learning](https://doi.org/10.18653/v1/2024.naacl-srw.7) |  | 0 | The opaque nature of neural networks, often described as black boxes, poses significant challenges in understanding their learning mechanisms, which limit our ability to fully optimize and trust these models.Inspired by how humans learn, this paper proposes a novel neural network training strategy that employs multitask learning with progressive difficulty subtasks, which we believe can potentially shed light on the internal learning mechanisms of neural... | Yunfei Luo, Yuyang Liu, Rukai Cai, Tauhidur Rahman |  |
| 8 |  |  [LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues](https://doi.org/10.18653/v1/2024.naacl-srw.8) |  | 0 | Spurred by recent advances in Large Language Models (LLMs), virtual assistants are poised to take a leap forward in terms of their dialogue capabilities. Yet a major bottleneck to achieving genuinely transformative task-oriented dialogue capabilities remains the scarcity of high quality data. Existing datasets, while impressive in scale, have limited domain coverage and contain few genuinely challenging conversational phenomena; those which are present are... | Joe Stacey, Jianpeng Cheng, John Torr, Tristan Guigue, Joris Driesen, Alexandru Coca, Mark Gaynor, Anders Johannsen |  |
| 9 |  |  [Fine-tuning Pre-trained Named Entity Recognition Models For Indian Languages](https://doi.org/10.18653/v1/2024.naacl-srw.9) |  | 0 | Named Entity Recognition (NER) is a use-ful component in Natural Language Process-ing (NLP) applications. It is used in varioustasks such as Machine Translation, Summa-rization, Information Retrieval, and Question-Answering systems. The research on NER iscentered around English and some other ma-jor languages, whereas limited attention hasbeen given to Indian languages. We analyze thechallenges and propose techniques that can betailored for Multilingual Named... | Sankalp Bahad, Pruthwik Mishra, Parameswari Krishnamurthy, Dipti Misra Sharma |  |
| 10 |  |  [Knowledge-centered conversational agents with a drive to learn](https://doi.org/10.18653/v1/2024.naacl-srw.10) |  | 0 | We create an adaptive conversational agent that assesses the quality of its knowledge and is driven to become more knowledgeable. Unlike agents with predefined tasks, ours can leverage people as diverse sources to meet its knowledge needs. We test the agent in social contexts, where personal and subjective information can be obtained through dialogue. We provide the agent both with generic methods for assessing its knowledge quality (e.g. correctness,... | Selene Baez Santamaría |  |
| 11 |  |  [Exploring Inherent Biases in LLMs within Korean Social Context: A Comparative Analysis of ChatGPT and GPT-4](https://doi.org/10.18653/v1/2024.naacl-srw.11) |  | 0 | Large Language Models (LLMs) have significantly impacted various fields requiring advanced linguistic understanding, yet concerns regarding their inherent biases and ethical considerations have also increased. Notably, LLMs have been critiqued for perpetuating stereotypes against diverse groups based on race, sexual orientation, and other attributes. However, most research analyzing these biases has predominantly focused on communities where English is the... | Seungyoon Lee, Dong Kim, Dahyun Jung, Chanjun Park, Heuiseok Lim |  |
| 12 |  |  [To Clarify or not to Clarify: A Comparative Analysis of Clarification Classification with Fine-Tuning, Prompt Tuning, and Prompt Engineering](https://doi.org/10.18653/v1/2024.naacl-srw.12) |  | 0 | Misunderstandings occur all the time in human conversation but deciding on when to ask for clarification is a challenging task for conversational systems that requires a balance between asking too many unnecessary questions and running the risk of providing incorrect information. This work investigates clarification identification based on the task and data from (Xu et al., 2019), reproducing their Transformer baseline and extending it by comparing... | Alina Leippert, Tatiana Anikina, Bernd Kiefer, Josef van Genabith |  |
| 13 |  |  [Detecting Response Generation Not Requiring Factual Judgment](https://doi.org/10.18653/v1/2024.naacl-srw.13) |  | 0 | With the remarkable development of large language models (LLMs), ensuring the factuality of output has become a challenge.However, having all the contents of the response with given knowledge or facts is not necessarily a good thing in dialogues.This study aimed to achieve both attractiveness and factuality in a dialogue response for which a task was set to predict sentences that do not require factual correctness judgment such as agreeing, or personal... | Ryohei Kamei, Daiki Shiono, Reina Akama, Jun Suzuki |  |
| 14 |  |  [Unknown Script: Impact of Script on Cross-Lingual Transfer](https://doi.org/10.18653/v1/2024.naacl-srw.14) |  | 0 | Cross-lingual transfer has become an effective way of transferring knowledge between languages. In this paper, we explore an often overlooked aspect in this domain: the influence of the source language of a language model on language transfer performance. We consider a case where the target language and its script are not part of the pre-trained model. We conduct a series of experiments on monolingual and multilingual models that are pre-trained on different... | Wondimagegnhue Tufa, Ilia Markov, Piek Vossen |  |
| 15 |  |  [Improving Repository-level Code Search with Text Conversion](https://doi.org/10.18653/v1/2024.naacl-srw.15) |  | 0 | The ability to generate code using large language models (LLMs) has been increasing year by year. However, studies on code generation at the repository level are not very active. In repository-level code generation, it is necessary to refer to related code snippets among multiple files. By taking the similarity between code snippets, related files are searched and input into an LLM, and generation is performed. This paper proposes a method to search for... | Mizuki Kondo, Daisuke Kawahara, Toshiyuki Kurabayashi |  |
| 16 |  |  [Improving Multi-lingual Alignment Through Soft Contrastive Learning](https://doi.org/10.18653/v1/2024.naacl-srw.16) |  | 0 | Making decent multi-lingual sentence representations is critical to achieve high performances in cross-lingual downstream tasks. In this work, we propose a novel method to align multi-lingual embeddings based on the similarity of sentences measured by a pre-trained mono-lingual embedding model. Given translation sentence pairs, we train a multi-lingual model in a way that the similarity between cross-lingual embeddings follows the similarity of sentences... | Minsu Park, Seyeon Choi, Chanyeol Choi, JunSeong Kim, Jyyong Sohn |  |
| 17 |  |  [Few-Shot Event Argument Extraction Based on a Meta-Learning Approach](https://doi.org/10.18653/v1/2024.naacl-srw.17) |  | 0 | Few-shot learning techniques for Event Extraction are developed to alleviate the cost of data annotation. However, most studies on few-shot event extraction only focus on event trigger detection and no study has been proposed on argument extraction in a meta-learning context. In this paper, we investigate few-shot event argument extraction using prototypical networks, casting the task as a relation classification problem. Furthermore, we propose to enhance... | Aboubacar Tuo, Romaric Besançon, Olivier Ferret, Julien Tourille |  |
| 18 |  |  [Investigating Web Corpus Filtering Methods for Language Model Development in Japanese](https://doi.org/10.18653/v1/2024.naacl-srw.18) |  | 0 | The development of large language models (LLMs) is becoming increasingly significant, and there is a demand for high-quality, large-scale corpora for their pretraining.The quality of a web corpus is especially essential to improve the performance of LLMs because it accounts for a large proportion of the whole corpus. However, filtering methods for Web corpora have yet to be established.In this paper, we present empirical studies to reveal which filtering... | Rintaro Enomoto, Arseny Tolmachev, Takuro Niitsuma, Shuhei Kurita, Daisuke Kawahara |  |
| 19 |  |  [Referring Expressions in Human-Robot Common Ground: A Thesis Proposal](https://doi.org/10.18653/v1/2024.naacl-srw.19) |  | 0 | In this PhD, we investigate the processes through which common ground shapes the pragmatic use of referring expressions in Human-Robot Interaction. A central point in our investigation is the interplay between a growing common ground and changes in the surrounding context, which can create ambiguity, variation and the need for pragmatic interpretations. We outline three objectives that define the scope of our work: 1) obtaining data with common ground... | Jaap Kruijt |  |
| 20 |  |  [Source Code is a Graph, Not a Sequence: A Cross-Lingual Perspective on Code Clone Detection](https://doi.org/10.18653/v1/2024.naacl-srw.20) |  | 0 | Code clone detection is challenging, as sourcecode can be written in different languages, do-mains, and styles. In this paper, we arguethat source code is inherently a graph, not asequence, and that graph-based methods aremore suitable for code clone detection thansequence-based methods. We compare the per-formance of two state-of-the-art models: Code-BERT (Feng et al., 2020), a sequence-basedmodel, and CodeGraph (Yu et al., 2023), agraph-based model, on two... | Mohammed Ataaur Rahaman, Julia Ive |  |
| 21 |  |  [Distilling Text Style Transfer With Self-Explanation From LLMs](https://doi.org/10.18653/v1/2024.naacl-srw.21) |  | 0 | Text Style Transfer (TST) seeks to alter the style of text while retaining its core content. Given the constraints of limited parallel datasets for TST, we propose CoTeX, a framework that leverages large language models (LLMs) alongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills the complex rewriting and reasoning capabilities of LLMs into more streamlined models capable of working with both non-parallel and parallel data. Through... | Chiyu Zhang, Honglong Cai, Yuezhang Li, Yuexin Wu, Le Hou, Muhammad AbdulMageed |  |
| 22 |  |  [Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-srw.22) |  | 0 | Non-autoregressive (NAR) language models are known for their low latency in neural machine translation (NMT). However, a performance gap exists between NAR and autoregressive models due to the large decoding space and difficulty in capturing dependency between target words accurately. Compounding this, preparing appropriate training data for NAR models is a non-trivial task, often exacerbating exposure bias. To address these challenges, we apply reinforcement... | Hao Wang, Tetsuro Morimura, Ukyo Honda, Daisuke Kawahara |  |
| 23 |  |  [Evaluation Dataset for Japanese Medical Text Simplification](https://doi.org/10.18653/v1/2024.naacl-srw.23) |  | 0 | We create a parallel corpus for medical text simplification in Japanese, which simplifies medical terms into expressions that patients can understand without effort.While text simplification in the medial domain is strongly desired by society, it is less explored in Japanese because of the lack of language resources.In this study, we build a parallel corpus for Japanese text simplification evaluation in the medical domain using patients’ weblogs.This corpus... | Koki Horiguchi, Tomoyuki Kajiwara, Yuki Arase, Takashi Ninomiya |  |
| 24 |  |  [Multi-Source Text Classification for Multilingual Sentence Encoder with Machine Translation](https://doi.org/10.18653/v1/2024.naacl-srw.24) |  | 0 | To reduce the cost of training models for each language for developers of natural language processing applications, pre-trained multilingual sentence encoders are promising.However, since training corpora for such multilingual sentence encoders contain only a small amount of text in languages other than English, they suffer from performance degradation for non-English languages.To improve the performance of pre-trained multilingual sentence encoders for... | Reon Kajikawa, Keiichiro Yamada, Tomoyuki Kajiwara, Takashi Ninomiya |  |
| 25 |  |  [A Reproducibility Study on Quantifying Language Similarity: The Impact of Missing Values in the URIEL Knowledge Base](https://doi.org/10.18653/v1/2024.naacl-srw.25) |  | 0 | In the pursuit of supporting more languages around the world, tools that characterize properties of languages play a key role in expanding the existing multilingual NLP research. In this study, we focus on a widely used typological knowledge base, URIEL, which aggregates linguistic information into numeric vectors. Specifically, we delve into the soundness and reproducibility of the approach taken by URIEL in quantifying language similarity. Our analysis... | Hasti Toossi, Guo Qing Huai, Jinyu Liu, Eric Khiu, A. Seza Dogruöz, Enshiun Lee |  |
| 26 |  |  [Coding Open-Ended Responses using Pseudo Response Generation by Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.26) |  | 0 | Survey research using open-ended responses is an important method thatcontributes to the discovery of unknown issues and new needs. However,survey research generally requires time and cost-consuming manual dataprocessing, indicating that it is difficult to analyze large dataset.To address this issue, we propose an LLM-based method to automate partsof the grounded theory approach (GTA), a representative approach of thequalitative data analysis. We generated... | Yuki Zenimoto, Ryo Hasegawa, Takehito Utsuro, Masaharu Yoshioka, Noriko Kando |  |
| 27 |  |  [Cross-Task Generalization Abilities of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.27) |  | 0 | Humans can learn a new language task efficiently with only few examples, by leveraging their knowledge and experience obtained when learning prior tasks. Enabling similar cross-task generalization abilities in NLP systems is fundamental for approaching the goal of general intelligence and expanding the reach of language technology in the future.In this thesis proposal, I will present my work on (1) benchmarking cross-task generalization abilities with diverse... | Qinyuan Ye |  |
| 28 |  |  [Commentary Generation from Data Records of Multiplayer Strategy Esports Game](https://doi.org/10.18653/v1/2024.naacl-srw.28) |  | 0 | Esports, a sports competition on video games, has become one of the most important sporting events. Although esports play logs have been accumulated, only a small portion of them accompany text commentaries for the audience to retrieve and understand the plays. In this study, we therefore introduce the task of generating game commentaries from esports’ data records. We first build large-scale esports data-to-text datasets that pair structured data and... | Zihan Wang, Naoki Yoshinaga |  |
| 29 |  |  [Facilitating Opinion Diversity through Hybrid NLP Approaches](https://doi.org/10.18653/v1/2024.naacl-srw.29) |  | 0 | Modern democracies face a critical issue of declining citizen participation in decision-making. Online discussion forums are an important avenue for enhancing citizen participation. This thesis proposal 1) identifies the challenges involved in facilitating large-scale online discussions with Natural Language Processing (NLP), 2) suggests solutions to these challenges by incorporating hybrid human-AI technologies, and 3) investigates what these technologies... | Michiel van der Meer |  |
| 30 |  |  [HybridBERT - Making BERT Pretraining More Efficient Through Hybrid Mixture of Attention Mechanisms](https://doi.org/10.18653/v1/2024.naacl-srw.30) |  | 0 | Pretrained transformer-based language models have produced state-of-the-art performance in most natural language understanding tasks. These models undergo two stages of training: pretraining on a huge corpus of data and fine-tuning on a specific downstream task. The pretraining phase is extremely compute-intensive and requires several high-performance computing devices like GPUs and several days or even months of training, but it is crucial for the model to... | Gokul Srinivasagan, Simon Ostermann |  |
| 31 |  |  [TOPICAL: TOPIC Pages AutomagicaLly](https://doi.org/10.18653/v1/2024.naacl-demo.1) |  | 0 | Topic pages aggregate useful information about an entity or concept into a single succinct and accessible article. Automated creation of topic pages would enable their rapid curation as information resources, providing an alternative to traditional web search. While most prior work has focused on generating topic pages about biographical entities, in this work, we develop a completely automated process to generate high-quality topic pages for scientific... | John M. Giorgi, Amanpreet Singh, Doug Downey, Sergey Feldman, Lucy Lu Wang |  |
| 32 |  |  [Low-code LLM: Graphical User Interface over Large Language Models](https://doi.org/10.18653/v1/2024.naacl-demo.2) |  | 0 | Utilizing Large Language Models (LLMs) for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process. This paper introduces a novel human-LLM interaction framework, Low-code LLM. It incorporates six types of simple low-code visual programming interactions to achieve more controllable and stable responses. Through visual interaction with a graphical user interface, users can incorporate their ideas into the... | Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge, Chenfei Wu, Wang You, Ting Song, Yan Xia, Nan Duan, Furu Wei |  |
| 33 |  |  [EdTec-QBuilder: A Semantic Retrieval Tool for Assembling Vocational Training Exams in German Language](https://doi.org/10.18653/v1/2024.naacl-demo.3) |  | 0 | Selecting and assembling test items from a validated item database into comprehensive exam forms is an under-researched but significant challenge in education. Search and retrieval methods provide a robust framework to assist educators when filtering and assembling relevant test items. In this work, we present EdTec-QBuilder, a semantic search tool developed to assist vocational educators in assembling exam forms. To implement EdTec-QBuilder’s core search... | Alonso Palomino, Andreas Fischer, Jakub Kuzilek, Jarek Nitsch, Niels Pinkwart, Benjamin Paassen |  |
| 34 |  |  [DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-demo.4) |  | 0 | We present DIALIGHT, a toolkit for developing and evaluating multilingual Task-Oriented Dialogue (ToD) systems which facilitates systematic evaluations and comparisons between ToD systems using fine-tuning of Pretrained Language Models (PLMs) and those utilising the zero-shot and in-context learning capabilities of Large Language Models (LLMs). In addition to automatic evaluation, this toolkit features (i) a secure, user-friendly web interface for... | Songbo Hu, Xiaobin Wang, Moy Yuan, Anna Korhonen, Ivan Vulic |  |
| 35 |  |  [RTSUM: Relation Triple-based Interpretable Summarization with Multi-level Salience Visualization](https://doi.org/10.18653/v1/2024.naacl-demo.5) |  | 0 | In this paper, we present RTSum, an unsupervised summarization framework that utilizes relation triples as the basic unit for summarization. Given an input document, RTSum first selects salient relation triples via multi-level salience scoring and then generates a concise summary from the selected relation triples by using a text-to-text language model. On the basis of RTSum, we also develop a web demo for an interpretable summarizing tool, providing... | Seonglae Cho, Myungha Jang, Jinyoung Yeo, Dongha Lee |  |
| 36 |  |  [Edu-ConvoKit: An Open-Source Library for Education Conversation Data](https://doi.org/10.18653/v1/2024.naacl-demo.6) |  | 0 | We introduce Edu-ConvoKit, an open-source library designed to handle pre-processing, annotation and analysis of conversation data in education. Resources for analyzing education conversation data are scarce, making the research challenging to perform and therefore hard to access. We address these challenges with Edu-ConvoKit. Edu-ConvoKit is open-source [1], pip-installable [2], with comprehensive documentation [3]. Our demo video is available at:... | Rose E. Wang, Dorottya Demszky |  |
| 37 |  |  [jp-evalb: Robust Alignment-based PARSEVAL Measures](https://doi.org/10.18653/v1/2024.naacl-demo.7) |  | 0 | We introduce an evaluation system designed to compute PARSEVAL measures, offering a viable alternative to evalb commonly used for constituency parsing evaluation. The widely used evalb script has traditionally been employed for evaluating the accuracy of constituency parsing results, albeit with the requirement for consistent tokenization and sentence boundaries. In contrast, our approach, named jp-evalb, is founded on an alignment method. This method aligns... | Jungyeul Park, Junrui Wang, Eunkyul Leah Jo, Angela Yoonseo Park |  |
| 38 |  |  [OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs](https://doi.org/10.18653/v1/2024.naacl-demo.8) |  | 0 | Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions. However, an open research question concerns the inherent biases of trained models and their responses. For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias. Current research work seeks to de-bias... | Patrick Haller, Ansar Aynetdinov, Alan Akbik |  |
| 39 |  |  [ATLAS: A System for PDF-centric Human Interaction Data Collection](https://doi.org/10.18653/v1/2024.naacl-demo.9) |  | 0 | The Portable Document Format (PDF) is a popular format for distributing digital documents. Datasets on PDF reading behaviors and interactions remain limited due to the challenges of instrumenting PDF readers for these data collection tasks. We present ATLAS, a data collection tool designed to better support researchers in collecting rich PDF-centric datasets from users. ATLAS supports researchers in programmatically creating a user interface for data... | Alexa F. Siu, Zichao Wang, Joshua Hoeflich, Naman Kapasi, Ani Nenkova, Tong Sun |  |
| 40 |  |  [BeLeaf: Belief Prediction as Tree Generation](https://doi.org/10.18653/v1/2024.naacl-demo.10) |  | 0 | We present a novel approach to predicting source-and-target factuality by transforming it into a linearized tree generation task. Unlike previous work, our model and representation format fully account for the factuality tree structure, generating the full chain of nested sources instead of the last source only. Furthermore, our linearized tree representation significantly compresses the amount of tokens needed compared to other representations, allowing for... | John Murzaku, Owen Rambow |  |
| 41 |  |  [QueryExplorer: An Interactive Query Generation Assistant for Search and Exploration](https://doi.org/10.18653/v1/2024.naacl-demo.11) |  | 0 | Formulating effective search queries remains a challenging task, particularly when users lack expertise in a specific domain or are not proficient in the language of the content. Providing example documents of interest might be easier for a user. However, such query-by-example scenarios are prone to concept drift, and the retrieval effectiveness is highly sensitive to the query generation method, without a clear way to incorporate user feedback. To enable... | Kaustubh D. Dhole, Shivam Bajaj, Ramraj Chandradevan, Eugene Agichtein |  |
| 42 |  |  [LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models](https://doi.org/10.18653/v1/2024.naacl-demo.12) |  | 0 | Foundation models have demonstrated a great ability to achieve general human-level intelligence far beyond traditional approaches. As the technique keeps attracting attention from the AI community, more and more foundation models have become publicly available.However, most of those models exhibit a major deficiency in specialized-domain and specialized-task applications, where the step of domain- and task-aware finetuning is still required to obtain... | Shizhe Diao, Rui Pan, Hanze Dong, Kashun Shum, Jipeng Zhang, Wei Xiong, Tong Zhang |  |
| 43 |  |  [DOCMASTER: A Unified Platform for Annotation, Training, & Inference in Document Question-Answering](https://doi.org/10.18653/v1/2024.naacl-demo.13) |  | 0 | The application of natural language processing models to PDF documents is pivotal for various business applications yet the challenge of training models for this purpose persists in businesses due to specific hurdles. These include the complexity of working with PDF formats that necessitate parsing text and layout information for curating training data and the lack of privacy-preserving annotation tools. This paper introduces DOCMASTER, a unified platform... | Alex Nguyen, Zilong Wang, Jingbo Shang, Dheeraj Mekala |  |
| 44 |  |  [RedCoast: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs](https://doi.org/10.18653/v1/2024.naacl-demo.14) |  | 0 | The recent progress of AI can be largely attributed to large language models (LLMs). However, their escalating memory requirements introduce challenges for machine learning (ML) researchers and engineers. Addressing this requires developers to partition a large model to distribute it across multiple GPUs or TPUs. This necessitates considerable coding and intricate configuration efforts with existing model parallel tools, such as Megatron-LM, DeepSpeed, and... | Bowen Tan, Yun Zhu, Lijuan Liu, Hongyi Wang, Yonghao Zhuang, Jindong Chen, Eric P. Xing, Zhiting Hu |  |
| 45 |  |  [Concept Over Time Analysis: Unveiling Temporal Patterns for Qualitative Data Analysis](https://doi.org/10.18653/v1/2024.naacl-demo.15) |  | 0 | In this system demonstration paper, we present the Concept Over Time Analysis extension for the Discourse Analysis Tool Suite.The proposed tool empowers users to define, refine, and visualize their concepts of interest within an interactive interface. Adhering to the Human-in-the-loop paradigm, users can give feedback through sentence annotations. Utilizing few-shot sentence classification, the system employs Sentence Transformers to compute representations... | Tim Fischer, Florian Schneider, Robert Geislinger, Florian Helfer, Gertraud Koch, Chris Biemann |  |
| 46 |  |  [pyvene: A Library for Understanding and Improving PyTorch Models via Interventions](https://doi.org/10.18653/v1/2024.naacl-demo.16) |  | 0 | Interventions on model-internal states are fundamental operations in many areas of AI, including model editing, steering, robustness, and interpretability. To facilitate such research, we introduce pyvene, an open-source Python library that supports customizable interventions on a range of different PyTorch modules. pyvene supports complex intervention schemes with an intuitive configuration format, and its interventions can be static or include trainable... | Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts |  |
| 47 |  |  [Newspaper Signaling for Crisis Prediction](https://doi.org/10.18653/v1/2024.naacl-demo.17) |  | 0 | To establish sophisticated monitoring of newspaper articles for detecting crisis-related signals, natural language processing has to cope with unstructured data, media, and cultural bias as well as multiple languages. So far, research on detecting signals in newspaper articles is focusing on structured data, restricted language settings, and isolated application domains. When considering complex crisis-related signals, a high number of diverse newspaper... | Prajvi Saxena, Sabine Janzen, Wolfgang Maass |  |
| 48 |  |  [FastFit: Fast and Effective Few-Shot Text Classification with a Multitude of Classes](https://doi.org/10.18653/v1/2024.naacl-demo.18) |  | 0 | We present FastFit, a Python package designed to provide fast and accurate few-shot classification, especially for scenarios with many semantically similar classes. FastFit utilizes a novel approach integrating batch contrastive learning and token-level similarity score. Compared to existing few-shot learning packages, such as SetFit, Transformers, or few-shot prompting of large language models via API calls, FastFit significantly improves multi-class... | Asaf Yehudai, Elron Bandel |  |
| 49 |  |  [AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents](https://doi.org/10.18653/v1/2024.naacl-demo.19) |  | 0 | The advances made by Large Language Models (LLMs) have led to the pursuit of LLM agents that can solve intricate, multi-step reasoning tasks. As with any research pursuit, benchmarking and evaluation are key corner stones to efficient and reliable progress. However, existing benchmarks are often narrow and simply compute overall task success. To face these issues, we propose AgentQuest – a framework where (i) both benchmarks and metrics are modular and easily... | Luca Gioacchini, Giuseppe Siracusano, Davide Sanvito, Kiril Gashteovski, David Friede, Roberto Bifulco, Carolin Lawrence |  |
| 50 |  |  [ZhuJiu-Knowledge: A Fairer Platform for Evaluating Multiple Knowledge Types in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-demo.20) |  | 0 | The swift advancement in large language models (LLMs) has heightened the importance of model evaluations. LLMs have acquired a substantial amount of knowledge, and evaluating the knowledge of these LLMs is crucial. To address this, we introduce the ZhuJiu-Knowledge benchmark which carefully considers the following factors: (1) For knowledge scope, we concentrate on three domains: commonsense knowledge, world knowledge, language knowledge, which comes from... | Pengfan Du, Sirui Liang, Baoli Zhang, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 51 |  |  [Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI](https://doi.org/10.18653/v1/2024.naacl-demo.21) |  | 0 | In the dynamic landscape of generative NLP, traditional text processing pipelines limit research flexibility and reproducibility, as they are tailored to specific dataset, task, and model combinations. The escalating complexity, involving system prompts, model-specific formats, instructions, and more, calls for a shift to a structured, modular, and customizable solution.Addressing this need, we present Unitxt, an innovative library for customizable textual... | Elron Bandel, Yotam Perlitz, Elad Venezian, Roni Friedman, Ofir Arviv, Matan Orbach, Shachar DonYehiya, Dafna Sheinwald, Ariel Gera, Leshem Choshen, Michal ShmueliScheuer, Yoav Katz |  |
| 52 |  |  [HPipe: Large Language Model Pipeline Parallelism for Long Context on Heterogeneous Cost-effective Devices](https://doi.org/10.18653/v1/2024.naacl-industry.1) |  | 0 | Micro-enterprises and individual developers emerge analysis demands for long sequence with powerful Large Language Models (LLMs). They try to deploy the LLMs at local, but only possess various commodity devices and the unreliable interconnection between devices. Existing parallel techniques do not lead to the same effectiveness in limited environment. The heterogeneity of devices, coupled with their limited capacity and expensive communication, brings... | Ruilong Ma, Xiang Yang, Jing Wang, Qi Qi, Haifeng Sun, Zirui Zhuang, Jianxin Liao |  |
| 53 |  |  [Lossless Acceleration of Large Language Model via Adaptive N-gram Parallel Decoding](https://doi.org/10.18653/v1/2024.naacl-industry.2) |  | 0 | While Large Language Models (LLMs) have shown remarkable abilities, they are hindered by significant resource consumption and considerable latency due to autoregressive processing. In this study, we introduce Adaptive N-gram Parallel Decoding (ANPD), an innovative and lossless approach that accelerates inference by allowing the simultaneous generation of multiple tokens. ANPD incorporates a two-stage approach: it begins with a rapid drafting phase that... | Jie Ou, Yueming Chen, Wenhong Tian |  |
| 54 |  |  [SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling](https://doi.org/10.18653/v1/2024.naacl-industry.3) |  | 0 | We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, demonstrating superior performance in various natural language processing (NLP) tasks. Inspired by recent efforts to efficiently up-scale LLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which encompasses depthwise scaling and continued pretraining. In contrast to other LLM up-scaling methods that use mixture-of-experts, DUS does not require complex... | Sanghoon Kim, Dahyun Kim, Chanjun Park, Wonsung Lee, Wonho Song, Yunsu Kim, Hyeonwoo Kim, Yungi Kim, Hyeonju Lee, Jihoo Kim, Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim, Mikyoung Cha, Hwalsuk Lee, Sunghun Kim |  |
| 55 |  |  [UINav: A Practical Approach to Train On-Device Automation Agents](https://doi.org/10.18653/v1/2024.naacl-industry.4) |  | 0 | Automation systems that can autonomously drive application user interfaces to complete user tasks are of great benefit, especially when users are situationally or permanently impaired. Prior automation systems do not produce generalizable models while AI-based automation agents work reliably only in simple, hand-crafted applications or incur high computation costs. We propose UINav, a demonstration-based approach to train automation agents that fit mobile... | Wei Li, FuLin Hsu, William Bishop, Folawiyo CampbellAjala, Max Lin, Oriana Riva |  |
| 56 |  |  [Efficiently Distilling LLMs for Edge Applications](https://doi.org/10.18653/v1/2024.naacl-industry.5) |  | 0 | Supernet training of LLMs is of great interest in industrial applications as it confers the ability to produce a palette of smaller models at constant cost, regardless of the number of models (of different size / latency) produced. We propose a new method called Multistage Low-rank Fine-tuning of Super-transformers (MLFS) for parameter-efficient supernet training. We show that it is possible to obtain high-quality encoder models that are suitable for... | Achintya Kundu, Fabian Lim, Aaron Chew, Laura Wynter, Penny Chong, Rhui Dih Lee |  |
| 57 |  |  [Modeling and Detecting Company Risks from News](https://doi.org/10.18653/v1/2024.naacl-industry.6) |  | 0 | Identifying risks associated with a company is important to investors and the wellbeing of the overall financial markets. In this study, we build a computational framework to automatically extract company risk factors from news articles. Our newly proposed schema comprises seven distinct aspects, such as supply chain, regulations, and competition. We annotate 666 news articles and benchmark various machine learning models. While large language mod- els have... | Jiaxin Pei, Soumya Vadlamannati, LiangKang Huang, Daniel PreotiucPietro, Xinyu Hua |  |
| 58 |  |  [Multiple-Question Multiple-Answer Text-VQA](https://doi.org/10.18653/v1/2024.naacl-industry.7) |  | 0 | We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do text-VQA in encoder-decoder transformer models. To the best of our knowledge, almost all previous approaches for text-VQA process a single question and its associated content to predict a single answer. However, in industry applications, users may come up with multiple questions about a single image. In order to answer multiple questions from the same image, each question and content... | Peng Tang, Srikar Appalaraju, R. Manmatha, Yusheng Xie, Vijay Mahadevan |  |
| 59 |  |  [An NLP-Focused Pilot Training Agent for Safe and Efficient Aviation Communication](https://doi.org/10.18653/v1/2024.naacl-industry.8) |  | 0 | Aviation communication significantly influences the success of flight operations, ensuring safety of lives and efficient air transportation. In day-to-day flight operations, air traffic controllers (ATCos) would timely communicate instructions to pilots using specific phraseology for aircraft manipulation . However, pilots, originating from diverse backgrounds and understanding of English language, have struggled with conforming to strict phraseology for... | Xiaochen Liu, Bowei Zou, AiTi Aw |  |
| 60 |  |  [Visual Grounding for User Interfaces](https://doi.org/10.18653/v1/2024.naacl-industry.9) |  | 0 | Enabling autonomous language agents to drive application user interfaces (UIs) as humans do can significantly expand the capability of today’s API-based agents. Essential to this vision is the ability of agents to ground natural language commands to on-screen UI elements. Prior UI grounding approaches work by relaying on developer-provided UI metadata (UI trees, such as web DOM, and accessibility labels) to detect on-screen elements. However, such metadata is... | Yijun Qian, Yujie Lu, Alexander Hauptmann, Oriana Riva |  |
| 61 |  |  [Prompt Tuned Embedding Classification for Industry Sector Allocation](https://doi.org/10.18653/v1/2024.naacl-industry.10) |  | 0 | We introduce Prompt Tuned Embedding Classification (PTEC) for classifying companies within an investment firm’s proprietary industry taxonomy, supporting their thematic investment strategy. PTEC assigns companies to the sectors they primarily operate in, conceptualizing this process as a multi-label text classification task. Prompt Tuning, usually deployed as a text-to-text (T2T) classification approach, ensures low computational cost while maintaining high... | Valentin Leonhard Buchner, Lele Cao, JanChristoph Kalo, Vilhelm von Ehrenheim |  |
| 62 |  |  [REXEL: An End-to-end Model for Document-Level Relation Extraction and Entity Linking](https://doi.org/10.18653/v1/2024.naacl-industry.11) |  | 0 | Extracting structured information from unstructured text is critical for many downstream NLP applications and is traditionally achieved by closed information extraction (cIE). However, existing approaches for cIE suffer from two limitations: (i) they are often pipelines which makes them prone to error propagation, and/or (ii) they are restricted to sentence level which prevents them from capturing long-range dependencies and results in expensive inference... | Nacime Bouziani, Shubhi Tyagi, Joseph Fisher, Jens Lehmann, Andrea Pierleoni |  |
| 63 |  |  [Conformer-Based Speech Recognition On Extreme Edge-Computing Devices](https://doi.org/10.18653/v1/2024.naacl-industry.12) |  | 0 | With increasingly more powerful compute capabilities and resources in today’s devices, traditionally compute-intensive automatic speech recognition (ASR) has been moving from the cloud to devices to better protect user privacy. However, it is still challenging to implement on-device ASR on resource-constrained devices, such as smartphones, smart wearables, and other small home automation devices. In this paper, we propose a series of model architecture... | Mingbin Xu, Alex Jin, Sicheng Wang, Mu Su, Tim Ng, Henry Mason, Shiyi Han, Zhihong Lei, Yaqiao Deng, Zhen Huang, Mahesh Krishnamoorthy |  |
| 64 |  |  [Generating Signed Language Instructions in Large-Scale Dialogue Systems](https://doi.org/10.18653/v1/2024.naacl-industry.13) |  | 0 | We introduce a goal-oriented conversational AI system enhanced with American Sign Language (ASL) instructions, presenting the first implementation of such a system on a worldwide multimodal conversational AI platform. Accessible through a touch-based interface, our system receives input from users and seamlessly generates ASL instructions by leveraging retrieval methods and cognitively based gloss translations. Central to our design is a sign translation... | Mert Inan, Katherine Atwell, Anthony Sicilia, Lorna C. Quandt, Malihe Alikhani |  |
| 65 |  |  [Leveraging Natural Language Processing and Large Language Models for Assisting Due Diligence in the Legal Domain](https://doi.org/10.18653/v1/2024.naacl-industry.14) |  | 0 | Due diligence is a crucial legal process that mitigates potential risks of mergers and acquisitions (M&A). However, despite its prominent importance, there has been a lack of research regarding leveraging NLP techniques for due diligence. In this study, our aim is to explore the most efficient deep-learning model architecture for due diligence in terms of performance and latency, and evaluate the potential of large language models (LLMs) as an efficient due... | Myeongjun Jang, Gábor Stikkel |  |
| 66 |  |  [AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators](https://doi.org/10.18653/v1/2024.naacl-industry.15) |  | 0 | Many natural language processing (NLP) tasks rely on labeled data to train machine learning models with high performance. However, data annotation is time-consuming and expensive, especially when the task involves a large amount of data or requires specialized domains. Recently, GPT-3.5 series models have demonstrated remarkable few-shot and zero-shot ability across various NLP tasks. In this paper, we first claim that large language models (LLMs), such as... | Xingwei He, Zhenghao Lin, Yeyun Gong, ALong Jin, Hang Zhang, Chen Lin, Jian Jiao, Siu Ming Yiu, Nan Duan, Weizhu Chen |  |
| 67 |  |  [An Automatic Prompt Generation System for Tabular Data Tasks](https://doi.org/10.18653/v1/2024.naacl-industry.16) |  | 0 | Efficient processing of tabular data is important in various industries, especially when working with datasets containing a large number of columns. Large language models (LLMs) have demonstrated their ability on several tasks through carefully crafted prompts. However, creating effective prompts for tabular datasets is challenging due to the structured nature of the data and the need to manage numerous columns. This paper presents an innovative auto-prompt... | Ashlesha Akella, Abhijit Manatkar, Brijkumar Chavda, Hima Patel |  |
| 68 |  |  [Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data](https://doi.org/10.18653/v1/2024.naacl-industry.17) |  | 0 | In the financial industry, identifying the location of parties involved in payments is a major challenge in the context of Anti-Money Laundering transaction monitoring. For this purpose address parsing entails extracting fields such as street, postal code, or country from free text message attributes. While payment processing platforms are updating their standards with more structured formats such as SWIFT with ISO 20022, address parsing remains essential for... | Haitham Hammami, Louis Baligand, Bojan Petrovski |  |
| 69 |  |  [Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain](https://doi.org/10.18653/v1/2024.naacl-industry.18) |  | 0 | In difficult decision-making scenarios, it is common to have conflicting opinions among expert human decision-makers as there may not be a single right answer. Such decisions may be guided by different attributes that can be used to characterize an individual’s decision. We introduce a novel dataset for medical triage decision-making, labeled with a set of decision-maker attributes (DMAs). This dataset consists of 62 scenarios, covering six different DMAs,... | Brian Hu, Bill Ray, Alice Leung, Amy Summerville, David Joy, Christopher Funk, Arslan Basharat |  |
| 70 |  |  [Reducing hallucination in structured outputs via Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.naacl-industry.19) |  | 0 | A current limitation of Generative AI (GenAI) is its propensity to hallucinate. While Large Language Models (LLM) have taken the world by storm, without eliminating or at least reducing hallucination, real-world GenAI systems will likely continue to face challenges in user adoption. In the process of deploying an enterprise application that produces workflows from natural language requirements, we devised a system leveraging Retrieval-Augmented Generation... | Orlando Ayala, Patrice Béchard |  |
| 71 |  |  [Towards Translating Objective Product Attributes Into Customer Language](https://doi.org/10.18653/v1/2024.naacl-industry.20) |  | 0 | When customers search online for a product they are not familiar with, their needs are often expressed through subjective product attributes, such as ”picture quality” for a TV or ”easy to clean” for a sofa. In contrast, the product catalog in online stores includes objective attributes such as ”screen resolution” or ”material”. In this work, we aim to find a link between the objective product catalog and the subjective needs of the customers, to help... | Ram Yazdi, Oren Kalinsky, Alexander Libov, Dafna Shahaf |  |
| 72 |  |  [Automating the Generation of a Functional Semantic Types Ontology with Foundational Models](https://doi.org/10.18653/v1/2024.naacl-industry.21) |  | 0 | The rise of data science, the inherent dirtiness of data, and the proliferation of vast data providers have increased the value proposition of Semantic Types. Semantic Types are a way of encoding contextual information onto a data schema that informs the user about the definitional meaning of data, its broader context, and relationships to other types. We increasingly see a world where providing structure to this information, attached directly to data, will... | Sachin Konan, Larry Rudolph, Scott Affens |  |
| 73 |  |  [Leveraging Customer Feedback for Multi-modal Insight Extraction](https://doi.org/10.18653/v1/2024.naacl-industry.22) |  | 0 | Businesses can benefit from customer feedback in different modalities, such as text and images, to enhance their products and services. However, it is difficult to extract actionable and relevant pairs of text segments and images from customer feedback in a single pass. In this paper, we propose a novel multi-modal method that fuses image and text information in a latent space and decodes it to extract the relevant feedback segments using an image-text... | Sandeep Sricharan Mukku, Abinesh Kanagarajan, Pushpendu Ghosh, Chetan Aggarwal |  |
| 74 |  |  [Optimizing LLM Based Retrieval Augmented Generation Pipelines in the Financial Domain](https://doi.org/10.18653/v1/2024.naacl-industry.23) |  | 0 | Retrieval Augmented Generation (RAG) is a prominent approach in real-word applications for grounding large language model (LLM) generations in up to date and domain-specific knowledge. However, there is a lack of systematic investigations of the impact of each component (retrieval quality, prompts, generation models) on the generation quality of a RAG pipeline in real world scenarios. In this study, we benchmark 6 LLMs in 15 retrieval scenarios exploring 9... | Yiyun Zhao, Prateek Singh, Hanoz Bhathena, Bernardo Ramos, Aviral Joshi, Swaroop Gadiyaram, Saket Sharma |  |
| 75 |  |  [Scaling Up Authorship Attribution](https://doi.org/10.18653/v1/2024.naacl-industry.24) |  | 0 | We describe our system for authorship attribution in the IARPA HIATUS program. We describe the model and compute infrastructure developed to satisfy the set of technical constraints imposed by IARPA, including runtime limits as well as other constraints related to the ultimate use case. One use-case constraint concerns the explainability of the features used in the system. For this reason, we integrate features from frame semantic parsing, as they are both... | Jacob Striebel, Abishek R. Edikala, Ethan Irby, Alex Rosenfeld, J. Gage, Daniel Dakota, Sandra Kübler |  |
| 76 |  |  [Multimodal Contextual Dialogue Breakdown Detection for Conversational AI Models](https://doi.org/10.18653/v1/2024.naacl-industry.25) |  | 0 | Detecting dialogue breakdown in real time is critical for conversational AI systems, because it enables taking corrective action to successfully complete a task. In spoken dialog systems, this breakdown can be caused by a variety of unexpected situations including high levels of background noise, causing STT mistranscriptions, or unexpected user flows.In particular, industry settings like healthcare, require high precision and high flexibility to navigate... | Md Messal Monem Miah, Ulie Schnaithmann, Arushi Raghuvanshi, Youngseo Son |  |
| 77 |  |  [Deferred NAM: Low-latency Top-K Context Injection via Deferred Context Encoding for Non-Streaming ASR](https://doi.org/10.18653/v1/2024.naacl-industry.26) |  | 0 | Contextual biasing enables speech recognizers to transcribe important phrases in the speaker’s context, such as contact names, even if they are rare in, or absent from, the training data. Attention-based biasing is a leading approach which allows for full end-to-end cotraining of the recognizer and biasing system and requires no separate inference-time components. Such biasers typically consist of a context encoder; followed by a context filter which narrows... | Zelin Wu, Gan Song, Christopher Li, Pat Rondon, Zhong Meng, Xavier Velez, Weiran Wang, Diamantino Caseiro, Golan Pundak, Tsendsuren Munkhdalai, Angad Chandorkar, Rohit Prabhavalkar |  |
| 78 |  |  [Less is More for Improving Automatic Evaluation of Factual Consistency](https://doi.org/10.18653/v1/2024.naacl-industry.27) |  | 0 | Assessing the factual consistency of automatically generated texts in relation to source context is crucial for developing reliable natural language generation applications. Recent literature proposes AlignScore which uses a unified alignment model to evaluate factual consistency and substantially outperforms previous methods across many benchmark tasks. In this paper, we take a closer look of datasets used in AlignScore and uncover an unexpected finding:... | Tong Wang, Ninad Kulkarni, Yanjun Qi |  |
| 79 |  |  [DriftWatch: A Tool that Automatically Detects Data Drift and Extracts Representative Examples Affected by Drift](https://doi.org/10.18653/v1/2024.naacl-industry.28) |  | 0 | Data drift, which denotes a misalignment between the distribution of reference (i.e., training) and production data, constitutes a significant challenge for AI applications, as it undermines the generalisation capacity of machine learning (ML) models. Therefore, it is imperative to proactively identify data drift before users meet with performance degradation. Moreover, to ensure the successful execution of AI services, endeavours should be directed not only... | Myeongjun Jang, Antonios Georgiadis, Yiyun Zhao, Fran Silavong |  |
| 80 |  |  [Graph Integrated Language Transformers for Next Action Prediction in Complex Phone Calls](https://doi.org/10.18653/v1/2024.naacl-industry.29) |  | 0 | Current Conversational AI systems employ different machine learning pipelines, as well as external knowledge sources and business logic to predict the next action. Maintaining various components in dialogue managers’ pipeline adds complexity in expansion and updates, increases processing time, and causes additive noise through the pipeline that can lead to incorrect next action prediction. This paper investigates graph integration into language transformers... | Amin Hosseiny Marani, Ulie Schnaithmann, Youngseo Son, Akil Iyer, Manas Paldhe, Arushi Raghuvanshi |  |
| 81 |  |  [Leveraging LLMs for Dialogue Quality Measurement](https://doi.org/10.18653/v1/2024.naacl-industry.30) |  | 0 | In task-oriented conversational AI evaluation, unsupervised methods poorly correlate with human judgments, and supervised approaches lack generalization. Recent advances in large language models (LLMs) show robust zero- and few-shot capabilities across NLP tasks. Our paper explores using LLMs for automated dialogue quality evaluation, experimenting with various configurations on public and proprietary datasets. Manipulating factors such as model size,... | Jinghan Jia, Abi Komma, Timothy Leffel, Xujun Peng, Ajay Nagesh, Tamer Soliman, Aram Galstyan, Anoop Kumar |  |
| 82 |  |  [Uncertainty Estimation in Large Language Models to Support Biodiversity Conservation](https://doi.org/10.18653/v1/2024.naacl-industry.31) |  | 0 | Large Language Models (LLM) provide significant value in question answering (QA) scenarios and have practical application in complex decision-making contexts, such as biodiversity conservation. However, despite substantial performance improvements, they may still produce inaccurate outcomes. Consequently, incorporating uncertainty quantification alongside predictions is essential for mitigating the potential risks associated with their use. This study... | Maria MoraCross, Saúl Calderón Ramírez |  |
| 83 |  |  [AMA-LSTM: Pioneering Robust and Fair Financial Audio Analysis for Stock Volatility Prediction](https://doi.org/10.18653/v1/2024.naacl-industry.32) |  | 0 | Stock volatility prediction is an important task in the financial industry. Recent multimodal methods have shown advanced results by combining text and audio information, such as earnings calls. However, these multimodal methods have faced two drawbacks. First, they often fail to yield reliable models and overfit the data due to their absorption of stochastic information from the stock market. Moreover, using multimodal models to predict stock volatility... | Shengkun Wang, Taoran Ji, Jianfeng He, Mariam Almutairi, Dan Wang, Linhan Wang, Min Zhang, ChangTien Lu |  |
| 84 |  |  [Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?](https://doi.org/10.18653/v1/2024.naacl-industry.33) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities to solve a wide range of tasks without being explicitly fine-tuned on task-specific datasets. However, deploying LLMs in the real world is not trivial, as it requires substantial computing resources. In this paper, we investigate whether smaller, Compact LLMs are a good alternative to the comparatively Larger LLMs to address significant costs associated with utilizing LLMs in the real... | XueYong Fu, Md. Tahmid Rahman Laskar, Elena Khasanova, Cheng Chen, Shashi Bhushan TN |  |
| 85 |  |  [Shears: Unstructured Sparsity with Neural Low-rank Adapter Search](https://doi.org/10.18653/v1/2024.naacl-industry.34) |  | 0 | Recently, several approaches successfully demonstrated that weight-sharing Neural Architecture Search (NAS) can effectively explore a search space of elastic low-rank adapters (LoRA), allowing the parameter-efficient fine-tuning (PEFT) and compression of large language models. In this paper, we introduce a novel approach called Shears, demonstrating how the integration of cost-effective sparsity and a proposed Neural Low-rank adapter Search (NLS) algorithm... | J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain |  |
| 86 |  |  [Tree-of-Question: Structured Retrieval Framework for Korean Question Answering Systems](https://doi.org/10.18653/v1/2024.naacl-industry.35) |  | 0 | We introduce Korean language-specific RAG-based QA systems, primarily through the innovative Tree-of-Question (ToQ) methodology and enhanced query generation techniques. We address the complex, multi-hop nature of real-world questions by effectively integrating advanced LLMs with nuanced query planning. Our comprehensive evaluations, including a newly created Korean multi-hop QA dataset, demonstrate our method’s ability to elevate response validity and... | Dongyub Lee, Younghun Jeong, HwaYeon Kim, Hongyeon Yu, Seunghyun Han, Taesun Whang, Seungwoo Cho, Chanhee Lee, Gunsu Lee, Youngbum Kim |  |
| 87 |  |  [LLM-based Frameworks for API Argument Filling in Task-Oriented Conversational Systems](https://doi.org/10.18653/v1/2024.naacl-industry.36) |  | 0 | Task-orientated conversational agents interact with users and assist them via leveraging external APIs. A typical task-oriented conversational system can be broken down into three phases: external API selection, argument filling, and response generation. The focus of our work is the task of argument filling, which is in charge of accurately providing arguments required by the selected API. Upon comprehending the dialogue history and the pre-defined API... | Jisoo Mok, Mohammad Kachuee, Shuyang Dai, Shayan Ray, Tara Taghavi, Sungroh Yoon |  |
| 88 |  |  [Large Language Models Encode the Practice of Medicine](https://doi.org/10.18653/v1/2024.naacl-industry.37) |  | 0 | Healthcare tasks such as predicting clinical outcomes across medical and surgical populations, disease prediction, predicting patient health journeys, are typically approached with supervised learning on task-specific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of billions of administrative claims, which essentially encapsulates the practice of medicine, offering a... | Teja Kanchinadam, Shaheen Gauher |  |
| 89 |  |  [Leveraging Interesting Facts to Enhance User Engagement with Conversational Interfaces](https://doi.org/10.18653/v1/2024.naacl-industry.38) |  | 0 | Conversational Task Assistants (CTAs) guide users in performing a multitude of activities, such as making recipes. However, ensuring that interactions remain engaging, interesting, and enjoyable for CTA users is not trivial, especially for time-consuming or challenging tasks. Grounded in psychological theories of human interest, we propose to engage users with contextual and interesting statements or facts during interactions with a multi-modal CTA, to reduce... | Nikhita Vedula, Giuseppe Castellucci, Eugene Agichtein, Oleg Rokhlenko, Shervin Malmasi |  |
| 90 |  |  [Search Query Refinement for Japanese Named Entity Recognition in E-commerce Domain](https://doi.org/10.18653/v1/2024.naacl-industry.39) |  | 0 | In the E-Commerce domain, search query refinement reformulates malformed queries into canonicalized forms by preprocessing operations such as “term splitting” and “term merging”. Unfortunately, most relevant research is rather limited to English. In particular, there is a severe lack of study on search query refinement for the Japanese language. Furthermore, no attempt has ever been made to apply refinement methods to data improvement for downstream NLP tasks... | Yuki Nakayama, Ryutaro Tatsushima, Erick Mendieta, Koji Murakami, Keiji Shinzato |  |
| 91 |  |  [EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal LLM](https://doi.org/10.18653/v1/2024.naacl-industry.40) |  | 0 | In e-commerce, accurately extracting product attribute values from multimodal data is crucial for improving user experience and operational efficiency of retailers. However, previous approaches to multimodal attribute value extraction often struggle with implicit attribute values embedded in images or text, rely heavily on extensive labeled data, and can easily confuse similar attribute values. To address these issues, we introduce EIVEN, a data- and... | Henry Peng Zou, Gavin Heqing Yu, Ziwei Fan, Dan Bu, Han Liu, Peng Dai, Dongmei Jia, Cornelia Caragea |  |
| 92 |  |  [Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data](https://doi.org/10.18653/v1/2024.naacl-industry.41) |  | 0 | Augmenting Large Language Models (LLMs) for Question Answering (QA) with domain specific data has attracted wide attention. However, domain data often exists in a hybrid format, including text and semi-structured tables, posing challenges for the seamless integration of information. Table-to-Text Generation is a promising solution by facilitating the transformation of hybrid data into a uniformly text-formatted corpus. Although this technique has been widely... | Dehai Min, Nan Hu, Rihui Jin, Nuo Lin, Jiaoyan Chen, Yongrui Chen, Yu Li, Guilin Qi, Yun Li, Nijun Li, Qianren Wang |  |
| 93 |  |  [Solving General Natural-Language-Description Optimization Problems with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-industry.42) |  | 0 | Optimization problems seek to find the best solution to an objective under a set of constraints, and have been widely investigated in real-world applications. Modeling and solving optimization problems in a specific domain typically require a combination of domain knowledge, mathematical skills, and programming ability, making it difficult for general users and even domain professionals. In this paper, we propose a novel framework called OptLLM that augments... | Jihai Zhang, Wei Wang, Siyan Guo, Li Wang, Fangquan Lin, Cheng Yang, Wotao Yin |  |
| 94 |  |  [Self-Regulated Data-Free Knowledge Amalgamation for Text Classification](https://doi.org/10.18653/v1/2024.naacl-industry.43) |  | 0 | Recently, there has been a growing availability of pre-trained text models on various model repositories. These models greatly reduce the cost of training new models from scratch as they can be fine-tuned for specific tasks or trained on large datasets. However, these datasets may not be publicly accessible due to the privacy, security, or intellectual property issues. In this paper, we aim to develop a lightweight student network that can learn from multiple... | Prashanth Vijayaraghavan, Hongzhi Wang, Luyao Shi, Tyler Baldwin, David Beymer, Ehsan Degan |  |
| 95 |  |  [Frontmatter](https://aclanthology.org/2024.naacl-long.0) |  | 0 |  |  |  |
| 96 |  |  [Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences](https://doi.org/10.18653/v1/2024.naacl-long.1) |  | 0 | Named entity recognition is a key component of Information Extraction (IE), particularly in scientific domains such as biomedicine and chemistry, where large language models (LLMs), e.g., ChatGPT, fall short. We investigate the applicability of transfer learning for enhancing a named entity recognition model trained in the biomedical domain (the source domain) to be used in the chemical domain (the target domain). A common practice for training such a model... | Hongyi Liu, Qingyun Wang, Payam Karisani, Heng Ji |  |
| 97 |  |  [Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation](https://doi.org/10.18653/v1/2024.naacl-long.2) |  | 0 | The diffusion model, a new generative modeling paradigm, has achieved great success in image, audio, and video generation.However, considering the discrete categorical nature of the text, it is not trivial to extend continuous diffusion models to natural language. In this work, we propose SeqDiffuSeq, a text diffusion model, to approach sequence-to-sequence text generation with an encoder-decoder Transformer architecture.To improve the generation performance,... | Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, Songfang Huang |  |
| 98 |  |  [An Interactive Framework for Profiling News Media Sources](https://doi.org/10.18653/v1/2024.naacl-long.3) |  | 0 | The recent rise of social media has led to the spread of large amounts of fake and biased news, content published with the intent to sway beliefs. While detecting and profiling the sources that spread this news is important to maintain a healthy society, it is challenging for automated systems.In this paper, we propose an interactive framework for news media profiling. It combines the strengths of graph based news media profiling models, Pre-trained Large... | Nikhil Mehta, Dan Goldwasser |  |
| 99 |  |  [Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study](https://doi.org/10.18653/v1/2024.naacl-long.4) |  | 0 | Large Language Models (LLMs) have shown remarkable proficiency in language understanding and have been successfully applied to a variety of real-world tasks through task-specific fine-tuning or prompt engineering. Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data. In our research, we introduce a... | Yinghao Li, Haorui Wang, Chao Zhang |  |
| 100 |  |  [TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation](https://doi.org/10.18653/v1/2024.naacl-long.5) |  | 0 | Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue sys- tems to effectively respond to user requests. The emotions in a conversation can be identi- fied by the representations from various modal- ities, such as audio, visual, and text. How- ever, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading... | Taeyang Yun, Hyunkuk Lim, Jeonghwan Lee, Min Song |  |
| 101 |  |  [Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries](https://doi.org/10.18653/v1/2024.naacl-long.6) |  | 0 | Few-shot dialogue state tracking (DST) with Large Language Models (LLM) relies on an effective and efficient conversation retriever to find similar in-context examples for prompt learning. Previous works use raw dialogue context as search keys and queries, and a retriever is fine-tuned with annotated dialogues to achieve superior performance. However, the approach is less suited for scaling to new domains or new annotation languages, where fine-tuning data is... | Seanie Lee, Jianpeng Cheng, Joris Driesen, Alexandru Coca, Anders Johannsen |  |
| 102 |  |  [Promptly Predicting Structures: The Return of Inference](https://doi.org/10.18653/v1/2024.naacl-long.7) |  | 0 | Prompt-based methods have been used extensively across NLP to build zero- and few-shot label predictors. Many NLP tasks are naturally structured: that is, their outputs consist of multiple labels which constrain each other. Annotating data for such tasks can be cumbersome. Can the promise of the prompt-based paradigm be extended to such structured outputs? In this paper, we present a framework for constructing zero- and few-shot linguistic structure... | Maitrey Mehta, Valentina Pyatkin, Vivek Srikumar |  |
| 103 |  |  [On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL](https://doi.org/10.18653/v1/2024.naacl-long.8) |  | 0 | Structured data, prevalent in tables, databases, and knowledge graphs, poses a significant challenge in its representation. With the advent of large language models (LLMs), there has been a shift towards linearization-based methods, which process structured data as sequential token streams, diverging from approaches that explicitly model structure, often as a graph. Crucially, there remains a gap in our understanding of how these linearization-based methods... | Yutong Shao, Ndapa Nakashole |  |
| 104 |  |  [Extractive Summarization with Text Generator](https://doi.org/10.18653/v1/2024.naacl-long.9) |  | 0 | Standard extractive systems suffer from the lack of gold training signals since existing corpora solely provide document and human-written summary pairs while disregarding extractive labels. As a result, existing methods resort to imperfect pseudo-labels that are both biased and error-prone, thereby hindering the learning process of extractive models. In contrast, text generators which are commonly employed in abstractive summarization can effortlessly... | Thang Le, Anh Tuan Luu |  |
| 105 |  |  [Self-generated Replay Memories for Continual Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.10) |  | 0 | Modern Neural Machine Translation systems exhibit strong performance in several different languages and are constantly improving. Their ability to learn continuously is, however, still severely limited by the catastrophic forgetting issue. In this work, we leverage a key property of encoder-decoder Transformers, i.e. their generative ability, to propose a novel approach to continually learning Neural Machine Translation systems. We show how this can... | Michele Resta, Davide Bacciu |  |
| 106 |  |  [Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models](https://doi.org/10.18653/v1/2024.naacl-long.11) |  | 0 | Vision-language models (VLMs) have recently demonstrated strong efficacy as visual assistants that can parse natural queries about the visual content and generate human-like outputs. In this work, we explore the ability of these models to demonstrate human-like reasoning based on the perceived information. To address a crucial concern regarding the extent to which their reasoning capabilities are fully consistent and grounded, we also measure the reasoning... | Yangyi Chen, Karan Sikka, Michael Cogswell, Heng Ji, Ajay Divakaran |  |
| 107 |  |  [Building Knowledge-Guided Lexica to Model Cultural Variation](https://doi.org/10.18653/v1/2024.naacl-long.12) |  | 0 | Cultural variation exists between nations (e.g., the United States vs. China), but also within regions (e.g., California vs. Texas, Los Angeles vs. San Francisco). Measuring this regional cultural variation can illuminate how and why people think and behave differently. Historically, it has been difficult to computationally model cultural variation due to a lack of training data and scalability constraints. In this work, we introduce a new research problem... | Shreya Havaldar, Salvatore Giorgi, Sunny Rai, Thomas Talhelm, Sharath Chandra Guntuku, Lyle H. Ungar |  |
| 108 |  |  [Adaptive Rank Selections for Low-Rank Approximation of Language Models](https://doi.org/10.18653/v1/2024.naacl-long.13) |  | 0 | Singular Value Decomposition (SVD) or its weighted variants has significantly progressed in compressing language models. Previous works assume the same importance for all operations and assign the same number of ranks for different layers in a language model. However, such a uniform rank selection is sub-optimal since different operations (layers) have non-uniform demand in capacity. In other words, a desired SVD strategy should allocate more ranks for... | Shangqian Gao, Ting Hua, YenChang Hsu, Yilin Shen, Hongxia Jin |  |
| 109 |  |  [An Empirical Study of Consistency Regularization for End-to-End Speech-to-Text Translation](https://doi.org/10.18653/v1/2024.naacl-long.14) |  | 0 | Consistency regularization methods, such as R-Drop (Liang et al., 2021) and CrossConST (Gao et al., 2023), have achieved impressive supervised and zero-shot performance in the neural machine translation (NMT) field. Can we also boost end-to-end (E2E) speech-to-text translation (ST) by leveraging consistency regularization? In this paper, we conduct empirical studies on intra-modal and cross-modal consistency and propose two training strategies, SimRegCR and... | Pengzhi Gao, Ruiqing Zhang, Zhongjun He, Hua Wu, Haifeng Wang |  |
| 110 |  |  [Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration](https://doi.org/10.18653/v1/2024.naacl-long.15) |  | 0 | Human intelligence thrives on cognitive synergy, where collaboration among different minds yield superior outcomes compared to isolated individuals. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist is an intelligent agent that collaboratively combines multiple minds’ strengths and knowledge to enhance... | Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, Heng Ji |  |
| 111 |  |  [FPT: Feature Prompt Tuning for Few-shot Readability Assessment](https://doi.org/10.18653/v1/2024.naacl-long.16) |  | 0 | Prompt-based methods have achieved promising results in most few-shot text classification tasks. However, for readability assessment tasks, traditional prompt methods lack crucial linguistic knowledge, which has already been proven to be essential.Moreover, previous studies on utilizing linguistic features have shown non-robust performance in few-shot settings and may even impair model performance.To address these issues, we propose a novel prompt-based... | Ziyang Wang, Sanwoo Lee, HsiuYuan Huang, Yunfang Wu |  |
| 112 |  |  [Self-Prompting Large Language Models for Zero-Shot Open-Domain QA](https://doi.org/10.18653/v1/2024.naacl-long.17) |  | 0 | Open-Domain Question Answering (ODQA) aims to answer questions without explicitly providing specific background documents. This task becomes notably challenging in a zero-shot setting where no data is available to train tailored retrieval-reader models.While recent Large Language Models (LLMs) like GPT-3 have demonstrated their effectiveness in zero-shot ODQA using direct prompting methods, these methods still fall short of fully harnessing the potential of... | Junlong Li, Jinyuan Wang, Zhuosheng Zhang, Hai Zhao |  |
| 113 |  |  [Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?](https://doi.org/10.18653/v1/2024.naacl-long.18) |  | 0 | Since the recent prosperity of Large Language Models (LLMs), there have been interleaved discussions regarding how to reduce hallucinations from LLM responses, how to increase the factuality of LLMs, and whether Knowledge Graphs (KGs), which store the world knowledge in a symbolic form, will be replaced with LLMs. In this paper, we try to answer these questions from a new angle: How knowledgeable are LLMs?To answer this question, we constructed Head-to-Tail,... | Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, Xin Luna Dong |  |
| 114 |  |  [kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.19) |  | 0 | Task-Oriented Parsing (TOP) enables conversational assistants to interpret user commands expressed in natural language, transforming them into structured outputs that combine elements of both natural language and intent/slot tags. Recently, Large Language Models (LLMs) have achieved impressive performance in synthesizing computer programs based on a natural-language prompt, mitigating the gap between natural language and structured programs. Our paper focuses... | Wenting Zhao, Ye Liu, Yao Wan, Yibo Wang, Qingyang Wu, Zhongfen Deng, Jiangshu Du, Shuaiqi Liu, Yunlong Xu, Philip S. Yu |  |
| 115 |  |  [ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems](https://doi.org/10.18653/v1/2024.naacl-long.20) |  | 0 | Evaluating retrieval-augmented generation (RAG) systems traditionally relies on hand annotations for input queries, passages to retrieve, and responses to generate. We introduce ARES, an Automated RAG Evaluation System, for evaluating RAG systems along the dimensions of context relevance, answer faithfulness, and answer relevance. By creating its own synthetic training data, ARES finetunes lightweight LM judges to assess the quality of individual RAG... | Jon SaadFalcon, Omar Khattab, Christopher Potts, Matei Zaharia |  |
| 116 |  |  [DEMO: A Statistical Perspective for Efficient Image-Text Matching](https://doi.org/10.18653/v1/2024.naacl-long.21) |  | 0 | Image-text matching has been a long-standing problem, which seeks to connect vision and language through semantic understanding. Due to the capability to manage large-scale raw data, unsupervised hashing-based approaches have gained prominence recently. They typically construct a semantic similarity structure using the natural distance, which subsequently guides the optimization of the hashing network. However, the similarity structure could be biased at the... | Fan Zhang, XianSheng Hua, Chong Chen, Xiao Luo |  |
| 117 |  |  [SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.22) |  | 0 | We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical... | Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, AiTi Aw, Nancy F. Chen |  |
| 118 |  |  [Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision](https://doi.org/10.18653/v1/2024.naacl-long.23) |  | 0 | Large multimodal models suffer from multimodal hallucination, where they provide incorrect responses misaligned with the given visual information. Recent works have conjectured that one of the reasons behind multimodal hallucination is due to the vision encoder failing to ground on the image properly. To mitigate this issue, we propose a novel approach that leverages self-feedback as visual cues. Building on this approach, we introduce Volcano, a multimodal... | Seongyun Lee, Sue Hyun Park, Yongrae Jo, Minjoon Seo |  |
| 119 |  |  [LLMs Are Few-Shot In-Context Low-Resource Language Learners](https://doi.org/10.18653/v1/2024.naacl-long.24) |  | 0 | In-context learning (ICL) empowers large language models (LLMs) to perform diverse tasks in underrepresented languages using only short in-context information, offering a crucial avenue for narrowing the gap between high-resource and low-resource languages.Nonetheless, there is only a handful of works explored ICL for low-resource languages with most of them focusing on relatively high-resource languages, such as French and Spanish. In this work, we... | Samuel Cahyawijaya, Holy Lovenia, Pascale Fung |  |
| 120 |  |  [Simple and effective data augmentation for compositional generalization](https://doi.org/10.18653/v1/2024.naacl-long.25) |  | 0 | Compositional generalization, the ability to predict complex meanings from training on simpler sentences, poses challenges for powerful pretrained seq2seq models. In this paper, we show that data augmentation methods that sample MRs and backtranslate them can be effective for compositional generalization, but only if we sample from the right distribution. Remarkably, sampling from a uniform distribution performs almost as well as sampling from the test... | Yuekun Yao, Alexander Koller |  |
| 121 |  |  [Rethinking Tabular Data Understanding with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.26) |  | 0 | Large Language Models (LLMs) have shown to be capable of various tasks, yet their capability in interpreting and reasoning over tabular data remains an underexplored area. In this context, this study investigates from three core perspectives: the robustness of LLMs to structural perturbations in tables, the comparative analysis of textual and symbolic reasoning on tables, and the potential of boosting model performance through the aggregation of multiple... | Tianyang Liu, Fei Wang, Muhao Chen |  |
| 122 |  |  [From Shortcuts to Triggers: Backdoor Defense with Denoised PoE](https://doi.org/10.18653/v1/2024.naacl-long.27) |  | 0 | Language models are often at risk of diverse backdoor attacks, especially data poisoning. Thus, it is important to investigate defense solutions for addressing them. Existing backdoor defense methods mainly focus on backdoor attacks with explicit triggers, leaving a universal defense against various backdoor attacks with diverse triggers largely unexplored. In this paper, we propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised... | Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen |  |
| 123 |  |  [BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain](https://doi.org/10.18653/v1/2024.naacl-long.28) |  | 0 | Several large-scale datasets (e.g., WikiSQL, Spider) for developing natural language interfaces to databases have recently been proposed. These datasets cover a wide breadth of domains but fall short on some essential domains, such as finance and accounting. Given that accounting databases are used worldwide, particularly by non-technical people, there is an imminent need to develop models that could help extract information from accounting databases via... | Rahul Kumar, Amar Raja Dibbu, Shrutendra Harsola, Vignesh Subrahmaniam, Ashutosh Modi |  |
| 124 |  |  [FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs](https://doi.org/10.18653/v1/2024.naacl-long.29) |  | 0 | Planning is a crucial task for agents in task oriented dialogs (TODs). Human agents typically resolve user issues by following predefined workflows, decomposing workflow steps into actionable items, and performing actions by executing APIs in order; all of which require reasoning and planning. With the recent advances in LLMs, there have been increasing attempts to use them for task planning and API usage. However, the faithfulness of the plans to predefined... | Shamik Roy, Sailik Sengupta, Daniele Bonadiman, Saab Mansour, Arshit Gupta |  |
| 125 |  |  [DuRE: Dual Contrastive Self Training for Semi-Supervised Relation Extraction](https://doi.org/10.18653/v1/2024.naacl-long.30) |  | 0 | Document-level Relation Extraction (RE) aims to extract relation triples from documents. Existing document-RE models typically rely on supervised learning which requires substantial labeled data. To alleviate the amount of human supervision, Self-training (ST) has prospered again in language understanding by augmenting the fine-tuning of big pre-trained models whenever labeled data is insufficient. However, existing ST methods in RE fail to tackle the... | Yuxi Feng, Laks V. S. Lakshmanan |  |
| 126 |  |  [Query-Efficient Textual Adversarial Example Generation for Black-Box Attacks](https://doi.org/10.18653/v1/2024.naacl-long.31) |  | 0 | Deep neural networks for Natural Language Processing (NLP) have been demonstrated to be vulnerable to textual adversarial examples. Existing black-box attacks typically require thousands of queries on the target model, making them expensive in real-world applications. In this paper, we propose a new approach that guides the word substitutions using prior knowledge from the training set to improve the attack efficiency. Specifically, we introduce Adversarial... | Zhen Yu, Zhenhua Chen, Kun He |  |
| 127 |  |  [Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles](https://doi.org/10.18653/v1/2024.naacl-long.32) |  | 0 | Previous research in multi-document news summarization has typically concentrated on collating information that all sources agree upon. However, the summarization of diverse information dispersed across multiple articles about an event remains underexplored. In this paper, we propose a new task of summarizing diverse information encountered in multiple news articles encompassing the same event. To facilitate this task, we outlined a data collection schema for... | KungHsiang Huang, Philippe Laban, Alexander R. Fabbri, Prafulla Kumar Choubey, Shafiq Joty, Caiming Xiong, ChienSheng Wu |  |
| 128 |  |  [AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation](https://doi.org/10.18653/v1/2024.naacl-long.33) |  | 0 | Ensuring factual consistency is crucial for natural language generation tasks, particularly in abstractive summarization, where preserving the integrity of information is paramount. Prior works on evaluating factual consistency of summarization often take the entailment-based approaches that first generate perturbed (factual inconsistent) summaries and then train a classifier on the generated data to detect the factually inconsistencies during testing time.... | Haoyi Qiu, KungHsiang Huang, Jingnong Qu, Nanyun Peng |  |
| 129 |  |  [PILOT: Legal Case Outcome Prediction with Case Law](https://doi.org/10.18653/v1/2024.naacl-long.34) |  | 0 | Machine learning shows promise in predicting the outcome of legal cases, but most research has concentrated on civil law cases rather than case law systems. We identified two unique challenges in making legal case outcome predictions with case law. First, it is crucial to identify relevant precedent cases that serve as fundamental evidence for judges during decision-making. Second, it is necessary to consider the evolution of legal principles over time, as... | Lang Cao, Zifeng Wang, Cao Xiao, Jimeng Sun |  |
| 130 |  |  [ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.35) |  | 0 | Parameter-efficient fine-tuning (PEFT) is widely studied for its effectiveness and efficiency in the era of large language models. Low-rank adaptation (LoRA) has demonstrated commendable performance as a popular and representative method. However, it is implemented with a fixed intrinsic rank that might not be the ideal setting for the downstream tasks. Recognizing the need for more flexible downstream task adaptation, we extend the methodology of LoRA to an... | Zequan Liu, Jiawen Lyn, Wei Zhu, Xing Tian, Yvette Graham |  |
| 131 |  |  [R-Spin: Efficient Speaker and Noise-invariant Representation Learning with Acoustic Pieces](https://doi.org/10.18653/v1/2024.naacl-long.36) |  | 0 | This paper introduces Robust Spin (R-Spin), a data-efficient domain-specific self-supervision method for speaker and noise-invariant speech representations by learning discrete acoustic units with speaker-invariant clustering (Spin). R-Spin resolves Spin’s issues and enhances content representations by learning to predict acoustic pieces. R-Spin offers a 12X reduction in computational resources compared to previous state-of-the-art methods while outperforming... | HengJui Chang, James R. Glass |  |
| 132 |  |  [InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions](https://doi.org/10.18653/v1/2024.naacl-long.37) |  | 0 | Instruction tuning effectively optimizes Large Language Models (LLMs) for downstream tasks. Due to the changing environment in real-life applications, LLMs necessitate continual task-specific adaptation without catastrophic forgetting. Considering the heavy computational cost, replay-based Continual Learning (CL) methods are the simplest and most widely used for LLMs to address the forgetting issue. However, traditional replay-based methods do not fully... | Yifan Wang, Yafei Liu, Chufan Shi, Haoling Li, Chen Chen, Haonan Lu, Yujiu Yang |  |
| 133 |  |  [Language Agnostic Code Embeddings](https://doi.org/10.18653/v1/2024.naacl-long.38) |  | 0 | Recently, code language models have achieved notable advancements in addressing a diverse array of essential code comprehension and generation tasks. Yet, the field lacks a comprehensive deep dive and understanding of the code embeddings of multilingual code models. In this paper, we present a comprehensive study on multilingual code embeddings, focusing on the cross-lingual capabilities of these embeddings across different programming languages. Through... | Saiteja Utpala, Alex Gu, PinYu Chen |  |
| 134 |  |  [An Examination of the Compositionality of Large Generative Vision-Language Models](https://doi.org/10.18653/v1/2024.naacl-long.39) |  | 0 | With the success of Large Language Models (LLMs), many Generative Vision-Language Models (GVLMs) have been constructed via multimodal instruction tuning. However, the performance of GVLMs in multimodal compositional reasoning remains under-explored. In this paper, we examine both the evaluation metrics ( VisualGPTScore, etc.) and current benchmarks for evaluating the compositionality of GVLMs. We identify the syntactical bias in current benchmarks, which is... | Teli Ma, Rong Li, Junwei Liang |  |
| 135 |  |  [Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors](https://doi.org/10.18653/v1/2024.naacl-long.40) |  | 0 | Data poisoning backdoor attacks can cause undesirable behaviors in large language models (LLMs), and defending against them is of increasing importance. Existing defense mechanisms often assume that only one type of trigger is adopted by the attacker, while defending against multiple simultaneous and independent trigger types necessitates general defense frameworks and is relatively unexplored. In this paper, we propose Nested Product of Experts (NPoE)... | Victoria Graf, Qin Liu, Muhao Chen |  |
| 136 |  |  [VertAttack: Taking Advantage of Text Classifiers' Horizontal Vision](https://doi.org/10.18653/v1/2024.naacl-long.41) |  | 0 | Text classification systems have continuouslyimproved in performance over the years. How-ever, nearly all current SOTA classifiers have asimilar shortcoming, they process text in a hor-izontal manner. Vertically written words willnot be recognized by a classifier. In contrast,humans are easily able to recognize and readwords written both horizontally and vertically.Hence, a human adversary could write problem-atic words vertically and the meaning wouldstill... | Jonathan Rusert |  |
| 137 |  |  [KDMCSE: Knowledge Distillation Multimodal Sentence Embeddings with Adaptive Angular margin Contrastive Learning](https://doi.org/10.18653/v1/2024.naacl-long.42) |  | 0 | Previous work on multimodal sentence embedding has proposed multimodal contrastive learning and achieved promising results. However, by taking the rest of the batch as negative samples without reviewing when forming contrastive pairs, those studies encountered many suspicious and noisy negative examples, significantly affecting the methods’ overall performance. In this work, we propose KDMCSE (Knowledge Distillation Multimodal contrastive learning of Sentence... | CongDuy Nguyen, Thong Nguyen, Xiaobao Wu, Anh Tuan Luu |  |
| 138 |  |  [The taste of IPA: Towards open-vocabulary keyword spotting and forced alignment in any language](https://doi.org/10.18653/v1/2024.naacl-long.43) |  | 0 | In this project, we demonstrate that phoneme-based models for speech processing can achieve strong crosslinguistic generalizability to unseen languages. We curated the IPAPACK, a massively multilingual speech corpora with phonemic transcriptions, encompassing more than 115 languages from diverse language families, selectively checked by linguists. Based on the IPAPACK, we propose CLAP-IPA, a multi-lingual phoneme-speech contrastive embedding model capable of... | Jian Zhu, Changbing Yang, Farhan Samir, Jahurul Islam |  |
| 139 |  |  [Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias Towards Vision-Language Tasks](https://doi.org/10.18653/v1/2024.naacl-long.44) |  | 0 | Gender bias in vision-language models (VLMs) can reinforce harmful stereotypes and discrimination. In this paper, we focus on mitigating gender bias towards vision-language tasks. We identify object hallucination as the essence of gender bias in VLMs. Existing VLMs tend to focus on salient or familiar attributes in images but ignore contextualized nuances. Moreover, most VLMs rely on the co-occurrence between specific objects and gender attributes to infer... | Yunqi Zhang, Songda Li, Chunyuan Deng, Luyi Wang, Hui Zhao |  |
| 140 |  |  [BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings](https://doi.org/10.18653/v1/2024.naacl-long.45) |  | 0 | Sentence embeddings are crucial in measuring semantic similarity. Most recent studies employed large language models (LLMs) to learn sentence embeddings. Existing LLMs mainly adopted autoregressive architecture without explicit backward dependency modeling. Therefore, we examined the effects of backward dependencies in LLMs for semantic similarity measurements. Concretely, we propose a novel model: backward dependency enhanced large language model (BeLLM). It... | Xianming Li, Jing Li |  |
| 141 |  |  [Assessing Factual Reliability of Large Language Model Knowledge](https://doi.org/10.18653/v1/2024.naacl-long.46) |  | 0 | The factual knowledge of LLMs is typically evaluated using accuracy, yet this metric does not capture the vulnerability of LLMs to hallucination-inducing factors like prompt and context variability. How do we evaluate the capabilities of LLMs to consistently produce factually correct answers? In this paper, we propose MOdel kNowledge relIabiliTy scORe (MONITOR), a novel metric designed to directly measure LLMs’ factual reliability. MONITOR is designed to... | Weixuan Wang, Barry Haddow, Alexandra Birch, Wei Peng |  |
| 142 |  |  [Dial-MAE: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems](https://doi.org/10.18653/v1/2024.naacl-long.47) |  | 0 | Dialogue response selection aims to select an appropriate response from several candidates based on a given user and system utterance history. Most existing works primarily focus on post-training and fine-tuning tailored for cross-encoders. However, there are no post-training methods tailored for dense encoders in dialogue response selection. We argue that when the current language model, based on dense dialogue systems (such as BERT), is employed as a dense... | Zhenpeng Su, Xing Wu, Wei Zhou, Guangyuan Ma, Songlin Hu |  |
| 143 |  |  [Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model](https://doi.org/10.18653/v1/2024.naacl-long.48) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models. In this paper, we introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS)... | Cheng Qian, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu |  |
| 144 |  |  [Create! Don't Repeat: A Paradigm Shift in Multi-Label Augmentation through Label Creative Generation](https://doi.org/10.18653/v1/2024.naacl-long.49) |  | 0 | We propose Label Creative Generation (LCG), a new paradigm in multi-label data augmentation. Beyond repeating data points with fixed labels, LCG creates new data by exploring innovative label combinations. Within LCG, we introduce Tail-Driven Conditional Augmentation (TDCA), combining tail-driven label sampling and label-conditioned text generation for balanced, consistent data augmentation. Our approach has demonstrated a \*\*100.21%\*\* increase in PSP@1... | Letian Wang, Xianggen Liu, Jiancheng Lv |  |
| 145 |  |  [Neurocache: Efficient Vector Retrieval for Long-range Language Modeling](https://doi.org/10.18653/v1/2024.naacl-long.50) |  | 0 | This paper introduces Neurocache, an approach to extend the effective context size of large language models (LLMs) using an external vector cache to store its past states. Like recent vector retrieval approaches, Neurocache uses an efficient k-nearest-neighbor (kNN) algorithm to retrieve relevant past states and incorporate them into the attention process. Neurocache improves upon previous methods by (1) storing compressed states, which reduces cache size;... | Ali Safaya, Deniz Yuret |  |
| 146 |  |  [Unveiling the Generalization Power of Fine-Tuned Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.51) |  | 0 | While Large Language Models (LLMs) have demonstrated exceptional multitasking abilities, fine-tuning these models on downstream, domain-specific datasets is often necessary to yield superior performance on test sets compared to their counterparts without fine-tuning. However, the comprehensive effects of fine-tuning on the LLMs’ generalization ability are not fully understood.This paper delves into the differences between original, unmodified LLMs and their... | Haoran Yang, Yumeng Zhang, Jiaqi Xu, Hongyuan Lu, PhengAnn Heng, Wai Lam |  |
| 147 |  |  [A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.52) |  | 0 | Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether... | Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang |  |
| 148 |  |  [Exploring Self-supervised Logic-enhanced Training for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.53) |  | 0 | Traditional attempts to enhance the logical reasoning abilities of language models often rely on supervised fine-tuning, limiting their generalization to new tasks or domains. Large Language Models (LLMs), with their capacity to condense vast knowledge, can effectively tackle many tasks. Yet, our experiments reveal a gap in their performance on logical reasoning benchmarks when compared to state-of-the-art fine-tuning based models. To bridge this gap, we... | Fangkai Jiao, Zhiyang Teng, Bosheng Ding, Zhengyuan Liu, Nancy F. Chen, Shafiq Joty |  |
| 149 |  |  [MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.54) |  | 0 | Tool-augmented Large Language Models (TALMs) are known to enhance the skillset of large language models (LLMs), thereby, leading to their improved reasoning abilities across many tasks. While, TALMs have been successfully employed in different question-answering benchmarks, their efficacy on complex mathematical reasoning benchmarks, and the potential complementary benefits offered by tools for knowledge retrieval and mathematical equation solving are open... | Debrup Das, Debopriyo Banerjee, Somak Aditya, Ashish Kulkarni |  |
| 150 |  |  [CoUDA: Coherence Evaluation via Unified Data Augmentation](https://doi.org/10.18653/v1/2024.naacl-long.55) |  | 0 | Coherence evaluation aims to assess the organization and structure of a discourse, which remains challenging even in the era of large language models. Due to the scarcity of annotated data, data augmentation is commonly used for training coherence evaluation models. However, previous augmentations for this task primarily rely on heuristic rules, lacking designing criteria as guidance.In this paper, we take inspiration from linguistic theory of discourse... | Dawei Zhu, Wenhao Wu, Yifan Song, Fangwei Zhu, Ziqiang Cao, Sujian Li |  |
| 151 |  |  [mEdIT: Multilingual Text Editing via Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.56) |  | 0 | We introduce mEdIT, a multi-lingual extension to CoEdIT – the recent state-of-the-art text editing models for writing assistance. mEdIT models are trained by fine-tuning multi-lingual large, pre-trained language models (LLMs) via instruction tuning. They are designed to take instructions from the user specifying the attributes of the desired text in the form of natural language instructions, such as “Grammatik korrigieren” (German) or “이 텍스 트를 단순화” (Korean).... | Vipul Raheja, Dimitris Alikaniotis, Vivek Kulkarni, Bashar Alhafni, Dhruv Kumar |  |
| 152 |  |  [Navigation as Attackers Wish? Towards Building Robust Embodied Agents under Federated Learning](https://doi.org/10.18653/v1/2024.naacl-long.57) |  | 0 | Federated embodied agent learning protects the data privacy of individual visual environments by keeping data locally at each client (the individual environment) during training. However, since the local data is inaccessible to the server under federated learning, attackers may easily poison the training data of the local client to build a backdoor in the agent without notice. Deploying such an agent raises the risk of potential harm to humans, as the... | Yunchao Zhang, Zonglin Di, Kaiwen Zhou, Cihang Xie, Xin Wang |  |
| 153 |  |  [In-context Learning and Gradient Descent Revisited](https://doi.org/10.18653/v1/2024.naacl-long.58) |  | 0 | In-context learning (ICL) has shown impressive results in few-shot learning tasks, yet its underlying mechanism is still not fully understood. A recent line of work suggests that ICL performs gradient descent (GD)-based optimization implicitly. While appealing, much of the research focuses on simplified settings, where the parameters of a shallow model are optimized. In this work, we revisit evidence for ICL-GD correspondence on realistic NLP tasks and... | Gilad Deutch, Nadav Magar, Tomer Bar Natan, Guy Dar |  |
| 154 |  |  [Corpus Considerations for Annotator Modeling and Scaling](https://doi.org/10.18653/v1/2024.naacl-long.59) |  | 0 | Recent trends in natural language processing research and annotation tasks affirm a paradigm shift from the traditional reliance on a single ground truth to a focus on individual perspectives, particularly in subjective tasks. In scenarios where annotation tasks are meant to encompass diversity, models that solely rely on the majority class labels may inadvertently disregard valuable minority perspectives. This oversight could result in the omission of... | Olufunke Oluyemi Sarumi, Béla Neuendorf, Joan Plepi, Lucie Flek, Jörg Schlötterer, Charles Welch |  |
| 155 |  |  [On Large Language Models' Hallucination with Regard to Known Facts](https://doi.org/10.18653/v1/2024.naacl-long.60) |  | 0 | Large language models are successful in answering factoid questions but are also prone to hallucination.We investigate the phenomenon of LLMs possessing correct answer knowledge yet still hallucinating from the perspective of inference dynamics, an area not previously covered in studies on hallucinations.We are able to conduct this analysis via two key ideas.First, we identify the factual questions that query the same triplet knowledge but result in different... | Che Jiang, Biqing Qi, Xiangyu Hong, Dayuan Fu, Yang Cheng, Fandong Meng, Mo Yu, Bowen Zhou, Jie Zhou |  |
| 156 |  |  ["One-Size-Fits-All"? Examining Expectations around What Constitute "Fair" or "Good" NLG System Behaviors](https://doi.org/10.18653/v1/2024.naacl-long.61) |  | 0 | Fairness-related assumptions about what constitute appropriate NLG system behaviors range from invariance, where systems are expected to behave identically for social groups, to adaptation, where behaviors should instead vary across them. To illuminate tensions around invariance and adaptation, we conduct five case studies, in which we perturb different types of identity-related language features (names, roles, locations, dialect, and style) in NLG system... | Li Lucy, Su Lin Blodgett, Milad Shokouhi, Hanna M. Wallach, Alexandra Olteanu |  |
| 157 |  |  [Language Models Hallucinate, but May Excel at Fact Verification](https://doi.org/10.18653/v1/2024.naacl-long.62) |  | 0 | Recent progress in natural language processing (NLP) owes much to remarkable advances in large language models (LLMs). Nevertheless, LLMs frequently “hallucinate,” resulting in non-factual outputs. Our carefully-designed human evaluation substantiates the serious hallucination issue, revealing that even GPT-3.5 produces factual outputs less than 25% of the time. This underscores the importance of fact verifiers in order to measure and incentivize progress.... | Jian Guan, Jesse Dodge, David Wadden, Minlie Huang, Hao Peng |  |
| 158 |  |  [A Rationale-centric Counterfactual Data Augmentation Method for Cross-Document Event Coreference Resolution](https://doi.org/10.18653/v1/2024.naacl-long.63) |  | 0 | Based on Pre-trained Language Models (PLMs), event coreference resolution (ECR) systems have demonstrated outstanding performance in clustering coreferential events across documents. However, the state-of-the-art system exhibits an excessive reliance on the ‘triggers lexical matching’ spurious pattern in the input mention pair text. We formalize the decision-making process of the baseline ECR system using a Structural Causal Model (SCM), aiming to identify... | Bowen Ding, Qingkai Min, Shengkun Ma, Yingjie Li, Linyi Yang, Yue Zhang |  |
| 159 |  |  [TrojFSP: Trojan Insertion in Few-shot Prompt Tuning](https://doi.org/10.18653/v1/2024.naacl-long.64) |  | 0 | Prompt tuning is one of the most effective solutions to adapting a fixed pre-trained language model (PLM) for various downstream tasks, especially with only a few input samples. However, the security issues, e.g., Trojan attacks, of prompt tuning on a few data samples are not well-studied. Transferring established data poisoning attacks directly to few-shot prompt tuning presents multiple challenges. One significant issue is the _poisoned imbalance issue_,... | Mengxin Zheng, Jiaqi Xue, Xun Chen, Yanshan Wang, Qian Lou, Lei Jiang |  |
| 160 |  |  [Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models](https://doi.org/10.18653/v1/2024.naacl-long.65) |  | 0 | Large Language Models (LLMs) exhibit impressive capabilities but also present risks such as biased content generation and privacy issues. One of the current alignment techniques includes principle-driven integration, but it faces challenges arising from the imprecision of manually crafted rules and inadequate risk perception in models without safety training. To address these, we introduce Guide-Align, a two-stage approach. Initially, a safety-trained model... | Yi Luo, Zhenghao Lin, Yuhao Zhang, Jiashuo Sun, Chen Lin, Chengjin Xu, Xiangdong Su, Yelong Shen, Jian Guo, Yeyun Gong |  |
| 161 |  |  [X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs](https://doi.org/10.18653/v1/2024.naacl-long.66) |  | 0 | Understanding when two pieces of text convey the same information is a goal touching many subproblems in NLP, including textual entailment and fact-checking. This problem becomes more complex when those two pieces of text are in different languages. Here, we introduce X-PARADE (Cross-lingual Paragraph-level Analysis of Divergences and Entailments), the first cross-lingual dataset of paragraph-level information divergences. Annotators label a paragraph in a... | Juan Diego Rodriguez, Katrin Erk, Greg Durrett |  |
| 162 |  |  [Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers](https://doi.org/10.18653/v1/2024.naacl-long.67) |  | 0 | Large language models (LLMs) are dramatically influencing AI research, spurring discussions on what has changed so far and how to shape the field’s future. To clarify such questions, we analyze a new dataset of 16,979 LLM-related arXiv papers, focusing on recent trends in 2023 vs. 2018-2022. First, we study disciplinary shifts: LLM research increasingly considers societal impacts, evidenced by 20× growth in LLM submissions to the Computers and Society... | Rajiv Movva, Sidhika Balachandar, Kenny Peng, Gabriel Agostini, Nikhil Garg, Emma Pierson |  |
| 163 |  |  [E⁵: Zero-shot Hierarchical Table Analysis using Augmented LLMs via Explain, Extract, Execute, Exhibit and Extrapolate](https://doi.org/10.18653/v1/2024.naacl-long.68) |  | 0 | Analyzing large hierarchical tables with multi-level headers presents challenges due to their complex structure, implicit semantics, and calculation relationships. While recent advancements in large language models (LLMs) have shown promise in flat table analysis, their application to hierarchical tables is constrained by the reliance on manually curated exemplars and the model’s token capacity limitations. Addressing these challenges, we introduce a novel... | Zhehao Zhang, Yan Gao, JianGuang Lou |  |
| 164 |  |  [S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model](https://doi.org/10.18653/v1/2024.naacl-long.69) |  | 0 | The rapid development of Large Language Models (LLMs) has led to great strides in model capabilities like long-context understanding and reasoning.However, as LLMs are able to process longer contexts, it becomes more challenging to evaluate whether they have acquired certain capabilities, since the length of text (e.g., 200K tokens) they can process far exceeds what humans can reliably assess in a reasonable duration.In this paper, we propose using complex... | Fangyu Lei, Qian Liu, Yiming Huang, Shizhu He, Jun Zhao, Kang Liu |  |
| 165 |  |  [MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.70) |  | 0 | With the rapid development of large language models (LLMs) and their integration into large multimodal models (LMMs), there has beenimpressive progress in zero-shot completion of user-oriented vision-language tasks. However, a gap remains in the domain of chartimage understanding due to the distinct abstract components in charts. To address this, we introduce a large-scale MultiModal ChartInstruction (MMC-Instruction) dataset comprising 600k instances... | Fuxiao Liu, Xiaoyang Wang, Wenlin Yao, Jianshu Chen, Kaiqiang Song, Sangwoo Cho, Yaser Yacoob, Dong Yu |  |
| 166 |  |  [Visual Grounding Helps Learn Word Meanings in Low-Data Regimes](https://doi.org/10.18653/v1/2024.naacl-long.71) |  | 0 | Modern neural language models (LMs) are powerful tools for modeling human sentence production and comprehension, and their internal representations are remarkably well-aligned with representations of language in the human brain. But to achieve these results, LMs must be trained in distinctly un-human-like ways — requiring orders of magnitude more language data than children receive during development, and without perceptual or social context. Do models... | Chengxu Zhuang, Evelina Fedorenko, Jacob Andreas |  |
| 167 |  |  [Accurate Knowledge Distillation via n-best Reranking](https://doi.org/10.18653/v1/2024.naacl-long.72) |  | 0 | We propose utilizing n-best reranking to enhance Sequence-Level Knowledge Distillation (Kim and Rush, 2016) where we extract pseudo-labels for student model’s training data from top n-best hypotheses and leverage a diverse set of models with different inductive biases, objective functions or architectures, including some publicly-available large language models, to pick the highest-quality hypotheses as labels. The effectiveness of our proposal is validated... | Hendra Setiawan |  |
| 168 |  |  [AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition](https://doi.org/10.18653/v1/2024.naacl-long.73) |  | 0 | Recent advancements in large language models (LLMs) have shown promise in multi-step reasoning tasks, yet their reliance on extensive manual labeling to provide procedural feedback remains a significant impediment. To address this challenge, in this paper, we propose a novel self-supervised framework \*\*AutoPRM\*\* that efficiently enhances the fine-tuning of LLMs for intricate reasoning challenges. Specifically, \*\*AutoPRM\*\* first decomposes complex... | Zhaorun Chen, Zhuokai Zhao, Zhihong Zhu, Ruiqi Zhang, Xiang Li, Bhiksha Raj, Huaxiu Yao |  |
| 169 |  |  [SEMQA: Semi-Extractive Multi-Source Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.74) |  | 0 | Recently proposed long-form question answering (QA) systems, supported by large language models (LLMs), have shown promising capabilities. Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge.In this work, we introduce a new QA task for answering multi-answer questions by summarizing multiple diverse sources in a semi-extractive fashion. Specifically,... | Tal Schuster, Ádám D. Lelkes, Haitian Sun, Jai Gupta, Jonathan Berant, William W. Cohen, Donald Metzler |  |
| 170 |  |  [Fine-Tuning Language Models with Reward Learning on Policy](https://doi.org/10.18653/v1/2024.naacl-long.75) |  | 0 | Reinforcement learning from human feedback (RLHF) has emerged as an effective approach to aligning large language models (LLMs) to human preferences.RLHF contains three steps, i.e., human preference collecting, reward learning, and policy optimization, which are usually performed serially.Despite its popularity, however, (fixed) reward models may suffer from inaccurate off-distribution, since policy optimization continuously shifts LLMs’ data... | Hao Lang, Fei Huang, Yongbin Li |  |
| 171 |  |  [A Universal Dependencies Treebank for Highland Puebla Nahuatl](https://doi.org/10.18653/v1/2024.naacl-long.76) |  | 0 | We present a Universal Dependencies (UD) treebank for Highland Puebla Nahuatl. The treebank is only the second such UD corpus for a Mexican language, and supplements an existing treebank for another Nahuatl variant. We describe the process of data collection, annotation decisions and interesting syntactic constructions, and discuss some similarities and differences between the Highland Puebla Nahuatl treebank and the existing Western Sierra Puebla Nahuatl... | Robert Pugh, Francis M. Tyers |  |
| 172 |  |  [COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances](https://doi.org/10.18653/v1/2024.naacl-long.77) |  | 0 | We present COPAL-ID, a novel, public Indonesian language common sense reasoning dataset. Unlike the previous Indonesian COPA dataset (XCOPA-ID), COPAL-ID incorporates Indonesian local and cultural nuances, and therefore, provides a more natural portrayal of day-to-day causal reasoning within the Indonesian cultural sphere. Professionally written by natives from scratch, COPAL-ID is more fluent and free from awkward phrases, unlike the translated XCOPA-ID. In... | Haryo Akbarianto Wibowo, Erland Hilman Fuadi, Made Nindyatama Nityasya, Radityo Eko Prasojo, Alham Fikri Aji |  |
| 173 |  |  [IterAlign: Iterative Constitutional Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.78) |  | 0 | With the rapid development of large language models (LLMs), aligning LLMs with human values and societal norms to ensure their reliability and safety has become crucial. Reinforcement learning with human feedback (RLHF) and Constitutional AI (CAI) have been proposed for LLM alignment. However, these methods require either heavy human annotations or explicitly pre-defined constitutions, which are labor-intensive and resource-consuming. To overcome these... | Xiusi Chen, Hongzhi Wen, Sreyashi Nag, Chen Luo, Qingyu Yin, Ruirui Li, Zheng Li, Wei Wang |  |
| 174 |  |  [OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking](https://doi.org/10.18653/v1/2024.naacl-long.79) |  | 0 | Large language models (LLMs) have revolutionized the landscape of Natural Language Processing, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Smaller Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction... | ChiaHsuan Lee, Hao Cheng, Mari Ostendorf |  |
| 175 |  |  [Multi-Operational Mathematical Derivations in Latent Space](https://doi.org/10.18653/v1/2024.naacl-long.80) |  | 0 | This paper investigates the possibility of approximating multiple mathematical operations in latent space for expression derivation. To this end, we introduce different multi-operational representation paradigms, modelling mathematical operations as explicit geometric transformations. By leveraging a symbolic engine, we construct a large-scale dataset comprising 1.7M derivation steps stemming from 61K premises and 6 operators, analysing the properties of each... | Marco Valentino, Jordan Meadows, Lan Zhang, André Freitas |  |
| 176 |  |  [Large Language Models Help Humans Verify Truthfulness - Except When They Are Convincingly Wrong](https://doi.org/10.18653/v1/2024.naacl-long.81) |  | 0 | Large Language Models (LLMs) are increasingly used for accessing information on the web. Their truthfulness and factuality are thus of great interest. To help users make the right decisions about the information they get, LLMs should not only provide information but also help users fact-check it. We conduct human experiments with 80 crowdworkers to compare language models with search engines (information retrieval systems) at facilitating fact-checking. We... | Chenglei Si, Navita Goyal, Tongshuang Wu, Chen Zhao, Shi Feng, Hal Daumé III, Jordan L. BoydGraber |  |
| 177 |  |  [XferBench: a Data-Driven Benchmark for Emergent Language](https://doi.org/10.18653/v1/2024.naacl-long.82) |  | 0 | In this paper, we introduce a benchmark for evaluating the overall quality of emergent languages using data-driven methods. Specifically, we interpret the notion of the “quality” of an emergent language as its similarity to human language within a deep learning framework. We measure this by using the emergent language as pretraining data for a downstream NLP tasks in human language—the better the downstream performance, the better the emergent language. We... | Brendon Boldt, David R. Mortensen |  |
| 178 |  |  [Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation](https://doi.org/10.18653/v1/2024.naacl-long.83) |  | 0 | Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each... | Seeun Yoon, Zhankui He, Jessica Maria Echterhoff, Julian J. McAuley |  |
| 179 |  |  [A Symbolic Framework for Evaluating Mathematical Reasoning and Generalisation with Transformers](https://doi.org/10.18653/v1/2024.naacl-long.84) |  | 0 | This paper proposes a methodology for generating and perturbing detailed derivations of equations at scale, aided by a symbolic engine, to evaluate the generalisability of Transformers to out-of-distribution mathematical reasoning problems. Instantiating the framework in the context of sequence classification tasks, we compare the capabilities of GPT-4, GPT-3.5, and a canon of fine-tuned BERT models, exploring the relationship between specific operators and... | Jordan Meadows, Marco Valentino, Damien Teney, André Freitas |  |
| 180 |  |  [Identifying Linear Relational Concepts in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.85) |  | 0 | Transformer language models (LMs) have been shown to represent concepts as directions in the latent space of hidden activations. However, for any human-interpretable concept, how can we find its direction in the latent space? We present a technique called linear relational concepts (LRC) for finding concept directions corresponding to human-interpretable concepts by first modeling the relation between subject and object as a linear relational embedding (LRE).... | David Chanin, Anthony Hunter, OanaMaria Camburu |  |
| 181 |  |  [Benchmark Transparency: Measuring the Impact of Data on Evaluation](https://doi.org/10.18653/v1/2024.naacl-long.86) |  | 0 | In this paper we present an exploratory research on quantifying the impact that data distribution has on the performance and evaluation of NLP models. We propose an automated framework that measures the data point distribution across 6 different dimensions: ambiguity, difficulty, discriminability, length, noise, and perplexity.We use disproportional stratified sampling to measure how much the data distribution affects absolute (Acc/F1) and relative (Rank)... | Venelin Kovatchev, Matthew Lease |  |
| 182 |  |  [JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models](https://doi.org/10.18653/v1/2024.naacl-long.87) |  | 0 | The permanence of online content combined with the enhanced authorship identification techniques calls for stronger computational methods to protect the identity and privacy of online authorship when needed, e.g., blind reviews for scientific papers, anonymous online reviews, or anonymous interactions in the mental health forums. In this paper, we propose an unsupervised inference-time approach to authorship obfuscation to address the unique challenges of... | Jillian Fisher, Ximing Lu, Jaehun Jung, Liwei Jiang, Zaïd Harchaoui, Yejin Choi |  |
| 183 |  |  [REST: Retrieval-Based Speculative Decoding](https://doi.org/10.18653/v1/2024.naacl-long.88) |  | 0 | We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm designed to speed up language model generation. The key insight driving the development of REST is the observation that the process of text generation often includes certain common phases and patterns. Unlike previous methods that rely on a draft language model for speculative decoding, REST harnesses the power of retrieval to generate draft tokens. This method draws from the... | Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D. Lee, Di He |  |
| 184 |  |  [Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic Representations](https://doi.org/10.18653/v1/2024.naacl-long.89) |  | 0 | We introduce sub-sentence encoder, a contrastively-learned contextual embedding model for fine-grained semantic representation of text. In contrast to the standard practice with sentence embeddings, where the meaning of an entire sequence of text is encoded into a fixed-length vector, the sub-sentence encoder learns to produce distinct contextual embeddings corresponding to different atomic propositions, i.e. atomic units of meaning expressed within a text... | Sihao Chen, Hongming Zhang, Tong Chen, Ben Zhou, Wenhao Yu, Dian Yu, Baolin Peng, Hongwei Wang, Dan Roth, Dong Yu |  |
| 185 |  |  [MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference](https://doi.org/10.18653/v1/2024.naacl-long.90) |  | 0 | The task of scientific Natural Language Inference (NLI) involves predicting the semantic relation between two sentences extracted from research articles. This task was recently proposed along with a new dataset called SciNLI derived from papers published in the computational linguistics domain. In this paper, we aim to introduce diversity in the scientific NLI task and present MSciNLI, a dataset containing 132,320 sentence pairs extracted from five new... | Mobashir Sadat, Cornelia Caragea |  |
| 186 |  |  [Causal Inference for Human-Language Model Collaboration](https://doi.org/10.18653/v1/2024.naacl-long.91) |  | 0 | In this paper, we examine the collaborative dynamics between humansand language models (LMs), where the interactions typically involveLMs proposing text segments and humans editing or responding to theseproposals. Productive engagement with LMs in such scenarios necessitates that humans discern effective text-based interaction strategies, such as editing and response styles, from historical human-LM interactions. This objective is inherently causal, driven by... | Bohan Zhang, Yixin Wang, Paramveer Dhillon |  |
| 187 |  |  [SELF-GUARD: Empower the LLM to Safeguard Itself](https://doi.org/10.18653/v1/2024.naacl-long.92) |  | 0 | With the increasing risk posed by jailbreak attacks, recent studies have investigated various methods to improve the safety of large language models (LLMs), mainly falling into two strategies: safety training and safeguards. Safety training involves fine-tuning the LLM with adversarial samples, which activate the LLM’s capabilities against jailbreak. However, it is not always effective in countering new attacks and often leads to potential performance... | Zezhong Wang, Fangkai Yang, Lu Wang, Pu Zhao, Hongru Wang, Liang Chen, Qingwei Lin, KamFai Wong |  |
| 188 |  |  [COSIGN: Contextual Facts Guided Generation for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.naacl-long.93) |  | 0 | Knowledge graph completion (KGC) aims to infer missing facts based on existing facts within a KG. Recently, research on generative models (GMs) has addressed the limitations of embedding methods in terms of generality and scalability. However, GM-based methods are sensitive to contextual facts on KG, so the contextual facts of poor quality can cause GMs to generate erroneous results. To improve the performance of GM-based methods for various KGC tasks, we... | Jinpeng Li, Hang Yu, Xiangfeng Luo, Qian Liu |  |
| 189 |  |  [Toward Informal Language Processing: Knowledge of Slang in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.94) |  | 0 | Recent advancement in large language models (LLMs) has offered a strong potential for natural language systems to process informal language. A representative form of informal language is slang, used commonly in daily conversations and online social media. To date, slang has not been comprehensively evaluated in LLMs due partly to the absence of a carefully designed and publicly accessible benchmark. Using movie subtitles, we construct a dataset that supports... | Zhewei Sun, Qian Hu, Rahul Gupta, Richard S. Zemel, Yang Xu |  |
| 190 |  |  [Ghostbuster: Detecting Text Ghostwritten by Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.95) |  | 0 | We introduce Ghostbuster, a state-of-the-art system for detecting AI-generated text.Our method works by passing documents through a series of weaker language models, running a structured search over possible combinations of their features, and then training a classifier on the selected features to predict whether documents are AI-generated.Crucially, Ghostbuster does not require access to token probabilities from the target model, making it useful for... | Vivek Verma, Eve Fleisig, Nicholas Tomlin, Dan Klein |  |
| 191 |  |  [End-to-End Beam Retrieval for Multi-Hop Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.96) |  | 0 | Multi-hop question answering (QA) involves finding multiple relevant passages and step-by-step reasoning to answer complex questions, indicating a retrieve-and-read paradigm. However, previous retrievers were customized for two-hop questions, and most of them were trained separately across different hops, resulting in a lack of supervision over the entire multi-hop retrieval process and leading to poor performance in complicated scenarios beyond two hops. In... | Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, Shen Huang |  |
| 192 |  |  [Leveraging Generative Large Language Models with Visual Instruction and Demonstration Retrieval for Multimodal Sarcasm Detection](https://doi.org/10.18653/v1/2024.naacl-long.97) |  | 0 | Multimodal sarcasm detection aims to identify sarcasm in the given image-text pairs and has wide applications in the multimodal domains. Previous works primarily design complex network structures to fuse the image-text modality features for classification. However, such complicated structures may risk overfitting on in-domain data, reducing the performance in out-of-distribution (OOD) scenarios. Additionally, existing methods typically do not fully utilize... | Binghao Tang, Boda Lin, Haolong Yan, Si Li |  |
| 193 |  |  [Multi-Scale Prompt Memory-Augmented Model for Black-Box Scenarios](https://doi.org/10.18653/v1/2024.naacl-long.98) |  | 0 | Black-box few-shot text classification handles text classification in limited data without accessing the parameters and gradients of language models (LMs). Existing black-box optimization methods have demonstrated strong few-shot learning capabilities. However, they still require numerous LMs’ calls to search optimal prompts, thus resulting in overfitting performance and increasing computational cost. To address this issue, we present MuSKPrompt (Multi-scale... | Xiaojun Kuang, C. L. Philip Chen, Shuzhen Li, Tong Zhang |  |
| 194 |  |  [Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction](https://doi.org/10.18653/v1/2024.naacl-long.99) |  | 0 | In the era of large language models (LLMs), in-context learning (ICL) stands out as an effective prompting strategy that explores LLMs’ potency across various tasks. However, applying LLMs to grammatical error correction (GEC) is still a challenging task. In this paper, we propose a novel ungrammatical-syntax-based in-context example selection strategy for GEC. Specifically, we measure similarity of sentences based on their syntactic structures with diverse... | Chenming Tang, Fanyi Qu, Yunfang Wu |  |
| 195 |  |  [BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer](https://doi.org/10.18653/v1/2024.naacl-long.100) |  | 0 | Despite remarkable advancements in few-shot generalization in natural language processing, most models are developed and evaluated primarily in English. To establish a rigorous and equitable evaluation framework for few-shot cross-lingual transfer, we introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few-shot examples and instructions. Using BUFFET, we... | Akari Asai, Sneha Kudugunta, Xinyan Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, Hannaneh Hajishirzi |  |
| 196 |  |  [TISE: A Tripartite In-context Selection Method for Event Argument Extraction](https://doi.org/10.18653/v1/2024.naacl-long.101) |  | 0 | In-context learning enhances the reasoning capabilities of LLMs by providing several examples. A direct yet effective approach to obtain in-context example is to select the top-k examples based on their semantic similarity to the test input. However, when applied to event argument extraction (EAE), this approach exhibits two shortcomings: 1) It may select almost identical examples, thus failing to provide additional event information, and 2) It overlooks... | Yanhe Fu, Yanan Cao, Qingyue Wang, Yi Liu |  |
| 197 |  |  [Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks](https://doi.org/10.18653/v1/2024.naacl-long.102) |  | 0 | The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills. Are these skills general and transferable, or specialized to specific tasks seen during pretraining? To disentangle these effects, we propose an evaluation framework based on “counterfactual” task variants that deviate from the default assumptions underlying standard tasks. Across a suite of 11 tasks, we observe... | Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyürek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, Yoon Kim |  |
| 198 |  |  [TRUE-UIE: Two Universal Relations Unify Information Extraction Tasks](https://doi.org/10.18653/v1/2024.naacl-long.103) |  | 0 | Information extraction (IE) encounters challenges due to the variety of schemas and objectives that differ across tasks. Recent advancements hint at the potential for universal approaches to model such tasks, referred to as Universal Information Extraction (UIE). While handling diverse tasks in one model, their generalization is limited since they are actually learning task-specific knowledge.In this study, we introduce an innovative paradigm known as... | Yucheng Wang, Bowen Yu, Yilin Liu, Shudong Lu |  |
| 199 |  |  [zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.104) |  | 0 | Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become a heated topic. Various methods have been proposed to forecast links on TKGs. Most of them are embedding-based, where hidden representations are learned to represent knowledge graph (KG) entities and relations based on the observed graph contexts. Although these methods show strong performance on traditional TKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling... | Zifeng Ding, Heling Cai, Jingpei Wu, Yunpu Ma, Ruotong Liao, Bo Xiong, Volker Tresp |  |
| 200 |  |  [Embodied Executable Policy Learning with Language-based Scene Summarization](https://doi.org/10.18653/v1/2024.naacl-long.105) |  | 0 | Large Language models (LLMs) have shown remarkable success in assisting robot learning tasks, i.e., complex household planning.However, the performance of pretrained LLMs heavily relies on domain-specific templated text data, which may be infeasible in real-world robot learning tasks with image-based observations. Moreover, existing LLMs with text inputs lack the capability to evolve with non-expert interactions with environments.In this work, we introduce a... | Jielin Qiu, Mengdi Xu, William Han, Seungwhan Moon, Ding Zhao |  |
| 201 |  |  [Metacognitive Prompting Improves Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.106) |  | 0 | In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. Recent advancements in prompting have enhanced reasoning in logic-intensive tasks for LLMs, yet the nuanced understanding abilities of these models, crucial for processing and interpreting complex information, remain underexplored. In this study, we introduce Metacognitive Prompting (MP), a strategy inspired by... | Yuqing Wang, Yun Zhao |  |
| 202 |  |  [MART: Improving LLM Safety with Multi-round Automatic Red-Teaming](https://doi.org/10.18653/v1/2024.naacl-long.107) |  | 0 | Red-teaming is a common practice for mitigating unsafe behaviors in Large Language Models (LLMs), which involves thoroughly assessing LLMs to identify potential flaws and addressing them with responsible and accurate responses.While effective, manual red-teaming is costly, and existing automatic red-teaming typically discovers safety risks without addressing them.In this paper, we propose a Multi-round Automatic Red-Teaming (MART) method, which incorporates... | Suyu Ge, Chunting Zhou, Rui Hou, Madian Khabsa, YiChia Wang, Qifan Wang, Jiawei Han, Yuning Mao |  |
| 203 |  |  [DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset](https://doi.org/10.18653/v1/2024.naacl-long.108) |  | 0 | As sharing images in an instant message is a crucial factor, there has been active research on learning an image-text multi-modal dialogue models.However, training a well-generalized multi-modal dialogue model remains challenging due to the low quality and limited diversity of images per dialogue in existing multi-modal dialogue datasets.In this paper, we propose an automated pipeline to construct a multi-modal dialogue dataset, ensuring both dialogue quality... | YoungJun Lee, Byungsoo Ko, HanGyu Kim, Jonghwan Hyeon, HoJin Choi |  |
| 204 |  |  [Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.109) |  | 0 | The complementary potential of Large Language Models (LLM) assumes off-the-shelf LLMs have heterogeneous expertise in a wide range of domains and tasks so that an ensemble of LLMs can achieve consistently better performance. Existing ensemble methods for LLMs mainly focus on reward model ranking of outputs, leading to significant computation overhead. To combat this issue, we revisit the complementary potential of LLMs and further elaborate on it by mining... | Keming Lu, Hongyi Yuan, Runji Lin, Junyang Lin, Zheng Yuan, Chang Zhou, Jingren Zhou |  |
| 205 |  |  [Automatic Generation of Model and Data Cards: A Step Towards Responsible AI](https://doi.org/10.18653/v1/2024.naacl-long.110) |  | 0 | In an era of model and data proliferation in machine learning/AI especially marked by the rapid advancement of open-sourced technologies, there arises a critical need for standardized consistent documentation. Our work addresses the information incompleteness in current human-written model and data cards. We propose an automated generation approach using Large Language Models (LLMs). Our key contributions include the establishment of CardBench, a... | Jiarui Liu, Wenkai Li, Zhijing Jin, Mona T. Diab |  |
| 206 |  |  [FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual Transfer with Scheduled Unfreezing](https://doi.org/10.18653/v1/2024.naacl-long.111) |  | 0 | Standard fine-tuning of language models typically performs well on in-distribution data, but suffers with generalization to distribution shifts. In this work, we aim to improve the generalization of adapter-based cross-lingual task transfer where such cross-language distribution shifts are imminent. We investigate scheduled unfreezing algorithms –originally proposed to mitigate catastrophic forgetting in transfer learning – for fine-tuning task adapters. Our... | Chen Liu, Jonas Pfeiffer, Ivan Vulic, Iryna Gurevych |  |
| 207 |  |  [Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings](https://doi.org/10.18653/v1/2024.naacl-long.112) |  | 0 | Large language models (LLMs) are highly adept at question answering and reasoning tasks, but when reasoning in a situational context, human expectations vary depending on the relevant cultural common ground. As languages are associated with diverse cultures, LLMs should also be culturally-diverse reasoners. In this paper, we study the ability of a wide range of state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings in a conversational... | Chen Liu, Fajri Koto, Timothy Baldwin, Iryna Gurevych |  |
| 208 |  |  [The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth](https://doi.org/10.18653/v1/2024.naacl-long.113) |  | 0 | Queer youth face increased mental health risks, such as depression, anxiety, and suicidal ideation. Hindered by negative stigma, they often avoid seeking help and rely on online resources, which may provide incompatible information. Although access to a supportive environment and reliable information is invaluable, many queer youth worldwide have no access to such support. However, this could soon change due to the rapid adoption of Large Language Models... | Shir Lissak, Nitay Calderon, Geva Shenkman, Yaakov Ophir, Eyal Fruchter, Anat Brunstein Klomek, Roi Reichart |  |
| 209 |  |  [IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model](https://doi.org/10.18653/v1/2024.naacl-long.114) |  | 0 | Relational triple extraction is a fundamental task in the field of information extraction, and a promising framework based on table filling has recently gained attention as a potential baseline for entity relation extraction. However, inherent shortcomings such as redundant information and incomplete triple recognition remain problematic. To address these challenges, we propose an Implicit Perspective for relational triple Extraction based on Diffusion model... | Jianli Zhao, Changhao Xu, Bin Jiang |  |
| 210 |  |  [QualEval: Qualitative Evaluation for Model Improvement](https://doi.org/10.18653/v1/2024.naacl-long.115) |  | 0 | Quantitative evaluation metrics have been pivotal in gauging the advancements of AI systems like large language models (LLMs).However, due to the intricate nature of real-world tasks, a single scalar to quantify and compare performance trivializes the fine-grained nuances of model behavior. Additionally, metrics do not yield actionable diagnostics for model improvement, thus requiring extensive manual efforts of scientists, involving sifting through vast... | Vishvak Murahari, Ameet Deshpande, Peter Clark, Tanmay Rajpurohit, Ashish Sabharwal, Karthik Narasimhan, Ashwin Kalyan |  |
| 211 |  |  [Quantum-inspired Language Model with Lindblad Master Equation and Interference Measurement for Sentiment Analysis](https://doi.org/10.18653/v1/2024.naacl-long.116) |  | 0 | Quantum-inspired models have demonstrated superior performance in many downstream language tasks, such as question answering and sentiment analysis. However, recent models primarily focus on embedding and measurement operations, overlooking the significance of the quantum evolution process. In this work, we present a novel quantum-inspired neural network, LI-QiLM, which integrates the Lindblad Master Equation (LME) to model the evolution process and the... | Kehuan Yan, Peichao Lai, Yilei Wang |  |
| 212 |  |  [VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization](https://doi.org/10.18653/v1/2024.naacl-long.117) |  | 0 | This paper presents VisLingInstruct, a novel approach to advancing Multi-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show impressive zero-shot abilities in multi-modal tasks, but their performance depends heavily on the quality of instructions. VisLingInstruct tackles this by autonomously evaluating and optimizing instructional texts through In-Context Learning, improving the synergy between visual perception and linguistic expression... | Dongsheng Zhu, Daniel Tang, Weidong Han, Jinghui Lu, Yukun Zhao, Guoliang Xing, Junfeng Wang, Dawei Yin |  |
| 213 |  |  [A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily](https://doi.org/10.18653/v1/2024.naacl-long.118) |  | 0 | Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to provide useful and safe responses. However, adversarial prompts known as ‘jailbreaks’ can circumvent safeguards, leading LLMs to generate potentially harmful content. Exploring jailbreak prompts can help to better reveal the weaknesses of LLMs and further steer us to secure them. Unfortunately, existing jailbreak methods either suffer from intricate manual design or require optimization... | Peng Ding, Jun Kuang, Dan Ma, Xuezhi Cao, Yunsen Xian, Jiajun Chen, Shujian Huang |  |
| 214 |  |  [P³Sum: Preserving Author's Perspective in News Summarization with Diffusion Language Models](https://doi.org/10.18653/v1/2024.naacl-long.119) |  | 0 | In this work, we take a first step towards designing summarization systems that are faithful to the author’s intent, not only the semantic content of the article. Focusing on a case study of preserving political perspectives in news summarization, we find that existing approaches alter the political opinions and stances of news articles in more than 50% of summaries, misrepresenting the intent and perspectives of the news authors. We thus propose P3Sum, a... | Yuhan Liu, Shangbin Feng, Xiaochuang Han, Vidhisha Balachandran, Chan Young Park, Sachin Kumar, Yulia Tsvetkov |  |
| 215 |  |  [Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes](https://doi.org/10.18653/v1/2024.naacl-long.120) |  | 0 | Scaling high-quality tutoring remains a major challenge in education. Due to growing demand, many platforms employ novice tutors who, unlike experienced educators, struggle to address student mistakes and thus fail to seize prime learning opportunities. Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes. We contribute Bridge, a method that uses cognitive task analysis to... | Rose E. Wang, Qingyang Zhang, Carly Robinson, Susanna Loeb, Dorottya Demszky |  |
| 216 |  |  [RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization](https://doi.org/10.18653/v1/2024.naacl-long.121) |  | 0 | For long document summarization, discourse structure is important to discern the key content of the text and the differences in importance level between sentences. Unfortunately, the integration of rhetorical structure theory (RST) into parameter-efficient fine-tuning strategies for long document summarization remains unexplored. Therefore, this paper introduces RST-LoRA and proposes four RST-aware variants to explicitly incorporate RST into the LoRA model.... | Dongqi Liu, Vera Demberg |  |
| 217 |  |  [Strings from the Library of Babel: Random Sampling as a Strong Baseline for Prompt Optimisation](https://doi.org/10.18653/v1/2024.naacl-long.122) |  | 0 | Recent prompt optimisation approaches use the generative nature of language models to produce prompts – even rivaling the performance of human-curated prompts. In this paper, we demonstrate that randomly sampling tokens from the model vocabulary as “separators” can be as effective as language models for prompt-style text classification. Our experiments show that random separators are competitive baselines, having less than a 1% difference compared to previous... | Yao Lu, Jiayi Wang, Raphael Tang, Sebastian Riedel, Pontus Stenetorp |  |
| 218 |  |  [ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.123) |  | 0 | Current logical reasoning evaluations of Large Language Models (LLMs) primarily focus on single-turn and static environments, such as arithmetic problems. The crucial problem of multi-turn, strategic reasoning is under-explored. In this work, we analyze the multi-turn strategic reasoning of LLMs through text-driven complete- and incomplete-information gaming, e.g., board games (Tic-Tac-Toe, Connect-4) and poker games (Texas Hold’em Poker). Specifically, we... | Jinhao Duan, Shiqi Wang, James Diffenderfer, Lichao Sun, Tianlong Chen, Bhavya Kailkhura, Kaidi Xu |  |
| 219 |  |  [Fact Checking Beyond Training Set](https://doi.org/10.18653/v1/2024.naacl-long.124) |  | 0 | Evaluating the veracity of everyday claims is time consuming and in some cases requires domain expertise. We empirically demonstrate that the commonly used fact checking pipeline, known as the retriever-reader, suffers from performance deterioration when it is trained on the labeled data from one domain and used in another domain. Afterwards, we delve into each component of the pipeline and propose novel algorithms to address this problem. We propose an... | Payam Karisani, Heng Ji |  |
| 220 |  |  [Program-Aided Reasoners (Better) Know What They Know](https://doi.org/10.18653/v1/2024.naacl-long.125) |  | 0 | Prior work shows that program-aided reasoning, in which large language models (LLMs) are combined with programs written in programming languages such as Python, can significantly improve accuracy on various reasoning tasks. However, while accuracy is essential, it is also important for such reasoners to “know what they know”, which can be quantified through the calibration of the model. In this paper, we compare the calibration of Program Aided Language... | Anubha Kabra, Sanketh Rangreji, Yash Mathur, Aman Madaan, Emmy Liu, Graham Neubig |  |
| 221 |  |  [The Perspectivist Paradigm Shift: Assumptions and Challenges of Capturing Human Labels](https://doi.org/10.18653/v1/2024.naacl-long.126) |  | 0 | Longstanding data labeling practices in machine learning involve collecting and aggregating labels from multiple annotators. But what should we do when annotators disagree? Though annotator disagreement has long been seen as a problem to minimize, new perspectivist approaches challenge this assumption by treating disagreement as a valuable source of information. In this position paper, we examine practices and assumptions surrounding the causes of... | Eve Fleisig, Su Lin Blodgett, Dan Klein, Zeerak Talat |  |
| 222 |  |  [Principles from Clinical Research for NLP Model Generalization](https://doi.org/10.18653/v1/2024.naacl-long.127) |  | 0 | The NLP community typically relies on performance of a model on a held-out test set to assess generalization. Performance drops observed in datasets outside of official test sets are generally attributed to “out-of-distribution” effects. Here, we explore the foundations of generalizability and study the factors that affect it, articulating lessons from clinical studies. In clinical research, generalizability is an act of reasoning that depends on (a)... | Aparna Elangovan, Jiayuan He, Yuan Li, Karin Verspoor |  |
| 223 |  |  [First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.128) |  | 0 | Many NLP researchers are experiencing an existential crisis triggered by the astonishing success of ChatGPT and other systems based on large language models (LLMs). After such a disruptive change to our understanding of the field, what is left to do? Taking a historical lens, we look for guidance from the first era of LLMs, which began in 2005 with large n-gram models for machine translation (MT). We identify durable lessons from the first era, and more... | Naomi Saphra, Eve Fleisig, Kyunghyun Cho, Adam Lopez |  |
| 224 |  |  [Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.129) |  | 0 | Large language models (LLMs) exhibit positional bias in how they use context, which especially affects listwise ranking. To address this, we propose permutation self-consistency, a form of self-consistency over the ranking list outputs of black-box LLMs. Our key idea is to marginalize out different list orders in the prompt to produce an order-independent ranking with less positional bias. First, given some input prompt, we repeatedly shuffle the list in the... | Raphael Tang, Xinyu Zhang, Xueguang Ma, Jimmy Lin, Ferhan Ture |  |
| 225 |  |  [From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.130) |  | 0 | Large Language Models (LLMs) have achieved remarkable success, where instruction tuning is the critical step in aligning LLMs with user intentions. In this work, we investigate how the instruction tuning adjusts pre-trained models with a focus on intrinsic changes. Specifically, we first develop several local and global explanation methods, including a gradient-based method for input-output attribution, and techniques for interpreting patterns and concepts in... | Xuansheng Wu, Wenlin Yao, Jianshu Chen, Xiaoman Pan, Xiaoyang Wang, Ninghao Liu, Dong Yu |  |
| 226 |  |  [POLYIE: A Dataset of Information Extraction from Polymer Material Scientific Literature](https://doi.org/10.18653/v1/2024.naacl-long.131) |  | 0 | Scientific information extraction (SciIE), which aims to automatically extract information from scientific literature, is becoming more important than ever. However, there are no existing SciIE datasets for polymer materials, which is an important class of materials used ubiquitously in our daily lives. To bridge this gap, we introduce POLYIE, a new SciIE dataset for polymer materials. POLYIE is curated from 146 full-length polymer scholarly articles, which... | Jerry Junyang Cheung, Yuchen Zhuang, Yinghao Li, Pranav Shetty, Wantian Zhao, Sanjeev Grampurohit, Rampi Ramprasad, Chao Zhang |  |
| 227 |  |  [LLM-based Medical Assistant Personalization with Short- and Long-Term Memory Coordination](https://doi.org/10.18653/v1/2024.naacl-long.132) |  | 0 | Large Language Models (LLMs), such as GPT3.5, have exhibited remarkable proficiency in comprehending and generating natural language. On the other hand, medical assistants hold the potential to offer substantial benefits for individuals. However, the exploration of LLM-based personalized medical assistant remains relatively scarce. Typically, patients converse differently based on their background and preferences which necessitates the task of enhancing... | Kai Zhang, Yangyang Kang, Fubang Zhao, Xiaozhong Liu |  |
| 228 |  |  [SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual Summarization](https://doi.org/10.18653/v1/2024.naacl-long.133) |  | 0 | Cross-lingual summarization (XLS) generates summaries in a language different from that of the input documents (e.g., English to Spanish), allowing speakers of the target language to gain a concise view of their content. In the present day, the predominant approach to this task is to take a performing, pretrained multilingual language model (LM) and fine-tune it for XLS on the language pairs of interest. However, the scarcity of fine-tuning samples makes this... | Jacob Parnell, Inigo Jauregi Unanue, Massimo Piccardi |  |
| 229 |  |  [KTRL+F: Knowledge-Augmented In-Document Search](https://doi.org/10.18653/v1/2024.naacl-long.134) |  | 0 | We introduce a new problem KTRL+F, a knowledge-augmented in-document search that necessitates real-time identification of all semantic targets within a document with the awareness of external sources through a single natural query. KTRL+F addresses following unique challenges for in-document search: 1) utilizing knowledge outside the document for extended use of additional information about targets, and 2) balancing between real-time applicability with the... | Hanseok Oh, Haebin Shin, Miyoung Ko, Hyunji Lee, Minjoon Seo |  |
| 230 |  |  [How Well Do Large Language Models Truly Ground?](https://doi.org/10.18653/v1/2024.naacl-long.135) |  | 0 | To reduce issues like hallucinations and lack of control in Large Language Models (LLMs), a common method is to generate responses by grounding on external contexts given as input, known as knowledge-augmented models. However, previous research often narrowly defines “grounding” as just having the correct answer, which does not ensure the reliability of the entire response. To overcome this, we propose a stricter definition of grounding: a model is truly... | Hyunji Lee, Se June Joo, Chaeeun Kim, Joel Jang, Doyoung Kim, KyoungWoon On, Minjoon Seo |  |
| 231 |  |  [ALBA: Adaptive Language-Based Assessments for Mental Health](https://doi.org/10.18653/v1/2024.naacl-long.136) |  | 0 | Mental health issues differ widely among individuals, with varied signs and symptoms. Recently, language-based assessments haveshown promise in capturing this diversity, but they require a substantial sample of words per person for accuracy. This work introducesthe task of Adaptive Language-Based Assessment (ALBA), which involves adaptively ordering questions while also scoring an individual’s latent psychological trait using limited language responses to... | Vasudha Varadarajan, Sverker Sikström, Oscar N. E. Kjell, H. Andrew Schwartz |  |
| 232 |  |  [FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.137) |  | 0 | Table Question Answering (TQA) aims at composing an answer to a question based on tabular data. While prior research has shown that TQA models lack robustness, understanding the underlying cause and nature of this issue remains predominantly unclear, posing a significant obstacle to the development of robust TQA systems. In this paper, we formalize three major desiderata for a fine-grained evaluation of robustness of TQA systems. They should (i) answer... | Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich |  |
| 233 |  |  [MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion](https://doi.org/10.18653/v1/2024.naacl-long.138) |  | 0 | Query expansion, pivotal in search engines, enhances the representation of user information needs with additional terms. While existing methods expand queries using retrieved or generated contextual documents, each approach has notable limitations. Retrieval-based methods often fail to accurately capture search intent, particularly with brief or ambiguous queries. Generation-based methods, utilizing large language models (LLMs), generally lack corpus-specific... | Pengyue Jia, Yiding Liu, Xiangyu Zhao, Xiaopeng Li, Changying Hao, Shuaiqiang Wang, Dawei Yin |  |
| 234 |  |  [Efficient Benchmarking (of Language Models)](https://doi.org/10.18653/v1/2024.naacl-long.139) |  | 0 | The increasing versatility of language models (LMs) has given rise to a new class of benchmarks that comprehensively assess a broad range of capabilities. Such benchmarks are associated with massive computational costs, extending to thousands of GPU hours per model. However, the efficiency aspect of these evaluation efforts had raised little discussion in the literature.In this work, we present the problem of Efficient Benchmarking, namely, intelligently... | Yotam Perlitz, Elron Bandel, Ariel Gera, Ofir Arviv, Liat EinDor, Eyal Shnarch, Noam Slonim, Michal ShmueliScheuer, Leshem Choshen |  |
| 235 |  |  [ReFACT: Updating Text-to-Image Models by Editing the Text Encoder](https://doi.org/10.18653/v1/2024.naacl-long.140) |  | 0 | Our world is marked by unprecedented technological, global, and socio-political transformations, posing a significant challenge to textto-image generative models. These models encode factual associations within their parameters that can quickly become outdated, diminishing their utility for end-users. To that end, we introduce ReFACT, a novel approach for editing factual associations in text-to-image models without relaying on explicit input from end-users or... | Dana Arad, Hadas Orgad, Yonatan Belinkov |  |
| 236 |  |  [A Likelihood Ratio Test of Genetic Relationship among Languages](https://doi.org/10.18653/v1/2024.naacl-long.141) |  | 0 | Lexical resemblances among a group of languages indicate that the languages could be genetically related, i.e., they could have descended from a common ancestral language. However, such resemblances can arise by chance and, hence, need not always imply an underlying genetic relationship. Many tests of significance based on permutation of wordlists and word similarity measures appeared in the past to determine the statistical significance of such... | V. S. D. S. Mahesh Akavarapu, Arnab Bhattacharya |  |
| 237 |  |  [PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning](https://doi.org/10.18653/v1/2024.naacl-long.142) |  | 0 | While large language models (LLMs) excel in various natural language processing tasks, their huge size and the inaccessibility of parameters present challenges for practical deployment. Previous studies try to distill task-specific ability from LLMs to smaller models, using data synthesis and chain-of-thought (CoT) fine-tuning. However, synthetic CoT data often contains faulty reasoning, which deteriorates the quality of distillation, especially in reasoning... | Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xinwei Long, Zhouhan Lin, Bowen Zhou |  |
| 238 |  |  [MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks](https://doi.org/10.18653/v1/2024.naacl-long.143) |  | 0 | There has been a surge in LLM evaluation research to understand LLM capabilities and limitations. However, much of this research has been confined to English, leaving LLM building and evaluation for non-English languages relatively unexplored. Several new LLMs have been introduced recently, necessitating their evaluation on non-English languages. This study aims to perform a thorough evaluation of the non-English capabilities of SoTA LLMs (GPT-3.5-Turbo,... | Sanchit Ahuja, Divyanshu Aggarwal, Varun Gumma, Ishaan Watts, Ashutosh Sathe, Millicent Ochieng, Rishav Hada, Prachi Jain, Mohamed Ahmed, Kalika Bali, Sunayana Sitaram |  |
| 239 |  |  [Unlocking Emergent Modularity in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.144) |  | 0 | Modular Neural Networks (MNNs) demonstrate various advantages over monolithic models.Existing MNNs are generally explicit: their modular architectures are pre-defined, with individual modules expected to implement distinct functions.Recent works reveal that there exists implicit modularity in standard pre-trained transformers, namely Emergent Modularity.They indicate that such modular structures spontaneously exhibit during the early pre-training... | Zihan Qiu, Zeyu Huang, Jie Fu |  |
| 240 |  |  [A School Student Essay Corpus for Analyzing Interactions of Argumentative Structure and Quality](https://doi.org/10.18653/v1/2024.naacl-long.145) |  | 0 | Learning argumentative writing is challenging. Besides writing fundamentals such as syntax and grammar, learners must select and arrange argument components meaningfully to create high-quality essays. To support argumentative writing computationally, one step is to mine the argumentative structure. When combined with automatic essay scoring, interactions of the argumentative structure and quality scores can be exploited for comprehensive writing support.... | Maja Stahl, Nadine Michel, Sebastian Kilsbach, Julian Schmidtke, Sara Rezat, Henning Wachsmuth |  |
| 241 |  |  [Adjusting Interpretable Dimensions in Embedding Space with Human Judgments](https://doi.org/10.18653/v1/2024.naacl-long.146) |  | 0 | Embedding spaces contain interpretable dimensions indicating gender, formality in style, or even object properties. This has been observed multiple times. Such interpretable dimensions are becoming valuable tools in different areas of study, from social science to neuroscience. The standard way to compute these dimensions uses contrasting seed words and computes difference vectors over them. This is simple but does not always work well. We combine seed-based... | Katrin Erk, Marianna Apidianaki |  |
| 242 |  |  [PatentEval: Understanding Errors in Patent Generation](https://doi.org/10.18653/v1/2024.naacl-long.147) |  | 0 | In this work, we introduce a comprehensive error typology specifically designed for evaluating two distinct tasks in machine-generated patent texts: claims-to-abstract generation, and the generation of the next claim given previous ones. We have also developed a benchmark, PatentEval, for systematically assessing language models in this context. Our study includes a comparative analysis, annotated by humans, of various models. These range from those... | You Zuo, Kim Gerdes, Éric de la Clergerie, Benoît Sagot |  |
| 243 |  |  [Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing](https://doi.org/10.18653/v1/2024.naacl-long.148) |  | 0 | Large language models (LLMs) have demonstrated considerable success in various natural language processing tasks, but open-source LLMs have yet to attain state-of-the-art performance in Neural Machine Translation (NMT). Nevertheless, their significant performance in tasks demanding a broad understanding and contextual processing shows their potential for translation. To exploit these abilities, we investigate using LLMs for MT and explore recent... | Sai Koneru, Miriam Exel, Matthias Huck, Jan Niehues |  |
| 244 |  |  [Metaphor Detection with Context Enhancement and Curriculum Learning](https://doi.org/10.18653/v1/2024.naacl-long.149) |  | 0 | Metaphor detection is a challenging task for natural language processing (NLP) systems. Previous works failed to sufficiently utilize the internal and external semantic relationships between target words and their context. Furthermore, they have faced challenges in tackling the problem of data sparseness due to the very limited available training data. To address these two challenges, we propose a novel model called MiceCL. By leveraging the difference... | Kaidi Jia, Rongsheng Li |  |
| 245 |  |  [What Causes the Failure of Explicit to Implicit Discourse Relation Recognition?](https://doi.org/10.18653/v1/2024.naacl-long.150) |  | 0 | We consider an unanswered question in the discourse processing community: why do relation classifiers trained on explicit examples (with connectives removed) perform poorly in real implicit scenarios? Prior work claimed this is due to linguistic dissimilarity between explicit and implicit examples but provided no empirical evidence. In this study, we show that one cause for such failure is a label shift after connectives are eliminated. Specifically, we find... | Wei Liu, Stephen Wan, Michael Strube |  |
| 246 |  |  [UniverSLU: Universal Spoken Language Understanding for Diverse Tasks with Natural Language Instructions](https://doi.org/10.18653/v1/2024.naacl-long.151) |  | 0 | Recent studies leverage large language models with multi-tasking capabilities, using natural language prompts to guide the model’s behavior and surpassing performance of task-specific models. Motivated by this, we ask: can we build a single model that jointly performs various spoken language understanding (SLU) tasks? We start by adapting a pre-trained automatic speech recognition model to additional tasks using single-token task specifiers. We enhance this... | Siddhant Arora, Hayato Futami, Jeeweon Jung, Yifan Peng, Roshan S. Sharma, Yosuke Kashiwagi, Emiru Tsunoo, Karen Livescu, Shinji Watanabe |  |
| 247 |  |  [How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities](https://doi.org/10.18653/v1/2024.naacl-long.152) |  | 0 | The rapid progress in open-source Large Language Models (LLMs) is significantly driving AI development forward. However, there is still a limited understanding of their trustworthiness. Deploying these models at scale without sufficient trustworthiness can pose significant risks, highlighting the need to uncover these issues promptly. In this work, we conduct an adversarial assessment of open-source LLMs on trustworthiness, scrutinizing them across eight... | Lingbo Mo, Boshi Wang, Muhao Chen, Huan Sun |  |
| 248 |  |  [Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.153) |  | 0 | This paper studies the relationship between the surface form of a mathematical problem and its solvability by large language models. We find that subtle alterations in the surface form can significantly impact the answer distribution and the solve rate, exposing the language model’s lack of robustness and sensitivity to the surface form in reasoning through complex problems. To improve mathematical reasoning performance, we propose... | Yue Zhou, Yada Zhu, Diego Antognini, Yoon Kim, Yang Zhang |  |
| 249 |  |  [TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale](https://doi.org/10.18653/v1/2024.naacl-long.154) |  | 0 | The advent of large language models (LLMs) has significantly advanced natural language processing tasks like text summarization. However, their large size and computational demands, coupled with privacy concerns in data transmission, limit their use in resource-constrained and privacy-centric settings. To overcome this, we introduce TriSum, a framework for distilling LLMs’ text summarization abilities into a compact, local model. Initially, LLMs extract a set... | Pengcheng Jiang, Cao Xiao, Zifeng Wang, Parminder Bhatia, Jimeng Sun, Jiawei Han |  |
| 250 |  |  [GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.155) |  | 0 | The field of relation extraction (RE) is experiencing a notable shift towards generative relation extraction (GRE), leveraging the capabilities of large language models (LLMs). However, we discovered that traditional relation extraction (RE) metrics like precision and recall fall short in evaluating GRE methods. This shortfall arises because these metrics rely on exact matching with human-annotated reference relations, while GRE methods often produce diverse... | Pengcheng Jiang, Jiacheng Lin, Zifeng Wang, Jimeng Sun, Jiawei Han |  |
| 251 |  |  [Curated Datasets and Neural Models for Machine Translation of Informal Registers between Mayan and Spanish Vernaculars](https://doi.org/10.18653/v1/2024.naacl-long.156) |  | 0 | The Mayan languages comprise a language family with an ancient history, millions of speakers, and immense cultural value, that, nevertheless, remains severely underrepresented in terms of resources and global exposure. In this paper we develop, curate, and publicly release a set of corpora in several Mayan languages spoken in Guatemala and Southern Mexico, which we call MayanV. The datasets are parallel with Spanish, the dominant language of the region, and... | Andrés Lou, Juan Antonio PérezOrtiz, Felipe SánchezMartínez, Víctor M. SánchezCartagena |  |
| 252 |  |  [The Effect of Data Partitioning Strategy on Model Generalizability: A Case Study of Morphological Segmentation](https://doi.org/10.18653/v1/2024.naacl-long.157) |  | 0 | Recent work to enhance data partitioning strategies for more realistic model evaluation face challenges in providing a clear optimal choice. This study addresses these challenges, focusing on morphological segmentation and synthesizing limitations related to language diversity, adoption of multiple datasets and splits, and detailed model comparisons. Our study leverages data from 19 languages, including ten indigenous or endangered languages across 10... | Zoey Liu, Bonnie J. Dorr |  |
| 253 |  |  [Measuring Entrainment in Spontaneous Code-switched Speech](https://doi.org/10.18653/v1/2024.naacl-long.158) |  | 0 | It is well-known that speakers who entrain to one another have more successful conversations than those who do not. Previous research has shown that interlocutors entrain on linguistic features in both written and spoken monolingual domains. More recent work on code-switched communication has also shown preliminary evidence of entrainment on certain aspects of code-switching (CSW). However, such studies of entrainment in code-switched domains have been... | Debasmita Bhattacharya, Siying Ding, Alayna Nguyen, Julia Hirschberg |  |
| 254 |  |  [A Survey of Meaning Representations - From Theory to Practical Utility](https://doi.org/10.18653/v1/2024.naacl-long.159) |  | 0 | Symbolic meaning representations of natural language text have been studied since at least the 1960s. With the availability of large annotated corpora, and more powerful machine learning tools, the field has recently seen several new developments. In this survey, we study today’s most prominent Meaning Representation Frameworks. We shed light on their theoretical properties, as well as on their practical research environment, i.e., on datasets, parsers,... | Zacchary Sadeddine, Juri Opitz, Fabian M. Suchanek |  |
| 255 |  |  [Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation](https://doi.org/10.18653/v1/2024.naacl-long.160) |  | 0 | Large-scale multilingual Pretrained Language Models (mPLMs) yield impressive performance on cross-language tasks, yet significant performance disparities exist across different languages within the same mPLM. Previous studies endeavored to narrow these disparities by supervise fine-tuning the mPLMs with multilingual data.However, obtaining labeled multilingual data is time-consuming, and fine-tuning mPLM with limited labeled multilingual data merely... | Haozhe Zhao, Zefan Cai, Shuzheng Si, Liang Chen, Yufeng He, Kaikai An, Baobao Chang |  |
| 256 |  |  [Evaluating In-Context Learning of Libraries for Code Generation](https://doi.org/10.18653/v1/2024.naacl-long.161) |  | 0 | Contemporary Large Language Models (LLMs) exhibit a high degree of code generation and comprehension capability. A particularly promising area is their ability to interpret code modules from unfamiliar libraries for solving user-instructed tasks. Recent work has shown that large proprietary LLMs can learn novel library usage in-context from demonstrations. These results raise several open questions: whether demonstrations of library usage is required, whether... | Arkil Patel, Siva Reddy, Dzmitry Bahdanau, Pradeep Dasigi |  |
| 257 |  |  [Visually-Aware Context Modeling for News Image Captioning](https://doi.org/10.18653/v1/2024.naacl-long.162) |  | 0 | News Image Captioning aims to create captions from news articles and images, emphasizing the connection between textual context and visual elements. Recognizing the significance of human faces in news images and the face-name co-occurrence pattern in existing datasets, we propose a face-naming module for learning better name embeddings. Apart from names, which can be directly linked to an image area (faces), news image captions mostly contain context... | Tingyu Qu, Tinne Tuytelaars, MarieFrancine Moens |  |
| 258 |  |  [Regularized Conventions: Equilibrium Computation as a Model of Pragmatic Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.163) |  | 0 | We present a game-theoretic model of pragmatics that we call ReCo (for Regularized Conventions). This model formulates pragmatic communication as a game in which players are rewarded for communicating successfully and penalized for deviating from a shared, “default” semantics. As a result, players assign utterances context-dependent meanings that jointly optimize communicative success and naturalness with respect to speakers’ and listeners’ background... | Athul Paul Jacob, Gabriele Farina, Jacob Andreas |  |
| 259 |  |  [TopicGPT: A Prompt-based Topic Modeling Framework](https://doi.org/10.18653/v1/2024.naacl-long.164) |  | 0 | Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require “reading the tea leaves” to interpret; additionally, they offer users minimal control over the formatting and specificity of resulting topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics in a text... | Chau Pham, Alexander Miserlis Hoyle, Simeng Sun, Philip Resnik, Mohit Iyyer |  |
| 260 |  |  [ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger](https://doi.org/10.18653/v1/2024.naacl-long.165) |  | 0 | Textual backdoor attacks, characterized by subtle manipulations of input triggers and training dataset labels, pose significant threats to security-sensitive applications. The rise of advanced generative models, such as GPT-4, with their capacity for human-like rewriting, makes these attacks increasingly challenging to detect. In this study, we conduct an in-depth examination of black-box generative models as tools for backdoor attacks, thereby emphasizing... | Jiazhao Li, Yijin Yang, Zhuofeng Wu, V. G. Vinod Vydiswaran, Chaowei Xiao |  |
| 261 |  |  [Social Meme-ing: Measuring Linguistic Variation in Memes](https://doi.org/10.18653/v1/2024.naacl-long.166) |  | 0 | Much work in the space of NLP has used computational methods to explore sociolinguistic variation in text. In this paper, we argue that memes, as multimodal forms of language comprised of visual templates and text, also exhibit meaningful social variation. We construct a computational pipeline to cluster individual instances of memes into templates and semantic variables, taking advantage of their multimodal structure in doing so. We apply this method to a... | Naitian Zhou, David Jurgens, David Bamman |  |
| 262 |  |  [ExpertQA: Expert-Curated Questions and Attributed Answers](https://doi.org/10.18653/v1/2024.naacl-long.167) |  | 0 | As language models are adopted by a more sophisticated and diverse set of users, the importance of guaranteeing that they provide factually correct information supported by verifiable sources is critical across fields of study. This is especially the case for high-stakes fields, such as medicine and law, where the risk of propagating false information is high and can lead to undesirable societal consequences. Previous work studying attribution and factuality... | Chaitanya Malaviya, Subin Lee, Sihao Chen, Elizabeth Sieber, Mark Yatskar, Dan Roth |  |
| 263 |  |  [What if you said that differently?: How Explanation Formats Affect Human Feedback Efficacy and User Perception](https://doi.org/10.18653/v1/2024.naacl-long.168) |  | 0 | Eliciting feedback from end users of NLP models can be beneficial for improving models. However, how should we present model responses to users so they are most amenable to be corrected from user feedback? Further, what properties do users value to understand and trust responses? We answer these questions by analyzing the effect of rationales (or explanations) generated by QA models to support their answers. We specifically consider decomposed QA models that... | Chaitanya Malaviya, Subin Lee, Dan Roth, Mark Yatskar |  |
| 264 |  |  [When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels](https://doi.org/10.18653/v1/2024.naacl-long.169) |  | 0 | Deployed dialogue agents have the potential to integrate human feedback to continuously improve themselves. However, humans may not always provide explicit signals when the chatbot makes mistakes during interactions. In this work, we propose Juicer, a framework to make use of both binary and free-form textual human feedback. It works by: (i) extending sparse binary feedback by training a satisfaction classifier to label the unlabeled data; and (ii) training a... | Weiyan Shi, Emily Dinan, Kurt Shuster, Jason Weston, Jing Xu |  |
| 265 |  |  [Kreyòl-MT: Building MT for Latin American, Caribbean and Colonial African Creole Languages](https://doi.org/10.18653/v1/2024.naacl-long.170) |  | 0 | A majority of language technologies are tailored for a small number of high-resource languages, while relatively many low-resource languages are neglected. One such group, Creole languages, have long been marginalized in academic study, though their speakers could benefit from machine translation (MT). These languages are predominantly used in much of Latin America, Africa and the Caribbean. We present the largest cumulative dataset to date for Creole... | Nathaniel R. Robinson, Raj Dabre, Ammon Shurtz, Rasul Dent, Onenamiyi Onesi, Claire Bizon Monroc, Loïc Grobol, Hasan Muhammad, Ashi Garg, Naome A. Etori, Vijay Murari Tiyyala, Olanrewaju Samuel, Matthew Dean Stutzman, Bismarck Bamfo Odoom, Sanjeev Khudanpur, Stephen D. Richardson, Kenton Murray |  |
| 266 |  |  [Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.171) |  | 0 | We investigate security concerns of the emergent instruction tuning paradigm, that models are trained on crowdsourced datasets with task instructions to achieve superior performance. Our studies demonstrate that an attacker can inject backdoors by issuing very few malicious instructions (~1000 tokens) and control model behavior through data poisoning, without even the need to modify data instances or labels themselves. Through such instruction attacks, the... | Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, Muhao Chen |  |
| 267 |  |  [Modeling Empathetic Alignment in Conversation](https://doi.org/10.18653/v1/2024.naacl-long.172) |  | 0 | Empathy requires perspective-taking: empathetic responses require a person to reason about what another has experienced and communicate that understanding in language. However, most NLP approaches to empathy do not explicitly model this alignment process. Here, we introduce a new approach to recognizing alignment in empathetic speech, grounded in Appraisal Theory. We introduce a new dataset of over 9.2K span-level annotations of different types of appraisals... | Jiamin Yang, David Jurgens |  |
| 268 |  |  [Native Language Identification in Texts: A Survey](https://doi.org/10.18653/v1/2024.naacl-long.173) |  | 0 | We present the first comprehensive survey of Native Language Identification (NLI) applied to texts. NLI is the task of automatically identifying an author’s native language (L1) based on their second language (L2) production. NLI is an important task with practical applications in second language teaching and NLP. The task has been widely studied for both text and speech, particularly for L2 English due to the availability of suitable corpora. Speech-based... | Dhiman Goswami, Sharanya Thilagan, Kai North, Shervin Malmasi, Marcos Zampieri |  |
| 269 |  |  [LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.174) |  | 0 | Various parameter-efficient fine-tuning (PEFT) techniques have been proposed to enable computationally efficient fine-tuning while maintaining model performance. However, existing PEFT methods are still limited by the growing number of trainable parameters with the rapid deployment of Large Language Models (LLMs). To address this challenge, we present LoRETTA, an ultra-parameter-efficient framework that significantly reduces trainable parameters through... | Yifan Yang, Jiajun Zhou, Ngai Wong, Zheng Zhang |  |
| 270 |  |  [Which One? Leveraging Context Between Objects and Multiple Views for Language Grounding](https://doi.org/10.18653/v1/2024.naacl-long.175) |  | 0 | When connecting objects and their language referents in an embodied 3D environment, it is important to note that: (1) an object can be better characterized by leveraging comparative information between itself and other objects, and (2) an object’s appearance can vary with camera position. As such, we present the Multi-view Approach to Grounding in Context (MAGiC) model, which selects an object referent based on language that distinguishes between two similar... | Chancharik Mitra, Abrar Anwar, Rodolfo Corona, Dan Klein, Trevor Darrell, Jesse Thomason |  |
| 271 |  |  [Do Localization Methods Actually Localize Memorized Data in LLMs? A Tale of Two Benchmarks](https://doi.org/10.18653/v1/2024.naacl-long.176) |  | 0 | The concept of localization in LLMs is often mentioned in prior work; however, methods for localization have never been systematically and directly evaluated. We propose two complementary benchmarks that evaluate the ability of localization methods to pinpoint LLM components responsible for memorized data. In our INJ benchmark, we actively inject a piece of new information into a small subset of LLM weights, enabling us to directly evaluate whether... | TingYun Chang, Jesse Thomason, Robin Jia |  |
| 272 |  |  [PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning](https://doi.org/10.18653/v1/2024.naacl-long.177) |  | 0 | Pre-trained language models (PLMs) have attracted enormous attention over the past few years with their unparalleled performances. Meanwhile, the soaring cost to train PLMs as well as their amazing generalizability have jointly contributed to few-shot fine-tuning and prompting as the most popular training paradigms for natural language processing (NLP) models. Nevertheless, existing studies have shown that these NLP models can be backdoored such that model... | Tianrong Zhang, Zhaohan Xi, Ting Wang, Prasenjit Mitra, Jinghui Chen |  |
| 273 |  |  [Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models](https://doi.org/10.18653/v1/2024.naacl-long.178) |  | 0 | In many real natural language processing application scenarios, practitioners not only aim to maximize predictive performance but also seek faithful explanations for the model predictions. Rationales and importance distribution given by feature attribution methods (FAs) provide insights into how different parts of the input contribute to a prediction. Previous studies have explored how different factors affect faithfulness, mainly in the context of... | Zhixue Zhao, Nikolaos Aletras |  |
| 274 |  |  [A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity](https://doi.org/10.18653/v1/2024.naacl-long.179) |  | 0 | Pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. We pretrain models on data curated (1) at different collection times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we find that temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we measure the effect of quality... | Shayne Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David Mimno, Daphne Ippolito |  |
| 275 |  |  [Instructional Fingerprinting of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.180) |  | 0 | The exorbitant cost of training Large language models (LLMs) from scratch makes it essential to fingerprint the models to protect intellectual property via ownership authentication and to ensure downstream users and developers comply with their license terms (eg restricting commercial use). In this study, we present a pilot study on LLM fingerprinting as a form of very lightweight instruction tuning. Model publisher specifies a confidential private key and... | Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen |  |
| 276 |  |  [Reinforced Multiple Instance Selection for Speaker Attribute Prediction](https://doi.org/10.18653/v1/2024.naacl-long.181) |  | 0 | Language usage is related to speaker age, gender, moral concerns, political ideology, and other attributes. Current state-of-the-art methods for predicting these attributes take a speaker’s utterances as input and provide a prediction per speaker attribute. Most of these approaches struggle to handle a large number of utterances per speaker. This difficulty is primarily due to the computational constraints of the models. Additionally, only a subset of speaker... | Alireza Salkhordeh Ziabari, Ali Omrani, Parsa Hejabi, Preni Golazizian, Brendan Kennedy, Payam Piray, Morteza Dehghani |  |
| 277 |  |  [DynaMo: Accelerating Language Model Inference with Dynamic Multi-Token Sampling](https://doi.org/10.18653/v1/2024.naacl-long.182) |  | 0 | Traditional language models operate autoregressively, i.e., they predict one token at a time. Rapid explosion in model sizes has resulted in high inference times. In this work, we propose DynaMo, a suite of multi-token prediction language models that reduce net inference times. Our models \*dynamically\* predict multiple tokens based on their confidence in the predicted joint probability distribution. We propose a lightweighttechnique to train these models,... | Shikhar Tuli, ChiHeng Lin, YenChang Hsu, Niraj K. Jha, Yilin Shen, Hongxia Jin |  |
| 278 |  |  [Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation](https://doi.org/10.18653/v1/2024.naacl-long.183) |  | 0 | Few-shot Knowledge Graph (KG) Relational Reasoning aims to predict unseen triplets (i.e., query triplets) for rare relations in KGs, given only several triplets of these relations as references (i.e., support triplets). This task has gained significant traction due to the widespread use of knowledge graphs in various natural language processing applications. Previous approaches have utilized meta-training methods and manually constructed meta-relation sets to... | Haochen Liu, Song Wang, Chen Chen, Jundong Li |  |
| 279 |  |  [Uncertainty Quantification for In-Context Learning of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.184) |  | 0 | In-context learning has emerged as a groundbreaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM’s response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM’s response, but they often overlook the complex nature of LLMs and the uniqueness of in-context... | Chen Ling, Xujiang Zhao, Xuchao Zhang, Wei Cheng, Yanchi Liu, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Jie Ji, Guangji Bai, Liang Zhao, Haifeng Chen |  |
| 280 |  |  [HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM](https://doi.org/10.18653/v1/2024.naacl-long.185) |  | 0 | Existing open-source helpfulness preference datasets do not specify what makes some responses more helpful and others less so. Models trained on these datasets can incidentally learn to model dataset artifacts (e.g. preferring longer but unhelpful responses only due to their length). To alleviate this problem, we collect HelpSteer, a multi-attribute helpfulness dataset annotated for the various aspects that make responses helpful. Specifically, our 37k-sample... | Zhilin Wang, Yi Dong, Jiaqi Zeng, Virginia Adams, Makesh Narsimhan Sreedhar, Daniel Egert, Olivier Delalleau, Jane Polak Scowcroft, Neel Kant, Aidan Swope, Oleksii Kuchaiev |  |
| 281 |  |  [A Preference-driven Paradigm for Enhanced Translation with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.186) |  | 0 | Recent research has shown that large language models (LLMs) can achieve remarkable translation performance through supervised fine-tuning (SFT) using only a small amount of parallel data. However, SFT simply instructs the model to imitate the reference translations at the token level, making it vulnerable to the noise present in the references. Hence, the assistance from SFT often reaches a plateau once the LLMs have achieved a certain level of translation... | Dawei Zhu, Sony Trenous, Xiaoyu Shen, Dietrich Klakow, Bill Byrne, Eva Hasler |  |
| 282 |  |  [Fair Abstractive Summarization of Diverse Perspectives](https://doi.org/10.18653/v1/2024.naacl-long.187) |  | 0 | People from different social and demographic groups express diverse perspectives and conflicting opinions on a broad set of topics such as product reviews, healthcare, law, and politics. A fair summary should provide a comprehensive coverage of diverse perspectives without underrepresenting certain groups. However, current work in summarization metrics and Large Language Models (LLMs) evaluation has not explored fair abstractive summarization. In this paper,... | Yusen Zhang, Nan Zhang, Yixin Liu, Alexander R. Fabbri, Junru Liu, Ryo Kamoi, Xiaoxin Lu, Caiming Xiong, Jieyu Zhao, Dragomir Radev, Kathleen R. McKeown, Rui Zhang |  |
| 283 |  |  [What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases](https://doi.org/10.18653/v1/2024.naacl-long.188) |  | 0 | Vision-language (VL) models, pretrained on colossal image-text datasets, have attained broad VL competence that is difficult to evaluate. A common belief is that a small number of VL skills underlie the variety of VL tests. In this paper, we perform a large-scale transfer learning experiment aimed at discovering latent VL skills from data. We reveal interesting characteristics that have important implications for test suite design. First, generation tasks... | Anthony Meng Huat Tiong, Junqi Zhao, Boyang Li, Junnan Li, Steven C. H. Hoi, Caiming Xiong |  |
| 284 |  |  [Show Your Work with Confidence: Confidence Bands for Tuning Curves](https://doi.org/10.18653/v1/2024.naacl-long.189) |  | 0 | The choice of hyperparameters greatly impacts performance in natural language processing. Often, it is hard to tell if a method is better than another or just better tuned. \*Tuning curves\* fix this ambiguity by accounting for tuning effort. Specifically, they plot validation performance as a function of the number of hyperparameter choices tried so far. While several estimators exist for these curves, it is common to use point estimates, which we show fail... | Nicholas Lourie, Kyunghyun Cho, He He |  |
| 285 |  |  [GRASP: A Disagreement Analysis Framework to Assess Group Associations in Perspectives](https://doi.org/10.18653/v1/2024.naacl-long.190) |  | 0 | Human annotation plays a core role in machine learning — annotations for supervised models, safety guardrails for generative models, and human feedback for reinforcement learning, to cite a few avenues. However, the fact that many of these human annotations are inherently subjective is often overlooked. Recent work has demonstrated that ignoring rater subjectivity (typically resulting in rater disagreement) is problematic within specific tasks and for... | Vinodkumar Prabhakaran, Christopher Homan, Lora Aroyo, Aida Mostafazadeh Davani, Alicia Parrish, Alex S. Taylor, Mark Diaz, Ding Wang, Gregory SerapioGarcía |  |
| 286 |  |  [Event Causality Is Key to Computational Story Understanding](https://doi.org/10.18653/v1/2024.naacl-long.191) |  | 0 | Cognitive science and symbolic AI research suggest that event causality provides vital information for story understanding. However, machine learning systems for story understanding rarely employ event causality, partially due to the lack of methods that reliably identify open-world causal event relations. Leveraging recent progress in large language models, we present the first method for event causality identification that leads to material improvements in... | Yidan Sun, Qin Chao, Boyang Li |  |
| 287 |  |  [Subspace Representations for Soft Set Operations and Sentence Similarities](https://doi.org/10.18653/v1/2024.naacl-long.192) |  | 0 | In the field of natural language processing (NLP), continuous vector representations are crucial for capturing the semantic meanings of individual words. Yet, when it comes to the representations of sets of words, the conventional vector-based approaches often struggle with expressiveness and lack the essential set operations such as union, intersection, and complement. Inspired by quantum logic, we realize the representation of word sets and corresponding... | Yoichi Ishibashi, Sho Yokoi, Katsuhito Sudoh, Satoshi Nakamura |  |
| 288 |  |  [My Heart Skipped a Beat! Recognizing Expressions of Embodied Emotion in Natural Language](https://doi.org/10.18653/v1/2024.naacl-long.193) |  | 0 | Humans frequently experience emotions. When emotions arise, they affect not only our mental state but can also change our physical state. For example, we often open our eyes wide when we are surprised, or clap our hands when we feel excited. Physical manifestations of emotions are referred to as embodied emotion in the psychology literature. From an NLP perspective, recognizing descriptions of physical movements or physiological responses associated with... | Yuan Zhuang, Tianyu Jiang, Ellen Riloff |  |
| 289 |  |  [Low-Cost Generation and Evaluation of Dictionary Example Sentences](https://doi.org/10.18653/v1/2024.naacl-long.194) |  | 0 | Dictionary example sentences play an important role in illustrating word definitions and usage, but manually creating quality sentences is challenging. Prior works have demonstrated that language models can be trained to generate example sentences. However, they relied on costly customized models and word sense datasets for generation and evaluation of their work. Rapid advancements in foundational models present the opportunity to create low-cost, zero-shot... | Bill Cai, Clarence Boon Liang Ng, Daniel Liang, Shelvia Hotama |  |
| 290 |  |  [Making Language Models Better Tool Learners with Execution Feedback](https://doi.org/10.18653/v1/2024.naacl-long.195) |  | 0 | Tools serve as pivotal interfaces that enable humans to understand and reshape the environment. With the advent of foundation models, AI systems can utilize tools to expand their capabilities and interact with the real world. Existing tool learning methodologies, encompassing supervised fine-tuning and prompt engineering approaches, often induce large language models to utilize tools indiscriminately, as complex tasks often exceed their own competencies.... | Shuofei Qiao, Honghao Gui, Chengfei Lv, Qianghuai Jia, Huajun Chen, Ningyu Zhang |  |
| 291 |  |  [Complex Claim Verification with Evidence Retrieved in the Wild](https://doi.org/10.18653/v1/2024.naacl-long.196) |  | 0 | Retrieving evidence to support or refute claims is a core part of automatic fact-checking. Prior work makes simplifying assumptions in retrieval that depart from real-world use cases: either no access to evidence, access to evidence curated by a human fact-checker, or access to evidence published after a claim was made. In this work, we present the first realistic pipeline to check real-world claims by retrieving raw evidence from the web. We restrict our... | Jifan Chen, Grace Kim, Aniruddh Sriram, Greg Durrett, Eunsol Choi |  |
| 292 |  |  [Multimodal Multi-loss Fusion Network for Sentiment Analysis](https://doi.org/10.18653/v1/2024.naacl-long.197) |  | 0 | This paper investigates the optimal selection and fusion of feature encoders across multiple modalities and combines these in one neural network to improve sentiment detection. We compare different fusion methods and examine the impact of multi-loss training within the multi-modality fusion network, identifying surprisingly important findings relating to subnet performance. We have also found that integrating context significantly enhances model performance.... | Zehui Wu, Ziwei Gong, Jaywon Koo, Julia Hirschberg |  |
| 293 |  |  [Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications](https://doi.org/10.18653/v1/2024.naacl-long.198) |  | 0 | Recent literature has suggested the potential of using large language models (LLMs) to make classifications for tabular tasks. However, LLMs have been shown to exhibit harmful social biases that reflect the stereotypes and inequalities present in society. To this end, as well as the widespread use of tabular data in many high-stake applications, it is important to explore the following questions: what sources of information do LLMs draw upon when making... | Yanchen Liu, Srishti Gautam, Jiaqi Ma, Himabindu Lakkaraju |  |
| 294 |  |  [Analyzing the Use of Metaphors in News Editorials for Political Framing](https://doi.org/10.18653/v1/2024.naacl-long.199) |  | 0 | Metaphorical language is a pivotal element inthe realm of political framing. Existing workfrom linguistics and the social sciences providescompelling evidence regarding the distinctivenessof conceptual framing for politicalideology perspectives. However, the nature andutilization of metaphors and the effect on audiencesof different political ideologies withinpolitical discourses are hardly explored. Toenable research in this direction, in this workwe create a... | Meghdut Sengupta, Roxanne El Baff, Milad Alshomary, Henning Wachsmuth |  |
| 295 |  |  [SharpSeq: Empowering Continual Event Detection through Sharpness-Aware Sequential-task Learning](https://doi.org/10.18653/v1/2024.naacl-long.200) |  | 0 | Continual event detection is a cornerstone in uncovering valuable patterns in many dynamic practical applications, where novel events emerge daily. Existing state-of-the-art approaches with replay buffers still suffer from catastrophic forgetting, partially due to overly simplistic objective aggregation. This oversight disregards complex trade-offs and leads to sub-optimal gradient updates, resulting in performance deterioration across objectives. While there... | ThanhThien Le, Viet Dao, Linh Nguyen, ThiNhung Nguyen, Linh Ngo Van, Thien Huu Nguyen |  |
| 296 |  |  [Dissecting Paraphrases: The Impact of Prompt Syntax and supplementary Information on Knowledge Retrieval from Pretrained Language Models](https://doi.org/10.18653/v1/2024.naacl-long.201) |  | 0 | Pre-trained Language Models (PLMs) are known to contain various kinds of knowledge.One method to infer relational knowledge is through the use of cloze-style prompts, where a model is tasked to predict missing subjects orobjects. Typically, designing these prompts is a tedious task because small differences in syntax or semantics can have a substantial impact on knowledge retrieval performance. Simultaneously, evaluating the impact of either prompt syntax or... | Stephan Linzbach, Dimitar Dimitrov, Laura Kallmeyer, Kilian Evang, Hajira Jabeen, Stefan Dietze |  |
| 297 |  |  [Know When To Stop: A Study of Semantic Drift in Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.202) |  | 0 | In this work, we explicitly show that modern LLMs tend to generate correct facts first, then “drift away” and generate incorrect facts later: this was occasionally observed but never properly measured. We develop a semantic drift score that measures the degree of separation between correct and incorrect facts in generated texts and confirm our hypothesis when generating Wikipedia-style biographies. This correct-then-incorrect generation pattern suggests that... | Ava Spataru, Eric Hambro, Elena Voita, Nicola Cancedda |  |
| 298 |  |  [Curriculum Masking in Vision-Language Pretraining to Maximize Cross Modal Interaction](https://doi.org/10.18653/v1/2024.naacl-long.203) |  | 0 | Many leading methods in Vision and language (V+L) pretraining utilize masked language modeling (MLM) as a standard pretraining component, with the expectation that reconstruction of masked text tokens would necessitate reference to corresponding image context via cross/self attention and thus promote representation fusion. However, we observe that the minimization of MLM loss in earlier training stages can depend disproportionately on local text signals,... | Kraig Tou, Zijun Sun |  |
| 299 |  |  [Elote, Choclo and Mazorca: on the Varieties of Spanish](https://doi.org/10.18653/v1/2024.naacl-long.204) |  | 0 | Spanish is one of the most widespread languages: the official language in 20 countries and the second most-spoken native language. Its contact with other languages across different regions and the rich regional and cultural diversity has produced varieties which divert from each other, particularly in terms of lexicon. Still, available corpora, and models trained upon them, generally treat Spanish as one monolithic language, which dampers prediction and... | Cristina EspañaBonet, Alberto BarrónCedeño |  |
| 300 |  |  [Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks](https://doi.org/10.18653/v1/2024.naacl-long.205) |  | 0 | Recently, the large language model (LLM) community has shown increasing interest in enhancing LLMs’ capability to handle extremely long documents. As various long-text techniques and model architectures emerge, the precise and detailed evaluation of models’ long-text capabilities has become increasingly important. Existing long-text evaluation benchmarks, such as L-Eval and LongBench, construct long-text test sets based on open-source datasets, focusing... | Chonghua Wang, Haodong Duan, Songyang Zhang, Dahua Lin, Kai Chen |  |
| 301 |  |  [A Zero-Shot Monolingual Dual Stage Information Retrieval System for Spanish Biomedical Systematic Literature Reviews](https://doi.org/10.18653/v1/2024.naacl-long.206) |  | 0 | Systematic Reviews (SRs) are foundational in healthcare for synthesising evidence to inform clinical practices. Traditionally skewed towards English-language databases, SRs often exclude significant research in other languages, leading to potential biases. This study addresses this gap by focusing on Spanish, a language notably underrepresented in SRs. We present a foundational zero-shot dual information retrieval (IR) baseline system, integrating traditional... | Regina OforiBoateng, Magaly AcevesMartins, Nirmalie Wiratunga, Carlos Francisco MorenoGarcía |  |
| 302 |  |  [LayoutPointer: A Spatial-Context Adaptive Pointer Network for Visual Information Extraction](https://doi.org/10.18653/v1/2024.naacl-long.207) |  | 0 | Visual Information Extraction (VIE), as a crucial task of Document Intelligence, involves two primary sub-tasks: Semantic Entity Recognition (SER) and Relation Extraction (RE). However, VIE faces two significant challenges. Firstly, most existing models inadequately utilize spatial information of entities, often failing to predict connections or incorrectly linking spatially distant entities. Secondly, the improper input order of tokens challenges in... | Siyuan Huang, Yongping Xiong, Guibin Wu |  |
| 303 |  |  [Long-form evaluation of model editing](https://doi.org/10.18653/v1/2024.naacl-long.208) |  | 0 | Evaluations of model editing, a technique for changing the factual knowledge held by Large Language Models (LLMs), currently only use the ‘next few token’ completions after a prompt. As a result, the impact of these methods on longer natural language generation is largely unknown. We introduce long-form evaluation of model editing (LEME) a novel evaluation protocol that measures the efficacy and impact of model editing in long-form generative settings. Our... | Domenic Rosati, Robie Gonzales, Jinkun Chen, Xuemin Yu, Melis Erkan, Yahya Kayani, Satya Deepika Chavatapalli, Frank Rudzicz, Hassan Sajjad |  |
| 304 |  |  [Analyzing the Role of Semantic Representations in the Era of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.209) |  | 0 | Traditionally, natural language processing (NLP) models often use a rich set of features created by linguistic expertise, such as semantic representations. However, in the era of large language models (LLMs), more and more tasks are turned into generic, end-to-end sequence generation problems. In this paper, we investigate the question: what is the role of semantic representations in the era of LLMs? Specifically, we investigate the effect of Abstract Meaning... | Zhijing Jin, Yuen Chen, Fernando Gonzalez Adauto, Jiarui Liu, Jiayi Zhang, Julian Michael, Bernhard Schölkopf, Mona T. Diab |  |
| 305 |  |  [TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction](https://doi.org/10.18653/v1/2024.naacl-long.210) |  | 0 | When applied to open-domain question answering, large language models (LLMs) frequently generate incorrect responses based on made-up facts, which are called hallucinations. Retrieval augmented generation (RAG) is a promising strategy to avoid hallucinations, but it does not provide guarantees on its correctness. To address this challenge, we propose the Trustworthy Retrieval Augmented Question Answering, or \*TRAQ\*, which provides the first end-to-end... | Shuo Li, Sangdon Park, Insup Lee, Osbert Bastani |  |
| 306 |  |  [MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities](https://doi.org/10.18653/v1/2024.naacl-long.211) |  | 0 | Decoding continuous language from brain activity is a formidable yet promising field of research. It is particularly significant for aiding people with speech disabilities to communicate through brain signals. This field addresses the complex task of mapping brain signals to text. The previous best attempt reverse-engineered this process in an indirect way: it began by learning to encode brain activity from text and then guided text generation by aligning... | Xinpei Zhao, Jingyuan Sun, Shaonan Wang, Jing Ye, Xiaohan Zhang, Chengqing Zong |  |
| 307 |  |  [On-the-fly Definition Augmentation of LLMs for Biomedical NER](https://doi.org/10.18653/v1/2024.naacl-long.212) |  | 0 | Despite their general capabilities, LLMs still struggle on biomedicalNER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a... | Monica Munnangi, Sergey Feldman, Byron C. Wallace, Silvio Amir, Tom Hope, Aakanksha Naik |  |
| 308 |  |  [This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes](https://doi.org/10.18653/v1/2024.naacl-long.213) |  | 0 | Do the Spratly Islands belong to China, the Philippines, or Vietnam? A pretrained large language model (LLM) may answer differently if asked in the languages of each claimant country: Chinese, Tagalog, or Vietnamese. This contrasts with a multilingual human, who would likely answer consistently. In this paper, we show that LLMs recall certain geographical knowledge inconsistently when queried in different languages—a phenomenon we term geopolitical bias. As a... | Bryan Li, Samar Haider, Chris CallisonBurch |  |
| 309 |  |  [Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation](https://doi.org/10.18653/v1/2024.naacl-long.214) |  | 0 | Event temporal graphs have been shown as convenient and effective representations of complex temporal relations between events in text. Recent studies, which employ pre-trained language models to auto-regressively generate linearised graphs for constructing event temporal graphs, have shown promising results. However, these methods have often led to suboptimal graph generation as the linearised graphs exhibit set characteristics which are instead treated... | Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He |  |
| 310 |  |  [LanguageFlow: Advancing Diffusion Language Generation with Probabilistic Flows](https://doi.org/10.18653/v1/2024.naacl-long.215) |  | 0 | Recent works have demonstrated success in controlling sentence attributes (e.g., sentiment) and structure (e.g., syntactic structure) based on the diffusion language model. A key component that drives theimpressive performance for generating high-quality samples from noise is iteratively denoise for thousands of steps. While beneficial, the complexity of starting from the noise and the learning steps has limited its implementation to many NLP real-world... | Shujian Zhang, Lemeng Wu, Chengyue Gong, Xingchao Liu |  |
| 311 |  |  [Towards Improved Multi-Source Attribution for Long-Form Answer Generation](https://doi.org/10.18653/v1/2024.naacl-long.216) |  | 0 | Teaching large language models (LLMs) to generate text with attribution to evidence sources can reduce hallucinations, improve verifiability in question answering systems (QA), and increase reliability of retrieval augmented LLMs. Despite gaining increasing popularity for usage in QA systems and search engines, current LLMs struggle with attribution for long-form responses which require reasoning over multiple evidence sources. To address this, in this paper... | Nilay Patel, Shivashankar Subramanian, Siddhant Garg, Pratyay Banerjee, Amita Misra |  |
| 312 |  |  [Synthetic Query Generation for Privacy-Preserving Deep Retrieval Systems using Differentially Private Language Models](https://doi.org/10.18653/v1/2024.naacl-long.217) |  | 0 | We address the challenge of ensuring differential privacy (DP) guarantees in training deep retrieval systems. Training these systems often involves the use of contrastive-style losses, which are typically non-per-example decomposable, making them difficult to directly DP-train with since common techniques require per-example gradients. To address this issue, we propose an approach that prioritizes ensuring query privacy prior to training a deep retrieval... | Aldo G. Carranza, Rezsa Farahani, Natalia Ponomareva, Alexey Kurakin, Matthew Jagielski, Milad Nasr |  |
| 313 |  |  [Okay, Let's Do This! Modeling Event Coreference with Generated Rationales and Knowledge Distillation](https://doi.org/10.18653/v1/2024.naacl-long.218) |  | 0 | In NLP, Event Coreference Resolution (ECR) is the task of connecting event clusters that refer to the same underlying real-life event, usually via neural systems. In this work, we investigate using abductive free-text rationales (FTRs) generated by modern autoregressive LLMs as distant supervision of smaller student models for cross-document coreference (CDCR) of events. We implement novel rationale-oriented event clustering and knowledge distillation methods... | Abhijnan Nath, Shadi Manafi Avari, Avyakta Chelle, Nikhil Krishnaswamy |  |
| 314 |  |  [Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey](https://doi.org/10.18653/v1/2024.naacl-long.219) |  | 0 | The contemporary LLMs are prone to producing hallucinations, stemming mainly from the knowledge gaps within the models. To address this critical limitation, researchers employ diverse strategies to augment the LLMs by incorporating external knowledge, aiming to reduce hallucinations and enhance reasoning accuracy. Among these strategies, leveraging knowledge graphs as a source of external information has demonstrated promising results. In this survey, we... | Garima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, Huan Liu |  |
| 315 |  |  [Pedagogically Aligned Objectives Create Reliable Automatic Cloze Tests](https://doi.org/10.18653/v1/2024.naacl-long.220) |  | 0 | The cloze training objective of Masked Language Models makes them a natural choice for generating plausible distractors for human cloze questions. However, distractors must also be both distinct and incorrect, neither of which is directly addressed by existing neural methods. Evaluation of recent models has also relied largely on automated metrics, which cannot demonstrate the reliability or validity of human comprehension tests. In this work, we first... | Brian D. Ondov, Kush Attal, Dina DemnerFushman |  |
| 316 |  |  [Take One Step at a Time to Know Incremental Utility of Demonstration: An Analysis on Reranking for Few-Shot In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.221) |  | 0 | In-Context Learning (ICL) is an emergent capability of Large Language Models (LLMs). Only a few demonstrations enable LLMs to be used as blackbox for new tasks. Previous studies have shown that using LLMs’ outputs as labels is effective in training models to select demonstrations. Such a label is expected to estimate utility of a demonstration in ICL; however, it has not been well understood how different labeling strategies affect results on target tasks.... | Kazuma Hashimoto, Karthik Raman, Michael Bendersky |  |
| 317 |  |  [LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.222) |  | 0 | Today’s large language models (LLMs) typically train on short text segments (e.g., <4K tokens) due to the quadratic complexity of their Transformer architectures. As a result, their performance suffers drastically on inputs longer than those encountered during training, substantially limiting their applications in real-world tasks involving long contexts such as encod- ing scientific articles, code repositories, or long dialogues. Through both theoretical... | Chi Han, Qifan Wang, Hao Peng, Wenhan Xiong, Yu Chen, Heng Ji, Sinong Wang |  |
| 318 |  |  [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants](https://doi.org/10.18653/v1/2024.naacl-long.223) |  | 0 | A wave of new task-based virtual assistants has been fueled by increasingly powerful large language models (LLMs), such as GPT-4 (OpenAI, 2023). A major challenge in deploying LLM-based virtual conversational assistants in real world settings is ensuring they operate within what is admissible for the task. To overcome this challenge, the designers of these virtual assistants rely on an independent guardrail system that verifies the virtual assistant’s output... | Albert Yu Sun, Varun Nair, Elliot Schumacher, Anitha Kannan |  |
| 319 |  |  [Advancing Beyond Identification: Multi-bit Watermark for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.224) |  | 0 | We show the viability of tackling misuses of large language models beyond the identification of machine-generated text. While existing zero-bit watermark methods focus on detection only, some malicious misuses demand tracing the adversary user for counteracting them. To address this, we propose Multi-bit Watermark via Position Allocation, embedding traceable multi-bit information during language model generation. Through allocating tokens onto different parts... | KiYoon Yoo, Wonhyuk Ahn, Nojun Kwak |  |
| 320 |  |  [HTCCN: Temporal Causal Convolutional Networks with Hawkes Process for Extrapolation Reasoning in Temporal Knowledge Graphs](https://doi.org/10.18653/v1/2024.naacl-long.225) |  | 0 | Temporal knowledge graphs (TKGs) serve as powerful tools for storing and modeling dynamic facts, holding immense potential in anticipating future facts. Since future facts are inherently unknowable, effectively modeling the intricate temporal structure of historical facts becomes paramount for accurate prediction. However, current models often rely heavily on fact recurrence or periodicity, leading to information loss due to prolonged evolutionary processes.... | Tingxuan Chen, Jun Long, Liu Yang, Zidong Wang, Yongheng Wang, Xiongnan Jin |  |
| 321 |  |  [SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.226) |  | 0 | Existing watermarked generation algorithms employ token-level designs and therefore, are vulnerable to paraphrase attacks. To address this issue, we introduce watermarking on the semantic representation of sentences. We propose SemStamp, a robust sentence-level semantic watermarking algorithm that uses locality-sensitive hashing (LSH) to partition the semantic space of sentences. The algorithm encodes and LSH-hashes a candidate sentence generated by a... | Abe Bohan Hou, Jingyu Zhang, Tianxing He, Yichen Wang, YungSung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, Yulia Tsvetkov |  |
| 322 |  |  [Media Bias Detection Across Families of Language Models](https://doi.org/10.18653/v1/2024.naacl-long.227) |  | 0 | Bias in reporting can influence the public’s opinion on relevant societal issues. Examples include informational bias (selective presentation of content) and lexical bias (specific framing of content through linguistic choices). The recognition of media bias is arguably an area where NLP can contribute to the “social good”. Traditional NLP models have shown good performance in classifying media bias, but require careful model design and extensive tuning. In... | Iffat Maab, Edison MarreseTaylor, Sebastian Padó, Yutaka Matsuo |  |
| 323 |  |  [Better Zero-Shot Reasoning with Role-Play Prompting](https://doi.org/10.18653/v1/2024.naacl-long.228) |  | 0 | Modern large language models (LLMs) exhibit a remarkable capacity for role-playing, enabling them to embody not only human characters but also non-human entities. This versatility allows them to simulate complex human-like interactions and behaviors within various contexts, as well as to emulate specific objects or systems. While these capabilities have enhanced user engagement and introduced novel modes of interaction, the influence of role-playing on LLMs’... | Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi Sun, Xin Zhou, Enzhi Wang, Xiaohang Dong |  |
| 324 |  |  [Event-Content-Oriented Dialogue Generation in Short Video](https://doi.org/10.18653/v1/2024.naacl-long.229) |  | 0 | Understanding complex events from different modalities, associating to external knowledge and generating response in a clear point of view are still unexplored in today’s multi-modal dialogue research. The great challenges include 1) lack of event-based multi-modal dialogue dataset; 2) understanding of complex events and 3) heterogeneity gap between different modalities. To overcome these challenges, we firstly introduce a novel event-oriented video-dialogue... | Fenghua Cheng, Xue Li, Zi Huang, Jinxiang Wang, Sen Wang |  |
| 325 |  |  [DoG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded Instruction Wrapping](https://doi.org/10.18653/v1/2024.naacl-long.230) |  | 0 | The improvement of LLMs’ instruction-following capabilities relies heavily on the availability of high-quality instruction-response pairs. Unfortunately, the current methods used to collect the pairs suffer from either unaffordable labor costs or severe hallucinations in the self-generation of LLM.To tackle these challenges, this paper proposes a scalable solution.It involves training LLMs to generate instruction-response pairs based on human-written... | Yongrui Chen, Haiyun Jiang, Xinting Huang, Shuming Shi, Guilin Qi |  |
| 326 |  |  [Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case Summarization](https://doi.org/10.18653/v1/2024.naacl-long.231) |  | 0 | Legal professionals face the challenge of managing an overwhelming volume of lengthy judgments, making automated legal case summarization crucial. However, prior approaches mainly focused on training and evaluating these models within the same jurisdiction. In this study, we explore the cross-jurisdictional generalizability of legal case summarization models. Specifically, we explore how to effectively summarize legal cases of a target jurisdiction where... | T. Y. S. S. Santosh, Vatsal Venkatkrishna, Saptarshi Ghosh, Matthias Grabmair |  |
| 327 |  |  [EDC: Effective and Efficient Dialog Comprehension For Dialog State Tracking](https://doi.org/10.18653/v1/2024.naacl-long.232) |  | 0 | In Task-Oriented Dialog (TOD) systems, Dialog State Tracking (DST) structurally extracts information from user and system utterances, which can be further used for querying databases and forming responses to users. The two major categories of DST methods, sequential and independent methods, face trade-offs between accuracy and efficiency. To resolve this issue, we propose Effective and Efficient Dialog Comprehension (EDC), an alternative DST approach that... | Qifan Lu, Bhaskar Ramasubramanian, Radha Poovendran |  |
| 328 |  |  [Automatic Restoration of Diacritics for Speech Data Sets](https://doi.org/10.18653/v1/2024.naacl-long.233) |  | 0 | Automatic text-based diacritic restoration models generally have high diacritic error rates when applied to speech transcripts as a result of domain and style shifts in spoken language. In this work, we explore the possibility of improving the performance of automatic diacritic restoration when applied to speech data by utilizing parallel spoken utterances. In particular, we use the pre-trained Whisper ASR model fine-tuned on relatively small amounts of... | Sara Abedalmonem Mohammad Shatnawi, Sawsan Alqahtani, Hanan Aldarmaki |  |
| 329 |  |  [XNLIeu: a dataset for cross-lingual NLI in Basque](https://doi.org/10.18653/v1/2024.naacl-long.234) |  | 0 | XNLI is a popular Natural Language Inference (NLI) benchmark widely used to evaluate cross-lingual Natural Language Understanding (NLU) capabilities across languages. In this paper, we expand XNLI to include Basque, a low-resource language that can greatly benefit from transfer-learning approaches. The new dataset, dubbed XNLIeu, has been developed by first machine-translating the English XNLI corpus into Basque, followed by a manual post-edition step. We... | Maite Heredia, Julen Etxaniz, Muitze Zulaika, Xabier Saralegi, Jeremy Barnes, Aitor Soroa |  |
| 330 |  |  [MDR: Model-Specific Demonstration Retrieval at Inference Time for In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.235) |  | 0 | Recently, retrieval-based in-context learning (ICL) methods for selecting demonstrations have been widely investigated. Existing methods train a dense retriever to retrieve the most appropriate demonstrations for a given test query, which improves ICL performance. However, we find that distinct LLMs exhibit different biases for “what is a good demonstration” since they possess differences in training data, model architectures and training methods. As a... | Huazheng Wang, Jinming Wu, Haifeng Sun, Zixuan Xia, Daixuan Cheng, Jingyu Wang, Qi Qi, Jianxin Liao |  |
| 331 |  |  [Exploring Cross-Cultural Differences in English Hate Speech Annotations: From Dataset Construction to Analysis](https://doi.org/10.18653/v1/2024.naacl-long.236) |  | 0 | Most hate speech datasets neglect the cultural diversity within a single language, resulting in a critical shortcoming in hate speech detection. To address this, we introduce CREHate, a CRoss-cultural English Hate speech dataset. To construct CREHate, we follow a two-step procedure: 1) cultural post collection and 2) cross-cultural annotation. We sample posts from the SBIC dataset, which predominantly represents North America, and collect posts from four... | Nayeon Lee, Chani Jung, Junho Myung, Jiho Jin, José CamachoCollados, Juho Kim, Alice Oh |  |
| 332 |  |  [Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding](https://doi.org/10.18653/v1/2024.naacl-long.237) |  | 0 | Large language models (LLMs) tend to inadequately integrate input context during text generation, relying excessively on encoded prior knowledge in model parameters, potentially resulting in generated text with factual inconsistencies or contextually unfaithful content. LLMs utilize two primary knowledge sources: 1) prior (parametric) knowledge from pretraining, and 2) contextual (non-parametric) knowledge from input prompts. The study addresses the open... | Zheng Zhao, Emilio Monti, Jens Lehmann, Haytham Assem |  |
| 333 |  |  [Generalizable Sarcasm Detection is Just Around the Corner, of Course!](https://doi.org/10.18653/v1/2024.naacl-long.238) |  | 0 | We tested the robustness of sarcasm detection models by examining their behavior when fine-tuned on four sarcasm datasets containing varying characteristics of sarcasm: label source (authors vs. third-party), domain (social media/online vs. offline conversations/dialogues), style (aggressive vs. humorous mocking). We tested their prediction performance on the same dataset (intra-dataset) and across different datasets (cross-dataset). For intra-dataset... | Hyewon Jang, Diego Frassinelli |  |
| 334 |  |  [Encoding of lexical tone in self-supervised models of spoken language](https://doi.org/10.18653/v1/2024.naacl-long.239) |  | 0 | Interpretability research has shown that self-supervised Spoken LanguageModels (SLMs) encode a wide variety of features in human speech from theacoustic, phonetic, phonological, syntactic and semantic levels, to speakercharacteristics. The bulk of prior research on representations of phonologyhas focused on segmental features such as phonemes; the encoding ofsuprasegmental phonology (such as tone and stress patterns) in SLMs is not yetwell understood. Tone is... | Gaofei Shen, Michaela Watkins, Afra Alishahi, Arianna Bisazza, Grzegorz Chrupala |  |
| 335 |  |  [A Systematic Comparison of Contextualized Word Embeddings for Lexical Semantic Change](https://doi.org/10.18653/v1/2024.naacl-long.240) |  | 0 | Contextualized embeddings are the preferred tool for modeling Lexical Semantic Change (LSC). Current evaluations typically focus on a specific task known as Graded Change Detection (GCD). However, performance comparison across work are often misleading due to their reliance on diverse settings. In this paper, we evaluate state-of-the-art models and approaches for GCD under equal conditions. We further break the LSC problem into Word-in-Context (WiC) and Word... | Francesco Periti, Nina Tahmasebi |  |
| 336 |  |  [iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples](https://doi.org/10.18653/v1/2024.naacl-long.241) |  | 0 | Aspect-based sentiment analysis (ABSA) have been extensively studied, but little light has been shed on the quadruple extraction consisting of four fundamental elements: aspects, categories, opinions and sentiments, especially with implicit aspects and opinions. In this paper, we propose a new method iACOS for extracting Implicit Aspects with Categories and Opinions with Sentiments. First, iACOS appends two implicit tokens at the end of a text to capture the... | Xiancai Xu, JiaDong Zhang, Lei Xiong, Zhishang Liu |  |
| 337 |  |  [Rectifying Demonstration Shortcut in In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.242) |  | 0 | Large language models (LLMs) are able to solve various tasks with only a few demonstrations utilizing their in-context learning (ICL) abilities.However, LLMs often rely on their pre-trained semantic priors of demonstrations rather than on the input-label relationships to proceed with ICL prediction. In this work, we term this phenomenon as the ‘Demonstration Shortcut’.While previous works have primarily focused on improving ICL prediction results for... | Joonwon Jang, Sanghwan Jang, Wonbin Kweon, Minjin Jeon, Hwanjo Yu |  |
| 338 |  |  [Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark](https://doi.org/10.18653/v1/2024.naacl-long.243) |  | 0 | We introduce Universal NER (UNER), an open, community-driven project to develop gold-standard NER benchmarks in many languages. The overarching goal of UNER is to provide high-quality, cross-lingually consistent annotations to facilitate and standardize multilingual NER research. UNER v1 contains 19 datasets annotated with named entities in a cross-lingual consistent schema across 13 diverse languages. In this paper, we detail the dataset creation and... | Stephen Mayhew, Terra Blevins, Shuheng Liu, Marek Suppa, Hila Gonen, Joseph Marvin Imperial, Börje Karlsson, Peiqin Lin, Nikola Ljubesic, Lester James V. Miranda, Barbara Plank, Arij Riabi, Yuval Pinter |  |
| 339 |  |  [ODD: A Benchmark Dataset for the Natural Language Processing Based Opioid Related Aberrant Behavior Detection](https://doi.org/10.18653/v1/2024.naacl-long.244) |  | 0 | Opioid related aberrant behaviors (ORABs) present novel risk factors for opioid overdose. This paper introduces a novel biomedical natural language processing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset designed to identify ORABs from patients’ EHR notes and classify them into nine categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioid... | Sunjae Kwon, Xun Wang, Weisong Liu, Emily Druhl, Minhee L. Sung, Joel I. Reisman, Wenjun Li, Robert D. Kerns, William Becker, Hong Yu |  |
| 340 |  |  [A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models](https://doi.org/10.18653/v1/2024.naacl-long.245) |  | 0 | Chemical named entity recognition (NER) models are used in many downstream tasks, from adverse drug reaction identification to pharmacoepidemiology. However, it is unknown whether these models work the same for everyone. Performance disparities can potentially cause harm rather than the intended good. This paper assesses gender-related performance disparities in chemical NER systems. We develop a framework for measuring gender bias in chemical NER models... | Xingmeng Zhao, Ali Niazi, Anthony Rios |  |
| 341 |  |  [The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education](https://doi.org/10.18653/v1/2024.naacl-long.246) |  | 0 | Assessing instruction quality is a fundamental component of any improvement efforts in the education system. However, traditional manual assessments are expensive, subjective, and heavily dependent on observers’ expertise and idiosyncratic factors, preventing teachers from getting timely and frequent feedback. Different from prior research that mostly focuses on low-inference instructional practices on a singular basis, this paper presents the first study... | Paiheng Xu, Jing Liu, Nathan Jones, Julie Cohen, Wei Ai |  |
| 342 |  |  [Differentially Private Next-Token Prediction of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.247) |  | 0 | Ensuring the privacy of Large Language Models (LLMs) is becoming increasingly important. The most widely adopted technique to accomplish this is DP-SGD, which trains a model to guarantee Differential Privacy (DP). However, DP-SGD overestimates an adversary’s capabilities in having white box access to the model and, as a result, causes longer training times and larger memory usage than SGD. On the other hand, commercial LLM deployments are predominantly... | James Flemings, Meisam Razaviyayn, Murali Annavaram |  |
| 343 |  |  [Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset](https://doi.org/10.18653/v1/2024.naacl-long.248) |  | 0 | Hate speech detection models are only as good as the data they are trained on. Datasets sourced from social media suffer from systematic gaps and biases, leading to unreliable models with simplistic decision boundaries. Adversarial datasets, collected by exploiting model weaknesses, promise to fix this problem. However, adversarial data collection can be slow and costly, and individual annotators have limited creativity. In this paper, we introduce GAHD, a... | Janis Goldzycher, Paul Röttger, Gerold Schneider |  |
| 344 |  |  [Memory Augmented Language Models through Mixture of Word Experts](https://doi.org/10.18653/v1/2024.naacl-long.249) |  | 0 | Scaling up the number of parameters of language models has proven to be an effective approach to improve performance. For dense models, increasing their size proportionally increases their computational footprint. In this work, we seek to aggressively decouple learning capacity and FLOPs through Mixture-of-Experts (MoE) style models with large knowledge-rich vocabulary based routing functions. Our proposed approach, dubbed Mixture of Word Experts (MoWE), can... | Cícero Nogueira dos Santos, James LeeThorp, Isaac Noble, ChungChing Chang, David C. Uthus |  |
| 345 |  |  [Impossible Distillation for Paraphrasing and Summarization: How to Make High-quality Lemonade out of Small, Low-quality Model](https://doi.org/10.18653/v1/2024.naacl-long.250) |  | 0 | We present Impossible Distillation, a novel framework for paraphrasing and sentence summarization, that distills a high-quality dataset and model from a low-quality teacher that itself cannot perform these tasks. Unlike prior works that rely on an extreme-scale teacher model (e.g., GPT3) or task-specific architecture, we hypothesize and verify the paraphrastic proximity intrinsic to pre-trained LMs (e.g., GPT2), where paraphrases occupy a proximal subspace in... | Jaehun Jung, Peter West, Liwei Jiang, Faeze Brahman, Ximing Lu, Jillian Fisher, Taylor Sorensen, Yejin Choi |  |
| 346 |  |  [TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization](https://doi.org/10.18653/v1/2024.naacl-long.251) |  | 0 | Single document news summarization has seen substantial progress on faithfulness in recent years, driven by research on the evaluation of factual consistency, or hallucinations. We ask whether these advances carry over to other text summarization domains. We propose a new evaluation benchmark on topic-focused dialogue summarization, generated by LLMs of varying sizes. We provide binary sentence- level human annotations of the factual consistency of these... | Liyan Tang, Igor Shalyminov, Amy Wingmei Wong, Jon Burnsky, Jake W. Vincent, Yuan Yang, Siffi Singh, Song Feng, Hwanjun Song, Hang Su, Lijia Sun, Yi Zhang, Saab Mansour, Kathleen McKeown |  |
| 347 |  |  [MOKA: Moral Knowledge Augmentation for Moral Event Extraction](https://doi.org/10.18653/v1/2024.naacl-long.252) |  | 0 | News media often strive to minimize explicit moral language in news articles, yet most articles are dense with moral values as expressed through the reported events themselves. However, values that are reflected in the intricate dynamics among \*participating entities\* and \*moral events\* are far more challenging for most NLP systems to detect, including LLMs. To study this phenomenon, we annotate a new dataset, \*\*MORAL EVENTS\*\*, consisting of 5,494... | Xinliang Frederick Zhang, Winston Wu, Nicholas Beauchamp, Lu Wang |  |
| 348 |  |  [Fixing Rogue Memorization in Many-to-One Multilingual Translators of Extremely-Low-Resource Languages by Rephrasing Training Samples](https://doi.org/10.18653/v1/2024.naacl-long.253) |  | 0 | In this paper we study the fine-tuning of pre-trained large high-resource language models (LLMs) into many-to-one multilingual machine translators for extremely-low-resource languages such as endangered Indigenous languages. We explore those issues using datasets created from pseudo-parallel translations to English of The Bible written in 39 Brazilian Indigenous languages using mBART50 and WMT19 as pre-trained models and multiple translation metrics. We... | Paulo R. Cavalin, Pedro Henrique Domingues, Claudio S. Pinhanez, Julio Nogima |  |
| 349 |  |  [Backdoor Attacks on Multilingual Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.254) |  | 0 | While multilingual machine translation (MNMT) systems hold substantial promise, they also have security vulnerabilities. Our research highlights that MNMT systems can be susceptible to a particularly devious style of backdoor attack, whereby an attacker injects poisoned data into a low-resource language pair to cause malicious translations in other languages, including high-resource languages.Our experimental results reveal that injecting less than 0.01%... | Jun Wang, Qiongkai Xu, Xuanli He, Benjamin I. P. Rubinstein, Trevor Cohn |  |
| 350 |  |  [Personalized Jargon Identification for Enhanced Interdisciplinary Communication](https://doi.org/10.18653/v1/2024.naacl-long.255) |  | 0 | Scientific jargon can confuse researchers when they read materials from other domains. Identifying and translating jargon for individual researchers could speed up research, but current methods of jargon identification mainly use corpus-level familiarity indicators rather than modeling researcher-specific needs, which can vary greatly based on each researcher’s background. We collect a dataset of over 10K term familiarity annotations from 11 computer science... | Yue Guo, Joseph Chee Chang, Maria Antoniak, Erin Bransom, Trevor Cohen, Lucy Lu Wang, Tal August |  |
| 351 |  |  [Flames: Benchmarking Value Alignment of LLMs in Chinese](https://doi.org/10.18653/v1/2024.naacl-long.256) |  | 0 | The widespread adoption of large language models (LLMs) across various regions underscores the urgent need to evaluate their alignment with human values. Current benchmarks, however, fall short of effectively uncovering safety vulnerabilities in LLMs. Despite numerous models achieving high scores and ‘topping the chart’ in these evaluations, there is still a significant gap in LLMs’ deeper alignment with human values and achieving genuine harmlessness. To... | Kexin Huang, Xiangyang Liu, Qianyu Guo, Tianxiang Sun, Jiawei Sun, Yaru Wang, Zeyang Zhou, Yixu Wang, Yan Teng, Xipeng Qiu, Yingchun Wang, Dahua Lin |  |
| 352 |  |  [Mitigating Bias for Question Answering Models by Tracking Bias Influence](https://doi.org/10.18653/v1/2024.naacl-long.257) |  | 0 | Models of various NLP tasks have been shown to exhibit stereotypes, and the bias in the question answering (QA) models is especially harmful as the output answers might be directly consumed by the end users. There have been datasets to evaluate bias in QA models, while bias mitigation technique for the QA models is still under-explored. In this work, we propose BMBI, an approach to mitigate the bias of multiple-choice QA models. Based on the intuition that a... | Mingyu Derek Ma, JiunYu Kao, Arpit Gupta, YuHsiang Lin, Wenbo Zhao, Tagyoung Chung, Wei Wang, KaiWei Chang, Nanyun Peng |  |
| 353 |  |  [Extending CLIP's Image-Text Alignment to Referring Image Segmentation](https://doi.org/10.18653/v1/2024.naacl-long.258) |  | 0 | Referring Image Segmentation (RIS) is a cross-modal task that aims to segment an instance described by a natural language expression. Recent methods leverage large-scale pretrained unimodal models as backbones along with fusion techniques for joint reasoning across modalities. However, the inherent cross-modal nature of RIS raises questions about the effectiveness of unimodal backbones. We propose RISCLIP, a novel framework that effectively leverages the... | Seoyeon Kim, Minguk Kang, Dongwon Kim, Jaesik Park, Suha Kwak |  |
| 354 |  |  [Generating Attractive and Authentic Copywriting from Customer Reviews](https://doi.org/10.18653/v1/2024.naacl-long.259) |  | 0 | The goal of product copywriting is to capture the interest of potential buyers by emphasizing the features of products through text descriptions. As e-commerce platforms offer a wide range of services, it’s becoming essential to dynamically adjust the styles of these auto-generated descriptions. Typical approaches to copywriting generation often rely solely on specified product attributes, which may result in dull and repetitive content. To tackle this issue,... | YuXiang Lin, WeiYun Ma |  |
| 355 |  |  [Effective Long-Context Scaling of Foundation Models](https://doi.org/10.18653/v1/2024.naacl-long.260) |  | 0 | We present an effective recipe to train strong long-context LLMs that are capable of utilizing massive context windows of up to 32,000 tokens. Our models are built through continual pretraining from Llama 2 checkpoints with longer text sequences and on a dataset where long texts are upsampled. We perform extensive evaluation using language modeling, synthetic context probing tasks, and a wide range of downstream benchmarks. Across all evaluations, our models... | Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajjwal Bhargava, Rui Hou, Louis Martin, Rashi Rungta, Karthik Abinav Sankararaman, Barlas Oguz, Madian Khabsa, Han Fang, Yashar Mehdad, Sharan Narang, Kshitiz Malik, Angela Fan, Shruti Bhosale, Sergey Edunov, Mike Lewis, Sinong Wang, Hao Ma |  |
| 356 |  |  [Empowering Diffusion Models on the Embedding Space for Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.261) |  | 0 | Diffusion models have achieved state-of-the-art synthesis quality on both visual and audio tasks, and recent works further adapt them to textual data by diffusing on the embedding space. In this paper, we conduct systematic studies of the optimization challenges encountered with both the embedding space and the denoising model, which have not been carefully explored. Firstly, the data distribution is learnable for embeddings, which may lead to the collapse of... | Zhujin Gao, Junliang Guo, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, Linli Xu |  |
| 357 |  |  [Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback](https://doi.org/10.18653/v1/2024.naacl-long.262) |  | 0 | Large language models (LLMs) often generate biased outputs containing offensive, toxic, or stereotypical text. Existing LLM alignment methods such as reinforcement learning from human feedback (RLHF) alleviate biases primarily based on reward signals from current model outputs without considering the source of biases. In this work, to explore how biases are formed, we revisit LLMs’ text generation from a causal perspective. We identify pretraining data and... | Yu Xia, Tong Yu, Zhankui He, Handong Zhao, Julian J. McAuley, Shuai Li |  |
| 358 |  |  [Fake Alignment: Are LLMs Really Aligned Well?](https://doi.org/10.18653/v1/2024.naacl-long.263) |  | 0 | The growing awareness of safety concerns in large language models (LLMs) has sparked considerable interest in the evaluation of safety. This study investigates an under-explored issue about the evaluation of LLMs, namely the substantial discrepancy in performance between multiple-choice questions and open-ended questions. Inspired by research on jailbreak attack patterns, we argue this is caused by mismatched generalization. That is, LLM only remembers the... | Yixu Wang, Yan Teng, Kexin Huang, Chengqi Lyu, Songyang Zhang, Wenwei Zhang, Xingjun Ma, YuGang Jiang, Yu Qiao, Yingchun Wang |  |
| 359 |  |  [Visually Guided Generative Text-Layout Pre-training for Document Intelligence](https://doi.org/10.18653/v1/2024.naacl-long.264) |  | 0 | Prior study shows that pre-training techniques can boost the performance of visual document understanding (VDU), which typically requires models to gain abilities to perceive and reason both document texts and layouts (e.g., locations of texts and table-cells). To this end, we propose visually guided generative text-layout pre-training, named ViTLP. Given a document image, the model optimizes hierarchical language and layout modeling objectives to generate... | Zhiming Mao, Haoli Bai, Lu Hou, Lifeng Shang, Xin Jiang, Qun Liu, KamFai Wong |  |
| 360 |  |  [HILL: Hierarchy-aware Information Lossless Contrastive Learning for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.naacl-long.265) |  | 0 | Existing self-supervised methods in natural language processing (NLP), especially hierarchical text classification (HTC), mainly focus on self-supervised contrastive learning, extremely relying on human-designed augmentation rules to generate contrastive samples, which can potentially corrupt or distort the original information. In this paper, we tend to investigate the feasibility of a contrastive learning scheme in which the semantic and syntactic... | He Zhu, Junran Wu, Ruomei Liu, Yue Hou, Ze Yuan, Shangzhe Li, Yicheng Pan, Ke Xu |  |
| 361 |  |  [Investigating the Emergent Audio Classification Ability of ASR Foundation Models](https://doi.org/10.18653/v1/2024.naacl-long.266) |  | 0 | Text and vision foundation models can perform many tasks in a zero-shot setting, a desirable property that enables these systems to be applied in general and low-resource settings. There has been far less work, however, on the zero-shot abilities of ASR foundation models, with these systems typically fine-tuned to specific tasks or constrained to applications that match their training criterion and data annotation. In this work we investigate the ability of... | Rao Ma, Adian Liusie, Mark J. F. Gales, Kate M. Knill |  |
| 362 |  |  [In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax](https://doi.org/10.18653/v1/2024.naacl-long.267) |  | 0 | In-context learning (ICL) is now a common method for teaching large language models (LLMs) new tasks: given labeled examples in the input context, the LLM learns to perform the task without weight updates. Do models guided via ICL infer the underlying structure of the task defined by the context, or do they rely on superficial heuristics that only generalize to identically distributed examples? We address this question using transformations tasks and an NLI... | Aaron Mueller, Albert Webson, Jackson Petty, Tal Linzen |  |
| 363 |  |  [Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt](https://doi.org/10.18653/v1/2024.naacl-long.268) |  | 0 | Recent singing-voice-synthesis (SVS) methods have achieved remarkable audio quality and naturalness, yet they lack the capability to control the style attributes of the synthesized singing explicitly. We propose Prompt-Singer, the first SVS method that enables attribute controlling on singer gender, vocal range and volume with natural language. We adopt a model architecture based on a decoder-only transformer with a multi-scale hierarchy, and design a... | Yongqi Wang, Ruofan Hu, Rongjie Huang, Zhiqing Hong, Ruiqi Li, Wenrui Liu, Fuming You, Tao Jin, Zhou Zhao |  |
| 364 |  |  [Lost in Transcription: Identifying and Quantifying the Accuracy Biases of Automatic Speech Recognition Systems Against Disfluent Speech](https://doi.org/10.18653/v1/2024.naacl-long.269) |  | 0 | Automatic speech recognition (ASR) systems, increasingly prevalent in education, healthcare, employment, and mobile technology, face significant challenges in inclusivity, particularly for the 80 million-strong global community of people who stutter. These systems often fail to accurately interpret speech patterns deviating from typical fluency, leading to critical usability issues and misinterpretations. This study evaluates six leading ASRs, analyzing their... | Dena F. Mujtaba, Nihar R. Mahapatra, Megan Arney, J. Scott Yaruss, Hope GerlachHouck, Caryn Herring, Jia Bin |  |
| 365 |  |  [MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and Classification](https://doi.org/10.18653/v1/2024.naacl-long.270) |  | 0 | We introduce MAFALDA, a benchmark for fallacy classification that merges and unites previous fallacy datasets. It comes with a taxonomy that aligns, refines, and unifies existing classifications of fallacies. We further provide a manual annotation of a part of the dataset together with manual explanations for each annotation. We propose a new annotation scheme tailored for subjective NLP tasks, and a new evaluation method designed to handle subjectivity. We... | Chadi Helwe, Tom Calamai, PierreHenri Paris, Chloé Clavel, Fabian M. Suchanek |  |
| 366 |  |  [Diffusion Glancing Transformer for Parallel Sequence-to-Sequence Learning](https://doi.org/10.18653/v1/2024.naacl-long.271) |  | 0 | Previously, non-autoregressive models were widely recognized as being superior in generation efficiency but inferior in generation quality due to the challenges of modeling multiple target modalities.To enhance the multi-modality modeling ability, we propose the diffusion glancing transformer, which employs a modality diffusion process and residual glancing sampling.The modality diffusion process is a discrete process that interpolates the multi-modal... | Lihua Qian, Mingxuan Wang, Yang Liu, Hao Zhou |  |
| 367 |  |  [No Context Needed: Contextual Quandary In Idiomatic Reasoning With Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.naacl-long.272) |  | 0 | Reasoning in the presence of idiomatic expressions (IEs) remains a challenging frontier in natural language understanding (NLU). Unlike standard text, the non-compositional nature of an IE makes it difficult for model comprehension, as their figurative or non-literal mean- ing usually cannot be inferred from the constituent words alone. It stands to reason that in these challenging circumstances, pre-trained language models (PTLMs) should make use of the... | Kellen Cheng, Suma Bhat |  |
| 368 |  |  [Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation](https://doi.org/10.18653/v1/2024.naacl-long.273) |  | 0 | The International Classification of Diseases (ICD) serves as a definitive medical classification system encompassing a wide range of diseases and conditions. The primary objective of ICD indexing is to allocate a subset of ICD codes to a medical record, which facilitates standardized documentation and management of various health conditions. Most existing approaches have suffered from selecting the proper label subsets from an extremely large ICD collection... | Xindi Wang, Robert E. Mercer, Frank Rudzicz |  |
| 369 |  |  [Anisotropy is Not Inherent to Transformers](https://doi.org/10.18653/v1/2024.naacl-long.274) |  | 0 | Isotropy is the property that embeddings are uniformly distributed around the origin. Previous work has shown that Transformer embedding spaces are anisotropic, which is called the representation degradation problem. This degradation has been assumed to be inherent to the standard language modeling tasks and to apply to all Transformer models regardless of their architecture. In this work we identify a set of Transformer models with isotropic embedding... | Anemily Machina, Robert E. Mercer |  |
| 370 |  |  [Finding Replicable Human Evaluations via Stable Ranking Probability](https://doi.org/10.18653/v1/2024.naacl-long.275) |  | 0 | Reliable human evaluation is critical to the development of successful natural language generation models, but achieving it is notoriously difficult. Stability is a crucial requirement when ranking systems by quality: consistent ranking of systems across repeated evaluations is not just desirable, but essential. Without it, there is no reliable foundation for hill-climbing or product launch decisions. In this paper, we use machine translation and its... | Parker Riley, Daniel Deutsch, George F. Foster, Viresh Ratnakar, Ali Dabirmoghaddam, Markus Freitag |  |
| 371 |  |  [Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections](https://doi.org/10.18653/v1/2024.naacl-long.276) |  | 0 | Recent developments in Large Language Models (LLMs) have manifested significant advancements. To facilitate safeguards against malicious exploitation, a body of research has concentrated on aligning LLMs with human preferences and inhibiting their generation of inappropriate content. Unfortunately, such alignments are often vulnerable: fine-tuning with a minimal amount of harmful data can easily unalign the target LLM. While being effective, such... | Yuanpu Cao, Bochuan Cao, Jinghui Chen |  |
| 372 |  |  [Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts](https://doi.org/10.18653/v1/2024.naacl-long.277) |  | 0 | Pretrained Language Models (PLMs) have advanced Natural Language Processing (NLP) tasks significantly, but finetuning PLMs on low-resource datasets poses significant challenges such as instability and overfitting. Previous methods tackle these issues by finetuning a strategically chosen subnetwork on a downstream task, while keeping the remaining weights fixed to the pretrained weights. However, they rely on a suboptimal criteria for sub-network selection,... | Sai Ashish Somayajula, Youwei Liang, Li Zhang, Abhishek Singh, Pengtao Xie |  |
| 373 |  |  [Detecting Bipolar Disorder from Misdiagnosed Major Depressive Disorder with Mood-Aware Multi-Task Learning](https://doi.org/10.18653/v1/2024.naacl-long.278) |  | 0 | Bipolar Disorder (BD) is a mental disorder characterized by intense mood swings, from depression to manic states. Individuals with BD are at a higher risk of suicide, but BD is often misdiagnosed as Major Depressive Disorder (MDD) due to shared symptoms, resulting in delays in appropriate treatment and increased suicide risk. While early intervention based on social media data has been explored to uncover latent BD risk, little attention has been paid to... | Daeun Lee, Hyolim Jeon, Sejung Son, Chaewon Park, Ji Hyun An, Seungbae Kim, Jinyoung Han |  |
| 374 |  |  [Leveraging Code to Improve In-Context Learning for Semantic Parsing](https://doi.org/10.18653/v1/2024.naacl-long.279) |  | 0 | In-context learning (ICL) is an appealing approach for semantic parsing due to its few-shot nature and improved generalization. However, learning to parse to rare domain-specific languages (DSLs) from just a few demonstrations is challenging, limiting the performance of even the most capable LLMs.In this work, we show how pre-existing coding abilities of LLMs can be leveraged for semantic parsing by (1) using general-purpose programming languages such as... | Ben Bogin, Shivanshu Gupta, Peter Clark, Ashish Sabharwal |  |
| 375 |  |  [Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER](https://doi.org/10.18653/v1/2024.naacl-long.280) |  | 0 | Adapting language models (LMs) to novel domains is often achieved through fine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning introduces new knowledge into an LM, enabling it to comprehend and efficiently perform a target domain task. Fine-tuning can however be inadvertently insensitive if it ignores the wide array of disparities (e.g in word meaning) between source and target domains. For instance, words such as chronic and pressure may... | Micheal Abaho, Danushka Bollegala, Gary Leeming, Dan W. Joyce, Iain E. Buchan |  |
| 376 |  |  [Language Models Implement Simple Word2Vec-style Vector Arithmetic](https://doi.org/10.18653/v1/2024.naacl-long.281) |  | 0 | A primary criticism towards language models (LMs) is their inscrutability. This paper presents evidence that, despite their size and complexity, LMs sometimes exploit a simple vector arithmetic style mechanism to solve some relational tasks using regularities encoded in the hidden space of the model (e.g., Poland:Warsaw::China:Beijing). We investigate a range of language model sizes (from 124M parameters to 176B parameters) in an in-context learning setting,... | Jack Merullo, Carsten Eickhoff, Ellie Pavlick |  |
| 377 |  |  [AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning](https://doi.org/10.18653/v1/2024.naacl-long.282) |  | 0 | Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless,... | Ruiyi Zhang, Rushi Qiang, Sai Ashish Somayajula, Pengtao Xie |  |
| 378 |  |  [SportQA: A Benchmark for Sports Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.283) |  | 0 | A deep understanding of sports, a field rich in strategic and dynamic content, is crucial for advancing Natural Language Processing (NLP). This holds particular significance in the context of evaluating and advancing Large Language Models (LLMs), given the existing gap in specialized benchmarks. To bridge this gap, we introduce SportQA, a novel benchmark specifically designed for evaluating LLMs in the context of sports understanding. SportQA encompasses over... | Haotian Xia, Zhengbang Yang, Yuqing Wang, Rhys Tracy, Yun Zhao, Dongdong Huang, Zezhi Chen, Yan Zhu, YuanFang Wang, Weining Shen |  |
| 379 |  |  [Revisiting subword tokenization: A case study on affixal negation in large language models](https://doi.org/10.18653/v1/2024.naacl-long.284) |  | 0 | In this work, we measure the impact of affixal negation on modern English large language models (LLMs). In affixal negation, the negated meaning is expressed through a negative morpheme, which is potentially challenging for LLMs as their tokenizers are often not morphologically plausible. We conduct extensive experiments using LLMs with different subword tokenization methods, which lead to several insights on the interaction between tokenization performance... | Thinh Truong, Yulia Otmakhova, Karin Verspoor, Trevor Cohn, Timothy Baldwin |  |
| 380 |  |  [Generating Mental Health Transcripts with SAPE (Spanish Adaptive Prompt Engineering)](https://doi.org/10.18653/v1/2024.naacl-long.285) |  | 0 | Large language models have become valuable tools for data augmentation in scenarios with limited data availability, as they can generate synthetic data resembling real-world data. However, their generative performance depends on the quality of the prompt used to instruct the model. Prompt engineering that relies on hand-crafted strategies or requires domain experts to adjust the prompt often yields suboptimal results. In this paper we present SAPE, a Spanish... | Daniel Cabrera Lozoya, Alejandro Berazaluce, Juan Perches, Eloy Lúa, Mike Conway, Simon D'Alfonso |  |
| 381 |  |  [Where are you from? Geolocating Speech and Applications to Language Identification](https://doi.org/10.18653/v1/2024.naacl-long.286) |  | 0 | We train models to answer the question, Where are you from? and show how such models can be repurposed for language identification (LID). To our knowledge, this paper is the first to introduce data sources, methods and models to tackle the task of geolocation of speech at a global scale, and the first to explore using geolocation as a proxy-task for LID. Specifically, we explore whether radio broadcasts with known origin can be used to train regression and... | Patrick Foley, Matthew Wiesner, Bismarck Odoom, Leibny Paola GarcíaPerera, Kenton Murray, Philipp Koehn |  |
| 382 |  |  [Teaching Language Models to Self-Improve through Interactive Demonstrations](https://doi.org/10.18653/v1/2024.naacl-long.287) |  | 0 | The self-improving ability of large language models (LLMs), enabled by prompting them to analyze and revise their own outputs, has garnered significant interest in recent research. However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones. To reduce this gap, we introduce TriPosT, a training algorithm that endows smaller... | Xiao Yu, Baolin Peng, Michel Galley, Jianfeng Gao, Zhou Yu |  |
| 383 |  |  [MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets](https://doi.org/10.18653/v1/2024.naacl-long.288) |  | 0 | Development of multimodal interactive systems is hindered by the lack of rich, multimodal (text, images) conversational data, which is needed in large quantities for LLMs. Previous approaches augment textual dialogues with retrieved images, posing privacy, diversity, and quality constraints. In this work, we introduce Multimodal Augmented Generative Images Dialogues (MAGID), a framework to augment text-only dialogues with diverse and high-quality images .... | Hossein Aboutalebi, Hwanjun Song, Yusheng Xie, Arshit Gupta, Lijia Sun, Hang Su, Igor Shalyminov, Nikolaos Pappas, Siffi Singh, Saab Mansour |  |
| 384 |  |  [Zero-shot Generative Linguistic Steganography](https://doi.org/10.18653/v1/2024.naacl-long.289) |  | 0 | Generative linguistic steganography attempts to hide secret messages into covertext. Previous studies have generally focused on the statistical differences between the covertext and stegotext, however, ill-formed stegotext can readily be identified by humans. In this paper, we propose a novel zero-shot approach based on in-context learning for linguistic steganography to achieve better perceptual and statistical imperceptibility. We also design several new... | Ke Lin, Yiyang Luo, Zijian Zhang, Ping Luo |  |
| 385 |  |  [Does GPT-4 pass the Turing test?](https://doi.org/10.18653/v1/2024.naacl-long.290) |  | 0 | We evaluated GPT-4 in a public online Turing test. The best-performing GPT-4 prompt passed in 49.7% of games, outperforming ELIZA (22%) and GPT-3.5 (20%), but falling short of the baseline set by human participants (66%). Participants’ decisions were based mainly on linguistic style (35%) and socioemotional traits (27%), supporting the idea that intelligence, narrowly conceived, is not sufficient to pass the Turing test. Participant knowledge about LLMs and... | Cameron R. Jones, Ben Bergen |  |
| 386 |  |  [Polarity Calibration for Opinion Summarization](https://doi.org/10.18653/v1/2024.naacl-long.291) |  | 0 | Opinion summarization is automatically generating summaries from a variety of subjective information, such as product reviews or political opinions. The challenge of opinions summarization lies in presenting divergent or even conflicting opinions. We conduct an analysis of previous summarization models, which reveals their inclination to amplify the polarity bias, emphasizing the majority opinions while ignoring the minority opinions. To address this issue... | Yuanyuan Lei, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Ruihong Huang, Dong Yu |  |
| 387 |  |  [Sentence-level Media Bias Analysis with Event Relation Graph](https://doi.org/10.18653/v1/2024.naacl-long.292) |  | 0 | Media outlets are becoming more partisan and polarized nowadays. In this paper, we identify media bias at the sentence level, and pinpoint bias sentences that intend to sway readers’ opinions. As bias sentences are often expressed in a neutral and factual way, considering broader context outside a sentence can help reveal the bias. In particular, we observe that events in a bias sentence need to be understood in associations with other events in the document.... | Yuanyuan Lei, Ruihong Huang |  |
| 388 |  |  [EMONA: Event-level Moral Opinions in News Articles](https://doi.org/10.18653/v1/2024.naacl-long.293) |  | 0 | Most previous research on moral frames has focused on social media short texts, little work has explored moral sentiment within news articles. In news articles, authors often express their opinions or political stance through moral judgment towards events, specifically whether the event is right or wrong according to social moral rules. This paper initiates a new task to understand moral opinions towards events in news articles. We have created a new dataset,... | Yuanyuan Lei, Md Messal Monem Miah, Ayesha Qamar, Sai Ramana Reddy, Jonathan Tong, Haotian Xu, Ruihong Huang |  |
| 389 |  |  [DLM: A Decoupled Learning Model for Long-tailed Polyphone Disambiguation in Mandarin](https://doi.org/10.18653/v1/2024.naacl-long.294) |  | 0 | Grapheme-to-phoneme conversion (G2P) is a critical component of the text-to-speech system (TTS), where polyphone disambiguation is the most crucial task. However, polyphone disambiguation datasets often suffer from the long-tail problem, and context learning for polyphonic characters commonly stems from a single dimension. In this paper, we propose a novel model DLM: a Decoupled Learning Model for long-tailed polyphone disambiguation in Mandarin. Firstly, DLM... | Beibei Gao, Yangsen Zhang, Ga Xiang, Yushan Jiang |  |
| 390 |  |  [You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments](https://doi.org/10.18653/v1/2024.naacl-long.295) |  | 0 | The versatility of Large Language Models (LLMs) on natural language understanding tasks has made them popular for research in social sciences. To properly understand the properties and innate personas of LLMs, researchers have performed studies that involve using prompts in the form of questions that ask LLMs about particular opinions. In this study, we take a cautionary step back and examine whether the current format of prompting LLMs elicits responses in a... | Bangzhao Shu, Lechen Zhang, Minje Choi, Lavinia Dunagan, Lajanugen Logeswaran, Moontae Lee, Dallas Card, David Jurgens |  |
| 391 |  |  [CASA: Causality-driven Argument Sufficiency Assessment](https://doi.org/10.18653/v1/2024.naacl-long.296) |  | 0 | The argument sufficiency assessment task aims to determine if the premises of a given argument support its conclusion.To tackle this task, existing works often train a classifier on data annotated by humans. However, annotating data is laborious, and annotations are often inconsistent due to subjective criteria. Motivated by the definition of probability of sufficiency (PS) in the causal literature, we proposeCASA, a zero-shot causality-driven argument... | Xiao Liu, Yansong Feng, KaiWei Chang |  |
| 392 |  |  [MacGyver: Are Large Language Models Creative Problem Solvers?](https://doi.org/10.18653/v1/2024.naacl-long.297) |  | 0 | We explore the creative problem-solving capabilities of modern LLMs in a novel constrained setting. To this end, we create MACGYVER, an automatically generated dataset consisting of over 1,600 real-world problems deliberately designed to trigger innovative usage of objects and necessitate out-of-the-box thinking. We then present our collection to both LLMs and humans to compare and contrast their problem-solving abilities. MACGYVER is challenging for both... | Yufei Tian, Abhilasha Ravichander, Lianhui Qin, Ronan Le Bras, Raja Marjieh, Nanyun Peng, Yejin Choi, Thomas L. Griffiths, Faeze Brahman |  |
| 393 |  |  [To Translate or Not to Translate: A Systematic Investigation of Translation-Based Cross-Lingual Transfer to Low-Resource Languages](https://doi.org/10.18653/v1/2024.naacl-long.298) |  | 0 | Perfect machine translation (MT) would render cross-lingual transfer (XLT) by means of multilingual language models (mLMs) superfluous. Given, on the one hand, the large body of work on improving XLT with mLMs and, on the other hand, recent advances in massively multilingual MT, in this work, we systematically evaluate existing and propose new translation-based XLT approaches for transfer to low-resource languages. We show that all translation-based... | Benedikt Ebing, Goran Glavas |  |
| 394 |  |  [Enhancing Large Language Models Against Inductive Instructions with Dual-critique Prompting](https://doi.org/10.18653/v1/2024.naacl-long.299) |  | 0 | Numerous works are proposed to align large language models (LLMs) with human intents to better fulfill instructions, ensuring they are trustful and helpful.Nevertheless, some human instructions are often malicious or misleading and following them will lead to untruthful and unsafe responses.Previous work rarely focused on understanding how LLMs manage instructions based on counterfactual premises, referred to here as inductive instructions, which may stem... | Rui Wang, Hongru Wang, Fei Mi, Boyang Xue, Yi Chen, KamFai Wong, Ruifeng Xu |  |
| 395 |  |  [GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer](https://doi.org/10.18653/v1/2024.naacl-long.300) |  | 0 | Named Entity Recognition (NER) is essential in various Natural Language Processing (NLP) applications. Traditional NER models are effective but limited to a set of predefined entity types. In contrast, Large Language Models (LLMs) can extract arbitrary entities through natural language instructions, offering greater flexibility. However, their size and cost, particularly for those accessed via APIs like ChatGPT, make them impractical in resource-limited... | Urchade Zaratiana, Nadi Tomeh, Pierre Holat, Thierry Charnois |  |
| 396 |  |  [XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.301) |  | 0 | Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This risk motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse to comply with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that... | Paul Röttger, Hannah Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, Dirk Hovy |  |
| 397 |  |  [Carpe diem: On the Evaluation of World Knowledge in Lifelong Language Models](https://doi.org/10.18653/v1/2024.naacl-long.302) |  | 0 | The dynamic nature of knowledge in an ever-changing world presents challenges for language models trained on static data; the model in the real world often requires not only acquiring new knowledge but also overwriting outdated information into updated ones. To study the ability of language models for these time-dependent dynamics in human language, we introduce a novel task, EvolvingQA, a temporally evolving question-answering benchmark designed for training... | Yujin Kim, Jaehong Yoon, Seonghyeon Ye, Sangmin Bae, Namgyu Ho, Sung Ju Hwang, SeYoung Yun |  |
| 398 |  |  [Fine-grained Gender Control in Machine Translation with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.303) |  | 0 | In machine translation, the problem of ambiguously gendered input has been pointed out, where the gender of an entity is not available in the source sentence. To address this ambiguity issue, the task of controlled translation that takes the gender of the ambiguous entity as additional input have been proposed. However, most existing works have only considered a simplified setup of one target gender for input. In this paper, we tackle controlled translation... | Minwoo Lee, Hyukhun Koh, Minsung Kim, Kyomin Jung |  |
| 399 |  |  [DialogVCS: Robust Natural Language Understanding in Dialogue System Upgrade](https://doi.org/10.18653/v1/2024.naacl-long.304) |  | 0 | In the constant updates of the product dialogue systems, we need to retrain the natural language understanding (NLU) model as new data from the real users would be merged into the existing data accumulated in the last updates. Within the newly added data, new intents would emerge and might have semantic entanglement with the existing intents, e.g. new intents that are semantically too specific or generic are actually a subset or superset of some existing... | Zefan Cai, Xin Zheng, Tianyu Liu, Haoran Meng, Jiaqi Han, Gang Yuan, Binghuai Lin, Baobao Chang, Yunbo Cao |  |
| 400 |  |  [LLatrieval: LLM-Verified Retrieval for Verifiable Generation](https://doi.org/10.18653/v1/2024.naacl-long.305) |  | 0 | Verifiable generation aims to let the large language model (LLM) generate text with supporting documents, which enables the user to flexibly verify the answer and makes the LLM’s output more reliable. Retrieval plays a crucial role in verifiable generation. Specifically, the retrieved documents not only supplement knowledge to help the LLM generate correct answers, but also serve as supporting evidence for the user to verify the LLM’s output. However, the... | Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin, Tianxiang Sun, Xipeng Qiu |  |
| 401 |  |  [Mapping Long-term Causalities in Psychiatric Symptomatology and Life Events from Social Media](https://doi.org/10.18653/v1/2024.naacl-long.306) |  | 0 | Social media is a valuable data source for exploring mental health issues. However, previous studies have predominantly focused on the semantic content of these posts, overlooking the importance of their temporal attributes, as well as the evolving nature of mental disorders and symptoms.In this paper, we study the causality between psychiatric symptoms and life events, as well as among different symptoms from social media posts, which leads to better... | Siyuan Chen, Meilin Wang, Minghao Lv, Zhiling Zhang, Juqianqian Juqianqian, Dejiyangla Dejiyangla, Yujia Peng, Kenny Q. Zhu, Mengyue Wu |  |
| 402 |  |  [Multimodal Chart Retrieval: A Comparison of Text, Table and Image Based Approaches](https://doi.org/10.18653/v1/2024.naacl-long.307) |  | 0 | We investigate multimodal chart retrieval, addressing the challenge of retrieving image-based charts using textual queries. We compare four approaches: (a) OCR with text retrieval, (b) chart derendering (DePlot) followed by table retrieval, (c) a direct image understanding model (PaLI-3), and (d) a combined PaLI-3 + DePlot approach. As the table retrieval component we introduce Tab-GTR, a text retrieval model augmented with table structure embeddings,... | Averi Nowak, Francesco Piccinno, Yasemin Altun |  |
| 403 |  |  [Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models](https://doi.org/10.18653/v1/2024.naacl-long.308) |  | 0 | While large language models (LMs) demonstrate remarkable performance, they encounter challenges in providing accurate responses when queried for information beyond their pre-trained memorization. Although augmenting them with relevant external information can mitigate these issues, failure to consider the necessity of retrieval may adversely affect overall performance. Previous research has primarily focused on examining how entities influence retrieval... | Seiji Maekawa, Hayate Iso, Sairam Gurajada, Nikita Bhutani |  |
| 404 |  |  [AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs](https://doi.org/10.18653/v1/2024.naacl-long.309) |  | 0 | In this work, we extend the instruction-tuned Llama-2 model with end-to-end general-purpose speech processing and reasoning abilities while maintaining the wide range of original LLM capabilities, without using any carefully curated paired data. The resulting end-to-end model, named AudioChatLlama, can utilize audio prompts as a replacement for text and sustain a conversation. Such a model also has extended cross-modal capabilities such as being able to... | Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Ke Li, Junteng Jia, Yuan Shangguan, Jay Mahadeokar, Ozlem Kalinli, Christian Fuegen, Mike Seltzer |  |
| 405 |  |  [Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness](https://doi.org/10.18653/v1/2024.naacl-long.310) |  | 0 | \*Do larger and more performant models resolve NLP’s longstanding robustness issues?\* We investigate this question using over 20 models of different sizes spanning different architectural choices and pretraining objectives. We conduct evaluations using (a) out-of-domain and challenge test sets, (b) behavioral testing with CheckLists, (c) contrast sets, and (d) adversarial inputs. Our analysis reveals that not all out-of-domain tests provide insight into... | Ashim Gupta, Rishanth Rajendhran, Nathan Stringham, Vivek Srikumar, Ana Marasovic |  |
| 406 |  |  [Sequential Compositional Generalization in Multimodal Models](https://doi.org/10.18653/v1/2024.naacl-long.311) |  | 0 | The rise of large-scale multimodal models has paved the pathway for groundbreaking advances in generative modeling and reasoning, unlocking transformative applications in a variety of complex tasks. However, a pressing question that remains is their genuine capability for stronger forms of generalization, which has been largely underexplored in the multimodal setting. Our study aims to address this by examining sequential compositional generalization using... | Semih Yagcioglu, Osman Batur Ince, Aykut Erdem, Erkut Erdem, Desmond Elliott, Deniz Yuret |  |
| 407 |  |  [Generating Uncontextualized and Contextualized Questions for Document-Level Event Argument Extraction](https://doi.org/10.18653/v1/2024.naacl-long.312) |  | 0 | This paper presents multiple question generation strategies for document-level event argument extraction. These strategies do not require human involvement and result in uncontextualized questions as well as contextualized questions grounded on the event and document of interest. Experimental results show that combining uncontextualized and contextualized questions is beneficial,especially when event triggers and arguments appear in different sentences. Our... | Md Nayem Uddin, Enfa Rose George, Eduardo Blanco, Steven R. Corman |  |
| 408 |  |  [Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation](https://doi.org/10.18653/v1/2024.naacl-long.313) |  | 0 | The proliferation of online misinformation has posed significant threats to public interest. While numerous online users actively participate in the combat against misinformation, many of such responses can be characterized by the lack of politeness and supporting facts. As a solution, text generation approaches are proposed to automatically produce counter-misinformation responses. Nevertheless, existing methods are often trained end-to-end without... | Zhenrui Yue, Huimin Zeng, Yimeng Lu, Lanyu Shang, Yang Zhang, Dong Wang |  |
| 409 |  |  [Open-Vocabulary Federated Learning with Multimodal Prototyping](https://doi.org/10.18653/v1/2024.naacl-long.314) |  | 0 | Existing federated learning (FL) studies usuallyassume the training label space and test labelspace are identical. However, in real-world applications, this assumption is too ideal to betrue. A new user could come up with queriesthat involve data from unseen classes, and suchopen-vocabulary queries would directly defectsuch FL systems. Therefore, in this work, weexplicitly focus on the under-explored openvocabulary challenge in FL. That is, for a newuser, the... | Huimin Zeng, Zhenrui Yue, Dong Wang |  |
| 410 |  |  [Exploring Key Point Analysis with Pairwise Generation and Graph Partitioning](https://doi.org/10.18653/v1/2024.naacl-long.315) |  | 0 | Key Point Analysis (KPA), the summarization of multiple arguments into a concise collection of key points, continues to be a significant and unresolved issue within the field of argument mining. Existing models adapt a two-stage pipeline of clustering arguments or generating key points for argument clusters. This approach rely on semantic similarity instead of measuring the existence of shared key points among arguments. Additionally, it only models the... | Xiao Li, Yong Jiang, Shen Huang, Pengjun Xie, Gong Cheng, Fei Huang |  |
| 411 |  |  [Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense](https://doi.org/10.18653/v1/2024.naacl-long.316) |  | 0 | Large language models (LLMs) have demonstrated substantial commonsense understanding through numerous benchmark evaluations. However, their understanding of cultural commonsense remains largely unexamined. In this paper, we conduct a comprehensive examination of the capabilities and limitations of several state-of-the-art LLMs in the context of cultural commonsense tasks. Using several general and cultural commonsense benchmarks, we find that (1) LLMs have a... | Siqi Shen, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Soujanya Poria, Rada Mihalcea |  |
| 412 |  |  [Code Models are Zero-shot Precondition Reasoners](https://doi.org/10.18653/v1/2024.naacl-long.317) |  | 0 | One of the fundamental skills required for an agent acting in an environment to complete tasks is the ability to understand what actions are plausible at any given point. This work explores a novel use of code representations to reason about action preconditions for sequential decision making tasks. Code representations offer the flexibility to model procedural activities and associated constraints as well as the ability to execute and verify constraint... | Lajanugen Logeswaran, Sungryull Sohn, Yiwei Lyu, Anthony Z. Liu, DongKi Kim, Dongsub Shim, Moontae Lee, Honglak Lee |  |
| 413 |  |  [Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding](https://doi.org/10.18653/v1/2024.naacl-long.318) |  | 0 | Recently, deep end-to-end learning has been studied for intent classification in Spoken Language Understanding (SLU). However, end-to-end models require a large amount of speech data with intent labels, and highly optimized models are generally sensitive to the inconsistency between the training and evaluation conditions. Therefore, a natural language understanding approach based on Automatic Speech Recognition (ASR) remains attractive because it can utilize... | Suyoung Kim, Jiyeon Hwang, HoYoung Jung |  |
| 414 |  |  [Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers](https://doi.org/10.18653/v1/2024.naacl-long.319) |  | 0 | The integration of Large Language Models (LLMs) in information retrieval has raised a critical reevaluation of fairness in the text-ranking models. LLMs, such as GPT models and Llama2, have shown effectiveness in natural language understanding tasks, and prior works such as RankGPT have demonstrated that the LLMs have better performance than the traditional ranking models in the ranking task. However, their fairness remains largely unexplored. This paper... | Yuan Wang, Xuyang Wu, HsinTai Wu, Zhiqiang Tao, Yi Fang |  |
| 415 |  |  [TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition](https://doi.org/10.18653/v1/2024.naacl-long.320) |  | 0 | Table reasoning is a challenging task that requires understanding both natural language questions and structured tabular data. Large language models (LLMs) have shown impressive capabilities in natural language understanding and generation, but they often struggle with large tables due to their limited input length. In this paper, we propose TabSQLify, a novel method that leverages text-to-SQL generation to decompose tables into smaller and relevant... | Md Mahadi Hasan Nahid, Davood Rafiei |  |
| 416 |  |  [Contextual Label Projection for Cross-Lingual Structured Prediction](https://doi.org/10.18653/v1/2024.naacl-long.321) |  | 0 | Label projection, which involves obtaining translated labels and texts jointly, is essential for leveraging machine translation to facilitate cross-lingual transfer in structured prediction tasks. Prior research exploring label projection often compromise translation accuracy by favoring simplified label translation or relying solely on word-level alignments. In this paper, we introduce a novel label projection approach, CLaP, which translates text to the... | Tanmay Parekh, IHung Hsu, KuanHao Huang, KaiWei Chang, Nanyun Peng |  |
| 417 |  |  [Event Detection from Social Media for Epidemic Prediction](https://doi.org/10.18653/v1/2024.naacl-long.322) |  | 0 | Social media is an easy-to-access platform providing timely updates about societal trends and events. Discussions regarding epidemic-related events such as infections, symptoms, and social interactions can be crucial for informing policymaking during epidemic outbreaks. In our work, we pioneer exploiting Event Detection (ED) for better preparedness and early warnings of any upcoming epidemic by developing a framework to extract and analyze epidemic-related... | Tanmay Parekh, Anh Mac, Jiarui Yu, Yuxuan Dong, Syed Shahriar, Bonnie Liu, Eric Yang, KuanHao Huang, Wei Wang, Nanyun Peng, KaiWei Chang |  |
| 418 |  |  [RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.323) |  | 0 | Chain-of-thought (CoT) has impressively unlocked the reasoning potential of large language models (LLMs). Yet, it falls short when tackling problems that require multiple reasoning steps. This limitation arises from the complex nature of multi-step reasoning processes: later stages often depend not only on the immediately preceding step, but also on the results from several steps earlier. Such complexities indicate the reasoning process is naturally a graph.... | Song Jiang, Zahra Shakeri, Aaron Chan, Maziar Sanjabi, Hamed Firooz, Yinglong Xia, Bugra Akyildiz, Yizhou Sun, Jinchao Li, Qifan Wang, Asli Celikyilmaz |  |
| 419 |  |  [BPE-knockout: Pruning Pre-existing BPE Tokenisers with Backwards-compatible Morphological Semi-supervision](https://doi.org/10.18653/v1/2024.naacl-long.324) |  | 0 | Byte-pair encoding (BPE) has become the default subword tokeniser in language models (LMs), allowing the representation of an infinite space of text with a finite set of units. Yet, BPE training is unsupervised, receiving no explicit information about a language’s morphology. This results in a subword vocabulary wherein many units are a concatenation of partial morphemes, preventing their formation as tokens. This, in turn, causes consistent intra-word... | Thomas Bauwens, Pieter Delobelle |  |
| 420 |  |  [How are Prompts Different in Terms of Sensitivity?](https://doi.org/10.18653/v1/2024.naacl-long.325) |  | 0 | In-context learning (ICL) has become one of the most popular learning paradigms. While there is a growing body of literature focusing on prompt engineering, there is a lack of systematic analysis comparing the effects of prompt techniques across different models and tasks. To address this, we present a comprehensive prompt analysis based on sensitivity. Our analysis reveals that sensitivity is an unsupervised proxy for model performance, as it exhibits a... | Sheng Lu, Hendrik Schuff, Iryna Gurevych |  |
| 421 |  |  [LSTDial: Enhancing Dialogue Generation via Long- and Short-Term Measurement Feedback](https://doi.org/10.18653/v1/2024.naacl-long.326) |  | 0 | Generating high-quality responses is a key challenge for any open domain dialogue systems. However, even though there exist a variety of quality dimensions especially designed for dialogue evaluation (e.g., coherence and diversity scores), current dialogue systems rarely utilize them to guide the response generation during training. To alleviate this issue, we propose LSTDial (Long- and Short-Term Dialogue), a novel two-stage framework which generates and... | Guanghui Ye, Huan Zhao, Zixing Zhang, Xupeng Zha, Zhihua Jiang |  |
| 422 |  |  [The ART of LLM Refinement: Ask, Refine, and Trust](https://doi.org/10.18653/v1/2024.naacl-long.327) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable generative abilities, but can they judge the quality of their own generations and self-improve?A popular concept, referred to as \*self-refinement\*, postulates that LLMs can detect and correct the errors in their generations when asked to do so. However, recent empirical evidence points in the opposite direction, suggesting that LLMs often struggle to accurately identify errors when reasoning is... | Kumar Shridhar, Koustuv Sinha, Andrew Cohen, Tianlu Wang, Ping Yu, Ramakanth Pasunuru, Mrinmaya Sachan, Jason Weston, Asli Celikyilmaz |  |
| 423 |  |  [Modularized Multilingual NMT with Fine-grained Interlingua](https://doi.org/10.18653/v1/2024.naacl-long.328) |  | 0 | Recently, one popular alternative in Multilingual NMT (MNMT) is modularized MNMT that has both language-specific encoders and decoders. However, due to the absence of layer-sharing, the modularized MNMT failed to produce satisfactory language-independent (Interlingua) features, leading to performance degradation in zero-shot translation. To address this issue, a solution was proposed to share the top of language-specific encoder layers, enabling the... | Sungjun Lim, Yoonjung Choi, Sangha Kim |  |
| 424 |  |  [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](https://doi.org/10.18653/v1/2024.naacl-long.329) |  | 0 | Analogy-making is central to human cognition, allowing us to adapt to novel situations – an ability that current AI systems still lack. Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small. We believe that this holds back progress in computational analogy.In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph... | Oren Sultan, Yonatan Bitton, Ron Yosef, Dafna Shahaf |  |
| 425 |  |  [AWESOME: GPU Memory-constrained Long Document Summarization using Memory Mechanism and Global Salient Content](https://doi.org/10.18653/v1/2024.naacl-long.330) |  | 0 | Long document summarization systems are critical for domains with lengthy and jargon-laden text, yet they present significant challenges to researchers and developers with limited computing resources. Existing solutions mainly focus on efficient attentions or divide-and-conquer strategies. The former reduces theoretical time complexity, but is still memory-heavy. The latter methods sacrifice global context, leading to uninformative and incoherent summaries.... | Shuyang Cao, Lu Wang |  |
| 426 |  |  [NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but Teaching the Distinction Helps](https://doi.org/10.18653/v1/2024.naacl-long.331) |  | 0 | The use of words to convey speaker’s intent is traditionally distinguished from the ‘mention’ of words for quoting what someone said, or pointing out properties of a word. Here we show that computationally modeling this use-mention distinction is crucial for dealing with counterspeech online. Counterspeech that refutes problematic content often mentions harmful language but is not harmful itself (e.g., calling a vaccine dangerous is not the same as expressing... | Kristina Gligoric, Myra Cheng, Lucia Zheng, Esin Durmus, Dan Jurafsky |  |
| 427 |  |  [Debiasing with Sufficient Projection: A General Theoretical Framework for Vector Representations](https://doi.org/10.18653/v1/2024.naacl-long.332) |  | 0 | Pre-trained vector representations in natural language processing often inadvertently encode undesirable social biases. Identifying and removing unwanted biased information from vector representation is an evolving and significant challenge. Our study uniquely addresses this issue from the perspective of statistical independence, proposing a framework for reducing bias by transforming vector representations to an unbiased subspace using sufficient projection.... | Enze Shi, Lei Ding, Linglong Kong, Bei Jiang |  |
| 428 |  |  [Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection](https://doi.org/10.18653/v1/2024.naacl-long.333) |  | 0 | Semi-supervised dialogue summarization (SSDS) leverages model-generated summaries to reduce reliance on human-labeled data and improve the performance of summarization models. While addressing label noise, previous works on semi-supervised learning primarily focus on natural language understanding tasks, assuming each sample has a unique label. However, these methods are not directly applicable to SSDS, as it is a generative task, and each dialogue can be... | Jianfeng He, Hang Su, Jason Cai, Igor Shalyminov, Hwanjun Song, Saab Mansour |  |
| 429 |  |  [AfriMTE and AfriCOMET: Enhancing COMET to Embrace Under-resourced African Languages](https://doi.org/10.18653/v1/2024.naacl-long.334) |  | 0 | Despite the recent progress on scaling multilingual machine translation (MT) to several under-resourced African languages, accurately measuring this progress remains challenging, since evaluation is often performed on n-gram matching metrics such as BLEU, which typically show a weaker correlation with human judgments. Learned metrics such as COMET have higher correlation; however, the lack of evaluation data with human ratings for under-resourced languages,... | Jiayi Wang, David Ifeoluwa Adelani, Sweta Agrawal, Marek Masiak, Ricardo Rei, Eleftheria Briakou, Marine Carpuat, Xuanli He, Sofia Bourhim, Andiswa Bukula, Muhidin Mohamed, Temitayo Olatoye, Tosin P. Adewumi, Hamam Mokayed, Christine Mwase, Wangui Kimotho, Foutse Yuehgoh, Anuoluwapo Aremu, Jessica Ojo, Shamsuddeen Hassan Muhammad, Salomey Osei, AbdulHakeem Omotayo, Chiamaka Chukwuneke, Perez Ogayo, Oumaima Hourrane, Salma El Anigri, Lolwethu Ndolela, Thabiso Mangwana, Shafie Abdi Mohamed, Ayinde Hassan, Oluwabusayo Olufunke Awoyomi, Lama Alkhaled, Sana Sabah AlAzzawi, Naome A. Etori, Millicent Ochieng, Clemencia Siro, Njoroge Kiragu, Eric Muchiri, Wangari Kimotho, Sakayo Toadoum Sari, Lyse Naomi Wamba Momo, Daud Abolade, Simbiat Ajao, Iyanuoluwa Shode, Ricky Macharm, Ruqayya Nasir Iro, Saheed S. Abdullahi, Stephen E. Moore, Bernard Opoku, Zainab Akinjobi, Afolabi Abeeb, Nnaemeka C. Obiefuna, Onyekachi Raphael Ogbu, Sam Ochieng', Verrah Otiende, Chinedu E. Mbonu, Yao Lu, Pontus Stenetorp |  |
| 430 |  |  [TableLlama: Towards Open Large Generalist Models for Tables](https://doi.org/10.18653/v1/2024.naacl-long.335) |  | 0 | Semi-structured tables are ubiquitous. There has been a variety of tasks that aim to automatically interpret, augment, and query tables. Current methods often require pretraining on tables or special model architecture design, are restricted to specific table types, or have simplifying assumptions about tables and tasks. This paper makes the first step towards developing open-source large language models (LLMs) as generalists for a diversity of table-based... | Tianshu Zhang, Xiang Yue, Yifei Li, Huan Sun |  |
| 431 |  |  [PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language Models](https://doi.org/10.18653/v1/2024.naacl-long.336) |  | 0 | Pre-trained language models (PLMs) show impressive performance in various downstream NLP tasks. However, pre-training large language models demands substantial memory and training compute. Furthermore, due to the substantial resources required, many PLM weights are confidential. Consequently, users are compelled to share their data with model owners for fine-tuning specific tasks. To overcome the limitations, we introduce Plug-in External Memory Adaptation... | HyunJin Kim, Young Jin Kim, JinYeong Bak |  |
| 432 |  |  [Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection](https://doi.org/10.18653/v1/2024.naacl-long.337) |  | 0 | Instruction-tuned Large Language Models (LLMs) have become a ubiquitous platform for open-ended applications due to their ability to modulate responses based on human instructions. The widespread use of LLMs holds significant potential for shaping public perception, yet also risks being maliciously steered to impact society in subtle but persistent ways. In this paper, we formalize such a steering risk with Virtual Prompt Injection (VPI) as a novel backdoor... | Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin |  |
| 433 |  |  [Exploring the Factual Consistency in Dialogue Comprehension of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.338) |  | 0 | LLMs (Large Language Models) usually interact with users in the form of dialogue and generate responses following their instructions, which naturally require dialogue comprehension abilities. However, dialogue comprehension is a general language ability which is hard to be evaluated directly. In this work, we propose to perform the evaluation focusing on the factual consistency issue with the help of the dialogue summarization task. Besides evaluating and... | Shuaijie She, Shujian Huang, Xingyun Wang, Yanke Zhou, Jiajun Chen |  |
| 434 |  |  [Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly](https://doi.org/10.18653/v1/2024.naacl-long.339) |  | 0 | Despite their strong ability to retrieve knowledge in English, current large language models show imbalance abilities in different languages. Two approaches are proposed to address this, i.e., multilingual pretraining and multilingual instruction tuning. However, whether and how do such methods contribute to the cross-lingual knowledge alignment inside the models is unknown. In this paper, we propose CLiKA, a systematic framework to assess the cross-lingual... | Changjiang Gao, Hongda Hu, Peng Hu, Jiajun Chen, Jixing Li, Shujian Huang |  |
| 435 |  |  [A Study on the Calibration of In-context Learning](https://doi.org/10.18653/v1/2024.naacl-long.340) |  | 0 | Accurate uncertainty quantification is crucial for the safe deployment of machine learning models, and prior research has demonstrated improvements in the calibration of modern language models (LMs). We study in-context learning (ICL), a prevalent method for adapting static LMs through tailored prompts, and examine the balance between performance and calibration across a broad spectrum of natural language understanding and reasoning tasks. Through... | Hanlin Zhang, Yifan Zhang, Yaodong Yu, Dhruv Madeka, Dean P. Foster, Eric P. Xing, Himabindu Lakkaraju, Sham M. Kakade |  |
| 436 |  |  [DialogBench: Evaluating LLMs as Human-like Dialogue Systems](https://doi.org/10.18653/v1/2024.naacl-long.341) |  | 0 | Large language models (LLMs) have achieved remarkable breakthroughs in new dialogue capabilities by leveraging instruction tuning,which refreshes human impressions of dialogue systems. The long-standing goal of dialogue systems is to be human-like enough to establish long-term connections with users. Therefore, there has been an urgent need to evaluate LLMs as human-like dialogue systems. In this paper, we propose DialogBench, a dialogue evaluation benchmark... | Jiao Ou, Junda Lu, Che Liu, Yihong Tang, Fuzheng Zhang, Di Zhang, Kun Gai |  |
| 437 |  |  [GINopic: Topic Modeling with Graph Isomorphism Network](https://doi.org/10.18653/v1/2024.naacl-long.342) |  | 0 | Topic modeling is a widely used approach for analyzing and exploring large document collections. Recent research efforts have incorporated pre-trained contextualized language models, such as BERT embeddings, into topic modeling. However, they often neglect the intrinsic informational value conveyed by mutual dependencies between words. In this study, we introduce GINopic, a topic modeling framework based on graph isomorphism networks to capture the... | Suman Adhya, Debarshi Kumar Sanyal |  |
| 438 |  |  [CMB: A Comprehensive Medical Benchmark in Chinese](https://doi.org/10.18653/v1/2024.naacl-long.343) |  | 0 | Large Language Models (LLMs) provide a possibility to make a great breakthrough in medicine. The establishment of a standardized medical benchmark becomes a fundamental cornerstone to measure progression. However, medical environments in different regions have their local characteristics, e.g., the ubiquity and significance of traditional Chinese medicine within China. Therefore, merely translating English-based medical evaluation may result in contextual... | Xidong Wang, Guiming Chen, Dingjie Song, Zhiyi Zhang, Zhihong Chen, Qingying Xiao, Junying Chen, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, Haizhou Li |  |
| 439 |  |  [Massive End-to-end Speech Recognition Models with Time Reduction](https://doi.org/10.18653/v1/2024.naacl-long.344) |  | 0 | We investigate massive end-to-end automatic speech recognition (ASR) models with efficiency improvements achieved by time reduction. The encoders of our models use the neural architecture of Google’s universal speech model (USM), with additional funnel pooling layers to significantly reduce the frame rate and speed up training and inference. We also explore a few practical methods to mitigate potential accuracy loss due to time reduction, while enjoying most... | Weiran Wang, Rohit Prabhavalkar, Haozhe Shan, Zhong Meng, Dongseong Hwang, Qiujia Li, Khe Chai Sim, Bo Li, James Qin, Xingyu Cai, Adam Stooke, Chengjian Zheng, Yanzhang He, Tara N. Sainath, Pedro Moreno Mengibar |  |
| 440 |  |  [SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics](https://doi.org/10.18653/v1/2024.naacl-long.345) |  | 0 | Transformer-based models, such as BERT and ViT, have achieved state-of-the-art results across different natural language processing (NLP) and computer vision (CV) tasks. However, these models are extremely memory intensive during their fine-tuning process, making them difficult to deploy on GPUs with limited memory resources. To address this issue, we introduce a new tool called SlimFit that reduces the memory requirements of these models by dynamically... | Arash Ardakani, Altan Haan, Shangyin Tan, DoruThom Popovici, Alvin Cheung, Costin Iancu, Koushik Sen |  |
| 441 |  |  [Effective Large Language Model Adaptation for Improved Grounding and Citation Generation](https://doi.org/10.18653/v1/2024.naacl-long.346) |  | 0 | Large language models (LLMs) have achieved remarkable advancements in natural language understanding and generation. However, one major issue towards their widespread deployment in the real world is that they can generate “hallucinated” answers that are not factual.Towards this end, this paper focuses on improving LLMs by grounding their responses in retrieved passages and by providing citations. We propose a new framework, AGREE, Adaptation for GRounding... | Xi Ye, Ruoxi Sun, Sercan Ö. Arik, Tomas Pfister |  |
| 442 |  |  [Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.347) |  | 0 | We study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages. This underexplored problem poses new challenges at the pre-writing stage, including how to research the topic and prepare an outline prior to writing. We propose STORM, a writing system for the Synthesis of Topic Outlines throughRetrieval and Multi-perspective Question Asking. STORM models the... | Yijia Shao, Yucheng Jiang, Theodore A. Kanell, Peter Xu, Omar Khattab, Monica S. Lam |  |
| 443 |  |  [Grounding Gaps in Language Model Generations](https://doi.org/10.18653/v1/2024.naacl-long.348) |  | 0 | Effective conversation requires common ground: a shared understanding between the participants. Common ground, however, does not emerge spontaneously in conversation. Speakers and listeners work together to both identify and construct a shared basis while avoiding misunderstanding. To accomplish grounding, humans rely on a range of dialogue acts, like clarification (What do you mean?) and acknowledgment (I understand.). However, it is unclear whether large... | Omar Shaikh, Kristina Gligoric, Ashna Khetan, Matthias Gerstgrasser, Diyi Yang, Dan Jurafsky |  |
| 444 |  |  [When Does Monolingual Data Help Multilingual Translation: The Role of Domain and Model Scale](https://doi.org/10.18653/v1/2024.naacl-long.349) |  | 0 | Multilingual machine translation (MMT), trained on a mixture of parallel and monolingual data, is key for improving translation in low-resource language pairs. However, the literature offers conflicting results on the performance of different methods of including monolingual data. To resolve this, we examine how denoising autoencoding (DAE) and backtranslation (BT) impact MMT under different data conditions and model scales. Unlike prior studies, we use a... | Christos Baziotis, Biao Zhang, Alexandra Birch, Barry Haddow |  |
| 445 |  |  [ContraSim - Analyzing Neural Representations Based on Contrastive Learning](https://doi.org/10.18653/v1/2024.naacl-long.350) |  | 0 | Recent work has compared neural network representations via similarity-based analyses to improve model interpretation. The quality of a similarity measure is typically evaluated by its success in assigning a high score to representations that are expected to be matched. However, existing similarity measures perform mediocrely on standard benchmarks. In this work, we develop a new similarity measure, dubbed ContraSim, based on contrastive learning. In contrast... | Adir Rahamim, Yonatan Belinkov |  |
| 446 |  |  [Universal Prompt Optimizer for Safe Text-to-Image Generation](https://doi.org/10.18653/v1/2024.naacl-long.351) |  | 0 | Text-to-Image (T2I) models have shown great performance in generating images based on textual prompts. However, these models are vulnerable to unsafe input to generate unsafe content like sexual, harassment and illegal-activity images. Existing studies based on image checker, model fine-tuning and embedding blocking are impractical in real-world applications. Hence, we propose the first universal \*\*p\*\*rompt \*\*o\*\*ptimizer for \*\*s\*\*afe T2\*\*I\*\*... | Zongyu Wu, Hongcheng Gao, Yueze Wang, Xiang Zhang, Suhang Wang |  |
| 447 |  |  [Language Model Based Unsupervised Dependency Parsing with Conditional Mutual Information and Grammatical Constraints](https://doi.org/10.18653/v1/2024.naacl-long.352) |  | 0 | Previous methods based on Large Language Models (LLM) perform unsupervised dependency parsing by maximizing bi-lexical dependence scores. However, these previous methods adopt dependence scores that are difficult to interpret. These methods cannot incorporate grammatical constraints that previous grammar-based parsing research has shown beneficial to improving parsing performance. In this work, we apply Conditional Mutual Information (CMI), an interpretable... | Junjie Chen, Xiangheng He, Yusuke Miyao |  |
| 448 |  |  [The Bias Amplification Paradox in Text-to-Image Generation](https://doi.org/10.18653/v1/2024.naacl-long.353) |  | 0 | Bias amplification is a phenomenon in which models exacerbate biases or stereotypes present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stable Diffusion by comparing gender ratios in training vs. generated images. We find that the model appears to amplify gender-occupation biases found in the training data (LAION) considerably. However, we discover that amplification can be largely attributed to... | Preethi Seshadri, Sameer Singh, Yanai Elazar |  |
| 449 |  |  [Grammar-based Data Augmentation for Low-Resource Languages: The Case of Guarani-Spanish Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.354) |  | 0 | One of the main problems low-resource languages face in NLP can be pictured as a vicious circle: data is needed to build and test tools, but the available text is scarce and there are not powerful tools to collect it.In order to break this circle for Guarani, we explore if text automatically generated from a grammar can work as a Data Augmentation technique to boost the performance of Guarani-Spanish Machine Translation (MT) systems.After building a... | Agustín Lucas, Alexis Baladón, Victoria Pardiñas, Marvin M. AgüeroTorales, Santiago Góngora, Luis Chiruzzo |  |
| 450 |  |  [Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.355) |  | 0 | Exploring the intersection of language and culture in Large Language Models (LLMs), this study critically examines their capability to encapsulate cultural nuances across diverse linguistic landscapes. Central to our investigation are three research questions: the efficacy of language-specific instruction tuning, the impact of pretraining on dominant language data, and the identification of optimal approaches to elicit accurate cultural knowledge from LLMs.... | Anjishnu Mukherjee, Aylin Caliskan, Ziwei Zhu, Antonios Anastasopoulos |  |
| 451 |  |  [Toward Interactive Regional Understanding in Vision-Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.356) |  | 0 | Recent Vision-Language Pre-training (VLP) models have demonstrated significant advancements. Nevertheless, these models heavily rely on image-text pairs that capture only coarse and global information of an image, leading to a limitation in their regional understanding ability. In this work, we introduce RegionVLM, equipped with explicit regional modeling capabilities, allowing them to understand user-indicated image regions. To achieve this, we design a... | Jungbeom Lee, Sanghyuk Chun, Sangdoo Yun |  |
| 452 |  |  [ScriptMix: Mixing Scripts for Low-resource Language Parsing](https://doi.org/10.18653/v1/2024.naacl-long.357) |  | 0 | Despite the success of multilingual pretrained language models (mPLMs) for tasks such as dependency parsing (DEP) or part-of-speech (POS) tagging, their coverage of 100s of languages is still limited, as most of the 6500+ languages remains “unseen”. To adapt mPLMs for including such unseen langs, existing work has considered transliteration and vocabulary augmentation. Meanwhile, the consideration of combining the two has been surprisingly lacking. To... | Jaeseong Lee, Dohyeon Lee, Seungwon Hwang |  |
| 453 |  |  [MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.358) |  | 0 | Large Language Models (LLM) have demonstrated their strong ability in the field of machine translation, yet they suffer from high computational cost and latency. Therefore, transferring translation knowledge from giant LLMs to medium-sized machine translation models is a promising research direction. However, traditional knowledge distillation methods ignore the capability of student and teacher models, therefore repeatedly teaching student models on the... | Jiahuan Li, Shanbo Cheng, Shujian Huang, Jiajun Chen |  |
| 454 |  |  [ToXCL: A Unified Framework for Toxic Speech Detection and Explanation](https://doi.org/10.18653/v1/2024.naacl-long.359) |  | 0 | The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly... | Nhat M. Hoang, Xuan Long Do, Duc Anh Do, Duc Anh Vu, Anh Tuan Luu |  |
| 455 |  |  [LinkPrompt: Natural and Universal Adversarial Attacks on Prompt-based Language Models](https://doi.org/10.18653/v1/2024.naacl-long.360) |  | 0 | Prompt-based learning is a new language model training paradigm that adapts the Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes the performance benchmarks across various natural language processing (NLP) tasks. Instead of using a fixed prompt template to fine-tune the model, some research demonstrates the effectiveness of searching for the prompt via optimization. Such prompt optimization process of prompt-based learning on PLMs also... | Yue Xu, Wenjie Wang |  |
| 456 |  |  [CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions](https://doi.org/10.18653/v1/2024.naacl-long.361) |  | 0 | Recently, Large Language Models (LLMs) have been demonstrated to possess impressive capabilities in a variety of domains and tasks. We investigate the issue of prompt design in the multi-turn text-to-SQL task and attempt to enhance the LLMs’ reasoning capacity when generating SQL queries. In the conversational context, the current SQL query can be modified from the preceding SQL query with only a few operations due to the context dependency. We introduce our... | Hanchong Zhang, Ruisheng Cao, Hongshen Xu, Lu Chen, Kai Yu |  |
| 457 |  |  [ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.362) |  | 0 | In recent times, large language models (LLMs) have shown impressive performance on various document-level tasks such as document classification, summarization, and question-answering. However, research on understanding their capabilities on the task of self-contradictions in long documents has been very limited. In this work, we introduce ContraDoc, the first human-annotated dataset to study self-contradictions in long documents across multiple domains,... | Jierui Li, Vipul Raheja, Dhruv Kumar |  |
| 458 |  |  [Entity Disambiguation via Fusion Entity Decoding](https://doi.org/10.18653/v1/2024.naacl-long.363) |  | 0 | Entity disambiguation (ED), which links the mentions of ambiguous entities to their referent entities in a knowledge base, serves as a core component in entity linking (EL). Existing generative approaches demonstrate improved accuracy compared to classification approaches under the standardized ZELDA benchmark. Nevertheless, generative approaches suffer from the need for large-scale pre-training and inefficient generation. Most importantly, entity... | Junxiong Wang, Ali Mousavi, Omar Attia, Ronak Pradeep, Saloni Potdar, Alexander M. Rush, Umar Farooq Minhas, Yunyao Li |  |
| 459 |  |  [PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers](https://doi.org/10.18653/v1/2024.naacl-long.364) |  | 0 | In this paper, we conduct a study to utilize LLMs as a solution for decision making that requires complex data analysis. We define \*\*Decision QA\*\* as the task of answering the best decision, dbest, for a decision-making question Q, business rules R and a database D. Since there is no benchmark that can examine Decision QA, we propose Decision QA benchmark, \*\*DQA\*\*. It has two scenarios, Locating and Building, constructed from two video games (Europa... | Myeonghwa Lee, Seonho An, MinSoo Kim |  |
| 460 |  |  [GPTScore: Evaluate as You Desire](https://doi.org/10.18653/v1/2024.naacl-long.365) |  | 0 | Generative Artificial Intelligence (AI) has enabled the development of sophisticated models that are capable of producing high-caliber text, images, and other outputs through the utilization of large pre-trained models.Nevertheless, assessing the quality of the generation is an even more arduous task than the generation itself, and this issue has not been given adequate consideration recently.This paper proposes a novel evaluation framework, GPTScore, which... | Jinlan Fu, SeeKiong Ng, Zhengbao Jiang, Pengfei Liu |  |
| 461 |  |  [A Survey of Confidence Estimation and Calibration in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.366) |  | 0 | Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no... | Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, Iryna Gurevych |  |
| 462 |  |  [Not All Metrics Are Guilty: Improving NLG Evaluation by Diversifying References](https://doi.org/10.18653/v1/2024.naacl-long.367) |  | 0 | Most research about natural language generation (NLG) relies on evaluation benchmarks with limited references for a sample, which may result in poor correlations with human judgements. The underlying reason is that one semantic meaning can actually be expressed in different forms, and the evaluation with a single or few references may not accurately reflect the quality of the model’s hypotheses. To address this issue, this paper presents a simple and... | Tianyi Tang, Hongyuan Lu, Yuchen Jiang, Haoyang Huang, Dongdong Zhang, Wayne Xin Zhao, Tom Kocmi, Furu Wei |  |
| 463 |  |  [Separation and Fusion: A Novel Multiple Token Linking Model for Event Argument Extraction](https://doi.org/10.18653/v1/2024.naacl-long.368) |  | 0 | In event argument extraction (EAE), a promising approach involves jointly encoding text and argument roles, and performing multiple token linking operations. This approach further falls into two categories. One extracts arguments within a single event, while the other attempts to extract arguments from multiple events simultaneously. However, the former lacks to leverage cross-event information and the latter requires tougher predictions with longer encoded... | Jing Xu, Dandan Song, Siu Hui, Zhijing Wu, Meihuizi Jia, Hao Wang, Yanru Zhou, Changzhi Zhou, Ziyi Yang |  |
| 464 |  |  [The Integration of Semantic and Structural Knowledge in Knowledge Graph Entity Typing](https://doi.org/10.18653/v1/2024.naacl-long.369) |  | 0 | The Knowledge Graph Entity Typing (KGET) task aims to predict missing type annotations for entities in knowledge graphs. Recent works only utilize the structural knowledge in the local neighborhood of entities, disregarding semantic knowledge in the textual representations of entities, relations, and types that are also crucial for type inference. Additionally, we observe that the interaction between semantic and structural knowledge can be utilized to... | Muzhi Li, Minda Hu, Irwin King, Hofung Leung |  |
| 465 |  |  [ComCLIP: Training-Free Compositional Image and Text Matching](https://doi.org/10.18653/v1/2024.naacl-long.370) |  | 0 | Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-language pretrained models like CLIP to compositional image and text matching — a more challenging image and text matching task requiring the model’s understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text... | Kenan Jiang, Xuehai He, Ruize Xu, Xin Wang |  |
| 466 |  |  [ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications](https://doi.org/10.18653/v1/2024.naacl-long.371) |  | 0 | Extensive efforts in the past have been directed toward the development of summarization datasets. However, a predominant number of these resources have been (semi)-automatically generated, typically through web data crawling. This resulted in subpar resources for training and evaluating summarization systems, a quality compromise that is arguably due to the substantial costs associated with generating ground-truth summaries, particularly for diverse... | Sotaro Takeshita, Tommaso Green, Ines Reinig, Kai Eckert, Simone Paolo Ponzetto |  |
| 467 |  |  [XAL: EXplainable Active Learning Makes Classifiers Better Low-resource Learners](https://doi.org/10.18653/v1/2024.naacl-long.372) |  | 0 | Active learning (AL), which aims to construct an effective training set by iteratively curating the most formative unlabeled data for annotation, has been widely used in low-resource tasks. Most active learning techniques in classification rely on the model’s uncertainty or disagreement to choose unlabeled data, suffering from the problem of over-confidence in superficial patterns and a lack of exploration.Inspired by the cognitive processes in which humans... | Yun Luo, Zhen Yang, Fandong Meng, Yingjie Li, Fang Guo, Qinglin Qi, Jie Zhou, Yue Zhang |  |
| 468 |  |  [LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?](https://doi.org/10.18653/v1/2024.naacl-long.373) |  | 0 | Diffusion models have exhibited remarkable capabilities in text-to-image generation. However, their performance in image-to-text generation, specifically image captioning, has lagged behind Auto-Regressive (AR) models, casting doubt on their applicability for such tasks. In this work, we revisit diffusion models, highlighting their capacity for holistic context modeling and parallel decoding. With these benefits, diffusion models can alleviate the inherent... | Yuchi Wang, Shuhuai Ren, Rundong Gao, Linli Yao, Qingyan Guo, Kaikai An, Jianhong Bai, Xu Sun |  |
| 469 |  |  [Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF](https://doi.org/10.18653/v1/2024.naacl-long.374) |  | 0 | Counterspeech, defined as a response to mitigate online hate speech, is increasingly used as a non-censorial solution. The effectiveness of addressing hate speech involves dispelling the stereotypes, prejudices, and biases often subtly implied in brief, single-sentence statements or abuses. These expressions challenge language models, especially in seq2seq tasks, as model performance typically excels with longer contexts. Our study introduces CoARL, a novel... | Amey Hengle, Aswini Kumar, Sahajpreet Singh, Anil Bandhakavi, Md. Shad Akhtar, Tanmoy Chakraborty |  |
| 470 |  |  [Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey](https://doi.org/10.18653/v1/2024.naacl-long.375) |  | 0 | Large Language Models (LLMs) are now commonplace in conversation applications. However, their risks of misuse for generating harmful responses have raised serious societal concerns and spurred recent research on LLM conversation safety. Therefore, in this survey, we provide a comprehensive overview of recent studies, covering three critical aspects of LLM conversation safety: attacks, defenses, and evaluations. Our goal is to provide a structured summary that... | Zhichen Dong, Zhanhui Zhou, Chao Yang, Jing Shao, Yu Qiao |  |
| 471 |  |  [Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.376) |  | 0 | Large language models (LLMs) have achieved remarkable advancements in natural language processing. However, the massive scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained environments. While techniques such as chain-of-thought (CoT) distillation have displayed promise in distilling LLMs into small language models (SLMs), there is a risk that distilled SLMs may still... | Weize Liu, Guocong Li, Kai Zhang, Bang Du, Qiyuan Chen, Xuming Hu, Hongxia Xu, Jintai Chen, Jian Wu |  |
| 472 |  |  [Divergent Token Metrics: Measuring degradation to prune away LLM components - and optimize quantization](https://doi.org/10.18653/v1/2024.naacl-long.377) |  | 0 | Large Language Models (LLMs) have reshaped natural language processing with their impressive capabilities. However, their ever-increasing size has raised concerns about their effective deployment and the need for LLM compression. This study introduces the Divergent Token Metrics (DTMs), a novel approach to assessing compressed LLMs, addressing the limitations of traditional perplexity or accuracy measures that fail to accurately reflect text generation... | Björn Deiseroth, Max Meuer, Nikolas Gritsch, Constantin Eichenberg, Patrick Schramowski, Matthias Aßenmacher, Kristian Kersting |  |
| 473 |  |  [Beyond Performance: Quantifying and Mitigating Label Bias in LLMs](https://doi.org/10.18653/v1/2024.naacl-long.378) |  | 0 | Large language models (LLMs) have shown remarkable adaptability to diverse tasks, by leveraging context prompts containing instructions, or minimal input-output examples. However, recent work revealed they also exhibit \*label bias\*—an undesirable preference toward predicting certain answers over others. Still, detecting and measuring this bias reliably and at scale has remained relatively unexplored. In this study, we evaluate different approaches to... | Yuval Reif, Roy Schwartz |  |
| 474 |  |  [Instructing Large Language Models to Identify and Ignore Irrelevant Conditions](https://doi.org/10.18653/v1/2024.naacl-long.379) |  | 0 | Math word problem (MWP) solving requires generating a reasoning path based on a given problem description that often contains irrelevant conditions.Existing chain-of-thought (CoT) prompting methods elicited multi-step reasoning abilities of large language models (LLMs) to solve MWPs.However, they were seriously confused by the irrelevant conditions, resulting in low accuracy.In this paper, we propose a novel approach named I3C that instructs LLMs to identify... | Zhenyu Wu, Chao Shen, Meng Jiang |  |
| 475 |  |  [Lower Bounds on the Expressivity of Recurrent Neural Language Models](https://doi.org/10.18653/v1/2024.naacl-long.380) |  | 0 | The recent successes and spread of large neural language models (LMs) call for a thorough understanding of their abilities. Describing their abilities through LMs’ representational capacity is a lively area of research. Investigations of the representational capacity of neural LMs have predominantly focused on their ability to recognize formal languages. For example, recurrent neural networks (RNNs) as classifiers are tightly linked to regular languages,... | Anej Svete, Franz Nowak, Anisha Mohamed Sahabdeen, Ryan Cotterell |  |
| 476 |  |  [Transformers Can Represent n-gram Language Models](https://doi.org/10.18653/v1/2024.naacl-long.381) |  | 0 | Plenty of existing work has analyzed the abilities of the transformer architecture by describing its representational capacity with formal models of computation. However, the focus so far has been on analyzing the architecture in terms of language acceptance. We contend that this is an ill-suited problem in the study of language models (LMs), which are definitionally probability distributions over strings. In this paper, we focus on the relationship between... | Anej Svete, Ryan Cotterell |  |
| 477 |  |  [The Role of n-gram Smoothing in the Age of Neural Networks](https://doi.org/10.18653/v1/2024.naacl-long.382) |  | 0 | For nearly three decades, language models derived from the n-gram assumption held the state of the art on the task. The key to their success lay in the application of various smoothing techniques that served to combat overfitting. However, when neural language models toppled n-gram models as the best performers, n-gram smoothing techniques became less relevant. Indeed, it would hardly be an understatement to suggest that the line of inquiry into n-gram... | Luca Malagutti, Andrius Buinovskij, Anej Svete, Clara Meister, Afra Amini, Ryan Cotterell |  |
| 478 |  |  [Reliability Estimation of News Media Sources: Birds of a Feather Flock Together](https://doi.org/10.18653/v1/2024.naacl-long.383) |  | 0 | Evaluating the reliability of news sources is a routine task for journalists and organizations committed to acquiring and disseminating accurate information.Recent research has shown that predicting sources’ reliability represents an important first-prior step in addressing additional challenges such as fake news detection and fact-checking.In this paper, we introduce a novel approach for source reliability estimation that leverages reinforcement learning... | Sergio Burdisso, Dairazalia SanchezCortes, Esaú VillatoroTello, Petr Motlícek |  |
| 479 |  |  [On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons](https://doi.org/10.18653/v1/2024.naacl-long.384) |  | 0 | Current decoder-based pre-trained language models (PLMs) successfully demonstrate multilingual capabilities. However, it is unclear how these models handle multilingualism.We analyze the neuron-level internal behavior of multilingual decoder-based PLMs, Specifically examining the existence of neurons that fire “uniquely for each language” within decoder-only multilingual PLMs.We analyze six languages: English, German, French, Spanish, Chinese, and Japanese,... | Takeshi Kojima, Itsuki Okimura, Yusuke Iwasawa, Hitomi Yanaka, Yutaka Matsuo |  |
| 480 |  |  [NLP Progress in Indigenous Latin American Languages](https://doi.org/10.18653/v1/2024.naacl-long.385) |  | 0 | The paper focuses on the marginalization of indigenous language communities in the face of rapid technological advancements. We highlight the cultural richness of these languages and the risk they face of being overlooked in the realm of Natural Language Processing (NLP). We aim to bridge the gap between these communities and researchers, emphasizing the need for inclusive technological advancements that respect indigenous community perspectives. We show the... | Atnafu Lambebo Tonja, Fazlourrahman Balouchzahi, Sabur Butt, Olga Kolesnikova, Hector G. Ceballos, Alexander F. Gelbukh, Thamar Solorio |  |
| 481 |  |  [On the Effectiveness of Adversarial Robustness for Abuse Mitigation with Counterspeech](https://doi.org/10.18653/v1/2024.naacl-long.386) |  | 0 | Recent work on automated approaches to counterspeech have mostly focused on synthetic data but seldom look into how the public deals with abuse. While these systems identifying and generating counterspeech have the potential for abuse mitigation, it remains unclear how robust a model is against adversarial attacks across multiple domains and how models trained on synthetic data can handle unseen user-generated abusive content in the real world. To tackle... | YiLing Chung, Jonathan Bright |  |
| 482 |  |  [Leveraging the Structure of Pre-trained Embeddings to Minimize Annotation Effort](https://doi.org/10.18653/v1/2024.naacl-long.387) |  | 0 | Most current state-of-the-art approaches for text classification are based on fine-tuning the representations computed by large language models (LLMs). This strategy has led to significant improvements in classification performance and contributed to a reduction of the amount of labeled data required for training a model. However, for some challenging classification tasks, providing enough annotations to ensure a reliable classification continues to be the... | César GonzálezGutiérrez, Ariadna Quattoni |  |
| 483 |  |  [UniArk: Improving Generalisation and Consistency for Factual Knowledge Extraction through Debiasing](https://doi.org/10.18653/v1/2024.naacl-long.388) |  | 0 | Several recent papers have investigated the potential of language models as knowledge bases as well as the existence of severe biases when extracting factual knowledge. In this work, we focus on the factual probing performance over unseen prompts from tuning, and using a probabilistic view we show the inherent misalignment between pre-training and downstream tuning objectives in language models for probing knowledge. We hypothesize that simultaneously... | Yijun Yang, Jie He, Pinzhen Chen, Víctor GutiérrezBasulto, Jeff Z. Pan |  |
| 484 |  |  [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://doi.org/10.18653/v1/2024.naacl-long.389) |  | 0 | Retrieval-Augmented Large Language Models (LLMs), which incorporate the non-parametric knowledge from external knowledge bases into LLMs, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering (QA). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address... | Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, Jong Park |  |
| 485 |  |  [Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method](https://doi.org/10.18653/v1/2024.naacl-long.390) |  | 0 | Large Language Models (LLMs) have shown great potential in Natural Language Processing (NLP) tasks.However, recent literature reveals that LLMs hallucinate intermittently, which impedes their reliability for further utilization. In this paper, we propose a novel self-detection method to detect which questions an LLM does not know.Our proposal is empirical and applicable for continually upgrading LLMs compared with state-of-the-art methods. Specifically, we... | Yukun Zhao, Lingyong Yan, Weiwei Sun, Guoliang Xing, Chong Meng, Shuaiqiang Wang, Zhicong Cheng, Zhaochun Ren, Dawei Yin |  |
| 486 |  |  [Are Large Language Model Temporally Grounded?](https://doi.org/10.18653/v1/2024.naacl-long.391) |  | 0 | Are Large Language Models (LLMs) temporally grounded? Since LLMs cannot perceive and interact with the environment, it is impossible to answer this question directly. Instead, we provide LLMs with textual narratives and probe them with respect to their common-sense knowledge of the structure and duration of events, their ability to order events along a timeline, and self-consistency within their temporal model (e.g., temporal relations such as after and... | Yifu Qiu, Zheng Zhao, Yftah Ziser, Anna Korhonen, Edoardo Maria Ponti, Shay B. Cohen |  |
| 487 |  |  [Document Image Machine Translation with Dynamic Multi-pre-trained Models Assembling](https://doi.org/10.18653/v1/2024.naacl-long.392) |  | 0 | Text image machine translation (TIMT) is a task that translates source texts embedded in the image to target translations. The existing TIMT task mainly focuses on text-line-level images. In this paper, we extend the current TIMT task and propose a novel task, \*\*D\*\*ocument \*\*I\*\*mage \*\*M\*\*achine \*\*T\*\*ranslation to \*\*Markdown\*\* (\*\*DIMT2Markdown\*\*), which aims to translate a source document image with long context and complex layout... | Yupu Liang, Yaping Zhang, Cong Ma, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou |  |
| 488 |  |  [Elastic Weight Removal for Faithful and Abstractive Dialogue Generation](https://doi.org/10.18653/v1/2024.naacl-long.393) |  | 0 | Generating factual responses is a crucial requirement for dialogue systems. To promotemore factual responses, a common strategyis to ground their responses in relevant documents that inform response generation. However, common dialogue models still often hallucinate information that was not containedin these documents and is therefore unfaithful. In this work, we propose to alleviate suchhallucinations by ‘subtracting’ the parametersof a model trained to... | Nico Daheim, Nouha Dziri, Mrinmaya Sachan, Iryna Gurevych, Edoardo M. Ponti |  |
| 489 |  |  [R-Tuning: Instructing Large Language Models to Say 'I Don't Know'](https://doi.org/10.18653/v1/2024.naacl-long.394) |  | 0 | Large language models (LLMs) have revolutionized numerous domains with their impressive performance but still face their challenges. A predominant issue is the propensity for these models to generate non-existent facts, a concern termed hallucination. Our research is motivated by the observation that previous instruction tuning methods force the model to complete a sentence no matter whether the model knows the knowledge or not. When the question is out of... | Hanning Zhang, Shizhe Diao, Yong Lin, Yi R. Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, Tong Zhang |  |
| 490 |  |  [Bridging the Gap between Different Vocabularies for LLM Ensemble](https://doi.org/10.18653/v1/2024.naacl-long.395) |  | 0 | Ensembling different large language models (LLMs) to unleash their complementary potential and harness their individual strengths is highly valuable. Nevertheless, vocabulary discrepancies among various LLMs have constrained previous studies to either selecting or blending completely generated outputs. This limitation hinders the dynamic correction and enhancement of outputs during the generation process, resulting in a limited capacity for effective... | Yangyifan Xu, Jinliang Lu, Jiajun Zhang |  |
| 491 |  |  [KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation](https://doi.org/10.18653/v1/2024.naacl-long.396) |  | 0 | Parameter-efficient finetuning (PEFT) is a key technique for adapting large language models (LLMs) to downstream tasks. In this paper, we study leveraging knowledge graph embeddings to improve the effectiveness of PEFT. We propose a knowledgeable adaptation method called KnowLA. It inserts an adaptation layer into an LLM to integrate the embeddings of entities appearing in the input text. The adaptation layer is trained in combination with LoRA on instruction... | Xindi Luo, Zequn Sun, Jing Zhao, Zhe Zhao, Wei Hu |  |
| 492 |  |  [Extremely Weakly-supervised Text Classification with Wordsets Mining and Sync-Denoising](https://doi.org/10.18653/v1/2024.naacl-long.397) |  | 0 | Extremely weakly-supervised text classification aims to classify texts without any labeled data, but only relying on class names as supervision. Existing works include prompt-based and seed-based methods. Prompt-based methods prompt language model with instructions, while seed-based methods generate pseudo-labels with word matching. Both of them have significant flaws, including zero-shot instability and context-dependent ambiguities. This paper introduces... | Lysa Xiao |  |
| 493 |  |  [F-MALLOC: Feed-forward Memory Allocation for Continual Learning in Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.398) |  | 0 | In the evolving landscape of Neural Machine Translation (NMT), the pretrain-then-finetune paradigm has yielded impressive results. However, the persistent challenge of Catastrophic Forgetting (CF) remains a hurdle. While previous work has introduced Continual Learning (CL) methods to address CF, these approaches grapple with the delicate balance between avoiding forgetting and maintaining system extensibility. To address this, we propose a CL method, named... | Junhong Wu, Yuchen Liu, Chengqing Zong |  |
| 494 |  |  [Towards Reducing Diagnostic Errors with Interpretable Risk Prediction](https://doi.org/10.18653/v1/2024.naacl-long.399) |  | 0 | Many diagnostic errors occur because clinicians cannot easily access relevant information in patient Electronic Health Records (EHRs). In this work we propose a method to use LLMs to identify pieces of evidence in patient EHR data that indicate increased or decreased risk of specific diagnoses; our ultimate aim is to increase access to evidence and reduce diagnostic errors. In particular, we propose a Neural Additive Model to make predictions backed by... | Denis Jered McInerney, William Dickinson, Lucy C. Flynn, Andrea Young, Geoffrey S. Young, JanWillem van de Meent, Byron C. Wallace |  |
| 495 |  |  [Generalizable Multilingual Hate Speech Detection on Low Resource Indian Languages using Fair Selection in Federated Learning](https://doi.org/10.18653/v1/2024.naacl-long.400) |  | 0 | Social media, originally meant for peaceful communication, now faces issues with hate speech. Detecting hate speech from social media in Indian languages with linguistic diversity and cultural nuances presents a complex and challenging task. Furthermore, traditional methods involve sharing of users’ sensitive data with a server for model training making it undesirable and involving potential risk to their privacy remained under-studied. In this paper, we... | Akshay Singh, Rahul Thakur |  |
| 496 |  |  [Key ingredients for effective zero-shot cross-lingual knowledge transfer in generative tasks](https://doi.org/10.18653/v1/2024.naacl-long.401) |  | 0 | Zero-shot cross-lingual transfer, which implies finetuning of the multilingual pretrained language model on input-output pairs in one language and using it to make task predictions for inputs in other languages, was widely studied for natural language understanding but is understudied for generation. Previous works notice a frequent problem of generation in a wrong language and propose approaches to address it, usually using mT5 as a backbone model. In this... | Nadezhda Chirkova, Vassilina Nikoulina |  |
| 497 |  |  [The Impact of Depth on Compositional Generalization in Transformer Language Models](https://doi.org/10.18653/v1/2024.naacl-long.402) |  | 0 | To process novel sentences, language models (LMs) must generalize compositionally—combine familiar elements in new ways. What aspects of a model’s structure promote compositional generalization? Focusing on transformers, we test the hypothesis, motivated by theoretical and empirical work, that deeper transformers generalize more compositionally. Simply adding layers increases the total number of parameters; to address this confound between depth and size, we... | Jackson Petty, Sjoerd van Steenkiste, Ishita Dasgupta, Fei Sha, Dan Garrette, Tal Linzen |  |
| 498 |  |  [Pregnant Questions: The Importance of Pragmatic Awareness in Maternal Health Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.403) |  | 0 | Questions posed by information-seeking users often contain implicit false or potentially harmful assumptions. In a high-risk domain such as maternal and infant health, a question-answering system must recognize these pragmatic constraints and go beyond simply answering user questions, examining them in context to respond helpfully. To achieve this, we study assumptions and implications, or pragmatic inferences, made when mothers ask questions about pregnancy... | Neha Srikanth, Rupak Sarkar, Heran Mane, Elizabeth Aparicio, Quynh C. Nguyen, Rachel Rudinger, Jordan L. BoydGraber |  |
| 499 |  |  [Towards Explainability in Legal Outcome Prediction Models](https://doi.org/10.18653/v1/2024.naacl-long.404) |  | 0 | Current legal outcome prediction models - a staple of legal NLP - do not explain their reasoning. However, to employ these models in the real world, human legal actors need to be able to understand the model’s decisions. In the case of common law, legal practitioners reason towards the outcome of a case by referring to past case law, known as precedent. We contend that precedent is, therefore, a natural way of facilitating explainability for legal NLP models.... | Josef Valvoda, Ryan Cotterell |  |
| 500 |  |  [The steerability of large language models toward data-driven personas](https://doi.org/10.18653/v1/2024.naacl-long.405) |  | 0 | Large language models (LLMs) are known to generate biased responses where the opinions of certain groups and populations are underrepresented. Here, we present a novel approach to achieve controllable generation of specific viewpoints using LLMs, that can be leveraged to produce multiple perspectives and to reflect the diverse opinions. Moving beyond the traditional reliance on demographics like age, gender, or party affiliation, we introduce a data-driven... | Junyi Li, Charith Peris, Ninareh Mehrabi, Palash Goyal, KaiWei Chang, Aram Galstyan, Richard S. Zemel, Rahul Gupta |  |
| 501 |  |  [CCSum: A Large-Scale and High-Quality Dataset for Abstractive News Summarization](https://doi.org/10.18653/v1/2024.naacl-long.406) |  | 0 | Training a supervised news summarization model requires large amounts of high-quality training data consisting of news articles paired with reference summaries. However, obtaining such data is costly, and existing datasets contain considerable amount of noise. We present a new large-scale and high-quality dataset for supervised abstractive news summarization containing 1.3 million training samples, which we call CCSum. In creating this dataset, we take... | Xiang Jiang, Markus Dreyer |  |
| 502 |  |  [Capturing Perspectives of Crowdsourced Annotators in Subjective Learning Tasks](https://doi.org/10.18653/v1/2024.naacl-long.407) |  | 0 | Supervised classification heavily depends on datasets annotated by humans. However, in subjective tasks such as toxicity classification, these annotations often exhibit low agreement among raters. Annotations have commonly been aggregated by employing methods like majority voting to determine a single ground truth label. In subjective tasks, aggregating labels will result in biased labeling and, consequently, biased models that can overlook minority opinions.... | Negar Mokhberian, Myrl G. Marmarelis, Frederic R. Hopp, Valerio Basile, Fred Morstatter, Kristina Lerman |  |
| 503 |  |  [Improving Factual Accuracy of Neural Table-to-Text Output by Addressing Input Problems in ToTTo](https://doi.org/10.18653/v1/2024.naacl-long.408) |  | 0 | Neural Table-to-Text models tend to hallucinate, producing texts that contain factual errors. We investigate whether such errors in the output can be traced back to problems with the input. We manually annotated 1,837 texts generated by multiple models in the politics domain of the ToTTo dataset. We identify the input problems that are responsible for many output errors and show that fixing these inputs reduces factual errors by between 52% and 76% (depending... | Barkavi Sundararajan, Somayajulu Sripada, Ehud Reiter |  |
| 504 |  |  [CERET: Cost-Effective Extrinsic Refinement for Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.409) |  | 0 | Large Language Models (LLMs) are powerful models for generation tasks, but they may not generate good quality outputs in their first attempt. Apart from model fine-tuning, existing approaches to improve prediction accuracy and quality typically involve LLM self-improvement / self-reflection that incorporate feedback from models themselves. Despite their effectiveness, these methods are hindered by their high computational cost and lack of scalability. In this... | Jason Cai, Hang Su, Monica Sunkara, Igor Shalyminov, Saab Mansour |  |
| 505 |  |  [Parameter-Efficient Instruction Tuning of Large Language Models For Extreme Financial Numeral Labelling](https://doi.org/10.18653/v1/2024.naacl-long.410) |  | 0 | We study the problem of automatically annotating relevant numerals (GAAP metrics) occurring in the financial documents with their corresponding XBRL tags. Different from prior works, we investigate the feasibility of solving this extreme classification problem using a generative paradigm through instruction tuning of Large Language Models (LLMs). To this end, we leverage metric metadata informationto frame our target outputs while proposing a parameter... | Subhendu Khatuya, Rajdeep Mukherjee, Akash Ghosh, Manjunath Hegde, Koustuv Dasgupta, Niloy Ganguly, Saptarshi Ghosh, Pawan Goyal |  |
| 506 |  |  [Analysis of State-Level Legislative Process in Enhanced Linguistic and Nationwide Network Contexts](https://doi.org/10.18653/v1/2024.naacl-long.411) |  | 0 | State bills have a significant impact on various aspects of society, including health, education, and the economy. Consequently, it is crucial to conduct systematic research on state bills before and after they are enacted to evaluate their benefits and drawbacks, thereby guiding future decision-making. In this work, we developed the first state-level deep learning framework that (1) handles the complex and inconsistent language of policies across US states... | Maryam Davoodi, Dan Goldwasser |  |
| 507 |  |  [DeMuX: Data-efficient Multilingual Learning](https://doi.org/10.18653/v1/2024.naacl-long.412) |  | 0 | Pre-trained multilingual models have enabled deployment of NLP technologies for multiple languages. However, optimally fine-tuning these models under an annotation budget, such that performance on desired target languages is jointly maximized, still remains an open question. In this paper, we introduce DeMuX, a framework that prescribes the exact data-points to label from vast amounts of unlabelled multilingual data, having unknown degrees of overlap with the... | Simran Khanuja, Srinivas Gowriraj, Lucio M. Dery, Graham Neubig |  |
| 508 |  |  [DUQGen: Effective Unsupervised Domain Adaptation of Neural Rankers by Diversifying Synthetic Query Generation](https://doi.org/10.18653/v1/2024.naacl-long.413) |  | 0 | State-of-the-art neural rankers pre-trained on large task-specific training data such as MS-MARCO, have been shown to exhibit strong performance on various ranking tasks without domain adaptation, also called zero-shot. However, zero-shot neural ranking may be sub-optimal, as it does not take advantage of the target domain information. Unfortunately, acquiring sufficiently large and high quality target training data to improve a modern neural ranker can be... | Ramraj Chandradevan, Kaustubh D. Dhole, Eugene Agichtein |  |
| 509 |  |  [How did we get here? Summarizing conversation dynamics](https://doi.org/10.18653/v1/2024.naacl-long.414) |  | 0 | Throughout a conversation, the way participants interact with each other is in constant flux: their tones may change, they may resort to different strategies to convey their points, or they might alter their interaction patterns. An understanding of these dynamics can complement that of the actual facts and opinions discussed, offering a more holistic view of the trajectory of the conversation: how it arrived at its current state and where it is likely... | Yilun Hua, Nicholas Chernogor, Yuzhe Gu, Seoyeon Julie Jeong, Miranda Luo, Cristian DanescuNiculescuMizil |  |
| 510 |  |  [Can Language Model Moderators Improve the Health of Online Discourse?](https://doi.org/10.18653/v1/2024.naacl-long.415) |  | 0 | Conversational moderation of online communities is crucial to maintaining civility for a constructive environment, but it is challenging to scale and harmful to moderators. The inclusion of sophisticated natural language generation modules as a force multiplier to aid human moderators is a tantalizing prospect, but adequate evaluation approaches have so far been elusive. In this paper, we establish a systematic definition of conversational moderation... | Hyundong Cho, Shuai Liu, Taiwei Shi, Darpan Jain, Basem Rizk, Yuyang Huang, Zixun Lu, Nuan Wen, Jonathan Gratch, Emilio Ferrara, Jonathan May |  |
| 511 |  |  [LeanReasoner: Boosting Complex Logical Reasoning with Lean](https://doi.org/10.18653/v1/2024.naacl-long.416) |  | 0 | Large language models (LLMs) often struggle with complex logical reasoning due to logical inconsistencies and the inherent difficulty ofsuch reasoning. We use Lean, a theorem proving framework, to address these challenges. By formalizing logical reasoning problems intotheorems within Lean, we can solve them by proving or disproving the corresponding theorems. This method reduces the risk of logical inconsistencies with the help of Lean’s symbolic solver. It... | Dongwei Jiang, Marcio Fonseca, Shay B. Cohen |  |
| 512 |  |  [UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback](https://doi.org/10.18653/v1/2024.naacl-long.417) |  | 0 | Many large language models (LLMs) struggle to consistently generate UI code that compiles and produces visually relevant designs. Existing approaches to improve generation rely either on expensive human feedback or distilling a proprietary model. In this paper, we explore the use of automated feedback (compilers and multi-modal models) to guide LLMs to generate high-quality UI code. Our method starts with an existing LLM and iteratively produces improved... | Jason Wu, Eldon Schoop, Alan Leung, Titus Barik, Jeffrey P. Bigham, Jeffrey Nichols |  |
| 513 |  |  [Measuring Cross-lingual Transfer in Bytes](https://doi.org/10.18653/v1/2024.naacl-long.418) |  | 0 | Multilingual pretraining has been a successful solution to the challenges posed by the lack of resources for languages. These models can transfer knowledge to target languages with minimal or no examples. Recent research suggests that monolingual models also have a similar capability, but the mechanisms behind this transfer remain unclear. Some studies have explored factors like language contamination and syntactic similarity. An emerging line of research... | Leandro Rodrigues de Souza, Thales Sales Almeida, Roberto A. Lotufo, Rodrigo Frassetto Nogueira |  |
| 514 |  |  [MisgenderMender: A Community-Informed Approach to Interventions for Misgendering](https://doi.org/10.18653/v1/2024.naacl-long.419) |  | 0 | Content Warning: This paper contains examples of misgendering and erasure that could be offensive and potentially triggering.Misgendering, the act of incorrectly addressing someone’s gender, inflicts serious harm and is pervasive in everyday technologies, yet there is a notable lack of research to combat it. We are the first to address this lack of research into interventions for misgendering by conducting a survey of gender-diverse individuals in the US to... | Tamanna Hossain, Sunipa Dev, Sameer Singh |  |
| 515 |  |  [Interplay of Machine Translation, Diacritics, and Diacritization](https://doi.org/10.18653/v1/2024.naacl-long.420) |  | 0 | We investigate two research questions: (1) how do machine translation (MT) and diacritization influence the performance of each other in a multi-task learning setting (2) the effect of keeping (vs. removing) diacritics on MT performance. We examine these two questions in both high-resource (HR) and low-resource (LR) settings across 55 different languages (36 African languages and 19 European languages). For (1), results show that diacritization significantly... | WeiRui Chen, Ife Adebara, Muhammad AbdulMageed |  |
| 516 |  |  [From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.421) |  | 0 | In the realm of Large Language Models (LLMs), the balance between instruction data quality and quantity is a focal point. Recognizing this, we introduce a self-guided methodology for LLMs to autonomously discern and select cherry samples from open-source datasets, effectively minimizing manual curation and potential cost for instruction tuning an LLM. Our key innovation, the Instruction-Following Difficulty (IFD) metric, emerges as a pivotal metric to... | Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, Jing Xiao |  |
| 517 |  |  [Safer-Instruct: Aligning Language Models with Automated Preference Data](https://doi.org/10.18653/v1/2024.naacl-long.422) |  | 0 | Reinforcement learning from human feedback (RLHF) is a vital strategy for enhancing model capability in language models. However, annotating preference data for RLHF is a resource-intensive and creativity-demanding process, while existing automatic generation methods face limitations in data diversity and quality. In response, we present Safer-Instruct, a novel pipeline for automatically constructing large-scale preference data. Our approach leverages... | Taiwei Shi, Kai Chen, Jieyu Zhao |  |
| 518 |  |  [PELMS: Pre-training for Effective Low-Shot Multi-Document Summarization](https://doi.org/10.18653/v1/2024.naacl-long.423) |  | 0 | We investigate pre-training techniques for abstractive multi-document summarization (MDS), which is much less studied than summarizing single documents. Though recent work has demonstrated the effectiveness of highlighting information salience for pre-training strategy design, they struggle to generate abstractive and reflective summaries, which are critical properties for MDS. To this end, we present \*\*PELMS\*\*, a pre-trained model that uses pre-training... | Joseph Peper, Wenzhao Qiu, Lu Wang |  |
| 519 |  |  [Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?](https://doi.org/10.18653/v1/2024.naacl-long.424) |  | 0 | Despite the high performances of large language models (LLMs) across numerous benchmarks, recent research has unveiled their suffering from hallucinations and unfaithful reasoning. This work studies a type of hallucination induced by semantic associations. We investigate to what extent LLMs take shortcuts from certain keyword/entity biases in the prompt instead of following correct reasoning paths. To quantify this phenomenon, we propose a novel probing... | Bangzheng Li, Ben Zhou, Fei Wang, Xingyu Fu, Dan Roth, Muhao Chen |  |
| 520 |  |  [IndiSentiment140: Sentiment Analysis Dataset for Indian Languages with Emphasis on Low-Resource Languages using Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.425) |  | 0 | Sentiment analysis, a fundamental aspect of Natural Language Processing (NLP), involves the classification of emotions, opinions, and attitudes in text data. In the context of India, with its vast linguistic diversity and low-resource languages, the challenge is to support sentiment analysis in numerous Indian languages. This study explores the use of machine translation to bridge this gap. The investigation examines the feasibility of machine translation for... | Saurabh Kumar, Sanasam Ranbir Sanasam, Sukumar Nandi |  |
| 521 |  |  [Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval](https://doi.org/10.18653/v1/2024.naacl-long.426) |  | 0 | There has been limited success for dense retrieval models in multilingual retrieval, due to uneven and scarce training data available across multiple languages. Synthetic training data generation is promising (e.g., InPars or Promptagator), but has been investigated only for English. Therefore, to study model capabilities across both cross-lingual and monolingual retrieval tasks, we develop \*\*SWIM-IR\*\*, a synthetic retrieval training dataset containing 33... | Nandan Thakur, Jianmo Ni, Gustavo Hernández Ábrego, John Wieting, Jimmy Lin, Daniel Cer |  |
| 522 |  |  [SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities](https://doi.org/10.18653/v1/2024.naacl-long.427) |  | 0 | Recent advances in named entity recognition (NER) have pushed the boundary of the task to incorporate visual signals, leading to many variants, including multi-modal NER (MNER) or grounded MNER (GMNER). A key challenge to these tasks is that the model should be able to generalize to the entities unseen during the training, and should be able to handle the training samples with noisy annotations.To address this obstacle, we propose SCANNER (Span CANdidate... | Hyunjong Ok, Taeho Kil, Sukmin Seo, Jaeho Lee |  |
| 523 |  |  [A Theory Guided Scaffolding Instruction Framework for LLM-Enabled Metaphor Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.428) |  | 0 | Metaphor detection is a challenging task in figurative language processing, which aims to distinguish between metaphorical and literal expressions in text. Existing methods tackle metaphor detection via training or fine-tuning discriminative models on labeled data. However, these approaches struggle to explain the underlying reasoning process behind the metaphorical/literal judgment. Recently, large language models (LLMs) have shown promise in language... | Yuan Tian, Nan Xu, Wenji Mao |  |
| 524 |  |  [Learning to Compress Prompt in Natural Language Formats](https://doi.org/10.18653/v1/2024.naacl-long.429) |  | 0 | Large language models (LLMs) are great at processing multiple natural language processing tasks, but their abilities are constrained by inferior performance with long context, slow inference speed, and the high cost of computing the results. Deploying LLMs with precise and informative context helps users process large-scale datasets more effectively and cost-efficiently. Existing works rely on compressing long prompt contexts into soft prompts. However, soft... | YuNeng Chuang, Tianwei Xing, ChiaYuan Chang, Zirui Liu, Xun Chen, Xia Ben Hu |  |
| 525 |  |  [Automatic, Meta and Human Evaluation for Multimodal Summarization with Multimodal Output](https://doi.org/10.18653/v1/2024.naacl-long.430) |  | 0 | Multimodal summarization with multimodal output (MSMO) has attracted increasing research interests recently as multimodal summary could provide more comprehensive information compared to text-only summary, effectively improving the user experience and satisfaction. As one of the most fundamental components for the development of MSMO, evaluation is an emerging yet underexplored research topic. In this paper, we fill this gap and propose a research framework... | Haojie Zhuang, Wei Emma Zhang, Leon Xie, Weitong Chen, Jian Yang, Quan Sheng |  |
| 526 |  |  [Naive Bayes-based Context Extension for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.431) |  | 0 | Large Language Models (LLMs) have shown promising in-context learning abilities. However, conventional In-Context Learning (ICL) approaches are often impeded by length limitations of transformer architecture, which pose challenges when attempting to effectively integrate supervision from a substantial number of demonstration examples. In this paper, we introduce a novel framework, called Naive Bayes-based Context Extension (NBCE), to enable existing LLMs to... | Jianlin Su, Murtadha H. M. Ahmed, Bo Wen, Luo Ao, Mingren Zhu, Yunfeng Liu |  |
| 527 |  |  [Leitner-Guided Memory Replay for Cross-lingual Continual Learning](https://doi.org/10.18653/v1/2024.naacl-long.432) |  | 0 | Cross-lingual continual learning aims to continuously fine-tune a downstream model on emerging data from new languages. One major challenge in cross-lingual continual learning is catastrophic forgetting: a stability-plasticity dilemma, where performance on previously seen languages decreases as the model learns to transfer to new languages. Experience replay, which revisits data from a fixed-size memory of old languages while training on new ones, is among... | Meryem M'hamdi, Jonathan May |  |
| 528 |  |  [Multilingual Nonce Dependency Treebanks: Understanding how Language Models Represent and Process Syntactic Structure](https://doi.org/10.18653/v1/2024.naacl-long.433) |  | 0 | We introduce SPUD (Semantically Perturbed Universal Dependencies), a framework for creating nonce treebanks for the multilingual Universal Dependencies (UD) corpora. SPUD data satisfies syntactic argument structure, provides syntactic annotations, and ensures grammaticality via language-specific rules. We create nonce data in Arabic, English, French, German, and Russian, and demonstrate two use cases of SPUD treebanks. First, we investigate the effect of... | David Arps, Laura Kallmeyer, Younes Samih, Hassan Sajjad |  |
| 529 |  |  [Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery](https://doi.org/10.18653/v1/2024.naacl-long.434) |  | 0 | Generalized category discovery faces a key issue: the lack of supervision for new and unseen data categories. Traditional methods typically combine supervised pretraining with self-supervised learning to create models, and then employ clustering for category identification. However, these approaches tend to become overly tailored to known categories, failing to fully resolve the core issue. Hence, we propose to integrate the feedback from LLMs into an active... | Jinggui Liang, Lizi Liao, Hao Fei, Bobo Li, Jing Jiang |  |
| 530 |  |  [Explaining Text Similarity in Transformer Models](https://doi.org/10.18653/v1/2024.naacl-long.435) |  | 0 | As Transformers have become state-of-the-art models for natural language processing (NLP) tasks, the need to understand and explain their predictions is increasingly apparent. Especially in unsupervised applications, such as information retrieval tasks, similarity models built on top of foundation model representations have been widely applied. However, their inner prediction mechanisms have mostly remained opaque. Recent advances in explainable AI have made... | Alexandros Vasileiou, Oliver Eberle |  |
| 531 |  |  [Large Language Models can Contrastively Refine their Generation for Better Sentence Representation Learning](https://doi.org/10.18653/v1/2024.naacl-long.436) |  | 0 | Recently, large language models (LLMs) have emerged as a groundbreaking technology and their unparalleled text generation capabilities have sparked interest in their application to the fundamental sentence representation learning task. Existing methods have explored utilizing LLMs as data annotators to generate synthesized data for training contrastive learning based sentence embedding models such as SimCSE. However, since contrastive learning models are... | Huiming Wang, Zhaodonghui Li, Liying Cheng, De Wen Soh, Lidong Bing |  |
| 532 |  |  [HIL: Hybrid Isotropy Learning for Zero-shot Performance in Dense retrieval](https://doi.org/10.18653/v1/2024.naacl-long.437) |  | 0 | Advancements in dense retrieval models have brought ColBERT to prominence in Information Retrieval (IR) with its advanced interaction techniques.However, ColBERT is reported to frequently underperform in zero-shot scenarios, where traditional techniques such as BM25 still exceed it.Addressing this, we propose to balance representation isotropy and anisotropy for zero-shot model performance, based on our observations that isotropy can enhance cosine similarity... | Jaeyoung Kim, Dohyeon Lee, Seungwon Hwang |  |
| 533 |  |  [SuperGLEBer: German Language Understanding Evaluation Benchmark](https://doi.org/10.18653/v1/2024.naacl-long.438) |  | 0 | We assemble a broad Natural Language Understanding benchmark suite for the German language and consequently evaluate a wide array of existing German-capable models in order to create a better understanding of the current state of German LLMs. Our benchmark consists of 29 different tasks ranging over different types such as document classification, sequence tagging, sentence similarity, and question answering, on which we evaluate 10 different... | Jan Pfister, Andreas Hotho |  |
| 534 |  |  ["You are an expert annotator": Automatic Best-Worst-Scaling Annotations for Emotion Intensity Modeling](https://doi.org/10.18653/v1/2024.naacl-long.439) |  | 0 | Labeling corpora constitutes a bottleneck to create models for new tasks or domains. Large language models mitigate the issue with automatic corpus labeling methods, particularly for categorical annotations. Some NLP tasks such as emotion intensity prediction, however, require text regression, but there is no work on automating annotations for continuous label assignments. Regression is considered more challenging than classification: The fact that humans... | Christopher Bagdon, Prathamesh Karmalkar, Harsha Gurulingappa, Roman Klinger |  |
| 535 |  |  [What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?](https://doi.org/10.18653/v1/2024.naacl-long.440) |  | 0 | Recent advancements in GPT-4V have displayed remarkable multi-modal capabilities in processing image inputs and following open-ended instructions. Despite these advancements, there is considerable scope for enhancing open-source multi-modal LLMs, especially in terms of multi-modal understanding accuracy and instruction-following proficiency. In this paper, we conduct a comprehensive study on training GPT4-style models. We introduce Lynx a multi-modal LLM... | Yan Zeng, Hanbo Zhang, Jiani Zheng, Jiangnan Xia, Guoqiang Wei, Yang Wei, Yuchen Zhang, Tao Kong, Ruihua Song |  |
| 536 |  |  [Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation](https://doi.org/10.18653/v1/2024.naacl-long.441) |  | 0 | Human evaluation serves as the gold standard for assessing the quality of Natural Language Generation (NLG) systems. Nevertheless, the evaluation guideline, as a pivotal element ensuring reliable and reproducible human assessment, has received limited attention. Our investigation revealed that only 29.84% of recent papers involving human evaluation at top conferences release their evaluation guidelines, with vulnerabilities identified in 77.09% of these... | Jie Ruan, Wenqing Wang, Xiaojun Wan |  |
| 537 |  |  [MOSAICo: a Multilingual Open-text Semantically Annotated Interlinked Corpus](https://doi.org/10.18653/v1/2024.naacl-long.442) |  | 0 | Several Natural Language Understanding (NLU) tasks focus on linking text to explicit knowledge, including Word Sense Disambiguation, Semantic Role Labeling, Semantic Parsing, and Relation Extraction. In addition to the importance of connecting raw text with explicit knowledge bases, the integration of such carefully curated knowledge into deep learning models has been shown to be beneficial across a diverse range of applications, including Language Modeling... | Simone Conia, Edoardo Barba, Abelardo Carlos Martinez Lorenzo, PereLluís Huguet Cabot, Riccardo Orlando, Luigi Procopio, Roberto Navigli |  |
| 538 |  |  [SemRoDe: Macro Adversarial Training to Learn Representations that are Robust to Word-Level Attacks](https://doi.org/10.18653/v1/2024.naacl-long.443) |  | 0 | Language models (LMs) are indispensable tools for natural language processing tasks, but their vulnerability to adversarial attacks remains a concern. While current research has explored adversarial training techniques, their improvements to defend against word-level attacks have been limited. In this work, we propose a novel approach called Semantic Robust Defence (SemRoDe), a Macro Adversarial Training strategy to enhance the robustness of LMs. Drawing... | Brian Formento, Wenjie Feng, ChuanSheng Foo, Anh Tuan Luu, SeeKiong Ng |  |
| 539 |  |  [BUST: Benchmark for the evaluation of detectors of LLM-Generated Text](https://doi.org/10.18653/v1/2024.naacl-long.444) |  | 0 | We introduce BUST, a comprehensive benchmark designed to evaluate detectors of texts generated by instruction-tuned large language models (LLMs). Unlike previous benchmarks, our focus lies on evaluating the performance of detector systems, acknowledging the inevitable influence of the underlying tasks and different LLM generators. Our benchmark dataset consists of 25K texts from humans and 7 LLMs responding to instructions across 10 tasks from 3 diverse... | Joseph Cornelius, Oscar LithgowSerrano, Sandra Mitrovic, Ljiljana Dolamic, Fabio Rinaldi |  |
| 540 |  |  [Improving In-context Learning of Multilingual Generative Language Models with Cross-lingual Alignment](https://doi.org/10.18653/v1/2024.naacl-long.445) |  | 0 | Multilingual generative models obtain remarkable cross-lingual in-context learning capabilities through pre-training on large-scale corpora. However, they still exhibit a performance bias toward high-resource languages and learn isolated distributions of multilingual sentence representations, which may hinder knowledge transfer across languages. To bridge this gap, we propose a simple yet effective cross-lingual alignment framework exploiting pairs of... | Chong Li, Shaonan Wang, Jiajun Zhang, Chengqing Zong |  |
| 541 |  |  [MaCSC: Towards Multimodal-augmented Pre-trained Language Models via Conceptual Prototypes and Self-balancing Calibration](https://doi.org/10.18653/v1/2024.naacl-long.446) |  | 0 | Pre-trained language models (PLMs) that rely solely on textual data may exhibit limitations in multimodal semantics comprehension. Existing solutions attempt to alleviate this issue by incorporating explicit image retrieval or generation techniques.However, these methods: (1) focus exclusively on the static image modality; (2) inevitably encounter modality gaps and noise; (3) indiscriminately treat all modalities.In this paper, we propose a novel... | Xianwei Zhuang, Zhichang Wang, Xuxin Cheng, Yuxin Xie, Liming Liang, Yuexian Zou |  |
| 542 |  |  [Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?](https://doi.org/10.18653/v1/2024.naacl-long.447) |  | 0 | Knowledge graphs (KGs) consist of links that describe relationships between entities. Due to the difficulty of manually enumerating all relationships between entities, automatically completing them is essential for KGs. Knowledge Graph Completion (KGC) is a task that infers unseen relationships between entities in a KG. Traditional embedding-based KGC methods (e.g. RESCAL, TransE, DistMult, ComplEx, RotatE, HAKE, HousE, etc.) infer missing links using only... | Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe |  |
| 543 |  |  [Discovering Lobby-Parliamentarian Alignments through NLP](https://doi.org/10.18653/v1/2024.naacl-long.448) |  | 0 | We discover alignments of views between interest groups (lobbies) and members of the European Parliament (MEPs) by automatically analyzing their texts. Specifically, we do so by collecting novel datasets of lobbies’ position papers and MEPs’ speeches, and comparing these texts on the basis of semantic similarity and entailment. In the absence of ground-truth, we perform an indirect validation by comparing the discovered alignments with a dataset, which we... | Aswin Suresh, Lazar Radojevic, Francesco Salvi, Antoine Magron, Victor Kristof, Matthias Grossglauser |  |
| 544 |  |  [IterCQR: Iterative Conversational Query Reformulation with Retrieval Guidance](https://doi.org/10.18653/v1/2024.naacl-long.449) |  | 0 | Conversational search aims to retrieve passages containing essential information to answer queries in a multi-turn conversation. In conversational search, reformulating context-dependent conversational queries into stand-alone forms is imperative to effectively utilize off-the-shelf retrievers. Previous methodologies for conversational query reformulation frequently depend on human-annotated rewrites.However, these manually crafted queries often result in... | Yunah Jang, Kangil Lee, Hyunkyung Bae, Hwanhee Lee, Kyomin Jung |  |
| 545 |  |  [AceGPT, Localizing Large Language Models in Arabic](https://doi.org/10.18653/v1/2024.naacl-long.450) |  | 0 | This paper is devoted to the development of a localized Large Language Model (LLM) specifically for Arabic, a language imbued with unique cultural characteristics inadequately addressed by current mainstream models. Significant concerns emerge when addressing cultural sensitivity and local values. To address this, the paper proposes a comprehensive solution that includes further pre-training with Arabic texts, Supervised Fine-Tuning (SFT) utilizing native... | Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen, Mosen Alharthi, Bang An, Juncai He, Ziche Liu, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu |  |
| 546 |  |  [Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model](https://doi.org/10.18653/v1/2024.naacl-long.451) |  | 0 | Insufficient modeling of human preferences within the reward model is a major obstacle for leveraging human feedback to improve translation quality. Fortunately, quality estimation (QE), which predicts the quality of a given translation without reference, has achieved impressive alignment with human evaluations in the last two years. In this work, we investigate the potential of employing the QE model as the reward model to predict human preferences for... | Zhiwei He, Xing Wang, Wenxiang Jiao, Zhuosheng Zhang, Rui Wang, Shuming Shi, Zhaopeng Tu |  |
| 547 |  |  [Depression Detection in Clinical Interviews with LLM-Empowered Structural Element Graph](https://doi.org/10.18653/v1/2024.naacl-long.452) |  | 0 | Depression is a widespread mental health disorder affecting millions globally. Clinical interviews are the gold standard for assessing depression, but they heavily rely on scarce professional clinicians, highlighting the need for automated detection systems. However, existing methods only capture part of the relevant elements in clinical interviews, unable to incorporate all depressive cues. Moreover, the scarcity of participant data, due to privacy concerns... | Zhuang Chen, Jiawen Deng, Jinfeng Zhou, Jincenzi Wu, Tieyun Qian, Minlie Huang |  |
| 548 |  |  [SQATIN: Supervised Instruction Tuning Meets Question Answering for Improved Dialogue NLU](https://doi.org/10.18653/v1/2024.naacl-long.453) |  | 0 | Task-oriented dialogue (TOD) systems help users execute well-defined tasks across a variety of domains (e.g., flight booking or food ordering), with their Natural Language Understanding (NLU) components being dedicated to the analysis of user utterances, predicting users’ intents (Intent Detection, ID) and extracting values for informational slots (Value Extraction, VE). In most domains, labelled NLU data is scarce, making sample-efficient learning – enabled... | Evgeniia Razumovskaia, Goran Glavas, Anna Korhonen, Ivan Vulic |  |
| 549 |  |  [Enhancing Argument Summarization: Prioritizing Exhaustiveness in Key Point Generation and Introducing an Automatic Coverage Evaluation Metric](https://doi.org/10.18653/v1/2024.naacl-long.454) |  | 0 | The proliferation of social media platforms has given rise to the amount of online debates and arguments. Consequently, the need for automatic summarization methods for such debates is imperative, however this area of summarization is rather understudied. The Key Point Analysis (KPA) task formulates argument summarization as representing the summary of a large collection of arguments in the form of concise sentences in bullet-style format, called key points.... | Mohammad Khosravani, Chenyang Huang, Amine Trabelsi |  |
| 550 |  |  [ARM: Alignment with Residual Energy-Based Model](https://doi.org/10.18653/v1/2024.naacl-long.455) |  | 0 | While large language models (LLMs) trained with large-scale unsupervised learning acquire a wide variety of world knowledge and skills, its behavior does not necessarily align with human preferences. RLHF methods achieve successes in aligning LLM responses with human preferences and improving the controllability of LLM behavior with human instruction. However, RLHF methods are considerably complicated to implement, computationally expensive to train, and... | Bo Pang, Caiming Xiong, Yingbo Zhou |  |
| 551 |  |  [HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants](https://doi.org/10.18653/v1/2024.naacl-long.456) |  | 0 | Language models (LMs) as conversational assistants recently became popular tools that help people accomplish a variety of tasks. These typically result from adapting LMs pretrained on general domain text sequences through further instruction-tuning and possibly preference optimisation methods. The evaluation of such LMs would ideally be performed using human judgement, however, this is not scalable. On the other hand, automatic evaluation featuring auxiliary... | Milan Gritta, Gerasimos Lampouras, Ignacio Iacobacci |  |
| 552 |  |  [FAMuS: Frames Across Multiple Sources](https://doi.org/10.18653/v1/2024.naacl-long.457) |  | 0 | Understanding event descriptions is a central aspect of language processing, but current approaches focus overwhelmingly on single sentences or documents. Aggregating information about an event across documents can offer a much richer understanding. To this end, we present FAMuS, a new corpus of Wikipedia passages that report on some event, paired with underlying, genre-diverse (non-Wikipedia) source articles for the same event. Events and (cross-sentence)... | Siddharth Vashishtha, Alexander Martin, William Gantt, Benjamin Van Durme, Aaron Steven White |  |
| 553 |  |  [Rationale-based Opinion Summarization](https://doi.org/10.18653/v1/2024.naacl-long.458) |  | 0 | Opinion summarization aims to generate concise summaries that present popular opinions of a large group of reviews. However, these summaries can be too generic and lack supporting details. To address these issues, we propose a new paradigm for summarizing reviews, rationale-based opinion summarization. Rationale-based opinion summaries output the representative opinions as well as one or more corresponding rationales. To extract good rationales, we define... | Haoyuan Li, Snigdha Chaturvedi |  |
| 554 |  |  [Mustango: Toward Controllable Text-to-Music Generation](https://doi.org/10.18653/v1/2024.naacl-long.459) |  | 0 | The quality of the text-to-music models has reached new heights due to recent advancements in diffusion models. The controllability of various musical aspects, however, has barely been explored. In this paper, we propose Mustango: a music-domain-knowledge-inspired text-to-music system based on diffusion. Mustango aims to control the generated music, not only with general text captions, but with more rich captions that can include specific instructions related... | Jan Melechovský, Zixun Guo, Deepanway Ghosal, Navonil Majumder, Dorien Herremans, Soujanya Poria |  |
| 555 |  |  [Adaptive Cross-lingual Text Classification through In-Context One-Shot Demonstrations](https://doi.org/10.18653/v1/2024.naacl-long.460) |  | 0 | Zero-Shot Cross-lingual Transfer (ZS-XLT) utilizes a model trained in a source language to make predictions in another language, often with a performance loss. To alleviate this, additional improvements can be achieved through subsequent adaptation using examples in the target language. In this paper, we exploit In-Context Tuning (ICT) for One-Shot Cross-lingual transfer in the classification task by introducing In-Context Cross-lingual Transfer (IC-XLT). The... | Emilio VillaCueva, Adrián Pastor LópezMonroy, Fernando SánchezVega, Thamar Solorio |  |
| 556 |  |  [CNER: Concept and Named Entity Recognition](https://doi.org/10.18653/v1/2024.naacl-long.461) |  | 0 | Named entities – typically expressed via proper nouns – play a key role in Natural Language Processing, as their identification and comprehension are crucial in tasks such as Relation Extraction, Coreference Resolution and Question Answering, among others. Tasks like these also often entail dealing with concepts – typically represented by common nouns – which, however, have not received as much attention. Indeed, the potential of their identification and... | Giuliano Martinelli, Francesco Molfese, Simone Tedeschi, Alberte FernándezCastro, Roberto Navigli |  |
| 557 |  |  [Branch-Solve-Merge Improves Large Language Model Evaluation and Generation](https://doi.org/10.18653/v1/2024.naacl-long.462) |  | 0 | Large Language Models (LLMs) are frequently used for multi-faceted language generation and evaluation tasks that involve satisfying intricate user constraints or taking into account multiple aspects and criteria. However, their performance can fall short, due to the model’s lack of coherence and inability to plan and decompose the problem. We propose Branch-Solve-Merge (BSM), a Large Language Model program (Schlag et al., 2023) for tackling such challenging... | Swarnadeep Saha, Omer Levy, Asli Celikyilmaz, Mohit Bansal, Jason Weston, Xian Li |  |
| 558 |  |  [REPLUG: Retrieval-Augmented Black-Box Language Models](https://doi.org/10.18653/v1/2024.naacl-long.463) |  | 0 | We introduce REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model. Unlike prior retrieval-augmented LMs that train language models with special cross-attention mechanisms to encode the retrieved text, REPLUG simply prepends retrieved documents to the input for the frozen black-box LM. This simple design can be easily applied to any existing language models.... | Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Richard James, Mike Lewis, Luke Zettlemoyer, Wentau Yih |  |
| 559 |  |  [David helps Goliath: Inference-Time Collaboration Between Small Specialized and Large General Diffusion LMs](https://doi.org/10.18653/v1/2024.naacl-long.464) |  | 0 | Diffusion-based language models are emerging as a promising alternative to autoregressive LMs: they approach the competence of autoregressive LMs while offering nuanced controllability at inference time. While autoregressive LMs have benefited immensely from scaling and instruction-based learning, existing studies of diffusion LMs have been conducted on a smaller scale. Starting with a recently proposed diffusion model SSD-LM, in this work we first explore... | Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad |  |
| 560 |  |  [Efficient End-to-End Visual Document Understanding with Rationale Distillation](https://doi.org/10.18653/v1/2024.naacl-long.465) |  | 0 | Understanding visually situated language requires interpreting complex layouts of textual and visual elements. Pre-processing tools, such as optical character recognition (OCR), can map document image inputs to textual tokens, then large language models (LLMs) can reason over text.However, such methods have high computational and engineering complexity. Can small pretrained image-to-text models accurately understand visual documents through similar... | Wang Zhu, Alekh Agarwal, Mandar Joshi, Robin Jia, Jesse Thomason, Kristina Toutanova |  |
| 561 |  |  [A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models](https://doi.org/10.18653/v1/2024.naacl-long.466) |  | 0 | A central component of rational behavior is logical inference: the process of determining which conclusions follow from a set of premises. Psychologists have documented several ways in which humans’ inferences deviate from the rules of logic. Do language models, which are trained on text generated by humans, replicate such human biases, or are they able to overcome them? Focusing on the case of syllogisms—inferences from two simple premises—we show that,... | Tiwalayo Eisape, Michael Henry Tessler, Ishita Dasgupta, Fei Sha, Sjoerd van Steenkiste, Tal Linzen |  |
| 562 |  |  [AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets](https://doi.org/10.18653/v1/2024.naacl-long.467) |  | 0 | Active learning for imbalanced classification tasks is challenging as the minority classes naturally occur rarely. Gathering a large pool of unlabelled data is thus essential to capture minority instances. Standard pool-based active learning is computationally expensive on large pools and often reaches low accuracy by overfitting the initial decision boundary, thus failing to explore the input space and find minority instances. To address these issues we... | Pietro Lesci, Andreas Vlachos |  |
| 563 |  |  [ICLE++: Modeling Fine-Grained Traits for Holistic Essay Scoring](https://doi.org/10.18653/v1/2024.naacl-long.468) |  | 0 | The majority of the recently developed models for automated essay scoring (AES) are evaluated solely on the ASAP corpus. However, ASAP is not without its limitations. For instance, it is not clear whether models trained on ASAP can generalize well when evaluated on other corpora. In light of these limitations, we introduce ICLE++, a corpus of persuasive student essays annotated with both holistic scores and trait-specific scores. Not only can ICLE++ be used... | Shengjie Li, Vincent Ng |  |
| 564 |  |  [UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations](https://doi.org/10.18653/v1/2024.naacl-long.469) |  | 0 | Language technologies that accurately model the dynamics of events must perform commonsense reasoning. Existing work evaluating commonsense reasoning focuses on making inferences about common, everyday situations. To instead investigate the ability to model unusual, unexpected, and unlikely situations, we explore the task of uncommonsense abductive reasoning. Given a piece of context with an unexpected outcome, this task requires reasoning abductively to... | Wenting Zhao, Justin T. Chiu, Jena D. Hwang, Faeze Brahman, Jack Hessel, Sanjiban Choudhury, Yejin Choi, Xiang Li, Alane Suhr |  |
| 565 |  |  [To Tell The Truth: Language of Deception and Language Models](https://doi.org/10.18653/v1/2024.naacl-long.470) |  | 0 | Text-based false information permeates online discourses, yet evidence of people’s ability to discern truth from such deceptive textual content is scarce. We analyze a novel TV game show data where conversations in a high-stake environment between individuals with conflicting objectives result in lies. We investigate the manifestation of potentially verifiable language cues of deception in the presence of objective truth, a distinguishing feature absent in... | Sanchaita Hazra, Bodhisattwa Prasad Majumder |  |
| 566 |  |  [Multilingual Models for ASR in Chibchan Languages](https://doi.org/10.18653/v1/2024.naacl-long.471) |  | 0 | We present experiments on Automatic Speech Recognition (ASR) for Bribri and Cabécar, two languages from the Chibchan family. We fine-tune four ASR algorithms (Wav2Vec2, Whisper, MMS & WavLM) to create monolingual models, with the Wav2Vec2 model demonstrating the best performance. We then proceed to use Wav2Vec2 for (1) experiments on training joint and transfer learning models for both languages, and (2) an analysis of the errors, with a focus on the... | Rolando CotoSolano, TaiWan Kim, Alexander Jones, Sharid Loáiciga |  |
| 567 |  |  [LegalDiscourse: Interpreting When Laws Apply and To Whom](https://doi.org/10.18653/v1/2024.naacl-long.472) |  | 0 | While legal AI has made strides in recent years, it still struggles with basic legal concepts: _when_ does a law apply? _Who_ does it applies to? _What_ does it do? We take a _discourse_ approach to addressing these problems and introduce a novel taxonomy for span-and-relation parsing of legal texts. We create a dataset, _LegalDiscourse_ of 602 state-level law paragraphs consisting of 3,715 discourse spans and 1,671 relations. Our trained annotators have an... | Alexander Spangher, Zihan Xue, TeLin Wu, Mark Hansen, Jonathan May |  |
| 568 |  |  [X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented Instruction Tuning with Auxiliary Evaluation Aspects](https://doi.org/10.18653/v1/2024.naacl-long.473) |  | 0 | Natural Language Generation (NLG) typically involves evaluating the generated text in various aspects (e.g., consistency and naturalness) to obtain a comprehensive assessment. However, multi-aspect evaluation remains challenging as it may require the evaluator to generalize to any given evaluation aspect even if it’s absent during training. In this paper, we introduce X-Eval, a two-stage instruction tuning framework to evaluate text in both seen and unseen... | Minqian Liu, Ying Shen, Zhiyang Xu, Yixin Cao, Eunah Cho, Vaibhav Kumar, Reza Ghanadan, Lifu Huang |  |
| 569 |  |  [Is Reference Necessary in the Evaluation of NLG Systems? When and Where?](https://doi.org/10.18653/v1/2024.naacl-long.474) |  | 0 | The majority of automatic metrics for evaluating NLG systems are reference-based. However, the challenge of collecting human annotation results in a lack of reliable references in numerous application scenarios. Despite recent advancements in reference-free metrics, it has not been well understood when and where they can be used as an alternative to reference-based metrics. In this study, by employing diverse analytical approaches, we comprehensively assess... | Shuqian Sheng, Yi Xu, Luoyi Fu, Jiaxin Ding, Lei Zhou, Xinbing Wang, Chenghu Zhou |  |
| 570 |  |  [Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.475) |  | 0 | An important open question in the use of large language models for knowledge-intensive tasks is how to effectively integrate knowledge from three sources: the model’s parametric memory, external structured knowledge, and external unstructured knowledge. Most existing prompting methods either rely on one or two of these sources, or require repeatedly invoking large language models to generate similar or identical content. In this work, we overcome these... | Xin Su, Tiep Le, Steven Bethard, Phillip Howard |  |
| 571 |  |  [Evaluating the Deductive Competence of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.476) |  | 0 | The development of highly fluent large language models (LLMs) has prompted increased interest in assessing their reasoning and problem-solving capabilities. We investigate whether several LLMs can solve a classic type of deductive reasoning problem from the cognitive science literature. The tested LLMs have limited abilities to solve these problems in their conventional form. We performed follow up experiments to investigate if changes to the presentation... | S. M. Seals, Valerie L. Shalin |  |
| 572 |  |  [Large Human Language Models: A Need and the Challenges](https://doi.org/10.18653/v1/2024.naacl-long.477) |  | 0 | As research in human-centered NLP advances, there is a growing recognition of the importance of incorporating human and social factors into NLP models. At the same time, our NLP systems have become heavily reliant on LLMs, most of which do not model authors. To build NLP systems that can truly understand human language, we must better integrate human contexts into LLMs. This brings to the fore a range of design considerations and challenges in terms of what... | Nikita Soni, H. Andrew Schwartz, João Sedoc, Niranjan Balasubramanian |  |
| 573 |  |  [On Learning to Summarize with Large Language Models as References](https://doi.org/10.18653/v1/2024.naacl-long.478) |  | 0 | Recent studies have found that summaries generated by large language models (LLMs) are favored by human annotators over the original reference summaries in commonly used summarization datasets. Therefore, we study an LLM-as-reference learning setting for smaller text summarization models to investigate whether their performance can be substantially improved. To this end, we use LLMs as both oracle summary generators for standard supervised fine-tuning and... | Yixin Liu, Kejian Shi, Katherine He, Longtian Ye, Alexander R. Fabbri, Pengfei Liu, Dragomir Radev, Arman Cohan |  |
| 574 |  |  [Hallucination Diversity-Aware Active Learning for Text Summarization](https://doi.org/10.18653/v1/2024.naacl-long.479) |  | 0 | Large Language Models (LLMs) have shown propensity to generate hallucinated outputs, i.e., texts that are factually incorrect or unsupported. Existing methods for alleviating hallucinations typically require costly human annotations to identify and correct hallucinations in LLM outputs. Moreover, most of these methods focus on a specific type of hallucination, e.g., entity or token errors, which limits their effectiveness in addressing various types of... | Yu Xia, Xu Liu, Tong Yu, Sungchul Kim, Ryan A. Rossi, Anup B. Rao, Tung Mai, Shuai Li |  |
| 575 |  |  [Keep it Private: Unsupervised Privatization of Online Text](https://doi.org/10.18653/v1/2024.naacl-long.480) |  | 0 | Authorship obfuscation techniques hold the promise of helping people protect their privacy in online communications by automatically rewriting text to hide the identity of the original author. However, obfuscation has been evaluated in narrow settings in the NLP literature and has primarily been addressed with superficial edit operations that can lead to unnatural outputs. In this work, we introduce an automatic text privatization framework that fine-tunes a... | Calvin Bao, Marine Carpuat |  |
| 576 |  |  [Tied-LoRA: Enhancing parameter efficiency of LoRA with Weight Tying](https://doi.org/10.18653/v1/2024.naacl-long.481) |  | 0 | We introduce Tied-LoRA, a novel paradigm leveraging weight tying and selective training to enhance the parameter efficiency of Low-rank Adaptation (LoRA). Our exploration encompasses different plausible combinations of parameter training and freezing, coupled with weight tying, aimed at identifying the optimal trade-off between performance and the count of trainable parameters. Across 5 diverse tasks and two foundational language models with different... | Adithya Renduchintala, Tugrul Konuk, Oleksii Kuchaiev |  |
| 577 |  |  [Investigating Data Contamination in Modern Benchmarks for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.482) |  | 0 | Recent observations have underscored a disparity between the inflated benchmark scores and the actual performance of LLMs, raising concerns about potential contamination of evaluation benchmarks. This issue is especially critical for closed-source models and certain open-source models where training data transparency is lacking. In this paper we study data contamination by proposing two methods tailored for both open-source and proprietary LLMs. We first... | Chunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Gerstein, Arman Cohan |  |
| 578 |  |  [Pre-trained Language Models for Entity Blocking: A Reproducibility Study](https://doi.org/10.18653/v1/2024.naacl-long.483) |  | 0 | Entity Resolution (ER) is an essential task in data integration and its goal is to find records that represent the same entity in a dataset. Deep learning models, especially large pre-trained language models, have achieved state-of-the-art results on this task. A typical ER pipeline consists of Entity Blocking and Entity Matching: Entity Blocking finds candidate record pairs that potentially match and Entity Matching determines if the pairs match. The goal of... | Runhui Wang, Yongfeng Zhang |  |
| 579 |  |  [RE²: Region-Aware Relation Extraction from Visually Rich Documents](https://doi.org/10.18653/v1/2024.naacl-long.484) |  | 0 | Current research in form understanding predominantly relies on large pre-trained language models, necessitating extensive data for pre-training. However, the importance of layout structure (i.e., the spatial relationship between the entity blocks in the visually rich document) to relation extraction has been overlooked. In this paper, we propose REgion-Aware Relation Extraction (RE2) that leverages region-level spatial structure among the entity blocks to... | Pritika Ramu, Sijia Wang, Lalla Mouatadid, Joy Rimchala, Lifu Huang |  |
| 580 |  |  [Mix-Initiative Response Generation with Dynamic Prefix Tuning](https://doi.org/10.18653/v1/2024.naacl-long.485) |  | 0 | Mixed initiative serves as one of the key factors in controlling conversation directions. For a speaker, responding passively or leading proactively would result in rather different responses. However, most dialogue systems focus on training a holistic response generation model without any distinction among different initiatives. It leads to the cross-contamination problem, where the model confuses different initiatives and generates inappropriate responses.... | Yuxiang Nie, Heyan Huang, XianLing Mao, Lizi Liao |  |
| 581 |  |  [Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Value](https://doi.org/10.18653/v1/2024.naacl-long.486) |  | 0 | Value alignment is crucial for the responsible development of Large Language Models (LLMs). However, how to define values in this context remains largely unexplored. Existing work mainly specifies values as risk criteria formulated in the AI community, e.g., fairness and privacy protection, suffering from poor clarity, adaptability and transparency. Leveraging basic values established in humanity and social science that are compatible with values across... | Jing Yao, Xiaoyuan Yi, Yifan Gong, Xiting Wang, Xing Xie |  |
| 582 |  |  [IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context](https://doi.org/10.18653/v1/2024.naacl-long.487) |  | 0 | The pervasive influence of social biases in language data has sparked the need for benchmark datasets that capture and evaluate these biases in Large Language Models (LLMs). Existing efforts predominantly focus on English language and the Western context, leaving a void for a reliable dataset that encapsulates India’s unique socio-cultural nuances. To bridge this gap, we introduce IndiBias, a comprehensive benchmarking dataset designed specifically for... | Nihar R. Sahoo, Pranamya Prashant Kulkarni, Arif Ahmad, Tanu Goyal, Narjis Asad, Aparna Garimella, Pushpak Bhattacharyya |  |
| 583 |  |  [Findings of the Association for Computational Linguistics: NAACL 2024, Mexico City, Mexico, June 16-21, 2024](https://aclanthology.org/volumes/2024.findings-naacl/) |  | 0 |  | Kevin Duh, Helena GómezAdorno, Steven Bethard |  |
| 584 |  |  [Structured Pruning for Large Language Models Using Coupled Components Elimination and Minor Fine-tuning](https://doi.org/10.18653/v1/2024.findings-naacl.1) |  | 0 | Large language models (LLMs) have demonstrated powerful capabilities in natural language processing, yet their vast number of parameters poses challenges for deployment and inference efficiency. Structured model pruning emerges as a viable approach to reduce model size and accelerate inference, without requiring specialized operators and libraries for deployment. However, structured pruning often severely weakens the model’s capability.Despite repetitive... | Honghe Zhang, Xiaolong Shi, Jingwei Sun, Guangzhong Sun |  |
| 585 |  |  [Weight-Inherited Distillation for Task-Agnostic BERT Compression](https://doi.org/10.18653/v1/2024.findings-naacl.2) |  | 0 | Knowledge Distillation (KD) is a predominant approach for BERT compression.Previous KD-based methods focus on designing extra alignment losses for the student model to mimic the behavior of the teacher model.These methods transfer the knowledge in an indirect way.In this paper, we propose a novel Weight-Inherited Distillation (WID), which directly transfers knowledge from the teacher.WID does not require any additional alignment loss and trains a compact... | Taiqiang Wu, Cheng Hou, Shanshan Lao, Jiayi Li, Ngai Wong, Zhe Zhao, Yujiu Yang |  |
| 586 |  |  [Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for Pretraining on the Cybersecurity Domain](https://doi.org/10.18653/v1/2024.findings-naacl.3) |  | 0 | Cybersecurity information is often technically complex and relayed through unstructured text, making automation of cyber threat intelligence highly challenging. For such text domains that involve high levels of expertise, pretraining on in-domain corpora has been a popular method for language models to obtain domain expertise. However, cybersecurity texts often contain non-linguistic elements (such as URLs and hash values) that could be unsuitable with the... | Eugene Jang, Jian Cui, Dayeon Yim, Youngjin Jin, JinWoo Chung, Seungwon Shin, Yongjae Lee |  |
| 587 |  |  [Extremely efficient online query encoding for dense retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.4) |  | 0 | Existing dense retrieval systems utilize the same model architecture for encoding both the passages and the queries, even though queries are much shorter and simpler than passages. This leads to high latency of the query encoding, which is performed online and therefore might impact user experience. We show that combining a standard large passage encoder with a small efficient query encoder can provide significant latency drops with only a small decrease in... | Nachshon Cohen, Yaron Fairstein, Guy Kushilevitz |  |
| 588 |  |  [DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain Question Answering over Knowledge Base and Text](https://doi.org/10.18653/v1/2024.findings-naacl.5) |  | 0 | Large Language Models (LLMs) have exhibited impressive generation capabilities, but they suffer from hallucinations when solely relying on their internal knowledge, especially when answering questions that require less commonly known information. Retrievalaugmented LLMs have emerged as a potential solution to ground LLMs in external knowledge. Nonetheless, recent approaches have primarily emphasized retrieval from unstructured text corpora, owing to its... | Wenting Zhao, Ye Liu, Tong Niu, Yao Wan, Philip S. Yu, Shafiq Joty, Yingbo Zhou, Semih Yavuz |  |
| 589 |  |  [SpeedE: Euclidean Geometric Knowledge Graph Embedding Strikes Back](https://doi.org/10.18653/v1/2024.findings-naacl.6) |  | 0 | Geometric knowledge graph embedding models (gKGEs) have shown great potential for knowledge graph completion (KGC), i.e., automatically predicting missing triples. However, contemporary gKGEs require high embedding dimensionalities or complex embedding spaces for good KGC performance, drastically limiting their space and time efficiency. Facing these challenges, we propose SpeedE, a lightweight Euclidean gKGE that (1) provides strong inference capabilities,... | Aleksandar Pavlovic, Emanuel Sallinger |  |
| 590 |  |  [Language Guided Exploration for RL Agents in Text Environments](https://doi.org/10.18653/v1/2024.findings-naacl.7) |  | 0 |  | Hitesh Golchha, Sahil Yerawar, Dhruvesh Patel, Soham Dan, Keerthiram Murugesan |  |
| 591 |  |  [GPT-who: An Information Density-based Machine-Generated Text Detector](https://doi.org/10.18653/v1/2024.findings-naacl.8) |  | 0 | The Uniform Information Density (UID) principle posits that humans prefer to spread information evenly during language production. We examine if this UID principle can help capture differences between Large Language Models (LLMs)-generated and human-generated texts. We propose GPT-who, the first psycholinguistically-inspired domain-agnostic statistical detector. This detector employs UID-based featuresto model the unique statistical signature of each LLM and... | Saranya Venkatraman, Adaku Uchendu, Dongwon Lee |  |
| 592 |  |  [DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder Transformer Models](https://doi.org/10.18653/v1/2024.findings-naacl.9) |  | 0 | Encoder-decoder transformer models have achieved great success on various vision-language (VL) and language tasks, but they suffer from high inference latency. Typically, the decoder takes up most of the latency because of the auto-regressive decoding. To accelerate the inference, we propose an approach of performing Dynamic Early Exit on Decoder (DEED). We build a multi-exit encoder-decoder transformer model which is trained with deep supervision so that... | Peng Tang, Pengkai Zhu, Tian Li, Srikar Appalaraju, Vijay Mahadevan, R. Manmatha |  |
| 593 |  |  [Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation](https://doi.org/10.18653/v1/2024.findings-naacl.10) |  | 0 | An ideal length-extrapolatable Transformer language model can handle sequences longer than the training length without any fine-tuning. Such long-context utilization capability relies heavily on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However,... | TaChung Chi, TingHan Fan, Alexander Rudnicky |  |
| 594 |  |  [Automatic Pair Construction for Contrastive Post-training](https://doi.org/10.18653/v1/2024.findings-naacl.11) |  | 0 | Alignment serves as an important step to steer large language models (LLMs) towards human preferences. In this paper, we propose an automatic way to construct contrastive data for LLM, using preference pairs from multiple models of varying strengths (e.g., InstructGPT, ChatGPT and GPT-4). We compare the contrastive techniques of SLiC and DPO to SFT baselines and find that DPO provides a step-function improvement even after continuing SFT saturates. We also... | Canwen Xu, Corby Rosset, Ethan C. Chau, Luciano Del Corro, Shweti Mahajan, Julian J. McAuley, Jennifer Neville, Ahmed Awadallah, Nikhil Rao |  |
| 595 |  |  [Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.12) |  | 0 | Fact-checking is an essential task in NLP that is commonly utilized to validate the factual accuracy of a piece of text. Previous approaches mainly involve the resource-intensive process of fine-tuning pre-trained language models on specific datasets. In addition, there is a notable gap in datasets that focus on fact-checking texts generated by large language models (LLMs). In this paper, we introduce Self-Checker, a plug-and-play framework that harnesses... | Miaoran Li, Baolin Peng, Michel Galley, Jianfeng Gao, Zhu Zhang |  |
| 596 |  |  [Low-resource neural machine translation with morphological modeling](https://doi.org/10.18653/v1/2024.findings-naacl.13) |  | 0 | Morphological modeling in neural machine translation (NMT) is a promising approach to achieving open-vocabulary machine translation for morphologically-rich languages. However, existing methods such as sub-word tokenization and character-based models are limited to the surface forms of the words. In this work, we propose a framework-solution for modeling complex morphology in low-resource settings. A two-tier transformer architecture is chosen to encode... | Antoine Nzeyimana |  |
| 597 |  |  [Self-Cleaning: Improving a Named Entity Recognizer Trained on Noisy Data with a Few Clean Instances](https://doi.org/10.18653/v1/2024.findings-naacl.14) |  | 0 | To achieve state-of-the-art performance, one still needs to train NER models on large-scale, high-quality annotated data, an asset that is both costly and time-intensive to accumulate. In contrast, real-world applications often resort to massive low-quality labeled data through non-expert annotators via crowdsourcing and external knowledge bases via distant supervision as a cost-effective alternative. However, these annotation methods result in noisy labels,... | Zhendong Chu, Ruiyi Zhang, Tong Yu, Rajiv Jain, Vlad I. Morariu, Jiuxiang Gu, Ani Nenkova |  |
| 598 |  |  [VLUE: A New Benchmark and Multi-task Knowledge Transfer Learning for Vietnamese Natural Language Understanding](https://doi.org/10.18653/v1/2024.findings-naacl.15) |  | 0 | The success of Natural Language Understanding (NLU) benchmarks in various languages, such as GLUE for English, CLUE for Chinese, KLUE for Korean, and IndoNLU for Indonesian, has facilitated the evaluation of new NLU models across a wide range of tasks. To establish a standardized set of benchmarks for Vietnamese NLU, we introduce the first Vietnamese Language Understanding Evaluation (VLUE) benchmark. The VLUE benchmark encompasses five datasets covering... | Phong Do, Son Tran, Phu Hoang, Kiet Van Nguyen, Ngan LuuThuy Nguyen |  |
| 599 |  |  [LETI: Learning to Generate from Textual Interactions](https://doi.org/10.18653/v1/2024.findings-naacl.16) |  | 0 | Fine-tuning pre-trained language models (LMs) is essential for enhancing their capabilities.Existing techniques commonly fine-tune on input-output pairs (e.g., instruction tuning) or with numerical rewards that gauge the output quality (e.g., RLHF). We explore LMs’ potential to \*\*le\*\*arn from \*\*t\*\*extual \*\*i\*\*nteractions (\*\*LETI\*\*) that not only check their correctness with \*binary labels\* but also pinpoint and explain errors in their... | Xingyao Wang, Hao Peng, Reyhaneh Jabbarvand, Heng Ji |  |
| 600 |  |  [Bilateral Masking with prompt for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-naacl.17) |  | 0 | The pre-trained language model (PLM) has achieved significant success in the field of knowledge graph completion (KGC) by effectively modeling entity and relation descriptions. In recent studies, the research in this field has been categorized into methods based on word matching and sentence matching, with the former significantly lags behind. However, there is a critical issue in word matching methods, which is that these methods fail to obtain satisfactory... | Yonghui Kong, Cunhang Fan, Yujie Chen, Shuai Zhang, Zhao Lv, Jianhua Tao |  |
| 601 |  |  [MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.18) |  | 0 | Generative language models are usually pre-trained on large text corpus via predicting the next token (i.e., sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language models on downstream tasks. However, existing generative language models generally neglect an inherent challenge in text corpus during training, i.e., the imbalance between frequent tokens and infrequent ones. It can... | Zhenpeng Su, Zijia Lin, Bai Xue, Hui Chen, Guiguang Ding, Wei Zhou, Songlin Hu |  |
| 602 |  |  [GOLD: Geometry Problem Solver with Natural Language Description](https://doi.org/10.18653/v1/2024.findings-naacl.19) |  | 0 | Addressing the challenge of automated geometry math problem-solving in artificial intelligence (AI) involves understanding multi-modal information and mathematics. blackCurrent methods struggle with accurately interpreting geometry diagrams, which hinders effective problem-solving. To tackle this issue, we present the Geometry problem sOlver with natural Language Description (GOLD) model. GOLD enhances the extraction of geometric relations by separately... | Jiaxin Zhang, Yashar Moshfeghi |  |
| 603 |  |  [RoDia: A New Dataset for Romanian Dialect Identification from Speech](https://doi.org/10.18653/v1/2024.findings-naacl.20) |  | 0 | We introduce RoDia, the first dataset for Romanian dialect identification from speech. The RoDia dataset includes a varied compilation of speech samples from five distinct regions of Romania, covering both urban and rural environments, totaling 2 hours of manually annotated speech data. Along with our dataset, we introduce a set of competitive models to be used as baselines for future research. The top scoring model achieves a macro F1 score of 59.83% and a... | Rotaru Codrut, NicolaeCatalin Ristea, Radu Tudor Ionescu |  |
| 604 |  |  [Examining Modularity in Multilingual LMs via Language-Specialized Subnetworks](https://doi.org/10.18653/v1/2024.findings-naacl.21) |  | 0 | Recent work has proposed explicitly inducing language-wise modularity in multilingual LMs via sparse fine-tuning (SFT) on per-language subnetworks as a means of better guiding cross-lingual sharing. In this paper, we investigate (1) the degree to which language-wise modularity \*naturally\* arises within models with no special modularity interventions, and (2) how cross-lingual sharing and interference differ between such models and those with explicit... | Rochelle Choenni, Ekaterina Shutova, Dan Garrette |  |
| 605 |  |  [Reverse Chain: A Generic-Rule for LLMs to Master Multi-API Planning](https://doi.org/10.18653/v1/2024.findings-naacl.22) |  | 0 | While enabling large language models to implement function calling (known as APIs) can greatly enhance the performance of Large Language Models (LLMs), function calling is still a challenging task due to the complicated relations between different APIs, especially in a context-learning setting without fine-tuning. This paper introduces “Reverse Chain”, a controllable, target-driven approach designed to empower LLMs with the capability to operate external APIs... | Yinger Zhang, Hui Cai, Xierui Song, Yicheng Chen, Rui Sun, Jing Zheng |  |
| 606 |  |  [Incorporating Exponential Smoothing into MLP: a Simple but Effective Sequence Model](https://doi.org/10.18653/v1/2024.findings-naacl.23) |  | 0 | Modeling long-range dependencies in sequential data is a crucial step in sequence learning. A recently developed model, the Structured State Space (S4), demonstrated significant effectiveness in modeling long-range sequences. However, It is unclear whether the success of S4 can be attributed to its intricate parameterization and HiPPO initialization or simply due to State Space Models (SSMs). To further investigate the potential of the deep SSMs, we start... | Jiqun Chu, Zuoquan Lin |  |
| 607 |  |  [OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models](https://doi.org/10.18653/v1/2024.findings-naacl.24) |  | 0 | Object navigation (ObjectNav) requires an agent to navigate through unseen environments to find queried objects. Many previous methods attempted to solve this task by relying on supervised or reinforcement learning, where they are trained on limited household datasets with close-set objects. However, two key challenges are unsolved: understanding free-form natural language instructions that demand open-set objects, and generalizing to new environments in a... | Yuxuan Kuang, Hai Lin, Meng Jiang |  |
| 608 |  |  [Comparing Two Model Designs for Clinical Note Generation; Is an LLM a Useful Evaluator of Consistency?](https://doi.org/10.18653/v1/2024.findings-naacl.25) |  | 0 | Following an interaction with a patient, physicians are responsible for the submission of clinical documentation, often organized as a SOAP note. A clinical note is not simply a summary of the conversation but requires the use of appropriate medical terminology. The relevant information can then be extracted and organized according to the structure of the SOAP note. In this paper we analyze two different approaches to generate the different sections of a SOAP... | Nathan Brake, Thomas Schaaf |  |
| 609 |  |  [VOLTA: Improving Generative Diversity by Variational Mutual Information Maximizing Autoencoder](https://doi.org/10.18653/v1/2024.findings-naacl.26) |  | 0 | The natural language generation domain has witnessed great success thanks to Transformer models. Although they have achieved state-of-the-art generative quality, they often neglect generative diversity. Prior attempts to tackle this issue suffer from either low model capacity or over-complicated architectures. Some recent methods employ the VAE framework to enhance diversity, but their latent variables fully depend on the input context, restricting... | Yueen Ma, Dafeng Chi, Jingjing Li, Kai Song, Yuzheng Zhuang, Irwin King |  |
| 610 |  |  [EcoSpeak: Cost-Efficient Bias Mitigation for Partially Cross-Lingual Speaker Verification](https://doi.org/10.18653/v1/2024.findings-naacl.27) |  | 0 | Linguistic bias is a critical problem concerning the diversity, equity, and inclusiveness of Natural Language Processing tools. The severity of this problem intensifies in security systems, such as speaker verification, where fairness is paramount. Speaker verification systems are biometric systems that determine whether two speech recordings are of the same speaker. Such user-centric systems should be inclusive to bilingual speakers. However, Deep neural... | Divya V. Sharma |  |
| 611 |  |  [Leveraging Contextual Information for Effective Entity Salience Detection](https://doi.org/10.18653/v1/2024.findings-naacl.28) |  | 0 | In text documents such as news articles, the content and key events usually revolve around a subset of all the entities mentioned in a document. These entities, often deemed as salient entities, provide useful cues of the aboutness of a document to a reader. Identifying the salience of entities was found helpful in several downstream applications such as search, ranking, and entity-centric summarization, among others. Prior work on salient entity detection... | Rajarshi Bhowmik, Marco Ponza, Atharva Tendle, Anant Gupta, Rebecca Jiang, Xingyu Lu, Qian Zhao, Daniel PreotiucPietro |  |
| 612 |  |  [LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?](https://doi.org/10.18653/v1/2024.findings-naacl.29) |  | 0 | With the rapid development and widespread application of Large Language Models (LLMs), the use of Machine-Generated Text (MGT) has become increasingly common, bringing with it potential risks, especially in terms of quality and integrity in fields like news, education, and science. Current research mainly focuses on purely MGT detection, without adequately addressing mixed scenarios including AI-revised Human-Written Text (HWT) or human-revised MGT. To tackle... | Qihui Zhang, Chujie Gao, Dongping Chen, Yue Huang, Yixin Huang, Zhenyang Sun, Shilin Zhang, Weiye Li, Zhengyan Fu, Yao Wan, Lichao Sun |  |
| 613 |  |  [A (More) Realistic Evaluation Setup for Generalisation of Community Models on Malicious Content Detection](https://doi.org/10.18653/v1/2024.findings-naacl.30) |  | 0 | Community models for malicious content detection, which take into account the context from a social graph alongside the content itself, have shown remarkable performance on benchmark datasets. Yet, misinformation and hate speech continue to propagate on social media networks. This mismatch can be partially attributed to the limitations of current evaluation setups that neglect the rapid evolution of online content and the underlying social graph. In this... | Ivo Verhoeven, Pushkar Mishra, Rahel Beloch, Helen Yannakoudakis, Ekaterina Shutova |  |
| 614 |  |  [Citation: A Key to Building Responsible and Accountable Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.31) |  | 0 | Large Language Models (LLMs) bring transformative benefits alongside unique challenges, including intellectual property (IP) and ethical concerns. This position paper explores a novel angle to mitigate these risks, drawing parallels between LLMs and established web systems. We identify “citation”—the acknowledgement or reference to a source or evidence—as a crucial yet missing component in LLMs. Incorporating citation could enhance content transparency and... | Jie Huang, Kevin Chang |  |
| 615 |  |  [Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational AutoEncoders](https://doi.org/10.18653/v1/2024.findings-naacl.32) |  | 0 | The injection of syntactic information in Variational AutoEncoders (VAEs) can result in an overall improvement of performances and generalisation. An effective strategy to achieve such a goal is to separate the encoding of distributional semantic features and syntactic structures into heterogeneous latent spaces via multi-task learning or dual encoder architectures. However, existing works employing such techniques are limited to LSTM-based VAEs. This work... | Yingji Zhang, Marco Valentino, Danilo S. Carvalho, Ian PrattHartmann, André Freitas |  |
| 616 |  |  [Narrowing the Gap between Zero- and Few-shot Machine Translation by Matching Styles](https://doi.org/10.18653/v1/2024.findings-naacl.33) |  | 0 | Large language models trained primarily in a monolingual setting have demonstrated their ability to generalize to machine translation using zero- and few-shot examples with in-context learning. However, even though zero-shot translations are relatively good, there remains a discernible gap comparing their performance with the few-shot setting. In this paper, we investigate the factors contributing to this gap and find that this gap can largely be closed (for... | Weiting Tan, Haoran Xu, Lingfeng Shen, Shuyue Stella Li, Kenton Murray, Philipp Koehn, Benjamin Van Durme, Yunmo Chen |  |
| 617 |  |  [Which Modality should I use - Text, Motif, or Image? : Understanding Graphs with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.34) |  | 0 | Our research integrates graph data with Large Language Models (LLMs), which, despite their advancements in various fields using large text corpora, face limitations in encoding entire graphs due to context size constraints. This paper introduces a new approach to encoding a graph with diverse modalities, such as text, image, and motif, coupled with prompts to approximate a graph’s global connectivity, thereby enhancing LLMs’ efficiency in processing complex... | Debarati Das, Ishaan Gupta, Jaideep Srivastava, Dongyeop Kang |  |
| 618 |  |  [On-the-Fly Fusion of Large Language Models and Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.35) |  | 0 | We propose on-the-fly ensembling of a neural machine translation (NMT) model with a large language model (LLM), prompted on the same task and input. Through experiments on 4 language directions with varying data amounts, we find that a slightly weaker-at-translation LLM can improve translations of a NMT model, and such an ensemble can produce better translations than ensembling two stronger NMT models.We demonstrate that our ensemble method can be combined... | Hieu Hoang, Huda Khayrallah, Marcin JunczysDowmunt |  |
| 619 |  |  [READ: Improving Relation Extraction from an ADversarial Perspective](https://doi.org/10.18653/v1/2024.findings-naacl.36) |  | 0 | Recent works in relation extraction (RE) have achieved promising benchmark accuracy; however, our adversarial attack experiments show that these works excessively rely on entities, making their generalization capability questionable. To address this issue, we propose an adversarial training method specifically designed for RE. Our approach introduces both sequence- and token-level perturbations to the sample and uses a separate perturbation vocabulary to... | Dawei Li, William Hogan, Jingbo Shang |  |
| 620 |  |  [REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.37) |  | 0 | The extensive scope of large language models (LLMs) across various domains underscores the critical importance of responsibility in their application, beyond natural language processing. In particular, the randomized nature of LLMs, coupled with inherent biases and historical stereotypes in data, raises critical concerns regarding reliability and equity. Addressing these challenges are necessary before using LLMs for applications with societal impact. Towards... | Sana Ebrahimi, Nima Shahbazi, Abolfazl Asudeh |  |
| 621 |  |  [Addressing Both Statistical and Causal Gender Fairness in NLP Models](https://doi.org/10.18653/v1/2024.findings-naacl.38) |  | 0 | Statistical fairness stipulates equivalent outcomes for every protected group, whereas causal fairness prescribes that a model makes the same prediction for an individual regardless of their protected characteristics. Counterfactual data augmentation (CDA) is effective for reducing bias in NLP models, yet models trained with CDA are often evaluated only on metrics that are closely tied to the causal fairness notion; similarly, sampling-based methods designed... | Hannah Chen, Yangfeng Ji, David Evans |  |
| 622 |  |  [LLM-Rec: Personalized Recommendation via Prompting Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.39) |  | 0 | Text-based recommendation holds a wide range of practical applications due to its versatility, as textual descriptions can represent nearly any type of item. However, directly employing the original item descriptions may not yield optimal recommendation performance due to the lack of comprehensive information to align with user preferences. Recent advances in large language models (LLMs) have showcased their remarkable ability to harness commonsense knowledge... | Hanjia Lyu, Song Jiang, Hanqing Zeng, Yinglong Xia, Qifan Wang, Si Zhang, Ren Chen, Christopher Leung, Jiajie Tang, Jiebo Luo |  |
| 623 |  |  [A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://doi.org/10.18653/v1/2024.findings-naacl.40) |  | 0 | Large language models (LLMs) have show their remarkable ability in various natural language tasks. However, there are concerns that LLMs are possible to be used improperly or even illegally. To prevent the malicious usage of LLMs, detecting LLM-generated text becomes crucial in the deployment of LLM applications. Watermarking is an effective strategy to detect the LLM-generated content by encoding a pre-defined secret watermark to facilitate the detection... | Jie Ren, Han Xu, Yiding Liu, Yingqian Cui, Shuaiqiang Wang, Dawei Yin, Jiliang Tang |  |
| 624 |  |  [Solving Data-centric Tasks using Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.41) |  | 0 | Large language models are rapidly replacing help forums like StackOverflow, and are especially helpful to non-professional programmers and end users. These users are often interested in data-centric tasks, like spreadsheet manipulation and data wrangling, which are hard to solve if the intent is only communicated using a natural-language description, without including data. But how do we decide how much data and which data to include in the prompt?This paper... | Shraddha Barke, Christian Pölitz, Carina Negreanu, Benjamin Zorn, José Cambronero, Andrew D. Gordon, Vu Le, Elnaz Nouri, Nadia Polikarpova, Advait Sarkar, Brian Slininger, Neil Toronto, Jack Williams |  |
| 625 |  |  [A Novel Paradigm Boosting Translation Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.42) |  | 0 | This paper presents a study on strategies to enhance the translation capabilities of large language models (LLMs) in the context of machine translation (MT) tasks. The paper proposes a novel paradigm consisting of three stages: Secondary Pre-training using Extensive Monolingual Data, Continual Pre-training with Interlinear Text Format Documents, and Leveraging Source-Language Consistent Instruction for Supervised Fine-Tuning. Previous research on LLMs focused... | Jiaxin Guo, Hao Yang, Zongyao Li, Daimeng Wei, Hengchao Shang, Xiaoyu Chen |  |
| 626 |  |  [Measuring Social Norms of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.43) |  | 0 | We present a new challenge to examine whether large language models understand social norms. In contrast to existing datasets, our dataset requires a fundamental understanding of social norms to solve. Our dataset features the largest set of social norm skills, consisting of 402 skills and 12,383 questions covering a wide set of social norms ranging from opinions and arguments to culture and laws. We design our dataset according to the K-12 curriculum. This... | Ye Yuan, Kexin Tang, Jianhao Shen, Ming Zhang, Chenguang Wang |  |
| 627 |  |  [Source-Free Unsupervised Domain Adaptation for Question Answering via Prompt-Assisted Self-learning](https://doi.org/10.18653/v1/2024.findings-naacl.44) |  | 0 | This work addresses source-free domain adaptation (SFDA) for Question Answering (QA), wherein a model trained on a source domain is adapted to unlabeled target domains without additional source data. Existing SFDA methods only focus on the adaptation phase, overlooking the impact of source domain training on model generalizability. In this paper, we argue that source model training itself is also critical for improving the adaptation performance and... | Maxwell Yin, Boyu Wang, Charles Ling |  |
| 628 |  |  [Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level](https://doi.org/10.18653/v1/2024.findings-naacl.45) |  | 0 | Scientific document summarization has been a challenging task due to the long structure of the input text. The long input hinders the simultaneous effective modeling of both global high-order relations between sentences and local intra-sentence relations which is the most critical step in extractive summarization. However, existing methods mostly focus on one type of relation, neglecting the simultaneous effective modeling of both relations, which can lead to... | Chenlong Zhao, Xiwen Zhou, Xiaopeng Xie, Yong Zhang |  |
| 629 |  |  [LEEETs-Dial: Linguistic Entrainment in End-to-End Task-oriented Dialogue systems](https://doi.org/10.18653/v1/2024.findings-naacl.46) |  | 0 | Linguistic entrainment, or alignment, represents a phenomenon where linguistic patterns employed by conversational participants converge to one another. While entrainment has been shown to produce a more natural user experience, most dialogue systems do not have any provisions for it. In this work, we introduce methods for achieving dialogue entrainment in a GPT-2-based end-to-end task-oriented dialogue system through the utilization of shared vocabulary. We... | Nalin Kumar, Ondrej Dusek |  |
| 630 |  |  [Efficient Dependency Tree Sampling Without Replacement](https://doi.org/10.18653/v1/2024.findings-naacl.47) |  | 0 | In the context of computational models of dependency syntax, most dependency treebanks have the restriction that any valid dependency tree must have exactly one edge coming out of the root node in addition to respecting the spanning tree constraints. Many algorithms for dependency tree sampling were recently proposed, both for sampling with and without replacement.In this paper we propose a new algorithm called Wilson Reject SWOR for the case of sampling... | Bogdan Dobre |  |
| 631 |  |  [Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization](https://doi.org/10.18653/v1/2024.findings-naacl.48) |  | 0 | Open-domain Question Answering (OpenQA) aims at answering factual questions with an external large-scale knowledge corpus. However, real-world knowledge is not static; it updates and evolves continually. Such a dynamic characteristic of knowledge poses a vital challenge for these models, as the trained models need to constantly adapt to the latest information to make sure that the answers remain accurate. In addition, it is still unclear how well an OpenQA... | Zixuan Zhang, Revanth Gangi Reddy, Kevin Small, Tong Zhang, Heng Ji |  |
| 632 |  |  [GEE! Grammar Error Explanation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.49) |  | 0 | Existing grammatical error correction tools do not provide natural language explanations of the errors that they correct in user-written text. However, such explanations are essential for helping users learn the language by gaining a deeper understanding of its grammatical rules (DeKeyser, 2003; Ellis et al., 2006).To address this gap, we propose the task of grammar error explanation, where a system needs to provide one-sentence explanations for each... | Yixiao Song, Kalpesh Krishna, Rajesh Bhatt, Kevin Gimpel, Mohit Iyyer |  |
| 633 |  |  [AdaRefiner: Refining Decisions of Language Models with Adaptive Feedback](https://doi.org/10.18653/v1/2024.findings-naacl.50) |  | 0 | Large Language Models (LLMs) have demonstrated significant success across various domains. However, their application in complex decision-making tasks frequently necessitates intricate prompt engineering or fine-tuning, leading to challenges in unseen downstream tasks and heavy demands on computational resources. Meanwhile, Reinforcement Learning (RL) has been recognized as effective in decision-making problems but struggles in environments with sparse... | Wanpeng Zhang, Zongqing Lu |  |
| 634 |  |  [DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented Dialogue Representations](https://doi.org/10.18653/v1/2024.findings-naacl.51) |  | 0 | Language models pre-trained on general text have achieved impressive results in diverse fields. Yet, the distinct linguistic characteristics of task-oriented dialogues (TOD) compared to general text limit the practical utility of existing language models. Current task-oriented dialogue pre-training methods overlook the one-to-many property of conversations, where multiple responses can be appropriate given the same conversation context.In this paper, we... | Weihao Zeng, Dayuan Fu, Keqing He, Yejie Wang, Yukai Xu, Weiran Xu |  |
| 635 |  |  [Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training](https://doi.org/10.18653/v1/2024.findings-naacl.52) |  | 0 | Recent advancements in language modeling have led to the emergenceof Large Language Models (LLMs) capable ofvarious natural language processing tasks.Despite their success in text-based tasks, applying LLMs to the speech domainremains limited and challenging. This paper presents BLOOMZMMS, a novel modelthat integrates a multilingual LLM with a multilingual speech encoder,aiming to harness the capabilities of LLMs for speech recognition and beyond.Utilizing a... | Pavel Denisov, Thang Vu |  |
| 636 |  |  [CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.53) |  | 0 | We are currently in an era of fierce competition among various large language models (LLMs), continuously pushing the boundaries of benchmark performance. However, genuinely assessing the capabilities of these LLMs has become a challenging and critical issue due to potential data contamination. In this paper, we propose a novel and valuable method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs more cleanly. Clean-Eval... | Wenhong Zhu, Hongkun Hao, Zhiwei He, Yunze Song, Jiao Yueyang, Yumeng Zhang, Hanxu Hu, Yiran Wei, Rui Wang, Hongyuan Lu |  |
| 637 |  |  [R-BASS : Relevance-aided Block-wise Adaptation for Speech Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.54) |  | 0 | End-to-end speech summarization on long recordings is challenging because of the high computational cost. Block-wise Adaptation for Speech Summarization (BASS) summarizes arbitrarily long sequences by sequentially processing abutting chunks of audio. Despite the benefits of BASS, it has higher compute time due to sequential processing of all blocks, regardless of whether they are relevant to the final summary. In this paper, we propose R-BASS, a new... | Roshan Sharma, Ruchira Sharma, Hira Dhamyal, Rita Singh, Bhiksha Raj |  |
| 638 |  |  [OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.55) |  | 0 |  | Fei Yu, Anningzhe Gao, Benyou Wang |  |
| 639 |  |  [The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation](https://doi.org/10.18653/v1/2024.findings-naacl.56) |  | 0 | Large language models (LLMs) have shown excellent performance on various NLP tasks. To use LLMs as strong sequential recommenders, we explore the in-context learning approach to sequential recommendation. We investigate the effects of instruction format, task consistency, demonstration selection, and number of demonstrations. As increasing the number of demonstrations in ICL does not improve accuracy despite using a long prompt, we propose a novel method... | Lei Wang, EePeng Lim |  |
| 640 |  |  [Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA](https://doi.org/10.18653/v1/2024.findings-naacl.57) |  | 0 | We present BYOKG, a universal question-answering (QA) system that can operate on any knowledge graph (KG), requires no human-annotated training data, and can be ready to use within a day—attributes that are out-of-scope for current KGQA systems. BYOKG draws inspiration from the remarkable ability of humans to comprehend information present in an unseen KG through exploration—starting at random nodes, inspecting the labels of adjacent nodes and edges, and... | Dhruv Agarwal, Rajarshi Das, Sopan Khosla, Rashmi Gangadharaiah |  |
| 641 |  |  [GraSAME: Injecting Token-Level Structural Information to Pretrained Language Models via Graph-guided Self-Attention Mechanism](https://doi.org/10.18653/v1/2024.findings-naacl.58) |  | 0 | Pretrained Language Models (PLMs) benefit from external knowledge stored in graph structures for various downstream tasks. However, bridging the modality gap between graph structures and text remains a significant challenge. Traditional methods like linearizing graphs for PLMs lose vital graph connectivity, whereas Graph Neural Networks (GNNs) require cumbersome processes for integration into PLMs. In this work, we propose a novel graph-guided self-attention... | Shuzhou Yuan, Michael Färber |  |
| 642 |  |  [Can Public Large Language Models Help Private Cross-device Federated Learning?](https://doi.org/10.18653/v1/2024.findings-naacl.59) |  | 0 | We study (differentially) private federated learning (FL) of language models. The language models in cross-device FL are relatively small, which can be trained with meaningful formal user-level differential privacy (DP) guarantees when massive parallelism in training is enabled by the participation of a moderate size of users. Recently, public data has been used to improve privacy-utility trade-offs for both large and small language models. In this work, we... | Boxin Wang, Yibo Zhang, Yuan Cao, Bo Li, Hugh McMahan, Sewoong Oh, Zheng Xu, Manzil Zaheer |  |
| 643 |  |  [LangNav: Language as a Perceptual Representation for Navigation](https://doi.org/10.18653/v1/2024.findings-naacl.60) |  | 0 | We explore the use of language as a perceptual representation for vision-and-language navigation (VLN), with a focus on low-data settings. Our approach uses off-the-shelf vision systems for image captioning and object detection to convert an agent’s egocentric panoramic view at each time step into natural language descriptions. We then finetune a pretrained language model to select an action, based on the current view and the trajectory history, that would... | Bowen Pan, Rameswar Panda, SouYoung Jin, Rogério Feris, Aude Oliva, Phillip Isola, Yoon Kim |  |
| 644 |  |  [Planning and Editing What You Retrieve for Enhanced Tool Learning](https://doi.org/10.18653/v1/2024.findings-naacl.61) |  | 0 | Recent advancements in integrating external tools with Large Language Models (LLMs) have opened new frontiers, with applications in mathematical reasoning, code generators, and smart assistants. However, existing methods, relying on simple one-time retrieval strategies, fall short on effectively and accurately shortlisting relevant tools. This paper introduces a novel PLUTO (Planning, Learning, and Understanding for TOols) approach, encompassing... | Tenghao Huang, Dongwon Jung, Vaibhav Kumar, Mohammad Kachuee, Xiang Li, Puyang Xu, Muhao Chen |  |
| 645 |  |  [Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs](https://doi.org/10.18653/v1/2024.findings-naacl.62) |  | 0 | Vision-language models (VLMs) are achieving increasingly strong performance on multimodal tasks. However, reasoning capabilities remain limited particularly for smaller VLMs, while those of large-language models (LLMs) have seen numerous improvements. We pro-pose a technique to transfer capabilities from LLMs to VLMs. On the recently introduced ChartQA, our method obtains state-of-the-artperformance when applied on the PaLI3-5B VLM by Chen et al. (2023c),... | Victor Carbune, Hassan Mansoor, Fangyu Liu, Rahul Aralikatte, Gilles Baechler, Jindong Chen, Abhanshu Sharma |  |
| 646 |  |  [SLiM: Speculative Decoding with Hypothesis Reduction](https://doi.org/10.18653/v1/2024.findings-naacl.63) |  | 0 | Speculative decoding has emerged as a prominent alternative to autoregressive decoding for expediting inference in large language models (LLMs). However, prevailing assumptions often focus solely on latency reduction, neglecting the computational expenses. In this paper, we present Speculate Less, validate More (SLiM), a speculative decoding enhancement to reduce the speculation set while validating more effective tokens. SLiM is designed to mitigate LLMs’... | ChiHeng Lin, Shikhar Tuli, James Seale Smith, YenChang Hsu, Yilin Shen, Hongxia Jin |  |
| 647 |  |  [REMATCH: Robust and Efficient Matching of Local Knowledge Graphs to Improve Structural and Semantic Similarity](https://doi.org/10.18653/v1/2024.findings-naacl.64) |  | 0 | Knowledge graphs play a pivotal role in various applications, such as question-answering and fact-checking. Abstract Meaning Representation (AMR) represents text as knowledge graphs. Evaluating the quality of these graphs involves matching them structurally to each other and semantically to the source text. Existing AMR metrics are inefficient and struggle to capture semantic similarity. We also lack a systematic evaluation benchmark for assessing structural... | Zoher Kachwala, Jisun An, Haewoon Kwak, Filippo Menczer |  |
| 648 |  |  [Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing](https://doi.org/10.18653/v1/2024.findings-naacl.65) |  | 0 | This position paper concerns the use of religious texts in Natural Language Processing (NLP), which is of special interest to the Ethics of NLP. Religious texts are expressions of culturally important values, and machine learned models have a propensity to reproduce cultural values encoded in their training data. Furthermore, translations of religious texts are frequently used by NLP researchers when language data is scarce. This repurposes the translations... | Ben Hutchinson |  |
| 649 |  |  [Testing the Effect of Code Documentation on Large Language Model Code Understanding](https://doi.org/10.18653/v1/2024.findings-naacl.66) |  | 0 | Large Language Models (LLMs) have demonstrated impressive abilities in recent years with regards to code generation and understanding. However, little work has investigated how documentation and other code properties affect an LLM’s ability to understand and generate code or documentation. We present an empirical analysis of how underlying properties of code or documentation can affect an LLM’s capabilities. We show that providing an LLM with “incorrect”... | William Macke, Michael Doyle |  |
| 650 |  |  [Aligning Large Language Models with Recommendation Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.67) |  | 0 | Large language models (LLMs) have recently been used as backbones for recommender systems. However, their performance often lags behind conventional methods in standard tasks like retrieval. We attribute this to a mismatch between LLMs’ knowledge and the knowledge crucial for effective recommendations. While LLMs excel at natural language reasoning, they cannot model complex user-item interactions inherent in recommendation tasks. We propose bridging the... | Yuwei Cao, Nikhil Mehta, Xinyang Yi, Raghunandan Hulikal Keshavan, Lukasz Heldt, Lichan Hong, Ed H. Chi, Maheswaran Sathiamoorthy |  |
| 651 |  |  [OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient Large-scale Multilingual Continued Pretraining](https://doi.org/10.18653/v1/2024.findings-naacl.68) |  | 0 |  | Yihong Liu, Peiqin Lin, Mingyang Wang, Hinrich Schütze |  |
| 652 |  |  [SELF-EXPERTISE: Knowledge-based Instruction Dataset Augmentation for a Legal Expert Language Model](https://doi.org/10.18653/v1/2024.findings-naacl.69) |  | 0 | The advent of instruction-tuned large language models (LLMs) has significantly advanced the field of automatic instruction dataset augmentation. However, the method of generating instructions and outputs from inherent knowledge of LLM can unintentionally produce hallucinations — instances of generating factually incorrect or misleading information. To overcome this, we propose SELF-EXPERTISE, automatically generating instruction dataset in the legal domain... | Minju Kim, Haein Jung, MyoungWan Koo |  |
| 653 |  |  [Re-evaluating the Need for Visual Signals in Unsupervised Grammar Induction](https://doi.org/10.18653/v1/2024.findings-naacl.70) |  | 0 | Are multimodal inputs necessary for grammar induction? Recent work has shown that multimodal training inputs can improve grammar induction. However, these improvements are based on comparisons to weak text-only baselines that were trained on relatively little textual data. To determine whether multimodal inputs are needed in regimes with large amounts of textual training data, we design a stronger text-only baseline, which we refer to as LC-PCFG. LC-PCFG is a... | Boyi Li, Rodolfo Corona, Karttikeya Mangalam, Catherine Chen, Daniel Flaherty, Serge J. Belongie, Kilian Q. Weinberger, Jitendra Malik, Trevor Darrell, Dan Klein |  |
| 654 |  |  [EDEntail: An Entailment-based Few-shot Text Classification with Extensional Definition](https://doi.org/10.18653/v1/2024.findings-naacl.71) |  | 0 | Few-shot text classification has seen significant advancements, particularly with entailment-based methods, which typically use either class labels or intensional definitions of class labels in hypotheses for label semantics expression. In this paper, we propose EDEntail, a method that employs extensional definition (EDef) of class labels in hypotheses, aiming to express the semantics of class labels more explicitly. To achieve the above goal, we develop an... | Zixiao Zhu, Junlang Qian, Zijian Feng, Hanzhang Zhou, Kezhi Mao |  |
| 655 |  |  [What Makes Math Word Problems Challenging for LLMs?](https://doi.org/10.18653/v1/2024.findings-naacl.72) |  | 0 | This paper investigates the question of what makes math word problems (MWPs) in English challenging for large language models (LLMs). We conduct an in-depth analysis of the key linguistic and mathematical characteristics of MWPs. In addition, we train feature-based classifiers to better understand the impact of each feature on the overall difficulty of MWPs for prominent LLMs and investigate whether this helps predict how well LLMs fare against specific... | KV Aditya Srivatsa, Ekaterina Kochmar |  |
| 656 |  |  [SMILE: Multimodal Dataset for Understanding Laughter in Video with Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.73) |  | 0 | Despite the recent advances in artificial intelligence, building social intelligence remains a challenge.Among social signals, laughter is one of the distinctive expressions that occurs during social interactions between humans.In this work, we tackle a new challenge for machines to understand the rationale behind laughter in video, Video Laugh Reasoning.We introduce this new task to explain why people laugh in a particular video and a dataset for this... | Lee Hyun, Kim SungBin, Seungju Han, Youngjae Yu, TaeHyun Oh |  |
| 657 |  |  [T3M: Text Guided 3D Human Motion Synthesis from Speech](https://doi.org/10.18653/v1/2024.findings-naacl.74) |  | 0 | Speech-driven 3D motion synthesis seeks to create lifelike animations based on human speech, with potential uses in virtual reality, gaming, and the film production. Existing approaches reply solely on speech audio for motion generation, leading to inaccurate and inflexible synthesis results. To mitigate this problem, we introduce a novel text-guided 3D human motion synthesis method, termed T3M. Unlike traditional approaches, T3M allows precise control over... | Wenshuo Peng, Kaipeng Zhang, Sai Qian Zhang |  |
| 658 |  |  [Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.75) |  | 0 | Temporal Knowledge Graph Reasoning (TKGR) is the task of inferring missing facts for incomplete TKGs in complex scenarios (e.g., transductive and inductive settings), which has been gaining increasing attention. Recently, to mitigate dependence on structured connections in TKGs, text-based methods have been developed to utilize rich linguistic information from entity descriptions. However, suffering from the enormous parameters and inflexibility of... | Miao Peng, Ben Liu, Wenjie Xu, Zihao Jiang, Jiahui Zhu, Min Peng |  |
| 659 |  |  [Explanation Extraction from Hierarchical Classification Frameworks for Long Legal Documents](https://doi.org/10.18653/v1/2024.findings-naacl.76) |  | 0 | Hierarchical classification frameworks have been widely used to process long sequences, especially in the legal domain for predictions from long legal documents. But being black-box models they are unable to explain their predictions making them less reliable for practical applications, more so in the legal domain. In this work, we develop an extractive explanation algorithm for hierarchical frameworks for long sequences based on the sensitivity of the... | Nishchal Prasad, Taoufiq Dkaki, Mohand Boughanem |  |
| 660 |  |  [Low-Rank Adaptation for Multilingual Summarization: An Empirical Study](https://doi.org/10.18653/v1/2024.findings-naacl.77) |  | 0 | Although the advancements of pre-trained Large Language Models have significantly accelerated recent progress in NLP, their ever-increasing size poses significant challenges for conventional fine-tuning, especially in memory-intensive tasks. We investigate the potential of Parameter-Efficient Fine-Tuning, focusing on Low-Rank Adaptation (LoRA), in the domain of multilingual summarization, a task that is both challenging (due to typically long inputs), and... | Chenxi Whitehouse, Fantine Huot, Jasmijn Bastings, Mostafa Dehghani, ChuCheng Lin, Mirella Lapata |  |
| 661 |  |  [A Tree-of-Thoughts to Broaden Multi-step Reasoning across Languages](https://doi.org/10.18653/v1/2024.findings-naacl.78) |  | 0 | Reasoning methods, best exemplified by the well-known Chain-of-Thought (CoT), empower the reasoning abilities of Large Language Models (LLMs) by eliciting them to solve complex tasks in a step-by-step manner. Although they are achieving significant success, the ability to deliver multi-step reasoning remains limited to English because of the imbalance in the distribution of pre-training data, which makes other languages a barrier. In this paper, we propose... | Leonardo Ranaldi, Giulia Pucci, Federico Ranaldi, Elena Sofia Ruzzetti, Fabio Massimo Zanzotto |  |
| 662 |  |  [Emergent Abilities in Reduced-Scale Generative Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.79) |  | 0 | Large language models can solve new tasks without task-specific fine-tuning. This ability, also known as in-context learning (ICL), is considered an emergent ability and is primarily seen in large language models with billions of parameters. This study investigates if such emergent properties are strictly tied to model size or can be demonstrated by smaller models trained on reduced-scale data. To explore this, we simplify pre-training data and pre-train 36... | Sherin Muckatira, Vijeta Deshpande, Vladislav Lialin, Anna Rumshisky |  |
| 663 |  |  [Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-naacl.80) |  | 0 | Crowdsourced labels play a crucial role in evaluating task-oriented dialogue systems (TDSs). Obtaining high-quality and consistent ground-truth labels from annotators presents challenges. When evaluating a TDS, annotators must fully comprehend the dialogue before providing judgments. Previous studies suggest using only a portion of the dialogue context in the annotation process. However, the impact of this limitation on label quality remains unexplored. This... | Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke |  |
| 664 |  |  [Matching Varying-Length Texts via Topic-Informed and Decoupled Sentence Embeddings](https://doi.org/10.18653/v1/2024.findings-naacl.81) |  | 0 | Measuring semantic similarity between texts is a crucial task in natural language processing. While existing semantic text matching focuses on pairs of similar-length sequences, matching texts with non-comparable lengths has broader applications in specific domains, such as comparing professional document summaries and content. Current approaches struggle with text pairs of non-comparable lengths due to truncation issues. To address this, we split texts into... | Xixi Zhou, Chunbin Gu, Xin Jie, Jiajun Bu, Haishuai Wang |  |
| 665 |  |  [Instruction Tuning with Human Curriculum](https://doi.org/10.18653/v1/2024.findings-naacl.82) |  | 0 | In this work, we (1) introduce Curriculum Instruction Tuning, (2) explore the potential advantages of employing diverse curriculum strategies, and (3) delineate a synthetic instruction-response generation framework that complements our theoretical approach. Distinct from the existing instruction tuning dataset, our generation pipeline is systematically structured to emulate the sequential and orderly characteristic of human learning. Additionally, we describe... | Bruce W. Lee, Hyunsoo Cho, Kang Min Yoo |  |
| 666 |  |  [Natural Language-based State Representation in Deep Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-naacl.83) |  | 0 | This paper investigates the potential of using natural language descriptions as an alternative to direct image-based observations for learning policies in reinforcement learning. Due to the inherent challenges in managing image-based observations, which include abundant information and irrelevant features, we propose a method that compresses images into a natural language form for state representation. This approach allows better interpretability and... | Md Masudur Rahman, Yexiang Xue |  |
| 667 |  |  [Learning Cross-Architecture Instruction Embeddings for Binary Code Analysis in Low-Resource Architectures](https://doi.org/10.18653/v1/2024.findings-naacl.84) |  | 0 | Binary code analysis is indispensable for a variety of software security tasks. Applying deep learning to binary code analysis has drawn great attention because of its notable performance. Today, source code is frequently compiled for various Instruction Set Architectures (ISAs). It is thus critical to expand binary analysis capabilities to multiple ISAs. Given a binary analysis task, the scale of available data on different ISAs varies. As a result, the rich... | Junzhe Wang, Qiang Zeng, Lannan Luo |  |
| 668 |  |  [ReEval: Automatic Hallucination Evaluation for Retrieval-Augmented Large Language Models via Transferable Adversarial Attacks](https://doi.org/10.18653/v1/2024.findings-naacl.85) |  | 0 | Despite remarkable advancements in mitigating hallucinations in large language models (LLMs) by retrieval augmentation, it remains challenging to measure the reliability of LLMs using static question-answering (QA) data. Specifically, given the potential of data contamination (e.g., leading to memorization), good static benchmark performance does not ensure that model can reliably use the provided evidence for responding, which is essential to avoid... | Xiaodong Yu, Hao Cheng, Xiaodong Liu, Dan Roth, Jianfeng Gao |  |
| 669 |  |  [An Effective Automated Speaking Assessment Approach to Mitigating Data Scarcity and Imbalanced Distribution](https://doi.org/10.18653/v1/2024.findings-naacl.86) |  | 0 | Automated speaking assessment (ASA) typically involves automatic speech recognition (ASR) and hand-crafted feature extraction from the ASR transcript of a learner’s speech. Recently, self-supervised learning (SSL) has shown stellar performance compared to traditional methods. However, SSL-based ASA systems are faced with at least three data-related challenges: limited annotated data, uneven distribution of learner proficiency levels and non-uniform score... | TienHong Lo, FuAn Chao, TzuI Wu, YaoTing Sung, Berlin Chen |  |
| 670 |  |  [GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond](https://doi.org/10.18653/v1/2024.findings-naacl.87) |  | 0 | With the rapid advancement of large language models (LLMs), there is a pressing need for a comprehensive evaluation suite to assess their capabilities and limitations. Existing LLM leaderboards often reference scores reported in other papers without consistent settings and prompts, which may inadvertently encourage cherry-picking favored settings and prompts for better results. In this work, we introduce GPT-Fathom, an open-source and reproducible LLM... | Shen Zheng, Yuyu Zhang, Yijie Zhu, Chenguang Xi, Pengyang Gao, Zhou Xun, Kevin Chang |  |
| 671 |  |  [Subword Attention and Post-Processing for Rare and Unknown Contextualized Embeddings](https://doi.org/10.18653/v1/2024.findings-naacl.88) |  | 0 | Word representations are an important aspect of Natural Language Processing (NLP). Representations are trained using large corpora, either as independent static embeddings or as part of a deep contextualized model. While word embeddings are useful, they struggle on rare and unknown words. As such, a large body of work has been done on estimating rare and unknown words. However, most of the methods focus on static embeddings, with few models focused on... | Raj Patel, Carlotta Domeniconi |  |
| 672 |  |  [UGIF-DataSet: A New Dataset for Cross-lingual, Cross-modal Sequential actions on the UI](https://doi.org/10.18653/v1/2024.findings-naacl.89) |  | 0 | Help documents are supposed to aid smartphone users in resolving queries such as “How to block calls from unknown numbers?”. However, given a query, identifying the right help document, understanding instructions from the document, and using them to resolve the issue at hand is challenging. The user experience may be enhanced by converting the instructions in the help document to a step-by-step tutorial overlaid on the phone UI. Successful execution of this... | Sagar Gubbi Venkatesh, Partha Talukdar, Srini Narayanan |  |
| 673 |  |  [SimSCOOD: Systematic Analysis of Out-of-Distribution Generalization in Fine-tuned Source Code Models](https://doi.org/10.18653/v1/2024.findings-naacl.90) |  | 0 | Large code datasets have become increasingly accessible for pre-training source code models. However, for the fine-tuning phase, obtaining representative training data that fully covers the code distribution for specific downstream tasks remains challenging due to the task-specific nature and limited labeling resources. These lead to out-of-distribution (OOD) generalization issues with unexpected model inference behaviors that have not been systematically... | Hossein Hajipour, Ning Yu, CristianAlexandru Staicu, Mario Fritz |  |
| 674 |  |  [Pruning as a Domain-specific LLM Extractor](https://doi.org/10.18653/v1/2024.findings-naacl.91) |  | 0 | Large Language Models (LLMs) have exhibited remarkable proficiency across a wide array of NLP tasks. However, the escalation in model size also engenders substantial deployment costs. While few efforts have explored model pruning techniques to reduce the size of LLMs, they mainly center on general or task-specific weights. This leads to suboptimal performance due to lacking specificity on the target domain or generality on different tasks when applied to... | Nan Zhang, Yanchi Liu, Xujiang Zhao, Wei Cheng, Runxue Bao, Rui Zhang, Prasenjit Mitra, Haifeng Chen |  |
| 675 |  |  [LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback](https://doi.org/10.18653/v1/2024.findings-naacl.92) |  | 0 | Recent large language models (LLM) areleveraging human feedback to improve theirgeneration quality. However, human feedbackis costly to obtain, especially during inference.In this work, we propose LLMRefine, aninference time optimization method to refineLLM’s output. The core idea is to usea learned fine-grained feedback model topinpoint defects and guide LLM to refinethem iteratively. Using original LLM as aproposal of edits, LLMRefine searches... | Wenda Xu, Daniel Deutsch, Mara Finkelstein, Juraj Juraska, Biao Zhang, Zhongtao Liu, William Yang Wang, Lei Li, Markus Freitag |  |
| 676 |  |  [Noisy Multi-Label Text Classification via Instance-Label Pair Correction](https://doi.org/10.18653/v1/2024.findings-naacl.93) |  | 0 | In noisy label learning, instance selection based on small-loss criteria has been proven to be highly effective. However, in the case of noisy multi-label text classification (NMLTC), the presence of noise is not limited to the instance-level but extends to the (instance-label) pair-level.This gives rise to two main challenges.(1) The loss information at the pair-level fails to capture the variations between instances. (2) There are two types of noise at the... | Pengyu Xu, Mingyang Song, Linkaida Liu, Bing Liu, Hongjian Sun, Liping Jing, Jian Yu |  |
| 677 |  |  [Composite Backdoor Attacks Against Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.94) |  | 0 | Large language models (LLMs) have demonstrated superior performance compared to previous methods on various tasks, and often serve as the foundation models for many researches and services. However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks. In this paper, we explore the vulnerability of LLMs through the lens of backdoor attacks. Different from existing backdoor attacks against LLMs, ours scatters multiple... | Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang |  |
| 678 |  |  [Adapting Fake News Detection to the Era of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.95) |  | 0 | In the age of large language models (LLMs) and the widespread adoption of AI-driven content creation, the landscape of information dissemination has witnessed a paradigm shift. With the proliferation of both human-written and machine-generated real and fake news, robustly and effectively discerning the veracity of news articles has become an intricate challenge. While substantial research has been dedicated to fake news detection, it has either assumed that... | Jinyan Su, Claire Cardie, Preslav Nakov |  |
| 679 |  |  [MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.96) |  | 0 | Due to the success of large-scale visual-language pretraining (VLP) models and the widespread use of image-text retrieval in industry areas, it is now critically necessary to reduce the model size and streamline their mobile-device deployment. Single- and dual-stream model structures are commonly used in image-text retrieval with the goal of closing the semantic gap between textual and visual modalities. While single-stream models use deep feature fusion to... | Youbo Lei, Feifei He, Chen Chen, Yingbin Mo, Sijia Li, Defeng Xie, Haonan Lu |  |
| 680 |  |  [Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting](https://doi.org/10.18653/v1/2024.findings-naacl.97) |  | 0 | Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets.We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these challenging ranking formulations. In this paper, we... | Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Le Yan, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, Michael Bendersky |  |
| 681 |  |  [FedLFC: Towards Efficient Federated Multilingual Modeling with LoRA-based Language Family Clustering](https://doi.org/10.18653/v1/2024.findings-naacl.98) |  | 0 | Federated Multilingual Modeling (FMM) plays a crucial role in the applications of natural language processing due to the increasing diversity of languages and the growing demand for data privacy. However, FMM faces limitations stemming from (1) the substantial communication costs in networking and (2) the conflicts arising from parameter interference between different languages. To address these challenges, we introduce a communication-efficient federated... | Zhihan Guo, Yifei Zhang, Zhuo Zhang, Zenglin Xu, Irwin King |  |
| 682 |  |  [Gaussian Process Optimization for Adaptable Multi-Objective Text Generation using Linearly-Weighted Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.99) |  | 0 | In multi-objective text generation, we aim to optimize over multiple weighted aspects (e.g., toxicity, semantic preservation, fluency) of the generated text. However, multi-objective weighting schemes may change dynamically in practice according to deployment requirements, evolving business needs, personalization requirements on edge devices, or the availability of new language models and/or objective requirements. Ideally, we need an efficient method to... | Mohammad Mahdi Abdollah Pour, Ali Pesaranghader, Eldan Cohen, Scott Sanner |  |
| 683 |  |  [Groundedness in Retrieval-augmented Long-form Generation: An Empirical Study](https://doi.org/10.18653/v1/2024.findings-naacl.100) |  | 0 | We present an empirical study of groundedness in long-form question answering (LFQA) by retrieval-augmented large language models (LLMs).In particular, we evaluate whether every generated sentence is grounded in the retrieved documents or the model’s pre-training data.Across 3 datasets and 4 model families, our findings reveal that a significant fraction of generated sentences are consistently ungrounded, even when those sentences contain correct ground-truth... | Alessandro Stolfo |  |
| 684 |  |  [TagDebias: Entity and Concept Tagging for Social Bias Mitigation in Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.101) |  | 0 | Pre-trained language models (PLMs) play a crucial role in various applications, including sensitive domains such as the hiring process. However, extensive research has unveiled that these models tend to replicate social biases present in their pre-training data, raising ethical concerns. In this study, we propose the TagDebias method, which proposes debiasing a dataset using type tags. It then proceeds to fine-tune PLMs on this debiased dataset. Experiments... | Mehrnaz Moslemi, Amal Zouaq |  |
| 685 |  |  [Improving Absent Keyphrase Generation with Diversity Heads](https://doi.org/10.18653/v1/2024.findings-naacl.102) |  | 0 | Keyphrase Generation (KPG) is the task of automatically generating appropriate keyphrases for a given text, with a wide range of real-world applications such as document indexing and tagging, information retrieval, and text summarization. NLP research makes a distinction between present and absent keyphrases based on whether a keyphrase is directly present as a sequence of words in the document during evaluation. However, present and absent keyphrases are... | Edwin Thomas, Sowmya Vajjala |  |
| 686 |  |  [mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?](https://doi.org/10.18653/v1/2024.findings-naacl.103) |  | 0 | Many pretrained multilingual models exhibit cross-lingual transfer ability, which is often attributed to a learned language-neutral representation during pretraining. However, it remains unclear what factors contribute to the learning of a language-neutral representation, and whether the learned language-neutral representation suffices to facilitate cross-lingual transfer. We propose a synthetic task, Multilingual Othello (mOthello), as a testbed to delve... | Tianze Hua, Tian Yun, Ellie Pavlick |  |
| 687 |  |  [Discovering and Mitigating Indirect Bias in Attention-Based Model Explanations](https://doi.org/10.18653/v1/2024.findings-naacl.104) |  | 0 | As the field of Natural Language Processing (NLP) increasingly adopts transformer-based models, the issue of bias becomes more pronounced. Such bias, manifesting through stereotypes and discriminatory practices, can disadvantage certain groups. Our study focuses on direct and indirect bias in the model explanations, where the model makes predictions relying heavily on identity tokens or associated contexts. We present a novel analysis of bias in model... | Farsheed Haque, Depeng Xu, Shuhan Yuan |  |
| 688 |  |  [i-Code V2: An Autoregressive Generation Framework over Vision, Language, and Speech Data](https://doi.org/10.18653/v1/2024.findings-naacl.105) |  | 0 | The convergence of text, visual, and audio data is crucial towards human-like artificial intelligence, however the current Vision-Language-Speech landscape is dominated by encoder-only models that lack generative abilities. We propose closing this gap with i-Code V2, one of the first models capable of generating natural language from any combination of Vision, Language, and Speech data. i-Code V2 leverages state-of-the-art single-modality encoders, combining... | Ziyi Yang, Mahmoud Khademi, Yichong Xu, Reid Pryzant, Yuwei Fang, Chenguang Zhu, Dongdong Chen, Yao Qian, Xuemei Gao, YiLing Chen, Robert Gmyr, Naoyuki Kanda, Noel Codella, Bin Xiao, Yu Shi, Lu Yuan, Takuya Yoshioka, Michael Zeng, Xuedong Huang |  |
| 689 |  |  [Think While You Write: Hypothesis Verification Promotes Faithful Knowledge-to-Text Generation](https://doi.org/10.18653/v1/2024.findings-naacl.106) |  | 0 | Knowledge-to-text generators often struggle to faithfully generate descriptions for the input facts: they may produce hallucinations that contradict the input, or describe facts not present in the input. To reduce hallucinations, we propose a decoding-only method, TWEAK (Think While Effectively Articulating Knowledge), which can be integrated with any generator without retraining. TWEAK treats the generated sequences at each decoding step and its future... | Yifu Qiu, Varun Embar, Shay B. Cohen, Benjamin Han |  |
| 690 |  |  [It's All Relative! - A Synthetic Query Generation Approach for Improving Zero-Shot Relevance Prediction](https://doi.org/10.18653/v1/2024.findings-naacl.107) |  | 0 | Large language models (LLMs) have shown promising ability to generate synthetic query-document pairs by prompting with as few as 8 demonstrations. This has enabled building better IR models, especially for tasks with no training data. Typically, such synthetic query generation (QGen) approaches condition on an input context (e.g. a text document) and generate a query relevant to that context, or condition the QGen additionally on the relevance label (e.g.... | Aditi Chaudhary, Karthik Raman, Michael Bendersky |  |
| 691 |  |  [RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.108) |  | 0 | Reinforcement learning from human feedback (RLHF) has been extensively employed to align large language models with user intent. However, proximal policy optimization (PPO) based RLHF is occasionally unstable requiring significant hyperparameter finetuning, and computationally expensive to maximize the estimated reward during alignment. Recently, direct preference optimization (DPO) is proposed to address those challenges. However, DPO often relies on... | Saeed Khaki, JinJin Li, Lan Ma, Liu Yang, Prathap Ramachandra |  |
| 692 |  |  [Hypernetwork-Assisted Parameter-Efficient Fine-Tuning with Meta-Knowledge Distillation for Domain Knowledge Disentanglement](https://doi.org/10.18653/v1/2024.findings-naacl.109) |  | 0 | Domain adaptation from labeled source domains to the target domain is important in practical summarization scenarios. However, the key challenge is domain knowledge disentanglement. In this work, we explore how to disentangle domain-invariant knowledge from source domains while learning specific knowledge of the target domain. Specifically, we propose a hypernetwork-assisted encoder-decoder architecture with parameter-efficient fine-tuning. It leverages a... | Changqun Li, Linlin Wang, Xin Lin, Shizhou Huang, Liang He |  |
| 693 |  |  [MICo: Preventative Detoxification of Large Language Models through Inhibition Control](https://doi.org/10.18653/v1/2024.findings-naacl.110) |  | 0 | Large Language Models (LLMs) are powerful tools which have been both dominant and commonplace in the field of Artificial Intelligence. Yet, LLMs have a tendency to devolve into toxic degeneration, wherein otherwise safe and unproblematic models begin generating toxic content. For the sake of social responsibility and inspired by the biological mechanisms of inhibition control, we introduce the paradigm of Education for Societal Norms (ESN). By collecting and... | Roy Siegelmann, Ninareh Mehrabi, Palash Goyal, Prasoon Goyal, Lisa Bauer, Jwala Dhamala, Aram Galstyan, Rahul Gupta, Reza Ghanadan |  |
| 694 |  |  [Reinforcement Learning with Token-level Feedback for Controllable Text Generation](https://doi.org/10.18653/v1/2024.findings-naacl.111) |  | 0 | To meet the requirements of real-world applications, it is essential to control generations of large language models (LLMs). Prior research has tried to introduce reinforcement learning (RL) into controllable text generation while most existing methods suffer from overfitting issues (finetuning-based methods) or semantic collapse (post-processing methods). However, current RL methods are generally guided by coarse-grained (sentence/paragraph-level) feedback,... | Wendi Li, Wei Wei, Kaihe Xu, Wenfeng Xie, Dangyang Chen, Yu Cheng |  |
| 695 |  |  [CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving](https://doi.org/10.18653/v1/2024.findings-naacl.112) |  | 0 | Large Language Models (LLMs) have shown great ability in solving traditional natural language tasks and elementary reasoning tasks with appropriate prompting techniques. However, their ability is still limited in solving complicated science problems. In this work, we aim to push the upper bound of the reasoning capability of LLMs by proposing a collaborative multi-agent, multi-reasoning-path (CoMM) prompting framework. Specifically, we prompt LLMs to play... | Pei Chen, Shuai Zhang, Boran Han |  |
| 696 |  |  [Tokenization Matters: Navigating Data-Scarce Tokenization for Gender Inclusive Language Technologies](https://doi.org/10.18653/v1/2024.findings-naacl.113) |  | 0 | Gender-inclusive NLP research has documented the harmful limitations of gender binary-centric large language models (LLM), such as the inability to correctly use gender-diverse English neopronouns (e.g., xe, zir, fae). While data scarcity is a known culprit, the precise mechanisms through which scarcity affects this behavior remain underexplored. We discover LLM misgendering is significantly influenced by Byte-Pair Encoding (BPE) tokenization, the tokenizer... | Anaelia Ovalle, Ninareh Mehrabi, Palash Goyal, Jwala Dhamala, KaiWei Chang, Richard S. Zemel, Aram Galstyan, Yuval Pinter, Rahul Gupta |  |
| 697 |  |  [AdaPT: A Set of Guidelines for Hyperbolic Multimodal Multilingual NLP](https://doi.org/10.18653/v1/2024.findings-naacl.114) |  | 0 | The Euclidean space is the familiar space for training neural models and performing arithmetic operations.However, many data types inherently possess complex geometries, and model training methods involve operating over their latent representations, which cannot be effectively captured in the Euclidean space.The hyperbolic space provides a more generalized representative geometry to model the hierarchical complexities of the tree-like structure of natural... | Ramit Sawhney, Shrey Pandit, Vishwa Shah, Megh Thakkar, Shafiq Joty |  |
| 698 |  |  [More Samples or More Prompts? Exploring Effective Few-Shot In-Context Learning for LLMs with In-Context Sampling](https://doi.org/10.18653/v1/2024.findings-naacl.115) |  | 0 | While most existing works on LLM prompting techniques focus only on how to select a better set of data samples inside one single prompt input (In-Context Learning or ICL), why can not we design and leverage multiple prompts together to further improve the LLM’s performance? In this work, we propose In-Context Sampling (ICS), a low-resource LLM prompting technique to produce confident predictions by optimizing the construction of multiple ICL prompt inputs.... | Bingsheng Yao, Guiming Chen, Ruishi Zou, Yuxuan Lu, Jiachen Li, Shao Zhang, Yisi Sang, Sijia Liu, James A. Hendler, Dakuo Wang |  |
| 699 |  |  [ZSEE: A Dataset based on Zeolite Synthesis Event Extraction for Automated Synthesis Platform](https://doi.org/10.18653/v1/2024.findings-naacl.116) |  | 0 | Automated synthesis of zeolite, one of the most important catalysts in chemical industries, holds great significance for attaining economic and environmental benefits. Structural synthesis data extracted through NLP technologies from zeolite experimental procedures can significantly expedite automated synthesis owing to its machine readability. However, the utilization of NLP technologies in information extraction of zeolite synthesis remains restricted due... | Song He, Xin Peng, Yihan Cai, Xin Li, Zhiqing Yuan, Wenli Du, Weimin Yang |  |
| 700 |  |  [Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information](https://doi.org/10.18653/v1/2024.findings-naacl.117) |  | 0 | A primary challenge in abstractive summarization is hallucination—the phenomenon where a model generates plausible text that is absent in the source text. We hypothesize that the domain (or topic) of the source text triggers the model to generate text that is highly probable in the domain, neglecting the details of the source text. To alleviate this model bias, we introduce a decoding strategy based on domain-conditional pointwise mutual information. This... | Kyubyung Chae, Jaepill Choi, Yohan Jo, Taesup Kim |  |
| 701 |  |  [Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents](https://doi.org/10.18653/v1/2024.findings-naacl.118) |  | 0 | Recent advancements in open-domain dialogue systems have been propelled by the emergence of high-quality large language models (LLMs) and various effective training methodologies. Nevertheless, the presence of toxicity within these models presents a significant challenge that can potentially diminish the user experience. In this study, we introduce an innovative training algorithm, an improvement upon direct preference optimization (DPO), called adversarial... | San Kim, Gary Geunbae Lee |  |
| 702 |  |  [Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.119) |  | 0 | Prompt engineering is an essential technique for enhancing the abilities of large language models (LLMs) by providing explicit and specific instructions. It enables LLMs to excel in various tasks, such as arithmetic reasoning, question answering, summarization, relation extraction, machine translation, and sentiment analysis. Researchers have been actively exploring different prompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and... | Fobo Shi, Peijun Qing, Dong Yang, Nan Wang, Youbo Lei, Haonan Lu, Xiaodong Lin, Duantengchuan Li |  |
| 703 |  |  [DAGCN: Distance-based and Aspect-oriented Graph Convolutional Network for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.120) |  | 0 | Aspect-based sentiment analysis (ABSA) is a task that aims to determine the sentiment polarity of aspects by identifying opinion words. Recent advancements have predominantly been rooted either in semantic or syntactic methods. However, both of them tend to interference from local factors such as irrelevant words and edges, hindering the precise identification of opinion words. In this paper, we present Distance-based and Aspect-oriented Graph Convolutional... | Zhihao Wang, Bo Zhang, Ru Yang, Chang Guo, Maozhen Li |  |
| 704 |  |  [Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved Phrase Graphs](https://doi.org/10.18653/v1/2024.findings-naacl.121) |  | 0 | We study the patent phrase similarity inference task, which measures the semantic similarity between two patent phrases. As patent documents employ legal and highly technical language, existing semantic textual similarity methods that use localized contextual information do not perform satisfactorily in inferring patent phrase similarity. To address this, we introduce a graph-augmented approach to amplify the global contextual information of the patent... | Zhuoyi Peng, Yi Yang |  |
| 705 |  |  [Self-Regulated Sample Diversity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.122) |  | 0 | Sample diversity depends on the task; within mathematics, precision and determinism are paramount, while storytelling thrives on creativity and surprise. This paper presents a simple self-regulating approach where we adjust sample diversity inference parameters dynamically based on the input prompt—in contrast to existing methods that require expensive and inflexible setups, or maintain static values during inference. Capturing a broad spectrum of sample... | Mingyue Liu, Jonathan Frawley, Sarah Wyer, Hubert P. H. Shum, Sara L. Uckelman, Sue Black, Chris G. Willcocks |  |
| 706 |  |  [Methods, Applications, and Directions of Learning-to-Rank in NLP Research](https://doi.org/10.18653/v1/2024.findings-naacl.123) |  | 0 | Learning-to-rank (LTR) algorithms aim to order a set of items according to some criteria. They are at the core of applications such as web search and social media recommendations, and are an area of rapidly increasing interest, with the rise of large language models (LLMs) and the widespread impact of these technologies on society. In this paper, we survey the diverse use cases of LTR methods in natural language processing (NLP) research, looking at... | Justin Lee, Gabriel BernierColborne, Tegan Maharaj, Sowmya Vajjala |  |
| 707 |  |  [When Quantization Affects Confidence of Large Language Models?](https://doi.org/10.18653/v1/2024.findings-naacl.124) |  | 0 | Recent studies introduced effective compression techniques for Large Language Models (LLMs) via post-training quantization or low-bit weight representation. Although quantized weights offer storage efficiency and allow for faster inference, existing works have indicated that quantization might compromise performance and exacerbate biases in LLMs.This study investigates the confidence and calibration of quantized models, considering factors such as language... | Irina Proskurina, Luc Brun, Guillaume Metzler, Julien Velcin |  |
| 708 |  |  [MedCycle: Unpaired Medical Report Generation via Cycle-Consistency](https://doi.org/10.18653/v1/2024.findings-naacl.125) |  | 0 | Generating medical reports for X-ray images presents a significant challenge, particularly in unpaired scenarios where access to paired image-report data for training is unavailable. Previous works have typically learned a joint embedding space for images and reports, necessitating a specific labeling schema for both. We introduce an innovative approach that eliminates the need for consistent labeling schemas, thereby enhancing data accessibility and enabling... | Elad Hirsch, Gefen Dawidowicz, Ayellet Tal |  |
| 709 |  |  [Beta-LR: Interpretable Logical Reasoning based on Beta Distribution](https://doi.org/10.18653/v1/2024.findings-naacl.126) |  | 0 | The logical information contained in text isof significant importance for logical reasoning.Previous approaches have relied on embeddingtext into a low-dimensional vector to capturelogical information and perform reasoning inEuclidean space. These methods involve constructing special graph architectures that matchlogical relations or designing data augmentation frameworks by extending texts based onsymbolic logic. However, it presents two obvious problems. 1)... | Yizhuo Ma, Ke Qin, Shuang Liang |  |
| 710 |  |  [Applications of BERT Models Towards Automation of Clinical Coding in Icelandic](https://doi.org/10.18653/v1/2024.findings-naacl.127) |  | 0 | This study explores the potential of automating clinical coding in Icelandic, a language with limited digital resources, by leveraging over 25 years of electronic health records (EHR) from the Landspitali University Hospital. Traditionally a manual and error-prone task, clinical coding is essential for patient care, billing, and research. Our research delves into the effectiveness of Transformer-based models in automating this process. We investigate various... | Haraldur Orri Hauksson, Hafsteinn Einarsson |  |
| 711 |  |  ["Tell me who you are and I tell you how you argue": Predicting Stances and Arguments for Stakeholder Groups](https://doi.org/10.18653/v1/2024.findings-naacl.128) |  | 0 | Argument mining has focused so far mainly on the identification, extraction, and formalization of arguments. An important yet unaddressedtask consists in the prediction of the argumentative behavior of stakeholders in a debate. Predicting the argumentative behavior in advance can support foreseeing issues in public policy making or help recognize potential disagreements early on and help to resolve them. In this paper, we consider the novel task of predicting... | Philipp Heinisch, Lorik Dumani, Philipp Cimiano, Ralf Schenkel |  |
| 712 |  |  [Psychometric Predictive Power of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.129) |  | 0 | Instruction tuning aligns the response of large language models (LLMs) with human preferences.Despite such efforts in human–LLM alignment, we find that instruction tuning does not always make LLMs human-like from a cognitive modeling perspective. More specifically, next-word probabilities estimated by instruction-tuned LLMs are often worse at simulating human reading behavior than those estimated by base LLMs.In addition, we explore prompting methodologies... | Tatsuki Kuribayashi, Yohei Oseki, Timothy Baldwin |  |
| 713 |  |  [Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions](https://doi.org/10.18653/v1/2024.findings-naacl.130) |  | 0 | Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice... | Pouya Pezeshkpour, Estevam Hruschka |  |
| 714 |  |  [PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck](https://doi.org/10.18653/v1/2024.findings-naacl.131) |  | 0 | CLIP-based classifiers rely on the prompt containing a class name that is known to the text encoder. Therefore, they perform poorly on new classes or the classes whose names rarely appear on the Internet (e.g., scientific names of birds). For fine-grained classification, we propose PEEB – an explainable and editable classifier to (1) express the class name into a set of text descriptors that describe the visual parts of that class; and (2) match the... | Thang Pham, Peijie Chen, Tin Nguyen, Seunghyun Yoon, Trung Bui, Anh Nguyen |  |
| 715 |  |  [Ethos: Rectifying Language Models in Orthogonal Parameter Space](https://doi.org/10.18653/v1/2024.findings-naacl.132) |  | 0 | Language models (LMs) have greatly propelled the research on natural language processing. However, LMs also raise concerns regarding the generation of biased or toxic content and the potential disclosure of private information from the training dataset. In this work, we present a new efficient approach, Ethos, that rectifies LMs to mitigate toxicity and bias in outputs and avoid privacy leakage. Ethos is built on task arithmetic. However, unlike current task... | Lei Gao, Yue Niu, Tingting Tang, Salman Avestimehr, Murali Annavaram |  |
| 716 |  |  [Crafting In-context Examples according to LMs' Parametric Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.133) |  | 0 | In-context learning can improve the performances of knowledge-rich tasks such as question answering. In such scenarios, in-context examples trigger a language model (LM) to surface information stored in its parametric knowledge. We study how to better construct in-context example sets, based on whether the model is aware of the in-context examples. We identify ‘known’ examples, where models can correctly answer from their parametric knowledge, and ‘unknown’... | Yoonsang Lee, Pranav Atreya, Xi Ye, Eunsol Choi |  |
| 717 |  |  [ICXML: An In-Context Learning Framework for Zero-Shot Extreme Multi-Label Classification](https://doi.org/10.18653/v1/2024.findings-naacl.134) |  | 0 | This paper focuses on the task of Extreme Multi-Label Classification (XMC) whose goal is to predict multiple labels for each instance from an extremely large label space. While existing research has primarily focused on fully supervised XMC, real-world scenarios often lack supervision signals, highlighting the importance of zero-shot settings. Given the large label space, utilizing in-context learning approaches is not trivial. We address this issue by... | Yaxin Zhu, Hamed Zamani |  |
| 718 |  |  [CLGSI: A Multimodal Sentiment Analysis Framework based on Contrastive Learning Guided by Sentiment Intensity](https://doi.org/10.18653/v1/2024.findings-naacl.135) |  | 0 | Recently, contrastive learning has begun to gain popularity in multimodal sentiment analysis (MSA). However, most of existing MSA methods based on contrastive learning lacks more detailed learning of the distribution of sample pairs with different sentiment intensity differences in the contrastive learning representation space. In addition, limited research has been conducted on the fusion of each modality representation obtained by contrastive learning... | Yang Yang, Xunde Dong, Yupeng Qiang |  |
| 719 |  |  [Interpreting Answers to Yes-No Questions in Dialogues from Multiple Domains](https://doi.org/10.18653/v1/2024.findings-naacl.136) |  | 0 | People often answer yes-no questions without explicitly saying yes, no, or similar polar key-words. Figuring out the meaning of indirectanswers is challenging, even for large language models. In this paper, we investigate this problem working with dialogues from multiple domains. We present new benchmarks in three diverse domains: movie scripts, tennis interviews, and airline customer service. We present an approach grounded on distant supervision and blended... | Zijie Wang, Farzana Rashid, Eduardo Blanco |  |
| 720 |  |  [Enhancing Perception: Refining Explanations of News Claims with LLM Conversations](https://doi.org/10.18653/v1/2024.findings-naacl.137) |  | 0 | We introduce Enhancing Perception, a framework for Large Language Models (LLMs) designed to streamline the time-intensive task typically undertaken by professional fact-checkers of crafting explanations for fake news. This study investigates the effectiveness of enhancing LLM explanations through conversational refinement. We compare various questioner agents, including state-of-the-art LLMs like GPT-4, Claude 2, PaLM 2, and 193 American participants acting... | YiLi Hsu, JuiNing Chen, Yang Fan Chiang, ShangChien Liu, Aiping Xiong, LunWei Ku |  |
| 721 |  |  [How Interpretable are Reasoning Explanations from Prompting Large Language Models?](https://doi.org/10.18653/v1/2024.findings-naacl.138) |  | 0 | Prompt Engineering has garnered significant attention for enhancing the performance of large language models across a multitude of tasks. Techniques such as the Chain-of-Thought not only bolster task performance but also delineate a clear trajectory of reasoning steps, offering a tangible form of explanation for the audience. Prior works on interpretability assess the reasoning chains yielded by Chain-of-Thought solely along a singular axis, namely... | Wei Jie Yeo, Ranjan Satapathy, Rich Siow Mong Goh, Erik Cambria |  |
| 722 |  |  [Plug-in Language Model: Controlling Text Generation with a Simple Regression Model](https://doi.org/10.18653/v1/2024.findings-naacl.139) |  | 0 | Large-scale pre-trained language models have displayed unrivaled capacity in generating text that closely resembles human-written text. Nevertheless, generating texts adhering to specific conditions without fine-tuning or adding new parameters can be challenging. Contemporary approaches commonly rely on either prompts or auxiliary models to avoid modifying the language models. These auxiliary models are designed to assess whether a generated token contributes... | NaiChi Yang, WeiYun Ma, PuJen Cheng |  |
| 723 |  |  [Signer Diversity-driven Data Augmentation for Signer-Independent Sign Language Translation](https://doi.org/10.18653/v1/2024.findings-naacl.140) |  | 0 | The primary objective of sign language translation (SLT) is to transform sign language videos into natural sentences.A crucial challenge in this field is developing signer-independent SLT systems which requires models to generalize effectively to signers not encountered during training.This challenge is exacerbated by the limited diversity of signers in existing SLT datasets, which often results in suboptimal generalization capabilities of current... | Honghaofu Honghaofu, Liang Zhang, Biao Fu, Rui Zhao, Jinsong Su, Xiaodong Shi, Yidong Chen |  |
| 724 |  |  [A Systematic Analysis of Subwords and Cross-Lingual Transfer in Multilingual Translation](https://doi.org/10.18653/v1/2024.findings-naacl.141) |  | 0 | Multilingual modelling can improve machine translation for low-resource languages, partly through shared subword representations. This paper studies the role of subword segmentation in cross-lingual transfer. We systematically compare the efficacy of several subword methods in promoting synergy and preventing interference across different linguistic typologies. Our findings show that subword regularisation boosts synergy in multilingual modelling, whereas BPE... | Francois Meyer, Jan Buys |  |
| 725 |  |  [Multi-Granularity Guided Fusion-in-Decoder](https://doi.org/10.18653/v1/2024.findings-naacl.142) |  | 0 | In Open-domain Question Answering (ODQA), it is essential to discern relevant contexts as evidence and avoid spurious ones among retrieved results. The model architecture that uses concatenated multiple contexts in the decoding phase, \*i.e.\*, Fusion-in-Decoder, demonstrates promising performance but generates incorrect outputs from seemingly plausible contexts. To address this problem, we propose the \*\*\*M\*\*ulti-\*\*G\*\*ranularity guided... | Eunseong Choi, Hyeri Lee, Jongwuk Lee |  |
| 726 |  |  [Group Fairness in Multilingual Speech Recognition Models](https://doi.org/10.18653/v1/2024.findings-naacl.143) |  | 0 | We evaluate the performance disparity of the Whisper and MMS families of ASR models across the VoxPopuli and Common Voice multilingual datasets, with an eye toward intersectionality. Our two most important findings are that model size, surprisingly, correlates logarithmically with worst-case performance disparities, meaning that larger (and better) models are less fair. We also observe the importance of intersectionality. In particular, models often exhibit... | Anna Zee, Marc Zee, Anders Søgaard |  |
| 727 |  |  [Rethinking Machine Ethics - Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?](https://doi.org/10.18653/v1/2024.findings-naacl.144) |  | 0 | Making moral judgments is an essential step toward developing ethical AI systems. Prevalent approaches are mostly implemented in a bottom-up manner, which uses a large set of annotated data to train models based on crowd-sourced opinions about morality. These approaches have been criticized for potentially overgeneralizing a limited group of annotators’ moral stances and lacking explainability. This work proposes a flexible top-down framework to steer (Large)... | Jingyan Zhou, Minda Hu, Junan Li, Xiaoying Zhang, Xixin Wu, Irwin King, Helen Meng |  |
| 728 |  |  [Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.145) |  | 0 | The growing interest in Large Language Models (LLMs) for specialized applications has revealed a significant challenge: when tailored to specific domains, LLMs tend to experience catastrophic forgetting, compromising their general capabilities and leading to a suboptimal user experience. Additionally, crafting a versatile model for multiple domains simultaneously often results in a decline in overall performance due to confusion between domains. In response... | Rui Wang, Fei Mi, Yi Chen, Boyang Xue, Hongru Wang, Qi Zhu, KamFai Wong, Ruifeng Xu |  |
| 729 |  |  [BERTweet's TACO Fiesta: Contrasting Flavors On The Path Of Inference And Information-Driven Argument Mining On Twitter](https://doi.org/10.18653/v1/2024.findings-naacl.146) |  | 0 |  | Marc Feger, Stefan Dietze |  |
| 730 |  |  [Testing the limits of logical reasoning in neural and hybrid models](https://doi.org/10.18653/v1/2024.findings-naacl.147) |  | 0 | We study the ability of neural and hybrid models to generalize logical reasoning patterns. We created a series of tests for analyzing various aspects of generalization in the context of language and reasoning, focusing on compositionality and recursiveness. We used them to study the syllogistic logic in hybrid models, where the network assists in premise selection. We analyzed feed-forward, recurrent, convolutional, and transformer architectures. Our... | Manuel Vargas Guzmán, Jakub Szymanik, Maciej Malicki |  |
| 731 |  |  [METAL: Towards Multilingual Meta-Evaluation](https://doi.org/10.18653/v1/2024.findings-naacl.148) |  | 0 | With the rising human-like precision of Large Language Models (LLMs) in numerous tasks, their utilization in a variety of real-world applications is becoming more prevalent. Several studies have shown that LLMs excel on many standard NLP benchmarks. However, it is challenging to evaluate LLMs due to test dataset contamination and the limitations of traditional metrics. Since human evaluations are difficult to collect, there is a growing interest in the... | Rishav Hada, Varun Gumma, Mohamed Ahmed, Kalika Bali, Sunayana Sitaram |  |
| 732 |  |  [AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models](https://doi.org/10.18653/v1/2024.findings-naacl.149) |  | 0 | Assessing foundation models’ abilities for human-level tasks is crucial for Artificial General Intelligence (AGI) development.Traditional benchmarks, which rely on artificial datasets, may not accurately represent these capabilities. In this paper, we introduce AGIEval, a novel bilingual benchmark designed to assess foundation models in the context of human-centric standardized exams, such as college entrance exams, law school admission tests, math... | Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, Nan Duan |  |
| 733 |  |  [Product Description and QA Assisted Self-Supervised Opinion Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.150) |  | 0 | In e-commerce, opinion summarization is the process of summarizing the consensus opinions found in product reviews. However, the potential of additional sources such as product description and question-answers (QA) has been considered less often. Moreover, the absence of any supervised training data makes this task challenging. To address this, we propose a novel synthetic dataset creation (SDC) strategy that leverages information from reviews as well as... | Tejpalsingh Siledar, Rupasai Rangaraju, Sankara Sri Raghava Ravindra Muddu, Suman Banerjee, Amey Patil, Sudhanshu Singh, Muthusamy Chelliah, Nikesh Garera, Swaprava Nath, Pushpak Bhattacharyya |  |
| 734 |  |  [COMEM: In-Context Retrieval-Augmented Mass-Editing Memory in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.151) |  | 0 |  | Shanbao Qiao, Xuebing Liu, SeungHoon Na |  |
| 735 |  |  [Content-Specific Humorous Image Captioning Using Incongruity Resolution Chain-of-Thought](https://doi.org/10.18653/v1/2024.findings-naacl.152) |  | 0 | Although automated image captioning methods have benefited considerably from the development of large language models (LLMs), generating humorous captions is still a challenging task. Humorous captions generated by humans are unique to the image and reflect the content of the image. However, captions generated using previous captioning models tend to be generic. Therefore, we propose incongruity-resolution chain-of-thought (IRCoT) as a novel prompting... | Kohtaro Tanaka, Kohei Uehara, Lin Gu, Yusuke Mukuta, Tatsuya Harada |  |
| 736 |  |  [Denoising Attention for Query-aware User Modeling](https://doi.org/10.18653/v1/2024.findings-naacl.153) |  | 0 | Personalization of search results has gained increasing attention in the past few years, also thanks to the development of Neural Networks-based approaches for Information Retrieval. Recent works have proposed to build user models at query time by leveraging the Attention mechanism, which allows weighing the contribution of the user-related information w.r.t. the current query.This approach allows giving more importance to the user’s interests related to the... | Elias Bassani, Pranav Kasela, Gabriella Pasi |  |
| 737 |  |  [A Lightweight Mixture-of-Experts Neural Machine Translation Model with Stage-wise Training Strategy](https://doi.org/10.18653/v1/2024.findings-naacl.154) |  | 0 | Dealing with language heterogeneity has always been one of the challenges in neural machine translation (NMT).The idea of using mixture-of-experts (MoE) naturally excels in addressing this issue by employing different experts to take responsibility for different problems.However, the parameter-inefficiency problem in MoE results in less performance improvement when boosting the number of parameters.Moreover, most of the MoE models are suffering from the... | Fan Zhang, Mei Tu, Song Liu, Jinyao Yan |  |
| 738 |  |  [BEAR: A Unified Framework for Evaluating Relational Knowledge in Causal and Masked Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.155) |  | 0 | Knowledge probing assesses to which degree a language model (LM) has successfully learned relational knowledge during pre-training. Probing is an inexpensive way to compare LMs of different sizes and training configurations. However, previous approaches rely on the objective function used in pre-training LMs and are thus applicable only to masked or causal LMs. As a result, comparing different types of LMs becomes impossible. To address this, we propose an... | Jacek Wiland, Max Ploner, Alan Akbik |  |
| 739 |  |  [Conformal Intent Classification and Clarification for Fast and Accurate Intent Recognition](https://doi.org/10.18653/v1/2024.findings-naacl.156) |  | 0 | We present Conformal Intent Classification and Clarification (CICC), a framework for fast and accurate intent classification for task-oriented dialogue systems. The framework turns heuristic uncertainty scores of any intent classifier into a clarification question that is guaranteed to contain the true intent at a pre-defined confidence level.By disambiguating between a small number of likely intents, the user query can be resolved quickly and accurately.... | Floris den Hengst, Ralf Wolter, Patrick Altmeyer, Arda Kaygan |  |
| 740 |  |  [Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models in Court Decisions](https://doi.org/10.18653/v1/2024.findings-naacl.157) |  | 0 | Anonymity in court rulings is a critical aspect of privacy protection in the European Union and Switzerland but with the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland (FSCS), we study re-identification risks using actual legal data. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to... | Alex Nyffenegger, Matthias Stürmer, Joel Niklaus |  |
| 741 |  |  [X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment](https://doi.org/10.18653/v1/2024.findings-naacl.158) |  | 0 | The impressive development of large language models (LLMs) is expanding into the realm of large multimodal models (LMMs), which incorporate multiple types of data beyond text. However, the nature of multimodal models leads to significant expenses in the creation of training data. Furthermore, constructing multilingual data for LMMs presents its own set of challenges due to language diversity and complexity. Therefore, in this study, we propose two... | Dongjae Shin, HyeonSeok Lim, Inho Won, ChangSu Choi, Minjun Kim, Seungwoo Song, Hangyeol Yoo, Sangmin Kim, Kyungtae Lim |  |
| 742 |  |  [Why So Gullible? Enhancing the Robustness of Retrieval-Augmented Models against Counterfactual Noise](https://doi.org/10.18653/v1/2024.findings-naacl.159) |  | 0 | Most existing retrieval-augmented language models (LMs) assume a naive dichotomy within a retrieved document set: query-relevance and irrelevance. Our work investigates a more challenging scenario in which even the “relevant” documents may contain misleading or incorrect information, causing conflict among the retrieved documents and thereby negatively influencing model decisions as noise. We observe that existing LMs are highly brittle to the presence of... | Giwon Hong, Jeonghwan Kim, Junmo Kang, SungHyon Myaeng, Joyce Jiyoung Whang |  |
| 743 |  |  [Heterogeneity over Homogeneity: Investigating Multilingual Speech Pre-Trained Models for Detecting Audio Deepfake](https://doi.org/10.18653/v1/2024.findings-naacl.160) |  | 0 | In this work, we investigate multilingual speech Pre-Trained models (PTMs) for Audio deepfake detection (ADD). We hypothesize thatmultilingual PTMs trained on large-scale diverse multilingual data gain knowledge about diverse pitches, accents, and tones, during theirpre-training phase and making them more robust to variations. As a result, they will be more effective for detecting audio deepfakes. To validate our hypothesis, we extract representations from... | Orchid Chetia Phukan, Gautam Siddharth Kashyap, Arun Balaji Buduru, Rajesh Sharma |  |
| 744 |  |  [Identifying Self-Disclosures of Use, Misuse and Addiction in Community-based Social Media Posts](https://doi.org/10.18653/v1/2024.findings-naacl.161) |  | 0 | In the last decade, the United States has lost more than 500,000 people from an overdose involving prescription and illicit opioids making it a national public health emergency (USDHHS, 2017). Medical practitioners require robust and timely tools that can effectively identify at-risk patients. Community-based social media platforms such as Reddit allow self-disclosure for users to discuss otherwise sensitive drug-related behaviors. We present a moderate size... | Chenghao Yang, Tuhin Chakrabarty, Karli R. Hochstatter, Melissa N. Slavin, Nabila ElBassel, Smaranda Muresan |  |
| 745 |  |  [Self-Adaptive Sampling for Accurate Video Question Answering on Image Text Models](https://doi.org/10.18653/v1/2024.findings-naacl.162) |  | 0 | Image–text models (ITMs) is the prevalent architecture to solve video question–answering tasks, which requires only a few input frames to save huge computational cost compared to video–language models.However, we find existent ITM video question–answering solutions either 1) adopt simplistic and unintentional sampling strategies, which may miss key frames to offer the answer clues; or 2) sample a large number of frames into divided groups, which the... | Wei Han, Hui Chen, MinYen Kan, Soujanya Poria |  |
| 746 |  |  [Towards an On-device Agent for Text Rewriting](https://doi.org/10.18653/v1/2024.findings-naacl.163) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities for text rewriting. However creating a smaller yet potent language model for text rewriting presents two formidable challenges: costly data collection and absence of emergent capabilities.In this paper we present solutions to address the above challenges.We propose an new instruction tuning method to develop a mo-bile text rewriting model that leverages LLM-generated data and heuristic... | Yun Zhu, Yinxiao Liu, Felix Stahlberg, Shankar Kumar, YuHui Chen, Liangchen Luo, Lei Shu, Renjie Liu, Jindong Chen, Lei Meng |  |
| 747 |  |  [Tailoring Vaccine Messaging with Common-Ground Opinions](https://doi.org/10.18653/v1/2024.findings-naacl.164) |  | 0 | One way to personalize chatbot interactions is by establishing common ground with the intended reader. A domain where establishing mutual understanding could be particularly impactful is vaccine concerns and misinformation. Vaccine interventions are forms of messaging which aim to answer concerns expressed about vaccination. Tailoring responses in this domain is difficult, since opinions often have seemingly little ideological overlap. We define the task of... | Rickard Stureborg, Sanxing Chen, Roy Xie, Aayushi Patel, Christopher Li, Chloe Qinyu Zhu, Tingnan Hu, Jun Yang, Bhuwan Dhingra |  |
| 748 |  |  [Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification](https://doi.org/10.18653/v1/2024.findings-naacl.165) |  | 0 | This paper introduces a novel neuro-symbolic architecture for relation classification (RC) that combines rule-based methods with contemporary deep learning techniques. This approach capitalizes on the strengths of both paradigms: the adaptability of rule-based systems and the generalization power of neural networks. Our architecture consists of two components: a declarative rule-based model for transparent classification and a neural component to enhance rule... | Robert Vacareanu, Fahmida Alam, Md. Asiful Islam, Haris Riaz, Mihai Surdeanu |  |
| 749 |  |  [Q-Tuning: Queue-based Prompt Tuning for Lifelong Few-shot Language Learning](https://doi.org/10.18653/v1/2024.findings-naacl.166) |  | 0 | This paper introduces Q-tuning, a novel approach for continual prompt tuning that enables the lifelong learning of a pre-trained language model. When learning a new task, Q-tuning trains a task-specific prompt by adding it to a prompt queue consisting of the prompts from older tasks. To better transfer the knowledge of old tasks, we design an adaptive knowledge aggregation technique that reweighs previous prompts in the queue with a learnable low-rank matrix.... | Yanhui Guo, Shaoyuan Xu, Jinmiao Fu, Jia Liu, Chaosheng Dong, Bryan Wang |  |
| 750 |  |  [In-Context Example Ordering Guided by Label Distributions](https://doi.org/10.18653/v1/2024.findings-naacl.167) |  | 0 | By allowing models to predict without task-specific training, in-context learning (ICL) with pretrained LLMs has enormous potential in NLP. However, a number of problems persist in ICL. In particular, its performance is sensitive to the choice and order of in-context examples. Given the same set of in-context examples with different orderings, model performance may vary from near random to near state-of-the-art. In this work, we formulate in-context example... | Zhichao Xu, Daniel Cohen, Bei Wang, Vivek Srikumar |  |
| 751 |  |  [Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial Narratives](https://doi.org/10.18653/v1/2024.findings-naacl.168) |  | 0 | In this paper, we introduce the Financial-STS task, a financial domain-specific NLP task designed to measure the nuanced semantic similarity between pairs of financial narratives. These narratives originate from the financial statements of the same company but correspond to different periods, such as year-over-year comparisons. Measuring the subtle semantic differences between these paired narratives enables market stakeholders to gauge changes over time in... | Jiaxin Liu, Yi Yang, Kar Yan Tam |  |
| 752 |  |  [Laying Anchors: Semantically Priming Numerals in Language Modeling](https://doi.org/10.18653/v1/2024.findings-naacl.169) |  | 0 | Off-the-shelf pre-trained language models have become the de facto standard in NLP pipelines for a multitude of downstream tasks. However, the inability of these models to properly encode numerals limits their performance on tasks requiring numeric comprehension. We introduce strategies to semantically prime numerals in any corpus by generating anchors governed by the distribution of numerals in said corpus, thereby enabling mathematically grounded... | Mandar Sharma, Rutuja Murlidhar Taware, Pravesh Koirala, Nikhil Muralidhar, Naren Ramakrishnan |  |
| 753 |  |  [UEGP: Unified Expert-Guided Pre-training for Knowledge Rekindle](https://doi.org/10.18653/v1/2024.findings-naacl.170) |  | 0 | Pre-training and fine-tuning framework has become the standard training paradigm for NLP tasks and is also widely used in industrial-level applications. However, there are still a limitation with this paradigm: simply fine-tuning with task-specific objectives tends to converge to local minima, resulting in a sub-optimal performance. In this paper, we first propose a new paradigm: knowledge rekindle, which aims to re-incorporate the fine-tuned expert model... | Yutao Mou, Kexiang Wang, Jianhe Lin, Dehong Ma, Jun Fan, Daiting Shi, Zhicong Cheng, Simiu Gu, Dawei Yin, Weiran Xu |  |
| 754 |  |  [LatticeGen: Hiding Generated Text in a Lattice for Privacy-Aware Large Language Model Generation on Cloud](https://doi.org/10.18653/v1/2024.findings-naacl.171) |  | 0 | In the current user-server interaction paradigm of prompted generation with large language models (LLMs) on cloud, the server fully controls the generation process, which leaves zero options for users who want to keep the generated text private to themselves. For privacy-aware text generation on cloud, we propose LatticeGen, a cooperative protocol in which the server still handles most of the computation while the client controls the sampling operation. The... | Mengke Zhang, Tianxing He, Tianle Wang, Lu Mi, Niloofar Mireshghallah, Binyi Chen, Hao Wang, Yulia Tsvetkov |  |
| 755 |  |  [HateModerate: Testing Hate Speech Detectors against Content Moderation Policies](https://doi.org/10.18653/v1/2024.findings-naacl.172) |  | 0 | To protect users from massive hateful content, existing works studied automated hate speech detection. Despite the existing efforts, one question remains: Do automated hate speech detectors conform to social media content policies? A platform’s content policies are a checklist of content moderated by the social media platform. Because content moderation rules are often uniquely defined, existing hate speech datasets cannot directly answer this question. This... | Jiangrui Zheng, Xueqing Liu, Mirazul Haque, Xing Qian, Guanqun Yang, Wei Yang |  |
| 756 |  |  [Compensate Quantization Errors: Make Weights Hierarchical to Compensate Each Other](https://doi.org/10.18653/v1/2024.findings-naacl.173) |  | 0 | Emergent Large Language Models (LLMs) use their extraordinary performance and powerful deduction capacity to discern from traditional language models. However, the expenses of computational resources and storage for these LLMs are stunning, quantization then arises as a trending conversation. To address accuracy decay caused by quantization, two streams of works in post-training quantization methods stand out. One uses other weights to compensate existing... | Yifei Gao, Jie Ou, Lei Wang, Yuting Xiao, Xiangzhiyuan Xiangzhiyuan, Ruiting Dai, Jun Cheng |  |
| 757 |  |  [Contrastive Preference Learning for Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.174) |  | 0 | There exists a discrepancy between the token-level objective during training and the overall sequence-level quality that is expected from the model. This discrepancy leads to issues like exposure bias.To align the model with human expectations, sequence-level objectives are often used to fine-tune pre-trained models.In this paper, we introduce a contrastive preference model that enhances the traditional Plackett-Luce model by incorporating an indicator... | Jianfei He, Shichao Sun, Sen Peng, Jie Xu, Xiaohua Jia, Wenjie Li |  |
| 758 |  |  [SocREval: Large Language Models with the Socratic Method for Reference-free Reasoning Evaluation](https://doi.org/10.18653/v1/2024.findings-naacl.175) |  | 0 | To comprehensively gauge the capacity of current models for complex reasoning, it is crucial to assess their step-by-step reasoning in a scalable manner. Established reference-based evaluation metrics rely on human-annotated reasoning chains as references to assess the model-derived chains. However, such “gold-standard” human-written reasoning chains may not be unique and their acquisition is often labor-intensive. Existing reference-free reasoning evaluation... | Hangfeng He, Hongming Zhang, Dan Roth |  |
| 759 |  |  [Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.176) |  | 0 | Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages? 2) Which factors affect LLMs’ performance in translation? We thoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our empirical results show that... | Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, Lei Li |  |
| 760 |  |  [Unleashing the Power of LLMs in Court View Generation by Stimulating Internal Knowledge and Incorporating External Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.177) |  | 0 | Court View Generation (CVG) plays a vital role in the realm of legal artificial intelligence, which aims to support judges in crafting legal judgment documents. The court view consists of three essential judgment parts: the charge-related, law article-related, and prison term-related parts, each requiring specialized legal knowledge, rendering CVG a challenging task.Although Large Language Models (LLMs) have made remarkable strides in language generation,... | Yifei Liu, Yiquan Wu, Ang Li, Yating Zhang, Changlong Sun, Weiming Lu, Fei Wu, Kun Kuang |  |
| 761 |  |  [Prompting Vision-Language Models For Aspect-Controlled Generation of Referring Expressions](https://doi.org/10.18653/v1/2024.findings-naacl.178) |  | 0 | Referring Expression Generation (REG) is the task of generating a description that unambiguously identifies a given target in the scene. Different from Image Captioning (IC), REG requires learning fine-grained characteristics of not only the scene objects but also their surrounding context. Referring expressions are usually not singular; an object can often be uniquely referenced in numerous ways, for instance, by color, by location, or by relationship with... | Danfeng Guo, Sanchit Agarwal, Arpit Gupta, JiunYu Kao, Emre Barut, Tagyoung Chung, Jing Huang, Mohit Bansal |  |
| 762 |  |  [Task-Agnostic Detector for Insertion-Based Backdoor Attacks](https://doi.org/10.18653/v1/2024.findings-naacl.179) |  | 0 | Textual backdoor attacks pose significant security threats. Current detection approaches, typically relying on intermediate feature representation or reconstructing potential triggers, are task-specific and less effective beyond sentence classification, struggling with tasks like question answering and named entity recognition. We introduce TABDet (Task-Agnostic Backdoor Detector), a pioneering task-agnostic method for backdoor detection. TABDet leverages... | Weimin Lyu, Xiao Lin, Songzhu Zheng, Lu Pang, Haibin Ling, Susmit Jha, Chao Chen |  |
| 763 |  |  [Uncertainty Estimation on Sequential Labeling via Uncertainty Transmission](https://doi.org/10.18653/v1/2024.findings-naacl.180) |  | 0 | Sequential labeling is a task predicting labels for each token in a sequence, such as Named Entity Recognition (NER). NER tasks aim to extract entities and predict their labels given a text, which is important in information extraction. Although previous works have shown great progress in improving NER performance, uncertainty estimation on NER (UE-NER) is still underexplored but essential. This work focuses on UE-NER, which aims to estimate uncertainty... | Jianfeng He, Linlin Yu, Shuo Lei, ChangTien Lu, Feng Chen |  |
| 764 |  |  [Exploring Language Model's Code Generation Ability with Auxiliary Functions](https://doi.org/10.18653/v1/2024.findings-naacl.181) |  | 0 | Auxiliary function is a helpful component to improve language model’s code generation ability. However, a systematic exploration of how they affect has yet to be done. In this work, we comprehensively evaluate the ability to utilize auxiliary functions encoded in recent code-pretrained language models. First, we construct a human-crafted evaluation set, called HumanExtension, which contains examples of two functions where one function assists the other.With... | Seonghyeon Lee, Sanghwan Jang, Seongbo Jang, Dongha Lee, Hwanjo Yu |  |
| 765 |  |  [Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.182) |  | 0 | Recent advancements in large language models (LLMs) have underscored their importance in the evolution of artificial intelligence. However, despite extensive pretraining on multilingual datasets, available open-sourced LLMs exhibit limited effectiveness in processing Vietnamese. The challenge is exacerbated by the absence of systematic benchmark datasets and metrics tailored for Vietnamese LLM evaluation. To mitigate these issues, we have finetuned LLMs... | Sang T. Truong, Duc Nguyen, Toan Nguyen, Dong D. Le, Nhi N. Truong, Tho Quan, Sanmi Koyejo |  |
| 766 |  |  [GoT: Effective Graph-of-Thought Reasoning in Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.183) |  | 0 | With the widespread use of language models (LMs) in NLP tasks, researchers have discovered the potential of Chain-of-thought (CoT) to assist LMs in accomplishing complex reasoning tasks by generating intermediate steps. However, human thought processes are often non-linear, rather than simply sequential chains of thoughts. Therefore, we propose Graph-of-Thought (GoT) reasoning, which models human thought processes not only as a chain but also as a graph. By... | Yao Yao, Zuchao Li, Hai Zhao |  |
| 767 |  |  [Enhancing the General Agent Capabilities of Low-Paramter LLMs through Tuning and Multi-Branch Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.184) |  | 0 | Open-source pre-trained Large Language Models (LLMs) exhibit strong language understanding and generation capabilities, making them highly successful in a variety of tasks. However, when used as agents for dealing with complex problems in the real world, their performance is far inferior to large commercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need to have the capabilities of task planning, long-term memory, and the ability to... | Qinhao Zhou, Zihan Zhang, Xiang Xiang, Ke Wang, Yuchuan Wu, Yongbin Li |  |
| 768 |  |  [MuMath: Multi-perspective Data Augmentation for Mathematical Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.185) |  | 0 | Recently, the tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs. However, these models fall short in demonstrating the calculation process, which compromises user-friendliness and understanding of problem-solving steps. Conversely, while tool-free methods offer a clear display of the problem-solving process, their accuracy leaves room for... | Weihao You, Shuo Yin, Xudong Zhao, Zhilong Ji, Guoqiang Zhong, Jinfeng Bai |  |
| 769 |  |  [Tram: A Token-level Retrieval-augmented Mechanism for Source Code Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.186) |  | 0 | Automatically generating human-readable text describing the functionality of a program is the intent of source code summarization. Although neural language models achieve significant performance in this field, they are limited by their inability to access external knowledge. To address this limitation, an emerging trend is combining neural models with external knowledge through retrieval methods. Previous methods have relied on the sentence-level retrieval... | Tong Ye, Lingfei Wu, Tengfei Ma, Xuhong Zhang, Yangkai Du, Peiyu Liu, Shouling Ji, Wenhai Wang |  |
| 770 |  |  [UNO-DST: Leveraging Unlabelled Data in Zero-Shot Dialogue State Tracking](https://doi.org/10.18653/v1/2024.findings-naacl.187) |  | 0 | Previous zero-shot dialogue state tracking (DST) methods only apply transfer learning, but ignore unlabelled data in the target domain.We transform zero-shot DST into few-shot DST by utilising such unlabelled data via joint and self-training methods. Our method incorporates auxiliary tasks that generate slot types as inverse prompts for main tasks, creating slot values during joint training. Cycle consistency between these two tasks enables the generation and... | Chuang Li, Yan Zhang, MinYen Kan, Haizhou Li |  |
| 771 |  |  [Evaluating Step-by-Step Reasoning through Symbolic Verification](https://doi.org/10.18653/v1/2024.findings-naacl.188) |  | 0 | Pre-trained language models (LMs) have shown remarkable reasoning performance using explanations or chain-of-thoughts (CoT)) for in-context learning. On the other hand, these reasoning tasks are usually presumed to be more approachable for symbolic programming. To understand the mechanism of reasoning of LMs, we curate synthetic datasets containing equivalent (natural, symbolic) data pairs, where symbolic examples contain first-order logic rules and... | Yifan Zhang, Hanlin Zhang, Li Li, Eric P. Xing |  |
| 772 |  |  [Multi-Review Fusion-in-Context](https://doi.org/10.18653/v1/2024.findings-naacl.189) |  | 0 | Grounded text generation, encompassing tasks such as long-form question-answering and summarization, necessitates both content selection and content consolidation. Current end-to-end methods are difficult to control and interpret due to their opaqueness.Accordingly, recent works have proposed a modular approach, with separate components for each step. Specifically, we focus on the second subtask, of generating coherent text given pre-selected content in a... | Aviv Slobodkin, Ori Shapira, Ran Levy, Ido Dagan |  |
| 773 |  |  [Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison](https://doi.org/10.18653/v1/2024.findings-naacl.190) |  | 0 | Retrieval-Augmented Neural Machine Translation (RAMT) architectures retrieve examples from memory to guide the generation process. While most works in this trend explore new ways to exploit the retrieved examples, the upstream retrieval step is mostly unexplored. In this paper, we study the effect of varying retrieval methods for several translation architectures to better understand the interplay between these two processes.We conduct experiments in two... | Maxime Bouthors, Josep Maria Crego, François Yvon |  |
| 774 |  |  [Extending Input Contexts of Language Models through Training on Segmented Sequences](https://doi.org/10.18653/v1/2024.findings-naacl.191) |  | 0 | Effectively training language models on longinputs poses many technical challenges. As acost consideration, languages models are pre-trained on a fixed sequence length before beingadapted to longer sequences. We explore var-ious methods for adapting models to longerinputs by training on segmented sequences andan interpolation-based method for extendingabsolute positional embeddings. We developa training procedure to extend the input con-text size of... | Petros Karypis, Julian J. McAuley, George Karypis |  |
| 775 |  |  [Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning through Logical Fallacy Understanding](https://doi.org/10.18653/v1/2024.findings-naacl.192) |  | 0 | Large Language Models (LLMs) have demonstrated good performance in many reasoning tasks, but they still struggle with some complicated reasoning tasks including logical reasoning. One non-negligible reason for LLMs’ suboptimal performance on logical reasoning is their overlooking of understanding logical fallacies correctly. To evaluate LLMs’ capability of logical fallacy understanding (LFU), we propose five concrete tasks from three cognitive dimensions of... | Yanda Li, Dixuan Wang, Jiaqing Liang, Guochao Jiang, Qianyu He, Yanghua Xiao, Deqing Yang |  |
| 776 |  |  [Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.193) |  | 0 | Multiple-choice questions (MCQs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable format in assessments and practices. One of the most important aspects of MCQs is the distractors, i.e., incorrect options that are designed to target common errors or misconceptions among real students. To date, the task of crafting high-quality distractors largely remains a labor and time-intensive process for... | Wanyong Feng, Jaewook Lee, Hunter McNichols, Alexander Scarlatos, Digory Smith, Simon Woodhead, Nancy Otero Ornelas, Andrew S. Lan |  |
| 777 |  |  [Aspect-based Sentiment Analysis with Context Denoising](https://doi.org/10.18653/v1/2024.findings-naacl.194) |  | 0 | Given a sentence and a particular aspect term, aspect-based sentiment analysis (ABSA) aims to predict the sentiment polarity towards this aspect term, which provides fine-grained analysis on sentiment understanding and it has attracted much attention in recent years. In order to achieve a good performance on ABSA, it is important for a model to appropriately encode contextual information, especially identifying salient features and eliminating noise in the... | Yuanhe Tian, Chang Liu, Yan Song, Fei Xia, Yongdong Zhang |  |
| 778 |  |  [IruMozhi: Automatically classifying diglossia in Tamil](https://doi.org/10.18653/v1/2024.findings-naacl.195) |  | 0 | Tamil, a Dravidian language of South Asia, is a highly diglossic language with two very different registers in everyday use: Literary Tamil (preferred in writing and formal communication) and Spoken Tamil (confined to speech and informal media). Spoken Tamil is under-studied in modern NLP systems compared to Literary Tamil written in the Tamil script, as evidenced by a lack of datasets explicitly targetting the Spoken variety. In this paper, we release... | Kabilan Prasanna, Aryaman Arora |  |
| 779 |  |  [RENOVI: A Benchmark Towards Remediating Norm Violations in Socio-Cultural Conversations](https://doi.org/10.18653/v1/2024.findings-naacl.196) |  | 0 | Norm violations occur when individuals fail to conform to culturally accepted behaviors, which may lead to potential conflicts. Remediating norm violations requires social awareness and cultural sensitivity of the nuances at play. To equip interactive AI systems with a remediation ability, we offer ReNoVi — a large-scale corpus of 9,258 multi-turn dialogues annotated with social norms, as well as define a sequence of tasks to help understand and remediate... | Haolan Zhan, Zhuang Li, Xiaoxi Kang, Tao Feng, Yuncheng Hua, Lizhen Qu, Yi Ying, Mei Rianto Chandra, Kelly Rosalin, Jureynolds Jureynolds, Suraj Sharma, Shilin Qu, Linhao Luo, Ingrid Zukerman, LayKi Soon, Zhaleh SemnaniAzad, Gholamreza Haffari |  |
| 780 |  |  [Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking](https://doi.org/10.18653/v1/2024.findings-naacl.197) |  | 0 |  | Hong Jin Kang, Fabrice HarelCanada, Muhammad Ali Gulzar, Nanyun Peng, Miryung Kim |  |
| 781 |  |  [COMMIT: Code-Mixing English-Centric Large Language Model for Multilingual Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-naacl.198) |  | 0 | Recently, instruction-tuned large language models (LLMs) are showing prominent performance on various tasks, such as question answering. However, the majority of instruction-tuned LLMs are English-centric, which hinders their application to low-resource language QA. In this paper, we propose COde-Mixed Multilingual Instruction Tuning (COMMIT) to adapt English-centric LLM to low-resource language QA. We point out two main causes of English-centricness:... | Jaeseong Lee, YeonJoon Jung, Seungwon Hwang |  |
| 782 |  |  [DiLM: Distilling Dataset into Language Model for Text-level Dataset Distillation](https://doi.org/10.18653/v1/2024.findings-naacl.199) |  | 0 | Dataset distillation aims to compress a training dataset by creating a small number of informative synthetic samples such that neural networks trained on them perform as well as those trained on the original training dataset. Current text dataset distillation methods create each synthetic sample as a sequence of word embeddings instead of a text to apply gradient-based optimization; however, such embedding-level distilled datasets cannot be used for training... | Aru Maekawa, Satoshi Kosugi, Kotaro Funakoshi, Manabu Okumura |  |
| 783 |  |  [MindAgent: Emergent Gaming Interaction](https://doi.org/10.18653/v1/2024.findings-naacl.200) |  | 0 | Large Foundation Models (LFMs) can perform complex scheduling in a multi-agent system and can coordinate agents to complete sophisticated tasks that require extensive collaboration.However, despite the introduction of numerous gaming frameworks, the community lacks adequate benchmarks that support the implementation of a general multi-agent infrastructure encompassing collaboration between LFMs and human-NPCs. We propose a novel infrastructure—Mindagent—for... | Ran Gong, Qiuyuan Huang, Xiaojian Ma, Yusuke Noda, Zane Durante, Zilong Zheng, Demetri Terzopoulos, Li FeiFei, Jianfeng Gao, Hoi Vo |  |
| 784 |  |  [BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.findings-naacl.201) |  | 0 | In the realm of modern Large Language Models (LLMs), facilitating high-quality, multi-turn dialogues with humans represents a cornerstone feature. However, human-based evaluation of such a capability involves substantial manual effort. This study offers a formative assessment of current LLMs’ proficiency in emulating human-like, multi-turn conversations using an LLM-centric approach. The evaluation encompasses three key elements in the evaluation pipeline:... | Haodong Duan, Jueqi Wei, Chonghua Wang, Hongwei Liu, Yixiao Fang, Songyang Zhang, Dahua Lin, Kai Chen |  |
| 785 |  |  [Learning Mutually Informed Representations for Characters and Subwords](https://doi.org/10.18653/v1/2024.findings-naacl.202) |  | 0 | Most pretrained language models rely on subword tokenization, which processes text as a sequence of subword tokens. However, different granularities of text, such as characters, subwords, and words, can contain different kinds of information. Previous studies have shown that incorporating multiple input granularities improves model generalization, yet very few of them outputs useful representations for each granularity. In this paper, we introduce the... | Yilin Wang, Xinyi Hu, Matthew Gormley |  |
| 786 |  |  [A Novel Two-step Fine-tuning Framework for Transfer Learning in Low-Resource Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.203) |  | 0 | Existing transfer learning methods for neural machine translation typically use a well-trained translation model (i.e., a parent model) of a high-resource language pair to directly initialize a translation model (i.e., a child model) of a low-resource language pair, and the child model is then fine-tuned with corresponding datasets. In this paper, we propose a novel two-step fine-tuning (TSFT) framework for transfer learning in low-resource neural machine... | Yuan Gao, Feng Hou, Ruili Wang |  |
| 787 |  |  [Enhancing Cross-lingual Sentence Embedding for Low-resource Languages with Word Alignment](https://doi.org/10.18653/v1/2024.findings-naacl.204) |  | 0 | The field of cross-lingual sentence embeddings has recently experienced significant advancements, but research concerning low-resource languages has lagged due to the scarcity of parallel corpora. This paper shows that cross-lingual word representation in low-resource languages is notably under-aligned with that in high-resource languages in current models. To address this, we introduce a novel framework that explicitly aligns words between English and eight... | Zhongtao Miao, Qiyu Wu, Kaiyan Zhao, Zilong Wu, Yoshimasa Tsuruoka |  |
| 788 |  |  [C³LPGCN:Integrating Contrastive Learning and Cooperative Learning with Prompt into Graph Convolutional Network for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.205) |  | 0 |  | Ye He, Shihao Zou, Yuzhe Chen, Xianying Huang |  |
| 789 |  |  [Visual Enhanced Entity-Level Interaction Network for Multimodal Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.206) |  | 0 | MultiModal Summarization (MMS) aims to generate a concise summary based on multimodal data like texts and images and has wide application in multimodal fields.Previous works mainly focus on the coarse-level textual and visual features in which the overall features of the image interact with the whole sentence.However, the entities of the input text and the objects of the image may be underutilized, limiting the performance of current MMS models.In this paper,... | Haolong Yan, Binghao Tang, Boda Lin, Gang Zhao, Si Li |  |
| 790 |  |  [Knowledgeable In-Context Tuning: Exploring and Exploiting Factual Knowledge for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-naacl.207) |  | 0 | Large language models (LLMs) enable in-context learning (ICL) by conditioning on a few labeled training examples as a text-based prompt, eliminating the need for parameter updates and achieving competitive performance. In this paper, we demonstrate that factual knowledge is imperative for the performance of ICL in three core facets: the inherent knowledge learned in LLMs, the factual knowledge derived from the selected in-context examples, and the knowledge... | Jianing Wang, Chengyu Wang, Chuanqi Tan, Jun Huang, Ming Gao |  |
| 791 |  |  [Time Machine GPT](https://doi.org/10.18653/v1/2024.findings-naacl.208) |  | 0 | Large language models (LLMs) are often trained on extensive, temporally indiscriminate text corpora, reflecting the lack of datasets with temporal metadata. This approach is not aligned with the evolving nature of language. Conventional methods for creating temporally adapted language models often depend on further pre-training static models on time-specific data. This paper presents a new approach: a series of point-in-time LLMs called TimeMachineGPT... | Felix Drinkall, Eghbal Rahimikia, Janet B. Pierrehumbert, Stefan Zohren |  |
| 792 |  |  [An End-to-End Submodular Framework for Data-Efficient In-Context Learning](https://doi.org/10.18653/v1/2024.findings-naacl.209) |  | 0 |  | Lilly Kumari, Shengjie Wang, Arnav Das, Tianyi Zhou, Jeff A. Bilmes |  |
| 793 |  |  [Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer](https://doi.org/10.18653/v1/2024.findings-naacl.210) |  | 0 | This paper explores cost-efficient methods to adapt pretrained Large Language Models (LLMs) to new lower-resource languages, with a specific focus on Estonian. Leveraging the Llama 2 model, we investigate the impact of combining cross-lingual instruction-tuning with additional monolingual pretraining. Our results demonstrate that even a relatively small amount of additional monolingual pretraining followed by cross-lingual instruction-tuning significantly... | HeleAndra Kuulmets, Taido Purason, Agnes Luhtaru, Mark Fishel |  |
| 794 |  |  [Simulating Opinion Dynamics with Networks of LLM-based Agents](https://doi.org/10.18653/v1/2024.findings-naacl.211) |  | 0 | Accurately simulating human opinion dynamics is crucial for understanding a variety of societal phenomena, including polarization and the spread of misinformation. However, the agent-based models (ABMs) commonly used for such simulations often over-simplify human behavior. We propose a new approach to simulating opinion dynamics based on populations of Large Language Models (LLMs). Our findings reveal a strong inherent bias in LLM agents towards producing... | YunShiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers |  |
| 795 |  |  [Probing the Category of Verbal Aspect in Transformer Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.212) |  | 0 | We investigate how pretrained language models (PLM) encode the grammatical category of verbal aspect in Russian. Encoding of aspect in transformer LMs has not been studied previously in any language. A particular challenge is posed by ”alternative contexts”: where either the perfective or the imperfective aspect is suitable grammatically and semantically. We perform probing using BERT and RoBERTa on alternative and non-alternative contexts. First, we assess... | Anisia Katinskaia, Roman Yangarber |  |
| 796 |  |  [A Measure for Transparent Comparison of Linguistic Diversity in Multilingual NLP Data Sets](https://doi.org/10.18653/v1/2024.findings-naacl.213) |  | 0 | Typologically diverse benchmarks are increasingly created to track the progress achieved in multilingual NLP. Linguistic diversity of these data sets is typically measured as the number of languages or language families included in the sample, but such measures do not consider structural properties of the included languages. In this paper, we propose assessing linguistic diversity of a data set against a reference language sample as a means of maximising... | Tanja Samardzic, Ximena Gutierrez, Christian Bentz, Steven Moran, Olga Pelloni |  |
| 797 |  |  [Beyond Read-Only: Crafting a Comprehensive Chinese Text-to-SQL Dataset for Database Manipulation and Query](https://doi.org/10.18653/v1/2024.findings-naacl.214) |  | 0 | Text-to-SQL aims to convert natural language into structured query language, which is a challenging task. Current research focuses mainly on read operations and ignores other aspects of database operations such as create, update, and delete operations. The benchmark datasets as well as models that have been proposed also fail to cover these operations, limiting the development and practical applications in the field. To bridge this gap, we propose CRUDSQL, a... | Xi Chen, Jinguo You, Likun Likun, Xiang Li |  |
| 798 |  |  [Normalizing without Modernizing: Keeping Historical Wordforms of Middle French while Reducing Spelling Variants](https://doi.org/10.18653/v1/2024.findings-naacl.215) |  | 0 | Conservation of historical documents benefits from computational methods by alleviating the manual labor related to digitization and modernization of textual content. Languages usually evolve over time and keeping historical wordforms is crucial for diachronic studies and digital humanities. However, spelling conventions did not necessarily exist when texts were originally written and orthographic variations are commonly observed depending on scribes and time... | Raphael Rubino, Johanna Gerlach, Jonathan Mutal, Pierrette Bouillon |  |
| 799 |  |  [Anti-LM Decoding for Zero-shot In-context Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.216) |  | 0 | Zero-shot In-context learning is the phenomenon where models can perform a task given only the instructions. However, pre-trained large language models are known to be poorly calibrated for zero-shot tasks. One of the most effective approaches to handling this bias is to adopt a contrastive decoding objective, which accounts for the prior probability of generating the next token by conditioning on a context. This work introduces an Anti-Language Model... | Suzanna Sia, Alexandra DeLucia, Kevin Duh |  |
| 800 |  |  [Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-naacl.217) |  | 0 | Recently, various parameter-efficient fine-tuning (PEFT) strategies for application to language models have been proposed and successfully implemented. However, this raises the question of whether PEFT, which only updates a limited set of model parameters, constitutes security vulnerabilities when confronted with weight-poisoning backdoor attacks. In this study, we show that PEFT is more susceptible to weight-poisoning backdoor attacks compared to the... | Shuai Zhao, Leilei Gan, Anh Tuan Luu, Jie Fu, Lingjuan Lyu, Meihuizi Jia, Jinming Wen |  |
| 801 |  |  [Select and Summarize: Scene Saliency for Movie Script Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.218) |  | 0 | Abstractive summarization for long-form narrative texts such as movie scripts is challenging due to the computational and memory constraints of current language models. A movie script typically comprises a large number of scenes; however, only a fraction of these scenes are salient, i.e., important for understanding the overall narrative. The salience of a scene can be operationalized by considering it as salient if it is mentioned in the summary.... | Rohit Saxena, Frank Keller |  |
| 802 |  |  [Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks](https://doi.org/10.18653/v1/2024.findings-naacl.219) |  | 0 | Offensive language detection is an important task for filtering out abusive expressions and improving online user experiences. However, malicious users often attempt to avoid filtering systems through the involvement of textual noises. In this paper, we propose these evasions as user-intended adversarial attacks that insert special symbols or leverage the distinctive features of the Korean language. Furthermore, we introduce simple yet effective pooling... | Seunguk Yu, Juhwan Choi, YoungBin Kim |  |
| 803 |  |  [Z-GMOT: Zero-shot Generic Multiple Object Tracking](https://doi.org/10.18653/v1/2024.findings-naacl.220) |  | 0 | Despite recent significant progress, Multi-Object Tracking (MOT) faces limitations such as reliance on prior knowledge and predefined categories and struggles with unseen objects. To address these issues, Generic Multiple Object Tracking (GMOT) has emerged as an alternative approach, requiring less prior information. However, current GMOT methods often rely on initial bounding boxes and struggle to handle variations in factors such as viewpoint, lighting,... | Kim Hoang Tran, Anh Duy Le Dinh, TienPhat Nguyen, Thinh Phan, Pha A. Nguyen, Khoa Luu, Donald A. Adjeroh, Gianfranco Doretto, Ngan Hoang Le |  |
| 804 |  |  [NLP for Counterspeech against Hate: A Survey and How-To Guide](https://doi.org/10.18653/v1/2024.findings-naacl.221) |  | 0 | In recent years, counterspeech has emerged as one of the most promising strategies to fight online hate. These non-escalatory responses tackle online abuse while preserving the freedom of speech of the users, and can have a tangible impact in reducing online and offline violence. Recently, there has been growing interest from the Natural Language Processing (NLP) community in addressing the challenges of analysing, collecting, classifying, and automatically... | Helena Bonaldi, YiLing Chung, Gavin Abercrombie, Marco Guerini |  |
| 805 |  |  [PRODIGy: a PROfile-based DIalogue Generation dataset](https://doi.org/10.18653/v1/2024.findings-naacl.222) |  | 0 | Providing dialogue agents with a profile representation can improve their consistency and coherence, leading to better conversations. However, current profile-based dialogue datasets for training such agents contain either explicit profile representations that are simple and dialogue-specific, or implicit representations that are difficult to collect. In this work, we introduce the PRODIGy (PROfile-based DIalogue Generation) dataset, which brings diverse... | Daniela Occhipinti, Serra Sinem Tekiroglu, Marco Guerini |  |
| 806 |  |  [WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.223) |  | 0 | Watermarking generative-AI systems, such as LLMs, has gained considerable interest, driven by their enhanced capabilities across a wide range of tasks. Although current approaches have demonstrated that small, context-dependent shifts in the word distributions can be used to apply and detect watermarks, there has been little work in analyzing the impact that these perturbations have on the quality of generated texts. Balancing high detectability with minimal... | Piotr Molenda, Adian Liusie, Mark J. F. Gales |  |
| 807 |  |  [Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking](https://doi.org/10.18653/v1/2024.findings-naacl.224) |  | 0 | While large language models (LLMs) have demonstrated increasing power, they have also called upon studies on their vulnerabilities. As representatives, jailbreak attacks can provoke harmful or unethical responses from LLMs, even after safety alignment. In this paper, we investigate a novel category of jailbreak attacks specifically designed to target the cognitive structure and processes of LLMs. Specifically, we analyze the safety vulnerability of LLMs in... | Nan Xu, Fei Wang, Ben Zhou, Bangzheng Li, Chaowei Xiao, Muhao Chen |  |
| 808 |  |  [PAELLA: Parameter-Efficient Lightweight Language-Agnostic Captioning Model](https://doi.org/10.18653/v1/2024.findings-naacl.225) |  | 0 | We introduce PAELLA, a Parameter-Efficient Lightweight Language-Agnostic image captioning model designed to be both parameter and data-efficient using retrieval augmentation. The model is trained by learning a small mapping network with 34M parameters between a pre-trained visual model and a multilingual language model that is conditioned on two types of input: (i) the image itself, and (ii) a set of retrieved captions in the target language. The retrieved... | Rita Ramos, Emanuele Bugliarello, Bruno Martins, Desmond Elliott |  |
| 809 |  |  [OSCaR: Object State Captioning and State Change Representation](https://doi.org/10.18653/v1/2024.findings-naacl.226) |  | 0 | The capability of intelligent models to extrapolate and comprehend changes in object states is a crucial yet demanding aspect of AI research, particularly through the lens of human interaction in real-world settings. This task involves describing complex visual environments, identifying active objects, and interpreting their changes as conveyed through language. Traditional methods, which isolate object captioning and state change detection, offer a limited... | Nguyen Nguyen, Jing Bi, Ali Vosoughi, Yapeng Tian, Pooyan Fazli, Chenliang Xu |  |
| 810 |  |  [SumCSE: Summary as a transformation for Contrastive Learning](https://doi.org/10.18653/v1/2024.findings-naacl.227) |  | 0 | Sentence embedding models are typically trained using contrastive learning (CL), either using human annotations directly or by repurposing other annotated datasets. In this work, we explore the recently introduced paradigm of generating CL data using generative language models (LM). In CL for computer vision (CV), compositional transformations (series of operations applied over an image. e.g. cropping + color distortion) which modify the input/image to retain... | Raghuveer Thirukovalluru, Xiaolan Wang, Jun Chen, Shuyang Li, Jie Lei, Rong Jin, Bhuwan Dhingra |  |
| 811 |  |  [The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text](https://doi.org/10.18653/v1/2024.findings-naacl.228) |  | 0 | This study investigates the consequences of training language models on synthetic data generated by their predecessors, an increasingly prevalent practice given the prominence of powerful generative models. Diverging from the usual emphasis on performance metrics, we focus on the impact of this training methodology on linguistic diversity, especially when conducted recursively over time. To assess this, we adapt and develop a set of novel metrics targeting... | Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, Chloé Clavel |  |
| 812 |  |  [PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits](https://doi.org/10.18653/v1/2024.findings-naacl.229) |  | 0 | Despite the many use cases for large language models (LLMs) in creating personalized chatbots, there has been limited research on evaluating the extent to which the behaviors of personalized LLMs accurately and consistently reflect specific personality traits. We consider studying the behavior of LLM-based agents which we refer to as LLM personas and present a case study with GPT-3.5 and GPT-4 to investigate whether LLMs can generate content that aligns with... | Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, Jad Kabbara |  |
| 813 |  |  [FIRE: A Dataset for Financial Relation Extraction](https://doi.org/10.18653/v1/2024.findings-naacl.230) |  | 0 | This paper introduces FIRE (\*\*FI\*\*nancial \*\*R\*\*elation \*\*E\*\*xtraction), a sentence-level dataset of named entities and relations within the financial sector. Comprising 3,025 instances, the dataset encapsulates 13 named entity types along with 18 relation types. Sourced from public financial reports and financial news articles, FIRE captures a wide array of financial information about a business including, but not limited to, corporate structure,... | Hassan Hamad, Abhinav Kumar Thakur, Nijil Kolleri, Sujith Pulikodan, Keith M. Chugg |  |
| 814 |  |  [MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response](https://doi.org/10.18653/v1/2024.findings-naacl.231) |  | 0 | Large Language Models (LLMs) have shown immense potential in multimodal applications, yet the convergence of textual and musical domains remains not well-explored. To address this gap, we present MusiLingo, a novel system for music caption generation and music-related query responses. MusiLingo employs a single projection layer to align music representations from the pre-trained frozen music audio model MERT (CITATION) with a frozen LLM, bridging the gap... | Zihao Deng, Yinghao Ma, Yudong Liu, Rongchen Guo, Ge Zhang, Wenhu Chen, Wenhao Huang, Emmanouil Benetos |  |
| 815 |  |  [Investigating Acceleration of LLaMA Inference by Enabling Intermediate Layer Decoding via Instruction Tuning with 'LITE'](https://doi.org/10.18653/v1/2024.findings-naacl.232) |  | 0 | Large Language Models (LLMs) have achieved remarkable performance across a wide variety of tasks; however, their large size makes their inference slow and computationally expensive. Focusing on this problem, we study instruction tuning LLMs with additional explicit Losses from the Intermediate layers (LITE) and show that it enables these layers to acquire ‘good’ generation ability without affecting the generation ability of the final layer. We then perform... | Neeraj Varshney, Agneet Chatterjee, Mihir Parmar, Chitta Baral |  |
| 816 |  |  [Instruction-following Evaluation through Verbalizer Manipulation](https://doi.org/10.18653/v1/2024.findings-naacl.233) |  | 0 | While instruction-tuned models have shown remarkable success in various natural language processing tasks, accurately evaluating their ability to follow instructions remains challenging. Existing benchmarks primarily focus on common instructions that align well with what the model learned during training. However, proficiency in responding to these instructions does not necessarily imply strong ability in instruction following. In this paper, we propose a... | Shiyang Li, Jun Yan, Hai Wang, Zheng Tang, Xiang Ren, Vijay Srinivasan, Hongxia Jin |  |
| 817 |  |  [WebWISE: Unlocking Web Interface Control for LLMs via Sequential Exploration](https://doi.org/10.18653/v1/2024.findings-naacl.234) |  | 0 | This paper investigates using Large Language Models (LLMs) to automatically perform web software tasks using click, scroll, and text in- put operations. Previous approaches, such as reinforcement learning (RL) or imitation learning, are inefficient to train and task-specific. Our method uses filtered Document Object Model (DOM) elements as observations and performs tasks step-by-step, sequentially generating small programs based on the current observations.... | Heyi Tao, Sethuraman TV, Michal ShlapentokhRothman, Tanmay Gupta, Heng Ji, Derek Hoiem |  |
| 818 |  |  [CodecLM: Aligning Language Models with Tailored Synthetic Data](https://doi.org/10.18653/v1/2024.findings-naacl.235) |  | 0 | Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and users’ actual goals. To reduce the labor and time cost to collect or annotate data by humans, researchers start to explore the use of LLMs to generate instruction-aligned synthetic data. Recent works focus on generating diverse instructions and applying LLM to... | Zifeng Wang, ChunLiang Li, Vincent Perot, Long T. Le, Jin Miao, Zizhao Zhang, ChenYu Lee, Tomas Pfister |  |
| 819 |  |  [Prompting Few-shot Multi-hop Question Generation via Comprehending Type-aware Semantics](https://doi.org/10.18653/v1/2024.findings-naacl.236) |  | 0 | Given several documents, multi-hop question generation (MQG) is a task aims to generate complicated questions that require reasoning over multiple pieces of these documents to find the answer. To perform this task, existing studies focus on designing advanced architectures to locate essential keywords or sentences in multiple documents and then generate questions accordingly, where they normally do not note that question types could provide crucial hints for... | Zefeng Lin, Weidong Chen, Yan Song, Yongdong Zhang |  |
| 820 |  |  [When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.237) |  | 0 | Recent studies suggest that self-reflective prompting can significantly enhance the reasoning capabilities of Large Language Models (LLMs). However, the use of external feedback as a stop criterion raises doubts about the true extent of LLMs’ ability to emulate human-like self-reflection. In this paper, we set out to clarify these capabilities under a more stringent evaluation setting in which we disallow any kind of external feedback. Our findings under this... | Yanhong Li, Chenghao Yang, Allyson Ettinger |  |
| 821 |  |  [CoDa: Constrained Generation based Data Augmentation for Low-Resource NLP](https://doi.org/10.18653/v1/2024.findings-naacl.238) |  | 0 | We present CoDa (\*\*Co\*\*nstrained Generation based \*\*Da\*\*ta Augmentation), a controllable, effective, and \*training-free\* data augmentation technique for low-resource (data-scarce) NLP. Our approach is based on prompting off-the-shelf instruction-following Large Language Models (LLMs) for generating text that satisfies a set of constraints. Precisely, we extract a set of simple constraints from every instance in the low-resource dataset and verbalize... | Chandra Kiran Reddy Evuru, Sreyan Ghosh, Sonal Kumar, Ramaneswaran S., Utkarsh Tyagi, Dinesh Manocha |  |
| 822 |  |  [Synonym relations affect object detection learned on vision-language data](https://doi.org/10.18653/v1/2024.findings-naacl.239) |  | 0 | We analyze whether object detectors trained on vision-language data learn effective visual representations for synonyms. Since many current vision-language models accept user-provided textual input, we highlight the need for such models to learn feature representations that are robust to changes in how such input is provided. Specifically, we analyze changes in synonyms used to refer to objects. Here, we study object detectors trained on vision-language data... | Giacomo Nebbia, Adriana Kovashka |  |
| 823 |  |  [CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models](https://doi.org/10.18653/v1/2024.findings-naacl.240) |  | 0 | Neural Text-to-Speech (TTS) systems find broad applications in voice assistants, e-learning, and audiobook creation. The pursuit of modern models, like Diffusion Models (DMs), holds promise for achieving high-fidelity, real-time speech synthesis. Yet, the efficiency of multi-step sampling in Diffusion Models presents challenges. Efforts have been made to integrate GANs with DMs, speeding up inference by approximating denoising distributions, but this... | Xiang Li, FanBu FanBu, Ambuj Mehrish, Yingting Li, Jiale Han, Bo Cheng, Soujanya Poria |  |
| 824 |  |  [RobustSentEmbed: Robust Sentence Embeddings Using Adversarial Self-Supervised Contrastive Learning](https://doi.org/10.18653/v1/2024.findings-naacl.241) |  | 0 | Pre-trained language models (PLMs) have consistently demonstrated outstanding performance across a diverse spectrum of natural language processing tasks. Nevertheless, despite their success with unseen data, current PLM-based representations often exhibit poor robustness in adversarial settings. In this paper, we introduce RobustSentEmbed, a self-supervised sentence embedding framework designed to improve both generalization and robustness in diverse text... | Javad Rafiei Asl, Prajwal Panzade, Eduardo Blanco, Daniel Takabi, Zhipeng Cai |  |
| 825 |  |  [Characterizing Human and Zero-Shot GPT-3.5 Object-Similarity Judgments](https://doi.org/10.18653/v1/2024.findings-naacl.242) |  | 0 | Recent advancements in large language models’ (LLMs) capabilities have yielded few-shot, human-comparable performance on a range of tasks. At the same time, researchers expend significant effort and resources gathering human annotations. At some point, LLMs may be able to perform some simple annotation tasks, but studies of LLM annotation accuracy and behavior are sparse. In this paper, we characterize OpenAI’s GPT-3.5’s judgment on a behavioral task for... | D. McKnight, Alona Fyshe |  |
| 826 |  |  [Self-Demos: Eliciting Out-of-Demonstration Generalizability in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.243) |  | 0 | Large language models (LLMs) have shown promising abilities of in-context learning (ICL), adapting swiftly to new tasks with only few-shot demonstrations. However, current few-shot methods heavily depend on high-quality, query-specific demos, which are often lacking. When faced with out-of-demonstration (OOD) queries, methods that rely on hand-crafted demos or external retrievers might fail. To bridge the gap between limited demos and OOD queries, we propose... | Wei He, Shichun Liu, Jun Zhao, Yiwen Ding, Yi Lu, Zhiheng Xi, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 827 |  |  [Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge Conflicts in Event Temporal Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.244) |  | 0 | Event temporal reasoning aims at identifying the temporal relations between two or more events from narratives. However, knowledge conflicts arise when there is a mismatch between the actual temporal relations of events in the context and the prior knowledge or biases learned by the model. In this paper, we propose to detect knowledge-conflict examples in event temporal reasoning using bias indicators, which include event relation prior bias, tense bias,... | Tianqing Fang, Zhaowei Wang, Wenxuan Zhou, Hongming Zhang, Yangqiu Song, Muhao Chen |  |
| 828 |  |  [MCECR: A Novel Dataset for Multilingual Cross-Document Event Coreference Resolution](https://doi.org/10.18653/v1/2024.findings-naacl.245) |  | 0 | Event coreference resolution (ECR) is a critical task in information extraction of natural language processing, aiming to identify and link event mentions across multiple documents. Despite recent progress, existing datasets for ECR primarily focus on within-document event coreference and English text, lacking cross-document ECR datasets for multiple languages beyond English. To address this issue, this work presents the first multiligual dataset for... | Amir Pouran Ben Veyseh, Viet Dac Lai, Chien Nguyen, Franck Dernoncourt, Thien Huu Nguyen |  |
| 829 |  |  [Sentiment Analysis in the Era of Large Language Models: A Reality Check](https://doi.org/10.18653/v1/2024.findings-naacl.246) |  | 0 | Sentiment analysis (SA) has been a long-standing research area in natural language processing. With the recent advent of large language models (LLMs), there is great potential for their employment on SA problems. However, the extent to which current LLMs can be leveraged for different sentiment analysis tasks remains unclear. This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks,... | Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, Lidong Bing |  |
| 830 |  |  [Tokenizer Choice For LLM Training: Negligible or Crucial?](https://doi.org/10.18653/v1/2024.findings-naacl.247) |  | 0 | The recent success of large language models (LLMs) has been predominantly driven by curating the training dataset composition, scaling of model architectures and dataset sizes and advancements in pretraining objectives, leaving tokenizer influence as a blind spot.Shedding light on this underexplored area, we conduct a comprehensive study on the influence of tokenizer choice on LLM downstream performance by training 24 mono- and multilingual LLMs at a 2.6B... | Mehdi Ali, Michael Fromm, Klaudia Thellmann, Richard Rutmann, Max Lübbering, Johannes Leveling, Katrin Klug, Jan Ebert, Niclas Doll, Jasper Schulze Buschhoff, Charvi Jain, Alexander Arno Weber, Lena Jurkschat, Hammam Abdelwahab, Chelsea John, Pedro Ortiz Suarez, Malte Ostendorff, Samuel Weinbach, Rafet Sifa, Stefan Kesselheim, Nicolas FloresHerr |  |
| 831 |  |  [Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue](https://doi.org/10.18653/v1/2024.findings-naacl.248) |  | 0 | The emergence of large language models (LLMs) further improves the capabilities of open-domain dialogue systems and can generate fluent, coherent, and diverse responses. However, LLMs still lack a crucial ability: communication skills. This limitation renders them more like information seeking tools rather than anthropomorphic chatbots. Communication skills, such as topic transition, proactively asking questions, concept guidance, empathy, and summarising... | Junkai Zhou, Liang Pang, Huawei Shen, Xueqi Cheng |  |
| 832 |  |  [The Impact of Differential Privacy on Group Disparity Mitigation](https://doi.org/10.18653/v1/2024.findings-naacl.249) |  | 0 | The performance cost of differential privacy has, for some applications, been shown to be higher for minority groups; fairness, conversely, has been shown to disproportionally compromise the privacy of members of such groups. Most work in this area has been restricted to computer vision and risk assessment. In response, we evaluate the impact of differential privacy on fairness across four diverse tasks, focusing on how attempts to mitigate privacy violations... | Victor Petrén Bach Hansen, Atula Tejaswi Neerkaje, Ramit Sawhney, Lucie Flek, Anders Søgaard |  |
| 833 |  |  [Isometric Neural Machine Translation using Phoneme Count Ratio Reward-based Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-naacl.250) |  | 0 | Traditional Automatic Video Dubbing (AVD) pipeline consists of three key modules, namely, Automatic Speech Recognition (ASR), Neural Machine Translation (NMT), and Text-to-Speech (TTS). Within AVD pipelines, isometric-NMT algorithms are employed to regulate the length of the synthesized output text. This is done to guarantee synchronization with respect to the alignment of video and audio subsequent to the dubbing process. Previous approaches have focused on... | Shivam Mhaskar, Nirmesh Shah, Mohammadi Zaki, Ashishkumar P. Gudmalwar, Pankaj Wasnik, Rajiv Ratn Shah |  |
| 834 |  |  [Read between the lines - Functionality Extraction From READMEs](https://doi.org/10.18653/v1/2024.findings-naacl.251) |  | 0 | While text summarization is a well-known NLP task, in this paper, we introduce a novel and useful variant of it called functionality extraction from Git README files. Though this task is a text2text generation at an abstract level, it involves its own peculiarities and challenges making existing text2text generation systems not very useful. The motivation behind this task stems from a recent surge in research and development activities around the use of large... | Prince Kumar, Srikanth Tamilselvam, Dinesh Garg |  |
| 835 |  |  [AbsPyramid: Benchmarking the Abstraction Ability of Language Models with a Unified Entailment Graph](https://doi.org/10.18653/v1/2024.findings-naacl.252) |  | 0 | Cognitive research indicates that abstraction ability is essential in human intelligence, which remains under-explored in language models. In this paper, we present AbsPyramid, a unified entailment graph of 221K textual descriptions of abstraction knowledge. While existing resources only touch nouns or verbs within simplified events or specific domains, AbsPyramid collects abstract knowledge for three components of diverse events to comprehensively evaluate... | Zhaowei Wang, Haochen Shi, Weiqi Wang, Tianqing Fang, Hongming Zhang, Sehyun Choi, Xin Liu, Yangqiu Song |  |
| 836 |  |  [Few-TK: A Dataset for Few-shot Scientific Typed Keyphrase Recognition](https://doi.org/10.18653/v1/2024.findings-naacl.253) |  | 0 | Scientific texts are distinctive from ordinary texts in quite a few aspects like their vocabulary and discourse structure. Consequently, Information Extraction (IE) tasks for scientific texts come with their own set of challenges. The classical definition of Named Entities restricts the inclusion of all scientific terms under its hood, which is why previous works have used the terms Named Entities and Keyphrases interchangeably. We suggest the rechristening... | Avishek Lahiri, Pratyay Sarkar, Medha Sen, Debarshi Kumar Sanyal, Imon Mukherjee |  |
| 837 |  |  [Language Models can be Deductive Solvers](https://doi.org/10.18653/v1/2024.findings-naacl.254) |  | 0 | Logical reasoning is a fundamental aspect of human intelligence and a key component of tasks like problem-solving and decision-making. Recent advancements have enabled Large Language Models (LLMs) to potentially exhibit reasoning capabilities, but complex logical reasoning remains a challenge. The state-of-the-art, solver-augmented language models, use LLMs to parse natural language logical questions into symbolic representations first and then adopt external... | Jiazhan Feng, Ruochen Xu, Junheng Hao, Hiteshi Sharma, Yelong Shen, Dongyan Zhao, Weizhu Chen |  |
| 838 |  |  [Interpreting User Requests in the Context of Natural Language Standing Instructions](https://doi.org/10.18653/v1/2024.findings-naacl.255) |  | 0 | Users of natural language interfaces, frequently powered by Large Language Models (LLMs), must often repeat their full set of preferences each time they make a similar request. We describe an approach to LLM-based dialogue modeling in which persistent user constraints and preferences – collectively termed standing instructions – are provided as additional context for such interfaces. For example, when a user states “I’m hungry”, a previously expressed... | Nikita Moghe, Patrick Xia, Jacob Andreas, Jason Eisner, Benjamin Van Durme, Harsh Jhamtani |  |
| 839 |  |  [Secure Your Model: An Effective Key Prompt Protection Mechanism for Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.256) |  | 0 | Large language models (LLMs) have notably revolutionized many domains within natural language processing due to their exceptional performance. Their security has become increasingly vital. This study is centered on protecting LLMs against unauthorized access and potential theft. We propose a simple yet effective protective measure wherein a unique key prompt is embedded within the LLM. This mechanism enables the model to respond only when presented with the... | Ruixiang Tang, YuNeng Chuang, Xuanting Cai, Mengnan Du, Xia Hu |  |
| 840 |  |  [Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.257) |  | 0 | Large language models (LLMs) can achieve impressive performance on various reasoning tasks by incorporating chain-of-thought (CoT) prompting, where step-by-step reasoning is provided to guide LLMs to generate answers to questions, and the question-rationale-answer triplets are utilized as demonstration exemplars. However, the reasoning chains of demonstrations generated by LLMs are observed to be prone to errors, which can subsequently lead to incorrect... | Jiashuo Sun, Yi Luo, Yeyun Gong, Chen Lin, Yelong Shen, Jian Guo, Nan Duan |  |
| 841 |  |  [Do Prompt Positions Really Matter?](https://doi.org/10.18653/v1/2024.findings-naacl.258) |  | 0 | Prompt-based models have gathered a lot of attention from researchers due to their remarkable advancements in the fields of zero-shot and few-shot learning. Developing an effective prompt template plays a critical role. However, prior studies have mainly focused on prompt vocabulary searching or embedding initialization within a predefined template with the prompt position fixed. In this empirical study, we conduct the most comprehensive analysis to date of... | Junyu Mao, Stuart E. Middleton, Mahesan Niranjan |  |
| 842 |  |  [Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.259) |  | 0 | How can we perform computations over natural language representations to solve tasks that require symbolic and numeric reasoning? We propose natural language embedded programs (NLEP) as a unifying framework for addressing math/symbolic reasoning, natural language understanding, and instruction following tasks. Our approach prompts a language model to generate full Python programs that define functions over data structures which contain natural language... | Tianhua Zhang, Jiaxin Ge, Hongyin Luo, YungSung Chuang, Mingye Gao, Yuan Gong, Yoon Kim, Xixin Wu, Helen Meng, Jim Glass |  |
| 843 |  |  [A Study on Scaling Up Multilingual News Framing Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.260) |  | 0 | Media framing is the study of strategically selecting and presenting specific aspects of political issues to shape public opinion. Despite its relevance to almost all societies around the world, research has been limited due to the lack of available datasets and other resources. This study explores the possibility of dataset creation through crowdsourcing, utilizing non-expert annotators to develop training corpora. We first extend framing analysis beyond... | Syeda Sabrina Akter, Antonios Anastasopoulos |  |
| 844 |  |  [ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.261) |  | 0 | As the number of language models has increased, various benchmarks have been suggested to assess the proficiency of the models in natural language understanding. However, there is a lack of such a benchmark in Vietnamese due to the difficulty in accessing natural language processing datasets or the scarcity of task-specific datasets. \*\*ViGLUE\*\*, the proposed dataset collection, is a \*\*Vi\*\*etnamese \*\*G\*\*eneral \*\*L\*\*anguage \*\*U\*\*nderstanding... | MinhNam Tran, PhuVinh Nguyen, Long Nguyen, Dien Dinh |  |
| 845 |  |  [Exploring the Trade-off Between Model Performance and Explanation Plausibility of Text Classifiers Using Human Rationales](https://doi.org/10.18653/v1/2024.findings-naacl.262) |  | 0 | Saliency post-hoc explainability methods are important tools for understanding increasingly complex NLP models. While these methods can reflect the model’s reasoning, they may not align with human intuition, making the explanations not plausible. In this work, we present a methodology for incorporating rationales, which are text annotations explaining human decisions, into text classification models. This incorporation enhances the plausibility of post-hoc... | Lucas Resck, Marcos M. Raimundo, Jorge Poco |  |
| 846 |  |  [Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language Translation](https://doi.org/10.18653/v1/2024.findings-naacl.263) |  | 0 | Parameter-efficient fine-tuning (PEFT) methods are increasingly vital in adapting large-scale pre-trained language models for diverse tasks, offering a balance between adaptability and computational efficiency. They are important in Low-Resource Language (LRL) Neural Machine Translation (NMT) to enhance translation accuracy with minimal resources. However, their practical effectiveness varies significantly across different languages. We conducted... | Tong Su, Xin Peng, Sarubi Thillainathan, David Guzmán, Surangika Ranathunga, EnShiun Annie Lee |  |
| 847 |  |  [ADaPT: As-Needed Decomposition and Planning with Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.264) |  | 0 | Large Language Models (LLMs) are increasingly being used for interactive decision-making tasks requiring planning and adapting to the environment. Recent works employ LLMs-as-agents in broadly two ways: iteratively determining the next action (iterative executors) or generating plans and executing sub-tasks using LLMs (plan-and-execute). However, these methods struggle with task complexity, as the inability to execute any sub-task may lead to task failure. To... | Archiki Prasad, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, Mohit Bansal, Tushar Khot |  |
| 848 |  |  [Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations](https://doi.org/10.18653/v1/2024.findings-naacl.265) |  | 0 | Machine Translation (MT) remains one of the last NLP tasks where large language models (LLMs) have not yet replaced dedicated supervised systems. This work exploits the complementary strengths of LLMs and supervised MT by guiding LLMs to automatically post-edit MT with external feedback on its quality, derived from Multidimensional Quality Metric (MQM) annotations. Working with LLaMA-2 models, we consider prompting strategies varying the nature of feedback... | Dayeon Ki, Marine Carpuat |  |
| 849 |  |  [Non-contrastive sentence representations via self-supervision](https://doi.org/10.18653/v1/2024.findings-naacl.266) |  | 0 | Sample contrastive methods, typically referred to simply as contrastive are the foundation of most unsupervised methods to learn text and sentence embeddings. On the other hand, a different class of self-supervised non-contrastive loss functions and methods have been considered in the computer vision community and referred to as dimension contrastive. In this paper, we thoroughly compare this class of methods with the standard baseline for contrastive... | Duccio Pappadopulo, Marco Farina |  |
| 850 |  |  [Semantically-Prompted Language Models Improve Visual Descriptions](https://doi.org/10.18653/v1/2024.findings-naacl.267) |  | 0 | Language-vision models like CLIP have made significant strides in vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive visual descriptions remains challenging; descriptions produced by current methods are often ambiguous and lacking in granularity. To tackle these issues, we propose V-GLOSS: Visual Glosses, a novel method built upon two key ideas. The first is Semantic Prompting, which conditions a language... | Michael Ogezi, Bradley Hauer, Grzegorz Kondrak |  |
| 851 |  |  [GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.268) |  | 0 | The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional embedding-based and rule-based methods dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However,... | Ruotong Liao, Xu Jia, Yangzhe Li, Yunpu Ma, Volker Tresp |  |
| 852 |  |  [A Transformer with Stack Attention](https://doi.org/10.18653/v1/2024.findings-naacl.269) |  | 0 | Natural languages are believed to be (mildly) context-sensitive. Despite underpinning remarkably capable large language models, transformers are unable to model many context-free language tasks. In an attempt to address this limitation in the modeling power of transformer-based language models, we propose augmenting them with a differentiable, stack-based attention mechanism. Our stack-basedattention mechanism can be incorporated into any transformer-based... | Jiaoda Li, Jennifer C. White, Mrinmaya Sachan, Ryan Cotterell |  |
| 853 |  |  [InstructEval: Systematic Evaluation of Instruction Selection Methods](https://doi.org/10.18653/v1/2024.findings-naacl.270) |  | 0 | In-context learning (ICL) performs tasks by prompting a large language model (LLM) using an instruction and a small set of annotated examples called demonstrations. Recent work has shown that precise details of the inputs used in the ICL prompt significantly impact performance, which has incentivized instruction selection algorithms. The effect of instruction-choice however is severely underexplored, with existing analyses restricted to shallow subsets of... | Anirudh Ajith, Chris Pan, Mengzhou Xia, Ameet Deshpande, Karthik Narasimhan |  |
| 854 |  |  [RecMind: Large Language Model Powered Agent For Recommendation](https://doi.org/10.18653/v1/2024.findings-naacl.271) |  | 0 | While the recommendation system (RS) has advanced significantly through deep learning, current RS approaches usually train and fine-tune models on task-specific datasets, limiting their generalizability to new recommendation tasks and their ability to leverage external knowledge due to model scale and data size constraints. Thus, we designed an LLM-powered autonomous recommender agent, RecMind, which is capable of leveraging external knowledge, utilizing... | Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Yanbin Lu, Xiaojiang Huang, Yingzhen Yang |  |
| 855 |  |  [GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided Language Data Generation](https://doi.org/10.18653/v1/2024.findings-naacl.272) |  | 0 | Knowledge distillation from LLMs is essential for the efficient deployment of language models. Prior works have proposed data generation using LLMs for preparing distilled models. We argue that generating data with LLMs is prone to sampling mainly from the center of original content distribution. This limitation hinders the distilled model from learning the true underlying data distribution and to forget the tails of the distributions (samples with lower... | Mohsen Gholami, Mohammad Akbari, Tianxi Hu, Vaden Masrani, Z. Wang, Yong Zhang |  |
| 856 |  |  [How Lexical is Bilingual Lexicon Induction?](https://doi.org/10.18653/v1/2024.findings-naacl.273) |  | 0 | In contemporary machine learning approaches to bilingual lexicon induction (BLI), a model learns a mapping between the embedding spaces of a language pair. Recently, retrieve-and-rank approach to BLI has achieved state of the art results on the task. However, the problem remains challenging in low-resource settings, due to the paucity of data. The task is complicated by factors such as lexical variation across languages. We argue that the incorporation of... | Harsh Kohli, Helian Feng, Nicholas Dronen, Calvin McCarter, Sina Moeini, Ali Kebarighotbi |  |
| 857 |  |  [Fumbling in Babel: An Investigation into ChatGPT's Language Identification Ability](https://doi.org/10.18653/v1/2024.findings-naacl.274) |  | 0 | ChatGPT has recently emerged as a powerful NLP tool that can carry out a variety of tasks. However, the range of languages ChatGPT can handle remains largely a mystery. To uncover which languages ChatGPT ‘knows’, we investigate its language identification (LID) abilities. For this purpose, we compile Babel-670, a benchmark comprising 670 languages representing 23 language families spoken in five continents. Languages in Babel-670 run the gamut from the very... | WeiRui Chen, Ife Adebara, Khai Duy Doan, Qisheng Liao, Muhammad AbdulMageed |  |
| 858 |  |  [Targeted Augmentation for Low-Resource Event Extraction](https://doi.org/10.18653/v1/2024.findings-naacl.275) |  | 0 | Addressing the challenge of low-resource information extraction remains an ongoing issue due to the inherent information scarcity within limited training examples. Existing data augmentation methods, considered potential solutions, struggle to strike a balance between weak augmentation (e.g., synonym augmentation) and drastic augmentation (e.g., conditional generation without proper guidance). This paper introduces a novel paradigm that employs targeted... | Sijia Wang, Lifu Huang |  |
| 859 |  |  [Asking More Informative Questions for Grounded Retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.276) |  | 0 | When a model is trying to gather information in an interactive setting, it benefits from asking informative questions. However, in the case of a grounded multi-turn image identification task, previous studies have been constrained to polar yes/no questions (White et al., 2021), limiting how much information the model can gain in a single turn. We present an approach that formulates more informative, open-ended questions. In doing so, we discover that... | Sedrick Keh, Justin T. Chiu, Daniel Fried |  |
| 860 |  |  [Efficient Citer: Tuning Large Language Models for Enhanced Answer Quality and Verification](https://doi.org/10.18653/v1/2024.findings-naacl.277) |  | 0 | In recent years, there has been a growing interest in utilizing external knowledge to reduce hallucinations in large language models (LLMs) and provide them with updated information. Despite this improvement, a major challenge lies in the lack of explicit citations, which hampers the ability to verify the information generated by these models.This paper focuses on providing models with citation capabilities efficiently. By constructing a dataset of citations,... | Marzieh S. Tahaei, Aref Jafari, Ahmad Rashid, David AlfonsoHermelo, Khalil Bibi, Yimeng Wu, Ali Ghodsi, Boxing Chen, Mehdi Rezagholizadeh |  |
| 861 |  |  [Addressing Healthcare-related Racial and LGBTQ+ Biases in Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.278) |  | 0 | Recent studies have highlighted the issue of Pretrained Language Models (PLMs) inadvertently propagating social stigmas and stereotypes, a critical concern given their widespread use. This is particularly problematic in sensitive areas like healthcare, where such biases could lead to detrimental outcomes. Our research addresses this by adapting two intrinsic bias benchmarks to quantify racial and LGBTQ+ biases in prevalent PLMs. We also empirically evaluate... | Sean Xie, Saeed Hassanpour, Soroush Vosoughi |  |
| 862 |  |  [ATG: Benchmarking Automated Theorem Generation for Generative Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.279) |  | 0 | Humans can develop new theorems to explore broader and more complex mathematical results.While current generative language models (LMs) have achieved significant improvement in automatically proving theorems, their ability to generate new or reusable theorems is still under-explored. Without the new theorems, current LMs struggle to prove harder theorems that are distant from the given hypotheses with the exponentially growing search space.More advanced... | Xiaohan Lin, Qingxing Cao, Yinya Huang, Zhicheng Yang, Zhengying Liu, Zhenguo Li, Xiaodan Liang |  |
| 863 |  |  [Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.280) |  | 0 | While large language models (LLMs) can already achieve strong performance on standard generic summarization benchmarks, their performance on more complex summarization task settings is less studied. Therefore, we benchmark LLMs on instruction controllable text summarization, where the model input consists of both a source article and a natural language requirement for desired summary characteristics. To this end, we curate an evaluation-only dataset for this... | Yixin Liu, Alexander R. Fabbri, Jiawen Chen, Yilun Zhao, Simeng Han, Shafiq Joty, Pengfei Liu, Dragomir Radev, ChienSheng Wu, Arman Cohan |  |
| 864 |  |  [NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.281) |  | 0 | Comparative knowledge (e.g., steel is stronger and heavier than styrofoam) is an essential component of our world knowledge, yet understudied in prior literature. In this paper, we harvest the dramatic improvements in knowledge capabilities of language models into a large-scale comparative knowledge base. While the ease of acquisition of such comparative knowledge is much higher from extreme-scale models like GPT-4, compared to their considerably smaller and... | Phillip Howard, Junlin Wang, Vasudev Lal, Gadi Singer, Yejin Choi, Swabha Swayamdipta |  |
| 865 |  |  [Emotion-Anchored Contrastive Learning Framework for Emotion Recognition in Conversation](https://doi.org/10.18653/v1/2024.findings-naacl.282) |  | 0 | Emotion Recognition in Conversation (ERC) involves detecting the underlying emotion behind each utterance within a conversation. Effectively generating representations for utterances remains a significant challenge in this task. Recent works propose various models to address this issue, but they still struggle with differentiating similar emotions such as excitement and happiness. To alleviate this problem, We propose an Emotion-Anchored Contrastive Learning... | Fangxu Yu, Junjie Guo, Zhen Wu, Xinyu Dai |  |
| 866 |  |  [SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.283) |  | 0 |  | Shicheng Liu, Jialiang Xu, Wesley Tjangnaka, Sina J. Semnani, Chen Jie Yu, Monica Lam |  |
| 867 |  |  [On Evaluating the Integration of Reasoning and Action in LLM Agents with Database Question Answering](https://doi.org/10.18653/v1/2024.findings-naacl.284) |  | 0 | This study introduces a new long-form database question answering dataset designed to evaluate how Large Language Models (LLMs) interact with a SQL interpreter. The task necessitates LLMs to strategically generate multiple SQL queries to retrieve sufficient data from a database, to reason with the acquired context, and to synthesize them into a comprehensive analytical narrative. Our findings highlight that this task poses great challenges even for the... | Linyong Nan, Ellen Zhang, Weijin Zou, Yilun Zhao, Wenfei Zhou, Arman Cohan |  |
| 868 |  |  [CARE: Extracting Experimental Findings From Clinical Literature](https://doi.org/10.18653/v1/2024.findings-naacl.285) |  | 0 | Extracting fine-grained experimental findings from literature can provide dramatic utility for scientific applications. Prior work has developed annotation schemas and datasets for limited aspects of this problem, failing to capture the real-world complexity and nuance required. Focusing on biomedicine, this work presents CARE—a new IE dataset for the task of extracting clinical findings. We develop a new annotation schema capturing fine-grained findings as... | Aakanksha Naik, Bailey Kuehl, Erin Bransom, Doug Downey, Tom Hope |  |
| 869 |  |  [Personalized Federated Learning for Text Classification with Gradient-Free Prompt Tuning](https://doi.org/10.18653/v1/2024.findings-naacl.286) |  | 0 | In this paper, we study personalized federated learning for text classification with Pretrained Language Models (PLMs). We identify two challenges in efficiently leveraging PLMs for personalized federated learning: 1) Communication. PLMs are usually large in size, e.g., with hundreds of millions of parameters, inducing huge communication cost in a federated setting. 2) Local Training. Training with PLMs generally requires back-propagation, during which memory... | Rui Wang, Tong Yu, Ruiyi Zhang, Sungchul Kim, Ryan A. Rossi, Handong Zhao, Junda Wu, Subrata Mitra, Lina Yao, Ricardo Henao |  |
| 870 |  |  [SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation](https://doi.org/10.18653/v1/2024.findings-naacl.287) |  | 0 | Knowledge base question generation (KBQG) aims to generate natural language questions from a set of triplet facts extracted from KB. Existing methods have significantly boosted the performance of KBQG via pre-trained language models (PLMs) thanks to the richly endowed semantic knowledge. With the advance of pre-training techniques, large language models (LLMs) (e.g., GPT-3.5) undoubtedly possess much more semantic knowledge. Therefore, how to effectively... | Shasha Guo, Lizi Liao, Jing Zhang, Yanling Wang, Cuiping Li, Hong Chen |  |
| 871 |  |  [Biomedical Entity Representation with Graph-Augmented Multi-Objective Transformer](https://doi.org/10.18653/v1/2024.findings-naacl.288) |  | 0 | Modern biomedical concept representations are mostly trained on synonymous concept names from a biomedical knowledge base, ignoring the inter-concept interactions and a concept’s local neighborhood in a knowledge base graph. In this paper, we introduce Biomedical Entity Representation with a Graph-Augmented Multi-Objective Transformer (BERGAMOT), which adopts the power of pre-trained language models (LMs) and graph neural networks to capture both... | Andrey Sakhovskiy, Natalia Semenova, Artur Kadurin, Elena Tutubalina |  |
| 872 |  |  [Cross-Lingual Summarization with Pseudo-Label Regularization](https://doi.org/10.18653/v1/2024.findings-naacl.289) |  | 0 | Cross-Lingual Summarization (XLS) aims to summarize a document in the source language into a condensed version in the target language, effectively removing language barriers for non-native readers. Previous approaches, however, have the same limitation that only a single reference (gold summary) is exploited during model training, making the base model exposed to an underrepresented hypothesis space since the actual number of possible hypotheses is... | Thang Le |  |
| 873 |  |  [On the Way to Gentle AI Counselor: Politeness Cause Elicitation and Intensity Tagging in Code-mixed Hinglish Conversations for Social Good](https://doi.org/10.18653/v1/2024.findings-naacl.290) |  | 0 | Politeness is a multifaceted concept influenced by individual perceptions of what is considered polite or impolite. With this objective, we introduce a novel task - Politeness Cause Elicitation and Intensity Tagging (PCEIT). This task focuses on conversations and aims to identify the underlying reasons behind the use of politeness and gauge the degree of politeness conveyed. To address this objective, we create HING-POEM, a new conversational dataset in... | Priyanshu Priya, Gopendra Vikram Singh, Mauajama Firdaus, Jyotsna Agrawal, Asif Ekbal |  |
| 874 |  |  [Leveraging Summarization for Unsupervised Dialogue Topic Segmentation](https://doi.org/10.18653/v1/2024.findings-naacl.291) |  | 0 | Traditional approaches to dialogue segmentation perform reasonably well on synthetic or written dialogues but suffer when dealing with spoken, noisy dialogs. In addition, such methods require careful tuning of hyperparameters. We propose to leverage a novel approach that is based on dialogue summaries. Experiments on different datasets showed that the new approach outperforms popular state-of-the-art algorithms in unsupervised topic segmentation and requires... | Aleksei Artemiev, Daniil Parinov, Alexey Grishanov, Ivan Borisov, Alexey Vasilev, Daniil Muravetskii, Aleksey Rezvykh, Aleksei Goncharov, Andrey V. Savchenko |  |
| 875 |  |  [LLaMA-Rider: Spurring Large Language Models to Explore the Open World](https://doi.org/10.18653/v1/2024.findings-naacl.292) |  | 0 | Recently, various studies have leveraged Large Language Models (LLMs) to help decision-making and planning in environments and try to align the LLMs’ knowledge with the world conditions. Nonetheless, the capacity of LLMs to continuously acquire environmental knowledge and adapt in an open world remains uncertain. In this paper, we propose an approach to spur LLMs to explore the open world, gather experiences, and learn to improve their task-solving... | Yicheng Feng, Yuxuan Wang, Jiazheng Liu, Sipeng Zheng, Zongqing Lu |  |
| 876 |  |  [Contrastive Learning as a Polarizer: Mitigating Gender Bias by Fair and Biased sentences](https://doi.org/10.18653/v1/2024.findings-naacl.293) |  | 0 | Recently, language models have accelerated the improvement in natural language processing. However, recent studies have highlighted a significant issue: social biases inherent in training data can lead models to learn and propagate these biases. In this study, we propose a contrastive learning method for bias mitigation, utilizing anchor points to push further negatives and pull closer positives within the representation space. This approach employs... | Kyungmin Park, Sihyun Oh, Daehyun Kim, Juae Kim |  |
| 877 |  |  [PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics](https://doi.org/10.18653/v1/2024.findings-naacl.294) |  | 0 |  | Derui Zhu, Dingfan Chen, Qing Li, Zongxiong Chen, Lei Ma, Jens Grossklags, Mario Fritz |  |
| 878 |  |  [Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.295) |  | 0 | In today’s digital world, seeking answers to health questions on the Internet is a common practice. However, existing question answering (QA) systems often rely on using pre-selected and annotated evidence documents, thus making them inadequate for addressing novel questions. Our study focuses on the open-domain QA setting, where the key challenge is to first uncover relevant evidence in large knowledge bases. By utilizing the common retrieve-then-read QA... | Juraj Vladika, Florian Matthes |  |
| 879 |  |  [DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers](https://doi.org/10.18653/v1/2024.findings-naacl.296) |  | 0 | In recent years, several interpretability methods have been proposed to interpret the inner workings of Transformer models at different levels of precision and complexity.In this work, we propose a simple but effective technique to analyze encoder-decoder Transformers. Our method, which we name DecoderLens, allows the decoder to cross-attend representations of intermediate encoder activations instead of using the default final encoder output.The method thus... | Anna Langedijk, Hosein Mohebbi, Gabriele Sarti, Willem H. Zuidema, Jaap Jumelet |  |
| 880 |  |  [Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias](https://doi.org/10.18653/v1/2024.naacl-short.1) |  | 0 | We characterize and study zero-shot abstractive summarization in Large Language Models (LLMs) by measuring position bias, which we propose as a general formulation of the more restrictive lead bias phenomenon studied previously in the literature. Position bias captures the tendency of a model unfairly prioritizing information from certain parts of the input text over others, leading to undesirable behavior. Through numerous experiments on four diverse... | Anshuman Chhabra, Hadi Askari, Prasant Mohapatra |  |
| 881 |  |  [Struc-Bench: Are Large Language Models Good at Generating Complex Structured Tabular Data?](https://doi.org/10.18653/v1/2024.naacl-short.2) |  | 0 | Despite the remarkable capabilities of Large Language Models (LLMs) like GPT-4, producing complex, structured tabular data remains challenging. Our study assesses LLMs’ proficiency in structuring tables and introduces a novel fine-tuning method, cognizant of data structures, to bolster their performance. We unveil Struc-Bench, a comprehensive benchmark featuring prominent LLMs (GPT-NeoX-20B, GPT-3.5, GPT-4, and Vicuna), which spans text tables, HTML, and... | Xiangru Tang, Yiming Zong, Jason Phang, Yilun Zhao, Wangchunshu Zhou, Arman Cohan, Mark Gerstein |  |
| 882 |  |  [Improving Toponym Resolution by Predicting Attributes to Constrain Geographical Ontology Entries](https://doi.org/10.18653/v1/2024.naacl-short.3) |  | 0 | Geocoding is the task of converting location mentions in text into structured geospatial data.We propose a new prompt-based paradigm for geocoding, where the machine learning algorithm encodes only the location mention and its context.We design a transformer network for predicting the country, state, and feature class of a location mention, and a deterministic algorithm that leverages the country, state, and feature class predictions as constraints in a... | Zeyu Zhang, Egoitz Laparra, Steven Bethard |  |
| 883 |  |  [Advancing Regular Language Reasoning in Linear Recurrent Neural Networks](https://doi.org/10.18653/v1/2024.naacl-short.4) |  | 0 | In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language and long-range modeling, while offering rapid parallel training and constant inference cost. With the resurgence of interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations... | TingHan Fan, TaChung Chi, Alexander Rudnicky |  |
| 884 |  |  [Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers](https://doi.org/10.18653/v1/2024.naacl-short.5) |  | 0 | Identifying linguistic differences between dialects of a language often requires expert knowledge and meticulous human analysis. This is largely due to the complexity and nuance involved in studying various dialects. We present a novel approach to extract distinguishing lexical features of dialects by utilizing interpretable dialect classifiers, even in the absence of human experts. We explore both post-hoc and intrinsic approaches to interpretability,... | Roy Xie, Orevaoghene Ahia, Yulia Tsvetkov, Antonios Anastasopoulos |  |
| 885 |  |  [Clear Up Confusion: Advancing Cross-Domain Few-Shot Relation Extraction through Relation-Aware Prompt Learning](https://doi.org/10.18653/v1/2024.naacl-short.6) |  | 0 | Cross-domain few-shot Relation Extraction (RE) aims to transfer knowledge from a source domain to a different target domain to address low-resource problems.Previous work utilized label descriptions and entity information to leverage the knowledge of the source domain.However, these models are prone to confusion when directly applying this knowledge to a target domain with entirely new types of relations, which becomes particularly pronounced when facing... | Ge Bai, Chenji Lu, Daichi Guo, Shilong Li, Ying Liu, Zhang Zhang, Guanting Dong, Ruifang Liu, Yong Sun |  |
| 886 |  |  [Fusion Makes Perfection: An Efficient Multi-Grained Matching Approach for Zero-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.naacl-short.7) |  | 0 | Predicting unseen relations that cannot be observed during the training phase is a challenging task in relation extraction. Previous works have made progress by matching the semantics between input instances and label descriptions. However, fine-grained matching often requires laborious manual annotation, and rich interactions between instances and label descriptions come with significant computational overhead. In this work, we propose an efficient... | Shilong Li, Ge Bai, Zhang Zhang, Ying Liu, Chenji Lu, Daichi Guo, Ruifang Liu, Yong Sun |  |
| 887 |  |  [Personalized Review Recommendation based on Implicit dimension mining](https://doi.org/10.18653/v1/2024.naacl-short.8) |  | 0 | Users usually browse product reviews before buying products from e-commerce websites. Lots of e-commerce websites can recommend reviews. However, existing research on review recommendation mainly focuses on the general usefulness of reviews and ignores personalized and implicit requirements. To address the issue, we propose a Large language model driven Personalized Review Recommendation model based on Implicit dimension mining (PRR-LI). The model mines... | Bei Xu, Yifan Xu |  |
| 888 |  |  [Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence](https://doi.org/10.18653/v1/2024.naacl-short.9) |  | 0 | Recent large language models (LLMs) have shown remarkable performance in aligning generated text with user intentions across various tasks. When it comes to long-form text generation, there has been a growing interest in generation from a discourse coherence perspective.However, existing lexical or semantic metrics such as BLEU, ROUGE, BertScore cannot effectively capture the discourse coherence.The development of discourse-specific automatic evaluation... | Yinhong Liu, Yixuan Su, Ehsan Shareghi, Nigel Collier |  |
| 889 |  |  [Returning to the Start: Generating Narratives with Related Endpoints](https://doi.org/10.18653/v1/2024.naacl-short.10) |  | 0 | Human writers often \*bookend\* their writing with ending sentences that relate back to the beginning sentences in order to compose a satisfying narrative that “closes the loop.” Motivated by this observation, we propose RENarGen, a controllable story-generation paradigm that generates narratives by ensuring the first and last sentences are related and then infilling the middle sentences. Our contributions include an initial exploration of how various methods... | Anneliese Brei, Chao Zhao, Snigdha Chaturvedi |  |
| 890 |  |  [Unified Examination of Entity Linking in Absence of Candidate Sets](https://doi.org/10.18653/v1/2024.naacl-short.11) |  | 0 | Despite remarkable strides made in the development of entity linking systems in recent years, a comprehensive comparative analysis of these systems using a unified framework is notably absent. This paper addresses this oversight by introducing a new black-box benchmark and conducting a comprehensive evaluation of all state-of-the-art entity linking methods. We use an ablation study to investigate the impact of candidate sets on the performance of entity... | Nicolas Ong, Hassan Shavarani, Anoop Sarkar |  |
| 891 |  |  [MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages](https://doi.org/10.18653/v1/2024.naacl-short.12) |  | 0 | Text detoxification is a textual style transfer (TST) task where a text is paraphrased from a toxic surface form, e.g. featuring rude words, to the neutral register. Recently, text detoxification methods found their applications in various task such as detoxification of Large Language Models (LLMs) (Leong et al., 2023; He et al., 2024; Tang et al., 2023) and toxic speech combating in social networks (Deng et al., 2023; Mun et al., 2023; Agarwal et al., 2023).... | Daryna Dementieva, Nikolay Babakov, Alexander Panchenko |  |
| 892 |  |  [SKICSE: Sentence Knowable Information Prompted by LLMs Improves Contrastive Sentence Embeddings](https://doi.org/10.18653/v1/2024.naacl-short.13) |  | 0 | Contrastive learning, which utilizes positive pairs and in-batch negatives to optimize the loss objective, has been proven to be an effective method for learning sentence embeddings. However, we argue that the previous methods of constructing positive pairs only through dropout perturbation or entailment relation are limited. Since there is more sentence knowable information (SKI) to be mined, such as sentence external knowledge, semantic analysis, and... | Fangwei Ou, Jinan Xu |  |
| 893 |  |  [A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models](https://doi.org/10.18653/v1/2024.naacl-short.14) |  | 0 | Counter narratives - informed responses to hate speech contexts designed to refute hateful claims and de-escalate encounters - have emerged as an effective hate speech intervention strategy. While previous work has proposed automatic counter narrative generation methods to aid manual interventions, the evaluation of these approaches remains underdeveloped. Previous automatic metrics for counter narrative evaluation lack alignment with human judgment as they... | Jaylen Jones, Lingbo Mo, Eric FoslerLussier, Huan Sun |  |
| 894 |  |  [How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes](https://doi.org/10.18653/v1/2024.naacl-short.15) |  | 0 | Large language models (LLM) have recently shown the extraordinary ability to perform unseen tasks based on few-shot examples provided as text, also known as in-context learning (ICL). While recent works have attempted to understand the mechanisms driving ICL, few have explored training strategies that incentivize these models to generalize to multiple tasks. Multi-task learning (MTL) for generalist models is a promising direction that offers transfer learning... | Harmon Bhasin, Timothy Ossowski, Yiqiao Zhong, Junjie Hu |  |
| 895 |  |  [CELI: Simple yet Effective Approach to Enhance Out-of-Domain Generalization of Cross-Encoders](https://doi.org/10.18653/v1/2024.naacl-short.16) |  | 0 | In text ranking, it is generally believed that the cross-encoders already gather sufficient token interaction information via the attention mechanism in the hidden layers. However, our results show that the cross-encoders can consistently benefit from additional token interaction in the similarity computation at the last layer. We introduce CELI (Cross-Encoder with Late Interaction), which incorporates a late interaction layer into the current cross-encoder... | Xinyu Zhang, Minghan Li, Jimmy Lin |  |
| 896 |  |  [ContrastiveMix: Overcoming Code-Mixing Dilemma in Cross-Lingual Transfer for Information Retrieval](https://doi.org/10.18653/v1/2024.naacl-short.17) |  | 0 | Multilingual pretrained language models (mPLMs) have been widely adopted in cross-lingual transfer, and code-mixing has demonstrated effectiveness across various tasks in the absence of target language data. Our contribution involves an in-depth investigation into the counterproductive nature of training mPLMs on code-mixed data for information retrieval (IR). Our finding is that while code-mixing demonstrates a positive effect in aligning representations... | Junggeun Do, Jaeseong Lee, Seungwon Hwang |  |
| 897 |  |  [SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window](https://doi.org/10.18653/v1/2024.naacl-short.18) |  | 0 | Reference-based metrics that operate at the sentence-level typically outperform quality estimation metrics, which have access only to the source and system output.This is unsurprising, since references resolve ambiguities that may be present in the source.In this paper, we investigate whether additional source context can effectively substitute for a reference.We present a metric named SLIDE (SLIding Document Evaluator), which operates on blocks of sentences.... | Vikas Raunak, Tom Kocmi, Matt Post |  |
| 898 |  |  [Separately Parameterizing Singleton Detection Improves End-to-end Neural Coreference Resolution](https://doi.org/10.18653/v1/2024.naacl-short.19) |  | 0 | Current end-to-end coreference resolution models combine detection of singleton mentions and antecedent linking into a single step. In contrast, singleton detection was often treated as a separate step in the pre-neural era. In this work, we show that separately parameterizing these two sub-tasks also benefits end-to-end neural coreference systems. Specifically, we add a singleton detector to the coarse-to-fine (C2F) coreference model, and design an... | Xiyuan Zou, Yiran Li, Ian Porada, Jackie C. K. Cheung |  |
| 899 |  |  [Unveiling Divergent Inductive Biases of LLMs on Temporal Data](https://doi.org/10.18653/v1/2024.naacl-short.20) |  | 0 | Unraveling the intricate details of events in natural language necessitates a subtle understanding of temporal dynamics. Despite the adeptness of Large Language Models (LLMs) in discerning patterns and relationships from data, their inherent comprehension of temporal dynamics remains a formidable challenge. This research meticulously explores these intrinsic challenges within LLMs, with a specific emphasis on evaluating the performance of GPT-3.5 and GPT-4... | Sindhu Kishore, Hangfeng He |  |
| 900 |  |  [On Retrieval Augmentation and the Limitations of Language Model Training](https://doi.org/10.18653/v1/2024.naacl-short.21) |  | 0 | Augmenting a language model (LM) with k-nearest neighbors (kNN) retrieval on its training data alone can decrease its perplexity, though the underlying reasons for this remain elusive. In this work, we rule out one previously posited possibility — the “softmax bottleneck.” We then create a new dataset to evaluate LM generalization ability in the setting where training data contains additional information that is not causally relevant. This task is challenging... | TingRui Chiang, Xinyan Yu, Joshua Robinson, Ollie Liu, Isabelle Lee, Dani Yogatama |  |
| 901 |  |  [GenDecider: Integrating "None of the Candidates" Judgments in Zero-Shot Entity Linking Re-ranking](https://doi.org/10.18653/v1/2024.naacl-short.22) |  | 0 | We introduce GenDecider, a novel re-ranking approach for Zero-Shot Entity Linking (ZSEL), built on the Llama model. It innovatively detects scenarios where the correct entity is not among the retrieved candidates, a common oversight in existing re-ranking methods. By autoregressively generating outputs based on the context of the entity mention and the candidate entities, GenDecider significantly enhances disambiguation, improving the accuracy and reliability... | Kang Zhou, Yuepei Li, Qing Wang, Qiao Qiao, Qi Li |  |
| 902 |  |  [Advancing the Robustness of Large Language Models through Self-Denoised Smoothing](https://doi.org/10.18653/v1/2024.naacl-short.23) |  | 0 | Although large language models (LLMs) have achieved significant success, their vulnerability to adversarial perturbations, including recent jailbreak attacks, has raised considerable concerns. However, the increasing size of these models and their limited access make improving their robustness a challenging task. Among various defense strategies, randomized smoothing has shown great potential for LLMs, as it does not require full access to the model’s... | Jiabao Ji, Bairu Hou, Zhen Zhang, Guanhua Zhang, Wenqi Fan, Qing Li, Yang Zhang, Gaowen Liu, Sijia Liu, Shiyu Chang |  |
| 903 |  |  [Can LLM's Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis](https://doi.org/10.18653/v1/2024.naacl-short.24) |  | 0 | We present a novel approach to automatically synthesize “wayfinding instructions” for an embodied robot agent. In contrast to prior approaches that are heavily reliant on human-annotated datasets designed exclusively for specific simulation platforms, our algorithm uses in-context learning to condition an LLM to generate instructions using just a few references. Using an LLM-based Visual Question Answering strategy, we gather detailed information about the... | Vishnu Sashank Dorbala, Sanjoy Chowdhury, Dinesh Manocha |  |
| 904 |  |  [On the Role of Summary Content Units in Text Summarization Evaluation](https://doi.org/10.18653/v1/2024.naacl-short.25) |  | 0 | At the heart of the Pyramid evaluation method for text summarization lie human written summary content units (SCUs). These SCUs areconcise sentences that decompose a summary into small facts. Such SCUs can be used to judge the quality of a candidate summary, possibly partially automated via natural language inference (NLI) systems. Interestingly, with the aim to fully automate the Pyramid evaluation, Zhang and Bansal (2021) show that SCUs can be approximated... | Marcel Nawrath, Agnieszka Nowak, Tristan Ratz, Danilo C. Walenta, Juri Opitz, Leonardo F. R. Ribeiro, João Sedoc, Daniel Deutsch, Simon Mille, Yixin Liu, Sebastian Gehrmann, Lining Zhang, Saad Mahamood, Miruna Clinciu, Khyathi Raghavi Chandu, Yufang Hou |  |
| 905 |  |  [More room for language: Investigating the effect of retrieval on language models](https://doi.org/10.18653/v1/2024.naacl-short.26) |  | 0 | Retrieval-augmented language models pose a promising alternative to standard language modeling. During pretraining, these models search in a corpus of documents for contextually relevant information that could aid the language modeling objective. We introduce an ‘ideal retrieval’ methodology to study these models in a fully controllable setting. We conduct an extensive evaluation to examine how retrieval augmentation affects the behavior of the underlying... | David Samuel, Lucas Georges Gabriel Charpentier, Sondre Wold |  |
| 906 |  |  [Discourse-Aware In-Context Learning for Temporal Expression Normalization](https://doi.org/10.18653/v1/2024.naacl-short.27) |  | 0 | Temporal expression (TE) normalization is a well-studied problem. However, the predominately used rule-based systems are highly restricted to specific settings, and upcoming machine learning approaches suffer from a lack of labeled data. In this work, we explore the feasibility of proprietary and open-source large language models (LLMs) for TE normalization using in-context learning to inject task, document, and example information into the model. We explore... | Akash Kumar Gautam, Lukas Lange, Jannik Strötgen |  |
| 907 |  |  [Contextualizing Argument Quality Assessment with Relevant Knowledge](https://doi.org/10.18653/v1/2024.naacl-short.28) |  | 0 | Automatic assessment of the quality of arguments has been recognized as a challenging task with significant implications for misinformation and targeted speech. While real-world arguments are tightly anchored in context, existing computational methods analyze their quality in isolation, which affects their accuracy and generalizability. We propose SPARK: a novel method for scoring argument quality based on contextualization via relevant knowledge. We devise... | Darshan Deshpande, Zhivar Sourati, Filip Ilievski, Fred Morstatter |  |
| 908 |  |  [Selective Perception: Learning Concise State Descriptions for Language Model Actors](https://doi.org/10.18653/v1/2024.naacl-short.29) |  | 0 | The latest large language models (LMs) support increasingly longer contexts. While this trend permits using substantial amounts of text with SOTA LMs, requiring these large LMs to process potentially redundant or irrelevant data needlessly increases inference time and cost. To remedy this problem, we propose BLINDER, a method that leverages a small finetuned LM to sample the minimal set of input features that maximizes the performance of a downstream LM.... | Kolby Nottingham, Yasaman Razeghi, Kyungmin Kim, JB Lanier, Pierre Baldi, Roy Fox, Sameer Singh |  |
| 909 |  |  [ALOHa: A New Measure for Hallucination in Captioning Models](https://doi.org/10.18653/v1/2024.naacl-short.30) |  | 0 | Despite recent advances in multimodal pre-training for visual description, state-of-the-art models still produce captions containing errors, such as hallucinating objects not present in a scene. The existing prominent metric for object hallucination, CHAIR, is limited to a fixed set of MS COCO objects and synonyms. In this work, we propose a modernized open-vocabulary metric, ALOHa, which leverages large language models (LLMs) to measure object... | Suzanne Petryk, David M. Chan, Anish Kachinthaya, Haodi Zou, John F. Canny, Joseph Gonzalez, Trevor Darrell |  |
| 910 |  |  [Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels](https://doi.org/10.18653/v1/2024.naacl-short.31) |  | 0 | Zero-shot text rankers powered by recent LLMs achieve remarkable ranking performance by simply prompting. Existing prompts for pointwise LLM rankers mostly ask the model to choose from binary relevance labels like “Yes” and “No”. However, the lack of intermediate relevance label options may cause the LLM to provide noisy or biased answers for documents that are partially relevant to the query. We propose to incorporate fine-grained relevance labels into the... | Honglei Zhuang, Zhen Qin, Kai Hui, Junru Wu, Le Yan, Xuanhui Wang, Michael Bendersky |  |
| 911 |  |  [LLM-Driven Knowledge Injection Advances Zero-Shot and Cross-Target Stance Detection](https://doi.org/10.18653/v1/2024.naacl-short.32) |  | 0 | Stance detection aims at inferring an author’s attitude towards a specific target in a text. Prior methods mainly consider target-related background information for a better understanding of targets while neglecting the accompanying input texts. In this study, we propose to prompt Large Language Models (LLMs) to explicitly extract the relationship between paired text and target as contextual knowledge. We then inject such LLM-driven knowledge into a... | Zhao Zhang, Yiming Li, Jin Zhang, Hui Xu |  |
| 912 |  |  [Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information](https://doi.org/10.18653/v1/2024.naacl-short.33) |  | 0 | Mitigating social biases typically requires identifying the social groups associated with each data sample. In this paper, we present DAFair, a novel approach to address social bias in language models. Unlike traditional methods that rely on explicit demographic labels, our approach does not require any such information. Instead, we leverage predefined prototypical demographic texts and incorporate a regularization term during the fine-tuning process to... | Shadi Iskander, Kira Radinsky, Yonatan Belinkov |  |
| 913 |  |  [Direct Preference Optimization for Neural Machine Translation with Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.naacl-short.34) |  | 0 | Minimum Bayes Risk (MBR) decoding can significantly improve translation performance of Multilingual Large Language Models (MLLMs). However, MBR decoding is computationally expensive. We show how the recently developed Reinforcement Learning technique, Direct Preference Optimization (DPO), can fine-tune MLLMs to get the gains of MBR without any additional computation in inference. Our method uses only a small monolingual fine-tuning set and yields... | Guangyu Yang, Jinghong Chen, Weizhe Lin, Bill Byrne |  |
| 914 |  |  [EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning](https://doi.org/10.18653/v1/2024.naacl-short.35) |  | 0 | Language models are achieving impressive performance on various tasks by aggressively adopting inference-time prompting techniques,such as zero-shot and few-shot prompting. In this work, we introduce EchoPrompt, a simple yet effective approach that prompts the model to rephrase its queries before answering them. EchoPrompt is tailored for four scenarios, including standard and chain-of-thought prompting, in both zero-shot and few-shot settings. Experimental... | Raja Sekhar Reddy Mekala, Yasaman Razeghi, Sameer Singh |  |
| 915 |  |  [LEAF: Language Learners' English Essays and Feedback Corpus](https://doi.org/10.18653/v1/2024.naacl-short.36) |  | 0 | This paper addresses the issue of automated feedback generation for English language learners by presenting a corpus of English essays and their corresponding feedback, called LEAF, collected from the “essayforum” website. The corpus comprises approximately 6K essay-feedback pairs, offering a diverse and valuable resource for developing personalized feedback generation systems that address the critical deficiencies within essays, spanning from rectifying... | Shabnam Behzad, Omid Kashefi, Swapna Somasundaran |  |
| 916 |  |  [Zero-Shot vs. Translation-Based Cross-Lingual Transfer: The Case of Lexical Gaps](https://doi.org/10.18653/v1/2024.naacl-short.37) |  | 0 | Cross-lingual transfer can be achieved through two main approaches: zero-shot transfer or machine translation (MT). While the former has been the dominant approach, both have been shown to be competitive. In this work, we compare the current performance and long-term viability of these methods. We leverage lexical gaps to create a multilingual question answering dataset, which provides a difficult domain for evaluation. Both approaches struggle in this... | Abteen Ebrahimi, Katharina von der Wense |  |
| 917 |  |  [On the True Distribution Approximation of Minimum Bayes-Risk Decoding](https://doi.org/10.18653/v1/2024.naacl-short.38) |  | 0 | Minimum Bayes-risk (MBR) decoding has recently gained renewed attention in text generation.MBR decoding considers texts sampled from a model as pseudo-references and selects the text with the highest similarity to the others.Therefore, sampling is one of the key elements of MBR decoding, and previous studies reported that the performance varies by sampling methods.From a theoretical standpoint, this performance variation is likely tied to how closely the... | Atsumoto Ohashi, Ukyo Honda, Tetsuro Morimura, Yuu Jinnai |  |
| 918 |  |  [Rehearsal-Free Modular and Compositional Continual Learning for Language Models](https://doi.org/10.18653/v1/2024.naacl-short.39) |  | 0 | Continual learning aims at incrementally acquiring new knowledge while not forgetting existing knowledge. To overcome catastrophic forgetting, methods are either rehearsal-based, i.e., store data examples from previous tasks for data replay, or isolate parameters dedicated to each task. However, rehearsal-based methods raise privacy and memory issues, and parameter-isolation continual learning does not consider interaction between tasks, thus hindering... | Mingyang Wang, Heike Adel, Lukas Lange, Jannik Strötgen, Hinrich Schütze |  |
| 919 |  |  [Llama meets EU: Investigating the European political spectrum through the lens of LLMs](https://doi.org/10.18653/v1/2024.naacl-short.40) |  | 0 | Instruction-finetuned Large Language Models inherit clear political leanings that have been shown to influence downstream task performance. We expand this line of research beyond the two-party system in the US and audit Llama Chat in the context of EU politics in various settings to analyze the model’s political knowledge and its ability to reason in context. We adapt, i.e., further fine-tune, Llama Chat on speeches of individual euro-parties from debates in... | Ilias Chalkidis, Stephanie Brandl |  |
| 920 |  |  [M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation](https://doi.org/10.18653/v1/2024.naacl-short.41) |  | 0 | Document translation poses a challenge for Neural Machine Translation (NMT) systems. Most document-level NMT systems rely on meticulously curated sentence-level parallel data, assuming flawless extraction of text from documents along with their precise reading order. These systems also tend to disregard additional visual cues such as the document layout, deeming it irrelevant. However, real-world documents often possess intricate text layouts that defy these... | Benjamin Hsu, Xiaoyu Liu, Huayang Li, Yoshinari Fujinuma, Maria Nadejde, Xing Niu, Ron Litman, Yair Kittenplon, Raghavendra Reddy Pappagari |  |
| 921 |  |  [Control-DAG: Constrained Decoding for Non-Autoregressive Directed Acyclic T5 using Weighted Finite State Automata](https://doi.org/10.18653/v1/2024.naacl-short.42) |  | 0 | The Directed Acyclic Transformer is a fast non-autoregressive (NAR) model that performs well in Neural Machine Translation. Two issues prevent its application to general Natural Language Generation (NLG) tasks: frequent Out-Of-Vocabulary (OOV) errors and the inability to faithfully generate entity names. We introduce Control-DAG, a constrained decoding algorithm for our Directed Acyclic T5 (DA-T5) model which offers lexical, vocabulary and length control. We... | Jinghong Chen, Weizhe Lin, Jingbiao Mei, Bill Byrne |  |
| 922 |  |  [Do Vision-Language Models Understand Compound Nouns?](https://doi.org/10.18653/v1/2024.naacl-short.43) |  | 0 | Open-vocabulary vision-language models (VLMs) like CLIP, trained using contrastive loss, have emerged as a promising new paradigm for text-to-image retrieval. However, do VLMs understand compound nouns (CNs) (e.g., \*lab coat\*) as well as they understand nouns (e.g., \*lab\*)? We curate Compun, a novel benchmark with 400 unique and commonly used CNs, to evaluate the effectiveness of VLMs in interpreting CNs. The Compun benchmark challenges a VLM for... | Sonal Kumar, Sreyan Ghosh, S. Sakshi, Utkarsh Tyagi, Dinesh Manocha |  |
| 923 |  |  [Is Prompt Transfer Always Effective? An Empirical Study of Prompt Transfer for Question Answering](https://doi.org/10.18653/v1/2024.naacl-short.44) |  | 0 | Prompt tuning, which freezes all parameters of a pre-trained model and only trains a soft prompt, has emerged as a parameter-efficient approach. For the reason that the prompt initialization becomes sensitive when the model size is small, the prompt transfer that uses the trained prompt as an initialization for the target task has recently been introduced. Since previous works have compared tasks in large categories (e.g., summarization, sentiment analysis),... | Minji Jung, Soyeon Park, Jeewoo Sul, Yong Suk Choi |  |
| 924 |  |  [Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers](https://doi.org/10.18653/v1/2024.naacl-short.45) |  | 0 | An effective method for combining frozen large language models (LLM) and visual encoders involves a resampler module that creates a ‘visual prompt’ which is provided to the LLM, along with the textual prompt. While this approach has enabled impressive performance across many coarse-grained tasks like image captioning and visual question answering, more fine-grained tasks that require spatial understanding have not been thoroughly examined. In this paper, we... | Georgios Pantazopoulos, Alessandro Suglia, Oliver Lemon, Arash Eshghi |  |
| 925 |  |  [Do Multilingual Language Models Think Better in English?](https://doi.org/10.18653/v1/2024.naacl-short.46) |  | 0 | Translate-test is a popular technique to improve the performance of multilingual language models. This approach works by translating the input into English using an external machine translation system before running inference. However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model. In this work, we introduce a new approach called... | Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, Mikel Artetxe |  |
| 926 |  |  [A Continued Pretrained LLM Approach for Automatic Medical Note Generation](https://doi.org/10.18653/v1/2024.naacl-short.47) |  | 0 | LLMs are revolutionizing NLP tasks. However, the use of the most advanced LLMs, such as GPT-4, is often prohibitively expensive for most specialized fields. We introduce HEAL, the first continuously trained 13B LLaMA2-based LLM that is purpose-built for medical conversations and measured on automated scribing. Our results demonstrate that HEAL outperforms GPT-4 and PMC-LLaMA in PubMedQA, with an accuracy of 78.4%. It also achieves parity with GPT-4 in... | Dong Yuan, Eti Rastogi, Gautam Naik, Sree Prasanna Rajagopal, Sagar Goyal, Fen Zhao, Bharath Chintagunta, Jeff Ward |  |
| 927 |  |  [Lost in Translation? Translation Errors and Challenges for Fair Assessment of Text-to-Image Models on Multilingual Concepts](https://doi.org/10.18653/v1/2024.naacl-short.48) |  | 0 | Benchmarks of the multilingual capabilities of text-to-image (T2I) models compare generated images prompted in a test language to an expected image distribution over a concept set. One such benchmark, “Conceptual Coverage Across Languages” (CoCo-CroLa), assesses the tangible noun inventory of T2I models by prompting them to generate pictures from a concept list translated to seven languages and comparing the output image populations. Unfortunately, we find... | Michael Saxon, Yiran Luo, Sharon Levy, Chitta Baral, Yezhou Yang, William Yang Wang |  |
| 928 |  |  [Self-Improving for Zero-Shot Named Entity Recognition with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-short.49) |  | 0 | Exploring the application of powerful large language models (LLMs) on the named entity recognition (NER) task has drawn much attention recently. This work pushes the performance boundary of zero-shot NER with LLMs by proposing a training-free self-improving framework, which utilizes an unlabeled corpus to stimulate the self-learning ability of LLMs. First, we use the LLM to make predictions on the unlabeled corpus using self-consistency and obtain a... | Tingyu Xie, Qi Li, Yan Zhang, Zuozhu Liu, Hongwei Wang |  |
| 929 |  |  [Lifelong Event Detection with Embedding Space Separation and Compaction](https://doi.org/10.18653/v1/2024.naacl-short.50) |  | 0 | To mitigate forgetting, existing lifelong event detection methods typically maintain a memory module and replay the stored memory data during the learning of a new task. However, the simple combination of memory data and new-task samples can still result in substantial forgetting of previously acquired knowledge, which may occur due to the potential overlap between the feature distribution of new data and the previously learned embedding space. Moreover, the... | Chengwei Qin, Ruirui Chen, Ruochen Zhao, Wenhan Xia, Shafiq Joty |  |
| 930 |  |  [Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion](https://doi.org/10.18653/v1/2024.naacl-short.51) |  | 0 | Situations and events evoke emotions in humans, but to what extent do they inform the prediction of emotion detection models? This work investigates how well human-annotated emotion triggers correlate with features that models deemed salient in their prediction of emotions. First, we introduce a novel dataset EmoTrigger, consisting of 900 social media posts sourced from three different datasets; these were annotated by experts for emotion triggers with high... | Smriti Singh, Cornelia Caragea, Junyi Jessy Li |  |
| 931 |  |  [CPopQA: Ranking Cultural Concept Popularity by LLMs](https://doi.org/10.18653/v1/2024.naacl-short.52) |  | 0 | Many recent studies examining the knowledge capacity of large language models (LLM) have focused on knowledge explicitly learned from the pretraining data or implicitly inferable from similar contexts. However, the extent to which an LLM effectively captures corpus-level statistical trends of concepts for reasoning, especially long-tail ones, is largely underexplored. In this study, we introduce a novel few-shot question-answering task (CPopQA) that examines... | Ming Jiang, Mansi Joshi |  |
| 932 |  |  [The Impact of Language on Arithmetic Proficiency: A Multilingual Investigation with Cross-Agent Checking Computation](https://doi.org/10.18653/v1/2024.naacl-short.53) |  | 0 | This paper critically examines the arithmetic capabilities of Large Language Models (LLMs), uncovering significant limitations in their performance. Our research reveals a notable decline in accuracy for complex calculations involving large numbers, with addition and subtraction tasks showing varying degrees of proficiency. Additionally, we challenge the notion that arithmetic is language-independent, finding up to a 10% difference in performance across... | ChungChi Chen, Hiroya Takamura, Ichiro Kobayashi, Yusuke Miyao |  |
| 933 |  |  [Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning](https://doi.org/10.18653/v1/2024.naacl-short.54) |  | 0 | Differentiating relationships between entity pairs with limited labeled instances poses a significant challenge in few-shot relation classification. Representations of textual data extract rich information spanning the domain, entities, and relations. In this paper, we introduce a novel approach to enhance information extraction combining multiple sentence representations and contrastive learning. While representations in relation classification are commonly... | Philipp Borchert, Jochen De Weerdt, MarieFrancine Moens |  |
| 934 |  |  [A diverse Multilingual News Headlines Dataset from around the World](https://doi.org/10.18653/v1/2024.naacl-short.55) |  | 0 | Babel Briefings is a novel dataset featuring 4.7 million news headlines from August 2020 to November 2021, across 30 languages and 54 locations worldwide with English translations of all articles included. Designed for natural language processing and media studies, it serves as a high-quality dataset for training or evaluating language models as well as offering a simple, accessible collection of articles, for example, to analyze global news coverage and... | Felix Leeb, Bernhard Schölkopf |  |
| 935 |  |  [The Unreasonable Effectiveness of Random Target Embeddings for Continuous-Output Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-short.56) |  | 0 | Continuous-output neural machine translation (CoNMT) replaces the discrete next-word prediction problem with an embedding prediction.The semantic structure of the target embedding space (\*i.e.\*, closeness of related words) is intuitively believed to be crucial. We challenge this assumption and show that completely random output embeddings can outperform laboriously pre-trained ones, especially on larger datasets. Further investigation shows this surprising... | Evgeniia Tokarchuk, Vlad Niculae |  |
| 936 |  |  [Efficient Sample-Specific Encoder Perturbations](https://doi.org/10.18653/v1/2024.naacl-short.57) |  | 0 | Encoder-decoder foundation models have displayed state-of-the-art performance on a range of autoregressive sequence tasks. This paper proposes a simple and lightweight modification to such systems to control the behaviour according to a specific attribute of interest. This paper proposes a novel inference-efficient approach to modifying the behaviour of an encoder-decoder system according to a specific attribute of interest. Specifically, we show that a small... | Yassir Fathullah, Mark J. F. Gales |  |
| 937 |  |  [Diverse Perspectives, Divergent Models: Cross-Cultural Evaluation of Depression Detection on Twitter](https://doi.org/10.18653/v1/2024.naacl-short.58) |  | 0 | Social media data has been used for detecting users with mental disorders, such as depression. Despite the global significance of cross-cultural representation and its potential impact on model performance, publicly available datasets often lack crucial metadata relatedto this aspect. In this work, we evaluate the generalization of benchmark datasets to build AI models on cross-cultural Twitter data. We gather a custom geo-located Twitter dataset of depressed... | Nuredin Ali Abdelkadir, Charles Zhang, Ned Mayo, Stevie Chancellor |  |
| 938 |  |  [Removing RLHF Protections in GPT-4 via Fine-Tuning](https://doi.org/10.18653/v1/2024.naacl-short.59) |  | 0 | As large language models (LLMs) have increased in their capabilities, so doestheir potential for dual use. To reduce harmful outputs, produces and vendors ofLLMs have used reinforcement learning with human feedback (RLHF). In tandem,LLM vendors have been increasingly enabling fine-tuning of their most powerfulmodels. However, concurrent work has shown that fine-tuning can remove RLHFprotections. We may expect that the most powerful models currently... | Qiusi Zhan, Richard Fang, Rohan Bindu, Akul Gupta, Tatsunori Hashimoto, Daniel Kang |  |
| 939 |  |  [LifeTox: Unveiling Implicit Toxicity in Life Advice](https://doi.org/10.18653/v1/2024.naacl-short.60) |  | 0 | As large language models become increasingly integrated into daily life, detecting implicit toxicity across diverse contexts is crucial. To this end, we introduce LifeTox, a dataset designed for identifying implicit toxicity within a broad range of advice-seeking scenarios. Unlike existing safety datasets, LifeTox comprises diverse contexts derived from personal experiences through open-ended questions. Our experiments demonstrate that RoBERTa fine-tuned on... | Minbeom Kim, Jahyun Koo, Hwanhee Lee, Joonsuk Park, Hwaran Lee, Kyomin Jung |  |
| 940 |  |  [Arithmetic Reasoning with LLM: Prolog Generation & Permutation](https://doi.org/10.18653/v1/2024.naacl-short.61) |  | 0 | Instructing large language models (LLMs) to solve elementary school math problems has shown great success using Chain of Thought (CoT). However, the CoT approach relies on an LLM to generate a sequence of arithmetic calculations which can be prone to cascaded calculation errors. We hypothesize that an LLM should focus on extracting predicates and generating symbolic formulas from the math problem description so that the underlying calculation can be done via... | Xiaocheng Yang, Bingsen Chen, YikCheung Tam |  |
| 941 |  |  [Verifying Claims About Metaphors with Large-Scale Automatic Metaphor Identification](https://doi.org/10.18653/v1/2024.naacl-short.62) |  | 0 | There are several linguistic claims about situations where words are more likely to be used as metaphors.However, few studies have sought to verify such claims with large corpora.This study entails a large-scale, corpus-based analysis of certain existing claims about verb metaphors, by applying metaphor detection to sentences extracted from Common Crawl and using the statistics obtained from the results.The verification results indicate that the direct... | Kotaro Aono, Ryohei Sasano, Koichi Takeda |  |
| 942 |  |  [InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis](https://doi.org/10.18653/v1/2024.naacl-short.63) |  | 0 | We introduce InstructABSA, an instruction learning paradigm for Aspect-Based Sentiment Analysis (ABSA) subtasks.Our method introduces positive, negative, and neutral examples to each training sample, and instruction tune the model (Tk-Instruct) for ABSA subtasks, yielding significant performance improvements. Experimental results on the Sem Eval 2014, 15, and 16 datasets demonstrate that InstructABSA outperforms the previous state-of-the-art (SOTA) approaches... | Kevin Scaria, Himanshu Gupta, Siddharth Goyal, Saurabh Arjun Sawant, Swaroop Mishra, Chitta Baral |  |
| 943 |  |  [MEMORY-VQ: Compression for Tractable Internet-Scale Memory](https://doi.org/10.18653/v1/2024.naacl-short.64) |  | 0 | Retrieval augmentation is a powerful but expensive method to make language models more knowledgeable about the world. Memory-based methods like LUMEN (de Jong et al., 2023a) pre-compute token representations for retrieved passages to drastically speed up inference. However, memory also leads to much greater storage requirements from storing pre-computed representations. We propose MEMORY-VQ, a new method to reduce storage requirements of memory-augmented... | Yury Zemlyanskiy, Michiel de Jong, Luke Vilnis, Santiago Ontañón, William W. Cohen, Sumit Sanghai, Joshua Ainslie |  |
| 944 |  |  [Unveiling the Magic: Investigating Attention Distillation in Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.naacl-short.65) |  | 0 | Retrieval-augmented generation framework addresses the limitations of large language models by enabling real-time knowledge updates for more accurate answers. An efficient way in the training phase of retrieval-augmented models is attention distillation, which uses attention scores as supervision signals instead of manually annotated query-document pairs. Despite its growing popularity, the detailed mechanisms behind the success of attention distillation... | Zizhong Li, Haopeng Zhang, Jiawei Zhang |  |
| 945 |  |  [Improving Factuality in Clinical Abstractive Multi-Document Summarization by Guided Continued Pre-training](https://doi.org/10.18653/v1/2024.naacl-short.66) |  | 0 | Factual accuracy is an important property of neural abstractive summarization models, especially in fact-critical domains such as the clinical literature. In this work, we introduce a guided continued pre-training stage for encoder-decoder models that improves their understanding of the factual attributes of documents, which is followed by supervised fine-tuning on summarization. Our approach extends the pre-training recipe of BART to incorporate 3 additional... | Ahmed Elhady, Khaled Mostafa Elsayed, Eneko Agirre, Mikel Artetxe |  |
| 946 |  |  [MuLan: A Study of Fact Mutability in Language Models](https://doi.org/10.18653/v1/2024.naacl-short.67) |  | 0 | Facts are subject to contingencies and can be true or false in different circumstances. One such contingency is time, wherein some facts mutate over a given period, e.g., the president of a country or the winner of a championship. Trustworthy language models ideally identify mutable facts as such and process them accordingly. We create MuLan, a benchmark for evaluating the ability of English language models to anticipate time-contingency, covering both 1:1... | Constanza Fierro, Nicolas Garneau, Emanuele Bugliarello, Yova Kementchedjhieva, Anders Søgaard |  |
| 947 |  |  [Language-Independent Representations Improve Zero-Shot Summarization](https://doi.org/10.18653/v1/2024.naacl-short.68) |  | 0 | Finetuning pretrained models on downstream generation tasks often leads to catastrophic forgetting in zero-shot conditions. In this work, we focus on summarization and tackle the problem through the lens of language-independent representations. After training on monolingual summarization, we perform zero-shot transfer to new languages or language pairs. We first show naively finetuned models are highly language-specific in both output behavior and internal... | Vladimir Solovyev, Danni Liu, Jan Niehues |  |
| 948 |  |  [Trusting Your Evidence: Hallucinate Less with Context-aware Decoding](https://doi.org/10.18653/v1/2024.naacl-short.69) |  | 0 | Language models (LMs) often struggle to pay enough attention to the input context, and generate texts that are unfaithful or contain hallucinations. To mitigate this issue, we present context-aware decoding (CAD), which follows a contrastive output distribution that amplifies the difference between the output probabilities when a model is used with and without context. Our experiments show that CAD, without additional training, significantly improves the... | Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, Wentau Yih |  |
| 949 |  |  [GuyLingo: The Republic of Guyana Creole Corpora](https://doi.org/10.18653/v1/2024.naacl-short.70) |  | 0 | While major languages often enjoy substantial attention and resources, the linguistic diversity across the globe encompasses a multitude of smaller, indigenous, and regional languages that lack the same level of computational support. One such region is the Caribbean. While commonly labeled as “English speaking”, the ex-British Caribbean region consists of a myriad of Creole languages thriving alongside English. In this paper, we present Guylingo: a... | Christopher Clarke, Roland Daynauth, Jason Mars, Charlene Wilkinson, Hubert Devonish |  |
| 950 |  |  [DoubleLingo: Causal Estimation with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-short.71) |  | 0 | Estimating causal effects from non-randomized data requires assumptions about the underlying data-generating process. To achieve unbiased estimates of the causal effect of a treatment on an outcome, we typically adjust for any confounding variables that influence both treatment and outcome. When such confounders include text data, existing causal inference methods struggle due to the high dimensionality of the text. The simple statistical models which have... | Marko Veljanovski, Zach WoodDoughty |  |
| 951 |  |  [Improved Text Emotion Prediction Using Combined Valence and Arousal Ordinal Classification](https://doi.org/10.18653/v1/2024.naacl-short.72) |  | 0 | Emotion detection in textual data has received growing interest in recent years, as it is pivotal for developing empathetic human-computer interaction systems.This paper introduces a method for categorizing emotions from text, which acknowledges and differentiates between the diversified similarities and distinctions of various emotions.Initially, we establish a baseline by training a transformer-based model for standard emotion classification, achieving... | Michail Mitsios, Georgios Vamvoukakis, Georgia Maniati, Nikolaos Ellinas, Georgios Dimitriou, Konstantinos Markopoulos, Panos Kakoulidis, Alexandra Vioni, Myrsini Christidou, Junkwang Oh, Gunu Jho, Inchul Hwang, Georgios Vardaxoglou, Aimilios Chalamandaris, Pirros Tsiakoulis, Spyros Raptis |  |
| 952 |  |  [On Narrative Question Answering Skills](https://doi.org/10.18653/v1/2024.naacl-short.73) |  | 0 | Narrative Question Answering is an important task for evaluating and improving reading comprehension abilities in both humans and machines. However, there is a lack of consensus on the skill taxonomy that would enable systematic and comprehensive assessment and learning of the various aspects of Narrative Question Answering. Existing task-level skill views oversimplify the multidimensional nature of tasks, while question-level taxonomies face issues in... | Emil Kalbaliyev, Kairit Sirts |  |
| 953 |  |  [Order-Based Pre-training Strategies for Procedural Text Understanding](https://doi.org/10.18653/v1/2024.naacl-short.74) |  | 0 | In this paper, we propose sequence-based pre-training methods to enhance procedural understanding in natural language processing. Procedural text, containing sequential instructions to accomplish a task, is difficult to understand due to the changing attributes of entities in the context. We focus on recipes as they are commonly represented as ordered instructions, and use this order as a supervision signal. Our work is one of the first to compare several... | Abhilash Nandy, Yash Kulkarni, Pawan Goyal, Niloy Ganguly |  |
| 954 |  |  [Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?](https://doi.org/10.18653/v1/2024.naacl-short.75) |  | 0 | Large language models hold significant promise in multilingual applications. However, inherent biases stemming from predominantly English-centric pre-training have led to the widespread practice of pre-translation, i.e., translating non-English inputs to English before inference, leading to complexity and information loss. This study re-evaluates the need for pre-translation in the context of PaLM2 models, which have been established as highly performant in... | Yotam Intrator, Matan Halfon, Roman Goldenberg, Reut Tsarfaty, Matan Eyal, Ehud Rivlin, Yossi Matias, Natalia Aizenberg |  |

# NAACL2024

## 会议论文列表

本会议共有 954 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [Systematic Analysis for Pretrained Language Model Priming for Parameter-Efficient Fine-tuning](https://doi.org/10.18653/v1/2024.naacl-srw.1) |  | 0 |  | ShihCheng Huang, ShihHeng Wang, MinHan Shih, Saurav Sahay, Hungyi Lee |  |
| 2 |  |  [Rephrasing Invokes Better Generations for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.2) |  | 0 | In the realm of emerging multitasking abilities of Large language models (LLMs), methodologies like prompt tuning enable low-cost adaptation to downstream tasks without retraining the model. However, automatic input pre-processing when LLMs are unavailable is currently under-studied. This paper proposes ReLLM (Rephrasing for LLMs), a method that automatically paraphrases input content for better output generations. ReLLM replaces low-frequency lexical items with their high-frequency counterparts. This substitution is particularly beneficial for low-resource language tasks that lack sufficient training data and resources. ReLLM is user-friendly and requires no additional LLM training. Experimental results in cross-lingual summarization, and natural language inference demonstrate the effectiveness of ReLLM. | Haoran Yang, Hongyuan Lu, Wai Lam |  |
| 3 |  |  [Exploring Compositional Generalization of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.3) |  | 0 | In this paper, we study the generalization ability of large language models (LLMs) with respect to compositional instructions, which are instructions that can be decomposed into several sub-instructions. We argue that the ability to generalize from simple instructions to more intricate compositional instructions represents a key aspect of the out-of-distribution generalization for LLMs. Since there are no specialized datasets for studying this phenomenon, we first construct a dataset with the help of ChatGPT, guided by the self-instruct technique. Then, we fine-tune and evaluate LLMs on these datasets. Interestingly, our experimental results indicate that training LLMs on higher-order compositional instructions enhances their performance on lower-order ones, but the reverse does not hold true. | Haoran Yang, Hongyuan Lu, Wai Lam, Deng Cai |  |
| 4 |  |  [Explainable CED: A Dataset for Explainable Critical Error Detection in Machine Translation](https://doi.org/10.18653/v1/2024.naacl-srw.4) |  | 0 |  | Dahyun Jung, Sugyeong Eo, Chanjun Park, Heuiseok Lim |  |
| 5 |  |  [SMARTR: A Framework for Early Detection using Survival Analysis of Longitudinal Texts](https://doi.org/10.18653/v1/2024.naacl-srw.5) |  | 0 |  | JeanThomas Baillargeon, Luc Lamontagne |  |
| 6 |  |  [Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)](https://doi.org/10.18653/v1/2024.naacl-srw.6) |  | 0 | Exact nearest neighbor search is a computationally intensive process, and even its simpler sibling — vector retrieval — can be computationally complex. This is exacerbated when retrieving vectors which have high-dimension d relative to the number of vectors, N, in the database. Exact nearest neighbor retrieval has been generally acknowledged to be a O(Nd) problem with no sub-linear solutions. Attention has instead shifted towards Approximate Nearest-Neighbor (ANN) retrieval techniques, many of which have sub-linear or even logarithmic time complexities. However, if our intuition from binary search problems (e.g. d=1 vector retrieval) carries, there ought to be a way to retrieve an organized representation of vectors without brute-forcing our way to a solution. For low dimension (e.g. d=2 or d=3 cases), kd-trees provide a O(dlog N) algorithm for retrieval. Unfortunately the algorithm deteriorates rapidly to a O(dN) solution at high dimensions (e.g. k=128), in practice. We propose a novel algorithm for logarithmic Fast Exact Retrieval for Nearest-neighbor lookup (FERN), inspired by kd-trees. The algorithm achieves O(dlog N) look-up with 100% recall on 10 million d=128 uniformly randomly generated vectors. | Richard Zhu |  |
| 7 |  |  [Start Simple: Progressive Difficulty Multitask Learning](https://doi.org/10.18653/v1/2024.naacl-srw.7) |  | 0 | The opaque nature of neural networks, often described as black boxes, poses significant challenges in understanding their learning mechanisms, which limit our ability to fully optimize and trust these models.Inspired by how humans learn, this paper proposes a novel neural network training strategy that employs multitask learning with progressive difficulty subtasks, which we believe can potentially shed light on the internal learning mechanisms of neural networks.We implemented this strategy across a range of NLP tasks, data sets, and neural network architectures and observed notable improvements in model performance.This suggests that neural networks may be able to extract common features and internalize shared representations across similar subtasks that differ in their difficulty.Analyzing this strategy could lead us to more interpretable and robust neural networks, enhancing both their performance and our understanding of their nature. | Yunfei Luo, Yuyang Liu, Rukai Cai, Tauhidur Rahman |  |
| 8 |  |  [LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues](https://doi.org/10.18653/v1/2024.naacl-srw.8) |  | 0 |  | Joe Stacey, Jianpeng Cheng, John Torr, Tristan Guigue, Joris Driesen, Alexandru Coca, Mark Gaynor, Anders Johannsen |  |
| 9 |  |  [Fine-tuning Pre-trained Named Entity Recognition Models For Indian Languages](https://doi.org/10.18653/v1/2024.naacl-srw.9) |  | 0 | Named Entity Recognition (NER) is a use-ful component in Natural Language Process-ing (NLP) applications. It is used in varioustasks such as Machine Translation, Summa-rization, Information Retrieval, and Question-Answering systems. The research on NER iscentered around English and some other ma-jor languages, whereas limited attention hasbeen given to Indian languages. We analyze thechallenges and propose techniques that can betailored for Multilingual Named Entity Recog-nition for Indian Languages. We present a hu-man annotated named entity corpora of ∼40Ksentences for 4 Indian languages from two ofthe major Indian language families. Addition-ally, we show the transfer learning capabilitiesof pre-trained transformer models from a highresource language to multiple low resource lan-guages through a series of experiments. Wealso present a multilingual model fine-tunedon our dataset, which achieves an F1 score of∼0.80 on our dataset on average. We achievecomparable performance on completely unseenbenchmark datasets for Indian languages whichaffirms the usability of our model. | Sankalp Bahad, Pruthwik Mishra, Parameswari Krishnamurthy, Dipti Misra Sharma |  |
| 10 |  |  [Knowledge-centered conversational agents with a drive to learn](https://doi.org/10.18653/v1/2024.naacl-srw.10) |  | 0 | We create an adaptive conversational agent that assesses the quality of its knowledge and is driven to become more knowledgeable. Unlike agents with predefined tasks, ours can leverage people as diverse sources to meet its knowledge needs. We test the agent in social contexts, where personal and subjective information can be obtained through dialogue. We provide the agent both with generic methods for assessing its knowledge quality (e.g. correctness, completeness, redundancy, interconnectedness, and diversity), as well as with generic capabilities to improve its knowledge by leveraging external sources. We demonstrate that the agent can learn effective policies to acquire the knowledge needed by assessing the efficiency of these capabilities during interaction. Our framework enables on-the-fly learning, offering a dynamic and adaptive approach to shaping conversational interactions. | Selene Baez Santamaría |  |
| 11 |  |  [Exploring Inherent Biases in LLMs within Korean Social Context: A Comparative Analysis of ChatGPT and GPT-4](https://doi.org/10.18653/v1/2024.naacl-srw.11) |  | 0 |  | Seungyoon Lee, Dong Kim, Dahyun Jung, Chanjun Park, Heuiseok Lim |  |
| 12 |  |  [To Clarify or not to Clarify: A Comparative Analysis of Clarification Classification with Fine-Tuning, Prompt Tuning, and Prompt Engineering](https://doi.org/10.18653/v1/2024.naacl-srw.12) |  | 0 | Misunderstandings occur all the time in human conversation but deciding on when to ask for clarification is a challenging task for conversational systems that requires a balance between asking too many unnecessary questions and running the risk of providing incorrect information. This work investigates clarification identification based on the task and data from (Xu et al., 2019), reproducing their Transformer baseline and extending it by comparing pre-trained language model fine-tuning, prompt tuning and manual prompt engineering on the task of clarification identification. Our experiments show strong performance with LM and a prompt tuning approach with BERT and RoBERTa, outperforming standard LM fine-tuning, while manual prompt engineering with GPT-3.5 proved to be less effective, although informative prompt instructions have the potential of steering the model towards generating more accurate explanations for why clarification is needed. | Alina Leippert, Tatiana Anikina, Bernd Kiefer, Josef van Genabith |  |
| 13 |  |  [Detecting Response Generation Not Requiring Factual Judgment](https://doi.org/10.18653/v1/2024.naacl-srw.13) |  | 0 | With the remarkable development of large language models (LLMs), ensuring the factuality of output has become a challenge.However, having all the contents of the response with given knowledge or facts is not necessarily a good thing in dialogues.This study aimed to achieve both attractiveness and factuality in a dialogue response for which a task was set to predict sentences that do not require factual correctness judgment such as agreeing, or personal opinions/feelings.We created a dataset, dialogue dataset annotated with fact-check-needed label (DDFC), for this task via crowdsourcing, and classification tasks were performed on several models using this dataset.The model with the highest classification accuracy could yield about 88% accurate classification results. | Ryohei Kamei, Daiki Shiono, Reina Akama, Jun Suzuki |  |
| 14 |  |  [Unknown Script: Impact of Script on Cross-Lingual Transfer](https://doi.org/10.18653/v1/2024.naacl-srw.14) |  | 0 | Cross-lingual transfer has become an effective way of transferring knowledge between languages. In this paper, we explore an often overlooked aspect in this domain: the influence of the source language of a language model on language transfer performance. We consider a case where the target language and its script are not part of the pre-trained model. We conduct a series of experiments on monolingual and multilingual models that are pre-trained on different tokenization methods to determine factors that affect cross-lingual transfer to a new language with a unique script. Our findings reveal the importance of the tokenizer as a stronger factor than the shared script, language similarity, and model size. | Wondimagegnhue Tufa, Ilia Markov, Piek Vossen |  |
| 15 |  |  [Improving Repository-level Code Search with Text Conversion](https://doi.org/10.18653/v1/2024.naacl-srw.15) |  | 0 |  | Mizuki Kondo, Daisuke Kawahara, Toshiyuki Kurabayashi |  |
| 16 |  |  [Improving Multi-lingual Alignment Through Soft Contrastive Learning](https://doi.org/10.18653/v1/2024.naacl-srw.16) |  | 0 | Making decent multi-lingual sentence representations is critical to achieve high performances in cross-lingual downstream tasks. In this work, we propose a novel method to align multi-lingual embeddings based on the similarity of sentences measured by a pre-trained mono-lingual embedding model. Given translation sentence pairs, we train a multi-lingual model in a way that the similarity between cross-lingual embeddings follows the similarity of sentences measured at the mono-lingual teacher model. Our method can be considered as contrastive learning with soft labels defined as the similarity between sentences. Our experimental results on five languages show that our contrastive loss with soft labels far outperforms conventional constrastive loss with hard labels in various benchmarks for bitext mining tasks and STS tasks. In addition, our method outperforms existing multi-lingual embeddings including LaBSE, for Tatoeba dataset. | Minsu Park, Seyeon Choi, Chanyeol Choi, JunSeong Kim, Jyyong Sohn |  |
| 17 |  |  [Few-Shot Event Argument Extraction Based on a Meta-Learning Approach](https://doi.org/10.18653/v1/2024.naacl-srw.17) |  | 0 |  | Aboubacar Tuo, Romaric Besançon, Olivier Ferret, Julien Tourille |  |
| 18 |  |  [Investigating Web Corpus Filtering Methods for Language Model Development in Japanese](https://doi.org/10.18653/v1/2024.naacl-srw.18) |  | 0 |  | Rintaro Enomoto, Arseny Tolmachev, Takuro Niitsuma, Shuhei Kurita, Daisuke Kawahara |  |
| 19 |  |  [Referring Expressions in Human-Robot Common Ground: A Thesis Proposal](https://doi.org/10.18653/v1/2024.naacl-srw.19) |  | 0 |  | Jaap Kruijt |  |
| 20 |  |  [Source Code is a Graph, Not a Sequence: A Cross-Lingual Perspective on Code Clone Detection](https://doi.org/10.18653/v1/2024.naacl-srw.20) |  | 0 | Code clone detection is challenging, as sourcecode can be written in different languages, do-mains, and styles. In this paper, we arguethat source code is inherently a graph, not asequence, and that graph-based methods aremore suitable for code clone detection thansequence-based methods. We compare the per-formance of two state-of-the-art models: Code-BERT (Feng et al., 2020), a sequence-basedmodel, and CodeGraph (Yu et al., 2023), agraph-based model, on two benchmark data-sets: BCB (Svajlenko et al., 2014) and PoolC(PoolC, no date). We show that CodeGraphoutperforms CodeBERT on both data-sets, es-pecially on cross-lingual code clones. To thebest of our knowledge, this is the first work todemonstrate the cross-lingual code clone detec-tion showing superiority on graph-based meth-ods over sequence-based methods | Mohammed Ataaur Rahaman, Julia Ive |  |
| 21 |  |  [Distilling Text Style Transfer With Self-Explanation From LLMs](https://doi.org/10.18653/v1/2024.naacl-srw.21) |  | 0 | Text Style Transfer (TST) seeks to alter the style of text while retaining its core content. Given the constraints of limited parallel datasets for TST, we propose CoTeX, a framework that leverages large language models (LLMs) alongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills the complex rewriting and reasoning capabilities of LLMs into more streamlined models capable of working with both non-parallel and parallel data. Through experimentation across four TST datasets, CoTeX is shown to surpass traditional supervised fine-tuning and knowledge distillation methods, particularly in low-resource settings. We conduct a comprehensive evaluation, comparing CoTeX against current unsupervised, supervised, in-context learning (ICL) techniques, and instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering transparent explanations for its style transfer process. | Chiyu Zhang, Honglong Cai, Yuezhang Li, Yuexin Wu, Le Hou, Muhammad AbdulMageed |  |
| 22 |  |  [Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-srw.22) |  | 0 |  | Hao Wang, Tetsuro Morimura, Ukyo Honda, Daisuke Kawahara |  |
| 23 |  |  [Evaluation Dataset for Japanese Medical Text Simplification](https://doi.org/10.18653/v1/2024.naacl-srw.23) |  | 0 | We create a parallel corpus for medical text simplification in Japanese, which simplifies medical terms into expressions that patients can understand without effort.While text simplification in the medial domain is strongly desired by society, it is less explored in Japanese because of the lack of language resources.In this study, we build a parallel corpus for Japanese text simplification evaluation in the medical domain using patients’ weblogs.This corpus consists of 1,425 pairs of complex and simple sentences with or without medical terms.To tackle medical text simplification without a training corpus of the corresponding domain, we repurpose a Japanese text simplification model of other domains.Furthermore, we propose a lexically constrained reranking method that allows to avoid technical terms to be output.Experimental results show that our method contributes to achieving higher simplification performance in the medical domain. | Koki Horiguchi, Tomoyuki Kajiwara, Yuki Arase, Takashi Ninomiya |  |
| 24 |  |  [Multi-Source Text Classification for Multilingual Sentence Encoder with Machine Translation](https://doi.org/10.18653/v1/2024.naacl-srw.24) |  | 0 | To reduce the cost of training models for each language for developers of natural language processing applications, pre-trained multilingual sentence encoders are promising.However, since training corpora for such multilingual sentence encoders contain only a small amount of text in languages other than English, they suffer from performance degradation for non-English languages.To improve the performance of pre-trained multilingual sentence encoders for non-English languages, we propose a method of machine translating a source sentence into English and then inputting it together with the source sentence in a multi-source manner.Experimental results on sentiment analysis and topic classification tasks in Japanese revealed the effectiveness of the proposed method. | Reon Kajikawa, Keiichiro Yamada, Tomoyuki Kajiwara, Takashi Ninomiya |  |
| 25 |  |  [A Reproducibility Study on Quantifying Language Similarity: The Impact of Missing Values in the URIEL Knowledge Base](https://doi.org/10.18653/v1/2024.naacl-srw.25) |  | 0 |  | Hasti Toossi, Guo Qing Huai, Jinyu Liu, Eric Khiu, A. Seza Dogruöz, Enshiun Lee |  |
| 26 |  |  [Coding Open-Ended Responses using Pseudo Response Generation by Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.26) |  | 0 |  | Yuki Zenimoto, Ryo Hasegawa, Takehito Utsuro, Masaharu Yoshioka, Noriko Kando |  |
| 27 |  |  [Cross-Task Generalization Abilities of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-srw.27) |  | 0 |  | Qinyuan Ye |  |
| 28 |  |  [Commentary Generation from Data Records of Multiplayer Strategy Esports Game](https://doi.org/10.18653/v1/2024.naacl-srw.28) |  | 0 | Esports, a sports competition on video games, has become one of the most important sporting events. Although esports play logs have been accumulated, only a small portion of them accompany text commentaries for the audience to retrieve and understand the plays. In this study, we therefore introduce the task of generating game commentaries from esports’ data records. We first build large-scale esports data-to-text datasets that pair structured data and commentaries from a popular esports game, League of Legends. We then evaluate Transformer-based models to generate game commentaries from structured data records, while examining the impact of the pre-trained language models. Evaluation results on our dataset revealed the challenges of this novel task. We will release our dataset to boost potential research in the data-to-text generation community. | Zihan Wang, Naoki Yoshinaga |  |
| 29 |  |  [Facilitating Opinion Diversity through Hybrid NLP Approaches](https://doi.org/10.18653/v1/2024.naacl-srw.29) |  | 0 | Modern democracies face a critical issue of declining citizen participation in decision-making. Online discussion forums are an important avenue for enhancing citizen participation. This thesis proposal 1) identifies the challenges involved in facilitating large-scale online discussions with Natural Language Processing (NLP), 2) suggests solutions to these challenges by incorporating hybrid human-AI technologies, and 3) investigates what these technologies can reveal about individual perspectives in online discussions. We propose a three-layered hierarchy for representing perspectives that can be obtained by a mixture of human intelligence and large language models. We illustrate how these representations can draw insights into the diversity of perspectives and allow us to investigate interactions in online discussions. | Michiel van der Meer |  |
| 30 |  |  [HybridBERT - Making BERT Pretraining More Efficient Through Hybrid Mixture of Attention Mechanisms](https://doi.org/10.18653/v1/2024.naacl-srw.30) |  | 0 | Pretrained transformer-based language models have produced state-of-the-art performance in most natural language understanding tasks. These models undergo two stages of training: pretraining on a huge corpus of data and fine-tuning on a specific downstream task. The pretraining phase is extremely compute-intensive and requires several high-performance computing devices like GPUs and several days or even months of training, but it is crucial for the model to capture global knowledge and also has a significant impact on the fine-tuning task. This is a major roadblock for researchers without access to sophisticated computing resources. To overcome this challenge, we propose two novel hybrid architectures called HybridBERT (HBERT), which combine self-attention and additive attention mechanisms together with sub-layer normalization. We introduce a computing budget to the pretraining phase, limiting the training time and usage to a single GPU. We show that HBERT attains twice the pretraining accuracy of a vanilla-BERT baseline. We also evaluate our proposed models on two downstream tasks, where we outperform BERT-base while accelerating inference. Moreover, we study the effect of weight initialization with a limited pretraining budget. The code and models are publicly available at: www.github.com/gokulsg/HBERT/. | Gokul Srinivasagan, Simon Ostermann |  |
| 31 |  |  [TOPICAL: TOPIC Pages AutomagicaLly](https://doi.org/10.18653/v1/2024.naacl-demo.1) |  | 0 | Topic pages aggregate useful information about an entity or concept into a single succinct and accessible article. Automated creation of topic pages would enable their rapid curation as information resources, providing an alternative to traditional web search. While most prior work has focused on generating topic pages about biographical entities, in this work, we develop a completely automated process to generate high-quality topic pages for scientific entities, with a focus on biomedical concepts. We release TOPICAL, a web app and associated open-source code, comprising a model pipeline combining retrieval, clustering, and prompting, that makes it easy for anyone to generate topic pages for a wide variety of biomedical entities on demand. In a human evaluation of 150 diverse topic pages generated using TOPICAL, we find that the vast majority were considered relevant, accurate, and coherent, with correct supporting citations. We make all code publicly available and host a free-to-use web app at: https://s2-topical.apps.allenai.org. | John M. Giorgi, Amanpreet Singh, Doug Downey, Sergey Feldman, Lucy Lu Wang |  |
| 32 |  |  [Low-code LLM: Graphical User Interface over Large Language Models](https://doi.org/10.18653/v1/2024.naacl-demo.2) |  | 0 | Utilizing Large Language Models (LLMs) for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process. This paper introduces a novel human-LLM interaction framework, Low-code LLM. It incorporates six types of simple low-code visual programming interactions to achieve more controllable and stable responses. Through visual interaction with a graphical user interface, users can incorporate their ideas into the process without writing trivial prompts. The proposed Low-code LLM framework consists of a Planning LLM that designs a structured planning workflow for complex tasks, which can be correspondingly edited and confirmed by users through low-code visual programming operations, and an Executing LLM that generates responses following the user-confirmed workflow. We highlight three advantages of the low-code LLM: user-friendly interaction, controllable generation, and wide applicability. We demonstrate its benefits using four typical applications. By introducing this framework, we aim to bridge the gap between humans and LLMs, enabling more effective and efficient utilization of LLMs for complex tasks. The code, prompts, and experimental details are available at https://github.com/moymix/TaskMatrix/tree/main/LowCodeLLM. A system demonstration video can be found at https://www.youtube.com/watch?v=jb2C1vaeO3E. | Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge, Chenfei Wu, Wang You, Ting Song, Yan Xia, Nan Duan, Furu Wei |  |
| 33 |  |  [EdTec-QBuilder: A Semantic Retrieval Tool for Assembling Vocational Training Exams in German Language](https://doi.org/10.18653/v1/2024.naacl-demo.3) |  | 0 |  | Alonso Palomino, Andreas Fischer, Jakub Kuzilek, Jarek Nitsch, Niels Pinkwart, Benjamin Paassen |  |
| 34 |  |  [DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-demo.4) |  | 0 | We present DIALIGHT, a toolkit for developing and evaluating multilingual Task-Oriented Dialogue (ToD) systems which facilitates systematic evaluations and comparisons between ToD systems using fine-tuning of Pretrained Language Models (PLMs) and those utilising the zero-shot and in-context learning capabilities of Large Language Models (LLMs). In addition to automatic evaluation, this toolkit features (i) a secure, user-friendly web interface for fine-grained human evaluation at both local utterance level and global dialogue level, and (ii) a microservice-based backend, improving efficiency and scalability. Our evaluations reveal that while PLM fine-tuning leads to higher accuracy and coherence, LLM-based systems excel in producing diverse and likeable responses. However, we also identify significant challenges of LLMs in adherence to task-specific instructions and generating outputs in multiple languages, highlighting areas for future research. We hope this open-sourced toolkit will serve as a valuable resource for researchers aiming to develop and properly evaluate multilingual ToD systems and will lower, currently still high, entry barriers in the field. | Songbo Hu, Xiaobin Wang, Moy Yuan, Anna Korhonen, Ivan Vulic |  |
| 35 |  |  [RTSUM: Relation Triple-based Interpretable Summarization with Multi-level Salience Visualization](https://doi.org/10.18653/v1/2024.naacl-demo.5) |  | 0 |  | Seonglae Cho, Myungha Jang, Jinyoung Yeo, Dongha Lee |  |
| 36 |  |  [Edu-ConvoKit: An Open-Source Library for Education Conversation Data](https://doi.org/10.18653/v1/2024.naacl-demo.6) |  | 0 | We introduce Edu-ConvoKit, an open-source library designed to handle pre-processing, annotation and analysis of conversation data in education. Resources for analyzing education conversation data are scarce, making the research challenging to perform and therefore hard to access. We address these challenges with Edu-ConvoKit. Edu-ConvoKit is open-source [1], pip-installable [2], with comprehensive documentation [3]. Our demo video is available at: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8-. We include additional resources, such as Colab applications of Edu-ConvoKit to three diverse education datasets [4] and a repository of Edu-ConvoKit-related papers [5].[1] https://github.com/stanfordnlp/edu-convokit[2] https://pypi.org/project/edu-convokit/[3] https://edu-convokit.readthedocs.io/en/latest/[4] https://github.com/stanfordnlp/edu-convokit?tab=readme-ov-file#datasets-with-edu-convokit[5] https://github.com/stanfordnlp/edu-convokit/blob/main/papers.md | Rose E. Wang, Dorottya Demszky |  |
| 37 |  |  [jp-evalb: Robust Alignment-based PARSEVAL Measures](https://doi.org/10.18653/v1/2024.naacl-demo.7) |  | 0 | We introduce an evaluation system designed to compute PARSEVAL measures, offering a viable alternative to evalb commonly used for constituency parsing evaluation. The widely used evalb script has traditionally been employed for evaluating the accuracy of constituency parsing results, albeit with the requirement for consistent tokenization and sentence boundaries. In contrast, our approach, named jp-evalb, is founded on an alignment method. This method aligns sentences and words when discrepancies arise. It aims to overcome several known issues associated with evalb by utilizing the ‘jointly preprocessed (JP)’ alignment-based method. We introduce a more flexible and adaptive framework, ultimately contributing to a more accurate assessment of constituency parsing performance. | Jungyeul Park, Junrui Wang, Eunkyul Leah Jo, Angela Yoonseo Park |  |
| 38 |  |  [OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs](https://doi.org/10.18653/v1/2024.naacl-demo.8) |  | 0 | Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions. However, an open research question concerns the inherent biases of trained models and their responses. For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias. Current research work seeks to de-bias such models, or suppress potentially biased answers.With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent. To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate. The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison. To train the underlying model, we identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics. This paper presents OpinionGPT, illustrates how we trained the bias-aware model and showcases the web application (available at https://opiniongpt.informatik.hu-berlin.de). | Patrick Haller, Ansar Aynetdinov, Alan Akbik |  |
| 39 |  |  [ATLAS: A System for PDF-centric Human Interaction Data Collection](https://doi.org/10.18653/v1/2024.naacl-demo.9) |  | 0 | The Portable Document Format (PDF) is a popular format for distributing digital documents. Datasets on PDF reading behaviors and interactions remain limited due to the challenges of instrumenting PDF readers for these data collection tasks. We present ATLAS, a data collection tool designed to better support researchers in collecting rich PDF-centric datasets from users. ATLAS supports researchers in programmatically creating a user interface for data collection that is ready to share with annotators. It includes a toolkit and an extensible schema to easily customize the data collection tasks for a variety of purposes, allowing collection of PDF annotations (e.g., highlights, drawings) as well as reading behavior analytics (e.g., page scroll, text selections). We open-source ATLAS1 to support future research efforts and review use cases of ATLAS that showcase our system’s broad applicability. | Alexa F. Siu, Zichao Wang, Joshua Hoeflich, Naman Kapasi, Ani Nenkova, Tong Sun |  |
| 40 |  |  [BeLeaf: Belief Prediction as Tree Generation](https://doi.org/10.18653/v1/2024.naacl-demo.10) |  | 0 | We present a novel approach to predicting source-and-target factuality by transforming it into a linearized tree generation task. Unlike previous work, our model and representation format fully account for the factuality tree structure, generating the full chain of nested sources instead of the last source only. Furthermore, our linearized tree representation significantly compresses the amount of tokens needed compared to other representations, allowing for fully end-to-end systems. We achieve state-of-the-art results on FactBank and the Modal Dependency Corpus, which are both corpora annotating source-and-target event factuality. Our results on fine-tuning validate the strong generality of the proposed linearized tree generation task, which can be easily adapted to other corpora with a similar structure. We then present BeLeaf, a system which directly leverages the linearized tree representation to create both sentence level and document level visualizations. Our system adds several missing pieces to the source-and-target factuality task such as coreference resolution and event head word to syntactic span conversion. Our demo code is available on https://github.com/yurpl/beleaf and our video is available on https://youtu.be/SpbMNnin-Po. | John Murzaku, Owen Rambow |  |
| 41 |  |  [QueryExplorer: An Interactive Query Generation Assistant for Search and Exploration](https://doi.org/10.18653/v1/2024.naacl-demo.11) |  | 0 |  | Kaustubh D. Dhole, Shivam Bajaj, Ramraj Chandradevan, Eugene Agichtein |  |
| 42 |  |  [LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models](https://doi.org/10.18653/v1/2024.naacl-demo.12) |  | 0 |  | Shizhe Diao, Rui Pan, Hanze Dong, Kashun Shum, Jipeng Zhang, Wei Xiong, Tong Zhang |  |
| 43 |  |  [DOCMASTER: A Unified Platform for Annotation, Training, & Inference in Document Question-Answering](https://doi.org/10.18653/v1/2024.naacl-demo.13) |  | 0 |  | Alex Nguyen, Zilong Wang, Jingbo Shang, Dheeraj Mekala |  |
| 44 |  |  [RedCoast: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs](https://doi.org/10.18653/v1/2024.naacl-demo.14) |  | 0 | The recent progress of AI can be largely attributed to large language models (LLMs). However, their escalating memory requirements introduce challenges for machine learning (ML) researchers and engineers. Addressing this requires developers to partition a large model to distribute it across multiple GPUs or TPUs. This necessitates considerable coding and intricate configuration efforts with existing model parallel tools, such as Megatron-LM, DeepSpeed, and Alpa. These tools require users’ expertise in machine learning systems (MLSys), creating a bottleneck in LLM development, particularly for developers without MLSys background. In this work, we present RedCoast (Redco), a lightweight and user-friendly tool crafted to automate distributed training and inference for LLMs, as well as to simplify ML pipeline development. The design of Redco emphasizes two key aspects. Firstly, to automate model parallelism, our study identifies two straightforward rules to generate tensor parallel strategies for any given LLM. Integrating these rules into Redco facilitates effortless distributed LLM training and inference, eliminating the need of additional coding or complex configurations. We demonstrate the effectiveness by applying Redco on a set of LLM architectures, such as GPT-J, LLaMA, T5, and OPT, up to the size of 66B. Secondly, we propose a mechanism that allows for the customization of diverse ML pipelines through the definition of merely three functions, avoiding redundant and formulaic code like multi-host related processing. This mechanism proves adaptable across a spectrum of ML algorithms, from foundational language modeling to complex algorithms like meta-learning and reinforcement learning. As a result, Redco implementations exhibit significantly fewer lines of code compared to their official counterparts. RedCoast (Redco) has been released under Apache 2.0 license at https://github.com/tanyuqian/redco. | Bowen Tan, Yun Zhu, Lijuan Liu, Hongyi Wang, Yonghao Zhuang, Jindong Chen, Eric P. Xing, Zhiting Hu |  |
| 45 |  |  [Concept Over Time Analysis: Unveiling Temporal Patterns for Qualitative Data Analysis](https://doi.org/10.18653/v1/2024.naacl-demo.15) |  | 0 | In this system demonstration paper, we present the Concept Over Time Analysis extension for the Discourse Analysis Tool Suite.The proposed tool empowers users to define, refine, and visualize their concepts of interest within an interactive interface. Adhering to the Human-in-the-loop paradigm, users can give feedback through sentence annotations. Utilizing few-shot sentence classification, the system employs Sentence Transformers to compute representations of sentences and concepts. Through an iterative process involving semantic similarity searches, sentence annotation, and fine-tuning with contrastive data, the model continuously refines, providing users with enhanced analysis outcomes. The final output is a timeline visualization of sentences classified to concepts. Especially suited for the Digital Humanities, Concept Over Time Analysis serves as a valuable tool for qualitative data analysis within extensive datasets. The chronological overview of concepts enables researchers to uncover patterns, trends, and shifts in discourse over time. | Tim Fischer, Florian Schneider, Robert Geislinger, Florian Helfer, Gertraud Koch, Chris Biemann |  |
| 46 |  |  [pyvene: A Library for Understanding and Improving PyTorch Models via Interventions](https://doi.org/10.18653/v1/2024.naacl-demo.16) |  | 0 |  | Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts |  |
| 47 |  |  [Newspaper Signaling for Crisis Prediction](https://doi.org/10.18653/v1/2024.naacl-demo.17) |  | 0 |  | Prajvi Saxena, Sabine Janzen, Wolfgang Maass |  |
| 48 |  |  [FastFit: Fast and Effective Few-Shot Text Classification with a Multitude of Classes](https://doi.org/10.18653/v1/2024.naacl-demo.18) |  | 0 |  | Asaf Yehudai, Elron Bandel |  |
| 49 |  |  [AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents](https://doi.org/10.18653/v1/2024.naacl-demo.19) |  | 0 |  | Luca Gioacchini, Giuseppe Siracusano, Davide Sanvito, Kiril Gashteovski, David Friede, Roberto Bifulco, Carolin Lawrence |  |
| 50 |  |  [ZhuJiu-Knowledge: A Fairer Platform for Evaluating Multiple Knowledge Types in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-demo.20) |  | 0 | The swift advancement in large language models (LLMs) has heightened the importance of model evaluations. LLMs have acquired a substantial amount of knowledge, and evaluating the knowledge of these LLMs is crucial. To address this, we introduce the ZhuJiu-Knowledge benchmark which carefully considers the following factors: (1) For knowledge scope, we concentrate on three domains: commonsense knowledge, world knowledge, language knowledge, which comes from ATOMIC, Conceptnet, Wikidata, and Wordnet. (2) For data construction, to prevent data contamination, we utilize knowledge derived from corpora and knowledge graphs to formulate novel questions which are ensured not to appear in the training corpus. A multitude of prompts is purposefully devised to mitigate the impact of prompt design on evaluation and to further analyze the LLMs’ sensitivity to various prompts. (3) For evaluation criteria, we propose a novel voting methodology for assessing generative text, aligning the model’s evaluation with human preferences to reduce biases inherent in individual model assessments. We evaluate 14 current mainstream LLMs and conduct a comprehensive discussion and analysis of their results. The ZhuJiu-Knowledge benchmark and open-participation leaderboard are publicly released at http://zhujiu-knowledge.top and we also provide a demo video at https://youtu.be/QJp4qlEHVH8. | Pengfan Du, Sirui Liang, Baoli Zhang, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao |  |
| 51 |  |  [Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI](https://doi.org/10.18653/v1/2024.naacl-demo.21) |  | 0 | In the dynamic landscape of generative NLP, traditional text processing pipelines limit research flexibility and reproducibility, as they are tailored to specific dataset, task, and model combinations. The escalating complexity, involving system prompts, model-specific formats, instructions, and more, calls for a shift to a structured, modular, and customizable solution.Addressing this need, we present Unitxt, an innovative library for customizable textual data preparation and evaluation tailored to generative language models. Unitxt natively integrates with common libraries like HuggingFace and LM-eval-harness and deconstructs processing flows into modular components, enabling easy customization and sharing between practitioners. These components encompass model-specific formats, task prompts, and many other comprehensive dataset processing definitions. The Unitxt Catalog centralizes these components, fostering collaboration and exploration in modern textual data workflows. Beyond being a tool, Unitxt is a community-driven platform, empowering users to build, share, and advance their pipelines collaboratively. Join the Unitxt community at https://github.com/IBM/unitxt | Elron Bandel, Yotam Perlitz, Elad Venezian, Roni Friedman, Ofir Arviv, Matan Orbach, Shachar DonYehiya, Dafna Sheinwald, Ariel Gera, Leshem Choshen, Michal ShmueliScheuer, Yoav Katz |  |
| 52 |  |  [HPipe: Large Language Model Pipeline Parallelism for Long Context on Heterogeneous Cost-effective Devices](https://doi.org/10.18653/v1/2024.naacl-industry.1) |  | 0 | Micro-enterprises and individual developers emerge analysis demands for long sequence with powerful Large Language Models (LLMs). They try to deploy the LLMs at local, but only possess various commodity devices and the unreliable interconnection between devices. Existing parallel techniques do not lead to the same effectiveness in limited environment. The heterogeneity of devices, coupled with their limited capacity and expensive communication, brings challenges to private deployment for maximized utilization of available devices while masking latency. Hence, we introduce HPipe, a pipeline inference framework that successfully mitigates LLMs from high-performance clusters to heterogeneous commodity devices. By ensuring a balanced distribution of workloads, HPipe facilitates the parallel execution of LLMs through pipelining the sequences on the token dimension. The evaluation conducted on LLaMA-7B and GPT3-2B demonstrates that HPipe holds the potential for context analysis on LLM with heterogeneity devices, achieving an impressive speedup in latency and throughput up to 2.28 times. | Ruilong Ma, Xiang Yang, Jing Wang, Qi Qi, Haifeng Sun, Zirui Zhuang, Jianxin Liao |  |
| 53 |  |  [Lossless Acceleration of Large Language Model via Adaptive N-gram Parallel Decoding](https://doi.org/10.18653/v1/2024.naacl-industry.2) |  | 0 | While Large Language Models (LLMs) have shown remarkable abilities, they are hindered by significant resource consumption and considerable latency due to autoregressive processing. In this study, we introduce Adaptive N-gram Parallel Decoding (ANPD), an innovative and lossless approach that accelerates inference by allowing the simultaneous generation of multiple tokens. ANPD incorporates a two-stage approach: it begins with a rapid drafting phase that employs an N-gram module, which adapts based on the current interactive context, followed by a verification phase, during which the original LLM assesses and confirms the proposed tokens. Consequently, ANPD preserves the integrity of the LLM’s original output while enhancing processing speed. We further leverage a multi-level architecture for the N-gram module to enhance the precision of the initial draft, consequently reducing inference latency. ANPD eliminates the need for retraining or extra GPU memory, making it an efficient and plug-and-play enhancement. In our experiments, models such as LLaMA and its fine-tuned variants have shown speed improvements up to 3.67x, validating the effectiveness of our proposed ANPD. | Jie Ou, Yueming Chen, Wenhong Tian |  |
| 54 |  |  [SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling](https://doi.org/10.18653/v1/2024.naacl-industry.3) |  | 0 | We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, demonstrating superior performance in various natural language processing (NLP) tasks. Inspired by recent efforts to efficiently up-scale LLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which encompasses depthwise scaling and continued pretraining. In contrast to other LLM up-scaling methods that use mixture-of-experts, DUS does not require complex changes to train and inference efficiently. We show experimentally that DUS is simple yet effective in scaling up high-performance LLMs from small ones. Building on the DUS model, we additionally present SOLAR 10.7B-Instruct, a variant fine-tuned for instruction-following capabilities, surpassing Mixtral-8x7B-Instruct. SOLAR 10.7B is publicly available under the Apache 2.0 license, promoting broad access and application in the LLM field. | Sanghoon Kim, Dahyun Kim, Chanjun Park, Wonsung Lee, Wonho Song, Yunsu Kim, Hyeonwoo Kim, Yungi Kim, Hyeonju Lee, Jihoo Kim, Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim, Mikyoung Cha, Hwalsuk Lee, Sunghun Kim |  |
| 55 |  |  [UINav: A Practical Approach to Train On-Device Automation Agents](https://doi.org/10.18653/v1/2024.naacl-industry.4) |  | 0 | Automation systems that can autonomously drive application user interfaces to complete user tasks are of great benefit, especially when users are situationally or permanently impaired. Prior automation systems do not produce generalizable models while AI-based automation agents work reliably only in simple, hand-crafted applications or incur high computation costs. We propose UINav, a demonstration-based approach to train automation agents that fit mobile devices, yet achieving high success rates with modest numbers of demonstrations. To reduce the demonstration overhead, UINav uses a referee model that provides users with immediate feedback on tasks where the agent fails, and automatically augments human demonstrations to increase diversity in training data. Our evaluation shows that with only 10 demonstrations can achieve 70% accuracy, and that with enough demonstrations it can surpass 90% accuracy. | Wei Li, FuLin Hsu, William Bishop, Folawiyo CampbellAjala, Max Lin, Oriana Riva |  |
| 56 |  |  [Efficiently Distilling LLMs for Edge Applications](https://doi.org/10.18653/v1/2024.naacl-industry.5) |  | 0 | Supernet training of LLMs is of great interest in industrial applications as it confers the ability to produce a palette of smaller models at constant cost, regardless of the number of models (of different size / latency) produced. We propose a new method called Multistage Low-rank Fine-tuning of Super-transformers (MLFS) for parameter-efficient supernet training. We show that it is possible to obtain high-quality encoder models that are suitable for commercial edge applications, and that while decoder-only models are resistant to a comparable degree of compression, decoders can be effectively sliced for a significant reduction in training time. | Achintya Kundu, Fabian Lim, Aaron Chew, Laura Wynter, Penny Chong, Rhui Dih Lee |  |
| 57 |  |  [Modeling and Detecting Company Risks from News](https://doi.org/10.18653/v1/2024.naacl-industry.6) |  | 0 | Identifying risks associated with a company is important to investors and the wellbeing of the overall financial markets. In this study, we build a computational framework to automatically extract company risk factors from news articles. Our newly proposed schema comprises seven distinct aspects, such as supply chain, regulations, and competition. We annotate 666 news articles and benchmark various machine learning models. While large language mod- els have achieved remarkable progress in various types of NLP tasks, our experiment shows that zero-shot and few-shot prompting state-of- the-art LLMs (e.g., Llama-2) can only achieve moderate to low performances in identifying risk factors. In contrast, fine-tuning pre-trained language models yields better results on most risk factors. Using this model, we analyze over 277K Bloomberg News articles and demonstrate that identifying risk factors from news could provide extensive insights into the operations of companies and industries. | Jiaxin Pei, Soumya Vadlamannati, LiangKang Huang, Daniel PreotiucPietro, Xinyu Hua |  |
| 58 |  |  [Multiple-Question Multiple-Answer Text-VQA](https://doi.org/10.18653/v1/2024.naacl-industry.7) |  | 0 | We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do text-VQA in encoder-decoder transformer models. To the best of our knowledge, almost all previous approaches for text-VQA process a single question and its associated content to predict a single answer. However, in industry applications, users may come up with multiple questions about a single image. In order to answer multiple questions from the same image, each question and content are fed into the model multiple times. In contrast, our proposed MQMA approach takes multiple questions and content as input at the encoder and predicts multiple answers at the decoder in an auto-regressive manner at the same time. We make several novel architectural modifications to standard encoder-decoder transformers to support MQMA. We also propose a novel MQMA denoising pre-training task which is designed to teach the model to align and delineate multiple questions and content with associated answers. MQMA pre-trained model achieves state-of-the-art results on multiple text-VQA datasets, each with strong baselines. Specifically, on OCR-VQA (+2.5%), TextVQA (+1.4%), ST-VQA (+0.6%), DocVQA (+1.1%) absolute improvements over the previous state-of-the-art approaches. | Peng Tang, Srikar Appalaraju, R. Manmatha, Yusheng Xie, Vijay Mahadevan |  |
| 59 |  |  [An NLP-Focused Pilot Training Agent for Safe and Efficient Aviation Communication](https://doi.org/10.18653/v1/2024.naacl-industry.8) |  | 0 | Aviation communication significantly influences the success of flight operations, ensuring safety of lives and efficient air transportation. In day-to-day flight operations, air traffic controllers (ATCos) would timely communicate instructions to pilots using specific phraseology for aircraft manipulation . However, pilots, originating from diverse backgrounds and understanding of English language, have struggled with conforming to strict phraseology for readback and communication in the live operation, this problem had not been effectively addressed over the past decades. Traditionally, aviation communication training involved expensive setups and resources, often relying on human-in-the-loop (HIL) air traffic simulations that demand allocating a specific environment, domain experts for participation, and substantial amount of annotated data for simulation. Therefore, we would like to propose an NLP-oriented training agent and address these challenges. Our approach involves leveraging only natural language capabilities and fine-tuning on communication data to generate instructions based on input scenarios (keywords). Given the absence of prior references for this business problem, we investigated the feasibility of our proposed solution by 1) generating all instructions at once and 2) generating one instruction while incorporating conversational history in each input. Our findings affirm the feasibility of this approach, highlighting the effectiveness of fine-tuning pre-trained models and large language models in advancing aviation communication training. | Xiaochen Liu, Bowei Zou, AiTi Aw |  |
| 60 |  |  [Visual Grounding for User Interfaces](https://doi.org/10.18653/v1/2024.naacl-industry.9) |  | 0 | Enabling autonomous language agents to drive application user interfaces (UIs) as humans do can significantly expand the capability of today’s API-based agents. Essential to this vision is the ability of agents to ground natural language commands to on-screen UI elements. Prior UI grounding approaches work by relaying on developer-provided UI metadata (UI trees, such as web DOM, and accessibility labels) to detect on-screen elements. However, such metadata is often unavailable or incomplete. Object detection techniques applied to UI screens remove this dependency, by inferring location and types of UI elements directly from the UI’s visual appearance. The extracted semantics, however, are too limited to directly enable grounding. We overcome the limitations of both approaches by introducing the task of visual UI grounding, which unifies detection and grounding. A model takes as input a UI screenshot and a free-form language expression, and must identify the referenced UI element. We propose a solution to this problem, LVG, which learns UI element detection and grounding using a new technique called layout-guided contrastive learning, where the semantics of individual UI objects are learned also from their visual organization. Due to the scarcity of UI datasets, LVG integrates synthetic data in its training using multi-context learning. LVG outperforms baselines pre-trained on much larger datasets by over 4.9 points in top-1 accuracy, thus demonstrating its effectiveness. | Yijun Qian, Yujie Lu, Alexander Hauptmann, Oriana Riva |  |
| 61 |  |  [Prompt Tuned Embedding Classification for Industry Sector Allocation](https://doi.org/10.18653/v1/2024.naacl-industry.10) |  | 0 | We introduce Prompt Tuned Embedding Classification (PTEC) for classifying companies within an investment firm’s proprietary industry taxonomy, supporting their thematic investment strategy. PTEC assigns companies to the sectors they primarily operate in, conceptualizing this process as a multi-label text classification task. Prompt Tuning, usually deployed as a text-to-text (T2T) classification approach, ensures low computational cost while maintaining high task performance. However, T2T classification has limitations on multi-label tasks due to the generation of non-existing labels, permutation invariance of the label sequence, and a lack of confidence scores. PTEC addresses these limitations by utilizing a classification head in place of the Large Language Models (LLMs) language head. PTEC surpasses both baselines and human performance while lowering computational demands. This indicates the continuing need to adapt state-of-the-art methods to domain-specific tasks, even in the era of LLMs with strong generalization abilities. | Valentin Leonhard Buchner, Lele Cao, JanChristoph Kalo, Vilhelm von Ehrenheim |  |
| 62 |  |  [REXEL: An End-to-end Model for Document-Level Relation Extraction and Entity Linking](https://doi.org/10.18653/v1/2024.naacl-industry.11) |  | 0 | Extracting structured information from unstructured text is critical for many downstream NLP applications and is traditionally achieved by closed information extraction (cIE). However, existing approaches for cIE suffer from two limitations: (i) they are often pipelines which makes them prone to error propagation, and/or (ii) they are restricted to sentence level which prevents them from capturing long-range dependencies and results in expensive inference time. We address these limitations by proposing REXEL, a highly efficient and accurate model for the joint task of document level cIE (DocIE). REXEL performs mention detection, entity typing, entity disambiguation, coreference resolution and document-level relation classification in a single forward pass to yield facts fully linked to a reference knowledge graph. It is on average 11 times faster than competitive existing approaches in a similar setting and performs competitively both when optimised for any of the individual sub-task and a variety of combinations of different joint tasks, surpassing the baselines by an average of more than 6 F1 points. The combination of speed and accuracy makes REXEL an accurate cost-efficient system for extracting structured information at web-scale. We also release an extension of the DocRED dataset to enable benchmarking of future work on DocIE, which will be available at https://github.com/amazon-science/e2e-docie. | Nacime Bouziani, Shubhi Tyagi, Joseph Fisher, Jens Lehmann, Andrea Pierleoni |  |
| 63 |  |  [Conformer-Based Speech Recognition On Extreme Edge-Computing Devices](https://doi.org/10.18653/v1/2024.naacl-industry.12) |  | 0 | With increasingly more powerful compute capabilities and resources in today’s devices, traditionally compute-intensive automatic speech recognition (ASR) has been moving from the cloud to devices to better protect user privacy. However, it is still challenging to implement on-device ASR on resource-constrained devices, such as smartphones, smart wearables, and other small home automation devices. In this paper, we propose a series of model architecture adaptions, neural network graph transformations, and numerical optimizations to fit an advanced Conformer based end-to-end streaming ASR system on resource-constrained devices without accuracy degradation. We achieve over 5.26 times faster than realtime (0.19 RTF) speech recognition on small wearables while minimizing energy consumption and achieving state-of-the-art accuracy. The proposed methods are widely applicable to other transformer-based server-free AI applications. In addition, we provide a complete theory on optimal pre-normalizers that numerically stabilize layer normalization in any Lp-norm using any floating point precision. | Mingbin Xu, Alex Jin, Sicheng Wang, Mu Su, Tim Ng, Henry Mason, Shiyi Han, Zhihong Lei, Yaqiao Deng, Zhen Huang, Mahesh Krishnamoorthy |  |
| 64 |  |  [Generating Signed Language Instructions in Large-Scale Dialogue Systems](https://doi.org/10.18653/v1/2024.naacl-industry.13) |  | 0 | We introduce a goal-oriented conversational AI system enhanced with American Sign Language (ASL) instructions, presenting the first implementation of such a system on a worldwide multimodal conversational AI platform. Accessible through a touch-based interface, our system receives input from users and seamlessly generates ASL instructions by leveraging retrieval methods and cognitively based gloss translations. Central to our design is a sign translation module powered by Large Language Models, alongside a token-based video retrieval system for delivering instructional content from recipes and wikiHow guides. Our development process is deeply rooted in a commitment to community engagement, incorporating insights from the Deaf and Hard-of-Hearing community, as well as experts in cognitive and ASL learning sciences. The effectiveness of our signing instructions is validated by user feedback, achieving ratings on par with those of the system in its non-signing variant. Additionally, our system demonstrates exceptional performance in retrieval accuracy and text-generation quality, measured by metrics such as BERTScore. We have made our codebase and datasets publicly accessible at https://github.com/Merterm/signed-dialogue, and a demo of our signed instruction video retrieval system is available at https://huggingface.co/spaces/merterm/signed-instructions. | Mert Inan, Katherine Atwell, Anthony Sicilia, Lorna C. Quandt, Malihe Alikhani |  |
| 65 |  |  [Leveraging Natural Language Processing and Large Language Models for Assisting Due Diligence in the Legal Domain](https://doi.org/10.18653/v1/2024.naacl-industry.14) |  | 0 | Due diligence is a crucial legal process that mitigates potential risks of mergers and acquisitions (M&A). However, despite its prominent importance, there has been a lack of research regarding leveraging NLP techniques for due diligence. In this study, our aim is to explore the most efficient deep-learning model architecture for due diligence in terms of performance and latency, and evaluate the potential of large language models (LLMs) as an efficient due diligence assistant. To our knowledge, this is the first study that employs pre-trained language models (PLMs) and LLMs for the due diligence problem. Our experimental results suggest that methodologies that have demonstrated promising performance in the general domain encounter challenges when applied in due diligence due to the inherent lengthy nature of legal documents. We also ascertain that LLMs can be a useful tool for helping lawyers who perform due diligence. | Myeongjun Jang, Gábor Stikkel |  |
| 66 |  |  [AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators](https://doi.org/10.18653/v1/2024.naacl-industry.15) |  | 0 | Many natural language processing (NLP) tasks rely on labeled data to train machine learning models with high performance. However, data annotation is time-consuming and expensive, especially when the task involves a large amount of data or requires specialized domains. Recently, GPT-3.5 series models have demonstrated remarkable few-shot and zero-shot ability across various NLP tasks. In this paper, we first claim that large language models (LLMs), such as GPT-3.5, can serve as an excellent crowdsourced annotator when provided with sufficient guidance and demonstrated examples. Accordingly, we propose AnnoLLM, an annotation system powered by LLMs, which adopts a two-step approach, explain-then-annotate. Concretely, we first prompt LLMs to provide explanations for why the specific ground truth answer/label was assigned for a given example. Then, we construct the few-shot chain-of-thought prompt with the self-generated explanation and employ it to annotate the unlabeled data with LLMs. Our experiment results on three tasks, including user input and keyword relevance assessment, BoolQ, and WiC, demonstrate that AnnoLLM surpasses or performs on par with crowdsourced annotators. Furthermore, we build the first conversation-based information retrieval dataset employing AnnoLLM. This dataset is designed to facilitate the development of retrieval models capable of retrieving pertinent documents for conversational text. Human evaluation has validated the dataset’s high quality. | Xingwei He, Zhenghao Lin, Yeyun Gong, ALong Jin, Hang Zhang, Chen Lin, Jian Jiao, Siu Ming Yiu, Nan Duan, Weizhu Chen |  |
| 67 |  |  [An Automatic Prompt Generation System for Tabular Data Tasks](https://doi.org/10.18653/v1/2024.naacl-industry.16) |  | 0 | Efficient processing of tabular data is important in various industries, especially when working with datasets containing a large number of columns. Large language models (LLMs) have demonstrated their ability on several tasks through carefully crafted prompts. However, creating effective prompts for tabular datasets is challenging due to the structured nature of the data and the need to manage numerous columns. This paper presents an innovative auto-prompt generation system suitable for multiple LLMs, with minimal training. It proposes two novel methods; 1) A Reinforcement Learning-based algorithm for identifying and sequencing task-relevant columns 2) cell-level similarity-based approach for enhancing few-shot example selection. Our approach has been extensively tested across 66 datasets, demonstrating improved performance in three downstream tasks: data imputation, error detection, and entity matching using two distinct LLMs; Google/flant-t5xxl and Mixtral 8x7B. | Ashlesha Akella, Abhijit Manatkar, Brijkumar Chavda, Hima Patel |  |
| 68 |  |  [Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data](https://doi.org/10.18653/v1/2024.naacl-industry.17) |  | 0 | In the financial industry, identifying the location of parties involved in payments is a major challenge in the context of Anti-Money Laundering transaction monitoring. For this purpose address parsing entails extracting fields such as street, postal code, or country from free text message attributes. While payment processing platforms are updating their standards with more structured formats such as SWIFT with ISO 20022, address parsing remains essential for a considerable volume of messages. With the emergence of Transformers and Generative Large Language Models (LLM), we explore the performance of state-of-the-art solutions given the constraint of processing a vast amount of daily data. This paper also aims to show the need for training robust models capable of dealing with real-world noisy transactional data. Our results suggest that a well fine-tuned Transformer model using early-stopping significantly outperforms other approaches. Nevertheless, generative LLMs demonstrate strong zero_shot performance and warrant further investigations. | Haitham Hammami, Louis Baligand, Bojan Petrovski |  |
| 69 |  |  [Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain](https://doi.org/10.18653/v1/2024.naacl-industry.18) |  | 0 | In difficult decision-making scenarios, it is common to have conflicting opinions among expert human decision-makers as there may not be a single right answer. Such decisions may be guided by different attributes that can be used to characterize an individual’s decision. We introduce a novel dataset for medical triage decision-making, labeled with a set of decision-maker attributes (DMAs). This dataset consists of 62 scenarios, covering six different DMAs, including ethical principles such as fairness and moral desert. We present a novel software framework for human-aligned decision-making by utilizing these DMAs, paving the way for trustworthy AI with better guardrails. Specifically, we demonstrate how large language models (LLMs) can serve as ethical decision-makers, and how their decisions can be aligned to different DMAs using zero-shot prompting. Our experiments focus on different open-source models with varying sizes and training techniques, such as Falcon, Mistral, and Llama 2. Finally, we also introduce a new form of weighted self-consistency that improves the overall quantified performance. Our results provide new research directions in the use of LLMs as alignable decision-makers. The dataset and open-source software are publicly available at: https://github.com/ITM-Kitware/llm-alignable-dm. | Brian Hu, Bill Ray, Alice Leung, Amy Summerville, David Joy, Christopher Funk, Arslan Basharat |  |
| 70 |  |  [Reducing hallucination in structured outputs via Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.naacl-industry.19) |  | 0 | A current limitation of Generative AI (GenAI) is its propensity to hallucinate. While Large Language Models (LLM) have taken the world by storm, without eliminating or at least reducing hallucination, real-world GenAI systems will likely continue to face challenges in user adoption. In the process of deploying an enterprise application that produces workflows from natural language requirements, we devised a system leveraging Retrieval-Augmented Generation (RAG) to improve the quality of the structured output that represents such workflows. Thanks to our implementation of RAG, our proposed system significantly reduces hallucination and allows the generalization of our LLM to out-of-domain settings. In addition, we show that using a small, well-trained retriever can reduce the size of the accompanying LLM at no loss in performance, thereby making deployments of LLM-based systems less resource-intensive. | Orlando Ayala, Patrice Béchard |  |
| 71 |  |  [Towards Translating Objective Product Attributes Into Customer Language](https://doi.org/10.18653/v1/2024.naacl-industry.20) |  | 0 | When customers search online for a product they are not familiar with, their needs are often expressed through subjective product attributes, such as ”picture quality” for a TV or ”easy to clean” for a sofa. In contrast, the product catalog in online stores includes objective attributes such as ”screen resolution” or ”material”. In this work, we aim to find a link between the objective product catalog and the subjective needs of the customers, to help customers better understand the product space using their own words. We apply correlation-based methods to the store’s product catalog and product reviews in order to find the best potential links between objective and subjective attributes; next, Large Language Models (LLMs) reduce spurious correlations by incorporating common sense and world knowledge (e.g., picture quality is indeed affected by screen resolution, and 8k is the best one). We curate a dataset for this task and show that our combined approach outperforms correlation-only and causation-only approaches. | Ram Yazdi, Oren Kalinsky, Alexander Libov, Dafna Shahaf |  |
| 72 |  |  [Automating the Generation of a Functional Semantic Types Ontology with Foundational Models](https://doi.org/10.18653/v1/2024.naacl-industry.21) |  | 0 | The rise of data science, the inherent dirtiness of data, and the proliferation of vast data providers have increased the value proposition of Semantic Types. Semantic Types are a way of encoding contextual information onto a data schema that informs the user about the definitional meaning of data, its broader context, and relationships to other types. We increasingly see a world where providing structure to this information, attached directly to data, will enable both people and systems to better understand the content of a dataset and the ability to efficiently automate data tasks such as validation, mapping/joins, and eventually machine learning. While ontological systems exist, they have not had widespread adoption due to challenges in mapping to operational datasets and lack of specificity of entity-types. Additionally, the validation checks associated with data are stored in code bases separate from the datasets that are distributed. In this paper, we address both challenges holistically by proposing a system that efficiently maps and encodes functional meaning on Semantic Types. | Sachin Konan, Larry Rudolph, Scott Affens |  |
| 73 |  |  [Leveraging Customer Feedback for Multi-modal Insight Extraction](https://doi.org/10.18653/v1/2024.naacl-industry.22) |  | 0 | Businesses can benefit from customer feedback in different modalities, such as text and images, to enhance their products and services. However, it is difficult to extract actionable and relevant pairs of text segments and images from customer feedback in a single pass. In this paper, we propose a novel multi-modal method that fuses image and text information in a latent space and decodes it to extract the relevant feedback segments using an image-text grounded text decoder. We also introduce a weakly-supervised data generation technique that produces training data for this task. We evaluate our model on unseen data and demonstrate that it can effectively mine actionable insights from multi-modal customer feedback, outperforming the existing baselines by 14 points in F1 score. | Sandeep Sricharan Mukku, Abinesh Kanagarajan, Pushpendu Ghosh, Chetan Aggarwal |  |
| 74 |  |  [Optimizing LLM Based Retrieval Augmented Generation Pipelines in the Financial Domain](https://doi.org/10.18653/v1/2024.naacl-industry.23) |  | 0 | Retrieval Augmented Generation (RAG) is a prominent approach in real-word applications for grounding large language model (LLM) generations in up to date and domain-specific knowledge. However, there is a lack of systematic investigations of the impact of each component (retrieval quality, prompts, generation models) on the generation quality of a RAG pipeline in real world scenarios. In this study, we benchmark 6 LLMs in 15 retrieval scenarios exploring 9 prompts over 2 real world financial domain datasets. We thoroughly discuss the impact of each component in RAG pipeline on answer generation quality and formulate specific recommendations for the design of RAG systems. | Yiyun Zhao, Prateek Singh, Hanoz Bhathena, Bernardo Ramos, Aviral Joshi, Swaroop Gadiyaram, Saket Sharma |  |
| 75 |  |  [Scaling Up Authorship Attribution](https://doi.org/10.18653/v1/2024.naacl-industry.24) |  | 0 | We describe our system for authorship attribution in the IARPA HIATUS program. We describe the model and compute infrastructure developed to satisfy the set of technical constraints imposed by IARPA, including runtime limits as well as other constraints related to the ultimate use case. One use-case constraint concerns the explainability of the features used in the system. For this reason, we integrate features from frame semantic parsing, as they are both interpretable and difficult for adversaries to evade. One trade-off with using such features, however, is that more sophisticated feature representations require more complicated architectures, which limit usefulness in time-sensitive and constrained compute environments. We propose an approach to increase the efficiency of frame semantic parsing through an analysis of parallelization and beam search sizes. Our approach results in a system that is approximately 8.37x faster than the base system with a minimal effect on accuracy. | Jacob Striebel, Abishek R. Edikala, Ethan Irby, Alex Rosenfeld, J. Gage, Daniel Dakota, Sandra Kübler |  |
| 76 |  |  [Multimodal Contextual Dialogue Breakdown Detection for Conversational AI Models](https://doi.org/10.18653/v1/2024.naacl-industry.25) |  | 0 | Detecting dialogue breakdown in real time is critical for conversational AI systems, because it enables taking corrective action to successfully complete a task. In spoken dialog systems, this breakdown can be caused by a variety of unexpected situations including high levels of background noise, causing STT mistranscriptions, or unexpected user flows.In particular, industry settings like healthcare, require high precision and high flexibility to navigate differently based on the conversation history and dialogue states. This makes it both more challenging and more critical to accurately detect dialog breakdown. To accurately detect breakdown, we found it requires processing audio inputs along with downstream NLP model inferences on transcribed text in real time. In this paper, we introduce a Multimodal Contextual Dialogue Breakdown (MultConDB) model. This model significantly outperforms other known best models by achieving an F1 of 69.27. | Md Messal Monem Miah, Ulie Schnaithmann, Arushi Raghuvanshi, Youngseo Son |  |
| 77 |  |  [Deferred NAM: Low-latency Top-K Context Injection via Deferred Context Encoding for Non-Streaming ASR](https://doi.org/10.18653/v1/2024.naacl-industry.26) |  | 0 | Contextual biasing enables speech recognizers to transcribe important phrases in the speaker’s context, such as contact names, even if they are rare in, or absent from, the training data. Attention-based biasing is a leading approach which allows for full end-to-end cotraining of the recognizer and biasing system and requires no separate inference-time components. Such biasers typically consist of a context encoder; followed by a context filter which narrows down the context to apply, improving per-step inference time; and, finally, context application via cross attention. Though much work has gone into optimizing per-frame performance, the context encoder is at least as important: recognition cannot begin before context encoding ends. Here, we show the lightweight phrase selection pass can be moved before context encoding, resulting in a speedup of up to 16.1 times and enabling biasing to scale to 20K phrases with a maximum pre-decoding delay under 33ms. With the addition of phrase- and wordpiece-level cross-entropy losses, our technique also achieves up to a 37.5% relative WER reduction over the baseline without the losses and lightweight phrase selection pass. | Zelin Wu, Gan Song, Christopher Li, Pat Rondon, Zhong Meng, Xavier Velez, Weiran Wang, Diamantino Caseiro, Golan Pundak, Tsendsuren Munkhdalai, Angad Chandorkar, Rohit Prabhavalkar |  |
| 78 |  |  [Less is More for Improving Automatic Evaluation of Factual Consistency](https://doi.org/10.18653/v1/2024.naacl-industry.27) |  | 0 | Assessing the factual consistency of automatically generated texts in relation to source context is crucial for developing reliable natural language generation applications. Recent literature proposes AlignScore which uses a unified alignment model to evaluate factual consistency and substantially outperforms previous methods across many benchmark tasks. In this paper, we take a closer look of datasets used in AlignScore and uncover an unexpected finding: utilizing a smaller number of data points can actually improve performance. We process the original AlignScore training dataset to remove noise, augment with robustness-enhanced samples, and utilize a subset comprising 10% of the data to train an improved factual consistency evaluation model, we call LIM-RA (Less Is More for Robust AlignScore). LIM-RA demonstrates superior performance, consistently outperforming AlignScore and other strong baselines like ChatGPT across four benchmarks (two utilizing traditional natural language generation datasets and two focused on large language model outputs). Our experiments show that LIM-RA achieves the highest score on 24 of the 33 test datasets, while staying competitive on the rest, establishing the new state-of-the-art benchmarks. | Tong Wang, Ninad Kulkarni, Yanjun Qi |  |
| 79 |  |  [DriftWatch: A Tool that Automatically Detects Data Drift and Extracts Representative Examples Affected by Drift](https://doi.org/10.18653/v1/2024.naacl-industry.28) |  | 0 | Data drift, which denotes a misalignment between the distribution of reference (i.e., training) and production data, constitutes a significant challenge for AI applications, as it undermines the generalisation capacity of machine learning (ML) models. Therefore, it is imperative to proactively identify data drift before users meet with performance degradation. Moreover, to ensure the successful execution of AI services, endeavours should be directed not only toward detecting the occurrence of drift but also toward effectively addressing this challenge. % considering the limited resources prevalent in practical industrial domains. In this work, we introduce a tool designed to detect data drift in text data. In addition, we propose an unsupervised sampling technique for extracting representative examples from drifted instances. This approach bestows a practical advantage by significantly reducing expenses associated with annotating the labels for drifted instances, an essential prerequisite for retraining the model to sustain its performance on production data. | Myeongjun Jang, Antonios Georgiadis, Yiyun Zhao, Fran Silavong |  |
| 80 |  |  [Graph Integrated Language Transformers for Next Action Prediction in Complex Phone Calls](https://doi.org/10.18653/v1/2024.naacl-industry.29) |  | 0 | Current Conversational AI systems employ different machine learning pipelines, as well as external knowledge sources and business logic to predict the next action. Maintaining various components in dialogue managers’ pipeline adds complexity in expansion and updates, increases processing time, and causes additive noise through the pipeline that can lead to incorrect next action prediction. This paper investigates graph integration into language transformers to improve understanding the relationships between humans’ utterances, previous, and next actions without the dependency on external sources or components. Experimental analyses on real calls indicate that the proposed Graph Integrated Language Transformer models can achieve higher performance compared to other production level conversational AI systems in driving interactive calls with human users in real-world settings. | Amin Hosseiny Marani, Ulie Schnaithmann, Youngseo Son, Akil Iyer, Manas Paldhe, Arushi Raghuvanshi |  |
| 81 |  |  [Leveraging LLMs for Dialogue Quality Measurement](https://doi.org/10.18653/v1/2024.naacl-industry.30) |  | 0 | In task-oriented conversational AI evaluation, unsupervised methods poorly correlate with human judgments, and supervised approaches lack generalization. Recent advances in large language models (LLMs) show robust zero- and few-shot capabilities across NLP tasks. Our paper explores using LLMs for automated dialogue quality evaluation, experimenting with various configurations on public and proprietary datasets. Manipulating factors such as model size, in-context examples, and selection techniques, we examine “chain-of-thought” (CoT) reasoning and label extraction procedures. Our results show that (1) larger models yield more accurate dialogue labels; (2) algorithmic selection of in-context examples outperforms random selection,; (3) CoT reasoning where an LLM is asked to provide justifications before outputting final labels improves performance; and (4) fine-tuned LLMs outperform out-of-the-box ones. In addition, we find that suitably tuned LLMs exhibit high accuracy in dialogue evaluation compared to human judgments. | Jinghan Jia, Abi Komma, Timothy Leffel, Xujun Peng, Ajay Nagesh, Tamer Soliman, Aram Galstyan, Anoop Kumar |  |
| 82 |  |  [Uncertainty Estimation in Large Language Models to Support Biodiversity Conservation](https://doi.org/10.18653/v1/2024.naacl-industry.31) |  | 0 | Large Language Models (LLM) provide significant value in question answering (QA) scenarios and have practical application in complex decision-making contexts, such as biodiversity conservation. However, despite substantial performance improvements, they may still produce inaccurate outcomes. Consequently, incorporating uncertainty quantification alongside predictions is essential for mitigating the potential risks associated with their use. This study introduces an exploratory analysis of the application of Monte Carlo Dropout (MCD) and Expected Calibration Error (ECE) to assess the uncertainty of generative language models. To that end, we analyzed two publicly available language models (Falcon-7B and DistilGPT-2). Our findings suggest the viability of employing ECE as a metric to estimate uncertainty in generative LLM. The findings from this research contribute to a broader project aiming at facilitating free and open access to standardized and integrated data and services about Costa Rica’s biodiversity to support the development of science, education, and biodiversity conservation. | Maria MoraCross, Saúl Calderón Ramírez |  |
| 83 |  |  [AMA-LSTM: Pioneering Robust and Fair Financial Audio Analysis for Stock Volatility Prediction](https://doi.org/10.18653/v1/2024.naacl-industry.32) |  | 0 | Stock volatility prediction is an important task in the financial industry. Recent multimodal methods have shown advanced results by combining text and audio information, such as earnings calls. However, these multimodal methods have faced two drawbacks. First, they often fail to yield reliable models and overfit the data due to their absorption of stochastic information from the stock market. Moreover, using multimodal models to predict stock volatility suffers from gender bias and lacks an efficient way to eliminate such bias. To address these aforementioned problems, we use adversarial training to generate perturbations that simulate the inherent stochasticity and bias, by creating areas resistant to random information around the input space to improve model robustness and fairness. Our comprehensive experiments on two real-world financial audio datasets reveal that this method exceeds the performance of current state-of-the-art solution. This confirms the value of adversarial training in reducing stochasticity and bias for stock volatility prediction tasks. | Shengkun Wang, Taoran Ji, Jianfeng He, Mariam Almutairi, Dan Wang, Linhan Wang, Min Zhang, ChangTien Lu |  |
| 84 |  |  [Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?](https://doi.org/10.18653/v1/2024.naacl-industry.33) |  | 0 | Large Language Models (LLMs) have demonstrated impressive capabilities to solve a wide range of tasks without being explicitly fine-tuned on task-specific datasets. However, deploying LLMs in the real world is not trivial, as it requires substantial computing resources. In this paper, we investigate whether smaller, Compact LLMs are a good alternative to the comparatively Larger LLMs to address significant costs associated with utilizing LLMs in the real world. In this regard, we study the meeting summarization task in a real-world industrial environment and conduct extensive experiments by comparing the performance of fine-tuned compact LLMs (FLAN-T5, TinyLLaMA, LiteLLaMA, etc.) with zero-shot larger LLMs (LLaMA-2, GPT-3.5, PaLM-2). We observe that most smaller LLMs, even after fine-tuning, fail to outperform larger zero-shot LLMs in meeting summarization datasets. However, a notable exception is FLAN-T5 (780M parameters), which achieves performance on par with zero-shot Larger LLMs (from 7B to above 70B parameters), while being significantly smaller. This makes compact LLMs like FLAN-T5 a suitable cost-efficient LLM for real-world industrial deployment. | XueYong Fu, Md. Tahmid Rahman Laskar, Elena Khasanova, Cheng Chen, Shashi Bhushan TN |  |
| 85 |  |  [Shears: Unstructured Sparsity with Neural Low-rank Adapter Search](https://doi.org/10.18653/v1/2024.naacl-industry.34) |  | 0 | Recently, several approaches successfully demonstrated that weight-sharing Neural Architecture Search (NAS) can effectively explore a search space of elastic low-rank adapters (LoRA), allowing the parameter-efficient fine-tuning (PEFT) and compression of large language models. In this paper, we introduce a novel approach called Shears, demonstrating how the integration of cost-effective sparsity and a proposed Neural Low-rank adapter Search (NLS) algorithm can further improve the efficiency of PEFT approaches. Results demonstrate the benefits of Shears compared to other methods, reaching high sparsity levels while improving or with little drop in accuracy, utilizing a single GPU for a pair of hours. | J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain |  |
| 86 |  |  [Tree-of-Question: Structured Retrieval Framework for Korean Question Answering Systems](https://doi.org/10.18653/v1/2024.naacl-industry.35) |  | 0 | We introduce Korean language-specific RAG-based QA systems, primarily through the innovative Tree-of-Question (ToQ) methodology and enhanced query generation techniques. We address the complex, multi-hop nature of real-world questions by effectively integrating advanced LLMs with nuanced query planning. Our comprehensive evaluations, including a newly created Korean multi-hop QA dataset, demonstrate our method’s ability to elevate response validity and accuracy, especially in deeper levels of reasoning. This paper not only showcases significant progress in handling the intricacies of Korean linguistic structures but also sets a new standard in the development of context-aware and linguistically sophisticated QA systems. | Dongyub Lee, Younghun Jeong, HwaYeon Kim, Hongyeon Yu, Seunghyun Han, Taesun Whang, Seungwoo Cho, Chanhee Lee, Gunsu Lee, Youngbum Kim |  |
| 87 |  |  [LLM-based Frameworks for API Argument Filling in Task-Oriented Conversational Systems](https://doi.org/10.18653/v1/2024.naacl-industry.36) |  | 0 | Task-orientated conversational agents interact with users and assist them via leveraging external APIs. A typical task-oriented conversational system can be broken down into three phases: external API selection, argument filling, and response generation. The focus of our work is the task of argument filling, which is in charge of accurately providing arguments required by the selected API. Upon comprehending the dialogue history and the pre-defined API schema, the argument filling task is expected to provide the external API with the necessary information to generate a desirable agent action. In this paper, we study the application of Large Language Models (LLMs) for the problem of API argument filling task. Our initial investigation reveals that LLMs require an additional grounding process to successfully perform argument filling, inspiring us to design training and prompting frameworks to ground their responses. Our experimental results demonstrate that when paired with proposed techniques, the argument filling performance of LLMs noticeably improves, paving a new way toward building an automated argument filling framework. | Jisoo Mok, Mohammad Kachuee, Shuyang Dai, Shayan Ray, Tara Taghavi, Sungroh Yoon |  |
| 88 |  |  [Large Language Models Encode the Practice of Medicine](https://doi.org/10.18653/v1/2024.naacl-industry.37) |  | 0 | Healthcare tasks such as predicting clinical outcomes across medical and surgical populations, disease prediction, predicting patient health journeys, are typically approached with supervised learning on task-specific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of billions of administrative claims, which essentially encapsulates the practice of medicine, offering a unique perspective on patient care and treatment patterns. Our model, MediClaimGPT, a 125M parameter Transformer demonstrates strong zero-shot predictive capabilities, accurately forecasting patient health events across four evaluation datasets, with its capabilities further demonstrated in various downstream tasks. A significant application of MediClaimGPT is in generating high-quality, clinically plausible synthetic claims data, enhancing healthcare data utility while preserving patient privacy. This research underscores the potential of language models in handling complex datasets and their strategic application in healthcare and related fields. | Teja Kanchinadam, Shaheen Gauher |  |
| 89 |  |  [Leveraging Interesting Facts to Enhance User Engagement with Conversational Interfaces](https://doi.org/10.18653/v1/2024.naacl-industry.38) |  | 0 | Conversational Task Assistants (CTAs) guide users in performing a multitude of activities, such as making recipes. However, ensuring that interactions remain engaging, interesting, and enjoyable for CTA users is not trivial, especially for time-consuming or challenging tasks. Grounded in psychological theories of human interest, we propose to engage users with contextual and interesting statements or facts during interactions with a multi-modal CTA, to reduce fatigue and task abandonment before a task is complete. To operationalize this idea, we train a high-performing classifier (82% F1-score) to automatically identify relevant and interesting facts for users. We use it to create an annotated dataset of task-specific interesting facts for the domain of cooking. Finally, we design and validate a dialogue policy to incorporate the identified relevant and interesting facts into a conversation, to improve user engagement and task completion. Live testing on a leading multi-modal voice assistant shows that 66% of the presented facts were received positively, leading to a 40% gain in the user satisfaction rating, and a 37% increase in conversation length. These findings emphasize that strategically incorporating interesting facts into the CTA experience can promote real-world user participation for guided task interactions. | Nikhita Vedula, Giuseppe Castellucci, Eugene Agichtein, Oleg Rokhlenko, Shervin Malmasi |  |
| 90 |  |  [Search Query Refinement for Japanese Named Entity Recognition in E-commerce Domain](https://doi.org/10.18653/v1/2024.naacl-industry.39) |  | 0 | In the E-Commerce domain, search query refinement reformulates malformed queries into canonicalized forms by preprocessing operations such as “term splitting” and “term merging”. Unfortunately, most relevant research is rather limited to English. In particular, there is a severe lack of study on search query refinement for the Japanese language. Furthermore, no attempt has ever been made to apply refinement methods to data improvement for downstream NLP tasks in real-world scenarios.This paper presents a novel query refinement approach for the Japanese language. Experimental results show that our method achieves significant improvement by 3.5 points through comparison with BERT-CRF as a baseline. Further experiments are also conducted to measure beneficial impact of query refinement on named entity recognition (NER) as the downstream task. Evaluations indicate that the proposed query refinement method contributes to better data quality, leading to performance boost on E-Commerce specific NER tasks by 11.7 points, compared to search query data preprocessed by MeCab, a very popularly adopted Japanese tokenizer. | Yuki Nakayama, Ryutaro Tatsushima, Erick Mendieta, Koji Murakami, Keiji Shinzato |  |
| 91 |  |  [EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal LLM](https://doi.org/10.18653/v1/2024.naacl-industry.40) |  | 0 | In e-commerce, accurately extracting product attribute values from multimodal data is crucial for improving user experience and operational efficiency of retailers. However, previous approaches to multimodal attribute value extraction often struggle with implicit attribute values embedded in images or text, rely heavily on extensive labeled data, and can easily confuse similar attribute values. To address these issues, we introduce EIVEN, a data- and parameter-efficient generative framework that pioneers the use of multimodal LLM for implicit attribute value extraction. EIVEN leverages the rich inherent knowledge of a pre-trained LLM and vision encoder to reduce reliance on labeled data. We also introduce a novel Learning-by-Comparison technique to reduce model confusion by enforcing attribute value comparison and difference identification. Additionally, we construct initial open-source datasets for multimodal implicit attribute value extraction. Our extensive experiments reveal that EIVEN significantly outperforms existing methods in extracting implicit attribute values while requiring less labeled data. | Henry Peng Zou, Gavin Heqing Yu, Ziwei Fan, Dan Bu, Han Liu, Peng Dai, Dongmei Jia, Cornelia Caragea |  |
| 92 |  |  [Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data](https://doi.org/10.18653/v1/2024.naacl-industry.41) |  | 0 | Augmenting Large Language Models (LLMs) for Question Answering (QA) with domain specific data has attracted wide attention. However, domain data often exists in a hybrid format, including text and semi-structured tables, posing challenges for the seamless integration of information. Table-to-Text Generation is a promising solution by facilitating the transformation of hybrid data into a uniformly text-formatted corpus. Although this technique has been widely studied by the NLP community, there is currently no comparative analysis on how corpora generated by different table-to-text methods affect the performance of QA systems.In this paper, we address this research gap in two steps. First, we innovatively integrate table-to-text generation into the framework of enhancing LLM-based QA systems with domain hybrid data. Then, we utilize this framework in real-world industrial data to conduct extensive experiments on two types of QA systems (DSFT and RAG frameworks) with four representative methods: Markdown format, Template serialization, TPLM-based method, and LLM-based method. Based on the experimental results, we draw some empirical findings and explore the underlying reasons behind the success of some methods. We hope the findings of this work will provide a valuable reference for the academic and industrial communities in developing robust QA systems. | Dehai Min, Nan Hu, Rihui Jin, Nuo Lin, Jiaoyan Chen, Yongrui Chen, Yu Li, Guilin Qi, Yun Li, Nijun Li, Qianren Wang |  |
| 93 |  |  [Solving General Natural-Language-Description Optimization Problems with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-industry.42) |  | 0 | Optimization problems seek to find the best solution to an objective under a set of constraints, and have been widely investigated in real-world applications. Modeling and solving optimization problems in a specific domain typically require a combination of domain knowledge, mathematical skills, and programming ability, making it difficult for general users and even domain professionals. In this paper, we propose a novel framework called OptLLM that augments LLMs with external solvers. Specifically, OptLLM accepts user queries in natural language, convert them into mathematical formulations and programming codes, and calls the solvers to calculate the results for decision-making. In addition, OptLLM supports multi-round dialogues to gradually refine the modeling and solving of optimization problems. To illustrate the effectiveness of OptLLM, we provide tutorials on three typical optimization applications and conduct experiments on both prompt-based GPT models and a fine-tuned Qwen model using a large-scale self-developed optimization dataset. Experimental results show that OptLLM works with various LLMs, and the fine-tuned model achieves an accuracy boost compared to the prompt-based models. Some features of OptLLM framework have been available for trial since June 2023 (https://opt.alibabacloud.com/chat or https://opt.aliyun.com/chat). | Jihai Zhang, Wei Wang, Siyan Guo, Li Wang, Fangquan Lin, Cheng Yang, Wotao Yin |  |
| 94 |  |  [Self-Regulated Data-Free Knowledge Amalgamation for Text Classification](https://doi.org/10.18653/v1/2024.naacl-industry.43) |  | 0 | Recently, there has been a growing availability of pre-trained text models on various model repositories. These models greatly reduce the cost of training new models from scratch as they can be fine-tuned for specific tasks or trained on large datasets. However, these datasets may not be publicly accessible due to the privacy, security, or intellectual property issues. In this paper, we aim to develop a lightweight student network that can learn from multiple teacher models without accessing their original training data. Hence, we investigate Data-Free Knowledge Amalgamation (DFKA), a knowledge-transfer task that combines insights from multiple pre-trained teacher models and transfers them effectively to a compact student network. To accomplish this, we propose STRATANET, a modeling framework comprising: (a) a steerable data generator that produces text data tailored to each teacher and (b) an amalgamation module that implements a self-regulative strategy using confidence estimates from the teachers’ different layers to selectively integrate their knowledge and train a versatile student. We evaluate our method on three benchmark text classification datasets with varying labels or domains. Empirically, we demonstrate that the student model learned using our STRATANET outperforms several baselines significantly under data-driven and data-free constraints. | Prashanth Vijayaraghavan, Hongzhi Wang, Luyao Shi, Tyler Baldwin, David Beymer, Ehsan Degan |  |
| 95 |  |  [Frontmatter](https://aclanthology.org/2024.naacl-long.0) |  | 0 |  |  |  |
| 96 |  |  [Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences](https://doi.org/10.18653/v1/2024.naacl-long.1) |  | 0 | Named entity recognition is a key component of Information Extraction (IE), particularly in scientific domains such as biomedicine and chemistry, where large language models (LLMs), e.g., ChatGPT, fall short. We investigate the applicability of transfer learning for enhancing a named entity recognition model trained in the biomedical domain (the source domain) to be used in the chemical domain (the target domain). A common practice for training such a model in a few-shot learning setting is to pretrain the model on the labeled source data, and then, to finetune it on a hand-full of labeled target examples. In our experiments, we observed that such a model is prone to mislabeling the source entities, which can often appear in the text, as the target entities. To alleviate this problem, we propose a model to transfer the knowledge from the source domain to the target domain, but, at the same time, to project the source entities and target entities into separate regions of the feature space. This diminishes the risk of mislabeling the source entities as the target entities. Our model consists of two stages: 1) entity grouping in the source domain, which incorporates knowledge from annotated events to establish relations between entities, and 2) entity discrimination in the target domain, which relies on pseudo labeling and contrastive learning to enhance discrimination between the entities in the two domains. We conduct our extensive experiments across three source and three target datasets, demonstrating that our method outperforms the baselines by up to 5% absolute value. Code, data, and resources are publicly available for research purposes: https://github.com/Lhtie/Bio-Domain-Transfer . | Hongyi Liu, Qingyun Wang, Payam Karisani, Heng Ji |  |
| 97 |  |  [Text Diffusion Model with Encoder-Decoder Transformers for Sequence-to-Sequence Generation](https://doi.org/10.18653/v1/2024.naacl-long.2) |  | 0 | The diffusion model, a new generative modeling paradigm, has achieved great success in image, audio, and video generation.However, considering the discrete categorical nature of the text, it is not trivial to extend continuous diffusion models to natural language. In this work, we propose SeqDiffuSeq, a text diffusion model, to approach sequence-to-sequence text generation with an encoder-decoder Transformer architecture.To improve the generation performance, SeqDiffuSeq is equipped with the self-conditioning technique and our newly proposed adaptive noise schedule technique. Self-conditioning enables SeqDiffuSeq to better use the predicted sequence information during the generation process.The adaptive noise schedule balances the difficulty of denoising across time steps at the token level.Experiment results illustrate the improved performance on five sequence-to-sequence generation tasks compared to other diffusion-based models regarding text quality and inference time. | Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, Songfang Huang |  |
| 98 |  |  [An Interactive Framework for Profiling News Media Sources](https://doi.org/10.18653/v1/2024.naacl-long.3) |  | 0 | The recent rise of social media has led to the spread of large amounts of fake and biased news, content published with the intent to sway beliefs. While detecting and profiling the sources that spread this news is important to maintain a healthy society, it is challenging for automated systems.In this paper, we propose an interactive framework for news media profiling. It combines the strengths of graph based news media profiling models, Pre-trained Large Language Models, and human insight to characterize the social context on social media. Experimental results show that with as little as 5 human interactions, our framework can rapidly detect fake and biased news media, even in the most challenging settings of emerging news events, where test data is unseen. | Nikhil Mehta, Dan Goldwasser |  |
| 99 |  |  [Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study](https://doi.org/10.18653/v1/2024.naacl-long.4) |  | 0 | Large Language Models (LLMs) have shown remarkable proficiency in language understanding and have been successfully applied to a variety of real-world tasks through task-specific fine-tuning or prompt engineering. Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data. In our research, we introduce a novel task—Minesweeper—specifically designed in a format unfamiliar to LLMs and absent from their training datasets. This task challenges LLMs to identify the locations of mines based on numerical clues provided by adjacent opened cells. Successfully completing this task requires an understanding of each cell’s state, discerning spatial relationships between the clues and mines, and strategizing actions based on logical deductions drawn from the arrangement of the cells. Our experiments, including trials with the advanced GPT-4 model, indicate that while LLMs possess the foundational abilities required for this task, they struggle to integrate these into a coherent, multi-step logical reasoning process needed to solve Minesweeper. These findings highlight the need for further research to understand the nature of reasoning capabilities in LLMs under similar circumstances, and to explore pathways towards more sophisticated AI reasoning and planning models. | Yinghao Li, Haorui Wang, Chao Zhang |  |
| 100 |  |  [TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation](https://doi.org/10.18653/v1/2024.naacl-long.5) |  | 0 | Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue sys- tems to effectively respond to user requests. The emotions in a conversation can be identi- fied by the representations from various modal- ities, such as audio, visual, and text. How- ever, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a lan- guage model acting as the teacher to the non- verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multi- modal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effec- tiveness of our components through additional experiments. | Taeyang Yun, Hyunkuk Lim, Jeonghwan Lee, Min Song |  |
| 101 |  |  [Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries](https://doi.org/10.18653/v1/2024.naacl-long.6) |  | 0 |  | Seanie Lee, Jianpeng Cheng, Joris Driesen, Alexandru Coca, Anders Johannsen |  |
| 102 |  |  [Promptly Predicting Structures: The Return of Inference](https://doi.org/10.18653/v1/2024.naacl-long.7) |  | 0 |  | Maitrey Mehta, Valentina Pyatkin, Vivek Srikumar |  |
| 103 |  |  [On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL](https://doi.org/10.18653/v1/2024.naacl-long.8) |  | 0 |  | Yutong Shao, Ndapa Nakashole |  |
| 104 |  |  [Extractive Summarization with Text Generator](https://doi.org/10.18653/v1/2024.naacl-long.9) |  | 0 |  | Thang Le, Anh Tuan Luu |  |
| 105 |  |  [Self-generated Replay Memories for Continual Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.10) |  | 0 |  | Michele Resta, Davide Bacciu |  |
| 106 |  |  [Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models](https://doi.org/10.18653/v1/2024.naacl-long.11) |  | 0 |  | Yangyi Chen, Karan Sikka, Michael Cogswell, Heng Ji, Ajay Divakaran |  |
| 107 |  |  [Building Knowledge-Guided Lexica to Model Cultural Variation](https://doi.org/10.18653/v1/2024.naacl-long.12) |  | 0 |  | Shreya Havaldar, Salvatore Giorgi, Sunny Rai, Thomas Talhelm, Sharath Chandra Guntuku, Lyle H. Ungar |  |
| 108 |  |  [Adaptive Rank Selections for Low-Rank Approximation of Language Models](https://doi.org/10.18653/v1/2024.naacl-long.13) |  | 0 |  | Shangqian Gao, Ting Hua, YenChang Hsu, Yilin Shen, Hongxia Jin |  |
| 109 |  |  [An Empirical Study of Consistency Regularization for End-to-End Speech-to-Text Translation](https://doi.org/10.18653/v1/2024.naacl-long.14) |  | 0 |  | Pengzhi Gao, Ruiqing Zhang, Zhongjun He, Hua Wu, Haifeng Wang |  |
| 110 |  |  [Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration](https://doi.org/10.18653/v1/2024.naacl-long.15) |  | 0 |  | Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, Heng Ji |  |
| 111 |  |  [FPT: Feature Prompt Tuning for Few-shot Readability Assessment](https://doi.org/10.18653/v1/2024.naacl-long.16) |  | 0 |  | Ziyang Wang, Sanwoo Lee, HsiuYuan Huang, Yunfang Wu |  |
| 112 |  |  [Self-Prompting Large Language Models for Zero-Shot Open-Domain QA](https://doi.org/10.18653/v1/2024.naacl-long.17) |  | 0 |  | Junlong Li, Jinyuan Wang, Zhuosheng Zhang, Hai Zhao |  |
| 113 |  |  [Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?](https://doi.org/10.18653/v1/2024.naacl-long.18) |  | 0 |  | Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, Xin Luna Dong |  |
| 114 |  |  [kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.19) |  | 0 |  | Wenting Zhao, Ye Liu, Yao Wan, Yibo Wang, Qingyang Wu, Zhongfen Deng, Jiangshu Du, Shuaiqi Liu, Yunlong Xu, Philip S. Yu |  |
| 115 |  |  [ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems](https://doi.org/10.18653/v1/2024.naacl-long.20) |  | 0 |  | Jon SaadFalcon, Omar Khattab, Christopher Potts, Matei Zaharia |  |
| 116 |  |  [DEMO: A Statistical Perspective for Efficient Image-Text Matching](https://doi.org/10.18653/v1/2024.naacl-long.21) |  | 0 |  | Fan Zhang, XianSheng Hua, Chong Chen, Xiao Luo |  |
| 117 |  |  [SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.22) |  | 0 |  | Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, AiTi Aw, Nancy F. Chen |  |
| 118 |  |  [Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision](https://doi.org/10.18653/v1/2024.naacl-long.23) |  | 0 |  | Seongyun Lee, Sue Hyun Park, Yongrae Jo, Minjoon Seo |  |
| 119 |  |  [LLMs Are Few-Shot In-Context Low-Resource Language Learners](https://doi.org/10.18653/v1/2024.naacl-long.24) |  | 0 |  | Samuel Cahyawijaya, Holy Lovenia, Pascale Fung |  |
| 120 |  |  [Simple and effective data augmentation for compositional generalization](https://doi.org/10.18653/v1/2024.naacl-long.25) |  | 0 |  | Yuekun Yao, Alexander Koller |  |
| 121 |  |  [Rethinking Tabular Data Understanding with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.26) |  | 0 |  | Tianyang Liu, Fei Wang, Muhao Chen |  |
| 122 |  |  [From Shortcuts to Triggers: Backdoor Defense with Denoised PoE](https://doi.org/10.18653/v1/2024.naacl-long.27) |  | 0 |  | Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen |  |
| 123 |  |  [BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain](https://doi.org/10.18653/v1/2024.naacl-long.28) |  | 0 |  | Rahul Kumar, Amar Raja Dibbu, Shrutendra Harsola, Vignesh Subrahmaniam, Ashutosh Modi |  |
| 124 |  |  [FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs](https://doi.org/10.18653/v1/2024.naacl-long.29) |  | 0 |  | Shamik Roy, Sailik Sengupta, Daniele Bonadiman, Saab Mansour, Arshit Gupta |  |
| 125 |  |  [DuRE: Dual Contrastive Self Training for Semi-Supervised Relation Extraction](https://doi.org/10.18653/v1/2024.naacl-long.30) |  | 0 |  | Yuxi Feng, Laks V. S. Lakshmanan |  |
| 126 |  |  [Query-Efficient Textual Adversarial Example Generation for Black-Box Attacks](https://doi.org/10.18653/v1/2024.naacl-long.31) |  | 0 |  | Zhen Yu, Zhenhua Chen, Kun He |  |
| 127 |  |  [Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles](https://doi.org/10.18653/v1/2024.naacl-long.32) |  | 0 |  | KungHsiang Huang, Philippe Laban, Alexander R. Fabbri, Prafulla Kumar Choubey, Shafiq Joty, Caiming Xiong, ChienSheng Wu |  |
| 128 |  |  [AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation](https://doi.org/10.18653/v1/2024.naacl-long.33) |  | 0 |  | Haoyi Qiu, KungHsiang Huang, Jingnong Qu, Nanyun Peng |  |
| 129 |  |  [PILOT: Legal Case Outcome Prediction with Case Law](https://doi.org/10.18653/v1/2024.naacl-long.34) |  | 0 |  | Lang Cao, Zifeng Wang, Cao Xiao, Jimeng Sun |  |
| 130 |  |  [ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.35) |  | 0 |  | Zequan Liu, Jiawen Lyn, Wei Zhu, Xing Tian, Yvette Graham |  |
| 131 |  |  [R-Spin: Efficient Speaker and Noise-invariant Representation Learning with Acoustic Pieces](https://doi.org/10.18653/v1/2024.naacl-long.36) |  | 0 |  | HengJui Chang, James R. Glass |  |
| 132 |  |  [InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions](https://doi.org/10.18653/v1/2024.naacl-long.37) |  | 0 |  | Yifan Wang, Yafei Liu, Chufan Shi, Haoling Li, Chen Chen, Haonan Lu, Yujiu Yang |  |
| 133 |  |  [Language Agnostic Code Embeddings](https://doi.org/10.18653/v1/2024.naacl-long.38) |  | 0 |  | Saiteja Utpala, Alex Gu, PinYu Chen |  |
| 134 |  |  [An Examination of the Compositionality of Large Generative Vision-Language Models](https://doi.org/10.18653/v1/2024.naacl-long.39) |  | 0 |  | Teli Ma, Rong Li, Junwei Liang |  |
| 135 |  |  [Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors](https://doi.org/10.18653/v1/2024.naacl-long.40) |  | 0 |  | Victoria Graf, Qin Liu, Muhao Chen |  |
| 136 |  |  [VertAttack: Taking Advantage of Text Classifiers' Horizontal Vision](https://doi.org/10.18653/v1/2024.naacl-long.41) |  | 0 |  | Jonathan Rusert |  |
| 137 |  |  [KDMCSE: Knowledge Distillation Multimodal Sentence Embeddings with Adaptive Angular margin Contrastive Learning](https://doi.org/10.18653/v1/2024.naacl-long.42) |  | 0 |  | CongDuy Nguyen, Thong Nguyen, Xiaobao Wu, Anh Tuan Luu |  |
| 138 |  |  [The taste of IPA: Towards open-vocabulary keyword spotting and forced alignment in any language](https://doi.org/10.18653/v1/2024.naacl-long.43) |  | 0 |  | Jian Zhu, Changbing Yang, Farhan Samir, Jahurul Islam |  |
| 139 |  |  [Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias Towards Vision-Language Tasks](https://doi.org/10.18653/v1/2024.naacl-long.44) |  | 0 |  | Yunqi Zhang, Songda Li, Chunyuan Deng, Luyi Wang, Hui Zhao |  |
| 140 |  |  [BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings](https://doi.org/10.18653/v1/2024.naacl-long.45) |  | 0 |  | Xianming Li, Jing Li |  |
| 141 |  |  [Assessing Factual Reliability of Large Language Model Knowledge](https://doi.org/10.18653/v1/2024.naacl-long.46) |  | 0 |  | Weixuan Wang, Barry Haddow, Alexandra Birch, Wei Peng |  |
| 142 |  |  [Dial-MAE: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems](https://doi.org/10.18653/v1/2024.naacl-long.47) |  | 0 |  | Zhenpeng Su, Xing Wu, Wei Zhou, Guangyuan Ma, Songlin Hu |  |
| 143 |  |  [Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model](https://doi.org/10.18653/v1/2024.naacl-long.48) |  | 0 |  | Cheng Qian, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu |  |
| 144 |  |  [Create! Don't Repeat: A Paradigm Shift in Multi-Label Augmentation through Label Creative Generation](https://doi.org/10.18653/v1/2024.naacl-long.49) |  | 0 |  | Letian Wang, Xianggen Liu, Jiancheng Lv |  |
| 145 |  |  [Neurocache: Efficient Vector Retrieval for Long-range Language Modeling](https://doi.org/10.18653/v1/2024.naacl-long.50) |  | 0 |  | Ali Safaya, Deniz Yuret |  |
| 146 |  |  [Unveiling the Generalization Power of Fine-Tuned Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.51) |  | 0 |  | Haoran Yang, Yumeng Zhang, Jiaqi Xu, Hongyuan Lu, PhengAnn Heng, Wai Lam |  |
| 147 |  |  [A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.52) |  | 0 |  | Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang |  |
| 148 |  |  [Exploring Self-supervised Logic-enhanced Training for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.53) |  | 0 |  | Fangkai Jiao, Zhiyang Teng, Bosheng Ding, Zhengyuan Liu, Nancy F. Chen, Shafiq Joty |  |
| 149 |  |  [MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.54) |  | 0 |  | Debrup Das, Debopriyo Banerjee, Somak Aditya, Ashish Kulkarni |  |
| 150 |  |  [CoUDA: Coherence Evaluation via Unified Data Augmentation](https://doi.org/10.18653/v1/2024.naacl-long.55) |  | 0 |  | Dawei Zhu, Wenhao Wu, Yifan Song, Fangwei Zhu, Ziqiang Cao, Sujian Li |  |
| 151 |  |  [mEdIT: Multilingual Text Editing via Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.56) |  | 0 |  | Vipul Raheja, Dimitris Alikaniotis, Vivek Kulkarni, Bashar Alhafni, Dhruv Kumar |  |
| 152 |  |  [Navigation as Attackers Wish? Towards Building Robust Embodied Agents under Federated Learning](https://doi.org/10.18653/v1/2024.naacl-long.57) |  | 0 |  | Yunchao Zhang, Zonglin Di, Kaiwen Zhou, Cihang Xie, Xin Wang |  |
| 153 |  |  [In-context Learning and Gradient Descent Revisited](https://doi.org/10.18653/v1/2024.naacl-long.58) |  | 0 |  | Gilad Deutch, Nadav Magar, Tomer Bar Natan, Guy Dar |  |
| 154 |  |  [Corpus Considerations for Annotator Modeling and Scaling](https://doi.org/10.18653/v1/2024.naacl-long.59) |  | 0 |  | Olufunke Oluyemi Sarumi, Béla Neuendorf, Joan Plepi, Lucie Flek, Jörg Schlötterer, Charles Welch |  |
| 155 |  |  [On Large Language Models' Hallucination with Regard to Known Facts](https://doi.org/10.18653/v1/2024.naacl-long.60) |  | 0 |  | Che Jiang, Biqing Qi, Xiangyu Hong, Dayuan Fu, Yang Cheng, Fandong Meng, Mo Yu, Bowen Zhou, Jie Zhou |  |
| 156 |  |  ["One-Size-Fits-All"? Examining Expectations around What Constitute "Fair" or "Good" NLG System Behaviors](https://doi.org/10.18653/v1/2024.naacl-long.61) |  | 0 |  | Li Lucy, Su Lin Blodgett, Milad Shokouhi, Hanna M. Wallach, Alexandra Olteanu |  |
| 157 |  |  [Language Models Hallucinate, but May Excel at Fact Verification](https://doi.org/10.18653/v1/2024.naacl-long.62) |  | 0 |  | Jian Guan, Jesse Dodge, David Wadden, Minlie Huang, Hao Peng |  |
| 158 |  |  [A Rationale-centric Counterfactual Data Augmentation Method for Cross-Document Event Coreference Resolution](https://doi.org/10.18653/v1/2024.naacl-long.63) |  | 0 |  | Bowen Ding, Qingkai Min, Shengkun Ma, Yingjie Li, Linyi Yang, Yue Zhang |  |
| 159 |  |  [TrojFSP: Trojan Insertion in Few-shot Prompt Tuning](https://doi.org/10.18653/v1/2024.naacl-long.64) |  | 0 |  | Mengxin Zheng, Jiaqi Xue, Xun Chen, Yanshan Wang, Qian Lou, Lei Jiang |  |
| 160 |  |  [Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models](https://doi.org/10.18653/v1/2024.naacl-long.65) |  | 0 |  | Yi Luo, Zhenghao Lin, Yuhao Zhang, Jiashuo Sun, Chen Lin, Chengjin Xu, Xiangdong Su, Yelong Shen, Jian Guo, Yeyun Gong |  |
| 161 |  |  [X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs](https://doi.org/10.18653/v1/2024.naacl-long.66) |  | 0 |  | Juan Diego Rodriguez, Katrin Erk, Greg Durrett |  |
| 162 |  |  [Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers](https://doi.org/10.18653/v1/2024.naacl-long.67) |  | 0 |  | Rajiv Movva, Sidhika Balachandar, Kenny Peng, Gabriel Agostini, Nikhil Garg, Emma Pierson |  |
| 163 |  |  [E⁵: Zero-shot Hierarchical Table Analysis using Augmented LLMs via Explain, Extract, Execute, Exhibit and Extrapolate](https://doi.org/10.18653/v1/2024.naacl-long.68) |  | 0 |  | Zhehao Zhang, Yan Gao, JianGuang Lou |  |
| 164 |  |  [S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model](https://doi.org/10.18653/v1/2024.naacl-long.69) |  | 0 |  | Fangyu Lei, Qian Liu, Yiming Huang, Shizhu He, Jun Zhao, Kang Liu |  |
| 165 |  |  [MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.70) |  | 0 |  | Fuxiao Liu, Xiaoyang Wang, Wenlin Yao, Jianshu Chen, Kaiqiang Song, Sangwoo Cho, Yaser Yacoob, Dong Yu |  |
| 166 |  |  [Visual Grounding Helps Learn Word Meanings in Low-Data Regimes](https://doi.org/10.18653/v1/2024.naacl-long.71) |  | 0 |  | Chengxu Zhuang, Evelina Fedorenko, Jacob Andreas |  |
| 167 |  |  [Accurate Knowledge Distillation via n-best Reranking](https://doi.org/10.18653/v1/2024.naacl-long.72) |  | 0 |  | Hendra Setiawan |  |
| 168 |  |  [AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition](https://doi.org/10.18653/v1/2024.naacl-long.73) |  | 0 |  | Zhaorun Chen, Zhuokai Zhao, Zhihong Zhu, Ruiqi Zhang, Xiang Li, Bhiksha Raj, Huaxiu Yao |  |
| 169 |  |  [SEMQA: Semi-Extractive Multi-Source Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.74) |  | 0 |  | Tal Schuster, Ádám D. Lelkes, Haitian Sun, Jai Gupta, Jonathan Berant, William W. Cohen, Donald Metzler |  |
| 170 |  |  [Fine-Tuning Language Models with Reward Learning on Policy](https://doi.org/10.18653/v1/2024.naacl-long.75) |  | 0 |  | Hao Lang, Fei Huang, Yongbin Li |  |
| 171 |  |  [A Universal Dependencies Treebank for Highland Puebla Nahuatl](https://doi.org/10.18653/v1/2024.naacl-long.76) |  | 0 |  | Robert Pugh, Francis M. Tyers |  |
| 172 |  |  [COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances](https://doi.org/10.18653/v1/2024.naacl-long.77) |  | 0 |  | Haryo Akbarianto Wibowo, Erland Hilman Fuadi, Made Nindyatama Nityasya, Radityo Eko Prasojo, Alham Fikri Aji |  |
| 173 |  |  [IterAlign: Iterative Constitutional Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.78) |  | 0 |  | Xiusi Chen, Hongzhi Wen, Sreyashi Nag, Chen Luo, Qingyu Yin, Ruirui Li, Zheng Li, Wei Wang |  |
| 174 |  |  [OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking](https://doi.org/10.18653/v1/2024.naacl-long.79) |  | 0 |  | ChiaHsuan Lee, Hao Cheng, Mari Ostendorf |  |
| 175 |  |  [Multi-Operational Mathematical Derivations in Latent Space](https://doi.org/10.18653/v1/2024.naacl-long.80) |  | 0 |  | Marco Valentino, Jordan Meadows, Lan Zhang, André Freitas |  |
| 176 |  |  [Large Language Models Help Humans Verify Truthfulness - Except When They Are Convincingly Wrong](https://doi.org/10.18653/v1/2024.naacl-long.81) |  | 0 |  | Chenglei Si, Navita Goyal, Tongshuang Wu, Chen Zhao, Shi Feng, Hal Daumé III, Jordan L. BoydGraber |  |
| 177 |  |  [XferBench: a Data-Driven Benchmark for Emergent Language](https://doi.org/10.18653/v1/2024.naacl-long.82) |  | 0 |  | Brendon Boldt, David R. Mortensen |  |
| 178 |  |  [Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation](https://doi.org/10.18653/v1/2024.naacl-long.83) |  | 0 |  | Seeun Yoon, Zhankui He, Jessica Maria Echterhoff, Julian J. McAuley |  |
| 179 |  |  [A Symbolic Framework for Evaluating Mathematical Reasoning and Generalisation with Transformers](https://doi.org/10.18653/v1/2024.naacl-long.84) |  | 0 |  | Jordan Meadows, Marco Valentino, Damien Teney, André Freitas |  |
| 180 |  |  [Identifying Linear Relational Concepts in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.85) |  | 0 |  | David Chanin, Anthony Hunter, OanaMaria Camburu |  |
| 181 |  |  [Benchmark Transparency: Measuring the Impact of Data on Evaluation](https://doi.org/10.18653/v1/2024.naacl-long.86) |  | 0 |  | Venelin Kovatchev, Matthew Lease |  |
| 182 |  |  [JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models](https://doi.org/10.18653/v1/2024.naacl-long.87) |  | 0 |  | Jillian Fisher, Ximing Lu, Jaehun Jung, Liwei Jiang, Zaïd Harchaoui, Yejin Choi |  |
| 183 |  |  [REST: Retrieval-Based Speculative Decoding](https://doi.org/10.18653/v1/2024.naacl-long.88) |  | 0 |  | Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D. Lee, Di He |  |
| 184 |  |  [Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic Representations](https://doi.org/10.18653/v1/2024.naacl-long.89) |  | 0 |  | Sihao Chen, Hongming Zhang, Tong Chen, Ben Zhou, Wenhao Yu, Dian Yu, Baolin Peng, Hongwei Wang, Dan Roth, Dong Yu |  |
| 185 |  |  [MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference](https://doi.org/10.18653/v1/2024.naacl-long.90) |  | 0 |  | Mobashir Sadat, Cornelia Caragea |  |
| 186 |  |  [Causal Inference for Human-Language Model Collaboration](https://doi.org/10.18653/v1/2024.naacl-long.91) |  | 0 |  | Bohan Zhang, Yixin Wang, Paramveer Dhillon |  |
| 187 |  |  [SELF-GUARD: Empower the LLM to Safeguard Itself](https://doi.org/10.18653/v1/2024.naacl-long.92) |  | 0 |  | Zezhong Wang, Fangkai Yang, Lu Wang, Pu Zhao, Hongru Wang, Liang Chen, Qingwei Lin, KamFai Wong |  |
| 188 |  |  [COSIGN: Contextual Facts Guided Generation for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.naacl-long.93) |  | 0 |  | Jinpeng Li, Hang Yu, Xiangfeng Luo, Qian Liu |  |
| 189 |  |  [Toward Informal Language Processing: Knowledge of Slang in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.94) |  | 0 |  | Zhewei Sun, Qian Hu, Rahul Gupta, Richard S. Zemel, Yang Xu |  |
| 190 |  |  [Ghostbuster: Detecting Text Ghostwritten by Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.95) |  | 0 |  | Vivek Verma, Eve Fleisig, Nicholas Tomlin, Dan Klein |  |
| 191 |  |  [End-to-End Beam Retrieval for Multi-Hop Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.96) |  | 0 |  | Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, Shen Huang |  |
| 192 |  |  [Leveraging Generative Large Language Models with Visual Instruction and Demonstration Retrieval for Multimodal Sarcasm Detection](https://doi.org/10.18653/v1/2024.naacl-long.97) |  | 0 |  | Binghao Tang, Boda Lin, Haolong Yan, Si Li |  |
| 193 |  |  [Multi-Scale Prompt Memory-Augmented Model for Black-Box Scenarios](https://doi.org/10.18653/v1/2024.naacl-long.98) |  | 0 |  | Xiaojun Kuang, C. L. Philip Chen, Shuzhen Li, Tong Zhang |  |
| 194 |  |  [Ungrammatical-syntax-based In-context Example Selection for Grammatical Error Correction](https://doi.org/10.18653/v1/2024.naacl-long.99) |  | 0 |  | Chenming Tang, Fanyi Qu, Yunfang Wu |  |
| 195 |  |  [BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer](https://doi.org/10.18653/v1/2024.naacl-long.100) |  | 0 |  | Akari Asai, Sneha Kudugunta, Xinyan Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, Hannaneh Hajishirzi |  |
| 196 |  |  [TISE: A Tripartite In-context Selection Method for Event Argument Extraction](https://doi.org/10.18653/v1/2024.naacl-long.101) |  | 0 |  | Yanhe Fu, Yanan Cao, Qingyue Wang, Yi Liu |  |
| 197 |  |  [Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks](https://doi.org/10.18653/v1/2024.naacl-long.102) |  | 0 |  | Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyürek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, Yoon Kim |  |
| 198 |  |  [TRUE-UIE: Two Universal Relations Unify Information Extraction Tasks](https://doi.org/10.18653/v1/2024.naacl-long.103) |  | 0 |  | Yucheng Wang, Bowen Yu, Yilin Liu, Shudong Lu |  |
| 199 |  |  [zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.104) |  | 0 |  | Zifeng Ding, Heling Cai, Jingpei Wu, Yunpu Ma, Ruotong Liao, Bo Xiong, Volker Tresp |  |
| 200 |  |  [Embodied Executable Policy Learning with Language-based Scene Summarization](https://doi.org/10.18653/v1/2024.naacl-long.105) |  | 0 |  | Jielin Qiu, Mengdi Xu, William Han, Seungwhan Moon, Ding Zhao |  |
| 201 |  |  [Metacognitive Prompting Improves Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.106) |  | 0 |  | Yuqing Wang, Yun Zhao |  |
| 202 |  |  [MART: Improving LLM Safety with Multi-round Automatic Red-Teaming](https://doi.org/10.18653/v1/2024.naacl-long.107) |  | 0 |  | Suyu Ge, Chunting Zhou, Rui Hou, Madian Khabsa, YiChia Wang, Qifan Wang, Jiawei Han, Yuning Mao |  |
| 203 |  |  [DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset](https://doi.org/10.18653/v1/2024.naacl-long.108) |  | 0 |  | YoungJun Lee, Byungsoo Ko, HanGyu Kim, Jonghwan Hyeon, HoJin Choi |  |
| 204 |  |  [Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.109) |  | 0 |  | Keming Lu, Hongyi Yuan, Runji Lin, Junyang Lin, Zheng Yuan, Chang Zhou, Jingren Zhou |  |
| 205 |  |  [Automatic Generation of Model and Data Cards: A Step Towards Responsible AI](https://doi.org/10.18653/v1/2024.naacl-long.110) |  | 0 |  | Jiarui Liu, Wenkai Li, Zhijing Jin, Mona T. Diab |  |
| 206 |  |  [FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual Transfer with Scheduled Unfreezing](https://doi.org/10.18653/v1/2024.naacl-long.111) |  | 0 |  | Chen Liu, Jonas Pfeiffer, Ivan Vulic, Iryna Gurevych |  |
| 207 |  |  [Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings](https://doi.org/10.18653/v1/2024.naacl-long.112) |  | 0 |  | Chen Liu, Fajri Koto, Timothy Baldwin, Iryna Gurevych |  |
| 208 |  |  [The Colorful Future of LLMs: Evaluating and Improving LLMs as Emotional Supporters for Queer Youth](https://doi.org/10.18653/v1/2024.naacl-long.113) |  | 0 |  | Shir Lissak, Nitay Calderon, Geva Shenkman, Yaakov Ophir, Eyal Fruchter, Anat Brunstein Klomek, Roi Reichart |  |
| 209 |  |  [IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model](https://doi.org/10.18653/v1/2024.naacl-long.114) |  | 0 |  | Jianli Zhao, Changhao Xu, Bin Jiang |  |
| 210 |  |  [QualEval: Qualitative Evaluation for Model Improvement](https://doi.org/10.18653/v1/2024.naacl-long.115) |  | 0 |  | Vishvak Murahari, Ameet Deshpande, Peter Clark, Tanmay Rajpurohit, Ashish Sabharwal, Karthik Narasimhan, Ashwin Kalyan |  |
| 211 |  |  [Quantum-inspired Language Model with Lindblad Master Equation and Interference Measurement for Sentiment Analysis](https://doi.org/10.18653/v1/2024.naacl-long.116) |  | 0 |  | Kehuan Yan, Peichao Lai, Yilei Wang |  |
| 212 |  |  [VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization](https://doi.org/10.18653/v1/2024.naacl-long.117) |  | 0 |  | Dongsheng Zhu, Daniel Tang, Weidong Han, Jinghui Lu, Yukun Zhao, Guoliang Xing, Junfeng Wang, Dawei Yin |  |
| 213 |  |  [A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily](https://doi.org/10.18653/v1/2024.naacl-long.118) |  | 0 |  | Peng Ding, Jun Kuang, Dan Ma, Xuezhi Cao, Yunsen Xian, Jiajun Chen, Shujian Huang |  |
| 214 |  |  [P³Sum: Preserving Author's Perspective in News Summarization with Diffusion Language Models](https://doi.org/10.18653/v1/2024.naacl-long.119) |  | 0 |  | Yuhan Liu, Shangbin Feng, Xiaochuang Han, Vidhisha Balachandran, Chan Young Park, Sachin Kumar, Yulia Tsvetkov |  |
| 215 |  |  [Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes](https://doi.org/10.18653/v1/2024.naacl-long.120) |  | 0 |  | Rose E. Wang, Qingyang Zhang, Carly Robinson, Susanna Loeb, Dorottya Demszky |  |
| 216 |  |  [RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization](https://doi.org/10.18653/v1/2024.naacl-long.121) |  | 0 |  | Dongqi Liu, Vera Demberg |  |
| 217 |  |  [Strings from the Library of Babel: Random Sampling as a Strong Baseline for Prompt Optimisation](https://doi.org/10.18653/v1/2024.naacl-long.122) |  | 0 |  | Yao Lu, Jiayi Wang, Raphael Tang, Sebastian Riedel, Pontus Stenetorp |  |
| 218 |  |  [ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.123) |  | 0 |  | Jinhao Duan, Shiqi Wang, James Diffenderfer, Lichao Sun, Tianlong Chen, Bhavya Kailkhura, Kaidi Xu |  |
| 219 |  |  [Fact Checking Beyond Training Set](https://doi.org/10.18653/v1/2024.naacl-long.124) |  | 0 |  | Payam Karisani, Heng Ji |  |
| 220 |  |  [Program-Aided Reasoners (Better) Know What They Know](https://doi.org/10.18653/v1/2024.naacl-long.125) |  | 0 |  | Anubha Kabra, Sanketh Rangreji, Yash Mathur, Aman Madaan, Emmy Liu, Graham Neubig |  |
| 221 |  |  [The Perspectivist Paradigm Shift: Assumptions and Challenges of Capturing Human Labels](https://doi.org/10.18653/v1/2024.naacl-long.126) |  | 0 |  | Eve Fleisig, Su Lin Blodgett, Dan Klein, Zeerak Talat |  |
| 222 |  |  [Principles from Clinical Research for NLP Model Generalization](https://doi.org/10.18653/v1/2024.naacl-long.127) |  | 0 |  | Aparna Elangovan, Jiayuan He, Yuan Li, Karin Verspoor |  |
| 223 |  |  [First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.128) |  | 0 |  | Naomi Saphra, Eve Fleisig, Kyunghyun Cho, Adam Lopez |  |
| 224 |  |  [Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.129) |  | 0 |  | Raphael Tang, Xinyu Zhang, Xueguang Ma, Jimmy Lin, Ferhan Ture |  |
| 225 |  |  [From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.130) |  | 0 |  | Xuansheng Wu, Wenlin Yao, Jianshu Chen, Xiaoman Pan, Xiaoyang Wang, Ninghao Liu, Dong Yu |  |
| 226 |  |  [POLYIE: A Dataset of Information Extraction from Polymer Material Scientific Literature](https://doi.org/10.18653/v1/2024.naacl-long.131) |  | 0 |  | Jerry Junyang Cheung, Yuchen Zhuang, Yinghao Li, Pranav Shetty, Wantian Zhao, Sanjeev Grampurohit, Rampi Ramprasad, Chao Zhang |  |
| 227 |  |  [LLM-based Medical Assistant Personalization with Short- and Long-Term Memory Coordination](https://doi.org/10.18653/v1/2024.naacl-long.132) |  | 0 |  | Kai Zhang, Yangyang Kang, Fubang Zhao, Xiaozhong Liu |  |
| 228 |  |  [SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual Summarization](https://doi.org/10.18653/v1/2024.naacl-long.133) |  | 0 |  | Jacob Parnell, Inigo Jauregi Unanue, Massimo Piccardi |  |
| 229 |  |  [KTRL+F: Knowledge-Augmented In-Document Search](https://doi.org/10.18653/v1/2024.naacl-long.134) |  | 0 |  | Hanseok Oh, Haebin Shin, Miyoung Ko, Hyunji Lee, Minjoon Seo |  |
| 230 |  |  [How Well Do Large Language Models Truly Ground?](https://doi.org/10.18653/v1/2024.naacl-long.135) |  | 0 |  | Hyunji Lee, Se June Joo, Chaeeun Kim, Joel Jang, Doyoung Kim, KyoungWoon On, Minjoon Seo |  |
| 231 |  |  [ALBA: Adaptive Language-Based Assessments for Mental Health](https://doi.org/10.18653/v1/2024.naacl-long.136) |  | 0 |  | Vasudha Varadarajan, Sverker Sikström, Oscar N. E. Kjell, H. Andrew Schwartz |  |
| 232 |  |  [FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.137) |  | 0 |  | Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich |  |
| 233 |  |  [MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion](https://doi.org/10.18653/v1/2024.naacl-long.138) |  | 0 |  | Pengyue Jia, Yiding Liu, Xiangyu Zhao, Xiaopeng Li, Changying Hao, Shuaiqiang Wang, Dawei Yin |  |
| 234 |  |  [Efficient Benchmarking (of Language Models)](https://doi.org/10.18653/v1/2024.naacl-long.139) |  | 0 |  | Yotam Perlitz, Elron Bandel, Ariel Gera, Ofir Arviv, Liat EinDor, Eyal Shnarch, Noam Slonim, Michal ShmueliScheuer, Leshem Choshen |  |
| 235 |  |  [ReFACT: Updating Text-to-Image Models by Editing the Text Encoder](https://doi.org/10.18653/v1/2024.naacl-long.140) |  | 0 |  | Dana Arad, Hadas Orgad, Yonatan Belinkov |  |
| 236 |  |  [A Likelihood Ratio Test of Genetic Relationship among Languages](https://doi.org/10.18653/v1/2024.naacl-long.141) |  | 0 |  | V. S. D. S. Mahesh Akavarapu, Arnab Bhattacharya |  |
| 237 |  |  [PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning](https://doi.org/10.18653/v1/2024.naacl-long.142) |  | 0 |  | Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xinwei Long, Zhouhan Lin, Bowen Zhou |  |
| 238 |  |  [MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks](https://doi.org/10.18653/v1/2024.naacl-long.143) |  | 0 |  | Sanchit Ahuja, Divyanshu Aggarwal, Varun Gumma, Ishaan Watts, Ashutosh Sathe, Millicent Ochieng, Rishav Hada, Prachi Jain, Mohamed Ahmed, Kalika Bali, Sunayana Sitaram |  |
| 239 |  |  [Unlocking Emergent Modularity in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.144) |  | 0 |  | Zihan Qiu, Zeyu Huang, Jie Fu |  |
| 240 |  |  [A School Student Essay Corpus for Analyzing Interactions of Argumentative Structure and Quality](https://doi.org/10.18653/v1/2024.naacl-long.145) |  | 0 |  | Maja Stahl, Nadine Michel, Sebastian Kilsbach, Julian Schmidtke, Sara Rezat, Henning Wachsmuth |  |
| 241 |  |  [Adjusting Interpretable Dimensions in Embedding Space with Human Judgments](https://doi.org/10.18653/v1/2024.naacl-long.146) |  | 0 |  | Katrin Erk, Marianna Apidianaki |  |
| 242 |  |  [PatentEval: Understanding Errors in Patent Generation](https://doi.org/10.18653/v1/2024.naacl-long.147) |  | 0 |  | You Zuo, Kim Gerdes, Éric de la Clergerie, Benoît Sagot |  |
| 243 |  |  [Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing](https://doi.org/10.18653/v1/2024.naacl-long.148) |  | 0 |  | Sai Koneru, Miriam Exel, Matthias Huck, Jan Niehues |  |
| 244 |  |  [Metaphor Detection with Context Enhancement and Curriculum Learning](https://doi.org/10.18653/v1/2024.naacl-long.149) |  | 0 |  | Kaidi Jia, Rongsheng Li |  |
| 245 |  |  [What Causes the Failure of Explicit to Implicit Discourse Relation Recognition?](https://doi.org/10.18653/v1/2024.naacl-long.150) |  | 0 |  | Wei Liu, Stephen Wan, Michael Strube |  |
| 246 |  |  [UniverSLU: Universal Spoken Language Understanding for Diverse Tasks with Natural Language Instructions](https://doi.org/10.18653/v1/2024.naacl-long.151) |  | 0 |  | Siddhant Arora, Hayato Futami, Jeeweon Jung, Yifan Peng, Roshan S. Sharma, Yosuke Kashiwagi, Emiru Tsunoo, Karen Livescu, Shinji Watanabe |  |
| 247 |  |  [How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities](https://doi.org/10.18653/v1/2024.naacl-long.152) |  | 0 |  | Lingbo Mo, Boshi Wang, Muhao Chen, Huan Sun |  |
| 248 |  |  [Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.153) |  | 0 |  | Yue Zhou, Yada Zhu, Diego Antognini, Yoon Kim, Yang Zhang |  |
| 249 |  |  [TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale](https://doi.org/10.18653/v1/2024.naacl-long.154) |  | 0 |  | Pengcheng Jiang, Cao Xiao, Zifeng Wang, Parminder Bhatia, Jimeng Sun, Jiawei Han |  |
| 250 |  |  [GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.155) |  | 0 |  | Pengcheng Jiang, Jiacheng Lin, Zifeng Wang, Jimeng Sun, Jiawei Han |  |
| 251 |  |  [Curated Datasets and Neural Models for Machine Translation of Informal Registers between Mayan and Spanish Vernaculars](https://doi.org/10.18653/v1/2024.naacl-long.156) |  | 0 |  | Andrés Lou, Juan Antonio PérezOrtiz, Felipe SánchezMartínez, Víctor M. SánchezCartagena |  |
| 252 |  |  [The Effect of Data Partitioning Strategy on Model Generalizability: A Case Study of Morphological Segmentation](https://doi.org/10.18653/v1/2024.naacl-long.157) |  | 0 |  | Zoey Liu, Bonnie J. Dorr |  |
| 253 |  |  [Measuring Entrainment in Spontaneous Code-switched Speech](https://doi.org/10.18653/v1/2024.naacl-long.158) |  | 0 |  | Debasmita Bhattacharya, Siying Ding, Alayna Nguyen, Julia Hirschberg |  |
| 254 |  |  [A Survey of Meaning Representations - From Theory to Practical Utility](https://doi.org/10.18653/v1/2024.naacl-long.159) |  | 0 |  | Zacchary Sadeddine, Juri Opitz, Fabian M. Suchanek |  |
| 255 |  |  [Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation](https://doi.org/10.18653/v1/2024.naacl-long.160) |  | 0 |  | Haozhe Zhao, Zefan Cai, Shuzheng Si, Liang Chen, Yufeng He, Kaikai An, Baobao Chang |  |
| 256 |  |  [Evaluating In-Context Learning of Libraries for Code Generation](https://doi.org/10.18653/v1/2024.naacl-long.161) |  | 0 |  | Arkil Patel, Siva Reddy, Dzmitry Bahdanau, Pradeep Dasigi |  |
| 257 |  |  [Visually-Aware Context Modeling for News Image Captioning](https://doi.org/10.18653/v1/2024.naacl-long.162) |  | 0 |  | Tingyu Qu, Tinne Tuytelaars, MarieFrancine Moens |  |
| 258 |  |  [Regularized Conventions: Equilibrium Computation as a Model of Pragmatic Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.163) |  | 0 |  | Athul Paul Jacob, Gabriele Farina, Jacob Andreas |  |
| 259 |  |  [TopicGPT: A Prompt-based Topic Modeling Framework](https://doi.org/10.18653/v1/2024.naacl-long.164) |  | 0 |  | Chau Pham, Alexander Miserlis Hoyle, Simeng Sun, Philip Resnik, Mohit Iyyer |  |
| 260 |  |  [ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger](https://doi.org/10.18653/v1/2024.naacl-long.165) |  | 0 |  | Jiazhao Li, Yijin Yang, Zhuofeng Wu, V. G. Vinod Vydiswaran, Chaowei Xiao |  |
| 261 |  |  [Social Meme-ing: Measuring Linguistic Variation in Memes](https://doi.org/10.18653/v1/2024.naacl-long.166) |  | 0 |  | Naitian Zhou, David Jurgens, David Bamman |  |
| 262 |  |  [ExpertQA: Expert-Curated Questions and Attributed Answers](https://doi.org/10.18653/v1/2024.naacl-long.167) |  | 0 |  | Chaitanya Malaviya, Subin Lee, Sihao Chen, Elizabeth Sieber, Mark Yatskar, Dan Roth |  |
| 263 |  |  [What if you said that differently?: How Explanation Formats Affect Human Feedback Efficacy and User Perception](https://doi.org/10.18653/v1/2024.naacl-long.168) |  | 0 |  | Chaitanya Malaviya, Subin Lee, Dan Roth, Mark Yatskar |  |
| 264 |  |  [When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels](https://doi.org/10.18653/v1/2024.naacl-long.169) |  | 0 |  | Weiyan Shi, Emily Dinan, Kurt Shuster, Jason Weston, Jing Xu |  |
| 265 |  |  [Kreyòl-MT: Building MT for Latin American, Caribbean and Colonial African Creole Languages](https://doi.org/10.18653/v1/2024.naacl-long.170) |  | 0 |  | Nathaniel R. Robinson, Raj Dabre, Ammon Shurtz, Rasul Dent, Onenamiyi Onesi, Claire Bizon Monroc, Loïc Grobol, Hasan Muhammad, Ashi Garg, Naome A. Etori, Vijay Murari Tiyyala, Olanrewaju Samuel, Matthew Dean Stutzman, Bismarck Bamfo Odoom, Sanjeev Khudanpur, Stephen D. Richardson, Kenton Murray |  |
| 266 |  |  [Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.171) |  | 0 |  | Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, Muhao Chen |  |
| 267 |  |  [Modeling Empathetic Alignment in Conversation](https://doi.org/10.18653/v1/2024.naacl-long.172) |  | 0 |  | Jiamin Yang, David Jurgens |  |
| 268 |  |  [Native Language Identification in Texts: A Survey](https://doi.org/10.18653/v1/2024.naacl-long.173) |  | 0 |  | Dhiman Goswami, Sharanya Thilagan, Kai North, Shervin Malmasi, Marcos Zampieri |  |
| 269 |  |  [LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.174) |  | 0 |  | Yifan Yang, Jiajun Zhou, Ngai Wong, Zheng Zhang |  |
| 270 |  |  [Which One? Leveraging Context Between Objects and Multiple Views for Language Grounding](https://doi.org/10.18653/v1/2024.naacl-long.175) |  | 0 |  | Chancharik Mitra, Abrar Anwar, Rodolfo Corona, Dan Klein, Trevor Darrell, Jesse Thomason |  |
| 271 |  |  [Do Localization Methods Actually Localize Memorized Data in LLMs? A Tale of Two Benchmarks](https://doi.org/10.18653/v1/2024.naacl-long.176) |  | 0 |  | TingYun Chang, Jesse Thomason, Robin Jia |  |
| 272 |  |  [PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning](https://doi.org/10.18653/v1/2024.naacl-long.177) |  | 0 |  | Tianrong Zhang, Zhaohan Xi, Ting Wang, Prasenjit Mitra, Jinghui Chen |  |
| 273 |  |  [Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models](https://doi.org/10.18653/v1/2024.naacl-long.178) |  | 0 |  | Zhixue Zhao, Nikolaos Aletras |  |
| 274 |  |  [A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity](https://doi.org/10.18653/v1/2024.naacl-long.179) |  | 0 |  | Shayne Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David Mimno, Daphne Ippolito |  |
| 275 |  |  [Instructional Fingerprinting of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.180) |  | 0 |  | Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen |  |
| 276 |  |  [Reinforced Multiple Instance Selection for Speaker Attribute Prediction](https://doi.org/10.18653/v1/2024.naacl-long.181) |  | 0 |  | Alireza Salkhordeh Ziabari, Ali Omrani, Parsa Hejabi, Preni Golazizian, Brendan Kennedy, Payam Piray, Morteza Dehghani |  |
| 277 |  |  [DynaMo: Accelerating Language Model Inference with Dynamic Multi-Token Sampling](https://doi.org/10.18653/v1/2024.naacl-long.182) |  | 0 |  | Shikhar Tuli, ChiHeng Lin, YenChang Hsu, Niraj K. Jha, Yilin Shen, Hongxia Jin |  |
| 278 |  |  [Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation](https://doi.org/10.18653/v1/2024.naacl-long.183) |  | 0 |  | Haochen Liu, Song Wang, Chen Chen, Jundong Li |  |
| 279 |  |  [Uncertainty Quantification for In-Context Learning of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.184) |  | 0 |  | Chen Ling, Xujiang Zhao, Xuchao Zhang, Wei Cheng, Yanchi Liu, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Jie Ji, Guangji Bai, Liang Zhao, Haifeng Chen |  |
| 280 |  |  [HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM](https://doi.org/10.18653/v1/2024.naacl-long.185) |  | 0 |  | Zhilin Wang, Yi Dong, Jiaqi Zeng, Virginia Adams, Makesh Narsimhan Sreedhar, Daniel Egert, Olivier Delalleau, Jane Polak Scowcroft, Neel Kant, Aidan Swope, Oleksii Kuchaiev |  |
| 281 |  |  [A Preference-driven Paradigm for Enhanced Translation with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.186) |  | 0 |  | Dawei Zhu, Sony Trenous, Xiaoyu Shen, Dietrich Klakow, Bill Byrne, Eva Hasler |  |
| 282 |  |  [Fair Abstractive Summarization of Diverse Perspectives](https://doi.org/10.18653/v1/2024.naacl-long.187) |  | 0 |  | Yusen Zhang, Nan Zhang, Yixin Liu, Alexander R. Fabbri, Junru Liu, Ryo Kamoi, Xiaoxin Lu, Caiming Xiong, Jieyu Zhao, Dragomir Radev, Kathleen R. McKeown, Rui Zhang |  |
| 283 |  |  [What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases](https://doi.org/10.18653/v1/2024.naacl-long.188) |  | 0 |  | Anthony Meng Huat Tiong, Junqi Zhao, Boyang Li, Junnan Li, Steven C. H. Hoi, Caiming Xiong |  |
| 284 |  |  [Show Your Work with Confidence: Confidence Bands for Tuning Curves](https://doi.org/10.18653/v1/2024.naacl-long.189) |  | 0 |  | Nicholas Lourie, Kyunghyun Cho, He He |  |
| 285 |  |  [GRASP: A Disagreement Analysis Framework to Assess Group Associations in Perspectives](https://doi.org/10.18653/v1/2024.naacl-long.190) |  | 0 |  | Vinodkumar Prabhakaran, Christopher Homan, Lora Aroyo, Aida Mostafazadeh Davani, Alicia Parrish, Alex S. Taylor, Mark Diaz, Ding Wang, Gregory SerapioGarcía |  |
| 286 |  |  [Event Causality Is Key to Computational Story Understanding](https://doi.org/10.18653/v1/2024.naacl-long.191) |  | 0 |  | Yidan Sun, Qin Chao, Boyang Li |  |
| 287 |  |  [Subspace Representations for Soft Set Operations and Sentence Similarities](https://doi.org/10.18653/v1/2024.naacl-long.192) |  | 0 |  | Yoichi Ishibashi, Sho Yokoi, Katsuhito Sudoh, Satoshi Nakamura |  |
| 288 |  |  [My Heart Skipped a Beat! Recognizing Expressions of Embodied Emotion in Natural Language](https://doi.org/10.18653/v1/2024.naacl-long.193) |  | 0 |  | Yuan Zhuang, Tianyu Jiang, Ellen Riloff |  |
| 289 |  |  [Low-Cost Generation and Evaluation of Dictionary Example Sentences](https://doi.org/10.18653/v1/2024.naacl-long.194) |  | 0 |  | Bill Cai, Clarence Boon Liang Ng, Daniel Liang, Shelvia Hotama |  |
| 290 |  |  [Making Language Models Better Tool Learners with Execution Feedback](https://doi.org/10.18653/v1/2024.naacl-long.195) |  | 0 |  | Shuofei Qiao, Honghao Gui, Chengfei Lv, Qianghuai Jia, Huajun Chen, Ningyu Zhang |  |
| 291 |  |  [Complex Claim Verification with Evidence Retrieved in the Wild](https://doi.org/10.18653/v1/2024.naacl-long.196) |  | 0 |  | Jifan Chen, Grace Kim, Aniruddh Sriram, Greg Durrett, Eunsol Choi |  |
| 292 |  |  [Multimodal Multi-loss Fusion Network for Sentiment Analysis](https://doi.org/10.18653/v1/2024.naacl-long.197) |  | 0 |  | Zehui Wu, Ziwei Gong, Jaywon Koo, Julia Hirschberg |  |
| 293 |  |  [Confronting LLMs with Traditional ML: Rethinking the Fairness of Large Language Models in Tabular Classifications](https://doi.org/10.18653/v1/2024.naacl-long.198) |  | 0 |  | Yanchen Liu, Srishti Gautam, Jiaqi Ma, Himabindu Lakkaraju |  |
| 294 |  |  [Analyzing the Use of Metaphors in News Editorials for Political Framing](https://doi.org/10.18653/v1/2024.naacl-long.199) |  | 0 |  | Meghdut Sengupta, Roxanne El Baff, Milad Alshomary, Henning Wachsmuth |  |
| 295 |  |  [SharpSeq: Empowering Continual Event Detection through Sharpness-Aware Sequential-task Learning](https://doi.org/10.18653/v1/2024.naacl-long.200) |  | 0 |  | ThanhThien Le, Viet Dao, Linh Nguyen, ThiNhung Nguyen, Linh Ngo Van, Thien Huu Nguyen |  |
| 296 |  |  [Dissecting Paraphrases: The Impact of Prompt Syntax and supplementary Information on Knowledge Retrieval from Pretrained Language Models](https://doi.org/10.18653/v1/2024.naacl-long.201) |  | 0 |  | Stephan Linzbach, Dimitar Dimitrov, Laura Kallmeyer, Kilian Evang, Hajira Jabeen, Stefan Dietze |  |
| 297 |  |  [Know When To Stop: A Study of Semantic Drift in Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.202) |  | 0 |  | Ava Spataru, Eric Hambro, Elena Voita, Nicola Cancedda |  |
| 298 |  |  [Curriculum Masking in Vision-Language Pretraining to Maximize Cross Modal Interaction](https://doi.org/10.18653/v1/2024.naacl-long.203) |  | 0 |  | Kraig Tou, Zijun Sun |  |
| 299 |  |  [Elote, Choclo and Mazorca: on the Varieties of Spanish](https://doi.org/10.18653/v1/2024.naacl-long.204) |  | 0 |  | Cristina EspañaBonet, Alberto BarrónCedeño |  |
| 300 |  |  [Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks](https://doi.org/10.18653/v1/2024.naacl-long.205) |  | 0 |  | Chonghua Wang, Haodong Duan, Songyang Zhang, Dahua Lin, Kai Chen |  |
| 301 |  |  [A Zero-Shot Monolingual Dual Stage Information Retrieval System for Spanish Biomedical Systematic Literature Reviews](https://doi.org/10.18653/v1/2024.naacl-long.206) |  | 0 |  | Regina OforiBoateng, Magaly AcevesMartins, Nirmalie Wiratunga, Carlos Francisco MorenoGarcía |  |
| 302 |  |  [LayoutPointer: A Spatial-Context Adaptive Pointer Network for Visual Information Extraction](https://doi.org/10.18653/v1/2024.naacl-long.207) |  | 0 |  | Siyuan Huang, Yongping Xiong, Guibin Wu |  |
| 303 |  |  [Long-form evaluation of model editing](https://doi.org/10.18653/v1/2024.naacl-long.208) |  | 0 |  | Domenic Rosati, Robie Gonzales, Jinkun Chen, Xuemin Yu, Melis Erkan, Yahya Kayani, Satya Deepika Chavatapalli, Frank Rudzicz, Hassan Sajjad |  |
| 304 |  |  [Analyzing the Role of Semantic Representations in the Era of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.209) |  | 0 |  | Zhijing Jin, Yuen Chen, Fernando Gonzalez Adauto, Jiarui Liu, Jiayi Zhang, Julian Michael, Bernhard Schölkopf, Mona T. Diab |  |
| 305 |  |  [TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction](https://doi.org/10.18653/v1/2024.naacl-long.210) |  | 0 |  | Shuo Li, Sangdon Park, Insup Lee, Osbert Bastani |  |
| 306 |  |  [MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities](https://doi.org/10.18653/v1/2024.naacl-long.211) |  | 0 |  | Xinpei Zhao, Jingyuan Sun, Shaonan Wang, Jing Ye, Xiaohan Zhang, Chengqing Zong |  |
| 307 |  |  [On-the-fly Definition Augmentation of LLMs for Biomedical NER](https://doi.org/10.18653/v1/2024.naacl-long.212) |  | 0 |  | Monica Munnangi, Sergey Feldman, Byron C. Wallace, Silvio Amir, Tom Hope, Aakanksha Naik |  |
| 308 |  |  [This Land is Your, My Land: Evaluating Geopolitical Bias in Language Models through Territorial Disputes](https://doi.org/10.18653/v1/2024.naacl-long.213) |  | 0 |  | Bryan Li, Samar Haider, Chris CallisonBurch |  |
| 309 |  |  [Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation](https://doi.org/10.18653/v1/2024.naacl-long.214) |  | 0 |  | Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He |  |
| 310 |  |  [LanguageFlow: Advancing Diffusion Language Generation with Probabilistic Flows](https://doi.org/10.18653/v1/2024.naacl-long.215) |  | 0 |  | Shujian Zhang, Lemeng Wu, Chengyue Gong, Xingchao Liu |  |
| 311 |  |  [Towards Improved Multi-Source Attribution for Long-Form Answer Generation](https://doi.org/10.18653/v1/2024.naacl-long.216) |  | 0 |  | Nilay Patel, Shivashankar Subramanian, Siddhant Garg, Pratyay Banerjee, Amita Misra |  |
| 312 |  |  [Synthetic Query Generation for Privacy-Preserving Deep Retrieval Systems using Differentially Private Language Models](https://doi.org/10.18653/v1/2024.naacl-long.217) |  | 0 |  | Aldo G. Carranza, Rezsa Farahani, Natalia Ponomareva, Alexey Kurakin, Matthew Jagielski, Milad Nasr |  |
| 313 |  |  [Okay, Let's Do This! Modeling Event Coreference with Generated Rationales and Knowledge Distillation](https://doi.org/10.18653/v1/2024.naacl-long.218) |  | 0 |  | Abhijnan Nath, Shadi Manafi Avari, Avyakta Chelle, Nikhil Krishnaswamy |  |
| 314 |  |  [Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey](https://doi.org/10.18653/v1/2024.naacl-long.219) |  | 0 |  | Garima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, Huan Liu |  |
| 315 |  |  [Pedagogically Aligned Objectives Create Reliable Automatic Cloze Tests](https://doi.org/10.18653/v1/2024.naacl-long.220) |  | 0 |  | Brian D. Ondov, Kush Attal, Dina DemnerFushman |  |
| 316 |  |  [Take One Step at a Time to Know Incremental Utility of Demonstration: An Analysis on Reranking for Few-Shot In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.221) |  | 0 |  | Kazuma Hashimoto, Karthik Raman, Michael Bendersky |  |
| 317 |  |  [LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.222) |  | 0 |  | Chi Han, Qifan Wang, Hao Peng, Wenhan Xiong, Yu Chen, Heng Ji, Sinong Wang |  |
| 318 |  |  [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants](https://doi.org/10.18653/v1/2024.naacl-long.223) |  | 0 |  | Albert Yu Sun, Varun Nair, Elliot Schumacher, Anitha Kannan |  |
| 319 |  |  [Advancing Beyond Identification: Multi-bit Watermark for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.224) |  | 0 |  | KiYoon Yoo, Wonhyuk Ahn, Nojun Kwak |  |
| 320 |  |  [HTCCN: Temporal Causal Convolutional Networks with Hawkes Process for Extrapolation Reasoning in Temporal Knowledge Graphs](https://doi.org/10.18653/v1/2024.naacl-long.225) |  | 0 |  | Tingxuan Chen, Jun Long, Liu Yang, Zidong Wang, Yongheng Wang, Xiongnan Jin |  |
| 321 |  |  [SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.226) |  | 0 |  | Abe Bohan Hou, Jingyu Zhang, Tianxing He, Yichen Wang, YungSung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, Yulia Tsvetkov |  |
| 322 |  |  [Media Bias Detection Across Families of Language Models](https://doi.org/10.18653/v1/2024.naacl-long.227) |  | 0 |  | Iffat Maab, Edison MarreseTaylor, Sebastian Padó, Yutaka Matsuo |  |
| 323 |  |  [Better Zero-Shot Reasoning with Role-Play Prompting](https://doi.org/10.18653/v1/2024.naacl-long.228) |  | 0 |  | Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi Sun, Xin Zhou, Enzhi Wang, Xiaohang Dong |  |
| 324 |  |  [Event-Content-Oriented Dialogue Generation in Short Video](https://doi.org/10.18653/v1/2024.naacl-long.229) |  | 0 |  | Fenghua Cheng, Xue Li, Zi Huang, Jinxiang Wang, Sen Wang |  |
| 325 |  |  [DoG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded Instruction Wrapping](https://doi.org/10.18653/v1/2024.naacl-long.230) |  | 0 |  | Yongrui Chen, Haiyun Jiang, Xinting Huang, Shuming Shi, Guilin Qi |  |
| 326 |  |  [Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case Summarization](https://doi.org/10.18653/v1/2024.naacl-long.231) |  | 0 |  | T. Y. S. S. Santosh, Vatsal Venkatkrishna, Saptarshi Ghosh, Matthias Grabmair |  |
| 327 |  |  [EDC: Effective and Efficient Dialog Comprehension For Dialog State Tracking](https://doi.org/10.18653/v1/2024.naacl-long.232) |  | 0 |  | Qifan Lu, Bhaskar Ramasubramanian, Radha Poovendran |  |
| 328 |  |  [Automatic Restoration of Diacritics for Speech Data Sets](https://doi.org/10.18653/v1/2024.naacl-long.233) |  | 0 |  | Sara Abedalmonem Mohammad Shatnawi, Sawsan Alqahtani, Hanan Aldarmaki |  |
| 329 |  |  [XNLIeu: a dataset for cross-lingual NLI in Basque](https://doi.org/10.18653/v1/2024.naacl-long.234) |  | 0 |  | Maite Heredia, Julen Etxaniz, Muitze Zulaika, Xabier Saralegi, Jeremy Barnes, Aitor Soroa |  |
| 330 |  |  [MDR: Model-Specific Demonstration Retrieval at Inference Time for In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.235) |  | 0 |  | Huazheng Wang, Jinming Wu, Haifeng Sun, Zixuan Xia, Daixuan Cheng, Jingyu Wang, Qi Qi, Jianxin Liao |  |
| 331 |  |  [Exploring Cross-Cultural Differences in English Hate Speech Annotations: From Dataset Construction to Analysis](https://doi.org/10.18653/v1/2024.naacl-long.236) |  | 0 |  | Nayeon Lee, Chani Jung, Junho Myung, Jiho Jin, José CamachoCollados, Juho Kim, Alice Oh |  |
| 332 |  |  [Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding](https://doi.org/10.18653/v1/2024.naacl-long.237) |  | 0 |  | Zheng Zhao, Emilio Monti, Jens Lehmann, Haytham Assem |  |
| 333 |  |  [Generalizable Sarcasm Detection is Just Around the Corner, of Course!](https://doi.org/10.18653/v1/2024.naacl-long.238) |  | 0 |  | Hyewon Jang, Diego Frassinelli |  |
| 334 |  |  [Encoding of lexical tone in self-supervised models of spoken language](https://doi.org/10.18653/v1/2024.naacl-long.239) |  | 0 |  | Gaofei Shen, Michaela Watkins, Afra Alishahi, Arianna Bisazza, Grzegorz Chrupala |  |
| 335 |  |  [A Systematic Comparison of Contextualized Word Embeddings for Lexical Semantic Change](https://doi.org/10.18653/v1/2024.naacl-long.240) |  | 0 |  | Francesco Periti, Nina Tahmasebi |  |
| 336 |  |  [iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples](https://doi.org/10.18653/v1/2024.naacl-long.241) |  | 0 |  | Xiancai Xu, JiaDong Zhang, Lei Xiong, Zhishang Liu |  |
| 337 |  |  [Rectifying Demonstration Shortcut in In-Context Learning](https://doi.org/10.18653/v1/2024.naacl-long.242) |  | 0 |  | Joonwon Jang, Sanghwan Jang, Wonbin Kweon, Minjin Jeon, Hwanjo Yu |  |
| 338 |  |  [Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark](https://doi.org/10.18653/v1/2024.naacl-long.243) |  | 0 |  | Stephen Mayhew, Terra Blevins, Shuheng Liu, Marek Suppa, Hila Gonen, Joseph Marvin Imperial, Börje Karlsson, Peiqin Lin, Nikola Ljubesic, Lester James V. Miranda, Barbara Plank, Arij Riabi, Yuval Pinter |  |
| 339 |  |  [ODD: A Benchmark Dataset for the Natural Language Processing Based Opioid Related Aberrant Behavior Detection](https://doi.org/10.18653/v1/2024.naacl-long.244) |  | 0 |  | Sunjae Kwon, Xun Wang, Weisong Liu, Emily Druhl, Minhee L. Sung, Joel I. Reisman, Wenjun Li, Robert D. Kerns, William Becker, Hong Yu |  |
| 340 |  |  [A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models](https://doi.org/10.18653/v1/2024.naacl-long.245) |  | 0 |  | Xingmeng Zhao, Ali Niazi, Anthony Rios |  |
| 341 |  |  [The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education](https://doi.org/10.18653/v1/2024.naacl-long.246) |  | 0 |  | Paiheng Xu, Jing Liu, Nathan Jones, Julie Cohen, Wei Ai |  |
| 342 |  |  [Differentially Private Next-Token Prediction of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.247) |  | 0 |  | James Flemings, Meisam Razaviyayn, Murali Annavaram |  |
| 343 |  |  [Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset](https://doi.org/10.18653/v1/2024.naacl-long.248) |  | 0 |  | Janis Goldzycher, Paul Röttger, Gerold Schneider |  |
| 344 |  |  [Memory Augmented Language Models through Mixture of Word Experts](https://doi.org/10.18653/v1/2024.naacl-long.249) |  | 0 |  | Cícero Nogueira dos Santos, James LeeThorp, Isaac Noble, ChungChing Chang, David C. Uthus |  |
| 345 |  |  [Impossible Distillation for Paraphrasing and Summarization: How to Make High-quality Lemonade out of Small, Low-quality Model](https://doi.org/10.18653/v1/2024.naacl-long.250) |  | 0 |  | Jaehun Jung, Peter West, Liwei Jiang, Faeze Brahman, Ximing Lu, Jillian Fisher, Taylor Sorensen, Yejin Choi |  |
| 346 |  |  [TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization](https://doi.org/10.18653/v1/2024.naacl-long.251) |  | 0 |  | Liyan Tang, Igor Shalyminov, Amy Wingmei Wong, Jon Burnsky, Jake W. Vincent, Yuan Yang, Siffi Singh, Song Feng, Hwanjun Song, Hang Su, Lijia Sun, Yi Zhang, Saab Mansour, Kathleen McKeown |  |
| 347 |  |  [MOKA: Moral Knowledge Augmentation for Moral Event Extraction](https://doi.org/10.18653/v1/2024.naacl-long.252) |  | 0 |  | Xinliang Frederick Zhang, Winston Wu, Nicholas Beauchamp, Lu Wang |  |
| 348 |  |  [Fixing Rogue Memorization in Many-to-One Multilingual Translators of Extremely-Low-Resource Languages by Rephrasing Training Samples](https://doi.org/10.18653/v1/2024.naacl-long.253) |  | 0 |  | Paulo R. Cavalin, Pedro Henrique Domingues, Claudio S. Pinhanez, Julio Nogima |  |
| 349 |  |  [Backdoor Attacks on Multilingual Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.254) |  | 0 |  | Jun Wang, Qiongkai Xu, Xuanli He, Benjamin I. P. Rubinstein, Trevor Cohn |  |
| 350 |  |  [Personalized Jargon Identification for Enhanced Interdisciplinary Communication](https://doi.org/10.18653/v1/2024.naacl-long.255) |  | 0 |  | Yue Guo, Joseph Chee Chang, Maria Antoniak, Erin Bransom, Trevor Cohen, Lucy Lu Wang, Tal August |  |
| 351 |  |  [Flames: Benchmarking Value Alignment of LLMs in Chinese](https://doi.org/10.18653/v1/2024.naacl-long.256) |  | 0 |  | Kexin Huang, Xiangyang Liu, Qianyu Guo, Tianxiang Sun, Jiawei Sun, Yaru Wang, Zeyang Zhou, Yixu Wang, Yan Teng, Xipeng Qiu, Yingchun Wang, Dahua Lin |  |
| 352 |  |  [Mitigating Bias for Question Answering Models by Tracking Bias Influence](https://doi.org/10.18653/v1/2024.naacl-long.257) |  | 0 |  | Mingyu Derek Ma, JiunYu Kao, Arpit Gupta, YuHsiang Lin, Wenbo Zhao, Tagyoung Chung, Wei Wang, KaiWei Chang, Nanyun Peng |  |
| 353 |  |  [Extending CLIP's Image-Text Alignment to Referring Image Segmentation](https://doi.org/10.18653/v1/2024.naacl-long.258) |  | 0 |  | Seoyeon Kim, Minguk Kang, Dongwon Kim, Jaesik Park, Suha Kwak |  |
| 354 |  |  [Generating Attractive and Authentic Copywriting from Customer Reviews](https://doi.org/10.18653/v1/2024.naacl-long.259) |  | 0 |  | YuXiang Lin, WeiYun Ma |  |
| 355 |  |  [Effective Long-Context Scaling of Foundation Models](https://doi.org/10.18653/v1/2024.naacl-long.260) |  | 0 |  | Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajjwal Bhargava, Rui Hou, Louis Martin, Rashi Rungta, Karthik Abinav Sankararaman, Barlas Oguz, Madian Khabsa, Han Fang, Yashar Mehdad, Sharan Narang, Kshitiz Malik, Angela Fan, Shruti Bhosale, Sergey Edunov, Mike Lewis, Sinong Wang, Hao Ma |  |
| 356 |  |  [Empowering Diffusion Models on the Embedding Space for Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.261) |  | 0 |  | Zhujin Gao, Junliang Guo, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, Linli Xu |  |
| 357 |  |  [Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback](https://doi.org/10.18653/v1/2024.naacl-long.262) |  | 0 |  | Yu Xia, Tong Yu, Zhankui He, Handong Zhao, Julian J. McAuley, Shuai Li |  |
| 358 |  |  [Fake Alignment: Are LLMs Really Aligned Well?](https://doi.org/10.18653/v1/2024.naacl-long.263) |  | 0 |  | Yixu Wang, Yan Teng, Kexin Huang, Chengqi Lyu, Songyang Zhang, Wenwei Zhang, Xingjun Ma, YuGang Jiang, Yu Qiao, Yingchun Wang |  |
| 359 |  |  [Visually Guided Generative Text-Layout Pre-training for Document Intelligence](https://doi.org/10.18653/v1/2024.naacl-long.264) |  | 0 |  | Zhiming Mao, Haoli Bai, Lu Hou, Lifeng Shang, Xin Jiang, Qun Liu, KamFai Wong |  |
| 360 |  |  [HILL: Hierarchy-aware Information Lossless Contrastive Learning for Hierarchical Text Classification](https://doi.org/10.18653/v1/2024.naacl-long.265) |  | 0 |  | He Zhu, Junran Wu, Ruomei Liu, Yue Hou, Ze Yuan, Shangzhe Li, Yicheng Pan, Ke Xu |  |
| 361 |  |  [Investigating the Emergent Audio Classification Ability of ASR Foundation Models](https://doi.org/10.18653/v1/2024.naacl-long.266) |  | 0 |  | Rao Ma, Adian Liusie, Mark J. F. Gales, Kate M. Knill |  |
| 362 |  |  [In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax](https://doi.org/10.18653/v1/2024.naacl-long.267) |  | 0 |  | Aaron Mueller, Albert Webson, Jackson Petty, Tal Linzen |  |
| 363 |  |  [Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt](https://doi.org/10.18653/v1/2024.naacl-long.268) |  | 0 |  | Yongqi Wang, Ruofan Hu, Rongjie Huang, Zhiqing Hong, Ruiqi Li, Wenrui Liu, Fuming You, Tao Jin, Zhou Zhao |  |
| 364 |  |  [Lost in Transcription: Identifying and Quantifying the Accuracy Biases of Automatic Speech Recognition Systems Against Disfluent Speech](https://doi.org/10.18653/v1/2024.naacl-long.269) |  | 0 |  | Dena F. Mujtaba, Nihar R. Mahapatra, Megan Arney, J. Scott Yaruss, Hope GerlachHouck, Caryn Herring, Jia Bin |  |
| 365 |  |  [MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and Classification](https://doi.org/10.18653/v1/2024.naacl-long.270) |  | 0 |  | Chadi Helwe, Tom Calamai, PierreHenri Paris, Chloé Clavel, Fabian M. Suchanek |  |
| 366 |  |  [Diffusion Glancing Transformer for Parallel Sequence-to-Sequence Learning](https://doi.org/10.18653/v1/2024.naacl-long.271) |  | 0 |  | Lihua Qian, Mingxuan Wang, Yang Liu, Hao Zhou |  |
| 367 |  |  [No Context Needed: Contextual Quandary In Idiomatic Reasoning With Pre-Trained Language Models](https://doi.org/10.18653/v1/2024.naacl-long.272) |  | 0 |  | Kellen Cheng, Suma Bhat |  |
| 368 |  |  [Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation](https://doi.org/10.18653/v1/2024.naacl-long.273) |  | 0 |  | Xindi Wang, Robert E. Mercer, Frank Rudzicz |  |
| 369 |  |  [Anisotropy is Not Inherent to Transformers](https://doi.org/10.18653/v1/2024.naacl-long.274) |  | 0 |  | Anemily Machina, Robert E. Mercer |  |
| 370 |  |  [Finding Replicable Human Evaluations via Stable Ranking Probability](https://doi.org/10.18653/v1/2024.naacl-long.275) |  | 0 |  | Parker Riley, Daniel Deutsch, George F. Foster, Viresh Ratnakar, Ali Dabirmoghaddam, Markus Freitag |  |
| 371 |  |  [Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections](https://doi.org/10.18653/v1/2024.naacl-long.276) |  | 0 |  | Yuanpu Cao, Bochuan Cao, Jinghui Chen |  |
| 372 |  |  [Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts](https://doi.org/10.18653/v1/2024.naacl-long.277) |  | 0 |  | Sai Ashish Somayajula, Youwei Liang, Li Zhang, Abhishek Singh, Pengtao Xie |  |
| 373 |  |  [Detecting Bipolar Disorder from Misdiagnosed Major Depressive Disorder with Mood-Aware Multi-Task Learning](https://doi.org/10.18653/v1/2024.naacl-long.278) |  | 0 |  | Daeun Lee, Hyolim Jeon, Sejung Son, Chaewon Park, Ji Hyun An, Seungbae Kim, Jinyoung Han |  |
| 374 |  |  [Leveraging Code to Improve In-Context Learning for Semantic Parsing](https://doi.org/10.18653/v1/2024.naacl-long.279) |  | 0 |  | Ben Bogin, Shivanshu Gupta, Peter Clark, Ashish Sabharwal |  |
| 375 |  |  [Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER](https://doi.org/10.18653/v1/2024.naacl-long.280) |  | 0 |  | Micheal Abaho, Danushka Bollegala, Gary Leeming, Dan W. Joyce, Iain E. Buchan |  |
| 376 |  |  [Language Models Implement Simple Word2Vec-style Vector Arithmetic](https://doi.org/10.18653/v1/2024.naacl-long.281) |  | 0 |  | Jack Merullo, Carsten Eickhoff, Ellie Pavlick |  |
| 377 |  |  [AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning](https://doi.org/10.18653/v1/2024.naacl-long.282) |  | 0 |  | Ruiyi Zhang, Rushi Qiang, Sai Ashish Somayajula, Pengtao Xie |  |
| 378 |  |  [SportQA: A Benchmark for Sports Understanding in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.283) |  | 0 |  | Haotian Xia, Zhengbang Yang, Yuqing Wang, Rhys Tracy, Yun Zhao, Dongdong Huang, Zezhi Chen, Yan Zhu, YuanFang Wang, Weining Shen |  |
| 379 |  |  [Revisiting subword tokenization: A case study on affixal negation in large language models](https://doi.org/10.18653/v1/2024.naacl-long.284) |  | 0 |  | Thinh Truong, Yulia Otmakhova, Karin Verspoor, Trevor Cohn, Timothy Baldwin |  |
| 380 |  |  [Generating Mental Health Transcripts with SAPE (Spanish Adaptive Prompt Engineering)](https://doi.org/10.18653/v1/2024.naacl-long.285) |  | 0 |  | Daniel Cabrera Lozoya, Alejandro Berazaluce, Juan Perches, Eloy Lúa, Mike Conway, Simon D'Alfonso |  |
| 381 |  |  [Where are you from? Geolocating Speech and Applications to Language Identification](https://doi.org/10.18653/v1/2024.naacl-long.286) |  | 0 |  | Patrick Foley, Matthew Wiesner, Bismarck Odoom, Leibny Paola GarcíaPerera, Kenton Murray, Philipp Koehn |  |
| 382 |  |  [Teaching Language Models to Self-Improve through Interactive Demonstrations](https://doi.org/10.18653/v1/2024.naacl-long.287) |  | 0 |  | Xiao Yu, Baolin Peng, Michel Galley, Jianfeng Gao, Zhou Yu |  |
| 383 |  |  [MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets](https://doi.org/10.18653/v1/2024.naacl-long.288) |  | 0 |  | Hossein Aboutalebi, Hwanjun Song, Yusheng Xie, Arshit Gupta, Lijia Sun, Hang Su, Igor Shalyminov, Nikolaos Pappas, Siffi Singh, Saab Mansour |  |
| 384 |  |  [Zero-shot Generative Linguistic Steganography](https://doi.org/10.18653/v1/2024.naacl-long.289) |  | 0 |  | Ke Lin, Yiyang Luo, Zijian Zhang, Ping Luo |  |
| 385 |  |  [Does GPT-4 pass the Turing test?](https://doi.org/10.18653/v1/2024.naacl-long.290) |  | 0 |  | Cameron R. Jones, Ben Bergen |  |
| 386 |  |  [Polarity Calibration for Opinion Summarization](https://doi.org/10.18653/v1/2024.naacl-long.291) |  | 0 |  | Yuanyuan Lei, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Ruihong Huang, Dong Yu |  |
| 387 |  |  [Sentence-level Media Bias Analysis with Event Relation Graph](https://doi.org/10.18653/v1/2024.naacl-long.292) |  | 0 |  | Yuanyuan Lei, Ruihong Huang |  |
| 388 |  |  [EMONA: Event-level Moral Opinions in News Articles](https://doi.org/10.18653/v1/2024.naacl-long.293) |  | 0 |  | Yuanyuan Lei, Md Messal Monem Miah, Ayesha Qamar, Sai Ramana Reddy, Jonathan Tong, Haotian Xu, Ruihong Huang |  |
| 389 |  |  [DLM: A Decoupled Learning Model for Long-tailed Polyphone Disambiguation in Mandarin](https://doi.org/10.18653/v1/2024.naacl-long.294) |  | 0 |  | Beibei Gao, Yangsen Zhang, Ga Xiang, Yushan Jiang |  |
| 390 |  |  [You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments](https://doi.org/10.18653/v1/2024.naacl-long.295) |  | 0 |  | Bangzhao Shu, Lechen Zhang, Minje Choi, Lavinia Dunagan, Lajanugen Logeswaran, Moontae Lee, Dallas Card, David Jurgens |  |
| 391 |  |  [CASA: Causality-driven Argument Sufficiency Assessment](https://doi.org/10.18653/v1/2024.naacl-long.296) |  | 0 |  | Xiao Liu, Yansong Feng, KaiWei Chang |  |
| 392 |  |  [MacGyver: Are Large Language Models Creative Problem Solvers?](https://doi.org/10.18653/v1/2024.naacl-long.297) |  | 0 |  | Yufei Tian, Abhilasha Ravichander, Lianhui Qin, Ronan Le Bras, Raja Marjieh, Nanyun Peng, Yejin Choi, Thomas L. Griffiths, Faeze Brahman |  |
| 393 |  |  [To Translate or Not to Translate: A Systematic Investigation of Translation-Based Cross-Lingual Transfer to Low-Resource Languages](https://doi.org/10.18653/v1/2024.naacl-long.298) |  | 0 |  | Benedikt Ebing, Goran Glavas |  |
| 394 |  |  [Enhancing Large Language Models Against Inductive Instructions with Dual-critique Prompting](https://doi.org/10.18653/v1/2024.naacl-long.299) |  | 0 |  | Rui Wang, Hongru Wang, Fei Mi, Boyang Xue, Yi Chen, KamFai Wong, Ruifeng Xu |  |
| 395 |  |  [GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer](https://doi.org/10.18653/v1/2024.naacl-long.300) |  | 0 |  | Urchade Zaratiana, Nadi Tomeh, Pierre Holat, Thierry Charnois |  |
| 396 |  |  [XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.301) |  | 0 |  | Paul Röttger, Hannah Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, Dirk Hovy |  |
| 397 |  |  [Carpe diem: On the Evaluation of World Knowledge in Lifelong Language Models](https://doi.org/10.18653/v1/2024.naacl-long.302) |  | 0 |  | Yujin Kim, Jaehong Yoon, Seonghyeon Ye, Sangmin Bae, Namgyu Ho, Sung Ju Hwang, SeYoung Yun |  |
| 398 |  |  [Fine-grained Gender Control in Machine Translation with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.303) |  | 0 |  | Minwoo Lee, Hyukhun Koh, Minsung Kim, Kyomin Jung |  |
| 399 |  |  [DialogVCS: Robust Natural Language Understanding in Dialogue System Upgrade](https://doi.org/10.18653/v1/2024.naacl-long.304) |  | 0 |  | Zefan Cai, Xin Zheng, Tianyu Liu, Haoran Meng, Jiaqi Han, Gang Yuan, Binghuai Lin, Baobao Chang, Yunbo Cao |  |
| 400 |  |  [LLatrieval: LLM-Verified Retrieval for Verifiable Generation](https://doi.org/10.18653/v1/2024.naacl-long.305) |  | 0 |  | Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin, Tianxiang Sun, Xipeng Qiu |  |
| 401 |  |  [Mapping Long-term Causalities in Psychiatric Symptomatology and Life Events from Social Media](https://doi.org/10.18653/v1/2024.naacl-long.306) |  | 0 |  | Siyuan Chen, Meilin Wang, Minghao Lv, Zhiling Zhang, Juqianqian Juqianqian, Dejiyangla Dejiyangla, Yujia Peng, Kenny Q. Zhu, Mengyue Wu |  |
| 402 |  |  [Multimodal Chart Retrieval: A Comparison of Text, Table and Image Based Approaches](https://doi.org/10.18653/v1/2024.naacl-long.307) |  | 0 |  | Averi Nowak, Francesco Piccinno, Yasemin Altun |  |
| 403 |  |  [Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval Augmentation to Language Models](https://doi.org/10.18653/v1/2024.naacl-long.308) |  | 0 |  | Seiji Maekawa, Hayate Iso, Sairam Gurajada, Nikita Bhutani |  |
| 404 |  |  [AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs](https://doi.org/10.18653/v1/2024.naacl-long.309) |  | 0 |  | Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Ke Li, Junteng Jia, Yuan Shangguan, Jay Mahadeokar, Ozlem Kalinli, Christian Fuegen, Mike Seltzer |  |
| 405 |  |  [Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness](https://doi.org/10.18653/v1/2024.naacl-long.310) |  | 0 |  | Ashim Gupta, Rishanth Rajendhran, Nathan Stringham, Vivek Srikumar, Ana Marasovic |  |
| 406 |  |  [Sequential Compositional Generalization in Multimodal Models](https://doi.org/10.18653/v1/2024.naacl-long.311) |  | 0 |  | Semih Yagcioglu, Osman Batur Ince, Aykut Erdem, Erkut Erdem, Desmond Elliott, Deniz Yuret |  |
| 407 |  |  [Generating Uncontextualized and Contextualized Questions for Document-Level Event Argument Extraction](https://doi.org/10.18653/v1/2024.naacl-long.312) |  | 0 |  | Md Nayem Uddin, Enfa Rose George, Eduardo Blanco, Steven R. Corman |  |
| 408 |  |  [Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation](https://doi.org/10.18653/v1/2024.naacl-long.313) |  | 0 |  | Zhenrui Yue, Huimin Zeng, Yimeng Lu, Lanyu Shang, Yang Zhang, Dong Wang |  |
| 409 |  |  [Open-Vocabulary Federated Learning with Multimodal Prototyping](https://doi.org/10.18653/v1/2024.naacl-long.314) |  | 0 |  | Huimin Zeng, Zhenrui Yue, Dong Wang |  |
| 410 |  |  [Exploring Key Point Analysis with Pairwise Generation and Graph Partitioning](https://doi.org/10.18653/v1/2024.naacl-long.315) |  | 0 |  | Xiao Li, Yong Jiang, Shen Huang, Pengjun Xie, Gong Cheng, Fei Huang |  |
| 411 |  |  [Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense](https://doi.org/10.18653/v1/2024.naacl-long.316) |  | 0 |  | Siqi Shen, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Soujanya Poria, Rada Mihalcea |  |
| 412 |  |  [Code Models are Zero-shot Precondition Reasoners](https://doi.org/10.18653/v1/2024.naacl-long.317) |  | 0 |  | Lajanugen Logeswaran, Sungryull Sohn, Yiwei Lyu, Anthony Z. Liu, DongKi Kim, Dongsub Shim, Moontae Lee, Honglak Lee |  |
| 413 |  |  [Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding](https://doi.org/10.18653/v1/2024.naacl-long.318) |  | 0 |  | Suyoung Kim, Jiyeon Hwang, HoYoung Jung |  |
| 414 |  |  [Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers](https://doi.org/10.18653/v1/2024.naacl-long.319) |  | 0 |  | Yuan Wang, Xuyang Wu, HsinTai Wu, Zhiqiang Tao, Yi Fang |  |
| 415 |  |  [TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition](https://doi.org/10.18653/v1/2024.naacl-long.320) |  | 0 |  | Md Mahadi Hasan Nahid, Davood Rafiei |  |
| 416 |  |  [Contextual Label Projection for Cross-Lingual Structured Prediction](https://doi.org/10.18653/v1/2024.naacl-long.321) |  | 0 |  | Tanmay Parekh, IHung Hsu, KuanHao Huang, KaiWei Chang, Nanyun Peng |  |
| 417 |  |  [Event Detection from Social Media for Epidemic Prediction](https://doi.org/10.18653/v1/2024.naacl-long.322) |  | 0 |  | Tanmay Parekh, Anh Mac, Jiarui Yu, Yuxuan Dong, Syed Shahriar, Bonnie Liu, Eric Yang, KuanHao Huang, Wei Wang, Nanyun Peng, KaiWei Chang |  |
| 418 |  |  [RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.323) |  | 0 |  | Song Jiang, Zahra Shakeri, Aaron Chan, Maziar Sanjabi, Hamed Firooz, Yinglong Xia, Bugra Akyildiz, Yizhou Sun, Jinchao Li, Qifan Wang, Asli Celikyilmaz |  |
| 419 |  |  [BPE-knockout: Pruning Pre-existing BPE Tokenisers with Backwards-compatible Morphological Semi-supervision](https://doi.org/10.18653/v1/2024.naacl-long.324) |  | 0 |  | Thomas Bauwens, Pieter Delobelle |  |
| 420 |  |  [How are Prompts Different in Terms of Sensitivity?](https://doi.org/10.18653/v1/2024.naacl-long.325) |  | 0 |  | Sheng Lu, Hendrik Schuff, Iryna Gurevych |  |
| 421 |  |  [LSTDial: Enhancing Dialogue Generation via Long- and Short-Term Measurement Feedback](https://doi.org/10.18653/v1/2024.naacl-long.326) |  | 0 |  | Guanghui Ye, Huan Zhao, Zixing Zhang, Xupeng Zha, Zhihua Jiang |  |
| 422 |  |  [The ART of LLM Refinement: Ask, Refine, and Trust](https://doi.org/10.18653/v1/2024.naacl-long.327) |  | 0 |  | Kumar Shridhar, Koustuv Sinha, Andrew Cohen, Tianlu Wang, Ping Yu, Ramakanth Pasunuru, Mrinmaya Sachan, Jason Weston, Asli Celikyilmaz |  |
| 423 |  |  [Modularized Multilingual NMT with Fine-grained Interlingua](https://doi.org/10.18653/v1/2024.naacl-long.328) |  | 0 |  | Sungjun Lim, Yoonjung Choi, Sangha Kim |  |
| 424 |  |  [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](https://doi.org/10.18653/v1/2024.naacl-long.329) |  | 0 |  | Oren Sultan, Yonatan Bitton, Ron Yosef, Dafna Shahaf |  |
| 425 |  |  [AWESOME: GPU Memory-constrained Long Document Summarization using Memory Mechanism and Global Salient Content](https://doi.org/10.18653/v1/2024.naacl-long.330) |  | 0 |  | Shuyang Cao, Lu Wang |  |
| 426 |  |  [NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but Teaching the Distinction Helps](https://doi.org/10.18653/v1/2024.naacl-long.331) |  | 0 |  | Kristina Gligoric, Myra Cheng, Lucia Zheng, Esin Durmus, Dan Jurafsky |  |
| 427 |  |  [Debiasing with Sufficient Projection: A General Theoretical Framework for Vector Representations](https://doi.org/10.18653/v1/2024.naacl-long.332) |  | 0 |  | Enze Shi, Lei Ding, Linglong Kong, Bei Jiang |  |
| 428 |  |  [Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection](https://doi.org/10.18653/v1/2024.naacl-long.333) |  | 0 |  | Jianfeng He, Hang Su, Jason Cai, Igor Shalyminov, Hwanjun Song, Saab Mansour |  |
| 429 |  |  [AfriMTE and AfriCOMET: Enhancing COMET to Embrace Under-resourced African Languages](https://doi.org/10.18653/v1/2024.naacl-long.334) |  | 0 |  | Jiayi Wang, David Ifeoluwa Adelani, Sweta Agrawal, Marek Masiak, Ricardo Rei, Eleftheria Briakou, Marine Carpuat, Xuanli He, Sofia Bourhim, Andiswa Bukula, Muhidin Mohamed, Temitayo Olatoye, Tosin P. Adewumi, Hamam Mokayed, Christine Mwase, Wangui Kimotho, Foutse Yuehgoh, Anuoluwapo Aremu, Jessica Ojo, Shamsuddeen Hassan Muhammad, Salomey Osei, AbdulHakeem Omotayo, Chiamaka Chukwuneke, Perez Ogayo, Oumaima Hourrane, Salma El Anigri, Lolwethu Ndolela, Thabiso Mangwana, Shafie Abdi Mohamed, Ayinde Hassan, Oluwabusayo Olufunke Awoyomi, Lama Alkhaled, Sana Sabah AlAzzawi, Naome A. Etori, Millicent Ochieng, Clemencia Siro, Njoroge Kiragu, Eric Muchiri, Wangari Kimotho, Sakayo Toadoum Sari, Lyse Naomi Wamba Momo, Daud Abolade, Simbiat Ajao, Iyanuoluwa Shode, Ricky Macharm, Ruqayya Nasir Iro, Saheed S. Abdullahi, Stephen E. Moore, Bernard Opoku, Zainab Akinjobi, Afolabi Abeeb, Nnaemeka C. Obiefuna, Onyekachi Raphael Ogbu, Sam Ochieng', Verrah Otiende, Chinedu E. Mbonu, Yao Lu, Pontus Stenetorp |  |
| 430 |  |  [TableLlama: Towards Open Large Generalist Models for Tables](https://doi.org/10.18653/v1/2024.naacl-long.335) |  | 0 |  | Tianshu Zhang, Xiang Yue, Yifei Li, Huan Sun |  |
| 431 |  |  [PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language Models](https://doi.org/10.18653/v1/2024.naacl-long.336) |  | 0 |  | HyunJin Kim, Young Jin Kim, JinYeong Bak |  |
| 432 |  |  [Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection](https://doi.org/10.18653/v1/2024.naacl-long.337) |  | 0 |  | Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin |  |
| 433 |  |  [Exploring the Factual Consistency in Dialogue Comprehension of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.338) |  | 0 |  | Shuaijie She, Shujian Huang, Xingyun Wang, Yanke Zhou, Jiajun Chen |  |
| 434 |  |  [Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual Knowledge Alignment, But Only Shallowly](https://doi.org/10.18653/v1/2024.naacl-long.339) |  | 0 |  | Changjiang Gao, Hongda Hu, Peng Hu, Jiajun Chen, Jixing Li, Shujian Huang |  |
| 435 |  |  [A Study on the Calibration of In-context Learning](https://doi.org/10.18653/v1/2024.naacl-long.340) |  | 0 |  | Hanlin Zhang, Yifan Zhang, Yaodong Yu, Dhruv Madeka, Dean P. Foster, Eric P. Xing, Himabindu Lakkaraju, Sham M. Kakade |  |
| 436 |  |  [DialogBench: Evaluating LLMs as Human-like Dialogue Systems](https://doi.org/10.18653/v1/2024.naacl-long.341) |  | 0 |  | Jiao Ou, Junda Lu, Che Liu, Yihong Tang, Fuzheng Zhang, Di Zhang, Kun Gai |  |
| 437 |  |  [GINopic: Topic Modeling with Graph Isomorphism Network](https://doi.org/10.18653/v1/2024.naacl-long.342) |  | 0 |  | Suman Adhya, Debarshi Kumar Sanyal |  |
| 438 |  |  [CMB: A Comprehensive Medical Benchmark in Chinese](https://doi.org/10.18653/v1/2024.naacl-long.343) |  | 0 |  | Xidong Wang, Guiming Chen, Dingjie Song, Zhiyi Zhang, Zhihong Chen, Qingying Xiao, Junying Chen, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, Haizhou Li |  |
| 439 |  |  [Massive End-to-end Speech Recognition Models with Time Reduction](https://doi.org/10.18653/v1/2024.naacl-long.344) |  | 0 |  | Weiran Wang, Rohit Prabhavalkar, Haozhe Shan, Zhong Meng, Dongseong Hwang, Qiujia Li, Khe Chai Sim, Bo Li, James Qin, Xingyu Cai, Adam Stooke, Chengjian Zheng, Yanzhang He, Tara N. Sainath, Pedro Moreno Mengibar |  |
| 440 |  |  [SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics](https://doi.org/10.18653/v1/2024.naacl-long.345) |  | 0 |  | Arash Ardakani, Altan Haan, Shangyin Tan, DoruThom Popovici, Alvin Cheung, Costin Iancu, Koushik Sen |  |
| 441 |  |  [Effective Large Language Model Adaptation for Improved Grounding and Citation Generation](https://doi.org/10.18653/v1/2024.naacl-long.346) |  | 0 |  | Xi Ye, Ruoxi Sun, Sercan Ö. Arik, Tomas Pfister |  |
| 442 |  |  [Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.347) |  | 0 |  | Yijia Shao, Yucheng Jiang, Theodore A. Kanell, Peter Xu, Omar Khattab, Monica S. Lam |  |
| 443 |  |  [Grounding Gaps in Language Model Generations](https://doi.org/10.18653/v1/2024.naacl-long.348) |  | 0 |  | Omar Shaikh, Kristina Gligoric, Ashna Khetan, Matthias Gerstgrasser, Diyi Yang, Dan Jurafsky |  |
| 444 |  |  [When Does Monolingual Data Help Multilingual Translation: The Role of Domain and Model Scale](https://doi.org/10.18653/v1/2024.naacl-long.349) |  | 0 |  | Christos Baziotis, Biao Zhang, Alexandra Birch, Barry Haddow |  |
| 445 |  |  [ContraSim - Analyzing Neural Representations Based on Contrastive Learning](https://doi.org/10.18653/v1/2024.naacl-long.350) |  | 0 |  | Adir Rahamim, Yonatan Belinkov |  |
| 446 |  |  [Universal Prompt Optimizer for Safe Text-to-Image Generation](https://doi.org/10.18653/v1/2024.naacl-long.351) |  | 0 |  | Zongyu Wu, Hongcheng Gao, Yueze Wang, Xiang Zhang, Suhang Wang |  |
| 447 |  |  [Language Model Based Unsupervised Dependency Parsing with Conditional Mutual Information and Grammatical Constraints](https://doi.org/10.18653/v1/2024.naacl-long.352) |  | 0 |  | Junjie Chen, Xiangheng He, Yusuke Miyao |  |
| 448 |  |  [The Bias Amplification Paradox in Text-to-Image Generation](https://doi.org/10.18653/v1/2024.naacl-long.353) |  | 0 |  | Preethi Seshadri, Sameer Singh, Yanai Elazar |  |
| 449 |  |  [Grammar-based Data Augmentation for Low-Resource Languages: The Case of Guarani-Spanish Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.354) |  | 0 |  | Agustín Lucas, Alexis Baladón, Victoria Pardiñas, Marvin M. AgüeroTorales, Santiago Góngora, Luis Chiruzzo |  |
| 450 |  |  [Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.355) |  | 0 |  | Anjishnu Mukherjee, Aylin Caliskan, Ziwei Zhu, Antonios Anastasopoulos |  |
| 451 |  |  [Toward Interactive Regional Understanding in Vision-Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.356) |  | 0 |  | Jungbeom Lee, Sanghyuk Chun, Sangdoo Yun |  |
| 452 |  |  [ScriptMix: Mixing Scripts for Low-resource Language Parsing](https://doi.org/10.18653/v1/2024.naacl-long.357) |  | 0 |  | Jaeseong Lee, Dohyeon Lee, Seungwon Hwang |  |
| 453 |  |  [MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.358) |  | 0 |  | Jiahuan Li, Shanbo Cheng, Shujian Huang, Jiajun Chen |  |
| 454 |  |  [ToXCL: A Unified Framework for Toxic Speech Detection and Explanation](https://doi.org/10.18653/v1/2024.naacl-long.359) |  | 0 |  | Nhat M. Hoang, Xuan Long Do, Duc Anh Do, Duc Anh Vu, Anh Tuan Luu |  |
| 455 |  |  [LinkPrompt: Natural and Universal Adversarial Attacks on Prompt-based Language Models](https://doi.org/10.18653/v1/2024.naacl-long.360) |  | 0 |  | Yue Xu, Wenjie Wang |  |
| 456 |  |  [CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions](https://doi.org/10.18653/v1/2024.naacl-long.361) |  | 0 |  | Hanchong Zhang, Ruisheng Cao, Hongshen Xu, Lu Chen, Kai Yu |  |
| 457 |  |  [ContraDoc: Understanding Self-Contradictions in Documents with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.362) |  | 0 |  | Jierui Li, Vipul Raheja, Dhruv Kumar |  |
| 458 |  |  [Entity Disambiguation via Fusion Entity Decoding](https://doi.org/10.18653/v1/2024.naacl-long.363) |  | 0 |  | Junxiong Wang, Ali Mousavi, Omar Attia, Ronak Pradeep, Saloni Potdar, Alexander M. Rush, Umar Farooq Minhas, Yunyao Li |  |
| 459 |  |  [PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers](https://doi.org/10.18653/v1/2024.naacl-long.364) |  | 0 |  | Myeonghwa Lee, Seonho An, MinSoo Kim |  |
| 460 |  |  [GPTScore: Evaluate as You Desire](https://doi.org/10.18653/v1/2024.naacl-long.365) |  | 0 |  | Jinlan Fu, SeeKiong Ng, Zhengbao Jiang, Pengfei Liu |  |
| 461 |  |  [A Survey of Confidence Estimation and Calibration in Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.366) |  | 0 |  | Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, Iryna Gurevych |  |
| 462 |  |  [Not All Metrics Are Guilty: Improving NLG Evaluation by Diversifying References](https://doi.org/10.18653/v1/2024.naacl-long.367) |  | 0 |  | Tianyi Tang, Hongyuan Lu, Yuchen Jiang, Haoyang Huang, Dongdong Zhang, Wayne Xin Zhao, Tom Kocmi, Furu Wei |  |
| 463 |  |  [Separation and Fusion: A Novel Multiple Token Linking Model for Event Argument Extraction](https://doi.org/10.18653/v1/2024.naacl-long.368) |  | 0 |  | Jing Xu, Dandan Song, Siu Hui, Zhijing Wu, Meihuizi Jia, Hao Wang, Yanru Zhou, Changzhi Zhou, Ziyi Yang |  |
| 464 |  |  [The Integration of Semantic and Structural Knowledge in Knowledge Graph Entity Typing](https://doi.org/10.18653/v1/2024.naacl-long.369) |  | 0 |  | Muzhi Li, Minda Hu, Irwin King, Hofung Leung |  |
| 465 |  |  [ComCLIP: Training-Free Compositional Image and Text Matching](https://doi.org/10.18653/v1/2024.naacl-long.370) |  | 0 |  | Kenan Jiang, Xuehai He, Ruize Xu, Xin Wang |  |
| 466 |  |  [ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications](https://doi.org/10.18653/v1/2024.naacl-long.371) |  | 0 |  | Sotaro Takeshita, Tommaso Green, Ines Reinig, Kai Eckert, Simone Paolo Ponzetto |  |
| 467 |  |  [XAL: EXplainable Active Learning Makes Classifiers Better Low-resource Learners](https://doi.org/10.18653/v1/2024.naacl-long.372) |  | 0 |  | Yun Luo, Zhen Yang, Fandong Meng, Yingjie Li, Fang Guo, Qinglin Qi, Jie Zhou, Yue Zhang |  |
| 468 |  |  [LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?](https://doi.org/10.18653/v1/2024.naacl-long.373) |  | 0 |  | Yuchi Wang, Shuhuai Ren, Rundong Gao, Linli Yao, Qingyan Guo, Kaikai An, Jianhong Bai, Xu Sun |  |
| 469 |  |  [Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF](https://doi.org/10.18653/v1/2024.naacl-long.374) |  | 0 |  | Amey Hengle, Aswini Kumar, Sahajpreet Singh, Anil Bandhakavi, Md. Shad Akhtar, Tanmoy Chakraborty |  |
| 470 |  |  [Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey](https://doi.org/10.18653/v1/2024.naacl-long.375) |  | 0 |  | Zhichen Dong, Zhanhui Zhou, Chao Yang, Jing Shao, Yu Qiao |  |
| 471 |  |  [Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.376) |  | 0 |  | Weize Liu, Guocong Li, Kai Zhang, Bang Du, Qiyuan Chen, Xuming Hu, Hongxia Xu, Jintai Chen, Jian Wu |  |
| 472 |  |  [Divergent Token Metrics: Measuring degradation to prune away LLM components - and optimize quantization](https://doi.org/10.18653/v1/2024.naacl-long.377) |  | 0 |  | Björn Deiseroth, Max Meuer, Nikolas Gritsch, Constantin Eichenberg, Patrick Schramowski, Matthias Aßenmacher, Kristian Kersting |  |
| 473 |  |  [Beyond Performance: Quantifying and Mitigating Label Bias in LLMs](https://doi.org/10.18653/v1/2024.naacl-long.378) |  | 0 |  | Yuval Reif, Roy Schwartz |  |
| 474 |  |  [Instructing Large Language Models to Identify and Ignore Irrelevant Conditions](https://doi.org/10.18653/v1/2024.naacl-long.379) |  | 0 |  | Zhenyu Wu, Chao Shen, Meng Jiang |  |
| 475 |  |  [Lower Bounds on the Expressivity of Recurrent Neural Language Models](https://doi.org/10.18653/v1/2024.naacl-long.380) |  | 0 |  | Anej Svete, Franz Nowak, Anisha Mohamed Sahabdeen, Ryan Cotterell |  |
| 476 |  |  [Transformers Can Represent n-gram Language Models](https://doi.org/10.18653/v1/2024.naacl-long.381) |  | 0 |  | Anej Svete, Ryan Cotterell |  |
| 477 |  |  [The Role of n-gram Smoothing in the Age of Neural Networks](https://doi.org/10.18653/v1/2024.naacl-long.382) |  | 0 |  | Luca Malagutti, Andrius Buinovskij, Anej Svete, Clara Meister, Afra Amini, Ryan Cotterell |  |
| 478 |  |  [Reliability Estimation of News Media Sources: Birds of a Feather Flock Together](https://doi.org/10.18653/v1/2024.naacl-long.383) |  | 0 |  | Sergio Burdisso, Dairazalia SanchezCortes, Esaú VillatoroTello, Petr Motlícek |  |
| 479 |  |  [On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons](https://doi.org/10.18653/v1/2024.naacl-long.384) |  | 0 |  | Takeshi Kojima, Itsuki Okimura, Yusuke Iwasawa, Hitomi Yanaka, Yutaka Matsuo |  |
| 480 |  |  [NLP Progress in Indigenous Latin American Languages](https://doi.org/10.18653/v1/2024.naacl-long.385) |  | 0 |  | Atnafu Lambebo Tonja, Fazlourrahman Balouchzahi, Sabur Butt, Olga Kolesnikova, Hector G. Ceballos, Alexander F. Gelbukh, Thamar Solorio |  |
| 481 |  |  [On the Effectiveness of Adversarial Robustness for Abuse Mitigation with Counterspeech](https://doi.org/10.18653/v1/2024.naacl-long.386) |  | 0 |  | YiLing Chung, Jonathan Bright |  |
| 482 |  |  [Leveraging the Structure of Pre-trained Embeddings to Minimize Annotation Effort](https://doi.org/10.18653/v1/2024.naacl-long.387) |  | 0 |  | César GonzálezGutiérrez, Ariadna Quattoni |  |
| 483 |  |  [UniArk: Improving Generalisation and Consistency for Factual Knowledge Extraction through Debiasing](https://doi.org/10.18653/v1/2024.naacl-long.388) |  | 0 |  | Yijun Yang, Jie He, Pinzhen Chen, Víctor GutiérrezBasulto, Jeff Z. Pan |  |
| 484 |  |  [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://doi.org/10.18653/v1/2024.naacl-long.389) |  | 0 |  | Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, Jong Park |  |
| 485 |  |  [Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method](https://doi.org/10.18653/v1/2024.naacl-long.390) |  | 0 |  | Yukun Zhao, Lingyong Yan, Weiwei Sun, Guoliang Xing, Chong Meng, Shuaiqiang Wang, Zhicong Cheng, Zhaochun Ren, Dawei Yin |  |
| 486 |  |  [Are Large Language Model Temporally Grounded?](https://doi.org/10.18653/v1/2024.naacl-long.391) |  | 0 |  | Yifu Qiu, Zheng Zhao, Yftah Ziser, Anna Korhonen, Edoardo Maria Ponti, Shay B. Cohen |  |
| 487 |  |  [Document Image Machine Translation with Dynamic Multi-pre-trained Models Assembling](https://doi.org/10.18653/v1/2024.naacl-long.392) |  | 0 |  | Yupu Liang, Yaping Zhang, Cong Ma, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou |  |
| 488 |  |  [Elastic Weight Removal for Faithful and Abstractive Dialogue Generation](https://doi.org/10.18653/v1/2024.naacl-long.393) |  | 0 |  | Nico Daheim, Nouha Dziri, Mrinmaya Sachan, Iryna Gurevych, Edoardo M. Ponti |  |
| 489 |  |  [R-Tuning: Instructing Large Language Models to Say 'I Don't Know'](https://doi.org/10.18653/v1/2024.naacl-long.394) |  | 0 |  | Hanning Zhang, Shizhe Diao, Yong Lin, Yi R. Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, Tong Zhang |  |
| 490 |  |  [Bridging the Gap between Different Vocabularies for LLM Ensemble](https://doi.org/10.18653/v1/2024.naacl-long.395) |  | 0 |  | Yangyifan Xu, Jinliang Lu, Jiajun Zhang |  |
| 491 |  |  [KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation](https://doi.org/10.18653/v1/2024.naacl-long.396) |  | 0 |  | Xindi Luo, Zequn Sun, Jing Zhao, Zhe Zhao, Wei Hu |  |
| 492 |  |  [Extremely Weakly-supervised Text Classification with Wordsets Mining and Sync-Denoising](https://doi.org/10.18653/v1/2024.naacl-long.397) |  | 0 |  | Lysa Xiao |  |
| 493 |  |  [F-MALLOC: Feed-forward Memory Allocation for Continual Learning in Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.398) |  | 0 |  | Junhong Wu, Yuchen Liu, Chengqing Zong |  |
| 494 |  |  [Towards Reducing Diagnostic Errors with Interpretable Risk Prediction](https://doi.org/10.18653/v1/2024.naacl-long.399) |  | 0 |  | Denis Jered McInerney, William Dickinson, Lucy C. Flynn, Andrea Young, Geoffrey S. Young, JanWillem van de Meent, Byron C. Wallace |  |
| 495 |  |  [Generalizable Multilingual Hate Speech Detection on Low Resource Indian Languages using Fair Selection in Federated Learning](https://doi.org/10.18653/v1/2024.naacl-long.400) |  | 0 |  | Akshay Singh, Rahul Thakur |  |
| 496 |  |  [Key ingredients for effective zero-shot cross-lingual knowledge transfer in generative tasks](https://doi.org/10.18653/v1/2024.naacl-long.401) |  | 0 |  | Nadezhda Chirkova, Vassilina Nikoulina |  |
| 497 |  |  [The Impact of Depth on Compositional Generalization in Transformer Language Models](https://doi.org/10.18653/v1/2024.naacl-long.402) |  | 0 |  | Jackson Petty, Sjoerd van Steenkiste, Ishita Dasgupta, Fei Sha, Dan Garrette, Tal Linzen |  |
| 498 |  |  [Pregnant Questions: The Importance of Pragmatic Awareness in Maternal Health Question Answering](https://doi.org/10.18653/v1/2024.naacl-long.403) |  | 0 |  | Neha Srikanth, Rupak Sarkar, Heran Mane, Elizabeth Aparicio, Quynh C. Nguyen, Rachel Rudinger, Jordan L. BoydGraber |  |
| 499 |  |  [Towards Explainability in Legal Outcome Prediction Models](https://doi.org/10.18653/v1/2024.naacl-long.404) |  | 0 |  | Josef Valvoda, Ryan Cotterell |  |
| 500 |  |  [The steerability of large language models toward data-driven personas](https://doi.org/10.18653/v1/2024.naacl-long.405) |  | 0 |  | Junyi Li, Charith Peris, Ninareh Mehrabi, Palash Goyal, KaiWei Chang, Aram Galstyan, Richard S. Zemel, Rahul Gupta |  |
| 501 |  |  [CCSum: A Large-Scale and High-Quality Dataset for Abstractive News Summarization](https://doi.org/10.18653/v1/2024.naacl-long.406) |  | 0 |  | Xiang Jiang, Markus Dreyer |  |
| 502 |  |  [Capturing Perspectives of Crowdsourced Annotators in Subjective Learning Tasks](https://doi.org/10.18653/v1/2024.naacl-long.407) |  | 0 |  | Negar Mokhberian, Myrl G. Marmarelis, Frederic R. Hopp, Valerio Basile, Fred Morstatter, Kristina Lerman |  |
| 503 |  |  [Improving Factual Accuracy of Neural Table-to-Text Output by Addressing Input Problems in ToTTo](https://doi.org/10.18653/v1/2024.naacl-long.408) |  | 0 |  | Barkavi Sundararajan, Somayajulu Sripada, Ehud Reiter |  |
| 504 |  |  [CERET: Cost-Effective Extrinsic Refinement for Text Generation](https://doi.org/10.18653/v1/2024.naacl-long.409) |  | 0 |  | Jason Cai, Hang Su, Monica Sunkara, Igor Shalyminov, Saab Mansour |  |
| 505 |  |  [Parameter-Efficient Instruction Tuning of Large Language Models For Extreme Financial Numeral Labelling](https://doi.org/10.18653/v1/2024.naacl-long.410) |  | 0 |  | Subhendu Khatuya, Rajdeep Mukherjee, Akash Ghosh, Manjunath Hegde, Koustuv Dasgupta, Niloy Ganguly, Saptarshi Ghosh, Pawan Goyal |  |
| 506 |  |  [Analysis of State-Level Legislative Process in Enhanced Linguistic and Nationwide Network Contexts](https://doi.org/10.18653/v1/2024.naacl-long.411) |  | 0 |  | Maryam Davoodi, Dan Goldwasser |  |
| 507 |  |  [DeMuX: Data-efficient Multilingual Learning](https://doi.org/10.18653/v1/2024.naacl-long.412) |  | 0 |  | Simran Khanuja, Srinivas Gowriraj, Lucio M. Dery, Graham Neubig |  |
| 508 |  |  [DUQGen: Effective Unsupervised Domain Adaptation of Neural Rankers by Diversifying Synthetic Query Generation](https://doi.org/10.18653/v1/2024.naacl-long.413) |  | 0 |  | Ramraj Chandradevan, Kaustubh D. Dhole, Eugene Agichtein |  |
| 509 |  |  [How did we get here? Summarizing conversation dynamics](https://doi.org/10.18653/v1/2024.naacl-long.414) |  | 0 |  | Yilun Hua, Nicholas Chernogor, Yuzhe Gu, Seoyeon Julie Jeong, Miranda Luo, Cristian DanescuNiculescuMizil |  |
| 510 |  |  [Can Language Model Moderators Improve the Health of Online Discourse?](https://doi.org/10.18653/v1/2024.naacl-long.415) |  | 0 |  | Hyundong Cho, Shuai Liu, Taiwei Shi, Darpan Jain, Basem Rizk, Yuyang Huang, Zixun Lu, Nuan Wen, Jonathan Gratch, Emilio Ferrara, Jonathan May |  |
| 511 |  |  [LeanReasoner: Boosting Complex Logical Reasoning with Lean](https://doi.org/10.18653/v1/2024.naacl-long.416) |  | 0 |  | Dongwei Jiang, Marcio Fonseca, Shay B. Cohen |  |
| 512 |  |  [UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback](https://doi.org/10.18653/v1/2024.naacl-long.417) |  | 0 |  | Jason Wu, Eldon Schoop, Alan Leung, Titus Barik, Jeffrey P. Bigham, Jeffrey Nichols |  |
| 513 |  |  [Measuring Cross-lingual Transfer in Bytes](https://doi.org/10.18653/v1/2024.naacl-long.418) |  | 0 |  | Leandro Rodrigues de Souza, Thales Sales Almeida, Roberto A. Lotufo, Rodrigo Frassetto Nogueira |  |
| 514 |  |  [MisgenderMender: A Community-Informed Approach to Interventions for Misgendering](https://doi.org/10.18653/v1/2024.naacl-long.419) |  | 0 |  | Tamanna Hossain, Sunipa Dev, Sameer Singh |  |
| 515 |  |  [Interplay of Machine Translation, Diacritics, and Diacritization](https://doi.org/10.18653/v1/2024.naacl-long.420) |  | 0 |  | WeiRui Chen, Ife Adebara, Muhammad AbdulMageed |  |
| 516 |  |  [From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning](https://doi.org/10.18653/v1/2024.naacl-long.421) |  | 0 |  | Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, Jing Xiao |  |
| 517 |  |  [Safer-Instruct: Aligning Language Models with Automated Preference Data](https://doi.org/10.18653/v1/2024.naacl-long.422) |  | 0 |  | Taiwei Shi, Kai Chen, Jieyu Zhao |  |
| 518 |  |  [PELMS: Pre-training for Effective Low-Shot Multi-Document Summarization](https://doi.org/10.18653/v1/2024.naacl-long.423) |  | 0 |  | Joseph Peper, Wenzhao Qiu, Lu Wang |  |
| 519 |  |  [Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?](https://doi.org/10.18653/v1/2024.naacl-long.424) |  | 0 |  | Bangzheng Li, Ben Zhou, Fei Wang, Xingyu Fu, Dan Roth, Muhao Chen |  |
| 520 |  |  [IndiSentiment140: Sentiment Analysis Dataset for Indian Languages with Emphasis on Low-Resource Languages using Machine Translation](https://doi.org/10.18653/v1/2024.naacl-long.425) |  | 0 |  | Saurabh Kumar, Sanasam Ranbir Sanasam, Sukumar Nandi |  |
| 521 |  |  [Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval](https://doi.org/10.18653/v1/2024.naacl-long.426) |  | 0 |  | Nandan Thakur, Jianmo Ni, Gustavo Hernández Ábrego, John Wieting, Jimmy Lin, Daniel Cer |  |
| 522 |  |  [SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities](https://doi.org/10.18653/v1/2024.naacl-long.427) |  | 0 |  | Hyunjong Ok, Taeho Kil, Sukmin Seo, Jaeho Lee |  |
| 523 |  |  [A Theory Guided Scaffolding Instruction Framework for LLM-Enabled Metaphor Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.428) |  | 0 |  | Yuan Tian, Nan Xu, Wenji Mao |  |
| 524 |  |  [Learning to Compress Prompt in Natural Language Formats](https://doi.org/10.18653/v1/2024.naacl-long.429) |  | 0 |  | YuNeng Chuang, Tianwei Xing, ChiaYuan Chang, Zirui Liu, Xun Chen, Xia Ben Hu |  |
| 525 |  |  [Automatic, Meta and Human Evaluation for Multimodal Summarization with Multimodal Output](https://doi.org/10.18653/v1/2024.naacl-long.430) |  | 0 |  | Haojie Zhuang, Wei Emma Zhang, Leon Xie, Weitong Chen, Jian Yang, Quan Sheng |  |
| 526 |  |  [Naive Bayes-based Context Extension for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.431) |  | 0 |  | Jianlin Su, Murtadha H. M. Ahmed, Bo Wen, Luo Ao, Mingren Zhu, Yunfeng Liu |  |
| 527 |  |  [Leitner-Guided Memory Replay for Cross-lingual Continual Learning](https://doi.org/10.18653/v1/2024.naacl-long.432) |  | 0 |  | Meryem M'hamdi, Jonathan May |  |
| 528 |  |  [Multilingual Nonce Dependency Treebanks: Understanding how Language Models Represent and Process Syntactic Structure](https://doi.org/10.18653/v1/2024.naacl-long.433) |  | 0 |  | David Arps, Laura Kallmeyer, Younes Samih, Hassan Sajjad |  |
| 529 |  |  [Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery](https://doi.org/10.18653/v1/2024.naacl-long.434) |  | 0 |  | Jinggui Liang, Lizi Liao, Hao Fei, Bobo Li, Jing Jiang |  |
| 530 |  |  [Explaining Text Similarity in Transformer Models](https://doi.org/10.18653/v1/2024.naacl-long.435) |  | 0 |  | Alexandros Vasileiou, Oliver Eberle |  |
| 531 |  |  [Large Language Models can Contrastively Refine their Generation for Better Sentence Representation Learning](https://doi.org/10.18653/v1/2024.naacl-long.436) |  | 0 |  | Huiming Wang, Zhaodonghui Li, Liying Cheng, De Wen Soh, Lidong Bing |  |
| 532 |  |  [HIL: Hybrid Isotropy Learning for Zero-shot Performance in Dense retrieval](https://doi.org/10.18653/v1/2024.naacl-long.437) |  | 0 |  | Jaeyoung Kim, Dohyeon Lee, Seungwon Hwang |  |
| 533 |  |  [SuperGLEBer: German Language Understanding Evaluation Benchmark](https://doi.org/10.18653/v1/2024.naacl-long.438) |  | 0 |  | Jan Pfister, Andreas Hotho |  |
| 534 |  |  ["You are an expert annotator": Automatic Best-Worst-Scaling Annotations for Emotion Intensity Modeling](https://doi.org/10.18653/v1/2024.naacl-long.439) |  | 0 |  | Christopher Bagdon, Prathamesh Karmalkar, Harsha Gurulingappa, Roman Klinger |  |
| 535 |  |  [What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?](https://doi.org/10.18653/v1/2024.naacl-long.440) |  | 0 |  | Yan Zeng, Hanbo Zhang, Jiani Zheng, Jiangnan Xia, Guoqiang Wei, Yang Wei, Yuchen Zhang, Tao Kong, Ruihua Song |  |
| 536 |  |  [Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation](https://doi.org/10.18653/v1/2024.naacl-long.441) |  | 0 |  | Jie Ruan, Wenqing Wang, Xiaojun Wan |  |
| 537 |  |  [MOSAICo: a Multilingual Open-text Semantically Annotated Interlinked Corpus](https://doi.org/10.18653/v1/2024.naacl-long.442) |  | 0 |  | Simone Conia, Edoardo Barba, Abelardo Carlos Martinez Lorenzo, PereLluís Huguet Cabot, Riccardo Orlando, Luigi Procopio, Roberto Navigli |  |
| 538 |  |  [SemRoDe: Macro Adversarial Training to Learn Representations that are Robust to Word-Level Attacks](https://doi.org/10.18653/v1/2024.naacl-long.443) |  | 0 |  | Brian Formento, Wenjie Feng, ChuanSheng Foo, Anh Tuan Luu, SeeKiong Ng |  |
| 539 |  |  [BUST: Benchmark for the evaluation of detectors of LLM-Generated Text](https://doi.org/10.18653/v1/2024.naacl-long.444) |  | 0 |  | Joseph Cornelius, Oscar LithgowSerrano, Sandra Mitrovic, Ljiljana Dolamic, Fabio Rinaldi |  |
| 540 |  |  [Improving In-context Learning of Multilingual Generative Language Models with Cross-lingual Alignment](https://doi.org/10.18653/v1/2024.naacl-long.445) |  | 0 |  | Chong Li, Shaonan Wang, Jiajun Zhang, Chengqing Zong |  |
| 541 |  |  [MaCSC: Towards Multimodal-augmented Pre-trained Language Models via Conceptual Prototypes and Self-balancing Calibration](https://doi.org/10.18653/v1/2024.naacl-long.446) |  | 0 |  | Xianwei Zhuang, Zhichang Wang, Xuxin Cheng, Yuxin Xie, Liming Liang, Yuexian Zou |  |
| 542 |  |  [Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?](https://doi.org/10.18653/v1/2024.naacl-long.447) |  | 0 |  | Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe |  |
| 543 |  |  [Discovering Lobby-Parliamentarian Alignments through NLP](https://doi.org/10.18653/v1/2024.naacl-long.448) |  | 0 |  | Aswin Suresh, Lazar Radojevic, Francesco Salvi, Antoine Magron, Victor Kristof, Matthias Grossglauser |  |
| 544 |  |  [IterCQR: Iterative Conversational Query Reformulation with Retrieval Guidance](https://doi.org/10.18653/v1/2024.naacl-long.449) |  | 0 |  | Yunah Jang, Kangil Lee, Hyunkyung Bae, Hwanhee Lee, Kyomin Jung |  |
| 545 |  |  [AceGPT, Localizing Large Language Models in Arabic](https://doi.org/10.18653/v1/2024.naacl-long.450) |  | 0 |  | Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen, Mosen Alharthi, Bang An, Juncai He, Ziche Liu, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu |  |
| 546 |  |  [Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model](https://doi.org/10.18653/v1/2024.naacl-long.451) |  | 0 |  | Zhiwei He, Xing Wang, Wenxiang Jiao, Zhuosheng Zhang, Rui Wang, Shuming Shi, Zhaopeng Tu |  |
| 547 |  |  [Depression Detection in Clinical Interviews with LLM-Empowered Structural Element Graph](https://doi.org/10.18653/v1/2024.naacl-long.452) |  | 0 |  | Zhuang Chen, Jiawen Deng, Jinfeng Zhou, Jincenzi Wu, Tieyun Qian, Minlie Huang |  |
| 548 |  |  [SQATIN: Supervised Instruction Tuning Meets Question Answering for Improved Dialogue NLU](https://doi.org/10.18653/v1/2024.naacl-long.453) |  | 0 |  | Evgeniia Razumovskaia, Goran Glavas, Anna Korhonen, Ivan Vulic |  |
| 549 |  |  [Enhancing Argument Summarization: Prioritizing Exhaustiveness in Key Point Generation and Introducing an Automatic Coverage Evaluation Metric](https://doi.org/10.18653/v1/2024.naacl-long.454) |  | 0 |  | Mohammad Khosravani, Chenyang Huang, Amine Trabelsi |  |
| 550 |  |  [ARM: Alignment with Residual Energy-Based Model](https://doi.org/10.18653/v1/2024.naacl-long.455) |  | 0 |  | Bo Pang, Caiming Xiong, Yingbo Zhou |  |
| 551 |  |  [HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants](https://doi.org/10.18653/v1/2024.naacl-long.456) |  | 0 |  | Milan Gritta, Gerasimos Lampouras, Ignacio Iacobacci |  |
| 552 |  |  [FAMuS: Frames Across Multiple Sources](https://doi.org/10.18653/v1/2024.naacl-long.457) |  | 0 |  | Siddharth Vashishtha, Alexander Martin, William Gantt, Benjamin Van Durme, Aaron Steven White |  |
| 553 |  |  [Rationale-based Opinion Summarization](https://doi.org/10.18653/v1/2024.naacl-long.458) |  | 0 |  | Haoyuan Li, Snigdha Chaturvedi |  |
| 554 |  |  [Mustango: Toward Controllable Text-to-Music Generation](https://doi.org/10.18653/v1/2024.naacl-long.459) |  | 0 |  | Jan Melechovský, Zixun Guo, Deepanway Ghosal, Navonil Majumder, Dorien Herremans, Soujanya Poria |  |
| 555 |  |  [Adaptive Cross-lingual Text Classification through In-Context One-Shot Demonstrations](https://doi.org/10.18653/v1/2024.naacl-long.460) |  | 0 |  | Emilio VillaCueva, Adrián Pastor LópezMonroy, Fernando SánchezVega, Thamar Solorio |  |
| 556 |  |  [CNER: Concept and Named Entity Recognition](https://doi.org/10.18653/v1/2024.naacl-long.461) |  | 0 |  | Giuliano Martinelli, Francesco Molfese, Simone Tedeschi, Alberte FernándezCastro, Roberto Navigli |  |
| 557 |  |  [Branch-Solve-Merge Improves Large Language Model Evaluation and Generation](https://doi.org/10.18653/v1/2024.naacl-long.462) |  | 0 |  | Swarnadeep Saha, Omer Levy, Asli Celikyilmaz, Mohit Bansal, Jason Weston, Xian Li |  |
| 558 |  |  [REPLUG: Retrieval-Augmented Black-Box Language Models](https://doi.org/10.18653/v1/2024.naacl-long.463) |  | 0 |  | Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Richard James, Mike Lewis, Luke Zettlemoyer, Wentau Yih |  |
| 559 |  |  [David helps Goliath: Inference-Time Collaboration Between Small Specialized and Large General Diffusion LMs](https://doi.org/10.18653/v1/2024.naacl-long.464) |  | 0 |  | Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad |  |
| 560 |  |  [Efficient End-to-End Visual Document Understanding with Rationale Distillation](https://doi.org/10.18653/v1/2024.naacl-long.465) |  | 0 |  | Wang Zhu, Alekh Agarwal, Mandar Joshi, Robin Jia, Jesse Thomason, Kristina Toutanova |  |
| 561 |  |  [A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models](https://doi.org/10.18653/v1/2024.naacl-long.466) |  | 0 |  | Tiwalayo Eisape, Michael Henry Tessler, Ishita Dasgupta, Fei Sha, Sjoerd van Steenkiste, Tal Linzen |  |
| 562 |  |  [AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets](https://doi.org/10.18653/v1/2024.naacl-long.467) |  | 0 |  | Pietro Lesci, Andreas Vlachos |  |
| 563 |  |  [ICLE++: Modeling Fine-Grained Traits for Holistic Essay Scoring](https://doi.org/10.18653/v1/2024.naacl-long.468) |  | 0 |  | Shengjie Li, Vincent Ng |  |
| 564 |  |  [UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations](https://doi.org/10.18653/v1/2024.naacl-long.469) |  | 0 |  | Wenting Zhao, Justin T. Chiu, Jena D. Hwang, Faeze Brahman, Jack Hessel, Sanjiban Choudhury, Yejin Choi, Xiang Li, Alane Suhr |  |
| 565 |  |  [To Tell The Truth: Language of Deception and Language Models](https://doi.org/10.18653/v1/2024.naacl-long.470) |  | 0 |  | Sanchaita Hazra, Bodhisattwa Prasad Majumder |  |
| 566 |  |  [Multilingual Models for ASR in Chibchan Languages](https://doi.org/10.18653/v1/2024.naacl-long.471) |  | 0 |  | Rolando CotoSolano, TaiWan Kim, Alexander Jones, Sharid Loáiciga |  |
| 567 |  |  [LegalDiscourse: Interpreting When Laws Apply and To Whom](https://doi.org/10.18653/v1/2024.naacl-long.472) |  | 0 |  | Alexander Spangher, Zihan Xue, TeLin Wu, Mark Hansen, Jonathan May |  |
| 568 |  |  [X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented Instruction Tuning with Auxiliary Evaluation Aspects](https://doi.org/10.18653/v1/2024.naacl-long.473) |  | 0 |  | Minqian Liu, Ying Shen, Zhiyang Xu, Yixin Cao, Eunah Cho, Vaibhav Kumar, Reza Ghanadan, Lifu Huang |  |
| 569 |  |  [Is Reference Necessary in the Evaluation of NLG Systems? When and Where?](https://doi.org/10.18653/v1/2024.naacl-long.474) |  | 0 |  | Shuqian Sheng, Yi Xu, Luoyi Fu, Jiaxin Ding, Lei Zhou, Xinbing Wang, Chenghu Zhou |  |
| 570 |  |  [Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning](https://doi.org/10.18653/v1/2024.naacl-long.475) |  | 0 |  | Xin Su, Tiep Le, Steven Bethard, Phillip Howard |  |
| 571 |  |  [Evaluating the Deductive Competence of Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.476) |  | 0 |  | S. M. Seals, Valerie L. Shalin |  |
| 572 |  |  [Large Human Language Models: A Need and the Challenges](https://doi.org/10.18653/v1/2024.naacl-long.477) |  | 0 |  | Nikita Soni, H. Andrew Schwartz, João Sedoc, Niranjan Balasubramanian |  |
| 573 |  |  [On Learning to Summarize with Large Language Models as References](https://doi.org/10.18653/v1/2024.naacl-long.478) |  | 0 |  | Yixin Liu, Kejian Shi, Katherine He, Longtian Ye, Alexander R. Fabbri, Pengfei Liu, Dragomir Radev, Arman Cohan |  |
| 574 |  |  [Hallucination Diversity-Aware Active Learning for Text Summarization](https://doi.org/10.18653/v1/2024.naacl-long.479) |  | 0 |  | Yu Xia, Xu Liu, Tong Yu, Sungchul Kim, Ryan A. Rossi, Anup B. Rao, Tung Mai, Shuai Li |  |
| 575 |  |  [Keep it Private: Unsupervised Privatization of Online Text](https://doi.org/10.18653/v1/2024.naacl-long.480) |  | 0 |  | Calvin Bao, Marine Carpuat |  |
| 576 |  |  [Tied-LoRA: Enhancing parameter efficiency of LoRA with Weight Tying](https://doi.org/10.18653/v1/2024.naacl-long.481) |  | 0 |  | Adithya Renduchintala, Tugrul Konuk, Oleksii Kuchaiev |  |
| 577 |  |  [Investigating Data Contamination in Modern Benchmarks for Large Language Models](https://doi.org/10.18653/v1/2024.naacl-long.482) |  | 0 |  | Chunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Gerstein, Arman Cohan |  |
| 578 |  |  [Pre-trained Language Models for Entity Blocking: A Reproducibility Study](https://doi.org/10.18653/v1/2024.naacl-long.483) |  | 0 |  | Runhui Wang, Yongfeng Zhang |  |
| 579 |  |  [RE²: Region-Aware Relation Extraction from Visually Rich Documents](https://doi.org/10.18653/v1/2024.naacl-long.484) |  | 0 |  | Pritika Ramu, Sijia Wang, Lalla Mouatadid, Joy Rimchala, Lifu Huang |  |
| 580 |  |  [Mix-Initiative Response Generation with Dynamic Prefix Tuning](https://doi.org/10.18653/v1/2024.naacl-long.485) |  | 0 |  | Yuxiang Nie, Heyan Huang, XianLing Mao, Lizi Liao |  |
| 581 |  |  [Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Value](https://doi.org/10.18653/v1/2024.naacl-long.486) |  | 0 |  | Jing Yao, Xiaoyuan Yi, Yifan Gong, Xiting Wang, Xing Xie |  |
| 582 |  |  [IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context](https://doi.org/10.18653/v1/2024.naacl-long.487) |  | 0 |  | Nihar R. Sahoo, Pranamya Prashant Kulkarni, Arif Ahmad, Tanu Goyal, Narjis Asad, Aparna Garimella, Pushpak Bhattacharyya |  |
| 583 |  |  [Findings of the Association for Computational Linguistics: NAACL 2024, Mexico City, Mexico, June 16-21, 2024](https://aclanthology.org/volumes/2024.findings-naacl/) |  | 0 |  | Kevin Duh, Helena GómezAdorno, Steven Bethard |  |
| 584 |  |  [Structured Pruning for Large Language Models Using Coupled Components Elimination and Minor Fine-tuning](https://doi.org/10.18653/v1/2024.findings-naacl.1) |  | 0 |  | Honghe Zhang, Xiaolong Shi, Jingwei Sun, Guangzhong Sun |  |
| 585 |  |  [Weight-Inherited Distillation for Task-Agnostic BERT Compression](https://doi.org/10.18653/v1/2024.findings-naacl.2) |  | 0 |  | Taiqiang Wu, Cheng Hou, Shanshan Lao, Jiayi Li, Ngai Wong, Zhe Zhao, Yujiu Yang |  |
| 586 |  |  [Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for Pretraining on the Cybersecurity Domain](https://doi.org/10.18653/v1/2024.findings-naacl.3) |  | 0 |  | Eugene Jang, Jian Cui, Dayeon Yim, Youngjin Jin, JinWoo Chung, Seungwon Shin, Yongjae Lee |  |
| 587 |  |  [Extremely efficient online query encoding for dense retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.4) |  | 0 |  | Nachshon Cohen, Yaron Fairstein, Guy Kushilevitz |  |
| 588 |  |  [DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain Question Answering over Knowledge Base and Text](https://doi.org/10.18653/v1/2024.findings-naacl.5) |  | 0 |  | Wenting Zhao, Ye Liu, Tong Niu, Yao Wan, Philip S. Yu, Shafiq Joty, Yingbo Zhou, Semih Yavuz |  |
| 589 |  |  [SpeedE: Euclidean Geometric Knowledge Graph Embedding Strikes Back](https://doi.org/10.18653/v1/2024.findings-naacl.6) |  | 0 |  | Aleksandar Pavlovic, Emanuel Sallinger |  |
| 590 |  |  [Language Guided Exploration for RL Agents in Text Environments](https://doi.org/10.18653/v1/2024.findings-naacl.7) |  | 0 |  | Hitesh Golchha, Sahil Yerawar, Dhruvesh Patel, Soham Dan, Keerthiram Murugesan |  |
| 591 |  |  [GPT-who: An Information Density-based Machine-Generated Text Detector](https://doi.org/10.18653/v1/2024.findings-naacl.8) |  | 0 |  | Saranya Venkatraman, Adaku Uchendu, Dongwon Lee |  |
| 592 |  |  [DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder Transformer Models](https://doi.org/10.18653/v1/2024.findings-naacl.9) |  | 0 |  | Peng Tang, Pengkai Zhu, Tian Li, Srikar Appalaraju, Vijay Mahadevan, R. Manmatha |  |
| 593 |  |  [Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation](https://doi.org/10.18653/v1/2024.findings-naacl.10) |  | 0 |  | TaChung Chi, TingHan Fan, Alexander Rudnicky |  |
| 594 |  |  [Automatic Pair Construction for Contrastive Post-training](https://doi.org/10.18653/v1/2024.findings-naacl.11) |  | 0 |  | Canwen Xu, Corby Rosset, Ethan C. Chau, Luciano Del Corro, Shweti Mahajan, Julian J. McAuley, Jennifer Neville, Ahmed Awadallah, Nikhil Rao |  |
| 595 |  |  [Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.12) |  | 0 |  | Miaoran Li, Baolin Peng, Michel Galley, Jianfeng Gao, Zhu Zhang |  |
| 596 |  |  [Low-resource neural machine translation with morphological modeling](https://doi.org/10.18653/v1/2024.findings-naacl.13) |  | 0 |  | Antoine Nzeyimana |  |
| 597 |  |  [Self-Cleaning: Improving a Named Entity Recognizer Trained on Noisy Data with a Few Clean Instances](https://doi.org/10.18653/v1/2024.findings-naacl.14) |  | 0 |  | Zhendong Chu, Ruiyi Zhang, Tong Yu, Rajiv Jain, Vlad I. Morariu, Jiuxiang Gu, Ani Nenkova |  |
| 598 |  |  [VLUE: A New Benchmark and Multi-task Knowledge Transfer Learning for Vietnamese Natural Language Understanding](https://doi.org/10.18653/v1/2024.findings-naacl.15) |  | 0 |  | Phong Do, Son Tran, Phu Hoang, Kiet Van Nguyen, Ngan LuuThuy Nguyen |  |
| 599 |  |  [LETI: Learning to Generate from Textual Interactions](https://doi.org/10.18653/v1/2024.findings-naacl.16) |  | 0 |  | Xingyao Wang, Hao Peng, Reyhaneh Jabbarvand, Heng Ji |  |
| 600 |  |  [Bilateral Masking with prompt for Knowledge Graph Completion](https://doi.org/10.18653/v1/2024.findings-naacl.17) |  | 0 |  | Yonghui Kong, Cunhang Fan, Yujie Chen, Shuai Zhang, Zhao Lv, Jianhua Tao |  |
| 601 |  |  [MiLe Loss: a New Loss for Mitigating the Bias of Learning Difficulties in Generative Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.18) |  | 0 |  | Zhenpeng Su, Zijia Lin, Bai Xue, Hui Chen, Guiguang Ding, Wei Zhou, Songlin Hu |  |
| 602 |  |  [GOLD: Geometry Problem Solver with Natural Language Description](https://doi.org/10.18653/v1/2024.findings-naacl.19) |  | 0 |  | Jiaxin Zhang, Yashar Moshfeghi |  |
| 603 |  |  [RoDia: A New Dataset for Romanian Dialect Identification from Speech](https://doi.org/10.18653/v1/2024.findings-naacl.20) |  | 0 |  | Rotaru Codrut, NicolaeCatalin Ristea, Radu Tudor Ionescu |  |
| 604 |  |  [Examining Modularity in Multilingual LMs via Language-Specialized Subnetworks](https://doi.org/10.18653/v1/2024.findings-naacl.21) |  | 0 |  | Rochelle Choenni, Ekaterina Shutova, Dan Garrette |  |
| 605 |  |  [Reverse Chain: A Generic-Rule for LLMs to Master Multi-API Planning](https://doi.org/10.18653/v1/2024.findings-naacl.22) |  | 0 |  | Yinger Zhang, Hui Cai, Xierui Song, Yicheng Chen, Rui Sun, Jing Zheng |  |
| 606 |  |  [Incorporating Exponential Smoothing into MLP: a Simple but Effective Sequence Model](https://doi.org/10.18653/v1/2024.findings-naacl.23) |  | 0 |  | Jiqun Chu, Zuoquan Lin |  |
| 607 |  |  [OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models](https://doi.org/10.18653/v1/2024.findings-naacl.24) |  | 0 |  | Yuxuan Kuang, Hai Lin, Meng Jiang |  |
| 608 |  |  [Comparing Two Model Designs for Clinical Note Generation; Is an LLM a Useful Evaluator of Consistency?](https://doi.org/10.18653/v1/2024.findings-naacl.25) |  | 0 |  | Nathan Brake, Thomas Schaaf |  |
| 609 |  |  [VOLTA: Improving Generative Diversity by Variational Mutual Information Maximizing Autoencoder](https://doi.org/10.18653/v1/2024.findings-naacl.26) |  | 0 |  | Yueen Ma, Dafeng Chi, Jingjing Li, Kai Song, Yuzheng Zhuang, Irwin King |  |
| 610 |  |  [EcoSpeak: Cost-Efficient Bias Mitigation for Partially Cross-Lingual Speaker Verification](https://doi.org/10.18653/v1/2024.findings-naacl.27) |  | 0 |  | Divya V. Sharma |  |
| 611 |  |  [Leveraging Contextual Information for Effective Entity Salience Detection](https://doi.org/10.18653/v1/2024.findings-naacl.28) |  | 0 |  | Rajarshi Bhowmik, Marco Ponza, Atharva Tendle, Anant Gupta, Rebecca Jiang, Xingyu Lu, Qian Zhao, Daniel PreotiucPietro |  |
| 612 |  |  [LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?](https://doi.org/10.18653/v1/2024.findings-naacl.29) |  | 0 |  | Qihui Zhang, Chujie Gao, Dongping Chen, Yue Huang, Yixin Huang, Zhenyang Sun, Shilin Zhang, Weiye Li, Zhengyan Fu, Yao Wan, Lichao Sun |  |
| 613 |  |  [A (More) Realistic Evaluation Setup for Generalisation of Community Models on Malicious Content Detection](https://doi.org/10.18653/v1/2024.findings-naacl.30) |  | 0 |  | Ivo Verhoeven, Pushkar Mishra, Rahel Beloch, Helen Yannakoudakis, Ekaterina Shutova |  |
| 614 |  |  [Citation: A Key to Building Responsible and Accountable Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.31) |  | 0 |  | Jie Huang, Kevin Chang |  |
| 615 |  |  [Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational AutoEncoders](https://doi.org/10.18653/v1/2024.findings-naacl.32) |  | 0 |  | Yingji Zhang, Marco Valentino, Danilo S. Carvalho, Ian PrattHartmann, André Freitas |  |
| 616 |  |  [Narrowing the Gap between Zero- and Few-shot Machine Translation by Matching Styles](https://doi.org/10.18653/v1/2024.findings-naacl.33) |  | 0 |  | Weiting Tan, Haoran Xu, Lingfeng Shen, Shuyue Stella Li, Kenton Murray, Philipp Koehn, Benjamin Van Durme, Yunmo Chen |  |
| 617 |  |  [Which Modality should I use - Text, Motif, or Image? : Understanding Graphs with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.34) |  | 0 |  | Debarati Das, Ishaan Gupta, Jaideep Srivastava, Dongyeop Kang |  |
| 618 |  |  [On-the-Fly Fusion of Large Language Models and Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.35) |  | 0 |  | Hieu Hoang, Huda Khayrallah, Marcin JunczysDowmunt |  |
| 619 |  |  [READ: Improving Relation Extraction from an ADversarial Perspective](https://doi.org/10.18653/v1/2024.findings-naacl.36) |  | 0 |  | Dawei Li, William Hogan, Jingbo Shang |  |
| 620 |  |  [REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.37) |  | 0 |  | Sana Ebrahimi, Nima Shahbazi, Abolfazl Asudeh |  |
| 621 |  |  [Addressing Both Statistical and Causal Gender Fairness in NLP Models](https://doi.org/10.18653/v1/2024.findings-naacl.38) |  | 0 |  | Hannah Chen, Yangfeng Ji, David Evans |  |
| 622 |  |  [LLM-Rec: Personalized Recommendation via Prompting Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.39) |  | 0 |  | Hanjia Lyu, Song Jiang, Hanqing Zeng, Yinglong Xia, Qifan Wang, Si Zhang, Ren Chen, Christopher Leung, Jiajie Tang, Jiebo Luo |  |
| 623 |  |  [A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://doi.org/10.18653/v1/2024.findings-naacl.40) |  | 0 |  | Jie Ren, Han Xu, Yiding Liu, Yingqian Cui, Shuaiqiang Wang, Dawei Yin, Jiliang Tang |  |
| 624 |  |  [Solving Data-centric Tasks using Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.41) |  | 0 |  | Shraddha Barke, Christian Pölitz, Carina Negreanu, Benjamin Zorn, José Cambronero, Andrew D. Gordon, Vu Le, Elnaz Nouri, Nadia Polikarpova, Advait Sarkar, Brian Slininger, Neil Toronto, Jack Williams |  |
| 625 |  |  [A Novel Paradigm Boosting Translation Capabilities of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.42) |  | 0 |  | Jiaxin Guo, Hao Yang, Zongyao Li, Daimeng Wei, Hengchao Shang, Xiaoyu Chen |  |
| 626 |  |  [Measuring Social Norms of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.43) |  | 0 |  | Ye Yuan, Kexin Tang, Jianhao Shen, Ming Zhang, Chenguang Wang |  |
| 627 |  |  [Source-Free Unsupervised Domain Adaptation for Question Answering via Prompt-Assisted Self-learning](https://doi.org/10.18653/v1/2024.findings-naacl.44) |  | 0 |  | Maxwell Yin, Boyu Wang, Charles Ling |  |
| 628 |  |  [Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level](https://doi.org/10.18653/v1/2024.findings-naacl.45) |  | 0 |  | Chenlong Zhao, Xiwen Zhou, Xiaopeng Xie, Yong Zhang |  |
| 629 |  |  [LEEETs-Dial: Linguistic Entrainment in End-to-End Task-oriented Dialogue systems](https://doi.org/10.18653/v1/2024.findings-naacl.46) |  | 0 |  | Nalin Kumar, Ondrej Dusek |  |
| 630 |  |  [Efficient Dependency Tree Sampling Without Replacement](https://doi.org/10.18653/v1/2024.findings-naacl.47) |  | 0 |  | Bogdan Dobre |  |
| 631 |  |  [Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization](https://doi.org/10.18653/v1/2024.findings-naacl.48) |  | 0 |  | Zixuan Zhang, Revanth Gangi Reddy, Kevin Small, Tong Zhang, Heng Ji |  |
| 632 |  |  [GEE! Grammar Error Explanation with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.49) |  | 0 |  | Yixiao Song, Kalpesh Krishna, Rajesh Bhatt, Kevin Gimpel, Mohit Iyyer |  |
| 633 |  |  [AdaRefiner: Refining Decisions of Language Models with Adaptive Feedback](https://doi.org/10.18653/v1/2024.findings-naacl.50) |  | 0 |  | Wanpeng Zhang, Zongqing Lu |  |
| 634 |  |  [DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented Dialogue Representations](https://doi.org/10.18653/v1/2024.findings-naacl.51) |  | 0 |  | Weihao Zeng, Dayuan Fu, Keqing He, Yejie Wang, Yukai Xu, Weiran Xu |  |
| 635 |  |  [Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training](https://doi.org/10.18653/v1/2024.findings-naacl.52) |  | 0 |  | Pavel Denisov, Thang Vu |  |
| 636 |  |  [CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.53) |  | 0 |  | Wenhong Zhu, Hongkun Hao, Zhiwei He, Yunze Song, Jiao Yueyang, Yumeng Zhang, Hanxu Hu, Yiran Wei, Rui Wang, Hongyuan Lu |  |
| 637 |  |  [R-BASS : Relevance-aided Block-wise Adaptation for Speech Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.54) |  | 0 |  | Roshan Sharma, Ruchira Sharma, Hira Dhamyal, Rita Singh, Bhiksha Raj |  |
| 638 |  |  [OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.55) |  | 0 |  | Fei Yu, Anningzhe Gao, Benyou Wang |  |
| 639 |  |  [The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation](https://doi.org/10.18653/v1/2024.findings-naacl.56) |  | 0 |  | Lei Wang, EePeng Lim |  |
| 640 |  |  [Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA](https://doi.org/10.18653/v1/2024.findings-naacl.57) |  | 0 |  | Dhruv Agarwal, Rajarshi Das, Sopan Khosla, Rashmi Gangadharaiah |  |
| 641 |  |  [GraSAME: Injecting Token-Level Structural Information to Pretrained Language Models via Graph-guided Self-Attention Mechanism](https://doi.org/10.18653/v1/2024.findings-naacl.58) |  | 0 |  | Shuzhou Yuan, Michael Färber |  |
| 642 |  |  [Can Public Large Language Models Help Private Cross-device Federated Learning?](https://doi.org/10.18653/v1/2024.findings-naacl.59) |  | 0 |  | Boxin Wang, Yibo Zhang, Yuan Cao, Bo Li, Hugh McMahan, Sewoong Oh, Zheng Xu, Manzil Zaheer |  |
| 643 |  |  [LangNav: Language as a Perceptual Representation for Navigation](https://doi.org/10.18653/v1/2024.findings-naacl.60) |  | 0 |  | Bowen Pan, Rameswar Panda, SouYoung Jin, Rogério Feris, Aude Oliva, Phillip Isola, Yoon Kim |  |
| 644 |  |  [Planning and Editing What You Retrieve for Enhanced Tool Learning](https://doi.org/10.18653/v1/2024.findings-naacl.61) |  | 0 |  | Tenghao Huang, Dongwon Jung, Vaibhav Kumar, Mohammad Kachuee, Xiang Li, Puyang Xu, Muhao Chen |  |
| 645 |  |  [Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs](https://doi.org/10.18653/v1/2024.findings-naacl.62) |  | 0 |  | Victor Carbune, Hassan Mansoor, Fangyu Liu, Rahul Aralikatte, Gilles Baechler, Jindong Chen, Abhanshu Sharma |  |
| 646 |  |  [SLiM: Speculative Decoding with Hypothesis Reduction](https://doi.org/10.18653/v1/2024.findings-naacl.63) |  | 0 |  | ChiHeng Lin, Shikhar Tuli, James Seale Smith, YenChang Hsu, Yilin Shen, Hongxia Jin |  |
| 647 |  |  [REMATCH: Robust and Efficient Matching of Local Knowledge Graphs to Improve Structural and Semantic Similarity](https://doi.org/10.18653/v1/2024.findings-naacl.64) |  | 0 |  | Zoher Kachwala, Jisun An, Haewoon Kwak, Filippo Menczer |  |
| 648 |  |  [Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing](https://doi.org/10.18653/v1/2024.findings-naacl.65) |  | 0 |  | Ben Hutchinson |  |
| 649 |  |  [Testing the Effect of Code Documentation on Large Language Model Code Understanding](https://doi.org/10.18653/v1/2024.findings-naacl.66) |  | 0 |  | William Macke, Michael Doyle |  |
| 650 |  |  [Aligning Large Language Models with Recommendation Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.67) |  | 0 |  | Yuwei Cao, Nikhil Mehta, Xinyang Yi, Raghunandan Hulikal Keshavan, Lukasz Heldt, Lichan Hong, Ed H. Chi, Maheswaran Sathiamoorthy |  |
| 651 |  |  [OFA: A Framework of Initializing Unseen Subword Embeddings for Efficient Large-scale Multilingual Continued Pretraining](https://doi.org/10.18653/v1/2024.findings-naacl.68) |  | 0 |  | Yihong Liu, Peiqin Lin, Mingyang Wang, Hinrich Schütze |  |
| 652 |  |  [SELF-EXPERTISE: Knowledge-based Instruction Dataset Augmentation for a Legal Expert Language Model](https://doi.org/10.18653/v1/2024.findings-naacl.69) |  | 0 |  | Minju Kim, Haein Jung, MyoungWan Koo |  |
| 653 |  |  [Re-evaluating the Need for Visual Signals in Unsupervised Grammar Induction](https://doi.org/10.18653/v1/2024.findings-naacl.70) |  | 0 |  | Boyi Li, Rodolfo Corona, Karttikeya Mangalam, Catherine Chen, Daniel Flaherty, Serge J. Belongie, Kilian Q. Weinberger, Jitendra Malik, Trevor Darrell, Dan Klein |  |
| 654 |  |  [EDEntail: An Entailment-based Few-shot Text Classification with Extensional Definition](https://doi.org/10.18653/v1/2024.findings-naacl.71) |  | 0 |  | Zixiao Zhu, Junlang Qian, Zijian Feng, Hanzhang Zhou, Kezhi Mao |  |
| 655 |  |  [What Makes Math Word Problems Challenging for LLMs?](https://doi.org/10.18653/v1/2024.findings-naacl.72) |  | 0 |  | KV Aditya Srivatsa, Ekaterina Kochmar |  |
| 656 |  |  [SMILE: Multimodal Dataset for Understanding Laughter in Video with Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.73) |  | 0 |  | Lee Hyun, Kim SungBin, Seungju Han, Youngjae Yu, TaeHyun Oh |  |
| 657 |  |  [T3M: Text Guided 3D Human Motion Synthesis from Speech](https://doi.org/10.18653/v1/2024.findings-naacl.74) |  | 0 |  | Wenshuo Peng, Kaipeng Zhang, Sai Qian Zhang |  |
| 658 |  |  [Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal Knowledge Graph Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.75) |  | 0 |  | Miao Peng, Ben Liu, Wenjie Xu, Zihao Jiang, Jiahui Zhu, Min Peng |  |
| 659 |  |  [Explanation Extraction from Hierarchical Classification Frameworks for Long Legal Documents](https://doi.org/10.18653/v1/2024.findings-naacl.76) |  | 0 |  | Nishchal Prasad, Taoufiq Dkaki, Mohand Boughanem |  |
| 660 |  |  [Low-Rank Adaptation for Multilingual Summarization: An Empirical Study](https://doi.org/10.18653/v1/2024.findings-naacl.77) |  | 0 |  | Chenxi Whitehouse, Fantine Huot, Jasmijn Bastings, Mostafa Dehghani, ChuCheng Lin, Mirella Lapata |  |
| 661 |  |  [A Tree-of-Thoughts to Broaden Multi-step Reasoning across Languages](https://doi.org/10.18653/v1/2024.findings-naacl.78) |  | 0 |  | Leonardo Ranaldi, Giulia Pucci, Federico Ranaldi, Elena Sofia Ruzzetti, Fabio Massimo Zanzotto |  |
| 662 |  |  [Emergent Abilities in Reduced-Scale Generative Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.79) |  | 0 |  | Sherin Muckatira, Vijeta Deshpande, Vladislav Lialin, Anna Rumshisky |  |
| 663 |  |  [Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems](https://doi.org/10.18653/v1/2024.findings-naacl.80) |  | 0 |  | Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke |  |
| 664 |  |  [Matching Varying-Length Texts via Topic-Informed and Decoupled Sentence Embeddings](https://doi.org/10.18653/v1/2024.findings-naacl.81) |  | 0 |  | Xixi Zhou, Chunbin Gu, Xin Jie, Jiajun Bu, Haishuai Wang |  |
| 665 |  |  [Instruction Tuning with Human Curriculum](https://doi.org/10.18653/v1/2024.findings-naacl.82) |  | 0 |  | Bruce W. Lee, Hyunsoo Cho, Kang Min Yoo |  |
| 666 |  |  [Natural Language-based State Representation in Deep Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-naacl.83) |  | 0 |  | Md Masudur Rahman, Yexiang Xue |  |
| 667 |  |  [Learning Cross-Architecture Instruction Embeddings for Binary Code Analysis in Low-Resource Architectures](https://doi.org/10.18653/v1/2024.findings-naacl.84) |  | 0 |  | Junzhe Wang, Qiang Zeng, Lannan Luo |  |
| 668 |  |  [ReEval: Automatic Hallucination Evaluation for Retrieval-Augmented Large Language Models via Transferable Adversarial Attacks](https://doi.org/10.18653/v1/2024.findings-naacl.85) |  | 0 |  | Xiaodong Yu, Hao Cheng, Xiaodong Liu, Dan Roth, Jianfeng Gao |  |
| 669 |  |  [An Effective Automated Speaking Assessment Approach to Mitigating Data Scarcity and Imbalanced Distribution](https://doi.org/10.18653/v1/2024.findings-naacl.86) |  | 0 |  | TienHong Lo, FuAn Chao, TzuI Wu, YaoTing Sung, Berlin Chen |  |
| 670 |  |  [GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond](https://doi.org/10.18653/v1/2024.findings-naacl.87) |  | 0 |  | Shen Zheng, Yuyu Zhang, Yijie Zhu, Chenguang Xi, Pengyang Gao, Zhou Xun, Kevin Chang |  |
| 671 |  |  [Subword Attention and Post-Processing for Rare and Unknown Contextualized Embeddings](https://doi.org/10.18653/v1/2024.findings-naacl.88) |  | 0 |  | Raj Patel, Carlotta Domeniconi |  |
| 672 |  |  [UGIF-DataSet: A New Dataset for Cross-lingual, Cross-modal Sequential actions on the UI](https://doi.org/10.18653/v1/2024.findings-naacl.89) |  | 0 |  | Sagar Gubbi Venkatesh, Partha Talukdar, Srini Narayanan |  |
| 673 |  |  [SimSCOOD: Systematic Analysis of Out-of-Distribution Generalization in Fine-tuned Source Code Models](https://doi.org/10.18653/v1/2024.findings-naacl.90) |  | 0 |  | Hossein Hajipour, Ning Yu, CristianAlexandru Staicu, Mario Fritz |  |
| 674 |  |  [Pruning as a Domain-specific LLM Extractor](https://doi.org/10.18653/v1/2024.findings-naacl.91) |  | 0 |  | Nan Zhang, Yanchi Liu, Xujiang Zhao, Wei Cheng, Runxue Bao, Rui Zhang, Prasenjit Mitra, Haifeng Chen |  |
| 675 |  |  [LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback](https://doi.org/10.18653/v1/2024.findings-naacl.92) |  | 0 |  | Wenda Xu, Daniel Deutsch, Mara Finkelstein, Juraj Juraska, Biao Zhang, Zhongtao Liu, William Yang Wang, Lei Li, Markus Freitag |  |
| 676 |  |  [Noisy Multi-Label Text Classification via Instance-Label Pair Correction](https://doi.org/10.18653/v1/2024.findings-naacl.93) |  | 0 |  | Pengyu Xu, Mingyang Song, Linkaida Liu, Bing Liu, Hongjian Sun, Liping Jing, Jian Yu |  |
| 677 |  |  [Composite Backdoor Attacks Against Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.94) |  | 0 |  | Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang |  |
| 678 |  |  [Adapting Fake News Detection to the Era of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.95) |  | 0 |  | Jinyan Su, Claire Cardie, Preslav Nakov |  |
| 679 |  |  [MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.96) |  | 0 |  | Youbo Lei, Feifei He, Chen Chen, Yingbin Mo, Sijia Li, Defeng Xie, Haonan Lu |  |
| 680 |  |  [Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting](https://doi.org/10.18653/v1/2024.findings-naacl.97) |  | 0 |  | Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Le Yan, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, Michael Bendersky |  |
| 681 |  |  [FedLFC: Towards Efficient Federated Multilingual Modeling with LoRA-based Language Family Clustering](https://doi.org/10.18653/v1/2024.findings-naacl.98) |  | 0 |  | Zhihan Guo, Yifei Zhang, Zhuo Zhang, Zenglin Xu, Irwin King |  |
| 682 |  |  [Gaussian Process Optimization for Adaptable Multi-Objective Text Generation using Linearly-Weighted Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.99) |  | 0 |  | Mohammad Mahdi Abdollah Pour, Ali Pesaranghader, Eldan Cohen, Scott Sanner |  |
| 683 |  |  [Groundedness in Retrieval-augmented Long-form Generation: An Empirical Study](https://doi.org/10.18653/v1/2024.findings-naacl.100) |  | 0 |  | Alessandro Stolfo |  |
| 684 |  |  [TagDebias: Entity and Concept Tagging for Social Bias Mitigation in Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.101) |  | 0 |  | Mehrnaz Moslemi, Amal Zouaq |  |
| 685 |  |  [Improving Absent Keyphrase Generation with Diversity Heads](https://doi.org/10.18653/v1/2024.findings-naacl.102) |  | 0 |  | Edwin Thomas, Sowmya Vajjala |  |
| 686 |  |  [mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?](https://doi.org/10.18653/v1/2024.findings-naacl.103) |  | 0 |  | Tianze Hua, Tian Yun, Ellie Pavlick |  |
| 687 |  |  [Discovering and Mitigating Indirect Bias in Attention-Based Model Explanations](https://doi.org/10.18653/v1/2024.findings-naacl.104) |  | 0 |  | Farsheed Haque, Depeng Xu, Shuhan Yuan |  |
| 688 |  |  [i-Code V2: An Autoregressive Generation Framework over Vision, Language, and Speech Data](https://doi.org/10.18653/v1/2024.findings-naacl.105) |  | 0 |  | Ziyi Yang, Mahmoud Khademi, Yichong Xu, Reid Pryzant, Yuwei Fang, Chenguang Zhu, Dongdong Chen, Yao Qian, Xuemei Gao, YiLing Chen, Robert Gmyr, Naoyuki Kanda, Noel Codella, Bin Xiao, Yu Shi, Lu Yuan, Takuya Yoshioka, Michael Zeng, Xuedong Huang |  |
| 689 |  |  [Think While You Write: Hypothesis Verification Promotes Faithful Knowledge-to-Text Generation](https://doi.org/10.18653/v1/2024.findings-naacl.106) |  | 0 |  | Yifu Qiu, Varun Embar, Shay B. Cohen, Benjamin Han |  |
| 690 |  |  [It's All Relative! - A Synthetic Query Generation Approach for Improving Zero-Shot Relevance Prediction](https://doi.org/10.18653/v1/2024.findings-naacl.107) |  | 0 |  | Aditi Chaudhary, Karthik Raman, Michael Bendersky |  |
| 691 |  |  [RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.108) |  | 0 |  | Saeed Khaki, JinJin Li, Lan Ma, Liu Yang, Prathap Ramachandra |  |
| 692 |  |  [Hypernetwork-Assisted Parameter-Efficient Fine-Tuning with Meta-Knowledge Distillation for Domain Knowledge Disentanglement](https://doi.org/10.18653/v1/2024.findings-naacl.109) |  | 0 |  | Changqun Li, Linlin Wang, Xin Lin, Shizhou Huang, Liang He |  |
| 693 |  |  [MICo: Preventative Detoxification of Large Language Models through Inhibition Control](https://doi.org/10.18653/v1/2024.findings-naacl.110) |  | 0 |  | Roy Siegelmann, Ninareh Mehrabi, Palash Goyal, Prasoon Goyal, Lisa Bauer, Jwala Dhamala, Aram Galstyan, Rahul Gupta, Reza Ghanadan |  |
| 694 |  |  [Reinforcement Learning with Token-level Feedback for Controllable Text Generation](https://doi.org/10.18653/v1/2024.findings-naacl.111) |  | 0 |  | Wendi Li, Wei Wei, Kaihe Xu, Wenfeng Xie, Dangyang Chen, Yu Cheng |  |
| 695 |  |  [CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving](https://doi.org/10.18653/v1/2024.findings-naacl.112) |  | 0 |  | Pei Chen, Shuai Zhang, Boran Han |  |
| 696 |  |  [Tokenization Matters: Navigating Data-Scarce Tokenization for Gender Inclusive Language Technologies](https://doi.org/10.18653/v1/2024.findings-naacl.113) |  | 0 |  | Anaelia Ovalle, Ninareh Mehrabi, Palash Goyal, Jwala Dhamala, KaiWei Chang, Richard S. Zemel, Aram Galstyan, Yuval Pinter, Rahul Gupta |  |
| 697 |  |  [AdaPT: A Set of Guidelines for Hyperbolic Multimodal Multilingual NLP](https://doi.org/10.18653/v1/2024.findings-naacl.114) |  | 0 |  | Ramit Sawhney, Shrey Pandit, Vishwa Shah, Megh Thakkar, Shafiq Joty |  |
| 698 |  |  [More Samples or More Prompts? Exploring Effective Few-Shot In-Context Learning for LLMs with In-Context Sampling](https://doi.org/10.18653/v1/2024.findings-naacl.115) |  | 0 |  | Bingsheng Yao, Guiming Chen, Ruishi Zou, Yuxuan Lu, Jiachen Li, Shao Zhang, Yisi Sang, Sijia Liu, James A. Hendler, Dakuo Wang |  |
| 699 |  |  [ZSEE: A Dataset based on Zeolite Synthesis Event Extraction for Automated Synthesis Platform](https://doi.org/10.18653/v1/2024.findings-naacl.116) |  | 0 |  | Song He, Xin Peng, Yihan Cai, Xin Li, Zhiqing Yuan, Wenli Du, Weimin Yang |  |
| 700 |  |  [Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information](https://doi.org/10.18653/v1/2024.findings-naacl.117) |  | 0 |  | Kyubyung Chae, Jaepill Choi, Yohan Jo, Taesup Kim |  |
| 701 |  |  [Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents](https://doi.org/10.18653/v1/2024.findings-naacl.118) |  | 0 |  | San Kim, Gary Geunbae Lee |  |
| 702 |  |  [Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.119) |  | 0 |  | Fobo Shi, Peijun Qing, Dong Yang, Nan Wang, Youbo Lei, Haonan Lu, Xiaodong Lin, Duantengchuan Li |  |
| 703 |  |  [DAGCN: Distance-based and Aspect-oriented Graph Convolutional Network for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.120) |  | 0 |  | Zhihao Wang, Bo Zhang, Ru Yang, Chang Guo, Maozhen Li |  |
| 704 |  |  [Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved Phrase Graphs](https://doi.org/10.18653/v1/2024.findings-naacl.121) |  | 0 |  | Zhuoyi Peng, Yi Yang |  |
| 705 |  |  [Self-Regulated Sample Diversity in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.122) |  | 0 |  | Mingyue Liu, Jonathan Frawley, Sarah Wyer, Hubert P. H. Shum, Sara L. Uckelman, Sue Black, Chris G. Willcocks |  |
| 706 |  |  [Methods, Applications, and Directions of Learning-to-Rank in NLP Research](https://doi.org/10.18653/v1/2024.findings-naacl.123) |  | 0 |  | Justin Lee, Gabriel BernierColborne, Tegan Maharaj, Sowmya Vajjala |  |
| 707 |  |  [When Quantization Affects Confidence of Large Language Models?](https://doi.org/10.18653/v1/2024.findings-naacl.124) |  | 0 |  | Irina Proskurina, Luc Brun, Guillaume Metzler, Julien Velcin |  |
| 708 |  |  [MedCycle: Unpaired Medical Report Generation via Cycle-Consistency](https://doi.org/10.18653/v1/2024.findings-naacl.125) |  | 0 |  | Elad Hirsch, Gefen Dawidowicz, Ayellet Tal |  |
| 709 |  |  [Beta-LR: Interpretable Logical Reasoning based on Beta Distribution](https://doi.org/10.18653/v1/2024.findings-naacl.126) |  | 0 |  | Yizhuo Ma, Ke Qin, Shuang Liang |  |
| 710 |  |  [Applications of BERT Models Towards Automation of Clinical Coding in Icelandic](https://doi.org/10.18653/v1/2024.findings-naacl.127) |  | 0 |  | Haraldur Orri Hauksson, Hafsteinn Einarsson |  |
| 711 |  |  ["Tell me who you are and I tell you how you argue": Predicting Stances and Arguments for Stakeholder Groups](https://doi.org/10.18653/v1/2024.findings-naacl.128) |  | 0 |  | Philipp Heinisch, Lorik Dumani, Philipp Cimiano, Ralf Schenkel |  |
| 712 |  |  [Psychometric Predictive Power of Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.129) |  | 0 |  | Tatsuki Kuribayashi, Yohei Oseki, Timothy Baldwin |  |
| 713 |  |  [Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions](https://doi.org/10.18653/v1/2024.findings-naacl.130) |  | 0 |  | Pouya Pezeshkpour, Estevam Hruschka |  |
| 714 |  |  [PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck](https://doi.org/10.18653/v1/2024.findings-naacl.131) |  | 0 |  | Thang Pham, Peijie Chen, Tin Nguyen, Seunghyun Yoon, Trung Bui, Anh Nguyen |  |
| 715 |  |  [Ethos: Rectifying Language Models in Orthogonal Parameter Space](https://doi.org/10.18653/v1/2024.findings-naacl.132) |  | 0 |  | Lei Gao, Yue Niu, Tingting Tang, Salman Avestimehr, Murali Annavaram |  |
| 716 |  |  [Crafting In-context Examples according to LMs' Parametric Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.133) |  | 0 |  | Yoonsang Lee, Pranav Atreya, Xi Ye, Eunsol Choi |  |
| 717 |  |  [ICXML: An In-Context Learning Framework for Zero-Shot Extreme Multi-Label Classification](https://doi.org/10.18653/v1/2024.findings-naacl.134) |  | 0 |  | Yaxin Zhu, Hamed Zamani |  |
| 718 |  |  [CLGSI: A Multimodal Sentiment Analysis Framework based on Contrastive Learning Guided by Sentiment Intensity](https://doi.org/10.18653/v1/2024.findings-naacl.135) |  | 0 |  | Yang Yang, Xunde Dong, Yupeng Qiang |  |
| 719 |  |  [Interpreting Answers to Yes-No Questions in Dialogues from Multiple Domains](https://doi.org/10.18653/v1/2024.findings-naacl.136) |  | 0 |  | Zijie Wang, Farzana Rashid, Eduardo Blanco |  |
| 720 |  |  [Enhancing Perception: Refining Explanations of News Claims with LLM Conversations](https://doi.org/10.18653/v1/2024.findings-naacl.137) |  | 0 |  | YiLi Hsu, JuiNing Chen, Yang Fan Chiang, ShangChien Liu, Aiping Xiong, LunWei Ku |  |
| 721 |  |  [How Interpretable are Reasoning Explanations from Prompting Large Language Models?](https://doi.org/10.18653/v1/2024.findings-naacl.138) |  | 0 |  | Wei Jie Yeo, Ranjan Satapathy, Rich Siow Mong Goh, Erik Cambria |  |
| 722 |  |  [Plug-in Language Model: Controlling Text Generation with a Simple Regression Model](https://doi.org/10.18653/v1/2024.findings-naacl.139) |  | 0 |  | NaiChi Yang, WeiYun Ma, PuJen Cheng |  |
| 723 |  |  [Signer Diversity-driven Data Augmentation for Signer-Independent Sign Language Translation](https://doi.org/10.18653/v1/2024.findings-naacl.140) |  | 0 |  | Honghaofu Honghaofu, Liang Zhang, Biao Fu, Rui Zhao, Jinsong Su, Xiaodong Shi, Yidong Chen |  |
| 724 |  |  [A Systematic Analysis of Subwords and Cross-Lingual Transfer in Multilingual Translation](https://doi.org/10.18653/v1/2024.findings-naacl.141) |  | 0 |  | Francois Meyer, Jan Buys |  |
| 725 |  |  [Multi-Granularity Guided Fusion-in-Decoder](https://doi.org/10.18653/v1/2024.findings-naacl.142) |  | 0 |  | Eunseong Choi, Hyeri Lee, Jongwuk Lee |  |
| 726 |  |  [Group Fairness in Multilingual Speech Recognition Models](https://doi.org/10.18653/v1/2024.findings-naacl.143) |  | 0 |  | Anna Zee, Marc Zee, Anders Søgaard |  |
| 727 |  |  [Rethinking Machine Ethics - Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?](https://doi.org/10.18653/v1/2024.findings-naacl.144) |  | 0 |  | Jingyan Zhou, Minda Hu, Junan Li, Xiaoying Zhang, Xixin Wu, Irwin King, Helen Meng |  |
| 728 |  |  [Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.145) |  | 0 |  | Rui Wang, Fei Mi, Yi Chen, Boyang Xue, Hongru Wang, Qi Zhu, KamFai Wong, Ruifeng Xu |  |
| 729 |  |  [BERTweet's TACO Fiesta: Contrasting Flavors On The Path Of Inference And Information-Driven Argument Mining On Twitter](https://doi.org/10.18653/v1/2024.findings-naacl.146) |  | 0 |  | Marc Feger, Stefan Dietze |  |
| 730 |  |  [Testing the limits of logical reasoning in neural and hybrid models](https://doi.org/10.18653/v1/2024.findings-naacl.147) |  | 0 |  | Manuel Vargas Guzmán, Jakub Szymanik, Maciej Malicki |  |
| 731 |  |  [METAL: Towards Multilingual Meta-Evaluation](https://doi.org/10.18653/v1/2024.findings-naacl.148) |  | 0 |  | Rishav Hada, Varun Gumma, Mohamed Ahmed, Kalika Bali, Sunayana Sitaram |  |
| 732 |  |  [AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models](https://doi.org/10.18653/v1/2024.findings-naacl.149) |  | 0 |  | Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, Nan Duan |  |
| 733 |  |  [Product Description and QA Assisted Self-Supervised Opinion Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.150) |  | 0 |  | Tejpalsingh Siledar, Rupasai Rangaraju, Sankara Sri Raghava Ravindra Muddu, Suman Banerjee, Amey Patil, Sudhanshu Singh, Muthusamy Chelliah, Nikesh Garera, Swaprava Nath, Pushpak Bhattacharyya |  |
| 734 |  |  [COMEM: In-Context Retrieval-Augmented Mass-Editing Memory in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.151) |  | 0 |  | Shanbao Qiao, Xuebing Liu, SeungHoon Na |  |
| 735 |  |  [Content-Specific Humorous Image Captioning Using Incongruity Resolution Chain-of-Thought](https://doi.org/10.18653/v1/2024.findings-naacl.152) |  | 0 |  | Kohtaro Tanaka, Kohei Uehara, Lin Gu, Yusuke Mukuta, Tatsuya Harada |  |
| 736 |  |  [Denoising Attention for Query-aware User Modeling](https://doi.org/10.18653/v1/2024.findings-naacl.153) |  | 0 |  | Elias Bassani, Pranav Kasela, Gabriella Pasi |  |
| 737 |  |  [A Lightweight Mixture-of-Experts Neural Machine Translation Model with Stage-wise Training Strategy](https://doi.org/10.18653/v1/2024.findings-naacl.154) |  | 0 |  | Fan Zhang, Mei Tu, Song Liu, Jinyao Yan |  |
| 738 |  |  [BEAR: A Unified Framework for Evaluating Relational Knowledge in Causal and Masked Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.155) |  | 0 |  | Jacek Wiland, Max Ploner, Alan Akbik |  |
| 739 |  |  [Conformal Intent Classification and Clarification for Fast and Accurate Intent Recognition](https://doi.org/10.18653/v1/2024.findings-naacl.156) |  | 0 |  | Floris den Hengst, Ralf Wolter, Patrick Altmeyer, Arda Kaygan |  |
| 740 |  |  [Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models in Court Decisions](https://doi.org/10.18653/v1/2024.findings-naacl.157) |  | 0 |  | Alex Nyffenegger, Matthias Stürmer, Joel Niklaus |  |
| 741 |  |  [X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment](https://doi.org/10.18653/v1/2024.findings-naacl.158) |  | 0 |  | Dongjae Shin, HyeonSeok Lim, Inho Won, ChangSu Choi, Minjun Kim, Seungwoo Song, Hangyeol Yoo, Sangmin Kim, Kyungtae Lim |  |
| 742 |  |  [Why So Gullible? Enhancing the Robustness of Retrieval-Augmented Models against Counterfactual Noise](https://doi.org/10.18653/v1/2024.findings-naacl.159) |  | 0 |  | Giwon Hong, Jeonghwan Kim, Junmo Kang, SungHyon Myaeng, Joyce Jiyoung Whang |  |
| 743 |  |  [Heterogeneity over Homogeneity: Investigating Multilingual Speech Pre-Trained Models for Detecting Audio Deepfake](https://doi.org/10.18653/v1/2024.findings-naacl.160) |  | 0 |  | Orchid Chetia Phukan, Gautam Siddharth Kashyap, Arun Balaji Buduru, Rajesh Sharma |  |
| 744 |  |  [Identifying Self-Disclosures of Use, Misuse and Addiction in Community-based Social Media Posts](https://doi.org/10.18653/v1/2024.findings-naacl.161) |  | 0 |  | Chenghao Yang, Tuhin Chakrabarty, Karli R. Hochstatter, Melissa N. Slavin, Nabila ElBassel, Smaranda Muresan |  |
| 745 |  |  [Self-Adaptive Sampling for Accurate Video Question Answering on Image Text Models](https://doi.org/10.18653/v1/2024.findings-naacl.162) |  | 0 |  | Wei Han, Hui Chen, MinYen Kan, Soujanya Poria |  |
| 746 |  |  [Towards an On-device Agent for Text Rewriting](https://doi.org/10.18653/v1/2024.findings-naacl.163) |  | 0 |  | Yun Zhu, Yinxiao Liu, Felix Stahlberg, Shankar Kumar, YuHui Chen, Liangchen Luo, Lei Shu, Renjie Liu, Jindong Chen, Lei Meng |  |
| 747 |  |  [Tailoring Vaccine Messaging with Common-Ground Opinions](https://doi.org/10.18653/v1/2024.findings-naacl.164) |  | 0 |  | Rickard Stureborg, Sanxing Chen, Roy Xie, Aayushi Patel, Christopher Li, Chloe Qinyu Zhu, Tingnan Hu, Jun Yang, Bhuwan Dhingra |  |
| 748 |  |  [Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification](https://doi.org/10.18653/v1/2024.findings-naacl.165) |  | 0 |  | Robert Vacareanu, Fahmida Alam, Md. Asiful Islam, Haris Riaz, Mihai Surdeanu |  |
| 749 |  |  [Q-Tuning: Queue-based Prompt Tuning for Lifelong Few-shot Language Learning](https://doi.org/10.18653/v1/2024.findings-naacl.166) |  | 0 |  | Yanhui Guo, Shaoyuan Xu, Jinmiao Fu, Jia Liu, Chaosheng Dong, Bryan Wang |  |
| 750 |  |  [In-Context Example Ordering Guided by Label Distributions](https://doi.org/10.18653/v1/2024.findings-naacl.167) |  | 0 |  | Zhichao Xu, Daniel Cohen, Bei Wang, Vivek Srikumar |  |
| 751 |  |  [Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial Narratives](https://doi.org/10.18653/v1/2024.findings-naacl.168) |  | 0 |  | Jiaxin Liu, Yi Yang, Kar Yan Tam |  |
| 752 |  |  [Laying Anchors: Semantically Priming Numerals in Language Modeling](https://doi.org/10.18653/v1/2024.findings-naacl.169) |  | 0 |  | Mandar Sharma, Rutuja Murlidhar Taware, Pravesh Koirala, Nikhil Muralidhar, Naren Ramakrishnan |  |
| 753 |  |  [UEGP: Unified Expert-Guided Pre-training for Knowledge Rekindle](https://doi.org/10.18653/v1/2024.findings-naacl.170) |  | 0 |  | Yutao Mou, Kexiang Wang, Jianhe Lin, Dehong Ma, Jun Fan, Daiting Shi, Zhicong Cheng, Simiu Gu, Dawei Yin, Weiran Xu |  |
| 754 |  |  [LatticeGen: Hiding Generated Text in a Lattice for Privacy-Aware Large Language Model Generation on Cloud](https://doi.org/10.18653/v1/2024.findings-naacl.171) |  | 0 |  | Mengke Zhang, Tianxing He, Tianle Wang, Lu Mi, Niloofar Mireshghallah, Binyi Chen, Hao Wang, Yulia Tsvetkov |  |
| 755 |  |  [HateModerate: Testing Hate Speech Detectors against Content Moderation Policies](https://doi.org/10.18653/v1/2024.findings-naacl.172) |  | 0 |  | Jiangrui Zheng, Xueqing Liu, Mirazul Haque, Xing Qian, Guanqun Yang, Wei Yang |  |
| 756 |  |  [Compensate Quantization Errors: Make Weights Hierarchical to Compensate Each Other](https://doi.org/10.18653/v1/2024.findings-naacl.173) |  | 0 |  | Yifei Gao, Jie Ou, Lei Wang, Yuting Xiao, Xiangzhiyuan Xiangzhiyuan, Ruiting Dai, Jun Cheng |  |
| 757 |  |  [Contrastive Preference Learning for Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.174) |  | 0 |  | Jianfei He, Shichao Sun, Sen Peng, Jie Xu, Xiaohua Jia, Wenjie Li |  |
| 758 |  |  [SocREval: Large Language Models with the Socratic Method for Reference-free Reasoning Evaluation](https://doi.org/10.18653/v1/2024.findings-naacl.175) |  | 0 |  | Hangfeng He, Hongming Zhang, Dan Roth |  |
| 759 |  |  [Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.176) |  | 0 |  | Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, Lei Li |  |
| 760 |  |  [Unleashing the Power of LLMs in Court View Generation by Stimulating Internal Knowledge and Incorporating External Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.177) |  | 0 |  | Yifei Liu, Yiquan Wu, Ang Li, Yating Zhang, Changlong Sun, Weiming Lu, Fei Wu, Kun Kuang |  |
| 761 |  |  [Prompting Vision-Language Models For Aspect-Controlled Generation of Referring Expressions](https://doi.org/10.18653/v1/2024.findings-naacl.178) |  | 0 |  | Danfeng Guo, Sanchit Agarwal, Arpit Gupta, JiunYu Kao, Emre Barut, Tagyoung Chung, Jing Huang, Mohit Bansal |  |
| 762 |  |  [Task-Agnostic Detector for Insertion-Based Backdoor Attacks](https://doi.org/10.18653/v1/2024.findings-naacl.179) |  | 0 |  | Weimin Lyu, Xiao Lin, Songzhu Zheng, Lu Pang, Haibin Ling, Susmit Jha, Chao Chen |  |
| 763 |  |  [Uncertainty Estimation on Sequential Labeling via Uncertainty Transmission](https://doi.org/10.18653/v1/2024.findings-naacl.180) |  | 0 |  | Jianfeng He, Linlin Yu, Shuo Lei, ChangTien Lu, Feng Chen |  |
| 764 |  |  [Exploring Language Model's Code Generation Ability with Auxiliary Functions](https://doi.org/10.18653/v1/2024.findings-naacl.181) |  | 0 |  | Seonghyeon Lee, Sanghwan Jang, Seongbo Jang, Dongha Lee, Hwanjo Yu |  |
| 765 |  |  [Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.182) |  | 0 |  | Sang T. Truong, Duc Nguyen, Toan Nguyen, Dong D. Le, Nhi N. Truong, Tho Quan, Sanmi Koyejo |  |
| 766 |  |  [GoT: Effective Graph-of-Thought Reasoning in Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.183) |  | 0 |  | Yao Yao, Zuchao Li, Hai Zhao |  |
| 767 |  |  [Enhancing the General Agent Capabilities of Low-Paramter LLMs through Tuning and Multi-Branch Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.184) |  | 0 |  | Qinhao Zhou, Zihan Zhang, Xiang Xiang, Ke Wang, Yuchuan Wu, Yongbin Li |  |
| 768 |  |  [MuMath: Multi-perspective Data Augmentation for Mathematical Reasoning in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.185) |  | 0 |  | Weihao You, Shuo Yin, Xudong Zhao, Zhilong Ji, Guoqiang Zhong, Jinfeng Bai |  |
| 769 |  |  [Tram: A Token-level Retrieval-augmented Mechanism for Source Code Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.186) |  | 0 |  | Tong Ye, Lingfei Wu, Tengfei Ma, Xuhong Zhang, Yangkai Du, Peiyu Liu, Shouling Ji, Wenhai Wang |  |
| 770 |  |  [UNO-DST: Leveraging Unlabelled Data in Zero-Shot Dialogue State Tracking](https://doi.org/10.18653/v1/2024.findings-naacl.187) |  | 0 |  | Chuang Li, Yan Zhang, MinYen Kan, Haizhou Li |  |
| 771 |  |  [Evaluating Step-by-Step Reasoning through Symbolic Verification](https://doi.org/10.18653/v1/2024.findings-naacl.188) |  | 0 |  | Yifan Zhang, Hanlin Zhang, Li Li, Eric P. Xing |  |
| 772 |  |  [Multi-Review Fusion-in-Context](https://doi.org/10.18653/v1/2024.findings-naacl.189) |  | 0 |  | Aviv Slobodkin, Ori Shapira, Ran Levy, Ido Dagan |  |
| 773 |  |  [Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison](https://doi.org/10.18653/v1/2024.findings-naacl.190) |  | 0 |  | Maxime Bouthors, Josep Maria Crego, François Yvon |  |
| 774 |  |  [Extending Input Contexts of Language Models through Training on Segmented Sequences](https://doi.org/10.18653/v1/2024.findings-naacl.191) |  | 0 |  | Petros Karypis, Julian J. McAuley, George Karypis |  |
| 775 |  |  [Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning through Logical Fallacy Understanding](https://doi.org/10.18653/v1/2024.findings-naacl.192) |  | 0 |  | Yanda Li, Dixuan Wang, Jiaqing Liang, Guochao Jiang, Qianyu He, Yanghua Xiao, Deqing Yang |  |
| 776 |  |  [Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.193) |  | 0 |  | Wanyong Feng, Jaewook Lee, Hunter McNichols, Alexander Scarlatos, Digory Smith, Simon Woodhead, Nancy Otero Ornelas, Andrew S. Lan |  |
| 777 |  |  [Aspect-based Sentiment Analysis with Context Denoising](https://doi.org/10.18653/v1/2024.findings-naacl.194) |  | 0 |  | Yuanhe Tian, Chang Liu, Yan Song, Fei Xia, Yongdong Zhang |  |
| 778 |  |  [IruMozhi: Automatically classifying diglossia in Tamil](https://doi.org/10.18653/v1/2024.findings-naacl.195) |  | 0 |  | Kabilan Prasanna, Aryaman Arora |  |
| 779 |  |  [RENOVI: A Benchmark Towards Remediating Norm Violations in Socio-Cultural Conversations](https://doi.org/10.18653/v1/2024.findings-naacl.196) |  | 0 |  | Haolan Zhan, Zhuang Li, Xiaoxi Kang, Tao Feng, Yuncheng Hua, Lizhen Qu, Yi Ying, Mei Rianto Chandra, Kelly Rosalin, Jureynolds Jureynolds, Suraj Sharma, Shilin Qu, Linhao Luo, Ingrid Zukerman, LayKi Soon, Zhaleh SemnaniAzad, Gholamreza Haffari |  |
| 780 |  |  [Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking](https://doi.org/10.18653/v1/2024.findings-naacl.197) |  | 0 |  | Hong Jin Kang, Fabrice HarelCanada, Muhammad Ali Gulzar, Nanyun Peng, Miryung Kim |  |
| 781 |  |  [COMMIT: Code-Mixing English-Centric Large Language Model for Multilingual Instruction Tuning](https://doi.org/10.18653/v1/2024.findings-naacl.198) |  | 0 |  | Jaeseong Lee, YeonJoon Jung, Seungwon Hwang |  |
| 782 |  |  [DiLM: Distilling Dataset into Language Model for Text-level Dataset Distillation](https://doi.org/10.18653/v1/2024.findings-naacl.199) |  | 0 |  | Aru Maekawa, Satoshi Kosugi, Kotaro Funakoshi, Manabu Okumura |  |
| 783 |  |  [MindAgent: Emergent Gaming Interaction](https://doi.org/10.18653/v1/2024.findings-naacl.200) |  | 0 |  | Ran Gong, Qiuyuan Huang, Xiaojian Ma, Yusuke Noda, Zane Durante, Zilong Zheng, Demetri Terzopoulos, Li FeiFei, Jianfeng Gao, Hoi Vo |  |
| 784 |  |  [BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues](https://doi.org/10.18653/v1/2024.findings-naacl.201) |  | 0 |  | Haodong Duan, Jueqi Wei, Chonghua Wang, Hongwei Liu, Yixiao Fang, Songyang Zhang, Dahua Lin, Kai Chen |  |
| 785 |  |  [Learning Mutually Informed Representations for Characters and Subwords](https://doi.org/10.18653/v1/2024.findings-naacl.202) |  | 0 |  | Yilin Wang, Xinyi Hu, Matthew Gormley |  |
| 786 |  |  [A Novel Two-step Fine-tuning Framework for Transfer Learning in Low-Resource Neural Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.203) |  | 0 |  | Yuan Gao, Feng Hou, Ruili Wang |  |
| 787 |  |  [Enhancing Cross-lingual Sentence Embedding for Low-resource Languages with Word Alignment](https://doi.org/10.18653/v1/2024.findings-naacl.204) |  | 0 |  | Zhongtao Miao, Qiyu Wu, Kaiyan Zhao, Zilong Wu, Yoshimasa Tsuruoka |  |
| 788 |  |  [C³LPGCN:Integrating Contrastive Learning and Cooperative Learning with Prompt into Graph Convolutional Network for Aspect-based Sentiment Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.205) |  | 0 |  | Ye He, Shihao Zou, Yuzhe Chen, Xianying Huang |  |
| 789 |  |  [Visual Enhanced Entity-Level Interaction Network for Multimodal Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.206) |  | 0 |  | Haolong Yan, Binghao Tang, Boda Lin, Gang Zhao, Si Li |  |
| 790 |  |  [Knowledgeable In-Context Tuning: Exploring and Exploiting Factual Knowledge for In-Context Learning](https://doi.org/10.18653/v1/2024.findings-naacl.207) |  | 0 |  | Jianing Wang, Chengyu Wang, Chuanqi Tan, Jun Huang, Ming Gao |  |
| 791 |  |  [Time Machine GPT](https://doi.org/10.18653/v1/2024.findings-naacl.208) |  | 0 |  | Felix Drinkall, Eghbal Rahimikia, Janet B. Pierrehumbert, Stefan Zohren |  |
| 792 |  |  [An End-to-End Submodular Framework for Data-Efficient In-Context Learning](https://doi.org/10.18653/v1/2024.findings-naacl.209) |  | 0 |  | Lilly Kumari, Shengjie Wang, Arnav Das, Tianyi Zhou, Jeff A. Bilmes |  |
| 793 |  |  [Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer](https://doi.org/10.18653/v1/2024.findings-naacl.210) |  | 0 |  | HeleAndra Kuulmets, Taido Purason, Agnes Luhtaru, Mark Fishel |  |
| 794 |  |  [Simulating Opinion Dynamics with Networks of LLM-based Agents](https://doi.org/10.18653/v1/2024.findings-naacl.211) |  | 0 |  | YunShiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers |  |
| 795 |  |  [Probing the Category of Verbal Aspect in Transformer Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.212) |  | 0 |  | Anisia Katinskaia, Roman Yangarber |  |
| 796 |  |  [A Measure for Transparent Comparison of Linguistic Diversity in Multilingual NLP Data Sets](https://doi.org/10.18653/v1/2024.findings-naacl.213) |  | 0 |  | Tanja Samardzic, Ximena Gutierrez, Christian Bentz, Steven Moran, Olga Pelloni |  |
| 797 |  |  [Beyond Read-Only: Crafting a Comprehensive Chinese Text-to-SQL Dataset for Database Manipulation and Query](https://doi.org/10.18653/v1/2024.findings-naacl.214) |  | 0 |  | Xi Chen, Jinguo You, Likun Likun, Xiang Li |  |
| 798 |  |  [Normalizing without Modernizing: Keeping Historical Wordforms of Middle French while Reducing Spelling Variants](https://doi.org/10.18653/v1/2024.findings-naacl.215) |  | 0 |  | Raphael Rubino, Johanna Gerlach, Jonathan Mutal, Pierrette Bouillon |  |
| 799 |  |  [Anti-LM Decoding for Zero-shot In-context Machine Translation](https://doi.org/10.18653/v1/2024.findings-naacl.216) |  | 0 |  | Suzanna Sia, Alexandra DeLucia, Kevin Duh |  |
| 800 |  |  [Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning](https://doi.org/10.18653/v1/2024.findings-naacl.217) |  | 0 |  | Shuai Zhao, Leilei Gan, Anh Tuan Luu, Jie Fu, Lingjuan Lyu, Meihuizi Jia, Jinming Wen |  |
| 801 |  |  [Select and Summarize: Scene Saliency for Movie Script Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.218) |  | 0 |  | Rohit Saxena, Frank Keller |  |
| 802 |  |  [Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks](https://doi.org/10.18653/v1/2024.findings-naacl.219) |  | 0 |  | Seunguk Yu, Juhwan Choi, YoungBin Kim |  |
| 803 |  |  [Z-GMOT: Zero-shot Generic Multiple Object Tracking](https://doi.org/10.18653/v1/2024.findings-naacl.220) |  | 0 |  | Kim Hoang Tran, Anh Duy Le Dinh, TienPhat Nguyen, Thinh Phan, Pha A. Nguyen, Khoa Luu, Donald A. Adjeroh, Gianfranco Doretto, Ngan Hoang Le |  |
| 804 |  |  [NLP for Counterspeech against Hate: A Survey and How-To Guide](https://doi.org/10.18653/v1/2024.findings-naacl.221) |  | 0 |  | Helena Bonaldi, YiLing Chung, Gavin Abercrombie, Marco Guerini |  |
| 805 |  |  [PRODIGy: a PROfile-based DIalogue Generation dataset](https://doi.org/10.18653/v1/2024.findings-naacl.222) |  | 0 |  | Daniela Occhipinti, Serra Sinem Tekiroglu, Marco Guerini |  |
| 806 |  |  [WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.223) |  | 0 |  | Piotr Molenda, Adian Liusie, Mark J. F. Gales |  |
| 807 |  |  [Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking](https://doi.org/10.18653/v1/2024.findings-naacl.224) |  | 0 |  | Nan Xu, Fei Wang, Ben Zhou, Bangzheng Li, Chaowei Xiao, Muhao Chen |  |
| 808 |  |  [PAELLA: Parameter-Efficient Lightweight Language-Agnostic Captioning Model](https://doi.org/10.18653/v1/2024.findings-naacl.225) |  | 0 |  | Rita Ramos, Emanuele Bugliarello, Bruno Martins, Desmond Elliott |  |
| 809 |  |  [OSCaR: Object State Captioning and State Change Representation](https://doi.org/10.18653/v1/2024.findings-naacl.226) |  | 0 |  | Nguyen Nguyen, Jing Bi, Ali Vosoughi, Yapeng Tian, Pooyan Fazli, Chenliang Xu |  |
| 810 |  |  [SumCSE: Summary as a transformation for Contrastive Learning](https://doi.org/10.18653/v1/2024.findings-naacl.227) |  | 0 |  | Raghuveer Thirukovalluru, Xiaolan Wang, Jun Chen, Shuyang Li, Jie Lei, Rong Jin, Bhuwan Dhingra |  |
| 811 |  |  [The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text](https://doi.org/10.18653/v1/2024.findings-naacl.228) |  | 0 |  | Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, Chloé Clavel |  |
| 812 |  |  [PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits](https://doi.org/10.18653/v1/2024.findings-naacl.229) |  | 0 |  | Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, Jad Kabbara |  |
| 813 |  |  [FIRE: A Dataset for Financial Relation Extraction](https://doi.org/10.18653/v1/2024.findings-naacl.230) |  | 0 |  | Hassan Hamad, Abhinav Kumar Thakur, Nijil Kolleri, Sujith Pulikodan, Keith M. Chugg |  |
| 814 |  |  [MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response](https://doi.org/10.18653/v1/2024.findings-naacl.231) |  | 0 |  | Zihao Deng, Yinghao Ma, Yudong Liu, Rongchen Guo, Ge Zhang, Wenhu Chen, Wenhao Huang, Emmanouil Benetos |  |
| 815 |  |  [Investigating Acceleration of LLaMA Inference by Enabling Intermediate Layer Decoding via Instruction Tuning with 'LITE'](https://doi.org/10.18653/v1/2024.findings-naacl.232) |  | 0 |  | Neeraj Varshney, Agneet Chatterjee, Mihir Parmar, Chitta Baral |  |
| 816 |  |  [Instruction-following Evaluation through Verbalizer Manipulation](https://doi.org/10.18653/v1/2024.findings-naacl.233) |  | 0 |  | Shiyang Li, Jun Yan, Hai Wang, Zheng Tang, Xiang Ren, Vijay Srinivasan, Hongxia Jin |  |
| 817 |  |  [WebWISE: Unlocking Web Interface Control for LLMs via Sequential Exploration](https://doi.org/10.18653/v1/2024.findings-naacl.234) |  | 0 |  | Heyi Tao, Sethuraman TV, Michal ShlapentokhRothman, Tanmay Gupta, Heng Ji, Derek Hoiem |  |
| 818 |  |  [CodecLM: Aligning Language Models with Tailored Synthetic Data](https://doi.org/10.18653/v1/2024.findings-naacl.235) |  | 0 |  | Zifeng Wang, ChunLiang Li, Vincent Perot, Long T. Le, Jin Miao, Zizhao Zhang, ChenYu Lee, Tomas Pfister |  |
| 819 |  |  [Prompting Few-shot Multi-hop Question Generation via Comprehending Type-aware Semantics](https://doi.org/10.18653/v1/2024.findings-naacl.236) |  | 0 |  | Zefeng Lin, Weidong Chen, Yan Song, Yongdong Zhang |  |
| 820 |  |  [When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.237) |  | 0 |  | Yanhong Li, Chenghao Yang, Allyson Ettinger |  |
| 821 |  |  [CoDa: Constrained Generation based Data Augmentation for Low-Resource NLP](https://doi.org/10.18653/v1/2024.findings-naacl.238) |  | 0 |  | Chandra Kiran Reddy Evuru, Sreyan Ghosh, Sonal Kumar, Ramaneswaran S., Utkarsh Tyagi, Dinesh Manocha |  |
| 822 |  |  [Synonym relations affect object detection learned on vision-language data](https://doi.org/10.18653/v1/2024.findings-naacl.239) |  | 0 |  | Giacomo Nebbia, Adriana Kovashka |  |
| 823 |  |  [CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models](https://doi.org/10.18653/v1/2024.findings-naacl.240) |  | 0 |  | Xiang Li, FanBu FanBu, Ambuj Mehrish, Yingting Li, Jiale Han, Bo Cheng, Soujanya Poria |  |
| 824 |  |  [RobustSentEmbed: Robust Sentence Embeddings Using Adversarial Self-Supervised Contrastive Learning](https://doi.org/10.18653/v1/2024.findings-naacl.241) |  | 0 |  | Javad Rafiei Asl, Prajwal Panzade, Eduardo Blanco, Daniel Takabi, Zhipeng Cai |  |
| 825 |  |  [Characterizing Human and Zero-Shot GPT-3.5 Object-Similarity Judgments](https://doi.org/10.18653/v1/2024.findings-naacl.242) |  | 0 |  | D. McKnight, Alona Fyshe |  |
| 826 |  |  [Self-Demos: Eliciting Out-of-Demonstration Generalizability in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.243) |  | 0 |  | Wei He, Shichun Liu, Jun Zhao, Yiwen Ding, Yi Lu, Zhiheng Xi, Tao Gui, Qi Zhang, Xuanjing Huang |  |
| 827 |  |  [Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge Conflicts in Event Temporal Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.244) |  | 0 |  | Tianqing Fang, Zhaowei Wang, Wenxuan Zhou, Hongming Zhang, Yangqiu Song, Muhao Chen |  |
| 828 |  |  [MCECR: A Novel Dataset for Multilingual Cross-Document Event Coreference Resolution](https://doi.org/10.18653/v1/2024.findings-naacl.245) |  | 0 |  | Amir Pouran Ben Veyseh, Viet Dac Lai, Chien Nguyen, Franck Dernoncourt, Thien Huu Nguyen |  |
| 829 |  |  [Sentiment Analysis in the Era of Large Language Models: A Reality Check](https://doi.org/10.18653/v1/2024.findings-naacl.246) |  | 0 |  | Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, Lidong Bing |  |
| 830 |  |  [Tokenizer Choice For LLM Training: Negligible or Crucial?](https://doi.org/10.18653/v1/2024.findings-naacl.247) |  | 0 |  | Mehdi Ali, Michael Fromm, Klaudia Thellmann, Richard Rutmann, Max Lübbering, Johannes Leveling, Katrin Klug, Jan Ebert, Niclas Doll, Jasper Schulze Buschhoff, Charvi Jain, Alexander Arno Weber, Lena Jurkschat, Hammam Abdelwahab, Chelsea John, Pedro Ortiz Suarez, Malte Ostendorff, Samuel Weinbach, Rafet Sifa, Stefan Kesselheim, Nicolas FloresHerr |  |
| 831 |  |  [Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue](https://doi.org/10.18653/v1/2024.findings-naacl.248) |  | 0 |  | Junkai Zhou, Liang Pang, Huawei Shen, Xueqi Cheng |  |
| 832 |  |  [The Impact of Differential Privacy on Group Disparity Mitigation](https://doi.org/10.18653/v1/2024.findings-naacl.249) |  | 0 |  | Victor Petrén Bach Hansen, Atula Tejaswi Neerkaje, Ramit Sawhney, Lucie Flek, Anders Søgaard |  |
| 833 |  |  [Isometric Neural Machine Translation using Phoneme Count Ratio Reward-based Reinforcement Learning](https://doi.org/10.18653/v1/2024.findings-naacl.250) |  | 0 |  | Shivam Mhaskar, Nirmesh Shah, Mohammadi Zaki, Ashishkumar P. Gudmalwar, Pankaj Wasnik, Rajiv Ratn Shah |  |
| 834 |  |  [Read between the lines - Functionality Extraction From READMEs](https://doi.org/10.18653/v1/2024.findings-naacl.251) |  | 0 |  | Prince Kumar, Srikanth Tamilselvam, Dinesh Garg |  |
| 835 |  |  [AbsPyramid: Benchmarking the Abstraction Ability of Language Models with a Unified Entailment Graph](https://doi.org/10.18653/v1/2024.findings-naacl.252) |  | 0 |  | Zhaowei Wang, Haochen Shi, Weiqi Wang, Tianqing Fang, Hongming Zhang, Sehyun Choi, Xin Liu, Yangqiu Song |  |
| 836 |  |  [Few-TK: A Dataset for Few-shot Scientific Typed Keyphrase Recognition](https://doi.org/10.18653/v1/2024.findings-naacl.253) |  | 0 |  | Avishek Lahiri, Pratyay Sarkar, Medha Sen, Debarshi Kumar Sanyal, Imon Mukherjee |  |
| 837 |  |  [Language Models can be Deductive Solvers](https://doi.org/10.18653/v1/2024.findings-naacl.254) |  | 0 |  | Jiazhan Feng, Ruochen Xu, Junheng Hao, Hiteshi Sharma, Yelong Shen, Dongyan Zhao, Weizhu Chen |  |
| 838 |  |  [Interpreting User Requests in the Context of Natural Language Standing Instructions](https://doi.org/10.18653/v1/2024.findings-naacl.255) |  | 0 |  | Nikita Moghe, Patrick Xia, Jacob Andreas, Jason Eisner, Benjamin Van Durme, Harsh Jhamtani |  |
| 839 |  |  [Secure Your Model: An Effective Key Prompt Protection Mechanism for Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.256) |  | 0 |  | Ruixiang Tang, YuNeng Chuang, Xuanting Cai, Mengnan Du, Xia Hu |  |
| 840 |  |  [Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.257) |  | 0 |  | Jiashuo Sun, Yi Luo, Yeyun Gong, Chen Lin, Yelong Shen, Jian Guo, Nan Duan |  |
| 841 |  |  [Do Prompt Positions Really Matter?](https://doi.org/10.18653/v1/2024.findings-naacl.258) |  | 0 |  | Junyu Mao, Stuart E. Middleton, Mahesan Niranjan |  |
| 842 |  |  [Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning](https://doi.org/10.18653/v1/2024.findings-naacl.259) |  | 0 |  | Tianhua Zhang, Jiaxin Ge, Hongyin Luo, YungSung Chuang, Mingye Gao, Yuan Gong, Yoon Kim, Xixin Wu, Helen Meng, Jim Glass |  |
| 843 |  |  [A Study on Scaling Up Multilingual News Framing Analysis](https://doi.org/10.18653/v1/2024.findings-naacl.260) |  | 0 |  | Syeda Sabrina Akter, Antonios Anastasopoulos |  |
| 844 |  |  [ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.261) |  | 0 |  | MinhNam Tran, PhuVinh Nguyen, Long Nguyen, Dien Dinh |  |
| 845 |  |  [Exploring the Trade-off Between Model Performance and Explanation Plausibility of Text Classifiers Using Human Rationales](https://doi.org/10.18653/v1/2024.findings-naacl.262) |  | 0 |  | Lucas Resck, Marcos M. Raimundo, Jorge Poco |  |
| 846 |  |  [Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language Translation](https://doi.org/10.18653/v1/2024.findings-naacl.263) |  | 0 |  | Tong Su, Xin Peng, Sarubi Thillainathan, David Guzmán, Surangika Ranathunga, EnShiun Annie Lee |  |
| 847 |  |  [ADaPT: As-Needed Decomposition and Planning with Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.264) |  | 0 |  | Archiki Prasad, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, Mohit Bansal, Tushar Khot |  |
| 848 |  |  [Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations](https://doi.org/10.18653/v1/2024.findings-naacl.265) |  | 0 |  | Dayeon Ki, Marine Carpuat |  |
| 849 |  |  [Non-contrastive sentence representations via self-supervision](https://doi.org/10.18653/v1/2024.findings-naacl.266) |  | 0 |  | Duccio Pappadopulo, Marco Farina |  |
| 850 |  |  [Semantically-Prompted Language Models Improve Visual Descriptions](https://doi.org/10.18653/v1/2024.findings-naacl.267) |  | 0 |  | Michael Ogezi, Bradley Hauer, Grzegorz Kondrak |  |
| 851 |  |  [GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.268) |  | 0 |  | Ruotong Liao, Xu Jia, Yangzhe Li, Yunpu Ma, Volker Tresp |  |
| 852 |  |  [A Transformer with Stack Attention](https://doi.org/10.18653/v1/2024.findings-naacl.269) |  | 0 |  | Jiaoda Li, Jennifer C. White, Mrinmaya Sachan, Ryan Cotterell |  |
| 853 |  |  [InstructEval: Systematic Evaluation of Instruction Selection Methods](https://doi.org/10.18653/v1/2024.findings-naacl.270) |  | 0 |  | Anirudh Ajith, Chris Pan, Mengzhou Xia, Ameet Deshpande, Karthik Narasimhan |  |
| 854 |  |  [RecMind: Large Language Model Powered Agent For Recommendation](https://doi.org/10.18653/v1/2024.findings-naacl.271) |  | 0 |  | Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Yanbin Lu, Xiaojiang Huang, Yingzhen Yang |  |
| 855 |  |  [GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided Language Data Generation](https://doi.org/10.18653/v1/2024.findings-naacl.272) |  | 0 |  | Mohsen Gholami, Mohammad Akbari, Tianxi Hu, Vaden Masrani, Z. Wang, Yong Zhang |  |
| 856 |  |  [How Lexical is Bilingual Lexicon Induction?](https://doi.org/10.18653/v1/2024.findings-naacl.273) |  | 0 |  | Harsh Kohli, Helian Feng, Nicholas Dronen, Calvin McCarter, Sina Moeini, Ali Kebarighotbi |  |
| 857 |  |  [Fumbling in Babel: An Investigation into ChatGPT's Language Identification Ability](https://doi.org/10.18653/v1/2024.findings-naacl.274) |  | 0 |  | WeiRui Chen, Ife Adebara, Khai Duy Doan, Qisheng Liao, Muhammad AbdulMageed |  |
| 858 |  |  [Targeted Augmentation for Low-Resource Event Extraction](https://doi.org/10.18653/v1/2024.findings-naacl.275) |  | 0 |  | Sijia Wang, Lifu Huang |  |
| 859 |  |  [Asking More Informative Questions for Grounded Retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.276) |  | 0 |  | Sedrick Keh, Justin T. Chiu, Daniel Fried |  |
| 860 |  |  [Efficient Citer: Tuning Large Language Models for Enhanced Answer Quality and Verification](https://doi.org/10.18653/v1/2024.findings-naacl.277) |  | 0 |  | Marzieh S. Tahaei, Aref Jafari, Ahmad Rashid, David AlfonsoHermelo, Khalil Bibi, Yimeng Wu, Ali Ghodsi, Boxing Chen, Mehdi Rezagholizadeh |  |
| 861 |  |  [Addressing Healthcare-related Racial and LGBTQ+ Biases in Pretrained Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.278) |  | 0 |  | Sean Xie, Saeed Hassanpour, Soroush Vosoughi |  |
| 862 |  |  [ATG: Benchmarking Automated Theorem Generation for Generative Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.279) |  | 0 |  | Xiaohan Lin, Qingxing Cao, Yinya Huang, Zhicheng Yang, Zhengying Liu, Zhenguo Li, Xiaodan Liang |  |
| 863 |  |  [Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization](https://doi.org/10.18653/v1/2024.findings-naacl.280) |  | 0 |  | Yixin Liu, Alexander R. Fabbri, Jiawen Chen, Yilun Zhao, Simeng Han, Shafiq Joty, Pengfei Liu, Dragomir Radev, ChienSheng Wu, Arman Cohan |  |
| 864 |  |  [NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge](https://doi.org/10.18653/v1/2024.findings-naacl.281) |  | 0 |  | Phillip Howard, Junlin Wang, Vasudev Lal, Gadi Singer, Yejin Choi, Swabha Swayamdipta |  |
| 865 |  |  [Emotion-Anchored Contrastive Learning Framework for Emotion Recognition in Conversation](https://doi.org/10.18653/v1/2024.findings-naacl.282) |  | 0 |  | Fangxu Yu, Junjie Guo, Zhen Wu, Xinyu Dai |  |
| 866 |  |  [SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models](https://doi.org/10.18653/v1/2024.findings-naacl.283) |  | 0 |  | Shicheng Liu, Jialiang Xu, Wesley Tjangnaka, Sina J. Semnani, Chen Jie Yu, Monica Lam |  |
| 867 |  |  [On Evaluating the Integration of Reasoning and Action in LLM Agents with Database Question Answering](https://doi.org/10.18653/v1/2024.findings-naacl.284) |  | 0 |  | Linyong Nan, Ellen Zhang, Weijin Zou, Yilun Zhao, Wenfei Zhou, Arman Cohan |  |
| 868 |  |  [CARE: Extracting Experimental Findings From Clinical Literature](https://doi.org/10.18653/v1/2024.findings-naacl.285) |  | 0 |  | Aakanksha Naik, Bailey Kuehl, Erin Bransom, Doug Downey, Tom Hope |  |
| 869 |  |  [Personalized Federated Learning for Text Classification with Gradient-Free Prompt Tuning](https://doi.org/10.18653/v1/2024.findings-naacl.286) |  | 0 |  | Rui Wang, Tong Yu, Ruiyi Zhang, Sungchul Kim, Ryan A. Rossi, Handong Zhao, Junda Wu, Subrata Mitra, Lina Yao, Ricardo Henao |  |
| 870 |  |  [SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation](https://doi.org/10.18653/v1/2024.findings-naacl.287) |  | 0 |  | Shasha Guo, Lizi Liao, Jing Zhang, Yanling Wang, Cuiping Li, Hong Chen |  |
| 871 |  |  [Biomedical Entity Representation with Graph-Augmented Multi-Objective Transformer](https://doi.org/10.18653/v1/2024.findings-naacl.288) |  | 0 |  | Andrey Sakhovskiy, Natalia Semenova, Artur Kadurin, Elena Tutubalina |  |
| 872 |  |  [Cross-Lingual Summarization with Pseudo-Label Regularization](https://doi.org/10.18653/v1/2024.findings-naacl.289) |  | 0 |  | Thang Le |  |
| 873 |  |  [On the Way to Gentle AI Counselor: Politeness Cause Elicitation and Intensity Tagging in Code-mixed Hinglish Conversations for Social Good](https://doi.org/10.18653/v1/2024.findings-naacl.290) |  | 0 |  | Priyanshu Priya, Gopendra Vikram Singh, Mauajama Firdaus, Jyotsna Agrawal, Asif Ekbal |  |
| 874 |  |  [Leveraging Summarization for Unsupervised Dialogue Topic Segmentation](https://doi.org/10.18653/v1/2024.findings-naacl.291) |  | 0 |  | Aleksei Artemiev, Daniil Parinov, Alexey Grishanov, Ivan Borisov, Alexey Vasilev, Daniil Muravetskii, Aleksey Rezvykh, Aleksei Goncharov, Andrey V. Savchenko |  |
| 875 |  |  [LLaMA-Rider: Spurring Large Language Models to Explore the Open World](https://doi.org/10.18653/v1/2024.findings-naacl.292) |  | 0 |  | Yicheng Feng, Yuxuan Wang, Jiazheng Liu, Sipeng Zheng, Zongqing Lu |  |
| 876 |  |  [Contrastive Learning as a Polarizer: Mitigating Gender Bias by Fair and Biased sentences](https://doi.org/10.18653/v1/2024.findings-naacl.293) |  | 0 |  | Kyungmin Park, Sihyun Oh, Daehyun Kim, Juae Kim |  |
| 877 |  |  [PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics](https://doi.org/10.18653/v1/2024.findings-naacl.294) |  | 0 |  | Derui Zhu, Dingfan Chen, Qing Li, Zongxiong Chen, Lei Ma, Jens Grossklags, Mario Fritz |  |
| 878 |  |  [Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval](https://doi.org/10.18653/v1/2024.findings-naacl.295) |  | 0 |  | Juraj Vladika, Florian Matthes |  |
| 879 |  |  [DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers](https://doi.org/10.18653/v1/2024.findings-naacl.296) |  | 0 |  | Anna Langedijk, Hosein Mohebbi, Gabriele Sarti, Willem H. Zuidema, Jaap Jumelet |  |
| 880 |  |  [Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias](https://doi.org/10.18653/v1/2024.naacl-short.1) |  | 0 |  | Anshuman Chhabra, Hadi Askari, Prasant Mohapatra |  |
| 881 |  |  [Struc-Bench: Are Large Language Models Good at Generating Complex Structured Tabular Data?](https://doi.org/10.18653/v1/2024.naacl-short.2) |  | 0 |  | Xiangru Tang, Yiming Zong, Jason Phang, Yilun Zhao, Wangchunshu Zhou, Arman Cohan, Mark Gerstein |  |
| 882 |  |  [Improving Toponym Resolution by Predicting Attributes to Constrain Geographical Ontology Entries](https://doi.org/10.18653/v1/2024.naacl-short.3) |  | 0 |  | Zeyu Zhang, Egoitz Laparra, Steven Bethard |  |
| 883 |  |  [Advancing Regular Language Reasoning in Linear Recurrent Neural Networks](https://doi.org/10.18653/v1/2024.naacl-short.4) |  | 0 |  | TingHan Fan, TaChung Chi, Alexander Rudnicky |  |
| 884 |  |  [Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers](https://doi.org/10.18653/v1/2024.naacl-short.5) |  | 0 |  | Roy Xie, Orevaoghene Ahia, Yulia Tsvetkov, Antonios Anastasopoulos |  |
| 885 |  |  [Clear Up Confusion: Advancing Cross-Domain Few-Shot Relation Extraction through Relation-Aware Prompt Learning](https://doi.org/10.18653/v1/2024.naacl-short.6) |  | 0 |  | Ge Bai, Chenji Lu, Daichi Guo, Shilong Li, Ying Liu, Zhang Zhang, Guanting Dong, Ruifang Liu, Yong Sun |  |
| 886 |  |  [Fusion Makes Perfection: An Efficient Multi-Grained Matching Approach for Zero-Shot Relation Extraction](https://doi.org/10.18653/v1/2024.naacl-short.7) |  | 0 |  | Shilong Li, Ge Bai, Zhang Zhang, Ying Liu, Chenji Lu, Daichi Guo, Ruifang Liu, Yong Sun |  |
| 887 |  |  [Personalized Review Recommendation based on Implicit dimension mining](https://doi.org/10.18653/v1/2024.naacl-short.8) |  | 0 |  | Bei Xu, Yifan Xu |  |
| 888 |  |  [Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence](https://doi.org/10.18653/v1/2024.naacl-short.9) |  | 0 |  | Yinhong Liu, Yixuan Su, Ehsan Shareghi, Nigel Collier |  |
| 889 |  |  [Returning to the Start: Generating Narratives with Related Endpoints](https://doi.org/10.18653/v1/2024.naacl-short.10) |  | 0 |  | Anneliese Brei, Chao Zhao, Snigdha Chaturvedi |  |
| 890 |  |  [Unified Examination of Entity Linking in Absence of Candidate Sets](https://doi.org/10.18653/v1/2024.naacl-short.11) |  | 0 |  | Nicolas Ong, Hassan Shavarani, Anoop Sarkar |  |
| 891 |  |  [MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages](https://doi.org/10.18653/v1/2024.naacl-short.12) |  | 0 |  | Daryna Dementieva, Nikolay Babakov, Alexander Panchenko |  |
| 892 |  |  [SKICSE: Sentence Knowable Information Prompted by LLMs Improves Contrastive Sentence Embeddings](https://doi.org/10.18653/v1/2024.naacl-short.13) |  | 0 |  | Fangwei Ou, Jinan Xu |  |
| 893 |  |  [A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models](https://doi.org/10.18653/v1/2024.naacl-short.14) |  | 0 |  | Jaylen Jones, Lingbo Mo, Eric FoslerLussier, Huan Sun |  |
| 894 |  |  [How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes](https://doi.org/10.18653/v1/2024.naacl-short.15) |  | 0 |  | Harmon Bhasin, Timothy Ossowski, Yiqiao Zhong, Junjie Hu |  |
| 895 |  |  [CELI: Simple yet Effective Approach to Enhance Out-of-Domain Generalization of Cross-Encoders](https://doi.org/10.18653/v1/2024.naacl-short.16) |  | 0 |  | Xinyu Zhang, Minghan Li, Jimmy Lin |  |
| 896 |  |  [ContrastiveMix: Overcoming Code-Mixing Dilemma in Cross-Lingual Transfer for Information Retrieval](https://doi.org/10.18653/v1/2024.naacl-short.17) |  | 0 |  | Junggeun Do, Jaeseong Lee, Seungwon Hwang |  |
| 897 |  |  [SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window](https://doi.org/10.18653/v1/2024.naacl-short.18) |  | 0 |  | Vikas Raunak, Tom Kocmi, Matt Post |  |
| 898 |  |  [Separately Parameterizing Singleton Detection Improves End-to-end Neural Coreference Resolution](https://doi.org/10.18653/v1/2024.naacl-short.19) |  | 0 |  | Xiyuan Zou, Yiran Li, Ian Porada, Jackie C. K. Cheung |  |
| 899 |  |  [Unveiling Divergent Inductive Biases of LLMs on Temporal Data](https://doi.org/10.18653/v1/2024.naacl-short.20) |  | 0 |  | Sindhu Kishore, Hangfeng He |  |
| 900 |  |  [On Retrieval Augmentation and the Limitations of Language Model Training](https://doi.org/10.18653/v1/2024.naacl-short.21) |  | 0 |  | TingRui Chiang, Xinyan Yu, Joshua Robinson, Ollie Liu, Isabelle Lee, Dani Yogatama |  |
| 901 |  |  [GenDecider: Integrating "None of the Candidates" Judgments in Zero-Shot Entity Linking Re-ranking](https://doi.org/10.18653/v1/2024.naacl-short.22) |  | 0 |  | Kang Zhou, Yuepei Li, Qing Wang, Qiao Qiao, Qi Li |  |
| 902 |  |  [Advancing the Robustness of Large Language Models through Self-Denoised Smoothing](https://doi.org/10.18653/v1/2024.naacl-short.23) |  | 0 |  | Jiabao Ji, Bairu Hou, Zhen Zhang, Guanhua Zhang, Wenqi Fan, Qing Li, Yang Zhang, Gaowen Liu, Sijia Liu, Shiyu Chang |  |
| 903 |  |  [Can LLM's Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis](https://doi.org/10.18653/v1/2024.naacl-short.24) |  | 0 |  | Vishnu Sashank Dorbala, Sanjoy Chowdhury, Dinesh Manocha |  |
| 904 |  |  [On the Role of Summary Content Units in Text Summarization Evaluation](https://doi.org/10.18653/v1/2024.naacl-short.25) |  | 0 |  | Marcel Nawrath, Agnieszka Nowak, Tristan Ratz, Danilo C. Walenta, Juri Opitz, Leonardo F. R. Ribeiro, João Sedoc, Daniel Deutsch, Simon Mille, Yixin Liu, Sebastian Gehrmann, Lining Zhang, Saad Mahamood, Miruna Clinciu, Khyathi Raghavi Chandu, Yufang Hou |  |
| 905 |  |  [More room for language: Investigating the effect of retrieval on language models](https://doi.org/10.18653/v1/2024.naacl-short.26) |  | 0 |  | David Samuel, Lucas Georges Gabriel Charpentier, Sondre Wold |  |
| 906 |  |  [Discourse-Aware In-Context Learning for Temporal Expression Normalization](https://doi.org/10.18653/v1/2024.naacl-short.27) |  | 0 |  | Akash Kumar Gautam, Lukas Lange, Jannik Strötgen |  |
| 907 |  |  [Contextualizing Argument Quality Assessment with Relevant Knowledge](https://doi.org/10.18653/v1/2024.naacl-short.28) |  | 0 |  | Darshan Deshpande, Zhivar Sourati, Filip Ilievski, Fred Morstatter |  |
| 908 |  |  [Selective Perception: Learning Concise State Descriptions for Language Model Actors](https://doi.org/10.18653/v1/2024.naacl-short.29) |  | 0 |  | Kolby Nottingham, Yasaman Razeghi, Kyungmin Kim, JB Lanier, Pierre Baldi, Roy Fox, Sameer Singh |  |
| 909 |  |  [ALOHa: A New Measure for Hallucination in Captioning Models](https://doi.org/10.18653/v1/2024.naacl-short.30) |  | 0 |  | Suzanne Petryk, David M. Chan, Anish Kachinthaya, Haodi Zou, John F. Canny, Joseph Gonzalez, Trevor Darrell |  |
| 910 |  |  [Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels](https://doi.org/10.18653/v1/2024.naacl-short.31) |  | 0 |  | Honglei Zhuang, Zhen Qin, Kai Hui, Junru Wu, Le Yan, Xuanhui Wang, Michael Bendersky |  |
| 911 |  |  [LLM-Driven Knowledge Injection Advances Zero-Shot and Cross-Target Stance Detection](https://doi.org/10.18653/v1/2024.naacl-short.32) |  | 0 |  | Zhao Zhang, Yiming Li, Jin Zhang, Hui Xu |  |
| 912 |  |  [Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information](https://doi.org/10.18653/v1/2024.naacl-short.33) |  | 0 |  | Shadi Iskander, Kira Radinsky, Yonatan Belinkov |  |
| 913 |  |  [Direct Preference Optimization for Neural Machine Translation with Minimum Bayes Risk Decoding](https://doi.org/10.18653/v1/2024.naacl-short.34) |  | 0 |  | Guangyu Yang, Jinghong Chen, Weizhe Lin, Bill Byrne |  |
| 914 |  |  [EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning](https://doi.org/10.18653/v1/2024.naacl-short.35) |  | 0 |  | Raja Sekhar Reddy Mekala, Yasaman Razeghi, Sameer Singh |  |
| 915 |  |  [LEAF: Language Learners' English Essays and Feedback Corpus](https://doi.org/10.18653/v1/2024.naacl-short.36) |  | 0 |  | Shabnam Behzad, Omid Kashefi, Swapna Somasundaran |  |
| 916 |  |  [Zero-Shot vs. Translation-Based Cross-Lingual Transfer: The Case of Lexical Gaps](https://doi.org/10.18653/v1/2024.naacl-short.37) |  | 0 |  | Abteen Ebrahimi, Katharina von der Wense |  |
| 917 |  |  [On the True Distribution Approximation of Minimum Bayes-Risk Decoding](https://doi.org/10.18653/v1/2024.naacl-short.38) |  | 0 |  | Atsumoto Ohashi, Ukyo Honda, Tetsuro Morimura, Yuu Jinnai |  |
| 918 |  |  [Rehearsal-Free Modular and Compositional Continual Learning for Language Models](https://doi.org/10.18653/v1/2024.naacl-short.39) |  | 0 |  | Mingyang Wang, Heike Adel, Lukas Lange, Jannik Strötgen, Hinrich Schütze |  |
| 919 |  |  [Llama meets EU: Investigating the European political spectrum through the lens of LLMs](https://doi.org/10.18653/v1/2024.naacl-short.40) |  | 0 |  | Ilias Chalkidis, Stephanie Brandl |  |
| 920 |  |  [M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation](https://doi.org/10.18653/v1/2024.naacl-short.41) |  | 0 |  | Benjamin Hsu, Xiaoyu Liu, Huayang Li, Yoshinari Fujinuma, Maria Nadejde, Xing Niu, Ron Litman, Yair Kittenplon, Raghavendra Reddy Pappagari |  |
| 921 |  |  [Control-DAG: Constrained Decoding for Non-Autoregressive Directed Acyclic T5 using Weighted Finite State Automata](https://doi.org/10.18653/v1/2024.naacl-short.42) |  | 0 |  | Jinghong Chen, Weizhe Lin, Jingbiao Mei, Bill Byrne |  |
| 922 |  |  [Do Vision-Language Models Understand Compound Nouns?](https://doi.org/10.18653/v1/2024.naacl-short.43) |  | 0 |  | Sonal Kumar, Sreyan Ghosh, S. Sakshi, Utkarsh Tyagi, Dinesh Manocha |  |
| 923 |  |  [Is Prompt Transfer Always Effective? An Empirical Study of Prompt Transfer for Question Answering](https://doi.org/10.18653/v1/2024.naacl-short.44) |  | 0 |  | Minji Jung, Soyeon Park, Jeewoo Sul, Yong Suk Choi |  |
| 924 |  |  [Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers](https://doi.org/10.18653/v1/2024.naacl-short.45) |  | 0 |  | Georgios Pantazopoulos, Alessandro Suglia, Oliver Lemon, Arash Eshghi |  |
| 925 |  |  [Do Multilingual Language Models Think Better in English?](https://doi.org/10.18653/v1/2024.naacl-short.46) |  | 0 |  | Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, Mikel Artetxe |  |
| 926 |  |  [A Continued Pretrained LLM Approach for Automatic Medical Note Generation](https://doi.org/10.18653/v1/2024.naacl-short.47) |  | 0 |  | Dong Yuan, Eti Rastogi, Gautam Naik, Sree Prasanna Rajagopal, Sagar Goyal, Fen Zhao, Bharath Chintagunta, Jeff Ward |  |
| 927 |  |  [Lost in Translation? Translation Errors and Challenges for Fair Assessment of Text-to-Image Models on Multilingual Concepts](https://doi.org/10.18653/v1/2024.naacl-short.48) |  | 0 |  | Michael Saxon, Yiran Luo, Sharon Levy, Chitta Baral, Yezhou Yang, William Yang Wang |  |
| 928 |  |  [Self-Improving for Zero-Shot Named Entity Recognition with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-short.49) |  | 0 |  | Tingyu Xie, Qi Li, Yan Zhang, Zuozhu Liu, Hongwei Wang |  |
| 929 |  |  [Lifelong Event Detection with Embedding Space Separation and Compaction](https://doi.org/10.18653/v1/2024.naacl-short.50) |  | 0 |  | Chengwei Qin, Ruirui Chen, Ruochen Zhao, Wenhan Xia, Shafiq Joty |  |
| 930 |  |  [Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion](https://doi.org/10.18653/v1/2024.naacl-short.51) |  | 0 |  | Smriti Singh, Cornelia Caragea, Junyi Jessy Li |  |
| 931 |  |  [CPopQA: Ranking Cultural Concept Popularity by LLMs](https://doi.org/10.18653/v1/2024.naacl-short.52) |  | 0 |  | Ming Jiang, Mansi Joshi |  |
| 932 |  |  [The Impact of Language on Arithmetic Proficiency: A Multilingual Investigation with Cross-Agent Checking Computation](https://doi.org/10.18653/v1/2024.naacl-short.53) |  | 0 |  | ChungChi Chen, Hiroya Takamura, Ichiro Kobayashi, Yusuke Miyao |  |
| 933 |  |  [Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning](https://doi.org/10.18653/v1/2024.naacl-short.54) |  | 0 |  | Philipp Borchert, Jochen De Weerdt, MarieFrancine Moens |  |
| 934 |  |  [A diverse Multilingual News Headlines Dataset from around the World](https://doi.org/10.18653/v1/2024.naacl-short.55) |  | 0 |  | Felix Leeb, Bernhard Schölkopf |  |
| 935 |  |  [The Unreasonable Effectiveness of Random Target Embeddings for Continuous-Output Neural Machine Translation](https://doi.org/10.18653/v1/2024.naacl-short.56) |  | 0 |  | Evgeniia Tokarchuk, Vlad Niculae |  |
| 936 |  |  [Efficient Sample-Specific Encoder Perturbations](https://doi.org/10.18653/v1/2024.naacl-short.57) |  | 0 |  | Yassir Fathullah, Mark J. F. Gales |  |
| 937 |  |  [Diverse Perspectives, Divergent Models: Cross-Cultural Evaluation of Depression Detection on Twitter](https://doi.org/10.18653/v1/2024.naacl-short.58) |  | 0 |  | Nuredin Ali Abdelkadir, Charles Zhang, Ned Mayo, Stevie Chancellor |  |
| 938 |  |  [Removing RLHF Protections in GPT-4 via Fine-Tuning](https://doi.org/10.18653/v1/2024.naacl-short.59) |  | 0 |  | Qiusi Zhan, Richard Fang, Rohan Bindu, Akul Gupta, Tatsunori Hashimoto, Daniel Kang |  |
| 939 |  |  [LifeTox: Unveiling Implicit Toxicity in Life Advice](https://doi.org/10.18653/v1/2024.naacl-short.60) |  | 0 |  | Minbeom Kim, Jahyun Koo, Hwanhee Lee, Joonsuk Park, Hwaran Lee, Kyomin Jung |  |
| 940 |  |  [Arithmetic Reasoning with LLM: Prolog Generation & Permutation](https://doi.org/10.18653/v1/2024.naacl-short.61) |  | 0 |  | Xiaocheng Yang, Bingsen Chen, YikCheung Tam |  |
| 941 |  |  [Verifying Claims About Metaphors with Large-Scale Automatic Metaphor Identification](https://doi.org/10.18653/v1/2024.naacl-short.62) |  | 0 |  | Kotaro Aono, Ryohei Sasano, Koichi Takeda |  |
| 942 |  |  [InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis](https://doi.org/10.18653/v1/2024.naacl-short.63) |  | 0 |  | Kevin Scaria, Himanshu Gupta, Siddharth Goyal, Saurabh Arjun Sawant, Swaroop Mishra, Chitta Baral |  |
| 943 |  |  [MEMORY-VQ: Compression for Tractable Internet-Scale Memory](https://doi.org/10.18653/v1/2024.naacl-short.64) |  | 0 |  | Yury Zemlyanskiy, Michiel de Jong, Luke Vilnis, Santiago Ontañón, William W. Cohen, Sumit Sanghai, Joshua Ainslie |  |
| 944 |  |  [Unveiling the Magic: Investigating Attention Distillation in Retrieval-Augmented Generation](https://doi.org/10.18653/v1/2024.naacl-short.65) |  | 0 |  | Zizhong Li, Haopeng Zhang, Jiawei Zhang |  |
| 945 |  |  [Improving Factuality in Clinical Abstractive Multi-Document Summarization by Guided Continued Pre-training](https://doi.org/10.18653/v1/2024.naacl-short.66) |  | 0 |  | Ahmed Elhady, Khaled Mostafa Elsayed, Eneko Agirre, Mikel Artetxe |  |
| 946 |  |  [MuLan: A Study of Fact Mutability in Language Models](https://doi.org/10.18653/v1/2024.naacl-short.67) |  | 0 |  | Constanza Fierro, Nicolas Garneau, Emanuele Bugliarello, Yova Kementchedjhieva, Anders Søgaard |  |
| 947 |  |  [Language-Independent Representations Improve Zero-Shot Summarization](https://doi.org/10.18653/v1/2024.naacl-short.68) |  | 0 |  | Vladimir Solovyev, Danni Liu, Jan Niehues |  |
| 948 |  |  [Trusting Your Evidence: Hallucinate Less with Context-aware Decoding](https://doi.org/10.18653/v1/2024.naacl-short.69) |  | 0 |  | Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, Wentau Yih |  |
| 949 |  |  [GuyLingo: The Republic of Guyana Creole Corpora](https://doi.org/10.18653/v1/2024.naacl-short.70) |  | 0 |  | Christopher Clarke, Roland Daynauth, Jason Mars, Charlene Wilkinson, Hubert Devonish |  |
| 950 |  |  [DoubleLingo: Causal Estimation with Large Language Models](https://doi.org/10.18653/v1/2024.naacl-short.71) |  | 0 |  | Marko Veljanovski, Zach WoodDoughty |  |
| 951 |  |  [Improved Text Emotion Prediction Using Combined Valence and Arousal Ordinal Classification](https://doi.org/10.18653/v1/2024.naacl-short.72) |  | 0 |  | Michail Mitsios, Georgios Vamvoukakis, Georgia Maniati, Nikolaos Ellinas, Georgios Dimitriou, Konstantinos Markopoulos, Panos Kakoulidis, Alexandra Vioni, Myrsini Christidou, Junkwang Oh, Gunu Jho, Inchul Hwang, Georgios Vardaxoglou, Aimilios Chalamandaris, Pirros Tsiakoulis, Spyros Raptis |  |
| 952 |  |  [On Narrative Question Answering Skills](https://doi.org/10.18653/v1/2024.naacl-short.73) |  | 0 |  | Emil Kalbaliyev, Kairit Sirts |  |
| 953 |  |  [Order-Based Pre-training Strategies for Procedural Text Understanding](https://doi.org/10.18653/v1/2024.naacl-short.74) |  | 0 |  | Abhilash Nandy, Yash Kulkarni, Pawan Goyal, Niloy Ganguly |  |
| 954 |  |  [Breaking the Language Barrier: Can Direct Inference Outperform Pre-Translation in Multilingual LLM Applications?](https://doi.org/10.18653/v1/2024.naacl-short.75) |  | 0 |  | Yotam Intrator, Matan Halfon, Roman Goldenberg, Reut Tsarfaty, Matan Eyal, Ehud Rivlin, Yossi Matias, Natalia Aizenberg |  |

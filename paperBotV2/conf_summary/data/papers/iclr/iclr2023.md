# ICLR2023

## 会议论文列表

本会议共有 2013 篇论文

| 序号 | 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 |  |  [The First Tiny Papers Track at ICLR 2023, Tiny Papers @ ICLR 2023, Kigali, Rwanda, May 5, 2023](https://openreview.net/group?id=ICLR.cc/2023/TinyPapers) |  | 0 |  | Krystal Maughan, Rosanne Liu, Thomas F. Burns |  |
| 2 |  |  [Statistical Property Testing for Generative Models](https://openreview.net/forum?id=xmY_plRB15j) |  | 0 | Generative models that produce images, text, or other types of data are recently be equipped with more powerful capabilities. Nevertheless, in some use cases of the generated data (e.g., using it for model training), one must ensure that the synthetic data points satisfy some properties that make... | ChihHong Cheng, Emmanouil Seferis, Simon Burton |  |
| 3 |  |  [Can Conformal Prediction Obtain Meaningful Safety Guarantees for ML Models?](https://openreview.net/forum?id=5aO1lsEJGu) |  | 0 | Conformal Prediction (CP) has been recently proposed as a methodology to calibrate the predictions of Machine Learning (ML) models so that they can output rigorous quantification of their uncertainties. For example, one can calibrate the predictions of an ML model into prediction sets, that... | ChihHong Cheng, Emmanouil Seferis, Simon Burton |  |
| 4 |  |  [A two-parameter learnable Logmoid Activation Unit](https://openreview.net/forum?id=LcXWYmA8Ek) |  | 0 | A novel learnable Logmoid Activation Unit (LAU) is proposed as, $f(x)=x\ln(1+\alpha\textrm{sigmoid}(\beta x))$, by parameterizing Sigmoid with two hyper-parameters $\alpha$ and $\beta$ that are optimized by the back-propagation algorithm. The end-to-end deep neural networks with learnable LAUs can... | Lingfang Li, Mingxing Luo, Xingzhou Zheng, Xuemei Zhou |  |
| 5 |  |  [Cross Domain Vulnerability Detection using Graph Contrastive Learning](https://openreview.net/forum?id=rrZtzI7xj2b) |  | 0 | To overcome the difficulty of finding good-quality labeled data in domains such as vulnerability detection, Self--Supervised Learning (SSL) methods such as Contrastive Learning (CL) algorithms were developed. We evaluate the performance of one such state-of-the-art CL method, GraphCL, that trains... | Kevin W. Hamlen, Latifur Khan, Mahmoud Zamani, Saquib Irtiza, Shamila Wickramasuriya |  |
| 6 |  |  [Tiny Attention: A Simple yet Effective Method for Learning Contextual Word Embeddings](https://openreview.net/forum?id=BWWrDHaP29) |  | 0 | Contextual Word Embedding (CWE) obtained via the Attention Mechanism in Transformer (AMT) models is one of the key drivers of the current revolution in Natural Language Processing. Previous techniques for learning CWEs are not only inferior to AMT but also are largely subpar to the simple... | Narayana Murthy Kavi, Renjith P. Ravindran |  |
| 7 |  |  [Training Data Eigenvector Dynamics in the EigenPro Implementation of the Neural Tangent Kernel and Recursive Feature Machines](https://openreview.net/forum?id=8WiNDyXgj6) |  | 0 | There has been much recent work on kernel methods as a viable alternative to deep neural networks (DNNs). The advent of the $\textit{Neural Tangent Kernel}$ (NTK) has brought on renewed interest in these methods and their application to typical deep learning tasks. Recently, kernels have been shown... | Cyril Gorlla |  |
| 8 |  |  [Metric Transform: Exploring beyond Affine Transform for Neural Networks](https://openreview.net/forum?id=fVuTIiTBky) |  | 0 | Artificial Neural Networks(ANN) of varying architectures are generally paired with linear transformation at the core. However, we find dot product neurons with global influence less interpretable as compared to a more local influence of euclidean distance (as used in RBF). In this work, we explore... | Binod Bhattarai, Suman Sapkota |  |
| 9 |  |  [MaskedFusion360: Reconstruct LiDAR Data by Querying Camera Features](https://openreview.net/forum?id=mIEMVZ47aNA) |  | 0 | In self-driving applications, LiDAR data provides accurate information about distances in 3D but lacks the semantic richness of camera data. Therefore, state-of-the-art methods for perception in urban scenes fuse data from both sensor types. In this work, we introduce a novel self-supervised method... | Carlos Fernández Lopez, Marvin Klemp, Royden Wagner |  |
| 10 |  |  [Meta-Learning for Subject Adaptation in Low-Data Environments for EEG-Based Motor Imagery Brain-Computer Interfaces](https://openreview.net/forum?id=7QqlQW9hJ8J) |  | 0 | Motor imagery classification from Electroencephalogram (EEG) signals involves decoding information during the imagination of specific movements. However, learning representations for EEG-based motor imagery classification is challenging due to inter-subject variability and differences in mental... | Arnav Pati, Debasis Samanta, Deepak Mewada |  |
| 11 |  |  [Fostering Effective Communication Between Humans and Machines](https://openreview.net/forum?id=AHnLJBD7xKx) |  | 0 | With the growing usage of smartphones, digital communication has become significant. This paper describes the primary research conducted to study user interaction patterns on smartphones. Results show that the time between two touches, or the editorial context duration, is just 5 to 10 seconds for... | Biju Dominic, Jieya Rawal, Karthika Kamath, Kirtana Sunil Phatnani, Tanya Upadhyay |  |
| 12 |  |  [Transfer Learning on Kinyarwanda Tweets Sentiment Analysis](https://openreview.net/forum?id=7lyEQXHkGpl) |  | 0 | Pretrained models available on platform such as Hugging Face have become a valuable resource for machine learning community, particularly for natural language processing task. In this study, we evaluated the performance of Kinyarwanda and English pretrained models for sentiment analysis of... | Roger Byakunda |  |
| 13 |  |  [Symbolic Regression in Financial Economics](https://openreview.net/forum?id=RuCQRXk7a7G) |  | 0 | We apply symbolic regression, the machine learning approach of recovering models from data, in financial economics. Specifically, we present a data set consisting of equations that cover a broad range of topics in financial economics. These equations are built off a common set of mathematical... | Jiacheng Liu, Siqi Guo |  |
| 14 |  |  [FRESCO: Federated Reinforcement Energy System for Cooperative Optimization](https://openreview.net/forum?id=75mWq5j4iso) |  | 0 | The rise in renewable energy is creating new dynamics in the energy grid that promise to create a cleaner and more participative energy grid, where technology plays a crucial part in creating the required flexibility to achieve the vision of the next-generation grid. This work presents FRESCO, a... | Martin Takác, Nicolas M. Cuadrado, Roberto Alejandro Gutiérrez Guillén |  |
| 15 |  |  [Learning Rotation-Agnostic Representations via Group Equivariant VAEs](https://openreview.net/forum?id=jbNqgEJf0EI) |  | 0 | An emerging field in representation learning involves the study of group-equivariant neural networks, that leverage concepts from group representation theory to design neural architectures that can exploit discrete and continuous symmetries to produce more general representations. Following this... | Ahmedeo Shokry, Antonio Norelli |  |
| 16 |  |  [Can Text Encoders be Deceived by Length Attack?](https://openreview.net/forum?id=KPHbtTtCDw) |  | 0 | Albeit \textit{de facto} to use in training dense retrieval models, we observe that contrastive learning is prone to length overfitting, making it vulnerable to adversarial length attacks. We examine the behaviour of this phenomenon and propose an editing method to mitigate this problem. We find... | Chenghao Xiao, G. Thomas Hudson, Noura Al Moubayed, Phil Blunsom, Zhongtian Sun, Zihuiwen Ye |  |
| 17 |  |  [Whispering Across the Continent: Collecting and Analyzing African Culture Using Community Radios](https://openreview.net/forum?id=kidk_E11QQ) |  | 0 | African culture is rich and diverse, but much of its knowledge is held by the elders of the community and passed down through oral traditions. With globalization, young Africans are becoming increasingly disconnected from their roots, making it essential to collect and preserve this knowledge.... | Guy Adingono Nkama, Joseph Domguia |  |
| 18 |  |  [Handling unstructured data for operator learning using implicit neural representations](https://openreview.net/forum?id=e2gSQqH3V10) |  | 0 | Operator learning methods are too often constrained by a fixed sampling of both the input and output functions. We propose a novel method to allow current operator learning methods to learn on any sampling. We show that our method can perform inference on unseen samplings, and that it allows... | Patrick Gallinari, Thomas X. Wang |  |
| 19 |  |  [Model Extraction Attacks on DistilBERT](https://openreview.net/forum?id=njpSzZ6mCU) |  | 0 | This paper investigates model extraction attacks, where an adversary can train a substitute model by collecting data through query access to a victim model and stealing its functionality. We use DistilBERT as the victim model due to its smaller size and faster processing speed. The results... | Amro Salman, Ayman Saeed, Khalid N. Elmadani, Sharief Babiker |  |
| 20 |  |  [One Important Thing To Do Before Federated Training](https://openreview.net/forum?id=qq-bA-VLUN) |  | 0 | Previous research in Federated learning (FL) have emphasized privacy protection, model optimization, and so on, meanwhile, they overlooked how to choose the appropriate FL algorithm for a new federation with preserving data privacy. In our study, we provide a formal problem formulation for... | DeChuan Zhan, Wenqian Li, Yan Pang, Yichu Xu, Yinchuan Li, Yunfeng Shao |  |
| 21 |  |  [Insights into the mechanism behind reusing Teacher's classifier in Knowledge Distillation](https://openreview.net/forum?id=_cL7Uj4LXAJ) |  | 0 | Knowledge distillation (KD) has emerged as an effective approach to compress deep neural networks by transferring knowledge from a powerful yet cumbersome teacher model to a lightweight student model. Recent research has suggested that re-using the teacher's final layer (i.e., the classifier) can... | Kinshuk Dua |  |
| 22 |  |  [When will federated learning transfer from generalization to personalization?](https://openreview.net/forum?id=iCqvQSvar5V) |  | 0 | The timing of personalization refers to determining when to train and update personalized models for the participants in Personalized federated learning. Determining the timing for personalization contributes to improving the overall efficiency of federated learning. We propose that training... | Jiaming Pei, Lukun Wang, Wenxuan Liu |  |
| 23 |  |  [A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion](https://openreview.net/forum?id=S9NTReFikL2) |  | 0 | Speech Emotion Recognition (SER) is a challenging task. In this paper, we introduce a modality conversion concept aimed at enhancing emotion recognition performance on the MELD dataset. We assess our approach through two experiments: first, a method named Modality-Conversion that employs automatic... | Ali Satvaty, Hossein Sameti, Zeinab Sadat Taghavi |  |
| 24 |  |  [Fairness Under Partial Observability](https://openreview.net/forum?id=if1Mmrxf-pq) |  | 0 | The purpose of this article is to discuss an important challenge faced in \`\`real life'' when trying to implement \emph{group} fairness-aware models and algorithms. Here, we focus specifically on the role that uncertainty and ambiguity play and revisit the case where protected attributes are only... | Francois BuetGolfouse, Islam Utyagulov, Peter Hill |  |
| 25 |  |  [Geodesic Mode Connectivity](https://openreview.net/forum?id=cFtt9fU7YB6) |  | 0 | Mode connectivity is a phenomenon where trained models are connected by a path of low loss. We reframe this in the context of Information Geometry, where neural networks are studied as spaces of parameterized distributions with curved geometry. We hypothesize that shortest paths in these spaces,... | Charlie Tan, Rudolf Laine, Sarah Zhao, Theodore Long |  |
| 26 |  |  [Pursuit Policies in Dynamic Environments](https://openreview.net/forum?id=_cZLvP7LAt7) |  | 0 | Cooperative pursuit is a popular multi-agent reinforcement learning (MARL) game where a team of predators target prey while avoiding obstacles. Previous literature has largely considered the impact of different predator, prey abilities on learning. Here, we investigate the impact of dynamic... | Andréa W. Richa, Joseph L. Briones |  |
| 27 |  |  [Resource-efficient image inpainting](https://openreview.net/forum?id=OJILbuOodvm) |  | 0 | Image inpainting refers to the synthesis of missing regions in an image, which can help restore occluded or degraded areas and also serve as a precursor task for self-supervision. The current state-of-the-art models for image inpainting are computationally heavy as they are based on vision... | Amit Sethi, Dharshan Sampath Kumar, Pranav Jeevan |  |
| 28 |  |  [Recursive Reasoning with Neural Networks](https://openreview.net/forum?id=TS8l4VS7_BK) |  | 0 | Many problems can naturally be thought about recursively. However, neural networks fundamentally cannot reason this way on arbitrarily large problems. This is because they do not have the memory to maintain state for the maximum recursion depth required. Solving this issue would enable neural... | Dulhan Hansaja Jayalath, Jonas Jürß |  |
| 29 |  |  [SUDANESE ARABIC DIALECT ENCODING USING XLM-RoBERTa LANGUAGE MODEL: Zol-ROBERTA](https://openreview.net/forum?id=wUEY2CdQGi1) |  | 0 | XLM-RoBERTa has proven to be very efficient at Natural Language Understanding (NLU), as it allows to achieve state-of-the-art results in most NLU tasks. In this work we aim to utilize the power of XLM-RoBERTa in Sudanese Arabic dialect. We collected over 6 million sentences in Sudanese dialect and... | Duaa Badradein Alshareif, Hiba Hassan S. M. Ali, Muhammed Yahya Saeed, Taiseer Abdulateef Fadlalla |  |
| 30 |  |  [Reducing the Effect of Incomplete Annotations in Object Detection for Histopathology](https://openreview.net/forum?id=PIfJnq9kpdw) |  | 0 | Training neural networks for object detection usually requires decent amounts of data to produce great results. Apart from the image variety, the number of annotated objects is a crucial factor for success. In histopathology, the average annotation density is very high, resulting in... | Denys Kaliuzhnyi, Dmytro Fishman, Mikhail Papkov |  |
| 31 |  |  [Experimenting with Multimodal AutoML: Detection and Evaluation of Alzheimer's Disease](https://openreview.net/forum?id=nSqrgBKBGkv) |  | 0 | This paper describes an experiment using AutoML, AutoGluon Tabular, to discover multimodal models for MMSE regression and AD detection. Using the ADReSSo dataset, this paper reports enhanced performance in classification models and comparable performance in regression models to the baseline,... | Saurav Keshari Aryal, Ujjawal Shah |  |
| 32 |  |  [GFlowNets with Human Feedback](https://openreview.net/forum?id=2KxH_4US0ZH) |  | 0 | We propose the GFlowNets with Human Feedback (GFlowHF) framework to improve the exploration of training language models. For tasks where the reward is unknown, we fit the reward function through human evaluations on different trajectories. The goal of GFlowHF is to learn a policy that is strictly... | Jianye Hao, Shuang Luo, Yinchuan Li, Yunfeng Shao |  |
| 33 |  |  [Attention-likelihood relationship in Transformers](https://openreview.net/forum?id=R82eeIF4rP_) |  | 0 | We analyze how large language models (LLMs) represent out-of-context words, investigating their reliance on the given context to capture their semantics. Our likelihood-guided text perturbations reveal a correlation between token likelihood and attention values in transformer-based language models.... | Fabrizio Silvestri, Valentino Maiorca, Valeria Ruscio |  |
| 34 |  |  [Truly Generative Data Augmentation for Image Segmentation - Case of Cloud Images](https://openreview.net/forum?id=cQ_eEMsc6p) |  | 0 | Supervised learning frameworks frequently rely on semantic image segmentation, which necessitates a substantial amount of annotated data. Existing methodologies for data augmentation either employ image transformations that are limited by the cardinality of the original dataset or employ generative... | Mayank Jain, Soumyabrata Dev |  |
| 35 |  |  [Fast Fourier Convolutions in Self-Supervised Neural Networks for Image Denoising](https://openreview.net/forum?id=ghfL1e2rOd) |  | 0 | Recently, denoising convolutional neural networks (CNN) have started to outperform classical denoising algorithms. However, CNNs performance could be constrained by the limited receptive field of regular convolution. To mitigate this problem, a new modification for CNNs was proposed: Fast Fourier... | Joonas Ariva, Mikhail Papkov |  |
| 36 |  |  [Personalized Federated Learning for Medical Segmentation using Hypernetworks](https://openreview.net/forum?id=lpcO1957Tv) |  | 0 | In federated learning (FL), several clients jointly train a shared model without sharing their data, maintaining data privacy and reducing communication costs. In personalized federated learning (PFL), each client has their own model, and models are trained jointly. Hypernetworks have been shown to... | Gal Chechik, Hilit Segev |  |
| 37 |  |  [Career Path Modeling and Recommendations with Linkedin Career Data and Predicted Salary Estimations](https://openreview.net/forum?id=R5NNAThG0i) |  | 0 | Career planning involves devising a sequence of steps that build up an ideal career path for a person. However, career planning has become more complex in recent years, demanding the need for better models and systems for recommending Career Paths. With that in mind, we explored new variables and... | Aaron Santillan, Carl John Vinas, Micaela Tayoto Cerilla, Michael B. Dela Fuente |  |
| 38 |  |  [Sleep Deprivation in the Forward-Forward Algorithm](https://openreview.net/forum?id=q_lJooPbX_) |  | 0 | This paper aims to explore the separation of the two forward passes in the Forward-Forward algorithm from a biological perspective in the context of sleep. We show the size of the gap between the sleep and awake phase influences the learning capabilities of the algorithm and highlight the... | David DinucuJianu, Mircea Tudor Lica |  |
| 39 |  |  [MetaXLR - Mixed Language Meta Representation Transformation for Low-resource Cross-lingual Learning based on Multi-Armed Bandit](https://openreview.net/forum?id=nF70Sl-HUZ) |  | 0 | Transfer learning for extremely low-resource languages is a challenging task as there is no large-scale monolingual corpora for pre-training or sufficient annotated data for fine-tuning. We follow the work of (Xia et al., 2021) which suggests using meta learning for transfer learning from a single... | Eyal Orgad, Liat Bezalel |  |
| 40 |  |  [Prune and Tune: Improving Efficient Pruning Techniques for Massive Language Models](https://openreview.net/forum?id=cKlgcx7nSZ) |  | 0 | Massive language models with billions of parameters have significant compute expenses and thus can benefit from pruning. Pruning techniques for massive models are typically iterative and require extensive weight retraining after pruning. SparseGPT, a recently introduced one-shot technique for... | Aaquib Syed, Phillip Guo, Vijaykaarti Sundarapandiyan |  |
| 41 |  |  [Model Extraction Attacks on Arabic BERT-Based APIs](https://openreview.net/forum?id=XptW6NuULJ) |  | 0 | In this paper, we study the feasibility of performing Model Extraction attacks on Arabic BERT-based APIs. In our experiments, we try to perform these attacks under different scenarios and observe the accuracy of the extracted model against the victim model. We then propose a method for protecting... | Anas Showk, Hassan Abbelkarim, Khalid N. Elmadani, Mohammed Eltahir |  |
| 42 |  |  [IMITATION LEARNING USING THE FORWARD-FORWARD ALGORITHM](https://openreview.net/forum?id=baF9FqIdTY) |  | 0 | The forward-forward (FF) algorithm has been recently introduced as a novel approach to training neural networks in a way that approximates the behavior of real neurons. Nevertheless, its application has been limited to visual domains and has not been investigated in the context of imitation... | Insik Chung, Isaac Han, KyungJoong Kim |  |
| 43 |  |  [The Geometry of Multilingual Language Models: An Equality Lens](https://openreview.net/forum?id=dGuMR8tLDs) |  | 0 | Understanding the representations of different languages in multilingual language models is essential for comprehending their cross-lingual properties, predicting their performance on downstream tasks, and identifying any biases across languages. In our study, we analyze the geometry of three... | Cheril Shah, Manan Suri, Yashashree Chandak |  |
| 44 |  |  [Dynamic Human AI Collaboration](https://openreview.net/forum?id=Muwb2KohnX) |  | 0 | Domain experts possess valuable knowledge and insights that can help improve the accuracy and relevance of the machine learning (ML) models. By incorporating expert opinions, the models can capture important nuances and factors that may not be captured by data-driven methods alone. The integration... | Francois BuetGolfouse, Kabir Thakur, Parth Pahwa |  |
| 45 |  |  [The Responsibility Problem in Neural Networks with Unordered Targets](https://openreview.net/forum?id=jd7Hy1jRiv4) |  | 0 | We discuss the discontinuities that arise when mapping unordered objects to neural network outputs of fixed permutation, referred to as the responsibility problem. Prior work has proved the existence of the issue by identifying a single discontinuity. Here, we show that discontinuities under such... | Ben Hayes, Charalampos Saitis, György Fazekas |  |
| 46 |  |  [Concept Understanding in Large Language Models: An Empirical Study](https://openreview.net/forum?id=losgEaOWIL7) |  | 0 | Large Language Models (LLMs) have demonstrated their superior comprehension and expressiveness across a wide range of tasks, and exhibited remarkable capabilities in real-world applications. Hence, it is crucial to investigate their potential and limitations for trustworthy performance in both... | Jiayi Liao, Lun Du, Xu Chen |  |
| 47 |  |  [Adaptive Distance Message Passing From the Multi-Relational Edge View](https://openreview.net/forum?id=rAT51tL04I2) |  | 0 | Message-passing graph neural networks (MP-GNNs) excel in deep learning on graphs. Despite their success in various studies, they are limited by passing information to the fixed length $k$ distance neighbouring nodes, where $k$ is the number of layers. In reality, different types of edges... | Alexandra I. Cristea, Jialin Yu, Pietro Lio, Zhongtian Sun |  |
| 48 |  |  [Sustainable Resource Management](https://openreview.net/forum?id=DLwlmWwmJBi) |  | 0 | Given finite resources and growing demand, a supply-side balance must be struck between maximising profit and sustainable resource management. This paper combines the two techniques in a stochastic setting to create a sustainable profit model and uses Gaussian processes to estimate and bound... | Francois BuetGolfouse, Nicholas William David Martin, Peter Hill, Tingsheng Tan |  |
| 49 |  |  [Chain Of Thought Prompting Under Streaming Batch: A Case Study](https://openreview.net/forum?id=n5aZMLXVndP) |  | 0 | Recently, Large Language Models (LLMs) have demonstrated remarkable capa- bilities. Chain-of-Thought (CoT) has been proposed as a way of assisting LLMs in performing complex reasoning. However, developing effective prompts can be a challenging and labor-intensive task. Many studies come out of some... | Yuxin Tang |  |
| 50 |  |  [Language Models can do Zero-Shot Visual Referring Expression Comprehension](https://openreview.net/forum?id=F7mdgA7c2zD) |  | 0 | The use of visual referring expressions is an important aspect of human-robot in- teractions. Comprehending referring expressions (ReC) like “the brown cookie near the cup” requires to understand both self-referential expressions, “brown cookie”, and relational referential expressions, “near the... | Hong Yang, Hongyuan Zhu, Shaohua Li, Xiuchao Sui, Yan Wu |  |
| 51 |  |  [Simple Parameter-free Self-attention Approximation](https://openreview.net/forum?id=isodM5jTA7h) |  | 0 | The hybrid model of self-attention and convolution is one of the methods to lighten ViT. The quadratic computational complexity of self-attention with respect to token length limits the efficiency of ViT on edge devices. We propose a self-attention approximation without training parameters, called... | Jing Hao, Liang Gao, Shumin Han, Xinyu Li, Yiping Gao, Yuwen Zhai |  |
| 52 |  |  [Neuromodulation Gated Transformer](https://openreview.net/forum?id=cYKtDg5JnxV) |  | 0 | We introduce a novel architecture, the Neuromodulation Gated Transformer (NGT), which is a simple implementation of neuromodulation in transformers via a multiplicative effect. We compare it to baselines and show that it results in the best average performance on the SuperGLUE benchmark validation... | Diana Benavides Prado, Gillian Dobbie, Joshua Bensemann, Kobe Knowles, Michael Witbrock, Vithya Yogarajan, Yang Chen |  |
| 53 |  |  [Decomposing Causality and Fairness](https://openreview.net/forum?id=Lm7z2vYergk) |  | 0 | It is often informative to decompose key quantities of interest into smaller components, in order to develop a better understanding of the key quantity. In this paper, we focus causality and fairness, where bias attribution can be particularly useful. We show how quantities can be broken down based... | Francois BuetGolfouse, Peter Hill |  |
| 54 |  |  [Self-Supervised Image Denoising with Swin Transformer](https://openreview.net/forum?id=EARgl3EH-nq) |  | 0 | Self-supervised image denoising aims to reconstruct signal from a noisy image with no additional information. Typically, this is accomplished by means of specific frameworks built upon fully-convolutional neural networks. In two such frameworks, Noise2Self and Noise2Same, we replaced conventional... | Mikhail Papkov, Pavel Chizhov |  |
| 55 |  |  [SimbaML: Connecting Mechanistic Models and Machine Learning with Augmented Data](https://openreview.net/forum?id=1wtUadpmVzu) |  | 0 | Training sophisticated machine learning (ML) models requires large datasets that are difficult or expensive to collect for many applications. If prior knowledge about system dynamics is available, mechanistic representations can be used to supplement real-world data. We present SimbaML... | Benedict B. Heyder, Bernhard Y. Renard, Julian Zabbarov, Katharina Baum, Lukas Drews, Maximilian Kleissl, Pascal Iversen, Simon Witzke |  |
| 56 |  |  [GeValDi: Generative Validation of Discriminative Models](https://openreview.net/forum?id=zwywBS3GyFs) |  | 0 | Evaluation of machine learning (ML) models is critically important for reliable use. Though typically done via unseen data, such validation datasets often need to be large and hard to procure; additionally, mutliple models may perform equally well on such datasets. To address these challenges, we... | Adrian Weller, Juyeon Heo, Katherine M. Collins, Matthew Ashman, Umang Bhatt, Vivek Palaniappan |  |
| 57 |  |  [Regularized Offline GFlowNets](https://openreview.net/forum?id=kbhUUAMZmQT) |  | 0 | We propose the regularized offline generative flow networks (RO-GFlowNets) that does not rely on online sampling. Since offline datasets usually cannot cover the entire state space, traditional GFlowNets cannot accurately predict the action sampling probability for each state. To address this... | Haozhi Wang, Jianye Hao, Yinchuan Li, Yunfeng Shao |  |
| 58 |  |  [Secure Communication Model for Quantum Federated Learning: A Proof of Concept](https://openreview.net/forum?id=xZGPLvRpf4N) |  | 0 | We design a model of Post Quantum Cryptography (PQC) Quantum Federated Learning (QFL). We develop a proof of concept with a dynamic server selection and study convergence and security conditions. We develop a preliminary study with a proof of concept model of post-quantum secure QFL. | Dev Gurung, Gang Li, Shiva Raj Pokhrel |  |
| 59 |  |  [Learn to Select: Efficient Cross-device Federated Learning via Reinforcement Learning](https://openreview.net/forum?id=wecTsVkrjit) |  | 0 | Federated Learning (FL) is a collaborative training method that provides data privacy in the age of big data. However, it is often ineffective on edge devices due to their heterogeneous and constrained resources. The primary challenge is to identify devices with useful training data and available... | Chunlin Tian, Li Li, Zhan Shi |  |
| 60 |  |  [A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge](https://openreview.net/forum?id=hli7A0ioiS_) |  | 0 | Transformer-based pretrained language models (PLMs) have shown to pre-learn rich prior knowledge. To assist data-to-text task, we propose a new dynamic prompt tuning method, DPTAK, to retrieve knowledge from a PLM that is associated with individual data-text pairs. Our method increases the... | Alex Yuxuan Peng, Jiamou Liu, Michael Witbrock, Qianqian Qi, Qiming Bao |  |
| 61 |  |  [MARKOVIAN EMBEDDINGS FOR COALITIONAL BARGAINING GAMES](https://openreview.net/forum?id=1LeLyB6T0JM) |  | 0 | We examine the Markovian properties of coalition bargaining games, in particular, the case where past rejected proposals cannot be repeated. We propose a Markovian embedding with filtrations to render the sates Markovian and thus, fit into the framework of stochastic games. | Lucia CipolinaKun |  |
| 62 |  |  [The Point to Which Soft Actor-Critic Converges](https://openreview.net/forum?id=1_PEwKmTepo) |  | 0 | Soft actor-critic is a successful successor over soft Q-learning. While lived under maximum entropy framework, their relationship is still unclear. In this paper, we prove that in the limit they converge to the same solution. This is appealing since it translates the optimization from an arduous to... | Jianfei Ma |  |
| 63 |  |  [No Double Descent in Self-Supervised Learning](https://openreview.net/forum?id=qNJRvdKDGYg) |  | 0 | Most investigations into double descent have focused on supervised models while the few works studying self-supervised settings find a surprising lack of the phenomenon. These results imply that double descent may not exist in self-supervised models. We show this empirically in two additional... | Alisia Maria Lupidi, Dulhan Hansaja Jayalath, Yonatan Gideoni |  |
| 64 |  |  [Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers](https://openreview.net/forum?id=kBkou5ucR_d) |  | 0 | Annealed Importance Sampling (AIS) moves particles along a Markov chain from a tractable initial distribution to an intractable target distribution. The recently proposed Differentiable AIS (DAIS) (Geffner & Domke, 2021; Zhang et al., 2021) enables efficient optimization of the transition kernels... | Johannes Zenn, Robert Bamler |  |
| 65 |  |  [Generalised Lookahead Optimiser](https://openreview.net/forum?id=uNrSvEr9Lqc) |  | 0 | The vast majority of deep learning models are trained using SGD or one of its variants. Zhang et al. (2019) suggested the Lookahead optimiser as an alternative which enjoys remarkable test performance on many established datasets and mod- els. In this work we investigate a generalisation of this... | CostinAndrei Oncescu, Jack Valmadre, João F. Henriques |  |
| 66 |  |  [Revisiting CounteRGAN for Counterfactual Explainability of Graphs](https://openreview.net/forum?id=d0m0Rl15q3g) |  | 0 | Counterfactual explainability (CE) has been widely explored in various domains ranging from medical image diagnosis to self-driving cars. Graph CE (GCE), on the other hand, and especially, generative-based GCE has yet to be explored. Here, we adapt CounteRGAN, an image-based generative approach, to... | Bardh Prenkaj, Giovanni Stilo, Mario Alfonso PradoRomero |  |
| 67 |  |  [Language Models Inversely Scale on Piecewise Function Evaluation with Biased Examples](https://openreview.net/forum?id=GJhsHNKm7kj) |  | 0 | We investigate whether pretrained language models (LMs) can be misled by providing them with factually correct, but unrepresentative/biased examples, in the context of integer-to-integer piecewise functions. Given the definition of a piecewise function and several examples of the function’s... | Atif Mahmud, Bradley C. A. Brown, Jordan Juravsky, Ryan Ehrlich, Wais Shahbaz |  |
| 68 |  |  [RETHINKING POSITIONAL EMBEDDING: A CASE STUDY IN TEMPORAL EVENT SEQUENCE MODELLING](https://openreview.net/forum?id=iF2w_kqmYmw) |  | 0 | In this paper, we present a time-decaying encoding as an alternative to sinusoidal positional encoding in the transformer architecture. We evaluate our approach in the context of an educational domain involving 14,043 question-solving interactions from 1,260 students. We argue that including... | Effat Farhana |  |
| 69 |  |  [Exploring Efficient and Simple Initialization Strategies for Bayesian Optimization with SETUP-BO](https://openreview.net/forum?id=TFrzVBZk05g) |  | 0 | This paper studies the effectiveness of random and grid initialization strategies in SETUP-BO, a self-tuning Bayesian optimization algorithm. Our experiments on benchmark functions compare the performance of these initialization strategies to deterministic initialization. The results show that... | Mohammad Taghi Manzuri, Seyed Ali YaghoubNejad |  |
| 70 |  |  [Quota Constraints for Diversity Interventions in Subset Selection](https://openreview.net/forum?id=x4MuUFPKEIj) |  | 0 | The combinatorial optimization problem of subset selection is often modeled as maximizing a set function that captures inter-element dependencies under some capacity/matroid constraints. In this paper, we examine this problem under “quota constraints” where the selected subset must meet some... | Neeraja Abhyankar |  |
| 71 |  |  [Mitigating Metastable Failures in Distributed Systems with Offline Reinforcement Learning](https://openreview.net/forum?id=zYF6NLJl6LM) |  | 0 | This paper introduces a load-shedding mechanism that mitigates metastable failures through offline reinforcement learning (RL). Previous studies have heavily focused on heuristics that are reactive and limited in generalization, while online RL algorithms face challenges in accurately simulating... | Christina Delimitrou, Daochen Zha, Francis Y. Yan, G. Edward Suh, Tianjun Zhang, Yueying Li |  |
| 72 |  |  [Knowledge Distillation of BERT Language Model on the Arabic Language](https://openreview.net/forum?id=-bMH1Sk8SSF) |  | 0 | The absence of good Arabic language models led to significant setbacks in the Arabic language related tasks and lag with respect to robustness and accuracy. While a pre-trained version of BERT on Arabic language is available, a smaller distilled version could be proven to be highly scalable. In... | Abrar Elidrisi, Hager Adil, Muhammed Saeed |  |
| 73 |  |  [Offensiveness as an Opinion: Dissecting population-level Label Distributions](https://openreview.net/forum?id=DoOiwBcRir3) |  | 0 | Human annotation is an essential component for building human-in-the-loop machine learning systems (MLs). The diverse human disagreement that arises during annotation is often obscured because of majority voting label aggregation used for training MLs. When the minority opinion is removed in this... | Christopher M. Homan, Sarah Luger, Tharindu Cyril Weerasooriya, Yu Liang |  |
| 74 |  |  [How do ConvNets Understand Image Intensity?](https://openreview.net/forum?id=z2Gr8YqsimF) |  | 0 | Convolutional Neural Networks (ConvNets) usually rely on edge/shape information to classify images. Visualization methods developed over the last decade confirm that ConvNets rely on edge information. We investigate situations where the ConvNet needs to rely on image intensity in addition to shape.... | Jackson Kaunismaa, Michael Guerzhoy |  |
| 75 |  |  [Learning Weight Sensitivity from Entropy](https://openreview.net/forum?id=x_adzmY6PQ5) |  | 0 | Multiple network pruning methods have used connection sensitivity of each weight to prune their network. This paper proposes a meta-learning approach to learn sensitivity of weights based on their entropy, or change, during the training phase. We have experimentally shown the validity of such an... | Novena Agnes |  |
| 76 |  |  [A Study on Sample Diversity in Generative Models: GANs vs. Diffusion Models](https://openreview.net/forum?id=BQpCuJoMykZ) |  | 0 | In this project, we compare the sample diversity of two generative models: Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs). GANs have achieved impressive results in generating high-quality samples, but have been known to suffer from the issue of mode... | Reza Bayat |  |
| 77 |  |  [Artificial Intelligent Life: A New Perspective on Artificial General Intelligence](https://openreview.net/forum?id=XCbe51-arJt) |  | 0 | We propose artificial intelligent life (AILife) as a new perspective to approach artificial general intelligence, similar to a living organism in reality. Unlike machine learning approaches that focus on reward functions and mathematical optimizations, AILife seeks to develop an artificial organism... | Borui Cai, Yao Zhao, Yong Xiang |  |
| 78 |  |  [Generative AI for Therapy? Opportunities and Barriers for ChatGPT in Speech-Language Therapy](https://openreview.net/forum?id=cRZSr6Tpr1S) |  | 0 | Speech-language pathologists (SLPs) are health professionals who work with children and adults with various communication disorders in areas such as speech, language, hearing, and voice. The rise of voice assistants and chatbots brings new opportunities for SLPs and points to new opportunities and... | Felix JuefeiXu, Yao Du |  |
| 79 |  |  [The Art of Embedding Fusion: Optimizing Hate Speech Detection](https://openreview.net/forum?id=1yXbt6_o6av) |  | 0 | Hate speech detection is a challenging natural language processing task that requires capturing linguistic and contextual nuances. Pre-trained language models (PLMs) offer rich semantic representations of text that can improve this task. However there is still limited knowledge about ways to... | Mohammad Aflah Khan, Mohit Jain, Neemesh Yadav, Sanyam Goyal |  |
| 80 |  |  [COLLABORATIVE CONCEPT DRIFT DETECTION](https://openreview.net/forum?id=STpRX-XCO6t) |  | 0 | Collaborative Concept Drift Detection (C2D2) combines Fast Correlated Based Filtering (FCBF) and Singular Value Decomposition (SVD) to detect concept drifts in 5 synthetic datasets. We compare our results against 6 diveregence tests and introduce Performance Gain Update Cost Ratio (PGUCR). Post-hoc... | Beverly Abadines Quon, JeanLuc Gaudiot |  |
| 81 |  |  [End-to-End Learnable Masks With Differentiable Indexing](https://openreview.net/forum?id=EyliiBqhFz) |  | 0 | An essential step towards developing efficient learning algorithms involves being able to work with as little data as possible to achieve good performance. For this reason, sparse representation learning is a crucial avenue of computer vision research. However, sparsity-inducing methods like... | Ashwath Shetty, Dibyanshu Shekhar, Ilia Sucholutsky, Sree Harsha Nelaturu |  |
| 82 |  |  [FigGen: Text to Scientific Figure Generation](https://openreview.net/forum?id=Hx_iTXnCR5) |  | 0 | The generative modeling landscape has experienced tremendous growth in recent years, particularly in generating natural images and art. Recent techniques have shown impressive potential in creating complex visual compositions while delivering impressive realism and quality. However,... | David Vázquez, Issam H. Laradji, Juan A. Rodríguez, Marco Pedersoli, Pau Rodríguez |  |
| 83 |  |  [Evaluating Impact of Emoticons and Pre-processing on Sentiment Classification of Translated African Tweets](https://openreview.net/forum?id=OMARmh02Ruk) |  | 0 | This paper examines the impact of emoticons and pre-processing on sentiment classification for English translations of 11 African languages. Using AfriSenti-SemEval datasets, Roberta and Twitter-Roberta models are fine-tuned, and standard classification metrics are used to assess performance. The... | Gaurav Adhikari, Saurav Keshari Aryal |  |
| 84 |  |  [SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels](https://openreview.net/forum?id=OiSbJbVWBJT) |  | 0 | Rule-based text data augmentation is widely used for NLP tasks due to its simplicity. However, this method can potentially damage the original meaning of the text, ultimately hurting the performance of the model. To overcome this limitation, we propose a straightforward technique for applying soft... | Juhwan Choi, Junho Lee, Kyohoon Jin, Sangmin Song, YoungBin Kim |  |
| 85 |  |  [MatPropXtractor: Generate to Extract](https://openreview.net/forum?id=5CdkvFyatt2) |  | 0 | The field of materials science has amassed a wealth of information about materials in text publications, however, such information is often confined within the publication. A lack of standardized structure and naming consistency preclude the information from being effectively utilized for research... | Aswathy Ajith, Ian T. Foster, Kyle Chard, Marcus Schwarting, Zhi Hong |  |
| 86 |  |  [Zero-Shot Classification Reveals Potential Positive Sentiment Bias in African Languages Translations](https://openreview.net/forum?id=-AIukSeLAz9) |  | 0 | Natural Language Processing research into African languages has been limited, with over 2000 languages still needing to be studied. We employ the AfriSenti-SemEval dataset, a recently released resource that provides annotated tweets across 13 African languages, for sentiment analysis to address... | Howard Prioleau, Hrishav Sapkota, Saurav Keshari Aryal |  |
| 87 |  |  [Lesion Search with Self-supervised Learning](https://openreview.net/forum?id=c-YTzVUkfAW) |  | 0 | Content-based image retrieval (CBIR) with self-supervised learning (SSL) accelerates clinicians’ interpretation of similar images without manual annotations. We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization to... | Daniel Haehn, Jiali Cheng, Kristin Qi |  |
| 88 |  |  [Feature Importance Analysis for Mini Mental Status Score Prediction in Alzheimer's Disease](https://openreview.net/forum?id=GPA-BPLwYHf) |  | 0 | This research article proposes developing predictive models to forecast Mini-Mental State Exam (MMSE) scores using the 54 most important features identified from the current state-of-the-art model. The study employs the SHapley Additive exPlanations (SHAP) method to explore feature importance and... | Howard Prioleau, Saurav Keshari Aryal |  |
| 89 |  |  [On a Relation Between the Rate-Distortion Function and Optimal Transport](https://openreview.net/forum?id=1F8pPnUinbU) |  | 0 | We discuss a relationship between rate-distortion and optimal transport (OT) theory, even though they seem to be unrelated at first glance. In particular, we show that a function defined via an extremal entropic OT distance is equivalent to the rate-distortion function. We numerically verify this... | Eric Lei, Hamed Hassani, Shirin Saeedi Bidokhti |  |
| 90 |  |  [Is CLIP Fooled by Optical Illusions?](https://openreview.net/forum?id=YdGkE4Ugg2C) |  | 0 | Recent large machine learning models such as CLIP have shown impressive generalization performance for various perception tasks. In this work, we explore to what extent they model the human cognitive process. We focus our attention on how these models perceive optical illusions. We present a simple... | Jerry Ngo, Phillip Isola, Swami Sankaranarayanan |  |
| 91 |  |  [Seeing in Words: Learning to Classify through Language Bottlenecks](https://openreview.net/forum?id=_QreMdMNIz-) |  | 0 | Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks. In contrast, humans can explain their predictions using succinct and intuitive descriptions. To incorporate explainability into neural networks, we train a vision model whose feature... | Jonas Geiping, Khalid Saifullah, Micah Goldblum, Tom Goldstein, Yuxin Wen |  |
| 92 |  |  [Towards Stochastic Gradient Variance Reduction by Solving a Filtering Problem](https://openreview.net/forum?id=0sxmoci9Ma) |  | 0 | Stochastic gradient descent is commonly used to optimize deep neural networks, but it often produces noisy and unreliable gradient estimates that hinder convergence. To address this issue, we introduce \textbf{Filter Gradient Descent} (FGD), a family of stochastic optimization algorithms that... | Xingyi Yang |  |
| 93 |  |  [MACHINE TRANSLATION BASELINES FOR ARABIC - SWAHILI](https://openreview.net/forum?id=aVepdnlRb5) |  | 0 | Building neural machine translation (NMT) systems for low-resource languages poses several challenges, mainly due to the lack of parallel data. In this research, we propose a baseline NMT system for translating between Arabic and Swahili. Despite being spoken by nearly 300 million individuals... | Ahmed Emadeldin Almahady, Asim Awad Osman, Hiba Hassan Sayed, Muhammed Saeed |  |
| 94 |  |  [Accuracy of white box and black box adversarial attacks on a sign activation 01 loss neural network ensemble](https://openreview.net/forum?id=QimsmhYvsf) |  | 0 | In this work we ask the question: is an ensemble of single hidden layer sign activation 01 loss networks more robust to white box and black box adversarial attacks than an ensemble of its differentiable counterpart of cross-entropy loss with relu activations and an ensemble of the approximate... | Usman Roshan, Yunzhe Xue |  |
| 95 |  |  [TopEx: Topic-based Explanations for Model Comparison](https://openreview.net/forum?id=AidIUjh__t) |  | 0 | Meaningfully comparing language models is challenging with current explanation methods. Current explanations are overwhelming for humans due to large vocabularies or incomparable across models. We present TopEx, an explanation method that enables a level playing field for comparing language models... | Adam Stein, Eric Wong, Lyle H. Ungar, Shreya Havaldar |  |
| 96 |  |  [GeneDAE: A Sparse Denoising Autoencoder for Deriving Interpretable Gene Embeddings](https://openreview.net/forum?id=cxmjk8O3Yn) |  | 0 | A challenge in genomics research involves identifying functionally relevant genes associated with diseases. We present GeneDAE, a sparse denoising autoencoder that extracts gene representations from large-scale population-level genotype data, which can then be used to identify gene-to-disease... | Andrew Hornback, Karan Samel, May Dongmei Wang, Monica Isgut, Neha Jain |  |
| 97 |  |  [Improving Hyperspectral Adversarial Robustness Under Multiple Attacks](https://openreview.net/forum?id=XHfWgU2IiP) |  | 0 | Semantic segmentation models classifying hyperspectral images (HSI) are vulnerable to adversarial examples. Traditional approaches to adversarial robustness focus on training or retraining a single network on attacked data, however, in the presence of multiple attacks these approaches decrease in... | Nicholas Soucy, Salimeh Yasaei Sekeh |  |
| 98 |  |  [Prompt Programming for the Visual Domain](https://openreview.net/forum?id=hBz5h3C9Sq) |  | 0 | In this work, we ask how text-to-image synthesis via large language models can effectively probe imagery that embodies fidelity and imagination. We investigate this question in the context of prompts (writing to language models) in a novel probing mechanism known as prompt programming, or... | Alayt Issak, Lav R. Varshney |  |
| 99 |  |  [Mapping the Typographic Latent Space of Digits](https://openreview.net/forum?id=ufA2FuCGyz) |  | 0 | Since the advancement of handwritten text to typefaces on a computer, the human mind has evolved towards corresponding various typefaces as norms of comprehension. Current-day typefaces, much like those written by hand, exist in disparities and are governed by consensus reached among Typographers.... | Alayt Issak, Casper Harteveld, Nik Bear Brown, Sair Goetz, Sarthak Kakkar |  |
| 100 |  |  [Hyperbolic Deep Reinforcement Learning for Continuous Control](https://openreview.net/forum?id=Mrz9PgP3sT) |  | 0 | Integrating hyperbolic representations with Deep Reinforcement Learning (DRL) has recently been proposed as a promising approach for enhancing generalization and sample-efficiency in discrete control tasks. In this work, we extend hyperbolic RL to continuous control by introducing a novel... | Arnab Kumar Mondal, Edoardo Cetin, Omar Salemohamed, Sai Rajeswar |  |
| 101 |  |  [Incorporating Expert Prior Knowledge for Oral Lesion Recognition](https://openreview.net/forum?id=XXsjViheWZ) |  | 0 | External information may improve predictive accuracy and uncertainty in medical image recognition. For example in oral lesion recognition, some lesion types are implausible to occur at certain anatomical locations. We propose a strategy to induce the prior knowledge about such correlations using an... | Adeetya Patel, Camille Besombes, Sreenath Arekunnath Madathil |  |
| 102 |  |  [LEARNING LIGHTWEIGHT STRUCTURE-AWARE EMBEDDINGS FOR PROTEIN SEQUENCES](https://openreview.net/forum?id=2M8dEAJcG5) |  | 0 | Machine learning models, such as AlphaFold, have recently demonstrated remarkable accuracy in predicting the structures of protein sequences. This capability enables their use as oracles for providing structure-based information to aid other learning tasks. In this study, we investigate the use of... | Jeffrey Nivala, Philip J. Y. Leung, Sidharth Lakshmanan |  |
| 103 |  |  [Proactive policing as reinforcement learning](https://openreview.net/forum?id=lmcPpHDa0B) |  | 0 | Recent analyses of predictive policing have shown the inherent biases in such systems. We show that the models considered in fact apply to proactive policing in general, which can be also viewed as a reinforcement learning system, and thus may also lead to over-policing. | Dawson Kinsman, Tian An Wong |  |
| 104 |  |  [The Small Batch Size Anomaly in Multistep Deep Reinforcement Learning](https://openreview.net/forum?id=G0heahVv5Y) |  | 0 | We present a surprising discovery: in deep reinforcement learning, decreasing the batch size during training can dramatically improve the agent's performance when combined with multi-step learning. Both reducing batch sizes and increasing the update horizon increase the variance of the gradients,... | Johan S. ObandoCeron, Marc G. Bellemare, Pablo Samuel Castro |  |
| 105 |  |  [Bootstrapping Parallel Anchors for Relative Representations](https://openreview.net/forum?id=VBuUL2IWlq) |  | 0 | The use of relative representations for latent embeddings has shown potential in enabling latent space communication and zero-shot model stitching across a wide range of applications. Nevertheless, relative representations rely on a certain amount of parallel anchors to be given as input, which can... | Antonio Norelli, Emanuele Rodolà, Irene Cannistraci, Luca Moschella, Marco Fumero, Valentino Maiorca |  |
| 106 |  |  [A Brief History of the Speculative Measures for Autonomy](https://openreview.net/forum?id=qqKO_rrg9y) |  | 0 | This paper presents a novel summary of the history of the evolution of the measures for autonomy (i.e. self-legislating systems), from Creation myths to the study of technological autonomy, progressing through five interrelated phases. First, the original legislator of the laws of nature is... | Micah Tewers |  |
| 107 |  |  [Semantic feature verification in FLAN-T5](https://openreview.net/forum?id=_1z2Bqte5L) |  | 0 | This study evaluates the potential of a large language model for aiding in generation of semantic feature norms–a critical tool for evaluating conceptual structure in cognitive science. Building from an existing human-generated dataset, we show that machine-verified norms capture aspects of... | Kushin Mukherjee, Siddharth Suresh, Timothy T. Rogers |  |
| 108 |  |  [Augmenting Collective Intelligence through Belbin's Team Roles](https://openreview.net/forum?id=XiZOalwf_U) |  | 0 | Augmented Collective Intelligence (ACI) allows organizations to improve performance by combining human and artificial intelligence in teams. We use Belbin’s Team Roles, a popular framework that identifies nine clusters of behavioral attributes, to explore how roles might be augmented by AI tools.... | Abhishek Gupta, Emily Dardaman |  |
| 109 |  |  [Text2Face: 3D Morphable Faces From Text](https://openreview.net/forum?id=7Zyv70nGl_g) |  | 0 | We present the first 3D morphable modelling approach, whereby 3D face shape can be directly and completely defined using a textual prompt. Building on work in multi-modal learning, we extend the FLAME head model to a common image-and-text latent space. This allows for direct 3D Morphable Model... | Andrew Keeling, Nick E. Pears, Patrik Huber, Will Rowan |  |
| 110 |  |  [Towards Parametric Robust Activation Functions in Adversarial Machine Learning](https://openreview.net/forum?id=oKa5_mxHBV) |  | 0 | Machine learning's vulnerability to adversarial perturbations has been argued to stem from a learning model's non-local generalization over complex input data. Given the incomplete information in a complex dataset, a learning model captures non-linear patterns between data points with volatility in... | Alberto Luis Dominguez, Ilan Grapel, Niki Pissinou, Sheila Alemany |  |
| 111 |  |  [Understanding Label Bias in Single Positive Multi-Label Learning](https://openreview.net/forum?id=iWiwox99aJ) |  | 0 | Annotating data for multi-label classification is prohibitively expensive because every category of interest must be confirmed to be either present or absent. Recent work on single positive multi-label (SPML) learning has shown that it is possible to train effective multi-label classifiers using... | Elijah Cole, Julio Arroyo, Pietro Perona |  |
| 112 |  |  [Knowledge and Attitude of Medical Students and Doctors towards Artificial Intelligence: A study of University of Ilorin](https://openreview.net/forum?id=5lZaexgIey) |  | 0 | This study assesses the knowledge and attitudes of medical students and doctors in University of Ilorin toward Artificial Intelligence (AI) in medical education. It involved a cross-sectional study using an online survey consisting of close-ended questions. The survey targeted medical students at... | Abdulhameed Abiola Dere |  |
| 113 |  |  [Human-machine cooperation for semantic feature listing](https://openreview.net/forum?id=K-SVVOIcsP) |  | 0 | Semantic feature norms — lists of features that concepts do and do not possess — have played a central role in characterizing human conceptual knowledge, but require extensive human labor. Large language models (LLMs) offer a novel avenue for the automatic generation of such feature lists, but are... | Kushin Mukherjee, Siddharth Suresh, Timothy T. Rogers |  |
| 114 |  |  [Improving generalization by loss modification](https://openreview.net/forum?id=vHOO1lxggJ) |  | 0 | What data points from available data set should be used for training? For all subsets of available data it will generally make different solutions. We show that a simple loss modification allows to find a single solution that represents data set properties and not particular selections of data... | Michael Tetelman |  |
| 115 |  |  [A Rate-Distortion View on Model Updates](https://openreview.net/forum?id=6ry6ibTKOx) |  | 0 | Compressing model updates is critical for reducing communication costs in federated learning. We examine the problem using rate--distortion theory to present a compression method that is near-optimal in many use cases. We empirically show that common transforms applied to model updates in standard... | Jakub Konecný, Johannes Ballé, Nicole Mitchell, Zachary Charles |  |
| 116 |  |  [Text-Based Games as a Challenging Benchmark for Large Language Models](https://openreview.net/forum?id=2g4m5S_knF) |  | 0 | Text-based games (TBG) are puzzle-solving, interactive dialogue language tasks that have the potential to become a challenging intelligence benchmark for large language models (LLMs). TBGs are similar to interactive dialogue, as they require the capability for bidirectional communication in natural... | Ashkan Kazemi, Qinyue Tan, Rada Mihalcea |  |
| 117 |  |  [Learned Learning Rate Schedules for Deep Neural Network Training Using Reinforcement Learning](https://openreview.net/forum?id=0Zhwu1VaOs) |  | 0 | We present a novel strategy to generate learned learning rate schedules for any optimizer using reinforcement learning (RL). Our approach trains a Proximal Policy Optimization (PPO) agent to predict optimal learning rate schedules for SGD, which we compare with other optimizer-scheduler... | Aly El Gamal, Shreyas Subramanian, Vignesh Ganapathiraman |  |
| 118 |  |  [Speaker-Invariant Speech Recognition through Fine-Tuning on Individual-Specific Data with Voice Conversion](https://openreview.net/forum?id=CTZigc9V69) |  | 0 | In this paper, we propose a speaker-invariant speech recognition method that fine-tunes a pre-trained model (Obtained by a self-supervised learning method) on a selected subset of data containing speech from a specific individual. This fine-tuning changes the network's behavior, allowing it to... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 119 |  |  [Effect of training fragment length on Transformers in text complexity prediction](https://openreview.net/forum?id=SBqbPjVFfm) |  | 0 | With the myriad practical applications of text complexity classification, it is important to optimize the training text fragment size for performance. We experiment with fine-tuning pre-trained BERT models to classify the complexity of Russian school text using different fragment sizes for training. | Rafik Hachana, Vladimir V. Ivanov |  |
| 120 |  |  [Revisiting Bisimulation: A Sampling-Based State Similarity Pseudo-metric](https://openreview.net/forum?id=lkWvTn2IzA) |  | 0 | In reinforcement learning (RL), we typically deal with systems with large or continuous states encoded in an unstructured way. Because it is not possible to represent the value of each state, it is necessary to learn a structured representation from limited state samples to express the value... | Charline Le Lan, Rishabh Agarwal |  |
| 121 |  |  [Efficient Learning rate schedules for Stochastic Non-negative Matrix Factorization via Reinforcement Learning](https://openreview.net/forum?id=AAu_WuIiwi) |  | 0 | For deep learning training, learning rate schedules are often picked through trial and error, or hand-crafted optimization algorithms that focus mostly on maintaining stability and convergence without systemic incorporation of higher order derivative information to optimize the convergence slope.... | Aly El Gamal, Shreyas Subramanian, Vignesh Ganapathiraman |  |
| 122 |  |  [Chaotic Transformers for Deep Reinforcement Learning in Algorithmic Trading](https://openreview.net/forum?id=H2mbtfasD4K) |  | 0 | Chaotic Transformers for Deep Reinforcement Learning can be applied in algorithmic trading to improve the efficiency and effectiveness of trading strategies. In algorithmic trading, deep reinforcement learning can be used to learn trading policies that maximize the expected reward. However, due to... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 123 |  |  [Effects of Single-Attribute Control on the Music Generated by FIGARO](https://openreview.net/forum?id=G_MpqMHYo-) |  | 0 | We have experimented with controlling the musical attributes of the music generated by the FIGARO model, while evaluating the success of control and the overall musical quality. The results suggest non-trivial correlations between the musical attributes and the musical quality metrics. | Adil Khan, Rafik Hachana |  |
| 124 |  |  [Iterative weakly supervised learning for novel class object detection](https://openreview.net/forum?id=FWohKbMhlo) |  | 0 | Training object detectors for new classes usually requires collecting and labeling large amounts of data. Our paper introduces a new approach to address this issue - training novel-class object detectors using a combination of a few labeled images and weakly labeled data, that is easy to obtain. We... | Claudio Michaelis, Dejana Mandic, Wieland Brendel |  |
| 125 |  |  [BANDIT SAMPLING FOR FASTER NEURAL NETWORK TRAINING WITH SGD](https://openreview.net/forum?id=LV33sOiYCEP) |  | 0 | Importance sampling is a valuable technique in deep learning that involves sampling useful training examples more frequently to improve learning algorithms. However, obtaining reliable sample importance estimates early on in training can be challenging, as existing importance sampling methods can... | Anila Joshi, Francisco Javier Calderon, Vignesh Ganapathiraman |  |
| 126 |  |  [Train Monolingual, Infer Bilingual](https://openreview.net/forum?id=MjVdwBGkys) |  | 0 | Cross-lingual transfer learning has been studied at depth. While many methods have been developed for pretraining or fine-tuning on monolingual, multilingual and parallel corpora with the purpose of predicting on a low-resource monolingual test set; in this paper we investigate the feasibility of... | Alaeddin Selçuk Gürel, Aydin Gerek |  |
| 127 |  |  [A Simple, Fast Algorithm for Continual Learning from High-Dimensional Data](https://openreview.net/forum?id=TPTbHxeR6U) |  | 0 | As an alternative to resource-intensive deep learning approaches to the continual learning problem, we propose a simple, fast algorithm inspired by adaptive resonance theory (ART). To cope with the curse of dimensionality and avoid catastrophic forgetting, we apply incremental principal component... | Neil Ashtekar, Vasant G. Honavar |  |
| 128 |  |  [Discerning Self-Supervised Learning and Weakly Supervised Learning](https://openreview.net/forum?id=H9BGkFz-Sm) |  | 0 | The AI community has been a very rapidly growing community producing a vast amount of research in a very short span of time. These researches generate a lot of new methods and terminologies. With this scale of developments, it is very difficult to keep a track of terminologies, and under such... | Ali Jannesari, Chandan Kumar, Matthew J. Darr |  |
| 129 |  |  [DiffGANPaint: Fast Inpainting Using Denoising Diffusion GANs](https://openreview.net/forum?id=x2XNoPdXF8J) |  | 0 | Free-form image inpainting is the task of reconstructing parts of an image specified by an arbitrary binary mask. In this task, it is typically desired to generalize model capabilities to unseen mask types, rather than learning certain mask distributions. Capitalizing on the advances in diffusion... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 130 |  |  [Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis](https://openreview.net/forum?id=dJfdug9aGd8) |  | 0 | An indigenous perspective on the effectiveness of debiasing techniques for pre-trained language models (PLMs) is presented in this paper. The current techniques used to measure and debias PLMs are skewed towards the US racial biases and rely on pre-defined bias attributes (e.g. \`\`black'' vs... | Gillian Dobbie, Henry Gouk, Vithya Yogarajan |  |
| 131 |  |  [An Analysis of Transferability in Network Intrusion Detection using Distributed Deep Learning](https://openreview.net/forum?id=FPzByCI0yz1) |  | 0 | In this paper, we utilize a distributed deep learning framework to investigate transferability of network intrusion detection between federated nodes. Transferable learning makes intrusion detection systems more robust to rare attacks and enables them to adapt to real life scenarios. We analyze... | Abu Shafin Mohammad Mahdee Jameel, Aly El Gamal, Shreya Ghosh |  |
| 132 |  |  [MLP-Attention: Improving Transformer Architecture with MLP Attention Weights](https://openreview.net/forum?id=99XvUeDFYTD) |  | 0 | The Transformer architecture has revolutionized natural language processing (NLP) and has achieved state-of-the-art results in various tasks. The attention mechanism is one of the key components of the Transformer architecture, which allows the model to focus on relevant parts of the input. In the... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 133 |  |  [Averager Student: Distillation from Undistillable Teacher](https://openreview.net/forum?id=4isz71_aZN) |  | 0 | Today, some companies release their black-box model as a service for users, where users can see the model’s output corresponding to their input. However, these models can be stolen via knowledge distillation by malicious users. Recently, undistillable teacher (Ma et al., 2021) is introduced in... | Behçet Ugur Töreyin, Reyhan Kevser Keser |  |
| 134 |  |  [Inducing Document Representations from Graphs: A Blueprint](https://openreview.net/forum?id=2rp3guEM3A) |  | 0 | Representing textual documents in continuous numerical spaces is a crucial task in NLP. Early practitioners of NLP built their approach around capturing statistical patterns within documents and utilizing them as features in rich feature spaces. In contrast, contemporary state-of-the-art techniques... | Blaz Skrlj, Boshko Koloski, Marko Pranjic, Nada Lavrac, Senja Pollak |  |
| 135 |  |  [Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for Classification of Common Mental Illnesses on Social Media Posts](https://openreview.net/forum?id=a9VgV-hywP) |  | 0 | Given the current state of the world, because of existing situations around the world, millions of people suffering from mental illnesses feel isolated and unable to receive help in person. Psychological studies have shown that our state of mind can manifest itself in the linguistic features we use... | Mihir Agarwal, Pratinav Seth |  |
| 136 |  |  [Predicting Targets with Data from Non-Conforming Sources](https://openreview.net/forum?id=uMlLT_xuiE) |  | 0 | Machine learning applications to real-world settings are often tasked with making predictions on data generated by multiple sources. There are many methods for understanding when data is Out-Of-Distribution (OOD). A less explored area of importance is where OOD data can be considered... | Alexander Capstick, Payam M. Barnaghi |  |
| 137 |  |  [One Explanation Does Not Fit XIL](https://openreview.net/forum?id=o7uGWBK6Uo) |  | 0 | Current machine learning models produce outstanding results in many areas but, at the same time, suffer from shortcut learning. To address such flaws, the XIL framework has been proposed to revise a model by employing user feedback on a model's explanation. This work sheds light on the explanations... | David Steinmann, Felix Friedrich, Kristian Kersting |  |
| 138 |  |  [Fast Adversarial CNN-based Perturbation Attack on No-Reference Image- and Video-Quality Metrics](https://openreview.net/forum?id=xKf-LSD2-Jg) |  | 0 | Modern neural-network-based no-reference image- and video-quality metrics exhibit performance as high as full-reference metrics. These metrics are widely used to improve visual quality in computer vision methods and compare video processing methods. However, these metrics are not stable to... | Anastasia Antsiferova, Dmitriy S. Vatolin, Ekaterina Shumitskaya |  |
| 139 |  |  [GraphEx: A User-Centric Model-Level Explainer for Graph Neural Networks](https://openreview.net/forum?id=CuE1F1M0_yR) |  | 0 | With the increasing application of Graph Neural Networks (GNNs) in real-world domains, there is a growing need to understand the decision-making process of these models. To address this, we propose GraphEx, a model-level explainer that learns a graph generative model to approximate the distribution... | Monidipa Das, Sanghamitra Bandyopadhyay, Sayan Saha |  |
| 140 |  |  [Theta sequences as eligibility traces: A biological solution to credit assignment](https://openreview.net/forum?id=vd16AYbem3Z) |  | 0 | Credit assignment problems, for example policy evaluation in RL, often require bootstrapping prediction errors through preceding states or maintaining temporally extended memory traces; solutions which are unfavourable or implausible for biological networks of neurons. We propose theta sequences --... | Tom George |  |
| 141 |  |  [Federated Learning with Variational Autoencoders](https://openreview.net/forum?id=mvo72yTjhTl) |  | 0 | In this work we investigate the feasibility of using federated learning to train a variational autoencoder capable of generated handwritten digits when trained on the MNIST dataset. It was found that using federated learning we were able to train a model that produced comparable results to a... | Hugo Dugdale |  |
| 142 |  |  [TRACTABLE LARGE SCALE CALIBRATION WITH RL](https://openreview.net/forum?id=AXxBPw5zdl4) |  | 0 | In this work we show that Reinforcement Learning (RL) is an effective algorithm for calibration problems at a scale which traditionally applied Bayesian approaches struggle. This work uses synthetic data, so has access to ground truth parameters and it can be seen that RL learns different, arguably... | Fadel Thior, Rose Bandolo, Sekou Remy |  |
| 143 |  |  [A Variational Condition for Minimal-Residual Latent Representations](https://openreview.net/forum?id=A2VfgYliIT) |  | 0 | Autoencoders are a useful unsupervised-learning architecture that can be used to build surrogate models of systems governed by partial differential equations, enabling a more cost-effective route to study complex phenomena across science and engineering. In this article, we address two key... | Eloisa Bentivegna |  |
| 144 |  |  [Attention Based Variational Graph Auto-Encoder (AVGAE)](https://openreview.net/forum?id=j1gj0ndrk1) |  | 0 | Recently techniques such as VGAEs (Variational Graph Autoencoder) are quite popular in the unsupervised task setting and in generative modeling. Unlike conventional autoencoders, which typically use fully-connected layers to learn a latent representation of input data, VGAEs operate on... | Krishna Sri Ipsit Mantri, Nevasini Sasikumar |  |
| 145 |  |  [Generative STResnet for Crime Prediction](https://openreview.net/forum?id=-IH_dcPGWM) |  | 0 | In this work, we combine STResnet with VAE to generate crime distribution. The outputs can be used for downstream tasks such as patrol deployment planning. | Hoong Chuin Lau, Tran Phong |  |
| 146 |  |  [A Light Spectrometer Device for Crop Disease Monitoring](https://openreview.net/forum?id=KtVonyo4AS) |  | 0 | Portable devices for the early detection of crop diseases are needed to support the farmers working in the field. Spectrometers showed their potential in the detection of crop diseases. However, high interpretation skills are needed to use the currently available spectrometers. In this project, we... | Ephraim Nuwamanya, Estefania Talavera Martínez, Godliver Owomugisha, Joshua Jeremy Dhikusooka |  |
| 147 |  |  [Can Arterial Blood Pressure Predict Age? A ConvNet Classification Task](https://openreview.net/forum?id=jbBPBUGk-4) |  | 0 | Blood pressure (BP) increases throughout life, and is controlled by several feedback mechanisms in mammals. Therefore, high resolution BP data may contain information related to the health and functionality of those systems, and the organism as a whole. We used beat-to-beat BP data at different... | Abdalrhman Mostafa, Ahmed F. ElYazbi, Mohamed Abdelhack, NourMounira Z. Bakkar |  |
| 148 |  |  [Pay Attention to Multi-Channel for Improving Graph Neural Networks](https://openreview.net/forum?id=IkHVGw_Ipu) |  | 0 | We propose Multi-channel Graph Attention (MGAT) to efficiently handle channel-specific representations encoded by convolutional kernels, enhancing the incorporation of attention with graph convolutional network (GCN)-based architectures. Our experiments demonstrate the effectiveness of integrating... | ChungYi Lin, ShenLung Tung, Winston H. Hsu |  |
| 149 |  |  [pGS-CAM: Interpretable LiDAR Point Cloud Semantic Segmentation via Gradient Based Localization](https://openreview.net/forum?id=8kX0btdpAU5) |  | 0 | To extract the local information required for effective semantic segmentation of point clouds, a number of deep learning architectures typically make use of sophisticated feature extractors. Unfortunately, there has not been a lot of discussion on how to interpret their forecasts, which is... | Abhishek Kuriyal, Vaibhav Kumar |  |
| 150 |  |  [Large Language Models Perform Diagnostic Reasoning](https://openreview.net/forum?id=N0lQfjeNWOE) |  | 0 | We explore the extension of chain-of-thought (CoT) prompting to medical reasoning for the task of automatic diagnosis. Motivated by doctors' underlying reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical results demonstrate that by simply prompting large language models... | ChengKuang Wu, HsinHsi Chen, WeiLin Chen |  |
| 151 |  |  [A Simple Loss Function for Convergent Algorithm Synthesis using RNNs](https://openreview.net/forum?id=WaAJ883AqiY) |  | 0 | Running a Recurrent Neural Network (RNN) over the same input multiple times, or iterative reasoning, enables logical extrapolation, where a model can be run on problems larger than the models were trained on. The loss function used to train these networks has a profound impact on their... | Alexandre Salle, Shervin Malmasi |  |
| 152 |  |  [The Obscure Limitation of Modular Multilingual Language Models](https://openreview.net/forum?id=zEGstYVHBt) |  | 0 | We expose the limitation of modular multilingual language models (MLMs) in multilingual inference scenarios with unknown languages. Existing evaluations of modular MLMs exclude the involvement of language identification (LID) modules, which obscures the performance of real-case multilingual... | Ayu Purwarianti, Muhammad Farid Adilazuarda, Samuel Cahyawijaya |  |
| 153 |  |  [Exploratory Analysis of Scholarly Publications on Artificial Intelligence (AI) in Colonoscopy using Litstudy](https://openreview.net/forum?id=zdhCATDn_Q) |  | 0 | Due to the large number of scholarly papers on AI and colonoscopy and the short research period, it can be difficult to answer general questions about the research area, such as who the key authors are and what the key issues or insights are. We use Litstudy, a Python library, to study colonoscopy... | Mary Adewunmi |  |
| 154 |  |  [Propagate Deeper and Adaptive Graph Convolutional Networks](https://openreview.net/forum?id=RR_w2fbYmV) |  | 0 | Graph Convolutional Networks (GCNs) are the basic architecture for handling graph-structured data. Deeper GCNs are required for large and sparse graph data. As the number of layers increases, the performance of GCNs degrades, which is commonly attributed to over-smoothing but is constantly debated.... | Fan Li, Ge Yu, Lun Du, Mengyuan Chen, Sisi Zhang |  |
| 155 |  |  [L2 Norm Guided Adaptive Computation](https://openreview.net/forum?id=qW_GZYyn7C) |  | 0 | Although the human brain can adjust the amount of time and energy it uses to solve problems of varying complexity, many standard neural networks require a fixed computation budget regardless of the problem’s complexity. This work introduces L2 Adaptive Computation (LAC), a new algorithm that... | Mani Shemiranifar, Mostafa Dehghani |  |
| 156 |  |  [Efficient Temporal Denoising for Improved Depth Map Applications](https://openreview.net/forum?id=nazr0QFvHR) |  | 0 | Depth estimation involves acquiring three-dimensional information from images, which has numerous applications in downstream tasks. Although several effective monocular depth estimation algorithms have been developed, directly applying frame-by-frame depth estimation can result in flickering, which... | Pengzhi Li, Zhiheng Li |  |
| 157 |  |  [AI-based opportunistic analysis of the CT images during COVID (2021): Does living in a metropolitan area affect the vertebral body mineral density in older people?](https://openreview.net/forum?id=QRKKFN7FLm) |  | 0 | The aim of the study is to reveal the problems of using information on several territorial units (districts) of an integral urban agglomeration for an identification of interdimensional peculiarities of living in a particular area by estimating vertebral bone mineral density in Moscow residents... | Alexei V. Petraikin, Andrey V. Vlasov |  |
| 158 |  |  [One Student Knows All Experts Know: From Sparse to Dense](https://openreview.net/forum?id=1PW_txDkX7) |  | 0 | Human education system trains one student by multiple experts. Mixture-of-experts (MoE) is a powerful sparse architecture including multiple experts. However, sparse MoE model is easy to overfit, hard to deploy, and not hardware-friendly for practitioners. In this work, inspired by the human... | Fuzhao Xue, Xiaoxin He, Xiaozhe Ren, Yang You, Yuxuan Lou |  |
| 159 |  |  [AN ENSEMBLE LEARNING FRAMEWORK FOR VISIBILITY PREDICTION IN INDO-GANGETIC REGION](https://openreview.net/forum?id=WkDqZD3VRo) |  | 0 | Visibility of an area affects all forms of transportation such as sea, surface and aviation which can further affect the economy of that area. Thus it is very important to accurately estimate the visibility of an area for the upcoming days based on different parameters of the past meteorological... | Arkapal Panda, Tanmay Basu, Vaibhav Kumar |  |
| 160 |  |  [Evolutionary Federated Learning Using Particle Swarm Optimization](https://openreview.net/forum?id=fcQFbluDTX) |  | 0 | Efficient communication is a key challenge in federated learning, where multiple clients contribute to a shared model. To address this issue, reducing local computation is an effective solution. This paper proposes an innovative federated learning algorithm that utilizes Particle Swarm... | Ender Minyard, Nayan Saxena, Steven Kolawole |  |
| 161 |  |  [Understanding the Effectiveness of Cross-Domain Contrastive Unsupervised Domain Adaptation](https://openreview.net/forum?id=0GpMf9UeI3G) |  | 0 | Unsupervised domain adaptation helps to transfer learned tasks from a source to a target domain in the lack of labeled data. Recently, contrastive learning showed promising results on this setup. However, there are limitations on the performance due to unbalanced objectives between the... | Adil Khan, Adín Ramírez Rivera, Viacheslav Sinii |  |
| 162 |  |  [Performance Evaluation of Enhanced ConvNeXtTiny-based Fire Detection System in Real-world Scenarios](https://openreview.net/forum?id=A-E41oZCfrf) |  | 0 | Timely detection of fires is crucial for saving human lives and minimizing the economic and ecological impact of such incidents. Although numerous attempts have been made to identify a fire in its early stage, significant challenges remain in achieving accurate and reliable detection. Therefore, we... | Chang Choi, Haci Ismail Aslan, Taimoor Khan |  |
| 163 |  |  [Robustness Evaluation of Multi-Agent Reinforcement Learning Algorithms using GNAs](https://openreview.net/forum?id=zZjPRz0EX5T) |  | 0 | Recently, multi-agent reinforcement learning (MARL) has shown its ability in solving sequential decision-making problems in complicated multi-agent environments. However, uncertainties from observations and executions undermine its performance when MARL methods are deployed in real-world... | Jianyu Zhang, Liangliang Yang, Sihong He, Wei Zhang, Xusheng Zhang, Yishu Gong, Zhengyu Chen |  |
| 164 |  |  [State Advantage Weighting for Offline RL](https://openreview.net/forum?id=PjypHLTo29v) |  | 0 | We present \textit{state advantage weighting} for offline reinforcement learning (RL). In contrast to action advantage $A(s,a)$ that we commonly adopt in QSA learning, we leverage state advantage $A(s,s^\prime)$ and QSS learning for offline RL, hence decoupling the action from values. We expect the... | Aicheng Gong, Jiafei Lyu, Le Wan, Xiu Li, Zongqing Lu |  |
| 165 |  |  [Towards Robust Feature Learning with t-vFM Similarity for Continual Learning](https://openreview.net/forum?id=6I5i0Ytnlul) |  | 0 | Continual learning has been developed using standard supervised contrastive loss from the perspective of feature learning. Due to the data imbalance during the training, there are still challenges in learning better representations. In this work, we suggest using a different similarity metric... | Bilan Gao, YoungBin Kim |  |
| 166 |  |  [When Biology has Chemistry: Solubility And Drug Subcategory Prediction using SMILES Strings](https://openreview.net/forum?id=28si4RXwDt1) |  | 0 | Drug discovery is a complex process that requires extensive research and development. One important aspect of drug discovery is the prediction of drug properties, such as solubility. In recent years, sequence-based embedding methods, such as SMILES strings, have gained popularity in the drug... | Murray Patterson, Prakash Chourasia, Sarwan Ali |  |
| 167 |  |  [Answering Questions Over Knowledge Graphs Using Logic Programming Along with Language Models](https://openreview.net/forum?id=D2lo4toTUTo) |  | 0 | Question Answering over Knowledge Graphs (KGQA) is the task of answering natural language questions over a knowledge graph (KG). This task requires a model to reason over multiple edges of the KG to reach the right answer. In this work, we present a method to equip large language models (LLMs) with... | Kenneth Joseph, Navid Madani |  |
| 168 |  |  [Contrastive Training with more data](https://openreview.net/forum?id=ZTp85mW5nFy) |  | 0 | This paper proposes a new method of contrastive training over multiple data points, focusing on the scaling issue present when using in-batch negatives. Our approach compares transformer training with dual encoders vs training with multiple encoders. Our method can provide a feasible approach to... | Hossein Rahmani, Scott Piao, Stephen Mander |  |
| 169 |  |  [Statistical Methods for Auditing the Quality of Manual Content Reviews](https://openreview.net/forum?id=GSlYBJ3aOpC) |  | 0 | Large technology firms face the problem of moderating content on their online platforms for compliance with laws and policies. To accomplish this at the scale of billions of pieces of content per day, a combination of human and machine review are necessary to label content. Subjective judgement and... | Andrew Smart, Daniel Theron, Xuan Yang |  |
| 170 |  |  [ARTIFICIAL PSYCHOLOGY](https://openreview.net/forum?id=TqkzImZ92t8) |  | 0 | Most Deep Learning based Model Compression methods draw their inspiration from the human brain. This is an example of how powerful but overlooked abstractions from the human mind are. Hoping to benefit the discipline of one from the other, this paper aims to draw attention to a line of research at... | Mubarek Mohammed |  |
| 171 |  |  [Automated Mapping of Healthcare Concepts to a Standardized Healthcare Taxonomy](https://openreview.net/forum?id=87oCobKKS6x) |  | 0 | SNOMED CT presents an opportunity for numerous research prospects to learn medical terminologies and effectively assist the diagnosis process. In this work, we propose mapping the information in medical records to paths extracted from the SNOMED CT knowledge graph. To achieve this, we have... | AKM Shahariar Azad Rabby, Fuad Rahman, Mashrur Wasek, Mohammed Rakib, Nabeel Mohammed, Sabbir Mollah |  |
| 172 |  |  [RepFair-GAN: Mitigating Representation Bias in GANs Using Gradient Clipping](https://openreview.net/forum?id=frB4MiYGoD_) |  | 0 | This work introduces a new notion of fairness, \textit{representational fairness}, for generative models, which ensures uniform representation of demographic groups in the generated data. Vanilla GANs violate this notion even when groups are equally represented. The proposed solution is to use... | Adil Khan, Adín Ramírez Rivera, Kamil Sabbagh, Patrik Joslin Kenfack |  |
| 173 |  |  [Prior knowledge meets Neural ODEs: a two-stage training method for improved explainability](https://openreview.net/forum?id=p7sHcNt_tqo) |  | 0 | Neural Ordinary Differential Equations (ODEs) have been used extensively to model physical systems because they represent a continuous-time function that can make predictions over the entire time domain. However, most of the time, the parameters of these physical systems are subject to strict... | C. Coelho, Luís L. Ferrás, M. Fernanda P. Costa |  |
| 174 |  |  [Self-Supervised Continual Learning](https://openreview.net/forum?id=udl9OobOxZu) |  | 0 | This paper proposes \textit{Self-Supervised Continual Learning (SCL)} for regularization-based class incremental learning. The novel pretext task in SCL utilizes randomly-transformed labels without depending on data-augmented transforms. \textit{SCL} trained with a novel incremental... | Bharat Giddwani, Kartik Thakral, Mayank Vatsa, Richa Singh, Surbhi Mittal, Utkarsh Uppal |  |
| 175 |  |  [When Spiking Neural Networks Meet Temporal Attention Image Decoding and Adaptive Spiking Neuron](https://openreview.net/forum?id=MuOFB0LQKcy) |  | 0 | Spiking Neural Networks (SNNs) are capable of encoding and processing temporal information in a biologically plausible way. However, most existing SNN-based methods for image tasks do not fully exploit this feature. Moreover, they often overlook the role of adaptive threshold in spiking neurons,... | RuiJie Zhu, Xuerui Qiu, Zhaorui Wang, Zheng Luan |  |
| 176 |  |  [Characters Are Like Faces](https://openreview.net/forum?id=HM_jOWEYL7y) |  | 0 | There are over 100,000 characters in Chinese, though only four thousand of them are used in our daily life. However for cultural researchers, they interact with those Rarely Used Characters (RUCs) frequently. It would facilitate using these RUCs for them with Optical Character Recognition (OCR)... | Haoyu Deng, Yule Duan, Zhaoteng Ye |  |
| 177 |  |  [A Scalable Self-supervised Learner for Hyperspectral Image Classification](https://openreview.net/forum?id=uwbyW92Sonu) |  | 0 | Learning-based Hyperspectral image classification methods have achieved fantastic performance due to their superior ability to represent features at the cost that these methods are complex, inflexible and weak to generalize. Thus, we propose a simple and scalable pretrained model which can greatly... | Baisen Liu, Jiaming Pei, Lin Qi, Weili Kong |  |
| 178 |  |  [Optimizing MPJPE promotes miscalibration in multi-hypothesis human pose lifting](https://openreview.net/forum?id=B5riBS9HZGn) |  | 0 | Due to depth ambiguities and occlusions, lifting 2D poses to 3D is a highly ill-posed problem. Well-calibrated distributions of possible poses can make these ambiguities explicit and preserve the resulting uncertainty for downstream tasks, thus providing the necessary trustworthiness in... | Fabian H. Sinz, Mohammad Bashiri, Pawel A. Pierzchlewicz, R. James Cotton |  |
| 179 |  |  [Unsupervised Detection of Cell Assemblies with Graph Neural Networks](https://openreview.net/forum?id=Tbzv_BbjjO8) |  | 0 | Cell assemblies, putative units of neural computation, manifest themselves as repeating and temporally coordinated activity of neurons. However, understanding of their role in brain function is hampered by a lack of scalable methods for their unsupervised detection. We propose using a graph neural... | Roman Koshkin, Tomoki Fukai |  |
| 180 |  |  [Heat Up The Sentiment Learning With ICE](https://openreview.net/forum?id=wFxjFCHUkS) |  | 0 | Recently, dramatic gains have been made on the task of aspect sentiment triplet extraction (ASTE). In this paper, we introduce a straightforward pipeline model to perform two-stage sequence labeling, including aspect and opinion terms identification and aspect-opinion pair classification. To... | Hai Zhao, Yao Yao, Zuchao Li |  |
| 181 |  |  [Almost Sure Last Iterate Convergence of Sharpness-Aware Minimization](https://openreview.net/forum?id=IcDTYTI0Nx) |  | 0 | Sharpness-Aware Minimization (SAM) is an iterative optimization process to train neural networks, by which the training is guided to find flat minima, such that the solution found at convergence may generalize well. However, previous studies on the convergence of SAM have only shown the existence... | Jinseok Chung, Kyunghun Nam, Namhoon Lee |  |
| 182 |  |  [On the application and impact of ε-DP and fairness in ambulance engagement time prediction](https://openreview.net/forum?id=WKVH54a1W4) |  | 0 | This study elaborates on a complete pipeline for the development of a private and fair Machine Learning (ML) model to predict ambulance engagement time. It was shown that sensitive variables reduced their impact on model building with Random Forest as the differential privacy budget (ε) decreased... | Catuscia Palamidessi, Selene Cerna |  |
| 183 |  |  [Adversarial Policy Gradient for Learning Graph-Based Representation in Human Visual Processing](https://openreview.net/forum?id=5-ROmmBJKV) |  | 0 | This article discusses the challenges in modeling the neural mechanisms underlying human visual processing and the use of graph-based representations to capture inter-region relationships in visual processing. While graphs have shown promise in analyzing neural responses, learning an optimal graph... | Debasis Samanta, Subhrasankar Chatterjee, Subrata Pain |  |
| 184 |  |  [Federated Learning for Local and Global Data Distribution](https://openreview.net/forum?id=qX8cGLnfAd) |  | 0 | Existing research in Federated Learning focuses on synthetic or small-scale datasets, with in-house distribution posing challenges for long-term real-world use cases. We propose a novel approach that maximizes in-house (local) distribution gains while focusing on generalization. Experimental... | Akshay Agarwal, Gaurav Goswami, Mayank Vatsa, Nalini K. Ratha, Richa Singh |  |
| 185 |  |  [Is DFR for Soft Biometrics Prediction in Unconstrained Images Fair and Effective?](https://openreview.net/forum?id=rLqN6XLbON) |  | 0 | Face being a nonintrusive recognition modality, is an ideal candidate for identifying criminals. The modality is not only related to identity but can also extract several other important features such as age, race, and gender. In this preliminary research, we have collected a novel unconstrained... | Akshay Agarwal, Udaybhan Rathore |  |
| 186 |  |  [Integrating Information from Natural Language Parse Tree to Code Generation](https://openreview.net/forum?id=1WEPXTIjAd) |  | 0 | While more and more research works have considered Natural Language artifacts as the inputs of software engineering research, such as code generation, information about their graph/tree representations needs to be carefully considered. In this work, we propose an approach for integrating... | Ali Jannesari, Hung Phan |  |
| 187 |  |  [Pseudo Labels for Single Positive Multi-Label Learning](https://openreview.net/forum?id=-CH1C-aQ5pk) |  | 0 | The cost of data annotation is a substantial impediment for multi-label image classification: in every image, every category must be labeled as present or absent. Single positive multi-label (SPML) learning is a cost-effective solution, where models are trained on a single positive label per image.... | Julio Arroyo |  |
| 188 |  |  [Drowning Detection based on YOLOv8 improved by GP-GAN Augmentation](https://openreview.net/forum?id=osqgjMNm4_) |  | 0 | Drowning is a significant safety issue worldwide, and a robust computer vision-based alert system can easily prevent such tragedies in swimming pools. However, due to domain shift caused by the visual gap (potentially due to lighting, indoor scene change, pool floor color etc.) between the training... | En Wei, Simiao Ren |  |
| 189 |  |  [Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech Detection](https://openreview.net/forum?id=eaKoBpxCPe) |  | 0 | Health experts assert that hope plays a crucial role in enhancing individuals' physical and mental well-being, facilitating their recovery, and promoting restoration. Hope speech refers to \`\`YouTube comments/posts that offer support, reassurance, suggestions, inspiration, and insight.". The... | Diksha Sethi, Mohammad Aflah Khan, Neemesh Yadav, Raghav Sahni |  |
| 190 |  |  [Group Equivariant Convolutional Networks](https://openreview.net/forum?id=niyvAOOnwPM) |  | 0 | Convolutional Neural Networks (CNN) are using symmetry priors to make the best out of the properties of the data, in particular translation invariance in images. Group Equivariant CNN (Cohen & Welling, 2016) extend CNN by using invari- ances from other groups of symmetry. After exploring their... | Maya Janvier |  |
| 191 |  |  [Exploring Semantic Variations in GAN Latent Spaces via Matrix Factorization](https://openreview.net/forum?id=2Z-dQTRezZ) |  | 0 | Controlled data generation with GANs is desirable but challenging due to the nonlinearity and high dimensionality of their latent spaces. In this work, we explore image manipulations learned by GANSpace, a state-of-the-art method based on PCA. Through quantitative and qualitative assessments we... | Adil Khan, Andrey Palaev, Rustam A. Lukmanov |  |
| 192 |  |  [The Polarised Regime of identifiable Variational Autoencoders](https://openreview.net/forum?id=iSkcAjBqUHU) |  | 0 | The polarised regime—the capacity of variational autoencoders (VAEs) to discard superfluous latent variables—is well-studied in the context of “classical” VAEs with a standard Gaussian prior. In this paper, we extend these results to the case of identifiable VAEs (iVAEs). | Lisa Bonheme, Marek Grzes |  |
| 193 |  |  [Uni-Match: A Semantic Unified Model for Query-Product Retrieval](https://openreview.net/forum?id=91Bcj6sgcxt) |  | 0 | For most practical search systems, the cascaded matching-prerank-rank architecture is designed. In the prerank stage, the dual-tower structure is widely used to maintain efficiency. However, due to the lack of interaction between query and document, this architecture could only take into account... | Qihang Zhao, RuiJie Zhu, Yunrui Ge, Zhenyang Zhu |  |
| 194 |  |  [Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention](https://openreview.net/forum?id=Peb3QdR8zzP) |  | 0 | Compared with standard text, understanding dialogue is more challenging for machines as the dynamic and unexpected semantic changes in each turn. To model such inconsistent semantics, we propose a simple but effective Hierarchical Dialogue Understanding model, HiDialog. Specifically, we first... | Fuzhao Xue, Heng Zhang, Jian Zhang, Xiao Liu, Yang You |  |
| 195 |  |  [Large Sparse Kernels for Federated Learning](https://openreview.net/forum?id=ZCv4E1unfJP) |  | 0 | Existing approaches to address non-iid data in federated learning are often tailored to specific types of heterogeneity and may lack generalizability to all scenarios. In this paper, we present empirical evidence supporting the claim that employing large sparse convolution kernels can lead to... | Feilong Zhang, Junjun Jiang, Shiyi Lin, Xianming Liu, Yinchuan Li, Yunfeng Shao |  |
| 196 |  |  [Using vision transformer-based GANs against Vision Transformers](https://openreview.net/forum?id=WFatA9XIQ0m) |  | 0 | Vision transformers have become one of the best architectures for image classification tasks. In this paper, we introduce a novel method for creating adversarial attacks in a black box environment without using surrogate models. Specifically, we introduce a single encoder and a three-encoder... | Andrei Florin Pamînt, Sergiu Adrian Darabant |  |
| 197 |  |  [Pivot Pre-finetuning for Low Resource MT: A Case Study in Kikamba](https://openreview.net/forum?id=PaHmtktx86H) |  | 0 | Current approaches to performant machine translation often require large amounts of data (Koehn et al., 2022). However for a majority of 7000+ languages in the world, these languages often have a relative lack of digitized/organized text available, and are considered low-resource. In practical... | Machel Reid, Stephen Ngumbi Kiilu |  |
| 198 |  |  [Unsupervised Learning for Anomaly Detection: A Comparison of Deep Generative Models](https://openreview.net/forum?id=WU3veNUvvU) |  | 0 | Anomaly detection is a critical task in various domains, including cybersecurity, fraud detection, and health monitoring. Traditional methods for anomaly detection rely on handcrafted features and require expert knowledge, which can be time-consuming and expensive. Recently, deep generative models... | Kitgak Simon |  |
| 199 |  |  [Bayes classifier cannot be learned from noisy responses with unknown noise rates](https://openreview.net/forum?id=U4o5iSWSaD) |  | 0 | Training a classifier with noisy labels typically requires the learner to specify the distribution of label noise, which is often unknown in practice. Although there have been some recent attempts to relax that requirement, we show that the Bayes decision rule is unidentified in most classification... | Soham Bakshi, Subha Maity |  |
| 200 |  |  [Contrastive Learning with 3D Shapes](https://openreview.net/forum?id=ChW0YYRIni) |  | 0 | In fields such as Computer Vision or NLP, there is a large amount of data available which, however, cannot be labeled, as it would be very expensive. A possible solution to this problem is Contrastive Learning, a Self-Supervised technique. This work aims to implement a contrastive learning regime... | Andrea Bernini |  |
| 201 |  |  [Adaptive-saturated RNN: Remember more with less instability](https://openreview.net/forum?id=Ihzsru2bw2) |  | 0 | Orthogonal parameterization is a compelling solution to the vanishing gradient problem (VGP) in recurrent neural networks (RNNs). With orthogonal parameters and non-saturated activation functions, gradients in such models are constrained to unit norms. On the other hand, although the traditional... | Binh T. Nguyen, Khoi Minh NguyenDuy, Quang Pham |  |
| 202 |  |  [Stratospheric Aerosols: Establishing a Novel Optical Thickness Benchmark for Effective Climate Change Mitigation](https://openreview.net/forum?id=pKd6q-FrprW) |  | 0 | Global Warming has been a problem at the heart of Earth’s environmental issues for nearly 5 decades, with the potential to affect a significant portion of the global population and cause catastrophic irreversible damage to the planet's future. Changes in Earth’s climate due to the rise in global... | Mihir Garimella |  |
| 203 |  |  [CausalStructCodec: Causally-aware observational and interventional data generator](https://openreview.net/forum?id=cKLmwCTFiI) |  | 0 | Over the last few years, causal generative models have massively gained popularity. Their main goal is to generate observational, interventional and counterfactual data. They are also interesting for causal discovery or fair Machine Learning. These generators are based on typical data generation... | Louis Hernandez, Matthieu Boussard |  |
| 204 |  |  [Semantic Similarity Based Label Augmentation for Visual Classification](https://openreview.net/forum?id=bRI_3OFg4o) |  | 0 | Real-world applications may present visual categories for which examples are many but a definition is elusive. When data augmentation helps little and hand-crafted heuristics fail to warrant weak supervision, similarity remains a simple but effective guide for augmenting training labels. This paper... | Yu Cao |  |
| 205 |  |  [Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning](https://openreview.net/forum?id=3EfxJTp_-Cj) |  | 0 | Prompt engineering and calibration make large language models excel at reasoning tasks, including multiple choice commonsense reasoning. From a practical perspective, we investigate and evaluate these strategies on smaller language models. Through experiments on five commonsense reasoning... | Chenkai Ma |  |
| 206 |  |  [Fidelity of Interpretability Methods and Perturbation Artifacts in Neural Networks](https://openreview.net/forum?id=nbqO93YTz-) |  | 0 | Despite excellent performance of deep neural networks (DNNs) in image classification, detection, and prediction, characterizing how DNNs make a given decision remains an open problem, resulting in a number of interpretability methods. Post-hoc interpretability methods primarily aim to quantify the... | Lennart Brocki, Neo Christopher Chung |  |
| 207 |  |  [EDCDE - Extended Discovery of Closed-Form Differential Equations](https://openreview.net/forum?id=EVz_vcZQvvg) |  | 0 | Understanding the mathematical connections between variables in a physical system, such as Ordinary Differential Equations (ODEs) is an essential part of the scientific method. This is where symbolic regression plays a key role in looking for closed-form functions given a dataset. We extend the... | Robert Joseph George |  |
| 208 |  |  [Synthetic Controls as Balancing Scores](https://openreview.net/forum?id=AFLNyWMg4D2) |  | 0 | We outline the factors under which conditioning on Synthetic Control (SC) weights emulates a randomized control trial where the treatment status is independent of potential outcomes. Specifically, we demonstrate that if there exist SC weights such that the treatment effects are exactly identified,... | Harsh Parikh |  |
| 209 |  |  [Clustered Federated Learning with Slightly Skewed Labels](https://openreview.net/forum?id=qPwZouq5sY_) |  | 0 | Clustered federated learning methods are proposed to realize the personalization of federated learning. The core of these methods is KMeans while it cannot identify sample from which cluster under slight non-IID data distribution. This paper proposed Gaussian mixture cluster (GMCFL) to measure the... | Jiaming Pei, Wei Li |  |
| 210 |  |  [Fusing 3D-CNN and lightweight Swin Transformer networks for HSI](https://openreview.net/forum?id=Jx44OPxLZ2-) |  | 0 | Recently deep learning has occupied an important position in hyperspectral image (HSI) classification. In this study, we explore the advantages of using convolutional neural networks (CNN) for feature extraction and fusing an advanced shift-window (swin) transformer network based on the transformer... | Baisen Liu, Wulin Zhang, Yiran Tian, Yuanjia Liu |  |
| 211 |  |  [Compound Tokens: Channel Fusion for Vision-Language Representation Learning](https://openreview.net/forum?id=_3_VZtMkvMB) |  | 0 | We present an effective method for fusing visual-and-language representations for several question answering tasks including visual question answering and visual entailment. In contrast to prior works that concatenate unimodal representations or use only cross-attention, we compose multimodal... | A. J. Piergiovanni, Maxwell Mbabilla Aladago |  |
| 212 |  |  [Message-passing Selection: Towards Interpretable GNNs for Graph Classification](https://openreview.net/forum?id=99Go96dla5y) |  | 0 | In this paper, we strive to develop an interpretable GNNs' inference paradigm, termed MSInterpreter, which can serve as a plug-and-play scheme readily applicable to various GNNs' baselines. Unlike the most existing explanation methods, MSInterpreter provides a Message-passing Selection... | Haofei Zhang, Kaixuan Chen, Mingli Song, Shunyu Liu, Wenda Li, Wenjie Huang, Yingjie Tian, Yun Su |  |
| 213 |  |  [Multi-Agent Reinforcement Learning for Coalitional Bargaining Games](https://openreview.net/forum?id=OaZktJBVpUy) |  | 0 | In recent years, there has been growing attention to the application of MARL to coalition formation problems, in particular, on coalitional bargaining games as a means of negotiation. However, the lack of theoretical principles for using MARL in coalitional bargaining games remain less explored.... | Enrico H. Gerding, Ignacio Carlucho, Kalesha Bullard, Lucia CipolinaKun, Sebastian Stein, Stephen Mak, Vahid Yazdanpanah |  |
| 214 |  |  [Astroformer: More Data might not be all you need for Classification](https://openreview.net/forum?id=ChqP6ORFYK6) |  | 0 | Recent advancements in areas such as natural language processing and computer vision rely on intricate and massive models that have been trained using vast amounts of unlabelled or partly labeled data and training or deploying these state-of-the-art methods to resource constraint environments has... | Rishit Dagli |  |
| 215 |  |  [Error Analysis of Fitted Q-iteration with ReLU-activated Deep Neural Networks](https://openreview.net/forum?id=EVwbNcRa6Yf) |  | 0 | Deep reinforcement learning (RL) has grown rapidly with the development of backbone feedforward neural networks (FNNs). However, there remains a theoretical gap when researchers conduct error analysis of the FNNs-based RL process. In this work, we provide an error analysis for deep-fitted... | Chang Zhu, Han Yuan, Lican Kang |  |
| 216 |  |  [General Purpose Artificial Intelligence Systems as Group Agents](https://openreview.net/forum?id=ddFJsnpZtTX) |  | 0 | This paper advocates for General Purpose Artificial Intelligence Systems to be viewed as group agents. This view emphasizes their shared agency characteristics and allows for the assignment of collective responsibility, while still recognizing individual accountability when necessary. This... | Matija Franklin |  |
| 217 |  |  [An Empirical Study of the Effect of Background Data Size on the Stability of SHapley Additive exPlanations (SHAP) for Deep Learning Models](https://openreview.net/forum?id=L38bbHmRKx) |  | 0 | SHapley Additive exPlanations (SHAP) is a popular method that requires a background dataset in uncovering the deduction mechanism of artificial neural networks (ANNs). Generally, a background dataset consists of instances randomly sampled from the training dataset. However, the sampling size and... | Chenkui Miao, Han Yuan, Lican Kang, Mingxuan Liu, Ying Wu |  |
| 218 |  |  [Interpretable Machine Learning-Based Risk Scoring with Individual and Ensemble Model Selection for Clinical Decision Making](https://openreview.net/forum?id=RNlfw6KXJey) |  | 0 | Clinical scores are highly interpretable and widely used in clinical risk stratification. AutoScore was previously developed as a clinical score generator, integrating the interpretability of clinical scores and the discriminability of machine learning. Although a basic framework has been... | Chenglin Niu, Feng Xie, Han Yuan, Jin Wee Lee, Jun Wen, Mingxuan Liu, Siqi Li |  |
| 219 |  |  [Analytical solutions for a family of single layer neural network regression problems](https://openreview.net/forum?id=g6ZFp73_T7) |  | 0 | In this paper, we analyze a family of penalized single layer neural network regression problems wherein the response variable has all non-negative entries. We show analytically that the optimal weights of the problem lie at the vector of zeros, which is a point of non-differentiability. | Siddharth Krishna Kumar |  |
| 220 |  |  [Pretrained Vision Models for Predicting High-Risk Breast Cancer Stage](https://openreview.net/forum?id=Idalad_7wG) |  | 0 | Cancer is increasingly a global health issue. Seconding cardiovascular diseases, cancers are the second biggest cause of death in the world with millions of people succumbing to the disease every year. According to the World Health Organization (WHO) report, by the end of 2020, more than 7.8... | Bonaventure F. P. Dossou, Miglanche Ghomsi Nono, Yenoukoume S. K. Gbenou |  |
| 221 |  |  [The First Tiny Papers Track at ICLR 2023, Tiny Papers @ ICLR 2023, Kigali, Rwanda, May 5, 2023](https://openreview.net/group?id=ICLR.cc/2023/TinyPapers) |  | 0 |  | Krystal Maughan, Rosanne Liu, Thomas F. Burns |  |
| 222 |  |  [Statistical Property Testing for Generative Models](https://openreview.net/forum?id=xmY_plRB15j) |  | 0 | Generative models that produce images, text, or other types of data are recently be equipped with more powerful capabilities. Nevertheless, in some use cases of the generated data (e.g., using it for model training), one must ensure that the synthetic data points satisfy some properties that make... | ChihHong Cheng, Emmanouil Seferis, Simon Burton |  |
| 223 |  |  [Can Conformal Prediction Obtain Meaningful Safety Guarantees for ML Models?](https://openreview.net/forum?id=5aO1lsEJGu) |  | 0 | Conformal Prediction (CP) has been recently proposed as a methodology to calibrate the predictions of Machine Learning (ML) models so that they can output rigorous quantification of their uncertainties. For example, one can calibrate the predictions of an ML model into prediction sets, that... | ChihHong Cheng, Emmanouil Seferis, Simon Burton |  |
| 224 |  |  [A two-parameter learnable Logmoid Activation Unit](https://openreview.net/forum?id=LcXWYmA8Ek) |  | 0 | A novel learnable Logmoid Activation Unit (LAU) is proposed as, $f(x)=x\ln(1+\alpha\textrm{sigmoid}(\beta x))$, by parameterizing Sigmoid with two hyper-parameters $\alpha$ and $\beta$ that are optimized by the back-propagation algorithm. The end-to-end deep neural networks with learnable LAUs can... | Lingfang Li, Mingxing Luo, Xingzhou Zheng, Xuemei Zhou |  |
| 225 |  |  [Cross Domain Vulnerability Detection using Graph Contrastive Learning](https://openreview.net/forum?id=rrZtzI7xj2b) |  | 0 | To overcome the difficulty of finding good-quality labeled data in domains such as vulnerability detection, Self--Supervised Learning (SSL) methods such as Contrastive Learning (CL) algorithms were developed. We evaluate the performance of one such state-of-the-art CL method, GraphCL, that trains... | Kevin W. Hamlen, Latifur Khan, Mahmoud Zamani, Saquib Irtiza, Shamila Wickramasuriya |  |
| 226 |  |  [Tiny Attention: A Simple yet Effective Method for Learning Contextual Word Embeddings](https://openreview.net/forum?id=BWWrDHaP29) |  | 0 | Contextual Word Embedding (CWE) obtained via the Attention Mechanism in Transformer (AMT) models is one of the key drivers of the current revolution in Natural Language Processing. Previous techniques for learning CWEs are not only inferior to AMT but also are largely subpar to the simple... | Narayana Murthy Kavi, Renjith P. Ravindran |  |
| 227 |  |  [Training Data Eigenvector Dynamics in the EigenPro Implementation of the Neural Tangent Kernel and Recursive Feature Machines](https://openreview.net/forum?id=8WiNDyXgj6) |  | 0 | There has been much recent work on kernel methods as a viable alternative to deep neural networks (DNNs). The advent of the $\textit{Neural Tangent Kernel}$ (NTK) has brought on renewed interest in these methods and their application to typical deep learning tasks. Recently, kernels have been shown... | Cyril Gorlla |  |
| 228 |  |  [Metric Transform: Exploring beyond Affine Transform for Neural Networks](https://openreview.net/forum?id=fVuTIiTBky) |  | 0 | Artificial Neural Networks(ANN) of varying architectures are generally paired with linear transformation at the core. However, we find dot product neurons with global influence less interpretable as compared to a more local influence of euclidean distance (as used in RBF). In this work, we explore... | Binod Bhattarai, Suman Sapkota |  |
| 229 |  |  [MaskedFusion360: Reconstruct LiDAR Data by Querying Camera Features](https://openreview.net/forum?id=mIEMVZ47aNA) |  | 0 | In self-driving applications, LiDAR data provides accurate information about distances in 3D but lacks the semantic richness of camera data. Therefore, state-of-the-art methods for perception in urban scenes fuse data from both sensor types. In this work, we introduce a novel self-supervised method... | Carlos Fernández Lopez, Marvin Klemp, Royden Wagner |  |
| 230 |  |  [Meta-Learning for Subject Adaptation in Low-Data Environments for EEG-Based Motor Imagery Brain-Computer Interfaces](https://openreview.net/forum?id=7QqlQW9hJ8J) |  | 0 | Motor imagery classification from Electroencephalogram (EEG) signals involves decoding information during the imagination of specific movements. However, learning representations for EEG-based motor imagery classification is challenging due to inter-subject variability and differences in mental... | Arnav Pati, Debasis Samanta, Deepak Mewada |  |
| 231 |  |  [Fostering Effective Communication Between Humans and Machines](https://openreview.net/forum?id=AHnLJBD7xKx) |  | 0 | With the growing usage of smartphones, digital communication has become significant. This paper describes the primary research conducted to study user interaction patterns on smartphones. Results show that the time between two touches, or the editorial context duration, is just 5 to 10 seconds for... | Biju Dominic, Jieya Rawal, Karthika Kamath, Kirtana Sunil Phatnani, Tanya Upadhyay |  |
| 232 |  |  [Transfer Learning on Kinyarwanda Tweets Sentiment Analysis](https://openreview.net/forum?id=7lyEQXHkGpl) |  | 0 | Pretrained models available on platform such as Hugging Face have become a valuable resource for machine learning community, particularly for natural language processing task. In this study, we evaluated the performance of Kinyarwanda and English pretrained models for sentiment analysis of... | Roger Byakunda |  |
| 233 |  |  [Symbolic Regression in Financial Economics](https://openreview.net/forum?id=RuCQRXk7a7G) |  | 0 | We apply symbolic regression, the machine learning approach of recovering models from data, in financial economics. Specifically, we present a data set consisting of equations that cover a broad range of topics in financial economics. These equations are built off a common set of mathematical... | Jiacheng Liu, Siqi Guo |  |
| 234 |  |  [FRESCO: Federated Reinforcement Energy System for Cooperative Optimization](https://openreview.net/forum?id=75mWq5j4iso) |  | 0 | The rise in renewable energy is creating new dynamics in the energy grid that promise to create a cleaner and more participative energy grid, where technology plays a crucial part in creating the required flexibility to achieve the vision of the next-generation grid. This work presents FRESCO, a... | Martin Takác, Nicolas M. Cuadrado, Roberto Alejandro Gutiérrez Guillén |  |
| 235 |  |  [Learning Rotation-Agnostic Representations via Group Equivariant VAEs](https://openreview.net/forum?id=jbNqgEJf0EI) |  | 0 | An emerging field in representation learning involves the study of group-equivariant neural networks, that leverage concepts from group representation theory to design neural architectures that can exploit discrete and continuous symmetries to produce more general representations. Following this... | Ahmedeo Shokry, Antonio Norelli |  |
| 236 |  |  [Can Text Encoders be Deceived by Length Attack?](https://openreview.net/forum?id=KPHbtTtCDw) |  | 0 | Albeit \textit{de facto} to use in training dense retrieval models, we observe that contrastive learning is prone to length overfitting, making it vulnerable to adversarial length attacks. We examine the behaviour of this phenomenon and propose an editing method to mitigate this problem. We find... | Chenghao Xiao, G. Thomas Hudson, Noura Al Moubayed, Phil Blunsom, Zhongtian Sun, Zihuiwen Ye |  |
| 237 |  |  [Whispering Across the Continent: Collecting and Analyzing African Culture Using Community Radios](https://openreview.net/forum?id=kidk_E11QQ) |  | 0 | African culture is rich and diverse, but much of its knowledge is held by the elders of the community and passed down through oral traditions. With globalization, young Africans are becoming increasingly disconnected from their roots, making it essential to collect and preserve this knowledge.... | Guy Adingono Nkama, Joseph Domguia |  |
| 238 |  |  [Handling unstructured data for operator learning using implicit neural representations](https://openreview.net/forum?id=e2gSQqH3V10) |  | 0 | Operator learning methods are too often constrained by a fixed sampling of both the input and output functions. We propose a novel method to allow current operator learning methods to learn on any sampling. We show that our method can perform inference on unseen samplings, and that it allows... | Patrick Gallinari, Thomas X. Wang |  |
| 239 |  |  [Model Extraction Attacks on DistilBERT](https://openreview.net/forum?id=njpSzZ6mCU) |  | 0 | This paper investigates model extraction attacks, where an adversary can train a substitute model by collecting data through query access to a victim model and stealing its functionality. We use DistilBERT as the victim model due to its smaller size and faster processing speed. The results... | Amro Salman, Ayman Saeed, Khalid N. Elmadani, Sharief Babiker |  |
| 240 |  |  [One Important Thing To Do Before Federated Training](https://openreview.net/forum?id=qq-bA-VLUN) |  | 0 | Previous research in Federated learning (FL) have emphasized privacy protection, model optimization, and so on, meanwhile, they overlooked how to choose the appropriate FL algorithm for a new federation with preserving data privacy. In our study, we provide a formal problem formulation for... | DeChuan Zhan, Wenqian Li, Yan Pang, Yichu Xu, Yinchuan Li, Yunfeng Shao |  |
| 241 |  |  [Insights into the mechanism behind reusing Teacher's classifier in Knowledge Distillation](https://openreview.net/forum?id=_cL7Uj4LXAJ) |  | 0 | Knowledge distillation (KD) has emerged as an effective approach to compress deep neural networks by transferring knowledge from a powerful yet cumbersome teacher model to a lightweight student model. Recent research has suggested that re-using the teacher's final layer (i.e., the classifier) can... | Kinshuk Dua |  |
| 242 |  |  [When will federated learning transfer from generalization to personalization?](https://openreview.net/forum?id=iCqvQSvar5V) |  | 0 | The timing of personalization refers to determining when to train and update personalized models for the participants in Personalized federated learning. Determining the timing for personalization contributes to improving the overall efficiency of federated learning. We propose that training... | Jiaming Pei, Lukun Wang, Wenxuan Liu |  |
| 243 |  |  [A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion](https://openreview.net/forum?id=S9NTReFikL2) |  | 0 | Speech Emotion Recognition (SER) is a challenging task. In this paper, we introduce a modality conversion concept aimed at enhancing emotion recognition performance on the MELD dataset. We assess our approach through two experiments: first, a method named Modality-Conversion that employs automatic... | Ali Satvaty, Hossein Sameti, Zeinab Sadat Taghavi |  |
| 244 |  |  [Fairness Under Partial Observability](https://openreview.net/forum?id=if1Mmrxf-pq) |  | 0 | The purpose of this article is to discuss an important challenge faced in \`\`real life'' when trying to implement \emph{group} fairness-aware models and algorithms. Here, we focus specifically on the role that uncertainty and ambiguity play and revisit the case where protected attributes are only... | Francois BuetGolfouse, Islam Utyagulov, Peter Hill |  |
| 245 |  |  [Geodesic Mode Connectivity](https://openreview.net/forum?id=cFtt9fU7YB6) |  | 0 | Mode connectivity is a phenomenon where trained models are connected by a path of low loss. We reframe this in the context of Information Geometry, where neural networks are studied as spaces of parameterized distributions with curved geometry. We hypothesize that shortest paths in these spaces,... | Charlie Tan, Rudolf Laine, Sarah Zhao, Theodore Long |  |
| 246 |  |  [Pursuit Policies in Dynamic Environments](https://openreview.net/forum?id=_cZLvP7LAt7) |  | 0 | Cooperative pursuit is a popular multi-agent reinforcement learning (MARL) game where a team of predators target prey while avoiding obstacles. Previous literature has largely considered the impact of different predator, prey abilities on learning. Here, we investigate the impact of dynamic... | Andréa W. Richa, Joseph L. Briones |  |
| 247 |  |  [Resource-efficient image inpainting](https://openreview.net/forum?id=OJILbuOodvm) |  | 0 | Image inpainting refers to the synthesis of missing regions in an image, which can help restore occluded or degraded areas and also serve as a precursor task for self-supervision. The current state-of-the-art models for image inpainting are computationally heavy as they are based on vision... | Amit Sethi, Dharshan Sampath Kumar, Pranav Jeevan |  |
| 248 |  |  [Recursive Reasoning with Neural Networks](https://openreview.net/forum?id=TS8l4VS7_BK) |  | 0 | Many problems can naturally be thought about recursively. However, neural networks fundamentally cannot reason this way on arbitrarily large problems. This is because they do not have the memory to maintain state for the maximum recursion depth required. Solving this issue would enable neural... | Dulhan Hansaja Jayalath, Jonas Jürß |  |
| 249 |  |  [SUDANESE ARABIC DIALECT ENCODING USING XLM-RoBERTa LANGUAGE MODEL: Zol-ROBERTA](https://openreview.net/forum?id=wUEY2CdQGi1) |  | 0 | XLM-RoBERTa has proven to be very efficient at Natural Language Understanding (NLU), as it allows to achieve state-of-the-art results in most NLU tasks. In this work we aim to utilize the power of XLM-RoBERTa in Sudanese Arabic dialect. We collected over 6 million sentences in Sudanese dialect and... | Duaa Badradein Alshareif, Hiba Hassan S. M. Ali, Muhammed Yahya Saeed, Taiseer Abdulateef Fadlalla |  |
| 250 |  |  [Reducing the Effect of Incomplete Annotations in Object Detection for Histopathology](https://openreview.net/forum?id=PIfJnq9kpdw) |  | 0 | Training neural networks for object detection usually requires decent amounts of data to produce great results. Apart from the image variety, the number of annotated objects is a crucial factor for success. In histopathology, the average annotation density is very high, resulting in... | Denys Kaliuzhnyi, Dmytro Fishman, Mikhail Papkov |  |
| 251 |  |  [Experimenting with Multimodal AutoML: Detection and Evaluation of Alzheimer's Disease](https://openreview.net/forum?id=nSqrgBKBGkv) |  | 0 | This paper describes an experiment using AutoML, AutoGluon Tabular, to discover multimodal models for MMSE regression and AD detection. Using the ADReSSo dataset, this paper reports enhanced performance in classification models and comparable performance in regression models to the baseline,... | Saurav Keshari Aryal, Ujjawal Shah |  |
| 252 |  |  [GFlowNets with Human Feedback](https://openreview.net/forum?id=2KxH_4US0ZH) |  | 0 | We propose the GFlowNets with Human Feedback (GFlowHF) framework to improve the exploration of training language models. For tasks where the reward is unknown, we fit the reward function through human evaluations on different trajectories. The goal of GFlowHF is to learn a policy that is strictly... | Jianye Hao, Shuang Luo, Yinchuan Li, Yunfeng Shao |  |
| 253 |  |  [Attention-likelihood relationship in Transformers](https://openreview.net/forum?id=R82eeIF4rP_) |  | 0 | We analyze how large language models (LLMs) represent out-of-context words, investigating their reliance on the given context to capture their semantics. Our likelihood-guided text perturbations reveal a correlation between token likelihood and attention values in transformer-based language models.... | Fabrizio Silvestri, Valentino Maiorca, Valeria Ruscio |  |
| 254 |  |  [Truly Generative Data Augmentation for Image Segmentation - Case of Cloud Images](https://openreview.net/forum?id=cQ_eEMsc6p) |  | 0 | Supervised learning frameworks frequently rely on semantic image segmentation, which necessitates a substantial amount of annotated data. Existing methodologies for data augmentation either employ image transformations that are limited by the cardinality of the original dataset or employ generative... | Mayank Jain, Soumyabrata Dev |  |
| 255 |  |  [Fast Fourier Convolutions in Self-Supervised Neural Networks for Image Denoising](https://openreview.net/forum?id=ghfL1e2rOd) |  | 0 | Recently, denoising convolutional neural networks (CNN) have started to outperform classical denoising algorithms. However, CNNs performance could be constrained by the limited receptive field of regular convolution. To mitigate this problem, a new modification for CNNs was proposed: Fast Fourier... | Joonas Ariva, Mikhail Papkov |  |
| 256 |  |  [Personalized Federated Learning for Medical Segmentation using Hypernetworks](https://openreview.net/forum?id=lpcO1957Tv) |  | 0 | In federated learning (FL), several clients jointly train a shared model without sharing their data, maintaining data privacy and reducing communication costs. In personalized federated learning (PFL), each client has their own model, and models are trained jointly. Hypernetworks have been shown to... | Gal Chechik, Hilit Segev |  |
| 257 |  |  [Career Path Modeling and Recommendations with Linkedin Career Data and Predicted Salary Estimations](https://openreview.net/forum?id=R5NNAThG0i) |  | 0 | Career planning involves devising a sequence of steps that build up an ideal career path for a person. However, career planning has become more complex in recent years, demanding the need for better models and systems for recommending Career Paths. With that in mind, we explored new variables and... | Aaron Santillan, Carl John Vinas, Micaela Tayoto Cerilla, Michael B. Dela Fuente |  |
| 258 |  |  [Sleep Deprivation in the Forward-Forward Algorithm](https://openreview.net/forum?id=q_lJooPbX_) |  | 0 | This paper aims to explore the separation of the two forward passes in the Forward-Forward algorithm from a biological perspective in the context of sleep. We show the size of the gap between the sleep and awake phase influences the learning capabilities of the algorithm and highlight the... | David DinucuJianu, Mircea Tudor Lica |  |
| 259 |  |  [MetaXLR - Mixed Language Meta Representation Transformation for Low-resource Cross-lingual Learning based on Multi-Armed Bandit](https://openreview.net/forum?id=nF70Sl-HUZ) |  | 0 | Transfer learning for extremely low-resource languages is a challenging task as there is no large-scale monolingual corpora for pre-training or sufficient annotated data for fine-tuning. We follow the work of (Xia et al., 2021) which suggests using meta learning for transfer learning from a single... | Eyal Orgad, Liat Bezalel |  |
| 260 |  |  [Prune and Tune: Improving Efficient Pruning Techniques for Massive Language Models](https://openreview.net/forum?id=cKlgcx7nSZ) |  | 0 | Massive language models with billions of parameters have significant compute expenses and thus can benefit from pruning. Pruning techniques for massive models are typically iterative and require extensive weight retraining after pruning. SparseGPT, a recently introduced one-shot technique for... | Aaquib Syed, Phillip Guo, Vijaykaarti Sundarapandiyan |  |
| 261 |  |  [Model Extraction Attacks on Arabic BERT-Based APIs](https://openreview.net/forum?id=XptW6NuULJ) |  | 0 | In this paper, we study the feasibility of performing Model Extraction attacks on Arabic BERT-based APIs. In our experiments, we try to perform these attacks under different scenarios and observe the accuracy of the extracted model against the victim model. We then propose a method for protecting... | Anas Showk, Hassan Abbelkarim, Khalid N. Elmadani, Mohammed Eltahir |  |
| 262 |  |  [IMITATION LEARNING USING THE FORWARD-FORWARD ALGORITHM](https://openreview.net/forum?id=baF9FqIdTY) |  | 0 | The forward-forward (FF) algorithm has been recently introduced as a novel approach to training neural networks in a way that approximates the behavior of real neurons. Nevertheless, its application has been limited to visual domains and has not been investigated in the context of imitation... | Insik Chung, Isaac Han, KyungJoong Kim |  |
| 263 |  |  [The Geometry of Multilingual Language Models: An Equality Lens](https://openreview.net/forum?id=dGuMR8tLDs) |  | 0 | Understanding the representations of different languages in multilingual language models is essential for comprehending their cross-lingual properties, predicting their performance on downstream tasks, and identifying any biases across languages. In our study, we analyze the geometry of three... | Cheril Shah, Manan Suri, Yashashree Chandak |  |
| 264 |  |  [Dynamic Human AI Collaboration](https://openreview.net/forum?id=Muwb2KohnX) |  | 0 | Domain experts possess valuable knowledge and insights that can help improve the accuracy and relevance of the machine learning (ML) models. By incorporating expert opinions, the models can capture important nuances and factors that may not be captured by data-driven methods alone. The integration... | Francois BuetGolfouse, Kabir Thakur, Parth Pahwa |  |
| 265 |  |  [The Responsibility Problem in Neural Networks with Unordered Targets](https://openreview.net/forum?id=jd7Hy1jRiv4) |  | 0 | We discuss the discontinuities that arise when mapping unordered objects to neural network outputs of fixed permutation, referred to as the responsibility problem. Prior work has proved the existence of the issue by identifying a single discontinuity. Here, we show that discontinuities under such... | Ben Hayes, Charalampos Saitis, György Fazekas |  |
| 266 |  |  [Concept Understanding in Large Language Models: An Empirical Study](https://openreview.net/forum?id=losgEaOWIL7) |  | 0 | Large Language Models (LLMs) have demonstrated their superior comprehension and expressiveness across a wide range of tasks, and exhibited remarkable capabilities in real-world applications. Hence, it is crucial to investigate their potential and limitations for trustworthy performance in both... | Jiayi Liao, Lun Du, Xu Chen |  |
| 267 |  |  [Adaptive Distance Message Passing From the Multi-Relational Edge View](https://openreview.net/forum?id=rAT51tL04I2) |  | 0 | Message-passing graph neural networks (MP-GNNs) excel in deep learning on graphs. Despite their success in various studies, they are limited by passing information to the fixed length $k$ distance neighbouring nodes, where $k$ is the number of layers. In reality, different types of edges... | Alexandra I. Cristea, Jialin Yu, Pietro Lio, Zhongtian Sun |  |
| 268 |  |  [Sustainable Resource Management](https://openreview.net/forum?id=DLwlmWwmJBi) |  | 0 | Given finite resources and growing demand, a supply-side balance must be struck between maximising profit and sustainable resource management. This paper combines the two techniques in a stochastic setting to create a sustainable profit model and uses Gaussian processes to estimate and bound... | Francois BuetGolfouse, Nicholas William David Martin, Peter Hill, Tingsheng Tan |  |
| 269 |  |  [Chain Of Thought Prompting Under Streaming Batch: A Case Study](https://openreview.net/forum?id=n5aZMLXVndP) |  | 0 | Recently, Large Language Models (LLMs) have demonstrated remarkable capa- bilities. Chain-of-Thought (CoT) has been proposed as a way of assisting LLMs in performing complex reasoning. However, developing effective prompts can be a challenging and labor-intensive task. Many studies come out of some... | Yuxin Tang |  |
| 270 |  |  [Language Models can do Zero-Shot Visual Referring Expression Comprehension](https://openreview.net/forum?id=F7mdgA7c2zD) |  | 0 | The use of visual referring expressions is an important aspect of human-robot in- teractions. Comprehending referring expressions (ReC) like “the brown cookie near the cup” requires to understand both self-referential expressions, “brown cookie”, and relational referential expressions, “near the... | Hong Yang, Hongyuan Zhu, Shaohua Li, Xiuchao Sui, Yan Wu |  |
| 271 |  |  [Simple Parameter-free Self-attention Approximation](https://openreview.net/forum?id=isodM5jTA7h) |  | 0 | The hybrid model of self-attention and convolution is one of the methods to lighten ViT. The quadratic computational complexity of self-attention with respect to token length limits the efficiency of ViT on edge devices. We propose a self-attention approximation without training parameters, called... | Jing Hao, Liang Gao, Shumin Han, Xinyu Li, Yiping Gao, Yuwen Zhai |  |
| 272 |  |  [Neuromodulation Gated Transformer](https://openreview.net/forum?id=cYKtDg5JnxV) |  | 0 | We introduce a novel architecture, the Neuromodulation Gated Transformer (NGT), which is a simple implementation of neuromodulation in transformers via a multiplicative effect. We compare it to baselines and show that it results in the best average performance on the SuperGLUE benchmark validation... | Diana Benavides Prado, Gillian Dobbie, Joshua Bensemann, Kobe Knowles, Michael Witbrock, Vithya Yogarajan, Yang Chen |  |
| 273 |  |  [Decomposing Causality and Fairness](https://openreview.net/forum?id=Lm7z2vYergk) |  | 0 | It is often informative to decompose key quantities of interest into smaller components, in order to develop a better understanding of the key quantity. In this paper, we focus causality and fairness, where bias attribution can be particularly useful. We show how quantities can be broken down based... | Francois BuetGolfouse, Peter Hill |  |
| 274 |  |  [Self-Supervised Image Denoising with Swin Transformer](https://openreview.net/forum?id=EARgl3EH-nq) |  | 0 | Self-supervised image denoising aims to reconstruct signal from a noisy image with no additional information. Typically, this is accomplished by means of specific frameworks built upon fully-convolutional neural networks. In two such frameworks, Noise2Self and Noise2Same, we replaced conventional... | Mikhail Papkov, Pavel Chizhov |  |
| 275 |  |  [SimbaML: Connecting Mechanistic Models and Machine Learning with Augmented Data](https://openreview.net/forum?id=1wtUadpmVzu) |  | 0 | Training sophisticated machine learning (ML) models requires large datasets that are difficult or expensive to collect for many applications. If prior knowledge about system dynamics is available, mechanistic representations can be used to supplement real-world data. We present SimbaML... | Benedict B. Heyder, Bernhard Y. Renard, Julian Zabbarov, Katharina Baum, Lukas Drews, Maximilian Kleissl, Pascal Iversen, Simon Witzke |  |
| 276 |  |  [GeValDi: Generative Validation of Discriminative Models](https://openreview.net/forum?id=zwywBS3GyFs) |  | 0 | Evaluation of machine learning (ML) models is critically important for reliable use. Though typically done via unseen data, such validation datasets often need to be large and hard to procure; additionally, mutliple models may perform equally well on such datasets. To address these challenges, we... | Adrian Weller, Juyeon Heo, Katherine M. Collins, Matthew Ashman, Umang Bhatt, Vivek Palaniappan |  |
| 277 |  |  [Regularized Offline GFlowNets](https://openreview.net/forum?id=kbhUUAMZmQT) |  | 0 | We propose the regularized offline generative flow networks (RO-GFlowNets) that does not rely on online sampling. Since offline datasets usually cannot cover the entire state space, traditional GFlowNets cannot accurately predict the action sampling probability for each state. To address this... | Haozhi Wang, Jianye Hao, Yinchuan Li, Yunfeng Shao |  |
| 278 |  |  [Secure Communication Model for Quantum Federated Learning: A Proof of Concept](https://openreview.net/forum?id=xZGPLvRpf4N) |  | 0 | We design a model of Post Quantum Cryptography (PQC) Quantum Federated Learning (QFL). We develop a proof of concept with a dynamic server selection and study convergence and security conditions. We develop a preliminary study with a proof of concept model of post-quantum secure QFL. | Dev Gurung, Gang Li, Shiva Raj Pokhrel |  |
| 279 |  |  [Learn to Select: Efficient Cross-device Federated Learning via Reinforcement Learning](https://openreview.net/forum?id=wecTsVkrjit) |  | 0 | Federated Learning (FL) is a collaborative training method that provides data privacy in the age of big data. However, it is often ineffective on edge devices due to their heterogeneous and constrained resources. The primary challenge is to identify devices with useful training data and available... | Chunlin Tian, Li Li, Zhan Shi |  |
| 280 |  |  [A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge](https://openreview.net/forum?id=hli7A0ioiS_) |  | 0 | Transformer-based pretrained language models (PLMs) have shown to pre-learn rich prior knowledge. To assist data-to-text task, we propose a new dynamic prompt tuning method, DPTAK, to retrieve knowledge from a PLM that is associated with individual data-text pairs. Our method increases the... | Alex Yuxuan Peng, Jiamou Liu, Michael Witbrock, Qianqian Qi, Qiming Bao |  |
| 281 |  |  [MARKOVIAN EMBEDDINGS FOR COALITIONAL BARGAINING GAMES](https://openreview.net/forum?id=1LeLyB6T0JM) |  | 0 | We examine the Markovian properties of coalition bargaining games, in particular, the case where past rejected proposals cannot be repeated. We propose a Markovian embedding with filtrations to render the sates Markovian and thus, fit into the framework of stochastic games. | Lucia CipolinaKun |  |
| 282 |  |  [The Point to Which Soft Actor-Critic Converges](https://openreview.net/forum?id=1_PEwKmTepo) |  | 0 | Soft actor-critic is a successful successor over soft Q-learning. While lived under maximum entropy framework, their relationship is still unclear. In this paper, we prove that in the limit they converge to the same solution. This is appealing since it translates the optimization from an arduous to... | Jianfei Ma |  |
| 283 |  |  [No Double Descent in Self-Supervised Learning](https://openreview.net/forum?id=qNJRvdKDGYg) |  | 0 | Most investigations into double descent have focused on supervised models while the few works studying self-supervised settings find a surprising lack of the phenomenon. These results imply that double descent may not exist in self-supervised models. We show this empirically in two additional... | Alisia Maria Lupidi, Dulhan Hansaja Jayalath, Yonatan Gideoni |  |
| 284 |  |  [Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers](https://openreview.net/forum?id=kBkou5ucR_d) |  | 0 | Annealed Importance Sampling (AIS) moves particles along a Markov chain from a tractable initial distribution to an intractable target distribution. The recently proposed Differentiable AIS (DAIS) (Geffner & Domke, 2021; Zhang et al., 2021) enables efficient optimization of the transition kernels... | Johannes Zenn, Robert Bamler |  |
| 285 |  |  [Generalised Lookahead Optimiser](https://openreview.net/forum?id=uNrSvEr9Lqc) |  | 0 | The vast majority of deep learning models are trained using SGD or one of its variants. Zhang et al. (2019) suggested the Lookahead optimiser as an alternative which enjoys remarkable test performance on many established datasets and mod- els. In this work we investigate a generalisation of this... | CostinAndrei Oncescu, Jack Valmadre, João F. Henriques |  |
| 286 |  |  [Revisiting CounteRGAN for Counterfactual Explainability of Graphs](https://openreview.net/forum?id=d0m0Rl15q3g) |  | 0 | Counterfactual explainability (CE) has been widely explored in various domains ranging from medical image diagnosis to self-driving cars. Graph CE (GCE), on the other hand, and especially, generative-based GCE has yet to be explored. Here, we adapt CounteRGAN, an image-based generative approach, to... | Bardh Prenkaj, Giovanni Stilo, Mario Alfonso PradoRomero |  |
| 287 |  |  [Language Models Inversely Scale on Piecewise Function Evaluation with Biased Examples](https://openreview.net/forum?id=GJhsHNKm7kj) |  | 0 | We investigate whether pretrained language models (LMs) can be misled by providing them with factually correct, but unrepresentative/biased examples, in the context of integer-to-integer piecewise functions. Given the definition of a piecewise function and several examples of the function’s... | Atif Mahmud, Bradley C. A. Brown, Jordan Juravsky, Ryan Ehrlich, Wais Shahbaz |  |
| 288 |  |  [RETHINKING POSITIONAL EMBEDDING: A CASE STUDY IN TEMPORAL EVENT SEQUENCE MODELLING](https://openreview.net/forum?id=iF2w_kqmYmw) |  | 0 | In this paper, we present a time-decaying encoding as an alternative to sinusoidal positional encoding in the transformer architecture. We evaluate our approach in the context of an educational domain involving 14,043 question-solving interactions from 1,260 students. We argue that including... | Effat Farhana |  |
| 289 |  |  [Exploring Efficient and Simple Initialization Strategies for Bayesian Optimization with SETUP-BO](https://openreview.net/forum?id=TFrzVBZk05g) |  | 0 | This paper studies the effectiveness of random and grid initialization strategies in SETUP-BO, a self-tuning Bayesian optimization algorithm. Our experiments on benchmark functions compare the performance of these initialization strategies to deterministic initialization. The results show that... | Mohammad Taghi Manzuri, Seyed Ali YaghoubNejad |  |
| 290 |  |  [Quota Constraints for Diversity Interventions in Subset Selection](https://openreview.net/forum?id=x4MuUFPKEIj) |  | 0 | The combinatorial optimization problem of subset selection is often modeled as maximizing a set function that captures inter-element dependencies under some capacity/matroid constraints. In this paper, we examine this problem under “quota constraints” where the selected subset must meet some... | Neeraja Abhyankar |  |
| 291 |  |  [Mitigating Metastable Failures in Distributed Systems with Offline Reinforcement Learning](https://openreview.net/forum?id=zYF6NLJl6LM) |  | 0 | This paper introduces a load-shedding mechanism that mitigates metastable failures through offline reinforcement learning (RL). Previous studies have heavily focused on heuristics that are reactive and limited in generalization, while online RL algorithms face challenges in accurately simulating... | Christina Delimitrou, Daochen Zha, Francis Y. Yan, G. Edward Suh, Tianjun Zhang, Yueying Li |  |
| 292 |  |  [Knowledge Distillation of BERT Language Model on the Arabic Language](https://openreview.net/forum?id=-bMH1Sk8SSF) |  | 0 | The absence of good Arabic language models led to significant setbacks in the Arabic language related tasks and lag with respect to robustness and accuracy. While a pre-trained version of BERT on Arabic language is available, a smaller distilled version could be proven to be highly scalable. In... | Abrar Elidrisi, Hager Adil, Muhammed Saeed |  |
| 293 |  |  [Offensiveness as an Opinion: Dissecting population-level Label Distributions](https://openreview.net/forum?id=DoOiwBcRir3) |  | 0 | Human annotation is an essential component for building human-in-the-loop machine learning systems (MLs). The diverse human disagreement that arises during annotation is often obscured because of majority voting label aggregation used for training MLs. When the minority opinion is removed in this... | Christopher M. Homan, Sarah Luger, Tharindu Cyril Weerasooriya, Yu Liang |  |
| 294 |  |  [How do ConvNets Understand Image Intensity?](https://openreview.net/forum?id=z2Gr8YqsimF) |  | 0 | Convolutional Neural Networks (ConvNets) usually rely on edge/shape information to classify images. Visualization methods developed over the last decade confirm that ConvNets rely on edge information. We investigate situations where the ConvNet needs to rely on image intensity in addition to shape.... | Jackson Kaunismaa, Michael Guerzhoy |  |
| 295 |  |  [Learning Weight Sensitivity from Entropy](https://openreview.net/forum?id=x_adzmY6PQ5) |  | 0 | Multiple network pruning methods have used connection sensitivity of each weight to prune their network. This paper proposes a meta-learning approach to learn sensitivity of weights based on their entropy, or change, during the training phase. We have experimentally shown the validity of such an... | Novena Agnes |  |
| 296 |  |  [A Study on Sample Diversity in Generative Models: GANs vs. Diffusion Models](https://openreview.net/forum?id=BQpCuJoMykZ) |  | 0 | In this project, we compare the sample diversity of two generative models: Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs). GANs have achieved impressive results in generating high-quality samples, but have been known to suffer from the issue of mode... | Reza Bayat |  |
| 297 |  |  [Artificial Intelligent Life: A New Perspective on Artificial General Intelligence](https://openreview.net/forum?id=XCbe51-arJt) |  | 0 | We propose artificial intelligent life (AILife) as a new perspective to approach artificial general intelligence, similar to a living organism in reality. Unlike machine learning approaches that focus on reward functions and mathematical optimizations, AILife seeks to develop an artificial organism... | Borui Cai, Yao Zhao, Yong Xiang |  |
| 298 |  |  [Generative AI for Therapy? Opportunities and Barriers for ChatGPT in Speech-Language Therapy](https://openreview.net/forum?id=cRZSr6Tpr1S) |  | 0 | Speech-language pathologists (SLPs) are health professionals who work with children and adults with various communication disorders in areas such as speech, language, hearing, and voice. The rise of voice assistants and chatbots brings new opportunities for SLPs and points to new opportunities and... | Felix JuefeiXu, Yao Du |  |
| 299 |  |  [The Art of Embedding Fusion: Optimizing Hate Speech Detection](https://openreview.net/forum?id=1yXbt6_o6av) |  | 0 | Hate speech detection is a challenging natural language processing task that requires capturing linguistic and contextual nuances. Pre-trained language models (PLMs) offer rich semantic representations of text that can improve this task. However there is still limited knowledge about ways to... | Mohammad Aflah Khan, Mohit Jain, Neemesh Yadav, Sanyam Goyal |  |
| 300 |  |  [COLLABORATIVE CONCEPT DRIFT DETECTION](https://openreview.net/forum?id=STpRX-XCO6t) |  | 0 | Collaborative Concept Drift Detection (C2D2) combines Fast Correlated Based Filtering (FCBF) and Singular Value Decomposition (SVD) to detect concept drifts in 5 synthetic datasets. We compare our results against 6 diveregence tests and introduce Performance Gain Update Cost Ratio (PGUCR). Post-hoc... | Beverly Abadines Quon, JeanLuc Gaudiot |  |
| 301 |  |  [End-to-End Learnable Masks With Differentiable Indexing](https://openreview.net/forum?id=EyliiBqhFz) |  | 0 | An essential step towards developing efficient learning algorithms involves being able to work with as little data as possible to achieve good performance. For this reason, sparse representation learning is a crucial avenue of computer vision research. However, sparsity-inducing methods like... | Ashwath Shetty, Dibyanshu Shekhar, Ilia Sucholutsky, Sree Harsha Nelaturu |  |
| 302 |  |  [FigGen: Text to Scientific Figure Generation](https://openreview.net/forum?id=Hx_iTXnCR5) |  | 0 | The generative modeling landscape has experienced tremendous growth in recent years, particularly in generating natural images and art. Recent techniques have shown impressive potential in creating complex visual compositions while delivering impressive realism and quality. However,... | David Vázquez, Issam H. Laradji, Juan A. Rodríguez, Marco Pedersoli, Pau Rodríguez |  |
| 303 |  |  [Evaluating Impact of Emoticons and Pre-processing on Sentiment Classification of Translated African Tweets](https://openreview.net/forum?id=OMARmh02Ruk) |  | 0 | This paper examines the impact of emoticons and pre-processing on sentiment classification for English translations of 11 African languages. Using AfriSenti-SemEval datasets, Roberta and Twitter-Roberta models are fine-tuned, and standard classification metrics are used to assess performance. The... | Gaurav Adhikari, Saurav Keshari Aryal |  |
| 304 |  |  [SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels](https://openreview.net/forum?id=OiSbJbVWBJT) |  | 0 | Rule-based text data augmentation is widely used for NLP tasks due to its simplicity. However, this method can potentially damage the original meaning of the text, ultimately hurting the performance of the model. To overcome this limitation, we propose a straightforward technique for applying soft... | Juhwan Choi, Junho Lee, Kyohoon Jin, Sangmin Song, YoungBin Kim |  |
| 305 |  |  [MatPropXtractor: Generate to Extract](https://openreview.net/forum?id=5CdkvFyatt2) |  | 0 | The field of materials science has amassed a wealth of information about materials in text publications, however, such information is often confined within the publication. A lack of standardized structure and naming consistency preclude the information from being effectively utilized for research... | Aswathy Ajith, Ian T. Foster, Kyle Chard, Marcus Schwarting, Zhi Hong |  |
| 306 |  |  [Zero-Shot Classification Reveals Potential Positive Sentiment Bias in African Languages Translations](https://openreview.net/forum?id=-AIukSeLAz9) |  | 0 | Natural Language Processing research into African languages has been limited, with over 2000 languages still needing to be studied. We employ the AfriSenti-SemEval dataset, a recently released resource that provides annotated tweets across 13 African languages, for sentiment analysis to address... | Howard Prioleau, Hrishav Sapkota, Saurav Keshari Aryal |  |
| 307 |  |  [Lesion Search with Self-supervised Learning](https://openreview.net/forum?id=c-YTzVUkfAW) |  | 0 | Content-based image retrieval (CBIR) with self-supervised learning (SSL) accelerates clinicians’ interpretation of similar images without manual annotations. We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization to... | Daniel Haehn, Jiali Cheng, Kristin Qi |  |
| 308 |  |  [Feature Importance Analysis for Mini Mental Status Score Prediction in Alzheimer's Disease](https://openreview.net/forum?id=GPA-BPLwYHf) |  | 0 | This research article proposes developing predictive models to forecast Mini-Mental State Exam (MMSE) scores using the 54 most important features identified from the current state-of-the-art model. The study employs the SHapley Additive exPlanations (SHAP) method to explore feature importance and... | Howard Prioleau, Saurav Keshari Aryal |  |
| 309 |  |  [On a Relation Between the Rate-Distortion Function and Optimal Transport](https://openreview.net/forum?id=1F8pPnUinbU) |  | 0 | We discuss a relationship between rate-distortion and optimal transport (OT) theory, even though they seem to be unrelated at first glance. In particular, we show that a function defined via an extremal entropic OT distance is equivalent to the rate-distortion function. We numerically verify this... | Eric Lei, Hamed Hassani, Shirin Saeedi Bidokhti |  |
| 310 |  |  [Is CLIP Fooled by Optical Illusions?](https://openreview.net/forum?id=YdGkE4Ugg2C) |  | 0 | Recent large machine learning models such as CLIP have shown impressive generalization performance for various perception tasks. In this work, we explore to what extent they model the human cognitive process. We focus our attention on how these models perceive optical illusions. We present a simple... | Jerry Ngo, Phillip Isola, Swami Sankaranarayanan |  |
| 311 |  |  [Seeing in Words: Learning to Classify through Language Bottlenecks](https://openreview.net/forum?id=_QreMdMNIz-) |  | 0 | Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks. In contrast, humans can explain their predictions using succinct and intuitive descriptions. To incorporate explainability into neural networks, we train a vision model whose feature... | Jonas Geiping, Khalid Saifullah, Micah Goldblum, Tom Goldstein, Yuxin Wen |  |
| 312 |  |  [Towards Stochastic Gradient Variance Reduction by Solving a Filtering Problem](https://openreview.net/forum?id=0sxmoci9Ma) |  | 0 | Stochastic gradient descent is commonly used to optimize deep neural networks, but it often produces noisy and unreliable gradient estimates that hinder convergence. To address this issue, we introduce \textbf{Filter Gradient Descent} (FGD), a family of stochastic optimization algorithms that... | Xingyi Yang |  |
| 313 |  |  [MACHINE TRANSLATION BASELINES FOR ARABIC - SWAHILI](https://openreview.net/forum?id=aVepdnlRb5) |  | 0 | Building neural machine translation (NMT) systems for low-resource languages poses several challenges, mainly due to the lack of parallel data. In this research, we propose a baseline NMT system for translating between Arabic and Swahili. Despite being spoken by nearly 300 million individuals... | Ahmed Emadeldin Almahady, Asim Awad Osman, Hiba Hassan Sayed, Muhammed Saeed |  |
| 314 |  |  [Accuracy of white box and black box adversarial attacks on a sign activation 01 loss neural network ensemble](https://openreview.net/forum?id=QimsmhYvsf) |  | 0 | In this work we ask the question: is an ensemble of single hidden layer sign activation 01 loss networks more robust to white box and black box adversarial attacks than an ensemble of its differentiable counterpart of cross-entropy loss with relu activations and an ensemble of the approximate... | Usman Roshan, Yunzhe Xue |  |
| 315 |  |  [TopEx: Topic-based Explanations for Model Comparison](https://openreview.net/forum?id=AidIUjh__t) |  | 0 | Meaningfully comparing language models is challenging with current explanation methods. Current explanations are overwhelming for humans due to large vocabularies or incomparable across models. We present TopEx, an explanation method that enables a level playing field for comparing language models... | Adam Stein, Eric Wong, Lyle H. Ungar, Shreya Havaldar |  |
| 316 |  |  [GeneDAE: A Sparse Denoising Autoencoder for Deriving Interpretable Gene Embeddings](https://openreview.net/forum?id=cxmjk8O3Yn) |  | 0 | A challenge in genomics research involves identifying functionally relevant genes associated with diseases. We present GeneDAE, a sparse denoising autoencoder that extracts gene representations from large-scale population-level genotype data, which can then be used to identify gene-to-disease... | Andrew Hornback, Karan Samel, May Dongmei Wang, Monica Isgut, Neha Jain |  |
| 317 |  |  [Improving Hyperspectral Adversarial Robustness Under Multiple Attacks](https://openreview.net/forum?id=XHfWgU2IiP) |  | 0 | Semantic segmentation models classifying hyperspectral images (HSI) are vulnerable to adversarial examples. Traditional approaches to adversarial robustness focus on training or retraining a single network on attacked data, however, in the presence of multiple attacks these approaches decrease in... | Nicholas Soucy, Salimeh Yasaei Sekeh |  |
| 318 |  |  [Prompt Programming for the Visual Domain](https://openreview.net/forum?id=hBz5h3C9Sq) |  | 0 | In this work, we ask how text-to-image synthesis via large language models can effectively probe imagery that embodies fidelity and imagination. We investigate this question in the context of prompts (writing to language models) in a novel probing mechanism known as prompt programming, or... | Alayt Issak, Lav R. Varshney |  |
| 319 |  |  [Mapping the Typographic Latent Space of Digits](https://openreview.net/forum?id=ufA2FuCGyz) |  | 0 | Since the advancement of handwritten text to typefaces on a computer, the human mind has evolved towards corresponding various typefaces as norms of comprehension. Current-day typefaces, much like those written by hand, exist in disparities and are governed by consensus reached among Typographers.... | Alayt Issak, Casper Harteveld, Nik Bear Brown, Sair Goetz, Sarthak Kakkar |  |
| 320 |  |  [Hyperbolic Deep Reinforcement Learning for Continuous Control](https://openreview.net/forum?id=Mrz9PgP3sT) |  | 0 | Integrating hyperbolic representations with Deep Reinforcement Learning (DRL) has recently been proposed as a promising approach for enhancing generalization and sample-efficiency in discrete control tasks. In this work, we extend hyperbolic RL to continuous control by introducing a novel... | Arnab Kumar Mondal, Edoardo Cetin, Omar Salemohamed, Sai Rajeswar |  |
| 321 |  |  [Incorporating Expert Prior Knowledge for Oral Lesion Recognition](https://openreview.net/forum?id=XXsjViheWZ) |  | 0 | External information may improve predictive accuracy and uncertainty in medical image recognition. For example in oral lesion recognition, some lesion types are implausible to occur at certain anatomical locations. We propose a strategy to induce the prior knowledge about such correlations using an... | Adeetya Patel, Camille Besombes, Sreenath Arekunnath Madathil |  |
| 322 |  |  [LEARNING LIGHTWEIGHT STRUCTURE-AWARE EMBEDDINGS FOR PROTEIN SEQUENCES](https://openreview.net/forum?id=2M8dEAJcG5) |  | 0 | Machine learning models, such as AlphaFold, have recently demonstrated remarkable accuracy in predicting the structures of protein sequences. This capability enables their use as oracles for providing structure-based information to aid other learning tasks. In this study, we investigate the use of... | Jeffrey Nivala, Philip J. Y. Leung, Sidharth Lakshmanan |  |
| 323 |  |  [Proactive policing as reinforcement learning](https://openreview.net/forum?id=lmcPpHDa0B) |  | 0 | Recent analyses of predictive policing have shown the inherent biases in such systems. We show that the models considered in fact apply to proactive policing in general, which can be also viewed as a reinforcement learning system, and thus may also lead to over-policing. | Dawson Kinsman, Tian An Wong |  |
| 324 |  |  [The Small Batch Size Anomaly in Multistep Deep Reinforcement Learning](https://openreview.net/forum?id=G0heahVv5Y) |  | 0 | We present a surprising discovery: in deep reinforcement learning, decreasing the batch size during training can dramatically improve the agent's performance when combined with multi-step learning. Both reducing batch sizes and increasing the update horizon increase the variance of the gradients,... | Johan S. ObandoCeron, Marc G. Bellemare, Pablo Samuel Castro |  |
| 325 |  |  [Bootstrapping Parallel Anchors for Relative Representations](https://openreview.net/forum?id=VBuUL2IWlq) |  | 0 | The use of relative representations for latent embeddings has shown potential in enabling latent space communication and zero-shot model stitching across a wide range of applications. Nevertheless, relative representations rely on a certain amount of parallel anchors to be given as input, which can... | Antonio Norelli, Emanuele Rodolà, Irene Cannistraci, Luca Moschella, Marco Fumero, Valentino Maiorca |  |
| 326 |  |  [A Brief History of the Speculative Measures for Autonomy](https://openreview.net/forum?id=qqKO_rrg9y) |  | 0 | This paper presents a novel summary of the history of the evolution of the measures for autonomy (i.e. self-legislating systems), from Creation myths to the study of technological autonomy, progressing through five interrelated phases. First, the original legislator of the laws of nature is... | Micah Tewers |  |
| 327 |  |  [Semantic feature verification in FLAN-T5](https://openreview.net/forum?id=_1z2Bqte5L) |  | 0 | This study evaluates the potential of a large language model for aiding in generation of semantic feature norms–a critical tool for evaluating conceptual structure in cognitive science. Building from an existing human-generated dataset, we show that machine-verified norms capture aspects of... | Kushin Mukherjee, Siddharth Suresh, Timothy T. Rogers |  |
| 328 |  |  [Augmenting Collective Intelligence through Belbin's Team Roles](https://openreview.net/forum?id=XiZOalwf_U) |  | 0 | Augmented Collective Intelligence (ACI) allows organizations to improve performance by combining human and artificial intelligence in teams. We use Belbin’s Team Roles, a popular framework that identifies nine clusters of behavioral attributes, to explore how roles might be augmented by AI tools.... | Abhishek Gupta, Emily Dardaman |  |
| 329 |  |  [Text2Face: 3D Morphable Faces From Text](https://openreview.net/forum?id=7Zyv70nGl_g) |  | 0 | We present the first 3D morphable modelling approach, whereby 3D face shape can be directly and completely defined using a textual prompt. Building on work in multi-modal learning, we extend the FLAME head model to a common image-and-text latent space. This allows for direct 3D Morphable Model... | Andrew Keeling, Nick E. Pears, Patrik Huber, Will Rowan |  |
| 330 |  |  [Towards Parametric Robust Activation Functions in Adversarial Machine Learning](https://openreview.net/forum?id=oKa5_mxHBV) |  | 0 | Machine learning's vulnerability to adversarial perturbations has been argued to stem from a learning model's non-local generalization over complex input data. Given the incomplete information in a complex dataset, a learning model captures non-linear patterns between data points with volatility in... | Alberto Luis Dominguez, Ilan Grapel, Niki Pissinou, Sheila Alemany |  |
| 331 |  |  [Understanding Label Bias in Single Positive Multi-Label Learning](https://openreview.net/forum?id=iWiwox99aJ) |  | 0 | Annotating data for multi-label classification is prohibitively expensive because every category of interest must be confirmed to be either present or absent. Recent work on single positive multi-label (SPML) learning has shown that it is possible to train effective multi-label classifiers using... | Elijah Cole, Julio Arroyo, Pietro Perona |  |
| 332 |  |  [Knowledge and Attitude of Medical Students and Doctors towards Artificial Intelligence: A study of University of Ilorin](https://openreview.net/forum?id=5lZaexgIey) |  | 0 | This study assesses the knowledge and attitudes of medical students and doctors in University of Ilorin toward Artificial Intelligence (AI) in medical education. It involved a cross-sectional study using an online survey consisting of close-ended questions. The survey targeted medical students at... | Abdulhameed Abiola Dere |  |
| 333 |  |  [Human-machine cooperation for semantic feature listing](https://openreview.net/forum?id=K-SVVOIcsP) |  | 0 | Semantic feature norms — lists of features that concepts do and do not possess — have played a central role in characterizing human conceptual knowledge, but require extensive human labor. Large language models (LLMs) offer a novel avenue for the automatic generation of such feature lists, but are... | Kushin Mukherjee, Siddharth Suresh, Timothy T. Rogers |  |
| 334 |  |  [Improving generalization by loss modification](https://openreview.net/forum?id=vHOO1lxggJ) |  | 0 | What data points from available data set should be used for training? For all subsets of available data it will generally make different solutions. We show that a simple loss modification allows to find a single solution that represents data set properties and not particular selections of data... | Michael Tetelman |  |
| 335 |  |  [A Rate-Distortion View on Model Updates](https://openreview.net/forum?id=6ry6ibTKOx) |  | 0 | Compressing model updates is critical for reducing communication costs in federated learning. We examine the problem using rate--distortion theory to present a compression method that is near-optimal in many use cases. We empirically show that common transforms applied to model updates in standard... | Jakub Konecný, Johannes Ballé, Nicole Mitchell, Zachary Charles |  |
| 336 |  |  [Text-Based Games as a Challenging Benchmark for Large Language Models](https://openreview.net/forum?id=2g4m5S_knF) |  | 0 | Text-based games (TBG) are puzzle-solving, interactive dialogue language tasks that have the potential to become a challenging intelligence benchmark for large language models (LLMs). TBGs are similar to interactive dialogue, as they require the capability for bidirectional communication in natural... | Ashkan Kazemi, Qinyue Tan, Rada Mihalcea |  |
| 337 |  |  [Learned Learning Rate Schedules for Deep Neural Network Training Using Reinforcement Learning](https://openreview.net/forum?id=0Zhwu1VaOs) |  | 0 | We present a novel strategy to generate learned learning rate schedules for any optimizer using reinforcement learning (RL). Our approach trains a Proximal Policy Optimization (PPO) agent to predict optimal learning rate schedules for SGD, which we compare with other optimizer-scheduler... | Aly El Gamal, Shreyas Subramanian, Vignesh Ganapathiraman |  |
| 338 |  |  [Speaker-Invariant Speech Recognition through Fine-Tuning on Individual-Specific Data with Voice Conversion](https://openreview.net/forum?id=CTZigc9V69) |  | 0 | In this paper, we propose a speaker-invariant speech recognition method that fine-tunes a pre-trained model (Obtained by a self-supervised learning method) on a selected subset of data containing speech from a specific individual. This fine-tuning changes the network's behavior, allowing it to... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 339 |  |  [Effect of training fragment length on Transformers in text complexity prediction](https://openreview.net/forum?id=SBqbPjVFfm) |  | 0 | With the myriad practical applications of text complexity classification, it is important to optimize the training text fragment size for performance. We experiment with fine-tuning pre-trained BERT models to classify the complexity of Russian school text using different fragment sizes for training. | Rafik Hachana, Vladimir V. Ivanov |  |
| 340 |  |  [Revisiting Bisimulation: A Sampling-Based State Similarity Pseudo-metric](https://openreview.net/forum?id=lkWvTn2IzA) |  | 0 | In reinforcement learning (RL), we typically deal with systems with large or continuous states encoded in an unstructured way. Because it is not possible to represent the value of each state, it is necessary to learn a structured representation from limited state samples to express the value... | Charline Le Lan, Rishabh Agarwal |  |
| 341 |  |  [Efficient Learning rate schedules for Stochastic Non-negative Matrix Factorization via Reinforcement Learning](https://openreview.net/forum?id=AAu_WuIiwi) |  | 0 | For deep learning training, learning rate schedules are often picked through trial and error, or hand-crafted optimization algorithms that focus mostly on maintaining stability and convergence without systemic incorporation of higher order derivative information to optimize the convergence slope.... | Aly El Gamal, Shreyas Subramanian, Vignesh Ganapathiraman |  |
| 342 |  |  [Chaotic Transformers for Deep Reinforcement Learning in Algorithmic Trading](https://openreview.net/forum?id=H2mbtfasD4K) |  | 0 | Chaotic Transformers for Deep Reinforcement Learning can be applied in algorithmic trading to improve the efficiency and effectiveness of trading strategies. In algorithmic trading, deep reinforcement learning can be used to learn trading policies that maximize the expected reward. However, due to... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 343 |  |  [Effects of Single-Attribute Control on the Music Generated by FIGARO](https://openreview.net/forum?id=G_MpqMHYo-) |  | 0 | We have experimented with controlling the musical attributes of the music generated by the FIGARO model, while evaluating the success of control and the overall musical quality. The results suggest non-trivial correlations between the musical attributes and the musical quality metrics. | Adil Khan, Rafik Hachana |  |
| 344 |  |  [Iterative weakly supervised learning for novel class object detection](https://openreview.net/forum?id=FWohKbMhlo) |  | 0 | Training object detectors for new classes usually requires collecting and labeling large amounts of data. Our paper introduces a new approach to address this issue - training novel-class object detectors using a combination of a few labeled images and weakly labeled data, that is easy to obtain. We... | Claudio Michaelis, Dejana Mandic, Wieland Brendel |  |
| 345 |  |  [BANDIT SAMPLING FOR FASTER NEURAL NETWORK TRAINING WITH SGD](https://openreview.net/forum?id=LV33sOiYCEP) |  | 0 | Importance sampling is a valuable technique in deep learning that involves sampling useful training examples more frequently to improve learning algorithms. However, obtaining reliable sample importance estimates early on in training can be challenging, as existing importance sampling methods can... | Anila Joshi, Francisco Javier Calderon, Vignesh Ganapathiraman |  |
| 346 |  |  [Train Monolingual, Infer Bilingual](https://openreview.net/forum?id=MjVdwBGkys) |  | 0 | Cross-lingual transfer learning has been studied at depth. While many methods have been developed for pretraining or fine-tuning on monolingual, multilingual and parallel corpora with the purpose of predicting on a low-resource monolingual test set; in this paper we investigate the feasibility of... | Alaeddin Selçuk Gürel, Aydin Gerek |  |
| 347 |  |  [A Simple, Fast Algorithm for Continual Learning from High-Dimensional Data](https://openreview.net/forum?id=TPTbHxeR6U) |  | 0 | As an alternative to resource-intensive deep learning approaches to the continual learning problem, we propose a simple, fast algorithm inspired by adaptive resonance theory (ART). To cope with the curse of dimensionality and avoid catastrophic forgetting, we apply incremental principal component... | Neil Ashtekar, Vasant G. Honavar |  |
| 348 |  |  [Discerning Self-Supervised Learning and Weakly Supervised Learning](https://openreview.net/forum?id=H9BGkFz-Sm) |  | 0 | The AI community has been a very rapidly growing community producing a vast amount of research in a very short span of time. These researches generate a lot of new methods and terminologies. With this scale of developments, it is very difficult to keep a track of terminologies, and under such... | Ali Jannesari, Chandan Kumar, Matthew J. Darr |  |
| 349 |  |  [DiffGANPaint: Fast Inpainting Using Denoising Diffusion GANs](https://openreview.net/forum?id=x2XNoPdXF8J) |  | 0 | Free-form image inpainting is the task of reconstructing parts of an image specified by an arbitrary binary mask. In this task, it is typically desired to generalize model capabilities to unseen mask types, rather than learning certain mask distributions. Capitalizing on the advances in diffusion... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 350 |  |  [Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis](https://openreview.net/forum?id=dJfdug9aGd8) |  | 0 | An indigenous perspective on the effectiveness of debiasing techniques for pre-trained language models (PLMs) is presented in this paper. The current techniques used to measure and debias PLMs are skewed towards the US racial biases and rely on pre-defined bias attributes (e.g. \`\`black'' vs... | Gillian Dobbie, Henry Gouk, Vithya Yogarajan |  |
| 351 |  |  [An Analysis of Transferability in Network Intrusion Detection using Distributed Deep Learning](https://openreview.net/forum?id=FPzByCI0yz1) |  | 0 | In this paper, we utilize a distributed deep learning framework to investigate transferability of network intrusion detection between federated nodes. Transferable learning makes intrusion detection systems more robust to rare attacks and enables them to adapt to real life scenarios. We analyze... | Abu Shafin Mohammad Mahdee Jameel, Aly El Gamal, Shreya Ghosh |  |
| 352 |  |  [MLP-Attention: Improving Transformer Architecture with MLP Attention Weights](https://openreview.net/forum?id=99XvUeDFYTD) |  | 0 | The Transformer architecture has revolutionized natural language processing (NLP) and has achieved state-of-the-art results in various tasks. The attention mechanism is one of the key components of the Transformer architecture, which allows the model to focus on relevant parts of the input. In the... | Alireza Morsali, Moein Heidari, Samin Heydarian, Tohid Abedini |  |
| 353 |  |  [Averager Student: Distillation from Undistillable Teacher](https://openreview.net/forum?id=4isz71_aZN) |  | 0 | Today, some companies release their black-box model as a service for users, where users can see the model’s output corresponding to their input. However, these models can be stolen via knowledge distillation by malicious users. Recently, undistillable teacher (Ma et al., 2021) is introduced in... | Behçet Ugur Töreyin, Reyhan Kevser Keser |  |
| 354 |  |  [Inducing Document Representations from Graphs: A Blueprint](https://openreview.net/forum?id=2rp3guEM3A) |  | 0 | Representing textual documents in continuous numerical spaces is a crucial task in NLP. Early practitioners of NLP built their approach around capturing statistical patterns within documents and utilizing them as features in rich feature spaces. In contrast, contemporary state-of-the-art techniques... | Blaz Skrlj, Boshko Koloski, Marko Pranjic, Nada Lavrac, Senja Pollak |  |
| 355 |  |  [Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for Classification of Common Mental Illnesses on Social Media Posts](https://openreview.net/forum?id=a9VgV-hywP) |  | 0 | Given the current state of the world, because of existing situations around the world, millions of people suffering from mental illnesses feel isolated and unable to receive help in person. Psychological studies have shown that our state of mind can manifest itself in the linguistic features we use... | Mihir Agarwal, Pratinav Seth |  |
| 356 |  |  [Predicting Targets with Data from Non-Conforming Sources](https://openreview.net/forum?id=uMlLT_xuiE) |  | 0 | Machine learning applications to real-world settings are often tasked with making predictions on data generated by multiple sources. There are many methods for understanding when data is Out-Of-Distribution (OOD). A less explored area of importance is where OOD data can be considered... | Alexander Capstick, Payam M. Barnaghi |  |
| 357 |  |  [One Explanation Does Not Fit XIL](https://openreview.net/forum?id=o7uGWBK6Uo) |  | 0 | Current machine learning models produce outstanding results in many areas but, at the same time, suffer from shortcut learning. To address such flaws, the XIL framework has been proposed to revise a model by employing user feedback on a model's explanation. This work sheds light on the explanations... | David Steinmann, Felix Friedrich, Kristian Kersting |  |
| 358 |  |  [Fast Adversarial CNN-based Perturbation Attack on No-Reference Image- and Video-Quality Metrics](https://openreview.net/forum?id=xKf-LSD2-Jg) |  | 0 | Modern neural-network-based no-reference image- and video-quality metrics exhibit performance as high as full-reference metrics. These metrics are widely used to improve visual quality in computer vision methods and compare video processing methods. However, these metrics are not stable to... | Anastasia Antsiferova, Dmitriy S. Vatolin, Ekaterina Shumitskaya |  |
| 359 |  |  [GraphEx: A User-Centric Model-Level Explainer for Graph Neural Networks](https://openreview.net/forum?id=CuE1F1M0_yR) |  | 0 | With the increasing application of Graph Neural Networks (GNNs) in real-world domains, there is a growing need to understand the decision-making process of these models. To address this, we propose GraphEx, a model-level explainer that learns a graph generative model to approximate the distribution... | Monidipa Das, Sanghamitra Bandyopadhyay, Sayan Saha |  |
| 360 |  |  [Theta sequences as eligibility traces: A biological solution to credit assignment](https://openreview.net/forum?id=vd16AYbem3Z) |  | 0 | Credit assignment problems, for example policy evaluation in RL, often require bootstrapping prediction errors through preceding states or maintaining temporally extended memory traces; solutions which are unfavourable or implausible for biological networks of neurons. We propose theta sequences --... | Tom George |  |
| 361 |  |  [Federated Learning with Variational Autoencoders](https://openreview.net/forum?id=mvo72yTjhTl) |  | 0 | In this work we investigate the feasibility of using federated learning to train a variational autoencoder capable of generated handwritten digits when trained on the MNIST dataset. It was found that using federated learning we were able to train a model that produced comparable results to a... | Hugo Dugdale |  |
| 362 |  |  [TRACTABLE LARGE SCALE CALIBRATION WITH RL](https://openreview.net/forum?id=AXxBPw5zdl4) |  | 0 | In this work we show that Reinforcement Learning (RL) is an effective algorithm for calibration problems at a scale which traditionally applied Bayesian approaches struggle. This work uses synthetic data, so has access to ground truth parameters and it can be seen that RL learns different, arguably... | Fadel Thior, Rose Bandolo, Sekou Remy |  |
| 363 |  |  [A Variational Condition for Minimal-Residual Latent Representations](https://openreview.net/forum?id=A2VfgYliIT) |  | 0 | Autoencoders are a useful unsupervised-learning architecture that can be used to build surrogate models of systems governed by partial differential equations, enabling a more cost-effective route to study complex phenomena across science and engineering. In this article, we address two key... | Eloisa Bentivegna |  |
| 364 |  |  [Attention Based Variational Graph Auto-Encoder (AVGAE)](https://openreview.net/forum?id=j1gj0ndrk1) |  | 0 | Recently techniques such as VGAEs (Variational Graph Autoencoder) are quite popular in the unsupervised task setting and in generative modeling. Unlike conventional autoencoders, which typically use fully-connected layers to learn a latent representation of input data, VGAEs operate on... | Krishna Sri Ipsit Mantri, Nevasini Sasikumar |  |
| 365 |  |  [Generative STResnet for Crime Prediction](https://openreview.net/forum?id=-IH_dcPGWM) |  | 0 | In this work, we combine STResnet with VAE to generate crime distribution. The outputs can be used for downstream tasks such as patrol deployment planning. | Hoong Chuin Lau, Tran Phong |  |
| 366 |  |  [A Light Spectrometer Device for Crop Disease Monitoring](https://openreview.net/forum?id=KtVonyo4AS) |  | 0 | Portable devices for the early detection of crop diseases are needed to support the farmers working in the field. Spectrometers showed their potential in the detection of crop diseases. However, high interpretation skills are needed to use the currently available spectrometers. In this project, we... | Ephraim Nuwamanya, Estefania Talavera Martínez, Godliver Owomugisha, Joshua Jeremy Dhikusooka |  |
| 367 |  |  [Can Arterial Blood Pressure Predict Age? A ConvNet Classification Task](https://openreview.net/forum?id=jbBPBUGk-4) |  | 0 | Blood pressure (BP) increases throughout life, and is controlled by several feedback mechanisms in mammals. Therefore, high resolution BP data may contain information related to the health and functionality of those systems, and the organism as a whole. We used beat-to-beat BP data at different... | Abdalrhman Mostafa, Ahmed F. ElYazbi, Mohamed Abdelhack, NourMounira Z. Bakkar |  |
| 368 |  |  [Pay Attention to Multi-Channel for Improving Graph Neural Networks](https://openreview.net/forum?id=IkHVGw_Ipu) |  | 0 | We propose Multi-channel Graph Attention (MGAT) to efficiently handle channel-specific representations encoded by convolutional kernels, enhancing the incorporation of attention with graph convolutional network (GCN)-based architectures. Our experiments demonstrate the effectiveness of integrating... | ChungYi Lin, ShenLung Tung, Winston H. Hsu |  |
| 369 |  |  [pGS-CAM: Interpretable LiDAR Point Cloud Semantic Segmentation via Gradient Based Localization](https://openreview.net/forum?id=8kX0btdpAU5) |  | 0 | To extract the local information required for effective semantic segmentation of point clouds, a number of deep learning architectures typically make use of sophisticated feature extractors. Unfortunately, there has not been a lot of discussion on how to interpret their forecasts, which is... | Abhishek Kuriyal, Vaibhav Kumar |  |
| 370 |  |  [Large Language Models Perform Diagnostic Reasoning](https://openreview.net/forum?id=N0lQfjeNWOE) |  | 0 | We explore the extension of chain-of-thought (CoT) prompting to medical reasoning for the task of automatic diagnosis. Motivated by doctors' underlying reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical results demonstrate that by simply prompting large language models... | ChengKuang Wu, HsinHsi Chen, WeiLin Chen |  |
| 371 |  |  [A Simple Loss Function for Convergent Algorithm Synthesis using RNNs](https://openreview.net/forum?id=WaAJ883AqiY) |  | 0 | Running a Recurrent Neural Network (RNN) over the same input multiple times, or iterative reasoning, enables logical extrapolation, where a model can be run on problems larger than the models were trained on. The loss function used to train these networks has a profound impact on their... | Alexandre Salle, Shervin Malmasi |  |
| 372 |  |  [The Obscure Limitation of Modular Multilingual Language Models](https://openreview.net/forum?id=zEGstYVHBt) |  | 0 | We expose the limitation of modular multilingual language models (MLMs) in multilingual inference scenarios with unknown languages. Existing evaluations of modular MLMs exclude the involvement of language identification (LID) modules, which obscures the performance of real-case multilingual... | Ayu Purwarianti, Muhammad Farid Adilazuarda, Samuel Cahyawijaya |  |
| 373 |  |  [Exploratory Analysis of Scholarly Publications on Artificial Intelligence (AI) in Colonoscopy using Litstudy](https://openreview.net/forum?id=zdhCATDn_Q) |  | 0 | Due to the large number of scholarly papers on AI and colonoscopy and the short research period, it can be difficult to answer general questions about the research area, such as who the key authors are and what the key issues or insights are. We use Litstudy, a Python library, to study colonoscopy... | Mary Adewunmi |  |
| 374 |  |  [Propagate Deeper and Adaptive Graph Convolutional Networks](https://openreview.net/forum?id=RR_w2fbYmV) |  | 0 | Graph Convolutional Networks (GCNs) are the basic architecture for handling graph-structured data. Deeper GCNs are required for large and sparse graph data. As the number of layers increases, the performance of GCNs degrades, which is commonly attributed to over-smoothing but is constantly debated.... | Fan Li, Ge Yu, Lun Du, Mengyuan Chen, Sisi Zhang |  |
| 375 |  |  [L2 Norm Guided Adaptive Computation](https://openreview.net/forum?id=qW_GZYyn7C) |  | 0 | Although the human brain can adjust the amount of time and energy it uses to solve problems of varying complexity, many standard neural networks require a fixed computation budget regardless of the problem’s complexity. This work introduces L2 Adaptive Computation (LAC), a new algorithm that... | Mani Shemiranifar, Mostafa Dehghani |  |
| 376 |  |  [Efficient Temporal Denoising for Improved Depth Map Applications](https://openreview.net/forum?id=nazr0QFvHR) |  | 0 | Depth estimation involves acquiring three-dimensional information from images, which has numerous applications in downstream tasks. Although several effective monocular depth estimation algorithms have been developed, directly applying frame-by-frame depth estimation can result in flickering, which... | Pengzhi Li, Zhiheng Li |  |
| 377 |  |  [AI-based opportunistic analysis of the CT images during COVID (2021): Does living in a metropolitan area affect the vertebral body mineral density in older people?](https://openreview.net/forum?id=QRKKFN7FLm) |  | 0 | The aim of the study is to reveal the problems of using information on several territorial units (districts) of an integral urban agglomeration for an identification of interdimensional peculiarities of living in a particular area by estimating vertebral bone mineral density in Moscow residents... | Alexei V. Petraikin, Andrey V. Vlasov |  |
| 378 |  |  [One Student Knows All Experts Know: From Sparse to Dense](https://openreview.net/forum?id=1PW_txDkX7) |  | 0 | Human education system trains one student by multiple experts. Mixture-of-experts (MoE) is a powerful sparse architecture including multiple experts. However, sparse MoE model is easy to overfit, hard to deploy, and not hardware-friendly for practitioners. In this work, inspired by the human... | Fuzhao Xue, Xiaoxin He, Xiaozhe Ren, Yang You, Yuxuan Lou |  |
| 379 |  |  [AN ENSEMBLE LEARNING FRAMEWORK FOR VISIBILITY PREDICTION IN INDO-GANGETIC REGION](https://openreview.net/forum?id=WkDqZD3VRo) |  | 0 | Visibility of an area affects all forms of transportation such as sea, surface and aviation which can further affect the economy of that area. Thus it is very important to accurately estimate the visibility of an area for the upcoming days based on different parameters of the past meteorological... | Arkapal Panda, Tanmay Basu, Vaibhav Kumar |  |
| 380 |  |  [Evolutionary Federated Learning Using Particle Swarm Optimization](https://openreview.net/forum?id=fcQFbluDTX) |  | 0 | Efficient communication is a key challenge in federated learning, where multiple clients contribute to a shared model. To address this issue, reducing local computation is an effective solution. This paper proposes an innovative federated learning algorithm that utilizes Particle Swarm... | Ender Minyard, Nayan Saxena, Steven Kolawole |  |
| 381 |  |  [Understanding the Effectiveness of Cross-Domain Contrastive Unsupervised Domain Adaptation](https://openreview.net/forum?id=0GpMf9UeI3G) |  | 0 | Unsupervised domain adaptation helps to transfer learned tasks from a source to a target domain in the lack of labeled data. Recently, contrastive learning showed promising results on this setup. However, there are limitations on the performance due to unbalanced objectives between the... | Adil Khan, Adín Ramírez Rivera, Viacheslav Sinii |  |
| 382 |  |  [Performance Evaluation of Enhanced ConvNeXtTiny-based Fire Detection System in Real-world Scenarios](https://openreview.net/forum?id=A-E41oZCfrf) |  | 0 | Timely detection of fires is crucial for saving human lives and minimizing the economic and ecological impact of such incidents. Although numerous attempts have been made to identify a fire in its early stage, significant challenges remain in achieving accurate and reliable detection. Therefore, we... | Chang Choi, Haci Ismail Aslan, Taimoor Khan |  |
| 383 |  |  [Robustness Evaluation of Multi-Agent Reinforcement Learning Algorithms using GNAs](https://openreview.net/forum?id=zZjPRz0EX5T) |  | 0 | Recently, multi-agent reinforcement learning (MARL) has shown its ability in solving sequential decision-making problems in complicated multi-agent environments. However, uncertainties from observations and executions undermine its performance when MARL methods are deployed in real-world... | Jianyu Zhang, Liangliang Yang, Sihong He, Wei Zhang, Xusheng Zhang, Yishu Gong, Zhengyu Chen |  |
| 384 |  |  [State Advantage Weighting for Offline RL](https://openreview.net/forum?id=PjypHLTo29v) |  | 0 | We present \textit{state advantage weighting} for offline reinforcement learning (RL). In contrast to action advantage $A(s,a)$ that we commonly adopt in QSA learning, we leverage state advantage $A(s,s^\prime)$ and QSS learning for offline RL, hence decoupling the action from values. We expect the... | Aicheng Gong, Jiafei Lyu, Le Wan, Xiu Li, Zongqing Lu |  |
| 385 |  |  [Towards Robust Feature Learning with t-vFM Similarity for Continual Learning](https://openreview.net/forum?id=6I5i0Ytnlul) |  | 0 | Continual learning has been developed using standard supervised contrastive loss from the perspective of feature learning. Due to the data imbalance during the training, there are still challenges in learning better representations. In this work, we suggest using a different similarity metric... | Bilan Gao, YoungBin Kim |  |
| 386 |  |  [When Biology has Chemistry: Solubility And Drug Subcategory Prediction using SMILES Strings](https://openreview.net/forum?id=28si4RXwDt1) |  | 0 | Drug discovery is a complex process that requires extensive research and development. One important aspect of drug discovery is the prediction of drug properties, such as solubility. In recent years, sequence-based embedding methods, such as SMILES strings, have gained popularity in the drug... | Murray Patterson, Prakash Chourasia, Sarwan Ali |  |
| 387 |  |  [Answering Questions Over Knowledge Graphs Using Logic Programming Along with Language Models](https://openreview.net/forum?id=D2lo4toTUTo) |  | 0 | Question Answering over Knowledge Graphs (KGQA) is the task of answering natural language questions over a knowledge graph (KG). This task requires a model to reason over multiple edges of the KG to reach the right answer. In this work, we present a method to equip large language models (LLMs) with... | Kenneth Joseph, Navid Madani |  |
| 388 |  |  [Contrastive Training with more data](https://openreview.net/forum?id=ZTp85mW5nFy) |  | 0 | This paper proposes a new method of contrastive training over multiple data points, focusing on the scaling issue present when using in-batch negatives. Our approach compares transformer training with dual encoders vs training with multiple encoders. Our method can provide a feasible approach to... | Hossein Rahmani, Scott Piao, Stephen Mander |  |
| 389 |  |  [Statistical Methods for Auditing the Quality of Manual Content Reviews](https://openreview.net/forum?id=GSlYBJ3aOpC) |  | 0 | Large technology firms face the problem of moderating content on their online platforms for compliance with laws and policies. To accomplish this at the scale of billions of pieces of content per day, a combination of human and machine review are necessary to label content. Subjective judgement and... | Andrew Smart, Daniel Theron, Xuan Yang |  |
| 390 |  |  [ARTIFICIAL PSYCHOLOGY](https://openreview.net/forum?id=TqkzImZ92t8) |  | 0 | Most Deep Learning based Model Compression methods draw their inspiration from the human brain. This is an example of how powerful but overlooked abstractions from the human mind are. Hoping to benefit the discipline of one from the other, this paper aims to draw attention to a line of research at... | Mubarek Mohammed |  |
| 391 |  |  [Automated Mapping of Healthcare Concepts to a Standardized Healthcare Taxonomy](https://openreview.net/forum?id=87oCobKKS6x) |  | 0 | SNOMED CT presents an opportunity for numerous research prospects to learn medical terminologies and effectively assist the diagnosis process. In this work, we propose mapping the information in medical records to paths extracted from the SNOMED CT knowledge graph. To achieve this, we have... | AKM Shahariar Azad Rabby, Fuad Rahman, Mashrur Wasek, Mohammed Rakib, Nabeel Mohammed, Sabbir Mollah |  |
| 392 |  |  [RepFair-GAN: Mitigating Representation Bias in GANs Using Gradient Clipping](https://openreview.net/forum?id=frB4MiYGoD_) |  | 0 | This work introduces a new notion of fairness, \textit{representational fairness}, for generative models, which ensures uniform representation of demographic groups in the generated data. Vanilla GANs violate this notion even when groups are equally represented. The proposed solution is to use... | Adil Khan, Adín Ramírez Rivera, Kamil Sabbagh, Patrik Joslin Kenfack |  |
| 393 |  |  [Prior knowledge meets Neural ODEs: a two-stage training method for improved explainability](https://openreview.net/forum?id=p7sHcNt_tqo) |  | 0 | Neural Ordinary Differential Equations (ODEs) have been used extensively to model physical systems because they represent a continuous-time function that can make predictions over the entire time domain. However, most of the time, the parameters of these physical systems are subject to strict... | C. Coelho, Luís L. Ferrás, M. Fernanda P. Costa |  |
| 394 |  |  [Self-Supervised Continual Learning](https://openreview.net/forum?id=udl9OobOxZu) |  | 0 | This paper proposes \textit{Self-Supervised Continual Learning (SCL)} for regularization-based class incremental learning. The novel pretext task in SCL utilizes randomly-transformed labels without depending on data-augmented transforms. \textit{SCL} trained with a novel incremental... | Bharat Giddwani, Kartik Thakral, Mayank Vatsa, Richa Singh, Surbhi Mittal, Utkarsh Uppal |  |
| 395 |  |  [When Spiking Neural Networks Meet Temporal Attention Image Decoding and Adaptive Spiking Neuron](https://openreview.net/forum?id=MuOFB0LQKcy) |  | 0 | Spiking Neural Networks (SNNs) are capable of encoding and processing temporal information in a biologically plausible way. However, most existing SNN-based methods for image tasks do not fully exploit this feature. Moreover, they often overlook the role of adaptive threshold in spiking neurons,... | RuiJie Zhu, Xuerui Qiu, Zhaorui Wang, Zheng Luan |  |
| 396 |  |  [Characters Are Like Faces](https://openreview.net/forum?id=HM_jOWEYL7y) |  | 0 | There are over 100,000 characters in Chinese, though only four thousand of them are used in our daily life. However for cultural researchers, they interact with those Rarely Used Characters (RUCs) frequently. It would facilitate using these RUCs for them with Optical Character Recognition (OCR)... | Haoyu Deng, Yule Duan, Zhaoteng Ye |  |
| 397 |  |  [A Scalable Self-supervised Learner for Hyperspectral Image Classification](https://openreview.net/forum?id=uwbyW92Sonu) |  | 0 | Learning-based Hyperspectral image classification methods have achieved fantastic performance due to their superior ability to represent features at the cost that these methods are complex, inflexible and weak to generalize. Thus, we propose a simple and scalable pretrained model which can greatly... | Baisen Liu, Jiaming Pei, Lin Qi, Weili Kong |  |
| 398 |  |  [Optimizing MPJPE promotes miscalibration in multi-hypothesis human pose lifting](https://openreview.net/forum?id=B5riBS9HZGn) |  | 0 | Due to depth ambiguities and occlusions, lifting 2D poses to 3D is a highly ill-posed problem. Well-calibrated distributions of possible poses can make these ambiguities explicit and preserve the resulting uncertainty for downstream tasks, thus providing the necessary trustworthiness in... | Fabian H. Sinz, Mohammad Bashiri, Pawel A. Pierzchlewicz, R. James Cotton |  |
| 399 |  |  [Unsupervised Detection of Cell Assemblies with Graph Neural Networks](https://openreview.net/forum?id=Tbzv_BbjjO8) |  | 0 | Cell assemblies, putative units of neural computation, manifest themselves as repeating and temporally coordinated activity of neurons. However, understanding of their role in brain function is hampered by a lack of scalable methods for their unsupervised detection. We propose using a graph neural... | Roman Koshkin, Tomoki Fukai |  |
| 400 |  |  [Heat Up The Sentiment Learning With ICE](https://openreview.net/forum?id=wFxjFCHUkS) |  | 0 | Recently, dramatic gains have been made on the task of aspect sentiment triplet extraction (ASTE). In this paper, we introduce a straightforward pipeline model to perform two-stage sequence labeling, including aspect and opinion terms identification and aspect-opinion pair classification. To... | Hai Zhao, Yao Yao, Zuchao Li |  |
| 401 |  |  [Almost Sure Last Iterate Convergence of Sharpness-Aware Minimization](https://openreview.net/forum?id=IcDTYTI0Nx) |  | 0 | Sharpness-Aware Minimization (SAM) is an iterative optimization process to train neural networks, by which the training is guided to find flat minima, such that the solution found at convergence may generalize well. However, previous studies on the convergence of SAM have only shown the existence... | Jinseok Chung, Kyunghun Nam, Namhoon Lee |  |
| 402 |  |  [On the application and impact of ε-DP and fairness in ambulance engagement time prediction](https://openreview.net/forum?id=WKVH54a1W4) |  | 0 | This study elaborates on a complete pipeline for the development of a private and fair Machine Learning (ML) model to predict ambulance engagement time. It was shown that sensitive variables reduced their impact on model building with Random Forest as the differential privacy budget (ε) decreased... | Catuscia Palamidessi, Selene Cerna |  |
| 403 |  |  [Adversarial Policy Gradient for Learning Graph-Based Representation in Human Visual Processing](https://openreview.net/forum?id=5-ROmmBJKV) |  | 0 | This article discusses the challenges in modeling the neural mechanisms underlying human visual processing and the use of graph-based representations to capture inter-region relationships in visual processing. While graphs have shown promise in analyzing neural responses, learning an optimal graph... | Debasis Samanta, Subhrasankar Chatterjee, Subrata Pain |  |
| 404 |  |  [Federated Learning for Local and Global Data Distribution](https://openreview.net/forum?id=qX8cGLnfAd) |  | 0 | Existing research in Federated Learning focuses on synthetic or small-scale datasets, with in-house distribution posing challenges for long-term real-world use cases. We propose a novel approach that maximizes in-house (local) distribution gains while focusing on generalization. Experimental... | Akshay Agarwal, Gaurav Goswami, Mayank Vatsa, Nalini K. Ratha, Richa Singh |  |
| 405 |  |  [Is DFR for Soft Biometrics Prediction in Unconstrained Images Fair and Effective?](https://openreview.net/forum?id=rLqN6XLbON) |  | 0 | Face being a nonintrusive recognition modality, is an ideal candidate for identifying criminals. The modality is not only related to identity but can also extract several other important features such as age, race, and gender. In this preliminary research, we have collected a novel unconstrained... | Akshay Agarwal, Udaybhan Rathore |  |
| 406 |  |  [Integrating Information from Natural Language Parse Tree to Code Generation](https://openreview.net/forum?id=1WEPXTIjAd) |  | 0 | While more and more research works have considered Natural Language artifacts as the inputs of software engineering research, such as code generation, information about their graph/tree representations needs to be carefully considered. In this work, we propose an approach for integrating... | Ali Jannesari, Hung Phan |  |
| 407 |  |  [Pseudo Labels for Single Positive Multi-Label Learning](https://openreview.net/forum?id=-CH1C-aQ5pk) |  | 0 | The cost of data annotation is a substantial impediment for multi-label image classification: in every image, every category must be labeled as present or absent. Single positive multi-label (SPML) learning is a cost-effective solution, where models are trained on a single positive label per image.... | Julio Arroyo |  |
| 408 |  |  [Drowning Detection based on YOLOv8 improved by GP-GAN Augmentation](https://openreview.net/forum?id=osqgjMNm4_) |  | 0 | Drowning is a significant safety issue worldwide, and a robust computer vision-based alert system can easily prevent such tragedies in swimming pools. However, due to domain shift caused by the visual gap (potentially due to lighting, indoor scene change, pool floor color etc.) between the training... | En Wei, Simiao Ren |  |
| 409 |  |  [Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech Detection](https://openreview.net/forum?id=eaKoBpxCPe) |  | 0 | Health experts assert that hope plays a crucial role in enhancing individuals' physical and mental well-being, facilitating their recovery, and promoting restoration. Hope speech refers to \`\`YouTube comments/posts that offer support, reassurance, suggestions, inspiration, and insight.". The... | Diksha Sethi, Mohammad Aflah Khan, Neemesh Yadav, Raghav Sahni |  |
| 410 |  |  [Group Equivariant Convolutional Networks](https://openreview.net/forum?id=niyvAOOnwPM) |  | 0 | Convolutional Neural Networks (CNN) are using symmetry priors to make the best out of the properties of the data, in particular translation invariance in images. Group Equivariant CNN (Cohen & Welling, 2016) extend CNN by using invari- ances from other groups of symmetry. After exploring their... | Maya Janvier |  |
| 411 |  |  [Exploring Semantic Variations in GAN Latent Spaces via Matrix Factorization](https://openreview.net/forum?id=2Z-dQTRezZ) |  | 0 | Controlled data generation with GANs is desirable but challenging due to the nonlinearity and high dimensionality of their latent spaces. In this work, we explore image manipulations learned by GANSpace, a state-of-the-art method based on PCA. Through quantitative and qualitative assessments we... | Adil Khan, Andrey Palaev, Rustam A. Lukmanov |  |
| 412 |  |  [The Polarised Regime of identifiable Variational Autoencoders](https://openreview.net/forum?id=iSkcAjBqUHU) |  | 0 | The polarised regime—the capacity of variational autoencoders (VAEs) to discard superfluous latent variables—is well-studied in the context of “classical” VAEs with a standard Gaussian prior. In this paper, we extend these results to the case of identifiable VAEs (iVAEs). | Lisa Bonheme, Marek Grzes |  |
| 413 |  |  [Uni-Match: A Semantic Unified Model for Query-Product Retrieval](https://openreview.net/forum?id=91Bcj6sgcxt) |  | 0 | For most practical search systems, the cascaded matching-prerank-rank architecture is designed. In the prerank stage, the dual-tower structure is widely used to maintain efficiency. However, due to the lack of interaction between query and document, this architecture could only take into account... | Qihang Zhao, RuiJie Zhu, Yunrui Ge, Zhenyang Zhu |  |
| 414 |  |  [Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention](https://openreview.net/forum?id=Peb3QdR8zzP) |  | 0 | Compared with standard text, understanding dialogue is more challenging for machines as the dynamic and unexpected semantic changes in each turn. To model such inconsistent semantics, we propose a simple but effective Hierarchical Dialogue Understanding model, HiDialog. Specifically, we first... | Fuzhao Xue, Heng Zhang, Jian Zhang, Xiao Liu, Yang You |  |
| 415 |  |  [Large Sparse Kernels for Federated Learning](https://openreview.net/forum?id=ZCv4E1unfJP) |  | 0 | Existing approaches to address non-iid data in federated learning are often tailored to specific types of heterogeneity and may lack generalizability to all scenarios. In this paper, we present empirical evidence supporting the claim that employing large sparse convolution kernels can lead to... | Feilong Zhang, Junjun Jiang, Shiyi Lin, Xianming Liu, Yinchuan Li, Yunfeng Shao |  |
| 416 |  |  [Using vision transformer-based GANs against Vision Transformers](https://openreview.net/forum?id=WFatA9XIQ0m) |  | 0 | Vision transformers have become one of the best architectures for image classification tasks. In this paper, we introduce a novel method for creating adversarial attacks in a black box environment without using surrogate models. Specifically, we introduce a single encoder and a three-encoder... | Andrei Florin Pamînt, Sergiu Adrian Darabant |  |
| 417 |  |  [Pivot Pre-finetuning for Low Resource MT: A Case Study in Kikamba](https://openreview.net/forum?id=PaHmtktx86H) |  | 0 | Current approaches to performant machine translation often require large amounts of data (Koehn et al., 2022). However for a majority of 7000+ languages in the world, these languages often have a relative lack of digitized/organized text available, and are considered low-resource. In practical... | Machel Reid, Stephen Ngumbi Kiilu |  |
| 418 |  |  [Unsupervised Learning for Anomaly Detection: A Comparison of Deep Generative Models](https://openreview.net/forum?id=WU3veNUvvU) |  | 0 | Anomaly detection is a critical task in various domains, including cybersecurity, fraud detection, and health monitoring. Traditional methods for anomaly detection rely on handcrafted features and require expert knowledge, which can be time-consuming and expensive. Recently, deep generative models... | Kitgak Simon |  |
| 419 |  |  [Bayes classifier cannot be learned from noisy responses with unknown noise rates](https://openreview.net/forum?id=U4o5iSWSaD) |  | 0 | Training a classifier with noisy labels typically requires the learner to specify the distribution of label noise, which is often unknown in practice. Although there have been some recent attempts to relax that requirement, we show that the Bayes decision rule is unidentified in most classification... | Soham Bakshi, Subha Maity |  |
| 420 |  |  [Contrastive Learning with 3D Shapes](https://openreview.net/forum?id=ChW0YYRIni) |  | 0 | In fields such as Computer Vision or NLP, there is a large amount of data available which, however, cannot be labeled, as it would be very expensive. A possible solution to this problem is Contrastive Learning, a Self-Supervised technique. This work aims to implement a contrastive learning regime... | Andrea Bernini |  |
| 421 |  |  [Adaptive-saturated RNN: Remember more with less instability](https://openreview.net/forum?id=Ihzsru2bw2) |  | 0 | Orthogonal parameterization is a compelling solution to the vanishing gradient problem (VGP) in recurrent neural networks (RNNs). With orthogonal parameters and non-saturated activation functions, gradients in such models are constrained to unit norms. On the other hand, although the traditional... | Binh T. Nguyen, Khoi Minh NguyenDuy, Quang Pham |  |
| 422 |  |  [Stratospheric Aerosols: Establishing a Novel Optical Thickness Benchmark for Effective Climate Change Mitigation](https://openreview.net/forum?id=pKd6q-FrprW) |  | 0 | Global Warming has been a problem at the heart of Earth’s environmental issues for nearly 5 decades, with the potential to affect a significant portion of the global population and cause catastrophic irreversible damage to the planet's future. Changes in Earth’s climate due to the rise in global... | Mihir Garimella |  |
| 423 |  |  [CausalStructCodec: Causally-aware observational and interventional data generator](https://openreview.net/forum?id=cKLmwCTFiI) |  | 0 | Over the last few years, causal generative models have massively gained popularity. Their main goal is to generate observational, interventional and counterfactual data. They are also interesting for causal discovery or fair Machine Learning. These generators are based on typical data generation... | Louis Hernandez, Matthieu Boussard |  |
| 424 |  |  [Semantic Similarity Based Label Augmentation for Visual Classification](https://openreview.net/forum?id=bRI_3OFg4o) |  | 0 | Real-world applications may present visual categories for which examples are many but a definition is elusive. When data augmentation helps little and hand-crafted heuristics fail to warrant weak supervision, similarity remains a simple but effective guide for augmenting training labels. This paper... | Yu Cao |  |
| 425 |  |  [Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning](https://openreview.net/forum?id=3EfxJTp_-Cj) |  | 0 | Prompt engineering and calibration make large language models excel at reasoning tasks, including multiple choice commonsense reasoning. From a practical perspective, we investigate and evaluate these strategies on smaller language models. Through experiments on five commonsense reasoning... | Chenkai Ma |  |
| 426 |  |  [Fidelity of Interpretability Methods and Perturbation Artifacts in Neural Networks](https://openreview.net/forum?id=nbqO93YTz-) |  | 0 | Despite excellent performance of deep neural networks (DNNs) in image classification, detection, and prediction, characterizing how DNNs make a given decision remains an open problem, resulting in a number of interpretability methods. Post-hoc interpretability methods primarily aim to quantify the... | Lennart Brocki, Neo Christopher Chung |  |
| 427 |  |  [EDCDE - Extended Discovery of Closed-Form Differential Equations](https://openreview.net/forum?id=EVz_vcZQvvg) |  | 0 | Understanding the mathematical connections between variables in a physical system, such as Ordinary Differential Equations (ODEs) is an essential part of the scientific method. This is where symbolic regression plays a key role in looking for closed-form functions given a dataset. We extend the... | Robert Joseph George |  |
| 428 |  |  [Synthetic Controls as Balancing Scores](https://openreview.net/forum?id=AFLNyWMg4D2) |  | 0 | We outline the factors under which conditioning on Synthetic Control (SC) weights emulates a randomized control trial where the treatment status is independent of potential outcomes. Specifically, we demonstrate that if there exist SC weights such that the treatment effects are exactly identified,... | Harsh Parikh |  |
| 429 |  |  [Clustered Federated Learning with Slightly Skewed Labels](https://openreview.net/forum?id=qPwZouq5sY_) |  | 0 | Clustered federated learning methods are proposed to realize the personalization of federated learning. The core of these methods is KMeans while it cannot identify sample from which cluster under slight non-IID data distribution. This paper proposed Gaussian mixture cluster (GMCFL) to measure the... | Jiaming Pei, Wei Li |  |
| 430 |  |  [Fusing 3D-CNN and lightweight Swin Transformer networks for HSI](https://openreview.net/forum?id=Jx44OPxLZ2-) |  | 0 | Recently deep learning has occupied an important position in hyperspectral image (HSI) classification. In this study, we explore the advantages of using convolutional neural networks (CNN) for feature extraction and fusing an advanced shift-window (swin) transformer network based on the transformer... | Baisen Liu, Wulin Zhang, Yiran Tian, Yuanjia Liu |  |
| 431 |  |  [Compound Tokens: Channel Fusion for Vision-Language Representation Learning](https://openreview.net/forum?id=_3_VZtMkvMB) |  | 0 | We present an effective method for fusing visual-and-language representations for several question answering tasks including visual question answering and visual entailment. In contrast to prior works that concatenate unimodal representations or use only cross-attention, we compose multimodal... | A. J. Piergiovanni, Maxwell Mbabilla Aladago |  |
| 432 |  |  [Message-passing Selection: Towards Interpretable GNNs for Graph Classification](https://openreview.net/forum?id=99Go96dla5y) |  | 0 | In this paper, we strive to develop an interpretable GNNs' inference paradigm, termed MSInterpreter, which can serve as a plug-and-play scheme readily applicable to various GNNs' baselines. Unlike the most existing explanation methods, MSInterpreter provides a Message-passing Selection... | Haofei Zhang, Kaixuan Chen, Mingli Song, Shunyu Liu, Wenda Li, Wenjie Huang, Yingjie Tian, Yun Su |  |
| 433 |  |  [Multi-Agent Reinforcement Learning for Coalitional Bargaining Games](https://openreview.net/forum?id=OaZktJBVpUy) |  | 0 | In recent years, there has been growing attention to the application of MARL to coalition formation problems, in particular, on coalitional bargaining games as a means of negotiation. However, the lack of theoretical principles for using MARL in coalitional bargaining games remain less explored.... | Enrico H. Gerding, Ignacio Carlucho, Kalesha Bullard, Lucia CipolinaKun, Sebastian Stein, Stephen Mak, Vahid Yazdanpanah |  |
| 434 |  |  [Astroformer: More Data might not be all you need for Classification](https://openreview.net/forum?id=ChqP6ORFYK6) |  | 0 | Recent advancements in areas such as natural language processing and computer vision rely on intricate and massive models that have been trained using vast amounts of unlabelled or partly labeled data and training or deploying these state-of-the-art methods to resource constraint environments has... | Rishit Dagli |  |
| 435 |  |  [Error Analysis of Fitted Q-iteration with ReLU-activated Deep Neural Networks](https://openreview.net/forum?id=EVwbNcRa6Yf) |  | 0 | Deep reinforcement learning (RL) has grown rapidly with the development of backbone feedforward neural networks (FNNs). However, there remains a theoretical gap when researchers conduct error analysis of the FNNs-based RL process. In this work, we provide an error analysis for deep-fitted... | Chang Zhu, Han Yuan, Lican Kang |  |
| 436 |  |  [General Purpose Artificial Intelligence Systems as Group Agents](https://openreview.net/forum?id=ddFJsnpZtTX) |  | 0 | This paper advocates for General Purpose Artificial Intelligence Systems to be viewed as group agents. This view emphasizes their shared agency characteristics and allows for the assignment of collective responsibility, while still recognizing individual accountability when necessary. This... | Matija Franklin |  |
| 437 |  |  [An Empirical Study of the Effect of Background Data Size on the Stability of SHapley Additive exPlanations (SHAP) for Deep Learning Models](https://openreview.net/forum?id=L38bbHmRKx) |  | 0 | SHapley Additive exPlanations (SHAP) is a popular method that requires a background dataset in uncovering the deduction mechanism of artificial neural networks (ANNs). Generally, a background dataset consists of instances randomly sampled from the training dataset. However, the sampling size and... | Chenkui Miao, Han Yuan, Lican Kang, Mingxuan Liu, Ying Wu |  |
| 438 |  |  [Interpretable Machine Learning-Based Risk Scoring with Individual and Ensemble Model Selection for Clinical Decision Making](https://openreview.net/forum?id=RNlfw6KXJey) |  | 0 | Clinical scores are highly interpretable and widely used in clinical risk stratification. AutoScore was previously developed as a clinical score generator, integrating the interpretability of clinical scores and the discriminability of machine learning. Although a basic framework has been... | Chenglin Niu, Feng Xie, Han Yuan, Jin Wee Lee, Jun Wen, Mingxuan Liu, Siqi Li |  |
| 439 |  |  [Analytical solutions for a family of single layer neural network regression problems](https://openreview.net/forum?id=g6ZFp73_T7) |  | 0 | In this paper, we analyze a family of penalized single layer neural network regression problems wherein the response variable has all non-negative entries. We show analytically that the optimal weights of the problem lie at the vector of zeros, which is a point of non-differentiability. | Siddharth Krishna Kumar |  |
| 440 |  |  [Pretrained Vision Models for Predicting High-Risk Breast Cancer Stage](https://openreview.net/forum?id=Idalad_7wG) |  | 0 | Cancer is increasingly a global health issue. Seconding cardiovascular diseases, cancers are the second biggest cause of death in the world with millions of people succumbing to the disease every year. According to the World Health Organization (WHO) report, by the end of 2020, more than 7.8... | Bonaventure F. P. Dossou, Miglanche Ghomsi Nono, Yenoukoume S. K. Gbenou |  |
| 441 |  |  [Encoding Recurrence into Transformers](https://openreview.net/forum?id=7YfHla7IxBJ) |  | 0 | This paper novelly breaks down with ignorable loss an RNN layer into a sequence of simple RNNs, each of which can be further rewritten into a lightweight positional encoding matrix of a self-attention, named the Recurrence Encoding Matrix (REM). Thus, recurrent dynamics introduced by the RNN layer... | Feiqing Huang, Guangjian Tian, Guodong Li, Kexin Lu, Yanwen Fang, Yuxi Cai, Zhen Qin |  |
| 442 |  |  [Modeling content creator incentives on algorithm-curated platforms](https://openreview.net/forum?id=l6CpxixmUg) |  | 0 | Content creators compete for user attention. Their reach crucially depends on algorithmic choices made by developers on online platforms. To maximize exposure, many creators adapt strategically, as evidenced by examples like the sprawling search engine optimization industry. This begets competition... | Jiri Hron, Karl Krauth, Michael I. Jordan, Niki Kilbertus, Sarah Dean |  |
| 443 |  |  [Transfer NAS with Meta-learned Bayesian Surrogates](https://openreview.net/forum?id=paGvsrl4Ntr) |  | 0 | While neural architecture search (NAS) is an intensely-researched area, approaches typically still suffer from either (i) high computational costs or (ii) lack of robustness across datasets and experiments. Furthermore, most methods start searching for an optimal architecture from scratch, ignoring... | Frank Hutter, Gresa Shala, Josif Grabocka, Thomas Elsken |  |
| 444 |  |  [Scaling Up Probabilistic Circuits by Latent Variable Distillation](https://openreview.net/forum?id=067CGykiZTS) |  | 0 | Probabilistic Circuits (PCs) are a unified framework for tractable probabilistic models that support efficient computation of various probabilistic queries (e.g., marginal probabilities). One key challenge is to scale PCs to model large and high-dimensional real-world datasets: we observe that as... | Anji Liu, Guy Van den Broeck, Honghua Zhang |  |
| 445 |  |  [A Kernel Perspective of Skip Connections in Convolutional Networks](https://openreview.net/forum?id=6H_uOfcwiVh) |  | 0 | Over-parameterized residual networks (ResNets) are amongst the most successful convolutional neural architectures for image processing. Here we study their properties through their Gaussian Process and Neural Tangent kernels. We derive explicit formulas for these kernels, analyze their spectra, and... | Amnon Geifman, Daniel Barzilai, Meirav Galun, Ronen Basri |  |
| 446 |  |  [WikiWhy: Answering and Explaining Cause-and-Effect Questions](https://openreview.net/forum?id=vaxnu-Utr4l) |  | 0 | As large language models (LLMs) grow larger and more sophisticated, assessing their "reasoning" capabilities in natural language grows more challenging. Recent question answering (QA) benchmarks that attempt to assess reasoning are often limited by a narrow scope of covered situations and subject... | Aditya Sharma, Justin Chang, Matthew Ho, Michael Saxon, Sharon Levy, William Yang Wang, Yujie Lu |  |
| 447 |  |  [Git Re-Basin: Merging Models modulo Permutation Symmetries](https://openreview.net/forum?id=CQsmMYmlP5T) |  | 0 | The success of deep learning is due in large part to our ability to solve certain massive non-convex optimization problems with relative ease. Though non-convex optimization is NP-hard, simple algorithms -- often variants of stochastic gradient descent -- exhibit surprising effectiveness in fitting... | Jonathan Hayase, Samuel K. Ainsworth, Siddhartha S. Srinivasa |  |
| 448 |  |  [The Role of Coverage in Online Reinforcement Learning](https://openreview.net/forum?id=LQIjzPdDt3q) |  | 0 | Coverage conditions---which assert that the data logging distribution adequately covers the state space---play a fundamental role in determining the sample complexity of offline reinforcement learning. While such conditions might seem irrelevant to online reinforcement learning at first glance, we... | Dylan J. Foster, Nan Jiang, Sham M. Kakade, Tengyang Xie, Yu Bai |  |
| 449 |  |  [Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification](https://openreview.net/forum?id=FZdJQgy05rz) |  | 0 | There is a fundamental limitation in the prediction performance that a machine learning model can achieve due to the inevitable uncertainty of the prediction target. In classification problems, this can be characterized by the Bayes error, which is the best achievable error with any classifier. The... | Gang Niu, Ikko Yamane, Masashi Sugiyama, Nontawat Charoenphakdee, Takashi Ishida |  |
| 450 |  |  [Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes](https://openreview.net/forum?id=4-k7kUavAj) |  | 0 | The potential of offline reinforcement learning (RL) is that high-capacity models trained on large, heterogeneous datasets can lead to agents that generalize broadly, analogously to similar advances in vision and NLP. However, recent works argue that offline RL methods encounter unique challenges... | Aviral Kumar, George Tucker, Rishabh Agarwal, Sergey Levine, Xinyang Geng |  |
| 451 |  |  [What learning algorithm is in-context learning? Investigations with linear models](https://openreview.net/forum?id=0g0X4H8yN4I) |  | 0 | Neural sequence models, especially transformers, exhibit a remarkable capacity for in-context learning. They can construct new predictors from sequences of labeled examples $(x, f(x))$ presented in the input without further parameter updates. We investigate the hypothesis that transformer-based... | Dale Schuurmans, Denny Zhou, Ekin Akyürek, Jacob Andreas, Tengyu Ma |  |
| 452 |  |  [Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning](https://openreview.net/forum?id=Uuf2q9TfXGA) |  | 0 | We formally study how \emph{ensemble} of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using \emph{knowledge distillation}. We consider the challenging case where the ensemble is simply an average of the outputs of... | Yuanzhi Li, Zeyuan AllenZhu |  |
| 453 |  |  [When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?](https://openreview.net/forum?id=KRLUvxh8uaX) |  | 0 | Despite the success of large vision and language models (VLMs) in many downstream applications, it is unclear how well they encode the compositional relationships between objects and attributes. Here, we create the Attribution, Relation, and Order (ARO) benchmark to systematically evaluate the... | Dan Jurafsky, Federico Bianchi, James Zou, Mert Yüksekgönül, Pratyusha Kalluri |  |
| 454 |  |  [Confidence-Conditioned Value Functions for Offline Reinforcement Learning](https://openreview.net/forum?id=Zeb5mTuqT5) |  | 0 | Offline reinforcement learning (RL) promises the ability to learn effective policies solely using existing, static datasets, without any costly online interaction. To do so, offline RL methods must handle distributional shift between the dataset and the learned policy. The most common approach is... | Aviral Kumar, Joey Hong, Sergey Levine |  |
| 455 |  |  [On the Sensitivity of Reward Inference to Misspecified Human Models](https://openreview.net/forum?id=hJqGbUpDGV) |  | 0 | Inferring reward functions from human behavior is at the center of value alignment – aligning AI objectives with what we, humans, actually want. But doing so relies on models of how humans behave given their objectives. After decades of research in cognitive science, neuroscience, and behavioral... | Anca D. Dragan, Joey Hong, Kush Bhatia |  |
| 456 |  |  [Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection](https://openreview.net/forum?id=H3HcEJA2Um) |  | 0 | While recent camera-only 3D detection methods leverage multiple timesteps, the limited history they use significantly hampers the extent to which temporal fusion can improve object perception. Observing that existing works' fusion of multi-frame images are instances of temporal stereo matching, we... | Chenfeng Xu, Jinhyung Park, Kris M. Kitani, Kurt Keutzer, Masayoshi Tomizuka, Shijia Yang, Wei Zhan |  |
| 457 |  |  [Dichotomy of Control: Separating What You Can Control from What You Cannot](https://openreview.net/forum?id=DEGjDDV22pI) |  | 0 | Future- or return-conditioned supervised learning is an emerging paradigm for offline reinforcement learning (RL), in which the future outcome (i.e., return) associated with a sequence of actions in an offline dataset is used as input to a policy trained to imitate those same actions. While... | Dale Schuurmans, Ofir Nachum, Pieter Abbeel, Sherry Yang |  |
| 458 |  |  [Learning where and when to reason in neuro-symbolic inference](https://openreview.net/forum?id=en9V5F8PR-) |  | 0 | The integration of hard constraints on neural network outputs is a very desirable capability. This allows to instill trust in AI by guaranteeing the sanity of that neural network predictions with respect to domain knowledge. Recently, this topic has received a lot of attention. However, all the... | Cristina Cornelio, Jan Stuehmer, Shell Xu Hu, Timothy M. Hospedales |  |
| 459 |  |  [On the duality between contrastive and non-contrastive self-supervised learning](https://openreview.net/forum?id=kDEL91Dufpa) |  | 0 | Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new... | Adrien Bardes, Laurent Najman, Quentin Garrido, Yann LeCun, Yubei Chen |  |
| 460 |  |  [DreamFusion: Text-to-3D using 2D Diffusion](https://openreview.net/forum?id=FjNys5c7VyY) |  | 0 | Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D or multiview data and efficient architectures for denoising 3D data, neither of which... | Ajay Jain, Ben Mildenhall, Ben Poole, Jonathan T. Barron |  |
| 461 |  |  [Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions](https://openreview.net/forum?id=zyLVMgsZ0U_) |  | 0 | We provide theoretical convergence guarantees for score-based generative models (SGMs) such as denoising diffusion probabilistic models (DDPMs), which constitute the backbone of large-scale real-world generative models such as DALL$\cdot$E 2. Our main result is that, assuming accurate score... | Adil Salim, Anru Zhang, Jerry Li, Sinho Chewi, Sitan Chen, Yuanzhi Li |  |
| 462 |  |  [Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching](https://openreview.net/forum?id=88nT0j5jAn) |  | 0 | Dense prediction tasks are a fundamental class of problems in computer vision. As supervised methods suffer from high pixel-wise labeling cost, a few-shot learning solution that can learn any dense task from a few labeled images is desired. Yet, current few-shot learning methods target a restricted... | Chong Luo, Donggyun Kim, Jinwoo Kim, Seongwoong Cho, Seunghoon Hong |  |
| 463 |  |  [Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach](https://openreview.net/forum?id=dLAYGdKTi2) |  | 0 | Many machine learning problems today have multiple objective functions. They appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are... | Han Shen, Heshan Devaka Fernando, Keerthiram Murugesan, Miao Liu, Subhajit Chaudhury, Tianyi Chen |  |
| 464 |  |  [ReAct: Synergizing Reasoning and Acting in Language Models](https://openreview.net/forum?id=WE_vluYUL-X) |  | 0 | While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate... | Dian Yu, Izhak Shafran, Jeffrey Zhao, Karthik R. Narasimhan, Nan Du, Shunyu Yao, Yuan Cao |  |
| 465 |  |  [Do We Really Need Complicated Model Architectures For Temporal Networks?](https://openreview.net/forum?id=ayPPc0SyLv1) |  | 0 | Recurrent neural network (RNN) and self-attention mechanism (SAM) are the de facto methods to extract spatial-temporal information for temporal graph learning. Interestingly, we found that although both RNN and SAM could lead to a good performance, in practice neither of them is always necessary.... | Baichuan Yuan, Hanghang Tong, Hao Wu, Jian Kang, Mehrdad Mahdavi, Si Zhang, Weilin Cong, Xin Zhou |  |
| 466 |  |  [Is Conditional Generative Modeling all you need for Decision Making?](https://openreview.net/forum?id=sP1fo2K9DFG) |  | 0 | Recent improvements in conditional generative modeling have made it possible to generate high-quality images from language descriptions alone. We investigate whether these methods can directly address the problem of sequential decision-making. We view decision-making not through the lens of... | Abhi Gupta, Anurag Ajay, Joshua B. Tenenbaum, Pulkit Agrawal, Tommi S. Jaakkola, Yilun Du |  |
| 467 |  |  [The Lie Derivative for Measuring Learned Equivariance](https://openreview.net/forum?id=JL7Va5Vy15J) |  | 0 | Equivariance guarantees that a model's predictions capture key symmetries in data. When an image is translated or rotated, an equivariant model's representation of that image will translate or rotate accordingly. The success of convolutional neural networks has historically been tied to translation... | Andrew Gordon Wilson, Marc Anton Finzi, Micah Goldblum, Nate Gruver |  |
| 468 |  |  [Agree to Disagree: Diversity through Disagreement for Better Transferability](https://openreview.net/forum?id=K7CbYQbyYhY) |  | 0 | Gradient-based learning algorithms have an implicit \emph{simplicity bias} which in effect can limit the diversity of predictors being sampled by the learning procedure. This behavior can hinder the transferability of trained models by (i) favoring the learning of simpler but spurious features ---... | François Fleuret, Martin Jaggi, Matteo Pagliardini, Sai Praneeth Karimireddy |  |
| 469 |  |  [Efficient Conditionally Invariant Representation Learning](https://openreview.net/forum?id=dJruFeSRym1) |  | 0 | We introduce the Conditional Independence Regression CovariancE (CIRCE), a measure of conditional independence for multivariate continuous-valued variables. CIRCE applies as a regularizer in settings where we wish to learn neural features $\varphi(X)$ of data $X$ to estimate a target $Y$, while... | Arthur Gretton, Danica J. Sutherland, Namrata Deka, Roman Pogodin, Victor Veitch, Yazhe Li |  |
| 470 |  |  [Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness](https://openreview.net/forum?id=SMYdcXjJh1q) |  | 0 | While some state-of-the-art artificial neural network systems in computer vision are strikingly accurate models of the corresponding primate visual processing, there are still many discrepancies between these models and the behavior of primates on object recognition tasks. Many current models... | David Daniel Cox, James J. DiCarlo, Joel Dapello, Kohitij Kar, Martin Schrimpf, Michael Ferguson, Robert Baldwin Geary |  |
| 471 |  |  [Transformers Learn Shortcuts to Automata](https://openreview.net/forum?id=De4FYqjFueZ) |  | 0 | Algorithmic reasoning requires capabilities which are most naturally understood through recurrent models of computation, like the Turing machine. However, Transformer models, while lacking recurrence, are able to perform such reasoning using far fewer layers than the number of reasoning steps. This... | Akshay Krishnamurthy, Bingbin Liu, Cyril Zhang, Jordan T. Ash, Surbhi Goel |  |
| 472 |  |  [In-context Reinforcement Learning with Algorithm Distillation](https://openreview.net/forum?id=hy0a5MMPUv) |  | 0 | We propose Algorithm Distillation (AD), a method for distilling reinforcement learning (RL) algorithms into neural networks by modeling their training histories with a causal sequence model. Algorithm Distillation treats learning to reinforcement learn as an across-episode sequential prediction... | Angelos Filos, DJ Strouse, Emilio Parisotto, Ethan Brooks, Himanshu Sahni, Junhyuk Oh, Luyu Wang, Maxime Gazeau, Michael Laskin, Richie Steigerwald, Satinder Singh, Stephen Spencer, Steven Stenberg Hansen, Volodymyr Mnih |  |
| 473 |  |  [Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning](https://openreview.net/forum?id=3Pf3Wg6o-A4) |  | 0 | Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 46 tasks that probe different aspects of... | Antonia Creswell, Irina Higgins, Murray Shanahan |  |
| 474 |  |  [Compressing multidimensional weather and climate data into neural networks](https://openreview.net/forum?id=Y5SEe3dfniJ) |  | 0 | Weather and climate simulations produce petabytes of high-resolution data that are later analyzed by researchers in order to understand climate change or severe weather. We propose a new method of compressing this multidimensional weather and climate data: a coordinate-based neural network is... | Langwen Huang, Torsten Hoefler |  |
| 475 |  |  [Confidential-PROFITT: Confidential PROof of FaIr Training of Trees](https://openreview.net/forum?id=iIfDQVyuFD) |  | 0 | Post hoc auditing of model fairness suffers from potential drawbacks: (1) auditing may be highly sensitive to the test samples chosen; (2) the model and/or its training data may need to be shared with an auditor thereby breaking confidentiality. We address these issues by instead providing a... | Adrian Weller, Ali Shahin Shamsabadi, Natalie Dullerud, Nicholas Franzese, Nicolas Papernot, Sierra Calanda Wyllie, Sébastien Gambs, Xiao Wang |  |
| 476 |  |  [Near-optimal Coresets for Robust Clustering](https://openreview.net/forum?id=Nc1ZkRW8Vde) |  | 0 | We consider robust clustering problems in $\mathbb{R}^d$, specifically $k$-clustering problems (e.g., $k$-Median and $k$-Means) with $m$ \emph{outliers}, where the cost for a given center set $C \subset \mathbb{R}^d$ aggregates the distances from $C$ to all but the furthest $m$ data points, instead... | Jianing Lou, Lingxiao Huang, Shaofeng H.C. Jiang, Xuan Wu |  |
| 477 |  |  [Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives](https://openreview.net/forum?id=0Ij9_q567Ma) |  | 0 | Motivated by various practical applications, we propose a novel and general formulation of targeted multi-objective hyperparameter optimization. Our formulation allows a clear specification of an automatable optimization goal using lexicographic preference over multiple objectives. We then propose... | Chi Wang, Feiran Jia, Qingyun Wu, Shaokun Zhang |  |
| 478 |  |  [Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning](https://openreview.net/forum?id=F61FwJTZhb) |  | 0 | No-press Diplomacy is a complex strategy game involving both cooperation and competition that has served as a benchmark for multi-agent AI research. While self-play reinforcement learning has resulted in numerous successes in purely adversarial games like chess, Go, and poker, self-play alone is... | Adam Lerer, Alexander H. Miller, Anton Bakhtin, Athul Paul Jacob, David J. Wu, Gabriele Farina, Jonathan Gray, Noam Brown |  |
| 479 |  |  [Efficient Attention via Control Variates](https://openreview.net/forum?id=G-uNfHKrj46) |  | 0 | Random-feature-based attention (RFA) is an efficient approximation of softmax attention with linear runtime and space complexity. However, the approximation gap between RFA and conventional softmax attention is not well studied. Built upon previous progress of RFA, we characterize this gap through... | Chong Wang, Jianbo Yuan, Lin Zheng, Lingpeng Kong |  |
| 480 |  |  [SAM as an Optimal Relaxation of Bayes](https://openreview.net/forum?id=k4fevFqSQcX) |  | 0 | Sharpness-aware minimization (SAM) and related adversarial deep-learning methods can drastically improve generalization, but their underlying mechanisms are not yet fully understood. Here, we establish SAM as a relaxation of the Bayes objective where the expected negative-loss is replaced by the... | Mohammad Emtiyaz Khan, Thomas Möllenhoff |  |
| 481 |  |  [Learning on Large-scale Text-attributed Graphs via Variational Inference](https://openreview.net/forum?id=q0nmYciuuZN) |  | 0 | This paper studies learning on text-attributed graphs (TAGs), where each node is associated with a text description. An ideal solution for such a problem would be integrating both the text and graph structure information with large language models and graph neural networks (GNNs). However, the... | Chaozhuo Li, Hao Yan, Jian Tang, Jianan Zhao, Meng Qu, Qian Liu, Rui Li, Xing Xie |  |
| 482 |  |  [Extreme Q-Learning: MaxEnt RL without Entropy](https://openreview.net/forum?id=SJ0Lde3tRL) |  | 0 | Modern Deep Reinforcement Learning (RL) algorithms require estimates of the maximal Q-value, which are difficult to compute in continuous domains with an infinite number of possible actions. In this work, we introduce a new update rule for online and offline RL which directly models the maximal... | Divyansh Garg, Joey Hejna, Matthieu Geist, Stefano Ermon |  |
| 483 |  |  [Efficiently Computing Nash Equilibria in Adversarial Team Markov Games](https://openreview.net/forum?id=mjzm6btqgV) |  | 0 | Computing Nash equilibrium policies is a central problem in multi-agent reinforcement learning that has received extensive attention both in theory and in practice. However, in light of computational intractability barriers in general-sum games, provable guarantees have been thus far either limited... | Emmanouil V. VlatakisGkaragkounis, Fivos Kalogiannis, Ioannis Anagnostides, Ioannis Panageas, Stelios Andrew Stavroulakis, Vaggos Chatziafratis |  |
| 484 |  |  [Simplified State Space Layers for Sequence Modeling](https://openreview.net/forum?id=Ai8Hw3AXqks) |  | 0 | Models using structured state space sequence (S4) layers have achieved state-of-the-art performance on long-range sequence modeling tasks. An S4 layer combines linear state space models (SSMs), the HiPPO framework, and deep learning to achieve high performance. We build on the design of the S4... | Andrew Warrington, Jimmy T. H. Smith, Scott W. Linderman |  |
| 485 |  |  [Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics](https://openreview.net/forum?id=vmjctNUSWI) |  | 0 | A common assumption when training embodied agents is that the impact of taking an action is stable; for instance, executing the \`\`move ahead'' action will always move the agent forward by a fixed distance, perhaps with some small amount of actuator-induced noise. This assumption is limiting; an... | Ali Farhadi, KuoHao Zeng, Luca Weihs, Roozbeh Mottaghi |  |
| 486 |  |  [SimPer: Simple Self-Supervised Learning of Periodic Targets](https://openreview.net/forum?id=EKpMeEV0hOo) |  | 0 | From human physiology to environmental evolution, important processes in nature often exhibit meaningful and strong periodic or quasi-periodic changes. Due to their inherent label scarcity, learning useful representations for periodic tasks with limited or no supervision is of great benefit. Yet,... | Daniel McDuff, Dina Katabi, Jiang Wu, MingZher Poh, Silviu Borac, Xin Liu, Yuzhe Yang |  |
| 487 |  |  [PaLI: A Jointly-Scaled Multilingual Language-Image Model](https://openreview.net/forum?id=mWVoBz4W0u) |  | 0 | Effective scaling and a flexible task interface enable large language models to excel at many tasks. We present PaLI, a model that extends this approach to the joint modeling of language and vision. PaLI generates text based on visual and textual inputs, and with this interface performs many... | A. J. Piergiovanni, Adam Grycner, Alexander Kolesnikov, Ashish V. Thapliyal, Basil Mustafa, Daniel Salz, Gaurav Mishra, Hassan Akbari, James Bradbury, Joan Puigcerver, Keran Rong, Linting Xue, Lucas Beyer, Nan Ding, Piotr Padlewski, Sebastian Goodman, Soravit Changpinyo, Weicheng Kuo, Xi Chen, Xiao Wang |  |
| 488 |  |  [Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier](https://openreview.net/forum?id=OpC-9aBBVJe) |  | 0 | Increasing the replay ratio, the number of updates of an agent's parameters per environment interaction, is an appealing strategy for improving the sample efficiency of deep reinforcement learning algorithms. In this work, we show that fully or partially resetting the parameters of deep... | Aaron C. Courville, Evgenii Nikishin, Marc G. Bellemare, Max Schwarzer, Pierluca D'Oro, PierreLuc Bacon |  |
| 489 |  |  [Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness](https://openreview.net/forum?id=Wc5bmZZU9cy) |  | 0 | Neural text-to-SQL models have achieved remarkable performance in translating natural language questions into SQL queries. However, recent studies reveal that text-to-SQL models are vulnerable to task-specific perturbations. Previous curated robustness test sets usually focus on individual... | Alexander Hanbo Li, Bing Xiang, Henghui Zhu, Jiarong Jiang, Joseph Lilien, Jun Wang, Lin Pan, Mingwen Dong, Patrick Ng, Sheng Zhang, Shuaichen Chang, Steve Ash, Vittorio Castelli, William Yang Wang, Wuwei Lan, Zhiguo Wang |  |
| 490 |  |  [Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks](https://openreview.net/forum?id=sWOsRj4nT1n) |  | 0 | Temporal domain generalization is a promising yet extremely challenging area where the goal is to learn models under temporally changing data distributions and generalize to unseen data distributions following the trends of the change. The advancement of this area is challenged by: 1)... | Chen Ling, Guangji Bai, Liang Zhao |  |
| 491 |  |  [Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs](https://openreview.net/forum?id=SMa9EAovKMC) |  | 0 | The formalization of existing mathematical proofs is a notoriously difficult process. Despite decades of research on automation and proof assistants, writing formal proofs remains arduous and only accessible to a few experts. While previous studies to automate formalization focused on powerful... | Albert Qiaochu Jiang, Guillaume Lample, Jiacheng Liu, Jin Peng Zhou, Mateja Jamnik, Sean Welleck, Timothée Lacroix, Wenda Li, Yuhuai Wu |  |
| 492 |  |  [Revisiting Pruning at Initialization Through the Lens of Ramanujan Graph](https://openreview.net/forum?id=uVcDssQff_) |  | 0 | Pruning neural networks at initialization (PaI) has received an upsurge of interest due to its end-to-end saving potential. PaI is able to find sparse subnetworks at initialization that can achieve comparable performance to the full networks. These methods can surpass the trivial baseline of random... | Duc N. M. Hoang, Radu Marculescu, Shiwei Liu, Zhangyang Wang |  |
| 493 |  |  [Embedding Fourier for Ultra-High-Definition Low-Light Image Enhancement](https://openreview.net/forum?id=5N0wtJZ89r9) |  | 0 | Ultra-High-Definition (UHD) photo has gradually become the standard configuration in advanced imaging devices. The new standard unveils many issues in existing approaches for low-light image enhancement (LLIE), especially in dealing with the intricate issue of joint luminance enhancement and noise... | Chen Change Loy, Chongyi Li, ChunLe Guo, Man Zhou, Ruicheng Feng, Shangchen Zhou, Zhexin Liang |  |
| 494 |  |  [A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification](https://openreview.net/forum?id=YnkGMIh0gvX) |  | 0 | Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by... | Carsten T. Lüth, Lukas Klein, Paul F. Jaeger, Till J. Bungert |  |
| 495 |  |  [Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search](https://openreview.net/forum?id=7JsGYvjE88d) |  | 0 | Complex reasoning problems contain states that vary in the computational cost required to determine the right action plan. To take advantage of this property, we propose Adaptive Subgoal Search (AdaSubS), a search method that adaptively adjusts the planning horizon. To this end, AdaSubS generates... | Damian Stachura, Konrad Czechowski, Lukasz Kucinski, Michal Tyrolski, Michal Zawalski, Piotr Milos, Piotr Piekos, Tomasz Odrzygózdz, Yuhuai Wu |  |
| 496 |  |  [Towards Open Temporal Graph Neural Networks](https://openreview.net/forum?id=N9Pk5iSCzAn) |  | 0 | Graph neural networks (GNNs) for temporal graphs have recently attracted increasing attentions, where a common assumption is that the class set for nodes is closed. However, in real-world scenarios, it often faces the open set problem with the dynamically increased class set as the time passes by.... | Changsheng Li, Jun Zhou, Kaituo Feng, Xiaolu Zhang |  |
| 497 |  |  [Relative representations enable zero-shot latent space communication](https://openreview.net/forum?id=SrC-nwieGJ) |  | 0 | Neural networks embed the geometric structure of a data manifold lying in a high-dimensional space into latent representations. Ideally, the distribution of the data points in the latent space should depend only on the task, the data, the loss, and other architecture-specific constraints. However,... | Antonio Norelli, Emanuele Rodolà, Francesco Locatello, Luca Moschella, Marco Fumero, Valentino Maiorca |  |
| 498 |  |  [Language Modelling with Pixels](https://openreview.net/forum?id=FkSp8VW8RjH) |  | 0 | Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages. Tackling this bottleneck results in a trade-off between what can be represented in the embedding matrix and computational issues in the output... | Desmond Elliott, Elizabeth Salesky, Emanuele Bugliarello, Jonas F. Lotz, Miryam de Lhoneux, Phillip Rust |  |
| 499 |  |  [Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation](https://openreview.net/forum?id=M95oDwJXayG) |  | 0 | We study the problem of choosing algorithm hyper-parameters in unsupervised domain adaptation, i.e., with labeled data in a source domain and unlabeled data in a target domain, drawn from a different input distribution. We follow the strategy to compute several models using different... | Andrea Huber, Bernhard Alois Moser, Hamid Eghbalzadeh, Hoan Duc Nguyen, MariusConstantin Dinu, Markus Holzleitner, Maximilian Beck, Sepp Hochreiter, Sergei V. Pereverzyev, Werner Zellinger |  |
| 500 |  |  [Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search](https://openreview.net/forum?id=ZTK3SefE8_Z) |  | 0 | Nonlinear dynamics is ubiquitous in nature and commonly seen in various science and engineering disciplines. Distilling analytical expressions that govern nonlinear dynamics from limited data remains vital but challenging. To tackle this fundamental issue, we propose a novel Symbolic Physics... | Fangzheng Sun, Hao Sun, JianXun Wang, Yang Liu |  |
| 501 |  |  [Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only](https://openreview.net/forum?id=rFQfjDC9Mt) |  | 0 | Multi-label models have been widely used in various applications including image annotation and object detection. The fly in the ointment is its inherent vulnerability to backdoor attacks due to the adoption of deep learning techniques. However, all existing backdoor attacks exclusively require to... | Guowen Xu, Jiwei Li, Kangjie Chen, Tianwei Zhang, Xiaoxuan Lou |  |
| 502 |  |  [Graph Neural Networks for Link Prediction with Subgraph Sketching](https://openreview.net/forum?id=m1oqEOAozQU) |  | 0 | Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those... | Benjamin Paul Chamberlain, Emanuele Rossi, Fabrizio Frasca, Max Hansmire, Michael M. Bronstein, Nils Yannick Hammerla, Sergey Shirobokov, Thomas Markovich |  |
| 503 |  |  [Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction](https://openreview.net/forum?id=_2bDpAtr7PI) |  | 0 | Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over... | David Klee, Ondrej Biza, Robert Platt, Robin Walters |  |
| 504 |  |  [MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting](https://openreview.net/forum?id=zt53IDUR1U) |  | 0 | Recently, Transformer-based methods have achieved surprising performance in the field of long-term series forecasting, but the attention mechanism for computing global correlations entails high complexity. And they do not allow for targeted modeling of local features as CNN structures do. To solve... | Feihu Huang, Huiqiang Wang, Jian Peng, Jince Wang, Junhui Chen, Yifei Xiao |  |
| 505 |  |  [Personalized Federated Learning with Feature Alignment and Classifier Collaboration](https://openreview.net/forum?id=SXZr8aDKia) |  | 0 | Data heterogeneity is one of the most challenging issues in federated learning, which motivates a variety of approaches to learn personalized models for participating clients. One such approach in deep neural networks based tasks is employing a shared feature representation and learning a... | Jian Xu, ShaoLun Huang, Xinyi Tong |  |
| 506 |  |  [From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data](https://openreview.net/forum?id=c7rM7F7jQjN) |  | 0 | While large-scale sequence modelling from offline data has led to impressive performance gains in natural language generation and image generation, directly translating such ideas to robotics has been challenging. One critical reason for this is that uncurated robot demonstration data, i.e. play... | Lerrel Pinto, Nur Muhammad (Mahi) Shafiullah, Yibin Wang, Zichen Jeff Cui |  |
| 507 |  |  [Visual Classification via Description from Large Language Models](https://openreview.net/forum?id=jlAjNL8z5cs) |  | 0 | Vision-language models such as CLIP have shown promising performance on a variety of recognition tasks using the standard zero-shot classification procedure -- computing similarity between the query image and the embedded words for each category. By only using the category name, they neglect to... | Carl Vondrick, Sachit Menon |  |
| 508 |  |  [The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation](https://openreview.net/forum?id=w0QXrZ3N-s) |  | 0 | Crossmodal knowledge distillation (KD) extends traditional knowledge distillation to the area of multimodal learning and demonstrates great success in various applications. To achieve knowledge transfer across modalities, a pretrained network from one modality is adopted as the teacher to provide... | Hang Zhao, Sucheng Ren, Zhengqi Gao, Zihui Xue |  |
| 509 |  |  [Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve](https://openreview.net/forum?id=OJ8aSjCaMNK) |  | 0 | Variational autoencoders (VAEs) are powerful tools for learning latent representations of data used in a wide range of applications. In practice, VAEs usually require multiple training rounds to choose the amount of information the latent variable should retain. This trade-off between the... | Eric Wang, Jimmy Ba, Juhan Bae, Michael R. Zhang, Michael Ruan, Roger Baker Grosse, So Hasegawa |  |
| 510 |  |  [Near-optimal Policy Identification in Active Reinforcement Learning](https://openreview.net/forum?id=3OR2tbtnYC-) |  | 0 | Many real-world reinforcement learning tasks require control of complex dynamical systems that involve both costly data acquisition processes and large state spaces. In cases where the expensive transition dynamics can be readily evaluated at specified states (e.g., via a simulator), agents can... | Andreas Krause, Ian Char, Ilija Bogunovic, Jeff Schneider, Johannes Kirschner, Viraj Mehta, Willie Neiswanger, Xiang Li |  |
| 511 |  |  [Conditional Antibody Design as 3D Equivariant Graph Translation](https://openreview.net/forum?id=LFHFQbjxIiP) |  | 0 | Antibody design is valuable for therapeutic usage and biological research. Existing deep-learning-based methods encounter several key issues: 1) incomplete context for Complementarity-Determining Regions (CDRs) generation; 2) incapability of capturing the entire 3D geometry of the input structure;... | Wenbing Huang, Xiangzhe Kong, Yang Liu |  |
| 512 |  |  [Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task](https://openreview.net/forum?id=DeG07_TcZvT) |  | 0 | Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this... | Aspen K. Hopkins, David Bau, Fernanda B. Viégas, Hanspeter Pfister, Kenneth Li, Martin Wattenberg |  |
| 513 |  |  [Tailoring Language Generation Models under Total Variation Distance](https://openreview.net/forum?id=VELL0PlWfc) |  | 0 | The standard paradigm of neural language generation adopts maximum likelihood estimation (MLE) as the optimizing method. From a distributional view, MLE in fact minimizes the Kullback-Leibler divergence (KLD) between the distribution of the real data and that of the model. However, this approach... | Haozhe Ji, Minlie Huang, Pei Ke, Rongsheng Zhang, Zhipeng Hu |  |
| 514 |  |  [Transformers are Sample-Efficient World Models](https://openreview.net/forum?id=vhFu1Acb0xb) |  | 0 | Deep reinforcement learning agents are notoriously sample inefficient, which considerably limits their application to real-world problems. Recently, many model-based methods have been designed to address this issue, with learning in the imagination of a world model being one of the most prominent... | Eloi Alonso, François Fleuret, Vincent Micheli |  |
| 515 |  |  [Statistical Efficiency of Score Matching: The View from Isoperimetry](https://openreview.net/forum?id=TD7AnQjNzR6) |  | 0 | Deep generative models parametrized up to a normalizing constant (e.g. energy-based models) are difficult to train by maximizing the likelihood of the data because the likelihood and/or gradients thereof cannot be explicitly or efficiently written down. Score matching is a training method, whereby... | Alexander Heckett, Andrej Risteski, Frederic Koehler |  |
| 516 |  |  [View Synthesis with Sculpted Neural Points](https://openreview.net/forum?id=0ypGZvm0er0) |  | 0 | We address the task of view synthesis, generating novel views of a scene given a set of images as input. In many recent works such as NeRF (Mildenhall et al., 2020), the scene geometry is parameterized using neural implicit representations (i.e., MLPs). Implicit neural representations have achieved... | Jia Deng, Yiming Zuo |  |
| 517 |  |  [AutoGT: Automated Graph Transformer Architecture Search](https://openreview.net/forum?id=GcM7qfl5zY) |  | 0 | Although Transformer architectures have been successfully applied to graph data with the advent of Graph Transformer, current design of Graph Transformer still heavily relies on human labor and expertise knowledge to decide proper neural architectures and suitable graph encoding strategies at each... | Chaoyu Guan, Haoyang Li, Wenwu Zhu, Xin Wang, Ziwei Zhang, Zizhao Zhang |  |
| 518 |  |  [Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting](https://openreview.net/forum?id=vSVLM2j9eie) |  | 0 | Recently many deep models have been proposed for multivariate time series (MTS) forecasting. In particular, Transformer-based models have shown great potential because they can capture long-term dependency. However, existing Transformer-based models mainly focus on modeling the temporal dependency... | Junchi Yan, Yunhao Zhang |  |
| 519 |  |  [Betty: An Automatic Differentiation Library for Multilevel Optimization](https://openreview.net/forum?id=LV_MeMS38Q9) |  | 0 | Gradient-based multilevel optimization (MLO) has gained attention as a framework for studying numerous problems, ranging from hyperparameter optimization and meta-learning to neural architecture search and reinforcement learning. However, gradients in MLO, which are obtained by composing... | Eric P. Xing, Pengtao Xie, Sang Keun Choe, Willie Neiswanger |  |
| 520 |  |  [Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization](https://openreview.net/forum?id=ueYYgo2pSSU) |  | 0 | Most offline reinforcement learning (RL) methods suffer from the trade-off between improving the policy to surpass the behavior policy and constraining the policy to limit the deviation from the behavior policy as computing $Q$-values using out-of-distribution (OOD) actions will suffer from errors... | Haoran Xu, Jianxiong Li, Li Jiang, Wai Kin Victor Chan, Xianyuan Zhan, Zhaoran Wang, Zhuoran Yang |  |
| 521 |  |  [Win: Weight-Decay-Integrated Nesterov Acceleration for Adaptive Gradient Algorithms](https://openreview.net/forum?id=CPdc77SQfQ5) |  | 0 | Training deep networks on large-scale datasets is computationally challenging. In this work, we explore the problem of \`\`\textit{how to accelerate adaptive gradient algorithms in a general manner}", and aim to provide practical efficiency-boosting insights. To this end, we propose an effective... | Pan Zhou, Shuicheng Yan, Xingyu Xie |  |
| 522 |  |  [Towards Stable Test-time Adaptation in Dynamic Wild World](https://openreview.net/forum?id=g2YraF75Tj) |  | 0 | Test-time adaptation (TTA) has shown to be effective at tackling distribution shifts between training and testing data by adapting a given model on test samples. However, the online model updating of TTA may be unstable and this is often a key obstacle preventing existing TTA methods from being... | Jiaxiang Wu, Mingkui Tan, Peilin Zhao, Shuaicheng Niu, Yaofo Chen, Yifan Zhang, Zhiquan Wen |  |
| 523 |  |  [MocoSFL: enabling cross-client collaborative self-supervised learning](https://openreview.net/forum?id=2QGJXyMNoPz) |  | 0 | Existing collaborative self-supervised learning (SSL) schemes are not suitable for cross-client applications because of their expensive computation and large local data requirements. To address these issues, we propose MocoSFL, a collaborative SSL framework based on Split Federated Learning (SFL)... | Chaitali Chakrabarti, Daisuke Iso, Jingtao Li, Lingjuan Lyu, Michael Spranger |  |
| 524 |  |  [DaxBench: Benchmarking Deformable Object Manipulation with Differentiable Physics](https://openreview.net/forum?id=1NAzMofMnWl) |  | 0 | Deformable object manipulation (DOM) is a long-standing challenge in robotics and has attracted significant interest recently. This paper presents DaXBench, a differentiable simulation framework for DOM. While existing work often focuses on a specific type of deformable objects, DaXBench supports... | Cunjun Yu, David Hsu, Linfeng Li, Siwei Chen, Xiao Ma, Yiqing Xu, Zhongwen Xu |  |
| 525 |  |  [3D generation on ImageNet](https://openreview.net/forum?id=U2WjB9xxZ9q) |  | 0 | All existing 3D-from-2D generators are designed for well-curated single-category datasets, where all the objects have (approximately) the same scale, 3D location, and orientation, and the camera always points to the center of the scene. This makes them inapplicable to diverse, in-the-wild datasets... | Aliaksandr Siarohin, HsinYing Lee, Ivan Skorokhodov, Jian Ren, Peter Wonka, Sergey Tulyakov, Yinghao Xu |  |
| 526 |  |  [Rethinking the Expressive Power of GNNs via Graph Biconnectivity](https://openreview.net/forum?id=r9hNv76KoT3) |  | 0 | Designing expressive Graph Neural Networks (GNNs) is a central topic in learning graph-structured data. While numerous approaches have been proposed to improve GNNs with respect to the Weisfeiler-Lehman (WL) test, for most of them, there is still a lack of deep understanding of what additional... | Bohang Zhang, Di He, Liwei Wang, Shengjie Luo |  |
| 527 |  |  [Sparse Mixture-of-Experts are Domain Generalizable Learners](https://openreview.net/forum?id=RecZ9nB9Q4) |  | 0 | Human visual perception can easily generalize to out-of-distributed visual data, which is far beyond the capability of modern machine learning models. Domain generalization (DG) aims to close this gap, with existing DG methods mainly focusing on the loss function design. In this paper, we propose... | Bo Li, Jiawei Ren, Jingkang Yang, Jun Zhang, Tong Che, Yezhen Wang, Yifei Shen, Ziwei Liu |  |
| 528 |  |  [Token Merging: Your ViT But Faster](https://openreview.net/forum?id=JroZRaRw7Eu) |  | 0 | We introduce Token Merging (ToMe), a simple method to increase the throughput of existing ViT models without needing to train. ToMe gradually combines similar tokens in a transformer using a general and light-weight matching algorithm that is as fast as pruning while being more accurate.... | ChengYang Fu, Christoph Feichtenhofer, Daniel Bolya, Judy Hoffman, Peizhao Zhang, Xiaoliang Dai |  |
| 529 |  |  [Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection](https://openreview.net/forum?id=FeWvD0L_a4) |  | 0 | The exploration problem is one of the main challenges in deep reinforcement learning (RL). Recent promising works tried to handle the problem with population-based methods, which collect samples with diverse behaviors derived from a population of different exploratory policies. Adaptive policy... | Bin Wang, Hao Wang, Jiajun Fan, Jiangcheng Zhu, Jianye Hao, ShuTao Xia, Yuecheng Liu, Yuzheng Zhuang |  |
| 530 |  |  [Image as Set of Points](https://openreview.net/forum?id=awnvqZja69) |  | 0 | What is an image, and how to extract latent features? Convolutional Networks (ConvNets) consider an image as organized pixels in a rectangular shape and extract features via convolutional operation in a local region; Vision Transformers (ViTs) treat an image as a sequence of patches and extract... | Bin Sun, Can Qin, Chang Liu, Huan Wang, Xu Ma, Yun Fu, Yuqian Zhou |  |
| 531 |  |  [Human-Guided Fair Classification for Natural Language Processing](https://openreview.net/forum?id=N_g8TT9Cy7f) |  | 0 | Text classifiers have promising applications in high-stake tasks such as resume screening and content moderation. These classifiers must be fair and avoid discriminatory decisions by being invariant to perturbations of sensitive attributes such as gender or ethnicity. However, there is a gap... | Elliott Ash, Florian E. Dorner, Martin T. Vechev, Momchil Peychev, Naman Goel, Nikola Konstantinov |  |
| 532 |  |  [Humanly Certifying Superhuman Classifiers](https://openreview.net/forum?id=X5ZMzRYqUjB) |  | 0 | This paper addresses a key question in current machine learning research: if we believe that a model's predictions might be better than those given by human experts, how can we (humans) verify these beliefs? In some cases, this \`\`superhuman'' performance is readily demonstrated; for example by... | Chenchen Xu, Christian Walder, Qiongkai Xu |  |
| 533 |  |  [Few-Shot Domain Adaptation For End-to-End Communication](https://openreview.net/forum?id=4F1gvduDeL) |  | 0 | The problem of end-to-end learning of a communication system using an autoencoder -- consisting of an encoder, channel, and decoder modeled using neural networks -- has recently been shown to be an effective approach. A challenge faced in the practical adoption of this learning approach is that... | Dolores García, Jayaram Raghuram, Joerg Widmer, Rafael Ruiz, Somesh Jha, Suman Banerjee, Yijing Zeng |  |
| 534 |  |  [Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering](https://openreview.net/forum?id=688hNNMigVX) |  | 0 | Feature engineering is widely acknowledged to be pivotal in tabular data analysis and prediction. Automated feature engineering (AutoFE) emerged to automate this process managed by experienced data scientists and engineers conventionally. In this area, most — if not all — prior work adopted an... | Gang Chen, Haobo Wang, Junbo Zhao, Liangyu Zha, Liyao Li, Qingyi Huang, Sai Wu |  |
| 535 |  |  [Learning Group Importance using the Differentiable Hypergeometric Distribution](https://openreview.net/forum?id=75O7S_L4oY) |  | 0 | Partitioning a set of elements into subsets of a priori unknown sizes is essential in many applications. These subset sizes are rarely explicitly learned - be it the cluster sizes in clustering applications or the number of shared versus independent generative latent factors in weakly-supervised... | Alain Ryser, Julia E. Vogt, Laura Manduchi, Thomas M. Sutter |  |
| 536 |  |  [Concept-level Debugging of Part-Prototype Networks](https://openreview.net/forum?id=oiwXWPDTyNk) |  | 0 | Part-prototype Networks (ProtoPNets) are concept-based classifiers designed to achieve the same performance as black-box models without compromising transparency. ProtoPNets compute predictions based on similarity to class-specific part-prototypes learned to recognize parts of training examples,... | Andrea Bontempelli, Andrea Passerini, Fausto Giunchiglia, Katya Tentori, Stefano Teso |  |
| 537 |  |  [Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery](https://openreview.net/forum?id=6BHlZgyPOZY) |  | 0 | Deep Reinforcement Learning (RL) has emerged as a powerful paradigm for training neural policies to solve complex control tasks. However, these policies tend to be overfit to the exact specifications of the task and environment they were trained on, and thus do not perform well when conditions... | Antoine Cully, Arthur Flajolet, Bryan Lim, Félix Chalumeau, Maxime Allard, Raphaël Boige, Thomas Pierrot, Valentin Macé |  |
| 538 |  |  [Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data](https://openreview.net/forum?id=JpbLyEI5EwW) |  | 0 | The implicit biases of gradient-based optimization algorithms are conjectured to be a major factor in the success of modern deep learning. In this work, we investigate the implicit bias of gradient flow and gradient descent in two-layer fully-connected neural networks with leaky ReLU activations... | Gal Vardi, Nathan Srebro, Peter L. Bartlett, Spencer Frei, Wei Hu |  |
| 539 |  |  [Guarded Policy Optimization with Imperfect Online Demonstrations](https://openreview.net/forum?id=O5rKg7IRQIO) |  | 0 | The Teacher-Student Framework (TSF) is a reinforcement learning setting where a teacher agent guards the training of a student agent by intervening and providing online demonstrations. Assuming optimal, the teacher policy has the perfect timing and capability to intervene in the learning process of... | Bolei Zhou, Quanyi Li, Zhenghai Xue, Zhenghao Peng, Zhihan Liu |  |
| 540 |  |  [Learning with Logical Constraints but without Shortcut Satisfaction](https://openreview.net/forum?id=M2unceRvqhh) |  | 0 | Recent studies have started to explore the integration of logical knowledge into deep learning via encoding logical constraints as an additional loss function. However, existing approaches tend to vacuously satisfy logical constraints through shortcuts, failing to fully exploit the knowledge. In... | Jian Lü, Jingwei Xu, Taolue Chen, Xiaoxing Ma, Yuan Yao, Zehua Liu, Zenan Li |  |
| 541 |  |  [Certified Training: Small Boxes are All You Need](https://openreview.net/forum?id=7oFuxtJtUMH) |  | 0 | To obtain, deterministic guarantees of adversarial robustness, specialized training methods are used. We propose, SABR, a novel such certified training method, based on the key insight that propagating interval bounds for a small but carefully selected subset of the adversarial input region is... | Franziska Eckert, Marc Fischer, Mark Niklas Müller, Martin T. Vechev |  |
| 542 |  |  [Multi-Objective Online Learning](https://openreview.net/forum?id=dKkMnCWfVmm) |  | 0 | This paper presents a systematic study of multi-objective online learning. We first formulate the framework of Multi-Objective Online Convex Optimization, which encompasses a novel multi-objective regret. This regret is built upon a sequence-wise extension of the commonly used discrepancy metric... | Jiyan Jiang, Lihong Gu, Shiji Zhou, Wenpeng Zhang, Wenwu Zhu, Xiaodong Zeng |  |
| 543 |  |  [Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning](https://openreview.net/forum?id=3ULaIHxn9u7) |  | 0 | In many real-world imitation learning tasks, the demonstrator and the learner have to act under different observation spaces. This situation brings significant obstacles to existing imitation learning approaches, since most of them learn policies under homogeneous observation spaces. On the other... | Masashi Sugiyama, XinQiang Cai, YaoXiang Ding, Yuan Jiang, ZhiHua Zhou, ZiXuan Chen |  |
| 544 |  |  [A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias](https://openreview.net/forum?id=wkg_b4-IwTZ) |  | 0 | Advances in the expressivity of pretrained models have increased interest in the design of adaptation protocols which enable safe and effective transfer learning. Going beyond conventional linear probing (LP) and fine tuning (FT) strategies, protocols that can effectively control feature... | Danai Koutra, Jayaraman J. Thiagarajan, Puja Trivedi |  |
| 545 |  |  [Understanding and Adopting Rational Behavior by Bellman Score Estimation](https://openreview.net/forum?id=WzGdBqcBicl) |  | 0 | We are interested in solving a class of problems that seek to understand and adopt rational behavior from demonstrations. We may broadly classify these problems into four categories of reward identification, counterfactual analysis, behavior imitation, and behavior transfer. In this work, we make a... | Kuno Kim, Stefano Ermon |  |
| 546 |  |  [STUNT: Few-shot Tabular Learning with Self-generated Tasks from Unlabeled Tables](https://openreview.net/forum?id=_xlsjehDvlY) |  | 0 | Learning with few labeled tabular samples is often an essential requirement for industrial machine learning applications as varieties of tabular data suffer from high annotation costs or have difficulties in collecting new samples for novel tasks. Despite the utter importance, such a problem is... | Hankook Lee, Jaehyun Nam, Jihoon Tack, Jinwoo Shin, Kyungmin Lee |  |
| 547 |  |  [Ask Me Anything: A simple strategy for prompting language models](https://openreview.net/forum?id=bhUPJnS2g0X) |  | 0 | Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model... | Avanika Narayan, Christopher Ré, Ines Chami, Kush Bhatia, Laurel J. Orr, Mayee F. Chen, Neel Guha, Simran Arora |  |
| 548 |  |  [On Representing Linear Programs by Graph Neural Networks](https://openreview.net/forum?id=cP2QVK-uygd) |  | 0 | Learning to optimize is a rapidly growing area that aims to solve optimization problems or improve existing optimization algorithms using machine learning (ML). In particular, the graph neural network (GNN) is considered a suitable ML model for optimization problems whose variables and constraints... | Jialin Liu, Wotao Yin, Xinshang Wang, Ziang Chen |  |
| 549 |  |  [Scale-invariant Bayesian Neural Networks with Connectivity Tangent Kernel](https://openreview.net/forum?id=VZ5EaTI6dqa) |  | 0 | Studying the loss landscapes of neural networks is critical to identifying generalizations and avoiding overconfident predictions. Flatness, which measures the perturbation resilience of pre-trained parameters for loss values, is widely acknowledged as an essential predictor of generalization.... | Eunho Yang, KyungSu Kim, Sihwan Park, Sungyub Kim |  |
| 550 |  |  [Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform](https://openreview.net/forum?id=nN_nBVKAhhD) |  | 0 | We describe a minimalistic and interpretable method for unsupervised representation learning that does not require data augmentation, hyperparameter tuning, or other engineering designs, but nonetheless achieves performance close to the state-of-the-art (SOTA) SSL methods. Our approach leverages... | Bruno A. Olshausen, Yann LeCun, Yi Ma, Yubei Chen, Zeyu Yun |  |
| 551 |  |  [GEASS: Neural causal feature selection for high-dimensional biological data](https://openreview.net/forum?id=aKcS3xojnwY) |  | 0 | Identifying nonlinear causal relationships in high-dimensional biological data is an important task. However, current neural network based causality detection approaches for such data suffer from poor interpretability and cannot scale well to the high dimensional regime. Here we present GEASS... | Mingze Dong, Yuval Kluger |  |
| 552 |  |  [SmartFRZ: An Efficient Training Framework using Attention-Based Layer Freezing](https://openreview.net/forum?id=i9UlAr1T_xl) |  | 0 | There has been a proliferation of artificial intelligence applications, where model training is key to promising high-quality services for these applications. However, the model training process is both time-intensive and energy-intensive, inevitably affecting the user's demand for application... | Geng Yuan, Sheng Li, Xulong Tang, Yanzhi Wang, Youtao Zhang, Yue Dai |  |
| 553 |  |  [The In-Sample Softmax for Offline Reinforcement Learning](https://openreview.net/forum?id=u-RuvyDYqCM) |  | 0 | Reinforcement learning (RL) agents can leverage batches of previously collected data to extract a reasonable control policy. An emerging issue in this offline RL setting, however, is that the bootstrapping update underlying many of our methods suffers from insufficient action-coverage: standard max... | Adam White, Chenjun Xiao, Han Wang, Martha White, Yangchen Pan |  |
| 554 |  |  [Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning](https://openreview.net/forum?id=TdTGGj7fYYJ) |  | 0 | Unsupervised meta-learning aims to learn generalizable knowledge across a distribution of tasks constructed from unlabeled data. Here, the main challenge is how to construct diverse tasks for meta-learning without label information; recent works have proposed to create, e.g., pseudo-labeling via... | Hankook Lee, Huiwon Jang, Jinwoo Shin |  |
| 555 |  |  [Guiding Energy-based Models via Contrastive Latent Variables](https://openreview.net/forum?id=CZmHHj9MgkP) |  | 0 | An energy-based model (EBM) is a popular generative framework that offers both explicit density and architectural flexibility, but training them is difficult since it is often unstable and time-consuming. In recent years, various training techniques have been developed, e.g., better divergence... | Hankook Lee, Jinwoo Shin, Jongheon Jeong, Sejun Park |  |
| 556 |  |  [Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent](https://openreview.net/forum?id=ZzdBhtEH9yB) |  | 0 | It is well known that the finite step-size ($h$) in Gradient descent (GD) implicitly regularizes solutions to flatter minimas. A natural question to ask is \textit{Does the momentum parameter $\beta$ (say) play a role in implicit regularization in Heavy-ball (H.B) momentum accelerated gradient... | Avrajit Ghosh, He Lyu, Rongrong Wang, Xitong Zhang |  |
| 557 |  |  [Real-time variational method for learning neural trajectory and its dynamics](https://openreview.net/forum?id=M_MvkWgQSt) |  | 0 | Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation. This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings. However, despite the potential of real-time... | Il Memming Park, Matthew Dowling, Yuan Zhao |  |
| 558 |  |  [Energy-Inspired Self-Supervised Pretraining for Vision Models](https://openreview.net/forum?id=ZMz-sW6gCLF) |  | 0 | Motivated by the fact that forward and backward passes of a deep network naturally form symmetric mappings between input and output representations, we introduce a simple yet effective self-supervised vision model pretraining framework inspired by energy-based models (EBMs). In the proposed... | Jiang Wang, Qiang Qiu, Ze Wang, Zicheng Liu |  |
| 559 |  |  [Binding Language Models in Symbolic Languages](https://openreview.net/forum?id=lH1PV42cbF) |  | 0 | Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of... | Caiming Xiong, Chengzu Li, Dragomir Radev, Luke Zettlemoyer, Mari Ostendorf, Noah A. Smith, Peng Shi, Rahul Nadkarni, Tao Yu, Tianbao Xie, Yushi Hu, Zhoujun Cheng |  |
| 560 |  |  [Evolve Smoothly, Fit Consistently: Learning Smooth Latent Dynamics For Advection-Dominated Systems](https://openreview.net/forum?id=Z4s73sJYQM) |  | 0 | We present a data-driven, space-time continuous framework to learn surrogate models for complex physical systems described by advection-dominated partial differential equations. Those systems have slow-decaying Kolmogorov n-width that hinders standard methods, including reduced order modeling, from... | Anudhyan Boral, Fei Sha, Leonardo ZepedaNúñez, Zhong Yi Wan |  |
| 561 |  |  [BC-IRL: Learning Generalizable Reward Functions from Demonstrations](https://openreview.net/forum?id=Ovnwe_sDQW) |  | 0 | How well do reward functions learned with inverse reinforcement learning (IRL) generalize? We illustrate that state-of-the-art IRL algorithms, which maximize a maximum-entropy objective, learn rewards that overfit to the demonstrations. Such rewards struggle to provide meaningful rewards for states... | Amy Zhang, Andrew Szot, Dhruv Batra, Franziska Meier, Zsolt Kira |  |
| 562 |  |  [Phase2vec: dynamical systems embedding with a physics-informed convolutional network](https://openreview.net/forum?id=z9C5dGip90) |  | 0 | Dynamical systems are found in innumerable forms across the physical and biological sciences, yet all these systems fall naturally into equivalence classes: conservative or dissipative, stable or unstable, compressible or incompressible. Predicting these classes from data remains an essential open... | Matthew Ricci, Mor Nitzan, Noa Moriel, Zoe Piran |  |
| 563 |  |  [gDDIM: Generalized denoising diffusion implicit models](https://openreview.net/forum?id=1hKE9qjvz-) |  | 0 | Our goal is to extend the denoising diffusion implicit model (DDIM) to general diffusion models~(DMs) besides isotropic diffusions. Instead of constructing a non-Markov noising process as in the original DDIM, we examine the mechanism of DDIM from a numerical perspective. We discover that the DDIM... | Molei Tao, Qinsheng Zhang, Yongxin Chen |  |
| 564 |  |  [FedExP: Speeding Up Federated Averaging via Extrapolation](https://openreview.net/forum?id=IPrzNbddXV) |  | 0 | Federated Averaging (FedAvg) remains the most popular algorithm for Federated Learning (FL) optimization due to its simple implementation, stateless nature, and privacy guarantees combined with secure aggregation. Recent work has sought to generalize the vanilla averaging in FedAvg to a generalized... | Divyansh Jhunjhunwala, Gauri Joshi, Shiqiang Wang |  |
| 565 |  |  [Serving Graph Compression for Graph Neural Networks](https://openreview.net/forum?id=T-qVtA3pAxG) |  | 0 | Serving a GNN model online is challenging --- in many applications when testing nodes are connected to training nodes, one has to propagate information from training nodes to testing nodes to achieve the best performance, and storing the whole training set (including training graph and node... | Ankit Singh Rawat, ChoJui Hsieh, Felix X. Yu, Sanjiv Kumar, Si Si |  |
| 566 |  |  [Learning MLPs on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency](https://openreview.net/forum?id=Cs3r5KLdoj) |  | 0 | While Graph Neural Networks (GNNs) have demonstrated their efficacy in dealing with non-Euclidean structural data, they are difficult to be deployed in real applications due to the scalability constraint imposed by the multi-hop data dependency. Existing methods attempt to address this scalability... | Chuxu Zhang, Nitesh V. Chawla, Xiangliang Zhang, Yijun Tian, Zhichun Guo |  |
| 567 |  |  [Contrastive Audio-Visual Masked Autoencoder](https://openreview.net/forum?id=QPtMRyk5rb) |  | 0 | In this paper, we first extend the recent Masked Auto-Encoder (MAE) model from a single modality to audio-visual multi-modalities. Subsequently, we propose the Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE) by combining contrastive learning and masked data modeling, two major... | Alexander H. Liu, Andrew Rouditchenko, David Harwath, Hilde Kuehne, James R. Glass, Leonid Karlinsky, Yuan Gong |  |
| 568 |  |  [The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks](https://openreview.net/forum?id=IM4xp7kGI5V) |  | 0 | In this work, we explore the maximum-margin bias of quasi-homogeneous neural networks trained with gradient flow on an exponential loss and past a point of separability. We introduce the class of quasi-homogeneous models, which is expressive enough to describe nearly all neural networks with... | Atsushi Yamamura, Chao Ma, Daniel Kunin, Surya Ganguli |  |
| 569 |  |  [Optimal Transport for Offline Imitation Learning](https://openreview.net/forum?id=MhuFzFsrfvH) |  | 0 | With the advent of large datasets, offline reinforcement learning is a promising framework for learning good decision-making policies without the need to interact with the real environment. However, offline RL requires the dataset to be reward-annotated, which presents practical challenges when... | Edward Grefenstette, Marc Peter Deisenroth, Samuel Cohen, Yicheng Luo, Zhengyao Jiang |  |
| 570 |  |  [Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization](https://openreview.net/forum?id=8aHzds2uUyB) |  | 0 | We tackle the problem of aligning pre-trained large language models (LMs) with human preferences. If we view text generation as a sequential decision-making problem, reinforcement learning (RL) appears to be a natural conceptual framework. However, using RL for LM-based generation faces empirical... | Christian Bauckhage, Hannaneh Hajishirzi, Jack Hessel, Kianté Brantley, Prithviraj Ammanabrolu, Rafet Sifa, Rajkumar Ramamurthy, Yejin Choi |  |
| 571 |  |  [Learning multi-scale local conditional probability models of images](https://openreview.net/forum?id=VZX2I_VVJKH) |  | 0 | Deep neural networks can learn powerful prior probability models for images, as evidenced by the high-quality generations obtained with recent score-based diffusion methods. But the means by which these networks capture complex global statistical structure, apparently without suffering from the... | Eero P. Simoncelli, Florentin Guth, Stéphane Mallat, Zahra Kadkhodaie |  |
| 572 |  |  [Disentanglement with Biological Constraints: A Theory of Functional Cell Types](https://openreview.net/forum?id=9Z_GfhZnGH) |  | 0 | Neurons in the brain are often finely tuned for specific task variables. Moreover, such disentangled representations are highly sought after in machine learning. Here we mathematically prove that simple biological constraints on neurons, namely nonnegativity and energy efficiency in both activity... | James C. R. Whittington, Surya Ganguli, Timothy Behrens, Will Dorrell |  |
| 573 |  |  [Learning rigid dynamics with face interaction graph networks](https://openreview.net/forum?id=J7Uh781A05p) |  | 0 | Simulating rigid collisions among arbitrary shapes is notoriously difficult due to complex geometry and the strong non-linearity of the interactions. While graph neural network (GNN)-based models are effective at learning to simulate complex physical dynamics, such as fluids, cloth and articulated... | Alvaro SanchezGonzalez, Kelsey R. Allen, Peter W. Battaglia, Tatiana LopezGuevara, Tobias Pfaff, William Whitney, Yulia Rubanova |  |
| 574 |  |  [Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions](https://openreview.net/forum?id=6iDHce-0B-a) |  | 0 | We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a... | Arthur Jacot |  |
| 575 |  |  [Depth Separation with Multilayer Mean-Field Networks](https://openreview.net/forum?id=uzFQpkEzOo) |  | 0 | Depth separation—why a deeper network is more powerful than a shallow one—has been a major problem in deep learning theory. Previous results often focus on representation power, for example, Safran et al. (2019) constructed a function that is easy to approximate using a 3-layer network but not... | Mo Zhou, Rong Ge, Yunwei Ren |  |
| 576 |  |  [Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise](https://openreview.net/forum?id=i_1rbq8yFWC) |  | 0 | Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains. For example, in stock markets, the announcement of acquisitions from leading companies may have immediate effects on stock prices and increase the uncertainty of... | Cheng Zhang, Joel Jennings, Nick Pawlowski, Wenbo Gong |  |
| 577 |  |  [Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation](https://openreview.net/forum?id=VD-AYtP0dve) |  | 0 | We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of "semantic... | Lorenz Kuhn, Sebastian Farquhar, Yarin Gal |  |
| 578 |  |  [DINO as a von Mises-Fisher mixture model](https://openreview.net/forum?id=cMJo1FTwBTQ) |  | 0 | Self-distillation methods using Siamese networks are popular for self-supervised pre-training. DINO is one such method based on a cross-entropy loss between $K$-dimensional probability vectors, obtained by applying a softmax function to the dot product between representations and learnt prototypes.... | Fredrik Lindsten, Hariprasath Govindarajan, Jacob Roll, Per Sidén |  |
| 579 |  |  [Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception](https://openreview.net/forum?id=ZCStthyW-TD) |  | 0 | We propose $\textit{EventFormer}$, a computationally efficient event-based representation learning framework for asynchronously processing event camera data. EventFormer treats sparse input events as a spatially unordered set and models their spatial interactions using self-attention mechanism. An... | Saibal Mukhopadhyay, Saurabh Dash, Uday Kamal |  |
| 580 |  |  [SMART: Self-supervised Multi-task pretrAining with contRol Transformers](https://openreview.net/forum?id=9piH3Hg8QEf) |  | 0 | Self-supervised pretraining has been extensively studied in language and vision domains, where a unified model can be easily adapted to various downstream tasks by pretraining representations without explicit labels. When it comes to sequential decision-making tasks, however, it is difficult to... | Ashish Kapoor, Furong Huang, Ratnesh Madaan, Rogerio Bonatti, Shuang Ma, Yanchao Sun |  |
| 581 |  |  [TEMPERA: Test-Time Prompt Editing via Reinforcement Learning](https://openreview.net/forum?id=gSHyqBijPFO) |  | 0 | Careful prompt design is critical to the use of large language models in zero-shot or few-shot learning. As a consequence, there is a growing interest in automated methods to design optimal prompts. In this work, we propose Test-time Prompt Editing using Reinforcement learning (TEMPERA). In... | Dale Schuurmans, Denny Zhou, Joseph E. Gonzalez, Tianjun Zhang, Xuezhi Wang |  |
| 582 |  |  [Provable Defense Against Geometric Transformations](https://openreview.net/forum?id=ThXqBsRI-cY) |  | 0 | Geometric image transformations that arise in the real world, such as scaling and rotation, have been shown to easily deceive deep neural networks (DNNs). Hence, training DNNs to be certifiably robust to these perturbations is critical. However, no prior work has been able to incorporate the... | Gagandeep Singh, Jacob Laurel, Rem Yang, Sasa Misailovic |  |
| 583 |  |  [Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations](https://openreview.net/forum?id=Zb6c8A-Fghk) |  | 0 | Neural network classifiers can largely rely on simple spurious features, such as image backgrounds, to make predictions. However, even in these cases, we show that they still often learn core features associated with the desired attributes of the data, contrary to recent findings. Inspired by this... | Andrew Gordon Wilson, Pavel Izmailov, Polina Kirichenko |  |
| 584 |  |  [Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes](https://openreview.net/forum?id=hWwY_Jq0xsN) |  | 0 | Despite recent success of deep learning models in research settings, their application in sensitive domains remains limited because of their opaque decision-making processes. Taking to this challenge, people have proposed various eXplainable AI (XAI) techniques designed to calibrate trust and... | Eoin M. Kenny, Julie Shah, Mycal Tucker |  |
| 585 |  |  [The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry](https://openreview.net/forum?id=P4MUGRM4Acu) |  | 0 | Extensive work has demonstrated that equivariant neural networks can significantly improve sample efficiency and generalization by enforcing an inductive bias in the network architecture. These applications typically assume that the domain symmetry is fully described by explicit transformations of... | Dian Wang, Jung Yeon Park, Lawson L. S. Wong, Neel Sortur, Robert Platt, Robin Walters |  |
| 586 |  |  [Task-customized Masked Autoencoder via Mixture of Cluster-conditional Experts](https://openreview.net/forum?id=j8IiQUM33s) |  | 0 | Masked Autoencoder (MAE) is a prevailing self-supervised learning method that achieves promising results in model pre-training. However, when the various downstream tasks have data distributions different from the pre-training data, the semantically irrelevant pre-training information might result... | Hang Xu, James T. Kwok, Jianhua Han, Kai Chen, Lanqing Hong, Zhenguo Li, Zhili Liu |  |
| 587 |  |  [Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization](https://openreview.net/forum?id=uyqks-LILZX) |  | 0 | Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over... | Amit Sharma, Emre Kiciman, Jivat Neet Kaur |  |
| 588 |  |  [Using Language to Extend to Unseen Domains](https://openreview.net/forum?id=eR2dG8yjnQ) |  | 0 | It is expensive to collect training data for every possible domain that a vision model may encounter when deployed. We instead consider how simply $\textit{verbalizing}$ the training domain (e.g.\`\`photos of birds'') as well as domains we want to extend to but do not have data for... | Aditi Raghunathan, Anna Rohrbach, Clara Mohri, Devin Guillory, Han Zhang, Joseph E. Gonzalez, Lisa Dunlap, Trevor Darrell |  |
| 589 |  |  [Can We Find Nash Equilibria at a Linear Rate in Markov Games?](https://openreview.net/forum?id=eQzLwwGyQrb) |  | 0 | We study decentralized learning in two-player zero-sum discounted Markov games where the goal is to design a policy optimization algorithm for either agent satisfying two properties. First, the player does not need to know the policy of the opponent to update its policy. Second, when both players... | Jason D. Lee, Zhuoqing Song, Zhuoran Yang |  |
| 590 |  |  [Hebbian Deep Learning Without Feedback](https://openreview.net/forum?id=8gd4M-_Rj1) |  | 0 | Recent approximations to backpropagation (BP) have mitigated many of BP's computational inefficiencies and incompatibilities with biology, but important limitations still remain. Moreover, the approximations significantly decrease accuracy in benchmarks, suggesting that an entirely different... | Adrien Journé, Hector Garcia Rodriguez, Qinghai Guo, Timoleon Moraitis |  |
| 591 |  |  [A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation](https://openreview.net/forum?id=kt-dcBQcSA) |  | 0 | Latent manifolds provide a compact characterization of neural population activity and of shared co-variability across brain areas. Nonetheless, existing statistical tools for extracting neural manifolds face limitations in terms of interpretability of latents with respect to task variables, and can... | Cristina Savin, Dora E. Angelaki, Edoardo Balzani, JeanPaul Noel, Pedro HerreroVidal |  |
| 592 |  |  [Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics](https://openreview.net/forum?id=PvLnIaJbt9) |  | 0 | Modern machine learning research relies on relatively few carefully curated datasets. Even in these datasets, and typically in \`untidy' or raw data, practitioners are faced with significant issues of data quality and diversity which can be prohibitively labor intensive to address. Existing methods... | David Krueger, Nitarshan Rajkumar, Sara Hooker, Shoaib Ahmed Siddiqui, Tegan Maharaj |  |
| 593 |  |  [Proposal-Contrastive Pretraining for Object Detection from Fewer Data](https://openreview.net/forum?id=gm0VZ-h-hPy) |  | 0 | The use of pretrained deep neural networks represents an attractive way to achieve strong results with few data available. When specialized in dense problems such as object detection, learning local rather than global information in images has proven to be more efficient. However, for unsupervised... | Amaury Habrard, Angélique Loesch, Quentin Bouniot, Romaric Audigier |  |
| 594 |  |  [ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations](https://openreview.net/forum?id=HXz7Vcm3VgM) |  | 0 | Deep learning vision systems are widely deployed across applications where reliability is critical. However, even today's best models can fail to recognize an object when its pose, lighting, or background varies. While existing benchmarks surface examples challenging for models, they do not explain... | Badr Youbi Idrissi, Caner Hazirbas, David LopezPaz, Diane Bouchacourt, Ivan Evtimov, Mark Ibrahim, Michal Drozdzal, Nicolas Ballas, Pascal Vincent, Randall Balestriero |  |
| 595 |  |  [Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries](https://openreview.net/forum?id=b7SBTEBFnC) |  | 0 | As industrial applications are increasingly automated by machine learning models, enforcing personal data ownership and intellectual property rights requires tracing training data back to their rightful owners. Membership inference algorithms approach this problem by using statistical techniques to... | Arpit Bansal, Eitan Borgnia, Hamid Kazemi, Jonas Geiping, Micah Goldblum, Tom Goldstein, Yuxin Wen |  |
| 596 |  |  [Choreographer: Learning and Adapting Skills in Imagination](https://openreview.net/forum?id=PhkWyijGi5b) |  | 0 | Unsupervised skill learning aims to learn a rich repertoire of behaviors without external supervision, providing artificial agents with the ability to control and influence the environment. However, without appropriate knowledge and exploration, skills may provide control only over a restricted... | Alexandre Lacoste, Bart Dhoedt, Pietro Mazzaglia, Sai Rajeswar, Tim Verbelen |  |
| 597 |  |  [Learning About Progress From Experts](https://openreview.net/forum?id=sKc6fgce1zs) |  | 0 | Many important tasks involve some notion of long-term progress in multiple phases: e.g. to clean a shelf it must be cleared of items, cleaning products applied, and then the items placed back on the shelf. In this work, we explore the use of expert demonstrations in long-horizon tasks to learn a... | Ankit Anand, Bogdan Mazoure, Jake Bruce, Rob Fergus |  |
| 598 |  |  [Learning Fair Graph Representations via Automated Data Augmentations](https://openreview.net/forum?id=1_OGWcP1s9w) |  | 0 | We consider fair graph representation learning via data augmentations. While this direction has been explored previously, existing methods invariably rely on certain assumptions on the properties of fair graph data in order to design fixed strategies on data augmentations. Nevertheless, the exact... | Hongyi Ling, Na Zou, Shuiwang Ji, Youzhi Luo, Zhimeng Jiang |  |
| 599 |  |  [Emergence of Maps in the Memories of Blind Navigation Agents](https://openreview.net/forum?id=lTt4KjHSsyl) |  | 0 | Animal navigation research posits that organisms build and maintain internal spa- tial representations, or maps, of their environment. We ask if machines – specifically, artificial intelligence (AI) navigation agents – also build implicit (or ‘mental’) maps. A positive answer to this question would... | Ari S. Morcos, Dhruv Batra, Erik Wijmans, Irfan Essa, Manolis Savva, Stefan Lee |  |
| 600 |  |  [Spectral Augmentation for Self-Supervised Learning on Graphs](https://openreview.net/forum?id=DjzBCrMBJ_p) |  | 0 | Graph contrastive learning (GCL), as an emerging self-supervised learning technique on graphs, aims to learn representations via instance discrimination. Its performance heavily relies on graph augmentation to reflect invariant patterns that are robust to small perturbations; yet it still remains... | Hongning Wang, Jinghui Chen, Lu Lin |  |
| 601 |  |  [VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation](https://openreview.net/forum?id=WOquZTLCBO1) |  | 0 | We propose a novel algorithm for offline reinforcement learning called Value Iteration with Perturbed Rewards (VIPeR), which amalgamates the pessimism principle with random perturbations of the value function. Most current offline RL algorithms explicitly construct statistical confidence regions to... | Raman Arora, Thanh NguyenTang |  |
| 602 |  |  [Self-supervised learning with rotation-invariant kernels](https://openreview.net/forum?id=8uu6JStuYm) |  | 0 | We introduce a regularization loss based on kernel mean embeddings with rotation-invariant kernels on the hypersphere (also known as dot-product kernels) for self-supervised learning of image representations. Besides being fully competitive with the state of the art, our method significantly... | Elisa Riccietti, Gilles Puy, Léon Zheng, Patrick Pérez, Rémi Gribonval |  |
| 603 |  |  [Neuromechanical Autoencoders: Learning to Couple Elastic and Neural Network Nonlinearity](https://openreview.net/forum?id=QubsmJT_A0) |  | 0 | Intelligent biological systems are characterized by their embodiment in a complex environment and the intimate interplay between their nervous systems and the nonlinear mechanical properties of their bodies. This coordination, in which the dynamics of the motor system co-evolved to reduce the... | Deniz Oktay, Eder Medina, Mehran Mirramezani, Ryan P. Adams |  |
| 604 |  |  [VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training](https://openreview.net/forum?id=YJ7o2wetJ2) |  | 0 | Reward and representation learning are two long-standing challenges for learning an expanding set of robot manipulation skills from sensory observations. Given the inherent cost and scarcity of in-domain, task-specific robot data, learning from large, diverse, offline human videos has emerged as a... | Amy Zhang, Dinesh Jayaraman, Osbert Bastani, Shagun Sodhani, Vikash Kumar, Yecheng Jason Ma |  |
| 605 |  |  [Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation](https://openreview.net/forum?id=74A-FDAyiL) |  | 0 | Kernel matrices, as well as weighted graphs represented by them, are ubiquitous objects in machine learning, statistics and other related fields. The main drawback of using kernel methods (learning and inference using kernel matrices) is efficiency -- given $n$ input points, most kernel-based... | Ainesh Bakshi, Piotr Indyk, Praneeth Kacham, Samson Zhou, Sandeep Silwal |  |
| 606 |  |  [A Higher Precision Algorithm for Computing the $1$-Wasserstein Distance](https://openreview.net/forum?id=aMXD8gqsIiC) |  | 0 | We consider the problem of computing the $1$-Wasserstein distance $\mathcal{W}(\mu,\nu)$ between two $d$-dimensional discrete distributions $\mu$ and $\nu$ whose support lie within the unit hypercube. There are several algorithms that estimate $\mathcal{W}(\mu,\nu)$ within an additive error of... | Pankaj K. Agarwal, Pouyan Shirzadian, Rachita Sowle, Sharath Raghvendra |  |
| 607 |  |  [Revisiting adapters with adversarial training](https://openreview.net/forum?id=HPdxC1THU8T) |  | 0 | While adversarial training is generally used as a defense mechanism, recent works show that it can also act as a regularizer. By co-training a neural network on clean and adversarial inputs, it is possible to improve classification accuracy on the clean, non-adversarial inputs. We demonstrate that,... | Francesco Croce, Sven Gowal, SylvestreAlvise Rebuffi |  |
| 608 |  |  [UNICORN: A Unified Backdoor Trigger Inversion Framework](https://openreview.net/forum?id=Mj7K4lglGyj) |  | 0 | The backdoor attack, where the adversary uses inputs stamped with triggers (e.g., a patch) to activate pre-planted malicious behaviors, is a severe threat to Deep Neural Network (DNN) models. Trigger inversion is an effective way of identifying backdoor models and understanding embedded adversarial... | Juan Zhai, Kai Mei, Shiqing Ma, Zhenting Wang |  |
| 609 |  |  [ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion](https://openreview.net/forum?id=xkev3_np08z) |  | 0 | Knowledge graphs are inherently incomplete. Therefore substantial research has been directed toward knowledge graph completion (KGC), i.e., predicting missing triples from the information represented in the knowledge graph (KG). KG embedding models (KGEs) have yielded promising results for KGC, yet... | Aleksandar Pavlovic, Emanuel Sallinger |  |
| 610 |  |  [Localized Randomized Smoothing for Collective Robustness Certification](https://openreview.net/forum?id=-k7Lvk0GpBl) |  | 0 | Models for image segmentation, node classification and many other tasks map a single input to multiple labels. By perturbing this single shared input (e.g. the image) an adversary can manipulate several predictions (e.g. misclassify several pixels). Collective robustness certification is the task... | Aleksandar Bojchevski, Jan Schuchardt, Stephan Günnemann, Tom Wollschläger |  |
| 611 |  |  [Learning Probabilistic Topological Representations Using Discrete Morse Theory](https://openreview.net/forum?id=cXMHQD-xQas) |  | 0 | Accurate delineation of fine-scale structures is a very important yet challenging problem. Existing methods use topological information as an additional training loss, but are ultimately making pixel-wise predictions. In this paper, we propose a novel deep learning based method to learn... | Chao Chen, Dimitris Samaras, Xiaoling Hu |  |
| 612 |  |  [Model-based Causal Bayesian Optimization](https://openreview.net/forum?id=Vk-34OQ7rFo) |  | 0 | How should we intervene on an unknown structural equation model to maximize a downstream variable of interest? This setting, also known as causal Bayesian optimization (CBO), has important applications in medicine, ecology, and manufacturing. Standard Bayesian optimization algorithms fail to... | Anastasia Makarova, Andreas Krause, Scott Sussex |  |
| 613 |  |  [Training language models to summarize narratives improves brain alignment](https://openreview.net/forum?id=KzkLAE49H9b) |  | 0 | Building systems that achieve a deeper understanding of language is one of the central goals of natural language processing (NLP). Towards this goal, recent works have begun to train language models on narrative datasets which require extracting the most critical information by integrating across... | Khai Loong Aw, Mariya Toneva |  |
| 614 |  |  [Dual Algorithmic Reasoning](https://openreview.net/forum?id=hhvkdRdWt1F) |  | 0 | Neural Algorithmic Reasoning is an emerging area of machine learning which seeks to infuse algorithmic computation in neural networks, typically by training neural models to approximate steps of classical algorithms. In this context, much of the current work has focused on learning reachability and... | Danilo Numeroso, Davide Bacciu, Petar Velickovic |  |
| 615 |  |  [A Primal-Dual Framework for Transformers and Neural Networks](https://openreview.net/forum?id=U_T8-5hClV) |  | 0 | Self-attention is key to the remarkable success of transformers in sequence modeling tasks including many applications in natural language processing and computer vision. Like neural network layers, these attention mechanisms are often developed by heuristics and experience. To provide a principled... | Andrea L. Bertozzi, Nhat Ho, Richard G. Baraniuk, Stanley J. Osher, Tam Minh Nguyen, Tan Minh Nguyen |  |
| 616 |  |  [Fisher-Legendre (FishLeg) optimization of deep neural networks](https://openreview.net/forum?id=c9lAOPvQHS) |  | 0 | Incorporating second-order gradient information (curvature) into optimization can dramatically reduce the number of iterations required to train machine learning models. In natural gradient descent, such information comes from the Fisher information matrix which yields a number of desirable... | Alberto Bernacchia, Federica Freddi, Guillaume Hennequin, Jezabel R. Garcia, Maolin Li, Sattar Vakili, Stathi Fotiadis |  |
| 617 |  |  [Capturing the Motion of Every Joint: 3D Human Pose and Shape Estimation with Independent Tokens](https://openreview.net/forum?id=0Vv4H4Ch0la) |  | 0 | In this paper we present a novel method to estimate 3D human pose and shape from monocular videos. This task requires directly recovering pixel-alignment 3D human pose and body shape from monocular images or videos, which is challenging due to its inherent ambiguity. To improve precision, existing... | Gang Liu, Gang Yu, Guozhong Luo, Sen Yang, Wankou Yang, Wen Heng |  |
| 618 |  |  [Efficient recurrent architectures through activity sparsity and sparse back-propagation through time](https://openreview.net/forum?id=lJdOlWg8td) |  | 0 | Recurrent neural networks (RNNs) are well suited for solving sequence tasks in resource-constrained systems due to their expressivity and low computational requirements. However, there is still a need to bridge the gap between what RNNs are capable of in terms of efficiency and performance and... | Anand Subramoney, Christian Mayr, David Kappel, Khaleelulla Khan Nazeer, Mark Schöne |  |
| 619 |  |  [Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow](https://openreview.net/forum?id=XVjTT1nw5z) |  | 0 | We present rectified flow, a simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions $\pi_0$ and $\pi_1$, hence providing a unified solution to generative modeling and domain transfer, among various other tasks... | Chengyue Gong, Qiang Liu, Xingchao Liu |  |
| 620 |  |  [Inequality phenomenon in l∞-adversarial training, and its unrealized threats](https://openreview.net/forum?id=4t9q35BxGr) |  | 0 | The appearance of adversarial examples raises attention from both academia and industry. Along with the attack-defense arms race, adversarial training is the most effective against adversarial examples. However, we find inequality phenomena occur during the $l_{\infty}$-adversarial training, that... | Hui Xue, Ranjie Duan, Rong Zhang, Xiaojun Jia, Yao Zhu, Yuefeng Chen |  |
| 621 |  |  [Learning Diffusion Bridges on Constrained Domains](https://openreview.net/forum?id=WH1yCa0TbB) |  | 0 | Diffusion models have achieved promising results on generative learning recently. However, because diffusion processes are most naturally applied on the unconstrained Euclidean space $\mathrm{R}^d$, key challenges arise for developing diffusion based models for learning data on constrained and... | Lemeng Wu, Mao Ye, Qiang Liu, Xingchao Liu |  |
| 622 |  |  [Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations](https://openreview.net/forum?id=1_jFneF07YC) |  | 0 | In this paper, we show that recent advances in self-supervised representation learning enable unsupervised object discovery and semantic segmentation with a performance that matches the state of the field on supervised semantic segmentation 10 years ago. We propose a methodology based on... | Andrii Zadaianchuk, Francesco Locatello, Matthäus Kleindessner, Thomas Brox, Yi Zhu |  |
| 623 |  |  [Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning](https://openreview.net/forum?id=f0a_dWEYg-Td) |  | 0 | Indiscriminate data poisoning attacks are quite effective against supervised learning. However, not much is known about their impact on unsupervised contrastive learning (CL). This paper is the first to consider indiscriminate poisoning attacks of contrastive learning. We propose Contrastive... | Dina Katabi, Hao He, Kaiwen Zha |  |
| 624 |  |  [Decompositional Generation Process for Instance-Dependent Partial Label Learning](https://openreview.net/forum?id=lKOfilXucGB) |  | 0 | Partial label learning (PLL) is a typical weakly supervised learning problem, where each training example is associated with a set of candidate labels among which only one is true. Most existing PLL approaches assume that the incorrect labels in each training example are randomly picked as the... | Congyu Qiao, Ning Xu, Xin Geng |  |
| 625 |  |  [Building a Subspace of Policies for Scalable Continual Learning](https://openreview.net/forum?id=UKr0MwZM6fL) |  | 0 | The ability to continuously acquire new knowledge and skills is crucial for autonomous agents. Existing methods are typically based on either fixed-size models that struggle to learn a large number of diverse behaviors, or growing-size models that scale poorly with the number of tasks. In this... | JeanBaptiste Gaya, Laure Soulier, Lucas Caccia, Ludovic Denoyer, Roberta Raileanu, Thang Doan |  |
| 626 |  |  [Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization](https://openreview.net/forum?id=KGV-GBh8fb) |  | 0 | Recent work has achieved remarkable zero-shot performance with multi-task prompted pretraining, but little has been understood. For the first time, we show that training on a small number of key tasks beats using all the training tasks, while removing these key tasks substantially hurts... | Jian Li, Jing Zhou, Yanan Zheng, Zhilin Yang, Zongyu Lin |  |
| 627 |  |  [Solving Constrained Variational Inequalities via a First-order Interior Point-based Method](https://openreview.net/forum?id=RQY2AXFMRiu) |  | 0 | We develop an interior-point approach to solve constrained variational inequality (cVI) problems. Inspired by the efficacy of the alternating direction method of multipliers (ADMM) method in the single-objective context, we generalize ADMM to derive a first-order method for cVIs, that we refer to... | Michael I. Jordan, Tatjana Chavdarova, Tong Yang |  |
| 628 |  |  [Symmetric Pruning in Quantum Neural Networks](https://openreview.net/forum?id=K96AogLDT2K) |  | 0 | Many fundamental properties of a quantum system are captured by its Hamiltonian and ground state. Despite the significance, ground states preparation (GSP) is classically intractable for large-scale Hamiltonians. Quantum neural networks (QNNs), which exert the power of modern quantum machines, have... | Dacheng Tao, Junyu Liu, Tongliang Liu, Xinbiao Wang, Yong Luo, Yuxuan Du |  |
| 629 |  |  [Minimum Variance Unbiased N: M Sparsity for the Neural Gradients](https://openreview.net/forum?id=vuD2xEtxZcj) |  | 0 | In deep learning, fine-grained N:M sparsity reduces the data footprint and bandwidth of a General Matrix multiply (GEMM) up to x2, and doubles throughput by skipping computation of zero values. So far, it was mainly only used to prune weights to accelerate the forward and backward phases. We... | Brian Chmiel, Daniel Soudry, Itay Hubara, Ron Banner |  |
| 630 |  |  [Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models](https://openreview.net/forum?id=a2jNdqE2102) |  | 0 | Fully-parametric language models generally require a huge number of model parameters to store the necessary knowledge for solving multiple natural language tasks in zero/few-shot settings. In addition, it is hard to adapt to the evolving world knowledge without the costly model re-training. In this... | Dian Yu, Dong Yu, Hongming Zhang, Jianshu Chen, Wenlin Yao, Xiaoman Pan |  |
| 631 |  |  [Mosaic Representation Learning for Self-supervised Visual Pre-training](https://openreview.net/forum?id=JAezPMehaUu) |  | 0 | Self-supervised learning has achieved significant success in learning visual representations without the need for manual annotation. To obtain generalizable representations, a meticulously designed data augmentation strategy is one of the most crucial parts. Recently, multi-crop strategies... | Jun Yu, Mingming Gong, Tongliang Liu, Yandong Guo, Yaqian Li, Zhaoqing Wang, Ziyu Chen |  |
| 632 |  |  [FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation](https://openreview.net/forum?id=Cp-io_BoFaE) |  | 0 | Humans manipulate various kinds of fluids in their everyday life: creating latte art, scooping floating objects from water, rolling an ice cream cone, etc. Using robots to augment or replace human labors in these daily settings remain as a challenging task due to the multifaceted complexities of... | Antonio Torralba, Bo Zhu, Chuang Gan, HsiaoYu Tung, Katerina Fragkiadaki, Zhenjia Xu, Zhou Xian |  |
| 633 |  |  [Flow Matching for Generative Modeling](https://openreview.net/forum?id=PqvMRDCJT9t) |  | 0 | We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed... | Heli BenHamu, Matthew Le, Maximilian Nickel, Ricky T. Q. Chen, Yaron Lipman |  |
| 634 |  |  [PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for Geometry-Agnostic System Identification](https://openreview.net/forum?id=tVkrbkz42vc) |  | 0 | Existing approaches to system identification (estimating the physical parameters of an object) from videos assume known object geometries. This precludes their applicability in a vast majority of scenes where object geometries are complex or unknown. In this work, we aim to identify parameters... | Chenfanfu Jiang, Chuang Gan, Krishna Murthy Jatavallabhula, Ming C. Lin, Peter Yichen Chen, Xuan Li, YiLing Qiao |  |
| 635 |  |  [CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks](https://openreview.net/forum?id=iPWiwWHc1V) |  | 0 | In this paper, we propose CLIP-Dissect, a new technique to automatically describe the function of individual hidden neurons inside vision networks. CLIP-Dissect leverages recent advances in multimodal vision/language models to label internal neurons with open-ended concepts without the need for any... | TsuiWei Weng, Tuomas P. Oikarinen |  |
| 636 |  |  [Data Continuity Matters: Improving Sequence Modeling with Lipschitz Regularizer](https://openreview.net/forum?id=27uBgHuoSQ) |  | 0 | Sequence modeling is a core problem in machine learning, and various neural networks have been designed to process different types of sequence data. However, few attempts have been made to understand the inherent data property of sequence data, neglecting the critical factor that may significantly... | Dongsheng Li, Eric Qu, Xufang Luo |  |
| 637 |  |  [CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis](https://openreview.net/forum?id=iaYcJKpY2B_) |  | 0 | Program synthesis strives to generate a computer program as a solution to a given problem specification, expressed with input-output examples or natural language descriptions. The prevalence of large language models advances the state-of-the-art for program synthesis, though limited training... | Bo Pang, Caiming Xiong, Erik Nijkamp, Hiroaki Hayashi, Huan Wang, Lifu Tu, Silvio Savarese, Yingbo Zhou |  |
| 638 |  |  [ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning](https://openreview.net/forum?id=xYlJRpzZtsY) |  | 0 | Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final... | Asli Celikyilmaz, Luke Zettlemoyer, Martin Corredor, Maryam FazelZarandi, Moya Chen, Olga Golovneva, Spencer Poff |  |
| 639 |  |  [Re-calibrating Feature Attributions for Model Interpretation](https://openreview.net/forum?id=WUWJIV2Yxtp) |  | 0 | The ability to interpret machine learning models is critical for high-stakes applications. Due to its desirable theoretical properties, path integration is a widely used scheme for feature attribution to interpret model predictions. However, the methods implementing this scheme currently rely on... | Ajmal Saeed Mian, Mubarak Shah, Naveed Akhtar, Peiyu Yang, Zeyi Wen |  |
| 640 |  |  [Adversarial Diversity in Hanabi](https://openreview.net/forum?id=uLE3WF3-H_5) |  | 0 | Many Dec-POMDPs admit a qualitatively diverse set of ''reasonable'' joint policies, where reasonableness is indicated by symmetry equivariance, non-sabotaging behaviour and the graceful degradation of performance when paired with ad-hoc partners. Some of the work in diversity literature is... | Andrei Lupu, Brandon Cui, David J. Wu, Hengyuan Hu, Jakob Nicolaus Foerster, Samuel Sokota |  |
| 641 |  |  [Optimal Conservative Offline RL with General Function Approximation via Augmented Lagrangian](https://openreview.net/forum?id=ZsvWb6mJnMv) |  | 0 | Offline reinforcement learning (RL), which aims at learning good policies from historical data, has received significant attention over the past years. Much effort has focused on improving offline RL practicality by addressing the prevalent issue of partial data coverage through various forms of... | Hanlin Zhu, Jiantao Jiao, Kunhe Yang, Paria Rashidinejad, Stuart Russell |  |
| 642 |  |  [DocPrompting: Generating Code by Retrieving the Docs](https://openreview.net/forum?id=ZTCxT2t2Ru) |  | 0 | Publicly available source-code libraries are continuously growing and changing. This makes it impossible for models of code to keep current with all available APIs by simply training these models on existing code repositories. Thus, existing models inherently cannot generalize to using unseen... | Frank F. Xu, Graham Neubig, Shuyan Zhou, Uri Alon, Zhengbao Jiang |  |
| 643 |  |  [A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation](https://openreview.net/forum?id=HcUf-QwZeFh) |  | 0 | The rise of generalist large-scale models in natural language and vision has made us expect that a massive data-driven approach could achieve broader generalization in other domains such as continuous control. In this work, we explore a method for learning a single policy that manipulates various... | Hiroki Furuta, Shixiang Shane Gu, Yusuke Iwasawa, Yutaka Matsuo |  |
| 644 |  |  [Progress measures for grokking via mechanistic interpretability](https://openreview.net/forum?id=9XFSbDPmdW) |  | 0 | Neural networks often exhibit emergent behavior in which qualitatively new capabilities that arise from scaling up the number of parameters, training data, or even the number of steps. One approach to understanding emergence is to find the continuous \textit{progress measures} that underlie the... | Jacob Steinhardt, Jess Smith, Lawrence Chan, Neel Nanda, Tom Lieberum |  |
| 645 |  |  [PiFold: Toward effective and efficient protein inverse folding](https://openreview.net/forum?id=oMsN9TYwJ0j) |  | 0 | How can we design protein sequences folding into the desired structures effectively and efficiently? AI methods for structure-based protein design have attracted increasing attention in recent years; however, few methods can simultaneously improve the accuracy and efficiency due to the lack of... | Cheng Tan, Stan Z. Li, Zhangyang Gao |  |
| 646 |  |  [Planning Goals for Exploration](https://openreview.net/forum?id=6qeBuZSo7Pr) |  | 0 | Dropped into an unknown environment, what should an agent do to quickly learn about the environment and how to accomplish diverse tasks within it? We address this question within the goal-conditioned reinforcement learning paradigm, by identifying how the agent should set its goals at training time... | Dinesh Jayaraman, Edward S. Hu, Oleh Rybkin, Richard Chang |  |
| 647 |  |  [Learning Sparse Group Models Through Boolean Relaxation](https://openreview.net/forum?id=Do9MOlwWHu0) |  | 0 | We introduce an efficient algorithmic framework for learning sparse group models formulated as the natural convex relaxation of a cardinality-constrained program with Boolean variables. We provide theoretical techniques to characterize the equivalent condition when the relaxation achieves the exact... | Jianzhu Ma, Jie Zhang, Kun Huang, Xiaoqing Huang, Yijie Wang, Yuan Zhou |  |
| 648 |  |  [MeshDiffusion: Score-based Generative 3D Mesh Modeling](https://openreview.net/forum?id=0cpM2ApF9p6) |  | 0 | We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy... | Derek Nowrouzezahrai, Liam Paull, Michael J. Black, Weiyang Liu, Yao Feng, Zhen Liu |  |
| 649 |  |  [Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms](https://openreview.net/forum?id=n05upKp02kQ) |  | 0 | Partial Observability---where agents can only observe partial information about the true underlying state of the system---is ubiquitous in real-world applications of Reinforcement Learning (RL). Theoretically, learning a near-optimal policy under partial observability is known to be hard in the... | Fan Chen, Song Mei, Yu Bai |  |
| 650 |  |  [Domain Generalization via Heckman-type Selection Models](https://openreview.net/forum?id=fk7RbGibe1) |  | 0 | The domain generalization (DG) setup considers the problem where models are trained on data sampled from multiple domains and evaluated on test domains unseen during training. In this paper, we formulate DG as a sample selection problem where each domain is sampled from a common underlying... | Hyungrok Do, Hyungu Kahng, Judy Zhong |  |
| 651 |  |  [A CMDP-within-online framework for Meta-Safe Reinforcement Learning](https://openreview.net/forum?id=mbxz9Cjehr) |  | 0 | Meta-reinforcement learning has widely been used as a learning-to-learn framework to solve unseen tasks with limited experience. However, the aspect of constraint violations has not been adequately addressed in the existing works, making their application restricted in real-world settings. In this... | Bilgehan Sel, Javad Lavaei, Ming Jin, Vanshaj Khattar, Yuhao Ding |  |
| 652 |  |  [Effects of Graph Convolutions in Multi-layer Networks](https://openreview.net/forum?id=P-73JPgRs0R) |  | 0 | Graph Convolutional Networks (GCNs) are one of the most popular architectures that are used to solve classification problems accompanied by graphical information. We present a rigorous theoretical understanding of the effects of graph convolutions in multi-layer networks. We study these effects... | Aseem Baranwal, Aukosh Jagannath, Kimon Fountoulakis |  |
| 653 |  |  [Post-hoc Concept Bottleneck Models](https://openreview.net/forum?id=nA5AZ8CEyow) |  | 0 | Concept Bottleneck Models (CBMs) map the inputs onto a set of interpretable concepts (\`\`the bottleneck'') and use the concepts to make predictions. A concept bottleneck enhances interpretability since it can be investigated to understand what concepts the model "sees" in an input and which of... | James Zou, Maggie Wang, Mert Yüksekgönül |  |
| 654 |  |  [When Source-Free Domain Adaptation Meets Learning with Noisy Labels](https://openreview.net/forum?id=u2Pd6x794I) |  | 0 | Recent state-of-the-art source-free domain adaptation (SFDA) methods have focused on learning meaningful cluster structures in the feature space, which have succeeded in adapting the knowledge from source domain to unlabeled target domain without accessing the private source data. However, existing... | A. Ian McLeod, Boyu Wang, Charles Ling, Gezheng Xu, Jiaqi Li, Li Yi, Pengcheng Xu, Ruizhi Pu |  |
| 655 |  |  [Neural Networks Efficiently Learn Low-Dimensional Representations with SGD](https://openreview.net/forum?id=6taykzqcPD) |  | 0 | We study the problem of training a two-layer neural network (NN) of arbitrary width using stochastic gradient descent (SGD) where the input $\boldsymbol{x}\in \mathbb{R}^d$ is Gaussian and the target $y \in \mathbb{R}$ follows a multiple-index model, i.e.,... | Alireza Mousavi Hosseini, Ioannis Mitliagkas, Manuela Girotti, Murat A. Erdogdu, Sejun Park |  |
| 656 |  |  [Does Zero-Shot Reinforcement Learning Exist?](https://openreview.net/forum?id=MYEap_OcQI) |  | 0 | A zero-shot RL agent is an agent that can solve any RL task in a given environment, instantly with no additional planning or learning, after an initial reward-free learning phase. This marks a shift from the reward-centric RL paradigm towards controllable agents that can follow arbitrary... | Ahmed Touati, Jérémy Rapin, Yann Ollivier |  |
| 657 |  |  [Hyperbolic Deep Reinforcement Learning](https://openreview.net/forum?id=TfBHFLgv77) |  | 0 | In deep reinforcement learning (RL), useful information about the state is inherently tied to its possible future successors. Consequently, encoding features that capture the hierarchical relationships between states into the model's latent representations is often conducive to recovering effective... | Benjamin Paul Chamberlain, Edoardo Cetin, Jonathan J. Hunt, Michael M. Bronstein |  |
| 658 |  |  [Learning Controllable Adaptive Simulation for Multi-resolution Physics](https://openreview.net/forum?id=PbfgkZ2HdbE) |  | 0 | Simulating the time evolution of physical systems is pivotal in many scientific and engineering problems. An open challenge in simulating such systems is their multi-resolution dynamics: a small fraction of the system is extremely dynamic, and requires very fine-grained resolution, while a majority... | Gordon Wetzstein, Jure Leskovec, Qingqing Zhao, Tailin Wu, Takashi Maruyama |  |
| 659 |  |  [Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning](https://openreview.net/forum?id=Mpa3tRJFBb) |  | 0 | An oft-cited challenge of federated learning is the presence of heterogeneity. \emph{Data heterogeneity} refers to the fact that data from different clients may follow very different distributions. \emph{System heterogeneity} refers to client devices having different system capabilities. A... | Jianyu Wang, John Nguyen, Kshitiz Malik, Maziar Sanjabi, Michael G. Rabbat |  |
| 660 |  |  [Parametrizing Product Shape Manifolds by Composite Networks](https://openreview.net/forum?id=F_EhNDSamN) |  | 0 | Parametrizations of data manifolds in shape spaces can be computed using the rich toolbox of Riemannian geometry. This, however, often comes with high computational costs, which raises the question if one can learn an efficient neural network approximation. We show that this is indeed possible for... | Benedikt Wirth, Josua Sassen, Klaus Hildebrandt, Martin Rumpf |  |
| 661 |  |  [Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?](https://openreview.net/forum?id=zKvm1ETDOq) |  | 0 | Indiscriminate data poisoning can decrease the clean test accuracy of a deep learning model by slightly perturbing its training samples. There is a consensus that such poisons can hardly harm adversarially-trained (AT) models when the adversarial training budget is no less than the poison budget,... | Michael Backes, Rui Wen, Tianhao Wang, Yang Zhang, Zhengyu Zhao, Zhuoran Liu |  |
| 662 |  |  [Learning with Stochastic Orders](https://openreview.net/forum?id=P3PJokAqGW) |  | 0 | Learning high-dimensional distributions is often done with explicit likelihood modeling or implicit modeling via minimizing integral probability metrics (IPMs). In this paper, we expand this learning paradigm to stochastic orders, namely, the convex or Choquet order between probability measures.... | Carles DomingoEnrich, Yair Schiff, Youssef Mroueh |  |
| 663 |  |  [MEDFAIR: Benchmarking Fairness for Medical Imaging](https://openreview.net/forum?id=6ve2CkeQe5S) |  | 0 | A multitude of work has shown that machine learning-based medical diagnosis systems can be biased against certain subgroups of people. This has motivated a growing number of bias mitigation algorithms that aim to address fairness issues in machine learning. However, it is difficult to compare their... | Timothy M. Hospedales, Yongshuo Zong, Yongxin Yang |  |
| 664 |  |  [Neural Design for Genetic Perturbation Experiments](https://openreview.net/forum?id=TUBpc5rqGA) |  | 0 | The problem of how to genetically modify cells in order to maximize a certain cellular phenotype has taken center stage in drug development over the last few years (with, for example, genetically edited CAR-T, CAR-NK, and CAR-NKT cells entering cancer clinical trials). Exhausting the search space... | Aldo Pacchiano, Drausin Wulsin, Luis F. Voloch, Robert A. Barton |  |
| 665 |  |  [Efficient Discrete Multi Marginal Optimal Transport Regularization](https://openreview.net/forum?id=R98ZfMt-jE) |  | 0 | Optimal transport has emerged as a powerful tool for a variety of problems in machine learning, and it is frequently used to enforce distributional constraints. In this context, existing methods often use either a Wasserstein metric, or else they apply concurrent barycenter approaches when more... | Glenn Fung, Jeffery Kline, Ronak Mehta, Vikas Singh, Vishnu Suresh Lokhande |  |
| 666 |  |  [Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?](https://openreview.net/forum?id=xSsW2Am-ukZ) |  | 0 | As neural networks get larger and costlier, it is important to find sparse networks that require less compute and memory but can be trained to the same accuracy as the full network (i.e. matching). Iterative magnitude pruning (IMP) is a state of the art algorithm that can find such highly sparse... | Brett W. Larsen, Feng Chen, Gintare Karolina Dziugaite, Jonathan Frankle, Mansheej Paul, Surya Ganguli |  |
| 667 |  |  [Quantifying Memorization Across Neural Language Models](https://openreview.net/forum?id=TatRHT_1cK) |  | 0 | Large language models (LMs) have been shown to memorize parts of their training data, and when prompted appropriately, they will emit the memorized training data verbatim. This is undesirable because memorization violates privacy (exposing user data), degrades utility (repeated easy-to-memorize... | Chiyuan Zhang, Daphne Ippolito, Florian Tramèr, Katherine Lee, Matthew Jagielski, Nicholas Carlini |  |
| 668 |  |  [Powderworld: A Platform for Understanding Generalization via Rich Task Distributions](https://openreview.net/forum?id=AWZgXGmsbA) |  | 0 | One of the grand challenges of reinforcement learning is the ability to generalize to new tasks. However, general agents require a set of rich, diverse tasks to train on. Designing a \`foundation environment' for such tasks is tricky -- the ideal environment would support a range of emergent... | Kevin Frans, Phillip Isola |  |
| 669 |  |  [Out-of-Distribution Detection and Selective Generation for Conditional Language Models](https://openreview.net/forum?id=kJUS5nD0vPB) |  | 0 | Machine learning algorithms typically assume independent and identically distributed samples in training and at test time (IID). Much work has shown that high-performing ML classifiers can degrade significantly and provide overly-confident, wrong classification predictions, particularly for... | Balaji Lakshminarayanan, Jiaming Luo, Jie Ren, Kundan Krishna, Mohammad Saleh, Peter J. Liu, Yao Zhao |  |
| 670 |  |  [Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model](https://openreview.net/forum?id=3UHoYrglYkG) |  | 0 | The data management of large companies often prioritize more recent data, as a source of higher accuracy prediction than outdated data. For example, the Facebook data policy retains user search histories for $6$ months while the Google data retention policy states that browser information may be... | Jeremiah Blocki, Samson Zhou, Seunghoon Lee, Tamalika Mukherjee |  |
| 671 |  |  [NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning](https://openreview.net/forum?id=ApF0dmi1_9K) |  | 0 | Neural Motion Planners (NMPs) have emerged as a promising tool for solving robot navigation tasks in complex environments. However, these methods often require expert data for learning, which limits their application to scenarios where data generation is time-consuming. Recent developments have... | Ahmed H. Qureshi, Ruiqi Ni |  |
| 672 |  |  [ZiCo: Zero-shot NAS via inverse Coefficient of Variation on Gradients](https://openreview.net/forum?id=rwo-ls5GqGn) |  | 0 | Neural Architecture Search (NAS) is widely used to automatically obtain the neural network with the best performance among a large number of candidate architectures. To reduce the search time, zero-shot NAS aims at designing training-free proxies that can predict the test performance of a given... | Guihong Li, Kartikeya Bhardwaj, Radu Marculescu, Yuedong Yang |  |
| 673 |  |  [Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning](https://openreview.net/forum?id=hQ9V5QN27eS) |  | 0 | In off-policy deep reinforcement learning with continuous action spaces, exploration is often implemented by injecting action noise into the action selection process. Popular algorithms based on stochastic policies, such as SAC or MPO, inject white noise by sampling actions from uncorrelated... | Cristina Pinneri, Georg Martius, Jakob J. Hollenstein, Onno Eberhard |  |
| 674 |  |  [STaSy: Score-based Tabular data Synthesis](https://openreview.net/forum?id=1mNssCWt_v) |  | 0 | Tabular data synthesis is a long-standing research topic in machine learning. Many different methods have been proposed over the past decades, ranging from statistical methods to deep generative methods. However, it has not always been successful due to the complicated nature of real-world tabular... | Chaejeong Lee, Jayoung Kim, Noseong Park |  |
| 675 |  |  [A Unified Algebraic Perspective on Lipschitz Neural Networks](https://openreview.net/forum?id=k71IGLC8cfc) |  | 0 | Important research efforts have focused on the design and training of neural networks with a controlled Lipschitz constant. The goal is to increase and sometimes guarantee the robustness against adversarial attacks. Recent promising techniques draw inspirations from different backgrounds to design... | Aaron J. Havens, Alexandre Allauzen, Alexandre Araujo, Bin Hu, Blaise Delattre |  |
| 676 |  |  [The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks](https://openreview.net/forum?id=nZ2NtpolC5-) |  | 0 | It is unclear how changing the learning rule of a deep neural network alters its learning dynamics and representations. To gain insight into the relationship between learned features, function approximation, and the learning rule, we analyze infinite-width deep networks trained with gradient... | Blake Bordelon, Cengiz Pehlevan |  |
| 677 |  |  [Few-shot Cross-domain Image Generation via Inference-time Latent-code Learning](https://openreview.net/forum?id=sCYXJr3QJM8) |  | 0 | In this work, our objective is to adapt a Deep generative model trained on a large-scale source dataset to multiple target domains with scarce data. Specifically, we focus on adapting a pre-trained Generative Adversarial Network (GAN) to a target domain without re-training the generator. Our method... | Arnab Kumar Mondal, Parag Singla, Piyush Tiwary, Prathosh AP |  |
| 678 |  |  [RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch](https://openreview.net/forum?id=DJEEqoAq7to) |  | 0 | Training deep reinforcement learning (DRL) models usually requires high computation costs. Therefore, compressing DRL models possesses immense potential for training acceleration and model deployment. However, existing methods that generate small models mainly adopt the knowledge distillation-based... | Jiatai Huang, Ling Pan, Longbo Huang, Pihe Hu, Yiqin Tan |  |
| 679 |  |  [Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!](https://openreview.net/forum?id=J6F3lLg4Kdp) |  | 0 | Sparse Neural Networks (SNNs) have received voluminous attention predominantly due to growing computational and memory footprints of consistently exploding parameter count in large-scale models. Similar to their dense counterparts, recent SNNs generalize just as well and are equipped with numerous... | Ajay Kumar Jaiswal, Shiwei Liu, Tianjin Huang, Tianlong Chen, Xuxi Chen, Zhangyang Wang, Zhenyu Zhang |  |
| 680 |  |  [Sparse MoE as the New Dropout: Scaling Dense and Self-Slimmable Transformers](https://openreview.net/forum?id=w1hwFUb_81) |  | 0 | Despite their remarkable achievement, gigantic transformers encounter significant drawbacks, including exorbitant computational and memory footprints during training, as well as severe collapse evidenced by a high degree of parameter redundancy. Sparsely-activated Mixture-of-Experts (SMoEs) have... | Ajay Kumar Jaiswal, Shiwei Liu, Tianlong Chen, Zhangyang Wang, Zhenyu Zhang |  |
| 681 |  |  [Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks](https://openreview.net/forum?id=LfdEuhjR5GV) |  | 0 | Monocular Depth Estimation (MDE) is a critical component in applications such as autonomous driving. There are various attacks against MDE networks. These attacks, especially the physical ones, pose a great threat to the security of such systems. Traditional adversarial training method requires... | Dongfang Liu, Guanhong Tao, James Liang, Xiangyu Zhang, Zhiyuan Cheng |  |
| 682 |  |  [Sparsity-Constrained Optimal Transport](https://openreview.net/forum?id=yHY9NbQJ5BP) |  | 0 | Regularized optimal transport (OT) is now increasingly used as a loss or as a matching layer in neural networks. Entropy-regularized OT can be computed using the Sinkhorn algorithm but it leads to fully-dense transportation plans, meaning that all sources are (fractionally) matched with all... | Joan Puigcerver, Mathieu Blondel, Tianlin Liu |  |
| 683 |  |  [Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection](https://openreview.net/forum?id=mMNimwRb7Gr) |  | 0 | Deep neural networks have witnessed huge successes in many challenging prediction tasks and yet they often suffer from out-of-distribution (OoD) samples, misclassifying them with high confidence. Recent advances show promising OoD detection performance for centralized training, and however, OoD... | Haotao Wang, Jiayu Zhou, Junyuan Hong, Shuyang Yu, Zhangyang Wang |  |
| 684 |  |  [DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion](https://openreview.net/forum?id=j6zUzrapY3L) |  | 0 | Real-world data generation often involves complex inter-dependencies among instances, violating the IID-data hypothesis of standard learning paradigms and posing a challenge for uncovering the geometric structures for learning desired instance representations. To this end, we introduce an energy... | Chenxiao Yang, David Wipf, Junchi Yan, Qitian Wu, Wentao Zhao, Yixuan He |  |
| 685 |  |  [Neural Lagrangian Schrödinger Bridge: Diffusion Modeling for Population Dynamics](https://openreview.net/forum?id=d3QNWD_pcFv) |  | 0 | Population dynamics is the study of temporal and spatial variation in the size of populations of organisms and is a major part of population ecology. One of the main difficulties in analyzing population dynamics is that we can only obtain observation data with coarse time intervals from fixed-point... | Issei Sato, Takeshi Koshizuka |  |
| 686 |  |  [Loss Landscapes are All You Need: Neural Network Generalization Can Be Explained Without the Implicit Bias of Gradient Descent](https://openreview.net/forum?id=QC10RmRbZy9) |  | 0 | It is commonly believed that the implicit regularization of optimizers is needed for neural networks to generalize in the overparameterized regime. In this paper, we observe experimentally that this implicit regularization behavior is {\em generic}, i.e. it does not depend strongly on the choice of... | Arpit Bansal, David Yu Miller, Jonas Geiping, Micah Goldblum, Pingyeh Chiang, Renkun Ni, Tom Goldstein |  |
| 687 |  |  [Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning](https://openreview.net/forum?id=h5OpjGd_lo6) |  | 0 | There is a rising interest in further exploring the zero-shot learning potential of large pre-trained language models (PLMs). A new paradigm called data-generation-based zero-shot learning has achieved impressive success. In this paradigm, the synthesized data from the PLM acts as the carrier of... | Hang Xu, Jiacheng Ye, Jiahui Gao, Lingpeng Kong, Renjie Pi, Weizhong Zhang, Xiaodan Liang, Yong Lin, Zhenguo Li, Zhiyong Wu |  |
| 688 |  |  [D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory](https://openreview.net/forum?id=aBWnqqsuot7) |  | 0 | Kohn-Sham Density Functional Theory (KS-DFT) has been traditionally solved by the Self-Consistent Field (SCF) method. Behind the SCF loop is the physics intuition of solving a system of non-interactive single-electron wave functions under an effective potential. In this work, we propose a deep... | A. H. Castro Neto, Giovanni Vignale, Kenji Kawaguchi, Kostya S. Novoselov, Kunhao Zheng, Min Lin, Shuicheng Yan, Tianbo Li, Zheyuan Hu |  |
| 689 |  |  [Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning](https://openreview.net/forum?id=kPLzOfPfA2l) |  | 0 | Class-incremental few-shot learning, where new sets of classes are provided sequentially with only a few training samples, presents a great challenge due to catastrophic forgetting of old knowledge and overfitting caused by lack of data. During finetuning on new classes, the performance on previous... | DoYeon Kim, DongJun Han, Jaekyun Moon, Jun Seo |  |
| 690 |  |  [Pre-training via Denoising for Molecular Property Prediction](https://openreview.net/forum?id=tYIMtogyee) |  | 0 | Many important problems involving molecular property prediction from 3D structures have limited data, posing a generalization challenge for neural networks. In this paper, we describe a pre-training technique based on denoising that achieves a new state-of-the-art in molecular property prediction... | Alvaro SanchezGonzalez, Hyunjik Kim, James Martens, Jonathan Godwin, Michael Schaarschmidt, Peter W. Battaglia, Razvan Pascanu, Sheheryar Zaidi, Yee Whye Teh |  |
| 691 |  |  [Martingale Posterior Neural Processes](https://openreview.net/forum?id=-9PVqZ-IR_) |  | 0 | A Neural Process (NP) estimates a stochastic process implicitly defined with neural networks given a stream of data, rather than pre-specifying priors already known, such as Gaussian processes. An ideal NP would learn everything from data without any inductive biases, but in practice, we often... | Edwin Fong, Eunggu Yun, Giung Nam, Hyungi Lee, Juho Lee |  |
| 692 |  |  [On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation](https://openreview.net/forum?id=bvpkw7UIRdU) |  | 0 | A good automatic evaluation metric for language generation ideally correlates highly with human judgements of text quality. Yet, there is a dearth of such metrics, which inhibits the rapid and efficient progress of language generators. One exception is the recently proposed Mauve. In theory, Mauve... | Clara Meister, Ryan Cotterell, Tiago Pimentel |  |
| 693 |  |  [DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems](https://openreview.net/forum?id=C-xa_D3oTj6) |  | 0 | Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. Reinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance. We conjecture that ineffective exploration in... | Daniel F. B. Haeufle, Dieter Büchler, Georg Martius, Pierre Schumacher, Syn Schmitt |  |
| 694 |  |  [The Symmetric Generalized Eigenvalue Problem as a Nash Equilibrium](https://openreview.net/forum?id=PEgBEB74JjB) |  | 0 | The symmetric generalized eigenvalue problem (SGEP) is a fundamental concept in numerical linear algebra. It captures the solution of many classical machine learning problems such as canonical correlation analysis, independent components analysis, partial least squares, linear discriminant... | Brian McWilliams, Charlie Chen, Ian Gemp |  |
| 695 |  |  [EA-HAS-Bench: Energy-aware Hyperparameter and Architecture Search Benchmark](https://openreview.net/forum?id=n-bvaLSCC78) |  | 0 | The energy consumption for training deep learning models is increasing at an alarming rate due to the growth of training data and model scale, resulting in a negative impact on carbon neutrality. Energy consumption is an especially pressing issue for AutoML algorithms because it usually requires... | Cairong Zhao, Dongsheng Li, Shuguang Dou, Xinyang Jiang |  |
| 696 |  |  [MARS: Meta-learning as Score Matching in the Function Space](https://openreview.net/forum?id=WAgXmT8BeRj) |  | 0 | Meta-learning aims to extract useful inductive biases from a set of related datasets. In Bayesian meta-learning, this is typically achieved by constructing a prior distribution over neural network parameters. However, specifying families of computationally viable prior distributions over the... | Andreas Krause, Jonas Rothfuss, Krunoslav Lehman Pavasovic |  |
| 697 |  |  [Faster Gradient-Free Methods for Escaping Saddle Points](https://openreview.net/forum?id=KDhFkA6MQsW) |  | 0 | Escaping from saddle points has become an important research topic in non-convex optimization. In this paper, we study the case when calculations of explicit gradients are expensive or even infeasible, and only function values are accessible. Currently, there have two types of gradient-free... | Bin Gu, Hualin Zhang |  |
| 698 |  |  [VA-DepthNet: A Variational Approach to Single Image Depth Prediction](https://openreview.net/forum?id=xjxUjHa_Wpa) |  | 0 | We introduce VA-DepthNet, a simple, effective, and accurate deep neural network approach for the single-image depth prediction (SIDP) problem. The proposed approach advocates using classical first-order variational constraints for this problem. While state-of-the-art deep neural network methods for... | Ce Liu, Luc Van Gool, Radu Timofte, Shuhang Gu, Suryansh Kumar |  |
| 699 |  |  [Prompt-to-Prompt Image Editing with Cross-Attention Control](https://openreview.net/forum?id=_CDixzkzeyb) |  | 0 | Recent large-scale text-driven synthesis diffusion models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Therefore, it is only natural to build upon these synthesis models to provide text-driven image editing... | Amir Hertz, Daniel CohenOr, Jay Tenenbaum, Kfir Aberman, Ron Mokady, Yael Pritch |  |
| 700 |  |  [DiffEdit: Diffusion-based semantic image editing with mask guidance](https://openreview.net/forum?id=3lge0p5o-M-) |  | 0 | Image generation has recently seen tremendous advances, with diffusion models allowing to synthesize convincing images for a large variety of text prompts. In this article, we propose DiffEdit, a method to take advantage of text-conditioned diffusion models for the task of semantic image editing,... | Guillaume Couairon, Holger Schwenk, Jakob Verbeek, Matthieu Cord |  |
| 701 |  |  [Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images](https://openreview.net/forum?id=JTGimap_-F) |  | 0 | Evaluation metrics in image synthesis play a key role to measure performances of generative models. However, most metrics mainly focus on image fidelity. Existing diversity metrics are derived by comparing distributions, and thus they cannot quantify the diversity or rarity degree of each generated... | Hwanil Choi, Jaesik Choi, Jiyeon Han, JungWoo Ha, Junho Kim, Yunjey Choi |  |
| 702 |  |  [Corrupted Image Modeling for Self-Supervised Visual Pre-Training](https://openreview.net/forum?id=09hVcSDkea) |  | 0 | We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial [MASK] tokens, where some patches are randomly selected and replaced with plausible alternatives... | Furu Wei, Hangbo Bao, Li Dong, Xinggang Wang, Yuxin Fang |  |
| 703 |  |  [Semi-Implicit Variational Inference via Score Matching](https://openreview.net/forum?id=sd90a2ytrt) |  | 0 | Semi-implicit variational inference (SIVI) greatly enriches the expressiveness of variational families by considering implicit variational distributions defined in a hierarchical manner. However, due to the intractable densities of variational distributions, current SIVI approaches often use... | Cheng Zhang, Longlin Yu |  |
| 704 |  |  [Exploring Temporally Dynamic Data Augmentation for Video Recognition](https://openreview.net/forum?id=fxjzKOdw9wb) |  | 0 | Data augmentation has recently emerged as an essential component of modern training recipes for visual recognition tasks. However, data augmentation for video recognition has been rarely explored despite its effectiveness. Few existing augmentation recipes for video recognition naively extend the... | Dongyoon Wee, Jinhyung Kim, Minho Shim, Myunggu Kang, Sangdoo Yun, Sangyoun Lee, Taeoh Kim |  |
| 705 |  |  [A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning](https://openreview.net/forum?id=dqITIpZ5Z4b) |  | 0 | With the increasing need for handling large state and action spaces, general function approximation has become a key technique in reinforcement learning (RL). In this paper, we propose a general framework that unifies model-based and model-free RL, and an Admissible Bellman Characterization (ABC)... | Chris Junchi Li, Huizhuo Yuan, Michael I. Jordan, Quanquan Gu, Zixiang Chen |  |
| 706 |  |  [Adversarial Attacks on Adversarial Bandits](https://openreview.net/forum?id=bBpT6dEjeRG) |  | 0 | We study a security threat to adversarial multi-armed bandit, in which an attacker perturbs the loss or reward signal to control the behavior of the victim bandit player. We show that the attacker is able to mislead any no-regret adversarial bandit algorithm into selecting a suboptimal target... | Yuzhe Ma, Zhijin Zhou |  |
| 707 |  |  [Ensuring DNN Solution Feasibility for Optimization Problems with Linear Constraints](https://openreview.net/forum?id=QVcDQJdFTG) |  | 0 | We propose preventive learning as the first framework to guarantee Deep Neural Network (DNN) solution feasibility for optimization problems with linear constraints without post-processing, upon satisfying a mild condition on constraint calibration. Without loss of generality, we focus on problems... | Minghua Chen, Steven H. Low, Tianyu Zhao, Xiang Pan |  |
| 708 |  |  [LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation](https://openreview.net/forum?id=FKXVK9dyMM) |  | 0 | Graph neural network (GNN) is a powerful learning approach for graph-based recommender systems. Recently, GNNs integrated with contrastive learning have shown superior performance in recommendation with their data augmentation schemes, aiming at dealing with highly sparse data. Despite their... | Chao Huang, Lianghao Xia, Xubin Ren, Xuheng Cai |  |
| 709 |  |  [MIMT: Masked Image Modeling Transformer for Video Compression](https://openreview.net/forum?id=j9m-mVnndbm) |  | 0 | Deep learning video compression outperforms its hand-craft counterparts with enhanced flexibility and capacity. One key component of the learned video codec is the autoregressive entropy model conditioned on spatial and temporal priors. Operating autoregressive on raster scanning order naively... | Jinxi Xiang, Jun Zhang, Kuan Tian |  |
| 710 |  |  [Hungry Hungry Hippos: Towards Language Modeling with State Space Models](https://openreview.net/forum?id=COZDy0WYGg) |  | 0 | State space models (SSMs) have demonstrated state-of-the-art sequence modeling performance in some modalities, but underperform attention in language modeling. Moreover, despite scaling nearly linearly in sequence length instead of quadratically, SSMs are still slower than Transformers due to poor... | Armin W. Thomas, Atri Rudra, Christopher Ré, Daniel Y. Fu, Khaled Kamal Saab, Tri Dao |  |
| 711 |  |  [ACMP: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks](https://openreview.net/forum?id=4fZc_79Lrqs) |  | 0 | Neural message passing is a basic feature extraction unit for graph-structured data considering neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising... | Kai Yi, Shi Jin, Xinliang Liu, Yu Guang Wang, Yuelin Wang |  |
| 712 |  |  [Relational Attention: Generalizing Transformers for Graph-Structured Tasks](https://openreview.net/forum?id=cFuMmbWiN6) |  | 0 | Transformers flexibly operate over sets of real-valued vectors representing task-specific entities and their attributes, where each vector might encode one word-piece token and its position in a sequence, or some piece of information that carries no position at all. As set processors, transformers... | Cameron Diao, Ricky Loynd |  |
| 713 |  |  [Distilling Model Failures as Directions in Latent Space](https://openreview.net/forum?id=99RpBVpLiX) |  | 0 | Existing methods for isolating hard subpopulations and spurious correlations in datasets often require human intervention. This can make these methods labor-intensive and dataset-specific. To address these shortcomings, we present a scalable method for automatically distilling a model's failure... | Aleksander Madry, Ankur Moitra, Hannah Lawrence, Saachi Jain |  |
| 714 |  |  [Combinatorial-Probabilistic Trade-Off: P-Values of Community Properties Test in the Stochastic Block Models](https://openreview.net/forum?id=8qjSA5QACb40) |  | 0 | We propose an inferential framework testing the general community combinatorial properties of the stochastic block model. We aim to test the hypothesis on whether a certain community property is satisfied, e.g., whether a given set of nodes belong to the same community, and provide p-values for... | Junwei Lu, Shuting Shen |  |
| 715 |  |  [Continuized Acceleration for Quasar Convex Functions in Non-Convex Optimization](https://openreview.net/forum?id=yYbhKqdi7Hz) |  | 0 | Quasar convexity is a condition that allows some first-order methods to efficiently minimize a function even when the optimization landscape is non-convex. Previous works develop near-optimal accelerated algorithms for minimizing this class of functions, however, they require a subroutine of binary... | Andre Wibisono, JunKun Wang |  |
| 716 |  |  [Learning Soft Constraints From Constrained Expert Demonstrations](https://openreview.net/forum?id=8sSnD78NqTN) |  | 0 | Inverse reinforcement learning (IRL) methods assume that the expert data is generated by an agent optimizing some reward function. However, in many settings, the agent may optimize a reward function subject to some constraints, where the constraints induce behaviors that may be otherwise difficult... | Ashish Gaurav, Guiliang Liu, Kasra Rezaee, Pascal Poupart |  |
| 717 |  |  [Learning to Grow Pretrained Models for Efficient Transformer Training](https://openreview.net/forum?id=cDYRS5iZ16f) |  | 0 | Scaling transformers has led to significant breakthroughs in many domains, leading to a paradigm in which larger versions of existing models are trained and released on a periodic basis. New instances of such models are typically trained completely from scratch, despite the fact that they are often... | David Daniel Cox, Leonid Karlinsky, Lucas Torroba Hennigen, Peihao Wang, Philip Greengard, Rameswar Panda, Rogério Feris, Yoon Kim, Zhangyang Wang |  |
| 718 |  |  [InCoder: A Generative Model for Code Infilling and Synthesis](https://openreview.net/forum?id=hQwb-lbM6EL) |  | 0 | Code is seldom written in a single left-to-right pass and is instead repeatedly edited and refined. We introduce InCoder, a unified generative model that can perform program synthesis (via left-to-right generation) as well as editing (via masking and infilling). InCoder is trained to generate code... | Armen Aghajanyan, Daniel Fried, Eric Wallace, Freda Shi, Jessy Lin, Luke Zettlemoyer, Mike Lewis, Ruiqi Zhong, Scott Yih, Sida Wang |  |
| 719 |  |  [UNIFIED-IO: A Unified Model for Vision, Language, and Multi-modal Tasks](https://openreview.net/forum?id=E01k9048soZ) |  | 0 | We propose Unified-IO, a model that performs a large variety of AI tasks spanning classical computer vision tasks, including pose estimation, object detection, depth estimation and image generation, vision-and-language tasks such as region captioning and referring expression, to natural language... | Aniruddha Kembhavi, Christopher Clark, Jiasen Lu, Roozbeh Mottaghi, Rowan Zellers |  |
| 720 |  |  [Benchmarking Offline Reinforcement Learning on Real-Robot Hardware](https://openreview.net/forum?id=3k5CUGDLNdd) |  | 0 | Learning policies from previously recorded data is a promising direction for real-world robotics tasks, as online learning is often infeasible. Dexterous manipulation in particular remains an open problem in its general form. The combination of offline reinforcement learning with large diverse... | Bernhard Schölkopf, Felix Widmaier, Georg Martius, Manuel Wuthrich, Nico Gürtler, Pavel Kolev, Sebastian Blaes, Stefan Bauer |  |
| 721 |  |  [CUDA: Curriculum of Data Augmentation for Long-tailed Recognition](https://openreview.net/forum?id=RgUPdudkWlN) |  | 0 | Class imbalance problems frequently occur in real-world tasks, and conventional deep learning algorithms are well known for performance degradation on imbalanced training datasets. To mitigate this problem, many approaches have aimed to balance among given classes by re-weighting or re-sampling... | Jongwoo Ko, SeYoung Yun, Sumyeong Ahn |  |
| 722 |  |  [Learning to Estimate Shapley Values with Vision Transformers](https://openreview.net/forum?id=5ktFNz_pJLK) |  | 0 | Transformers have become a default architecture in computer vision, but understanding what drives their predictions remains a challenging problem. Current explanation approaches rely on attention values or input gradients, but these provide a limited view of a model’s dependencies. Shapley values... | Chanwoo Kim, Ian Connick Covert, SuIn Lee |  |
| 723 |  |  [A framework for benchmarking Class-out-of-distribution detection and its application to ImageNet](https://openreview.net/forum?id=Iuubb9W6Jtk) |  | 0 | When deployed for risk-sensitive tasks, deep neural networks must be able to detect instances with labels from outside the distribution for which they were trained. In this paper we present a novel framework to benchmark the ability of image classifiers to detect class-out-of-distribution instances... | Ido Galil, Mohammed Dabbah, Ran ElYaniv |  |
| 724 |  |  [Retrieval-based Controllable Molecule Generation](https://openreview.net/forum?id=vDFA1tpuLvk) |  | 0 | Generating new molecules with specified chemical and biological properties via generative models has emerged as a promising direction for drug discovery. However, existing methods require extensive training/fine-tuning with a large dataset, often unavailable in real-world generation tasks. In this... | Anima Anandkumar, Chaowei Xiao, Richard G. Baraniuk, Weili Nie, Zhuoran Qiao, Zichao Wang |  |
| 725 |  |  [Stochastic Multi-Person 3D Motion Forecasting](https://openreview.net/forum?id=_s1N-DnxdyT) |  | 0 | This paper aims to deal with the ignored real-world complexities in prior work on human motion forecasting, emphasizing the social properties of multi-person motion, the diversity of motion and social interactions, and the complexity of articulated motion. To this end, we introduce a novel task of... | Liangyan Gui, Sirui Xu, YuXiong Wang |  |
| 726 |  |  [Sign and Basis Invariant Networks for Spectral Graph Representation Learning](https://openreview.net/forum?id=Q-UHqMorzil) |  | 0 | We introduce SignNet and BasisNet---new neural architectures that are invariant to two key symmetries displayed by eigenvectors: (i) sign flips, since if v is an eigenvector then so is -v; and (ii) more general basis symmetries, which occur in higher dimensional eigenspaces with infinitely many... | Derek Lim, Haggai Maron, Joshua David Robinson, Lingxiao Zhao, Stefanie Jegelka, Suvrit Sra, Tess E. Smidt |  |
| 727 |  |  [Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting](https://openreview.net/forum?id=7C9aRX2nBf2) |  | 0 | Modern applications increasingly require learning and forecasting latent dynamics from high-dimensional time-series. Compared to univariate time-series forecasting, this adds a new challenge of reasoning about the latent dynamics of an unobserved abstract state. Sequential latent variable models... | Linwei Wang, Ryan Missel, Xiajun Jiang, Zhiyuan Li |  |
| 728 |  |  [Code Translation with Compiler Representations](https://openreview.net/forum?id=XomEU3eNeSQ) |  | 0 | In this paper, we leverage low-level compiler intermediate representations (IR) code translation. Traditional transpilers rely on syntactic information and handcrafted rules, which limits their applicability and produces unnatural-looking code. Applying neural machine translation (NMT) approaches... | Baptiste Rozière, François Charton, Gabriel Synnaeve, Hugh Leather, Marc Szafraniec, Patrick Labatut |  |
| 729 |  |  [Omnigrok: Grokking Beyond Algorithmic Data](https://openreview.net/forum?id=zDiHoIWa0q1) |  | 0 | Grokking, the unusual phenomenon for algorithmic datasets where generalization happens long after overfitting the training data, has remained elusive. We aim to understand grokking by analyzing the loss landscapes of neural networks, identifying the mismatch between training and test losses as the... | Eric J. Michaud, Max Tegmark, Ziming Liu |  |
| 730 |  |  [Flow Annealed Importance Sampling Bootstrap](https://openreview.net/forum?id=XCTVFJwS9LJ) |  | 0 | Normalizing flows are tractable density models that can approximate complicated target distributions, e.g. Boltzmann distributions of physical systems. However, current methods for training flows either suffer from mode-seeking behavior, use samples from the target generated beforehand by expensive... | Bernhard Schölkopf, Gregor N. C. Simm, José Miguel HernándezLobato, Laurence Illing Midgley, Vincent Stimper |  |
| 731 |  |  [Continual Unsupervised Disentangling of Self-Organizing Representations](https://openreview.net/forum?id=ih0uFRFhaZZ) |  | 0 | Limited progress has been made in continual unsupervised learning of representations, especially in reusing, expanding, and continually disentangling learned semantic factors across data environments. We argue that this is because existing approaches treat continually-arrived data independently,... | Linwei Wang, Nilesh Kumar, Prashnna Kumar Gyawali, Ryan Missel, Xiajun Jiang, Zhiyuan Li |  |
| 732 |  |  [LMC: Fast Training of GNNs via Subgraph Sampling with Provable Convergence](https://openreview.net/forum?id=5VBBA91N6n) |  | 0 | The message passing-based graph neural networks (GNNs) have achieved great success in many real-world applications. However, training GNNs on large-scale graphs suffers from the well-known neighbor explosion problem, i.e., the exponentially increasing dependencies of nodes with the number of... | Jie Wang, Xize Liang, Zhihao Shi |  |
| 733 |  |  [Programmatically Grounded, Compositionally Generalizable Robotic Manipulation](https://openreview.net/forum?id=rZ-wylY5VI) |  | 0 | Robots operating in the real world require both rich manipulation skills as well as the ability to semantically reason about when to apply those skills. Towards this goal, recent works have integrated semantic representations from large-scale pretrained vision-language (VL) models into manipulation... | Hang Zhao, Jiajun Wu, Jiayuan Mao, Joy Hsu, Renhao Wang, Yang Gao |  |
| 734 |  |  [SketchKnitter: Vectorized Sketch Generation with Diffusion Models](https://openreview.net/forum?id=4eJ43EN2g6l) |  | 0 | We show vectorized sketch generation can be identified as a reversal of the stroke deformation process. This relationship was established by means of a diffusion model that learns data distributions over the stroke-point locations and pen states of real human sketches. Given randomly scattered... | Da Li, Haoge Deng, Qiang Wang, YiZhe Song, Yonggang Qi |  |
| 735 |  |  [A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning](https://openreview.net/forum?id=S07feAlQHgM) |  | 0 | Real-world applications require the classification model to adapt to new classes without forgetting old ones. Correspondingly, Class-Incremental Learning (CIL) aims to train a model with limited memory size to meet this requirement. Typical CIL methods tend to save representative exemplars from... | DaWei Zhou, DeChuan Zhan, HanJia Ye, QiWei Wang |  |
| 736 |  |  [Toeplitz Neural Network for Sequence Modeling](https://openreview.net/forum?id=IxmWsm4xrua) |  | 0 | Sequence modeling has important applications in natural language processing and computer vision. Recently, the transformer-based models have shown strong performance on various sequence modeling tasks, which rely on attention to capture pairwise token relations, and position embedding to inject... | Bowen He, Dong Li, Dongxu Li, Lingpeng Kong, Weixuan Sun, Xiaodong Han, Yiran Zhong, Yuchao Dai, Zhen Qin |  |
| 737 |  |  [QuAnt: Quantum Annealing with Learnt Couplings](https://openreview.net/forum?id=isiQ5KIXbjj) |  | 0 | Modern quantum annealers can find high-quality solutions to combinatorial optimisation objectives given as quadratic unconstrained binary optimisation (QUBO) problems. Unfortunately, obtaining suitable QUBO forms in computer vision remains challenging and currently requires problem-specific... | Edith Tretschk, Marcel Seelbach Benkner, Maximilian Krahn, Michael Moeller, Vladislav Golyanik, Zorah Lähner |  |
| 738 |  |  [Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective](https://openreview.net/forum?id=q3F0UBAruO) |  | 0 | MOBA games, e.g., Dota2 and Honor of Kings, have been actively used as the testbed for the recent AI research on games, and various AI systems have been developed at the human level so far. However, these AI systems mainly focus on how to compete with humans, less on exploring how to collaborate... | Feiyu Liu, Jiawei Wang, Lanxiao Huang, Liang Wang, Qiang Fu, Rundong Wang, Siqin Li, Wei Liu, Wei Yang, Weixuan Wang, Xianhan Zeng, Xianliang Wang, Yiming Gao, Zhenjie Lian |  |
| 739 |  |  [On the complexity of nonsmooth automatic differentiation](https://openreview.net/forum?id=uqg3FhRZaq) |  | 0 | Using the notion of conservative gradient, we provide a simple model to estimate the computational costs of the backward and forward modes of algorithmic differentiation for a wide class of nonsmooth programs. The complexity overhead of the backward mode turns out to be independent of the dimension... | Béatrice PesquetPopescu, Edouard Pauwels, Jérôme Bolte, Ryan Boustany |  |
| 740 |  |  [Diffusion Posterior Sampling for General Noisy Inverse Problems](https://openreview.net/forum?id=OnD9zGAGT0k) |  | 0 | Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which... | Hyungjin Chung, Jeongsol Kim, Jong Chul Ye, Marc Louis Klasky, Michael Thompson McCann |  |
| 741 |  |  [Mass-Editing Memory in a Transformer](https://openreview.net/forum?id=MkbcAHIYgyS) |  | 0 | Recent work has shown exciting promise in updating large language models with new memories, so as to replace obsolete information or add specialized knowledge. However, this line of work is predominantly limited to updating single associations. We develop MEMIT, a method for directly updating a... | Alex J. Andonian, Arnab Sen Sharma, David Bau, Kevin Meng, Yonatan Belinkov |  |
| 742 |  |  [Learning the Positions in CountSketch](https://openreview.net/forum?id=iV9Cs8s8keU) |  | 0 | We consider sketching algorithms which first compress data by multiplication with a random sketch matrix, and then apply the sketch to quickly solve an optimization problem, e.g., low-rank approximation and regression. In the learning-based sketching paradigm proposed by Indyk et al., the sketch... | Ali Vakilian, David P. Woodruff, Honghao Lin, Simin Liu, Yi Li |  |
| 743 |  |  [Outcome-directed Reinforcement Learning by Uncertainty \& Temporal Distance-Aware Curriculum Goal Generation](https://openreview.net/forum?id=v69itrHLEu) |  | 0 | Current reinforcement learning (RL) often suffers when solving a challenging exploration problem where the desired outcomes or high rewards are rarely observed. Even though curriculum RL, a framework that solves complex tasks by proposing a sequence of surrogate tasks, shows reasonable results,... | Daesol Cho, H. Jin Kim, Seungjae Lee |  |
| 744 |  |  [A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation](https://openreview.net/forum?id=Mvetq8DO05O) |  | 0 | Estimating the 3DoF rotation from a single RGB image is an important yet challenging problem. Probabilistic rotation regression has raised more and more attention with the benefit of expressing uncertainty information along with the prediction. Though modeling noise using Gaussian-resembling... | Baoquan Chen, He Wang, Yang Wang, Yingda Yin |  |
| 745 |  |  [HiViT: A Simpler and More Efficient Design of Hierarchical Vision Transformer](https://openreview.net/forum?id=3F6I-0-57SC) |  | 0 | There has been a debate on the choice of plain vs. hierarchical vision transformers, where researchers often believe that the former (e.g., ViT) has a simpler design but the latter (e.g., Swin) enjoys higher recognition accuracy. Recently, the emerge of masked image modeling (MIM), a... | Lingxi Xie, Qi Dai, Qi Tian, Qixiang Ye, Wei Huang, Xiaosong Zhang, Yunjie Tian |  |
| 746 |  |  [A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics](https://openreview.net/forum?id=kIPyTuEZuAK) |  | 0 | Inspired by humans' exceptional ability to master arithmetic and generalize to new problems, we present a new dataset, HINT, to examine machines' capability of learning generalizable concepts at three levels: perception, syntax, and semantics. In HINT, machines are tasked with learning how concepts... | Qing Li, Siyuan Huang, SongChun Zhu, Ying Nian Wu, Yining Hong, Yixin Zhu |  |
| 747 |  |  [Unsupervised Model Selection for Time Series Anomaly Detection](https://openreview.net/forum?id=gOZ_pKANaPW) |  | 0 | Anomaly detection in time-series has a wide range of practical applications. While numerous anomaly detection methods have been proposed in the literature, a recent survey concluded that no single method is the most accurate across various datasets. To make matters worse, anomaly labels are scarce... | Andrey Kan, Cristian I. Challu, Laurent Callot, Lenon Minorics, Mononito Goswami |  |
| 748 |  |  [AANG : Automating Auxiliary Learning](https://openreview.net/forum?id=vtVDI3w_BLL) |  | 0 | Auxiliary objectives, supplementary learning signals that are introduced to help aid learning on data-starved or highly complex end-tasks, are commonplace in machine learning. Whilst much work has been done to formulate useful auxiliary objectives, their construction is still an art which proceeds... | Ameet Talwalkar, Graham Neubig, Lucio M. Dery, Mikhail Khodak, Paul Michel |  |
| 749 |  |  [NeRN: Learning Neural Representations for Neural Networks](https://openreview.net/forum?id=9gfir3fSy3J) |  | 0 | Neural Representations have recently been shown to effectively reconstruct a wide range of signals from 3D meshes and shapes to images and videos. We show that, when adapted correctly, neural representations can be used to directly represent the weights of a pre-trained convolutional neural... | Elad Richardson, Eran Treister, Maor Ashkenazi, Pinchas Mintz, Ron Vainshtein, Shir Levi, Zohar Rimon |  |
| 750 |  |  [Formal Mathematics Statement Curriculum Learning](https://openreview.net/forum?id=-P7G-8dmSh4) |  | 0 | We explore the use of expert iteration in the context of language modeling applied to formal mathematics. We show that at same compute budget, expert iteration, by which we mean proof search interleaved with learning, dramatically outperforms proof search only. We also observe that when applied to... | Igor Babuschkin, Ilya Sutskever, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Stanislas Polu |  |
| 751 |  |  [Multifactor Sequential Disentanglement via Structured Koopman Autoencoders](https://openreview.net/forum?id=6fuPIe9tbnC) |  | 0 | Disentangling complex data to its latent factors of variation is a fundamental task in representation learning. Existing work on sequential disentanglement mostly provides two factor representations, i.e., it separates the data to time-varying and time-invariant factors. In contrast, we consider... | Ilan Naiman, Nimrod Berman, Omri Azencot |  |
| 752 |  |  [Packed Ensembles for efficient uncertainty estimation](https://openreview.net/forum?id=XXTyv1zD9zD) |  | 0 | Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks,... | Adrien Lafage, Andrei Bursuc, Enzo Tartaglione, Geoffrey Daniel, Gianni Franchi, JeanMarc Martinez, Olivier Laurent |  |
| 753 |  |  [Hidden Markov Transformer for Simultaneous Machine Translation](https://openreview.net/forum?id=9y0HFvaAYD6) |  | 0 | Simultaneous machine translation (SiMT) outputs the target sequence while receiving the source sequence, and hence learning when to start translating each target token is the core challenge for SiMT task. However, it is non-trivial to learn the optimal moment among many possible moments of starting... | Shaolei Zhang, Yang Feng |  |
| 754 |  |  [Multi-domain image generation and translation with identifiability guarantees](https://openreview.net/forum?id=U2g8OGONA_V) |  | 0 | Multi-domain image generation and unpaired image-to-to-image translation are two important and related computer vision problems. The common technique for the two tasks is the learning of a joint distribution from multiple marginal distributions. However, it is well known that there can be... | Kun Zhang, Lingjing Kong, Mingming Gong, Shaoan Xie |  |
| 755 |  |  [Continual evaluation for lifelong learning: Identifying the stability gap](https://openreview.net/forum?id=Zy350cRstc6) |  | 0 | Time-dependent data-generating distributions have proven to be difficult for gradient-based training of neural networks, as the greedy updates result in catastrophic forgetting of previously learned knowledge. Despite the progress in the field of continual learning to overcome this forgetting, we... | Gido M. van de Ven, Matthias De Lange, Tinne Tuytelaars |  |
| 756 |  |  [Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation](https://openreview.net/forum?id=pxStyaf2oJ5) |  | 0 | Previous studies have shown that leveraging "domain index" can significantly boost domain adaptation performance (Wang et al., 2020; Xu et al., 2022). However, such domain indices are not always available. To address this challenge, we first provide a formal definition of domain index from the... | GuangYuan Hao, Hao He, Hao Wang, Zihao Xu |  |
| 757 |  |  [One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks](https://openreview.net/forum?id=p7G8t5FVn2h) |  | 0 | Unlearnable examples (ULEs) aim to protect data from unauthorized usage for training DNNs. Existing work adds $\ell_\infty$-bounded perturbations to the original sample so that the trained model generalizes poorly. Such perturbations, however, are easy to eliminate by adversarial training and data... | Cihang Xie, Shutong Wu, Sizhe Chen, Xiaolin Huang |  |
| 758 |  |  [Deterministic training of generative autoencoders using invertible layers](https://openreview.net/forum?id=g8wBdhnstYz) |  | 0 | In this work, we provide a deterministic alternative to the stochastic variational training of generative autoencoders. We refer to these new generative autoencoders as AutoEncoders within Flows (AEF), since the encoder and decoder are defined as affine layers of an overall invertible architecture.... | Daan Roos, Gianluigi Silvestri, Luca Ambrogioni |  |
| 759 |  |  [A Holistic View of Label Noise Transition Matrix in Deep Learning and Beyond](https://openreview.net/forum?id=aFzaXRImWE) |  | 0 | In this paper, we explore learning statistically consistent classifiers under label noise by estimating the noise transition matrix T. We first provide a holistic view of existing T-estimation methods including those with or without anchor point assumptions. We unified them into the Minimum... | Bo Han, Jiahui Gao, Renjie Pi, Tongliang Liu, Weizhong Zhang, Xiao Zhou, Xiaobo Xia, Yong Lin |  |
| 760 |  |  [Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle](https://openreview.net/forum?id=ZTMuZ68B1g) |  | 0 | Acquiring labeled data is challenging in many machine learning applications with limited budgets. Active learning gives a procedure to select the most informative data points and improve data efficiency by reducing the cost of labeling. The info-max learning principle maximizing mutual information... | Jae Oh Woo |  |
| 761 |  |  [Near-Optimal Adversarial Reinforcement Learning with Switching Costs](https://openreview.net/forum?id=i9ogGQHYbkY) |  | 0 | Switching costs, which capture the costs for changing policies, are regarded as a critical metric in reinforcement learning (RL), in addition to the standard metric of losses (or rewards). However, existing studies on switching costs (with a coefficient that is strictly positive and is independent... | Ming Shi, Ness B. Shroff, Yingbin Liang |  |
| 762 |  |  [GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation](https://openreview.net/forum?id=IowKt5rYWsK) |  | 0 | We present the Group Propagation Vision Transformer (GPViT): a novel non- hierarchical (i.e. non-pyramidal) transformer model designed for general visual recognition with high-resolution features. High-resolution features (or tokens) are a natural fit for tasks that involve perceiving fine-grained... | Chenhongyi Yang, Elliot J. Crowley, Jiarui Xu, Shalini De Mello, Xiaolong Wang |  |
| 763 |  |  [Neural Optimal Transport](https://openreview.net/forum?id=d8CBRlWNkqH) |  | 0 | We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs. To justify the usage of neural networks, we prove that they are universal approximators of transport plans between probability distributions. We evaluate the... | Alexander Korotin, Daniil Selikhanovych, Evgeny Burnaev |  |
| 764 |  |  [Dirichlet-based Uncertainty Calibration for Active Domain Adaptation](https://openreview.net/forum?id=4WM4cy42B81) |  | 0 | Active domain adaptation (DA) aims to maximally boost the model adaptation on a new target domain by actively selecting limited target data to annotate, whereas traditional active learning methods may be less effective since they do not consider the domain shift issue. Despite active DA methods... | Chi Harold Liu, Mixue Xie, Rui Zhang, Shuang Li |  |
| 765 |  |  [Accurate Image Restoration with Attention Retractable Transformer](https://openreview.net/forum?id=IloMJ5rqfnt) |  | 0 | Recently, Transformer-based image restoration networks have achieved promising improvements over convolutional neural networks due to parameter-independent global interactions. To lower computational cost, existing works generally limit self-attention computation within non-overlapping windows.... | Jiale Zhang, Jinjin Gu, Linghe Kong, Xin Yuan, Yongbing Zhang, Yulun Zhang |  |
| 766 |  |  [Neural Episodic Control with State Abstraction](https://openreview.net/forum?id=C2fsSj3ZGiU) |  | 0 | Existing Deep Reinforcement Learning (DRL) algorithms suffer from sample inefficiency. Generally, episodic control-based approaches are solutions that leverage highly rewarded past experiences to improve sample efficiency of DRL algorithms. However, previous episodic control-based approaches fail... | Derui Zhu, Jianjun Zhao, Lei Ma, Xiaofei Xie, Yan Song, Yan Zheng, Yingfeng Chen, Yujing Hu, Zhuo Li |  |
| 767 |  |  [The Role of ImageNet Classes in Fréchet Inception Distance](https://openreview.net/forum?id=4oXTQ6m_ws8) |  | 0 | Fréchet Inception Distance (FID) is the primary metric for ranking models in data-driven generative modeling. While remarkably successful, the metric is known to sometimes disagree with human judgement. We investigate a root cause of these discrepancies, and visualize what FID "looks at" in... | Jaakko Lehtinen, Miika Aittala, Tero Karras, Timo Aila, Tuomas Kynkäänniemi |  |
| 768 |  |  [Diffusion Models Already Have A Semantic Latent Space](https://openreview.net/forum?id=pd1P2eUBVfq) |  | 0 | Diffusion models achieve outstanding generative performance in various domains. Despite their great success, they lack semantic latent space which is essential for controlling the generative process. To address the problem, we propose asymmetric reverse process (Asyrp) which discovers the semantic... | Jaeseok Jeong, Mingi Kwon, Youngjung Uh |  |
| 769 |  |  [Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model](https://openreview.net/forum?id=mRieQgMtNTQ) |  | 0 | Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image... | Jian Zhang, Jiwen Yu, Yinhuai Wang |  |
| 770 |  |  [Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities](https://openreview.net/forum?id=CrfhZAsJDsZ) |  | 0 | Discontinuous solutions arise in a large class of hyperbolic and advection-dominated PDEs. This paper investigates, both theoretically and empirically, the operator learning of PDEs with discontinuous solutions. We rigorously prove, in terms of lower approximation bounds, that methods which entail... | Patrik Hadorn, Roberto Molinaro, Samuel Lanthaler, Siddhartha Mishra |  |
| 771 |  |  [Learning Label Encodings for Deep Regression](https://openreview.net/forum?id=k60XE_b0Ix6) |  | 0 | Deep regression networks are widely used to tackle the problem of predicting a continuous value for a given input. Task-specialized approaches for training regression networks have shown significant improvement over generic approaches, such as direct regression. More recently, a generic approach... | Deval Shah, Tor M. Aamodt |  |
| 772 |  |  [Multi-skill Mobile Manipulation for Object Rearrangement](https://openreview.net/forum?id=Z3IClM_bzvP) |  | 0 | We study a modular approach to tackle long-horizon mobile manipulation tasks for object rearrangement, which decomposes a full task into a sequence of subtasks. To tackle the entire task, prior work chains multiple stationary manipulation skills with a point-goal navigation skill, which are learned... | Devendra Singh Chaplot, Hao Su, Jiayuan Gu, Jitendra Malik |  |
| 773 |  |  [Single-shot General Hyper-parameter Optimization for Federated Learning](https://openreview.net/forum?id=3RhuF8foyPW) |  | 0 | We address the problem of hyper-parameter optimization (HPO) for federated learning (FL-HPO). We introduce Federated Loss SuRface Aggregation (FLoRA), a general FL-HPO solution framework that can address use cases of tabular data and any Machine Learning (ML) model including gradient boosting... | Heiko Ludwig, Horst Samulowitz, Nathalie Baracaldo, Parikshit Ram, Theodoros Salonidis, Yi Zhou |  |
| 774 |  |  [Simplicial Embeddings in Self-Supervised Learning and Downstream Classification](https://openreview.net/forum?id=RWtGreRpovS) |  | 0 | Simplicial Embeddings (SEM) are representations learned through self-supervised learning (SSL), wherein a representation is projected into $L$ simplices of $V$ dimensions each using a \texttt{softmax} operation. This procedure conditions the representation onto a constrained space during... | Aaron C. Courville, Ankit Vani, Christos Tsirigotis, Kenji Kawaguchi, Max Schwarzer, Michael Noukhovitch, Samuel Lavoie |  |
| 775 |  |  [Vision Transformer Adapter for Dense Predictions](https://openreview.net/forum?id=plKu2GByCNW) |  | 0 | This work investigates a simple yet powerful dense prediction task adapter for Vision Transformer (ViT). Unlike recently advanced variants that incorporate vision-specific inductive biases into their architectures, the plain ViT suffers inferior performance on dense predictions due to weak prior... | Jifeng Dai, Junjun He, Tong Lu, Wenhai Wang, Yu Qiao, Yuchen Duan, Zhe Chen |  |
| 776 |  |  [Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors](https://openreview.net/forum?id=hVrXUps3LFA) |  | 0 | Domain Adaptation of Black-box Predictors (DABP) aims to learn a model on an unlabeled target domain supervised by a black-box predictor trained on a source domain. It does not require access to both the source-domain data and the predictor parameters, thus addressing the data privacy and... | Jianfei Yang, Jiashi Feng, Kai Wang, Lihua Xie, Xiangyu Peng, Yang You, Zheng Zhu |  |
| 777 |  |  [PLOT: Prompt Learning with Optimal Transport for Vision-Language Models](https://openreview.net/forum?id=zqwryBoXYnh) |  | 0 | With the increasing attention to large vision-language models such as CLIP, there has been a significant amount of effort dedicated to building efficient prompts. Unlike conventional methods of only learning one single prompt, we propose to learn multiple comprehensive prompts to describe diverse... | Guangyi Chen, Kun Zhang, Weiran Yao, Xiangchen Song, Xinyue Li, Yongming Rao |  |
| 778 |  |  [DASHA: Distributed Nonconvex Optimization with Communication Compression and Optimal Oracle Complexity](https://openreview.net/forum?id=VA1YpcNr7ul) |  | 0 | We develop and analyze DASHA: a new family of methods for nonconvex distributed optimization problems. When the local functions at the nodes have a finite-sum or an expectation form, our new methods, DASHA-PAGE, DASHA-MVR and DASHA-SYNC-MVR, improve the theoretical oracle and communication... | Alexander Tyurin, Peter Richtárik |  |
| 779 |  |  [LAVA: Data Valuation without Pre-Specified Learning Algorithms](https://openreview.net/forum?id=JJuP86nBl4q) |  | 0 | Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable... | Feiyang Kang, Hoang Anh Just, Ming Jin, Myeongseob Ko, Ruoxi Jia, Tianhao Wang, Yi Zeng |  |
| 780 |  |  [Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets](https://openreview.net/forum?id=SEh5SfEQtqB) |  | 0 | Distillation-aware Neural Architecture Search (DaNAS) aims to search for an optimal student architecture that obtains the best performance and/or efficiency when distilling the knowledge from a given teacher model. Previous DaNAS methods have mostly tackled the search for the neural architecture... | Hayeon Lee, Minseon Kim, Sohyun An, Sung Ju Hwang |  |
| 781 |  |  [Denoising Diffusion Error Correction Codes](https://openreview.net/forum?id=rLwC0_MG-4w) |  | 0 | Error correction code (ECC) is an integral part of the physical communication layer, ensuring reliable data transfer over noisy channels. Recently, neural decoders have demonstrated their advantage over classical decoding techniques. However, recent state-of-the-art neural decoders suffer from high... | Lior Wolf, Yoni Choukroun |  |
| 782 |  |  [Exploring Active 3D Object Detection from a Generalization Perspective](https://openreview.net/forum?id=2RwXVje1rAh) |  | 0 | To alleviate the high annotation cost in LiDAR-based 3D object detection, active learning is a promising solution that learns to select only a small portion of unlabeled data to annotate, without compromising model performance. Our empirical study, however, suggests that mainstream... | Mahsa Baktashmotlagh, Xin Yu, Yadan Luo, Zhuoxiao Chen, Zi Huang, Zijian Wang |  |
| 783 |  |  [Neuro-Symbolic Procedural Planning with Commonsense Prompting](https://openreview.net/forum?id=iOc57X9KM54) |  | 0 | Procedural planning aims to implement complex high-level goals by decomposition into simpler low-level steps. Although procedural planning is a basic skill set for humans in daily life, it remains a challenge for large language models (LLMs) that lack a deep understanding of the cause-effect... | Miguel P. Eckstein, Wanrong Zhu, Weixi Feng, Wenda Xu, William Yang Wang, Xin Eric Wang, Yujie Lu |  |
| 784 |  |  [Generative Augmented Flow Networks](https://openreview.net/forum?id=urF_CBK5XC0) |  | 0 | The Generative Flow Network is a probabilistic framework where an agent learns a stochastic policy for object generation, such that the probability of generating an object is proportional to a given reward function. Its effectiveness has been shown in discovering high-quality and diverse solutions,... | Aaron C. Courville, Dinghuai Zhang, Ling Pan, Longbo Huang, Yoshua Bengio |  |
| 785 |  |  [The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning](https://openreview.net/forum?id=rvsbw2YthH_) |  | 0 | Pre-training representations (a.k.a. foundation models) has recently become a prevalent learning paradigm, where one first pre-trains a representation using large-scale unlabeled data, and then learns simple predictors on top of the representation using small labeled data from the downstream tasks.... | Jayaram Raghuram, Jiefeng Chen, Kunyang Li, Somesh Jha, Xi Wu, Yingyu Liang, Zhenmei Shi |  |
| 786 |  |  [CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural Representations](https://openreview.net/forum?id=FUORz1tG8Og) |  | 0 | The long runtime of high-fidelity partial differential equation (PDE) solvers makes them unsuitable for time-critical applications. We propose to accelerate PDE solvers using reduced-order modeling (ROM). Whereas prior ROM approaches reduce the dimensionality of discretized vector fields, our... | Dong Heon Cho, Eitan Grinspun, G. A. Pershing, Henrique Teles Maia, Jinxu Xiang, Kevin T. Carlberg, Maurizio M. Chiaramonte, Peter Yichen Chen, Yue Chang |  |
| 787 |  |  [Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language](https://openreview.net/forum?id=G2Q2Mh3avow) |  | 0 | We investigate how multimodal prompt engineering can use language as the intermediate representation to combine complementary knowledge from different pretrained (potentially multimodal) language models for a variety of tasks. This approach is both distinct from and complementary to the dominant... | Adrian Wong, Andy Zeng, Aveek Purohit, Brian Ichter, Federico Tombari, Johnny Lee, Krzysztof Marcin Choromanski, Maria Attarian, Michael S. Ryoo, Pete Florence, Stefan Welker, Vikas Sindhwani, Vincent Vanhoucke |  |
| 788 |  |  [Multi-lingual Evaluation of Code Generation Models](https://openreview.net/forum?id=Bo7eeXm6An8) |  | 0 | We present two new benchmarks, MBXP and Multilingual HumanEval, designed to evaluate code completion models in over 10 programming languages. These datasets are generated using a conversion framework that transpiles prompts and test cases from the original MBPP and HumanEval datasets into the... | Arash Farahani, Ben Athiwaratkun, Haifeng Qian, Hantian Ding, Ming Tan, Mingyue Shang, Murali Krishna Ramanathan, Nathan Fulton, Qing Sun, Ramesh Nallapati, Robert Giaquinto, Sanjay Krishna Gouda, Shiqi Wang, Siddhartha Jain, Sujan Kumar Gonugondla, Varun Kumar, Wasi Uddin Ahmad, Xiaopeng Li, Yuchen Tian, Zijian Wang |  |
| 789 |  |  [GRACE-C: Generalized Rate Agnostic Causal Estimation via Constraints](https://openreview.net/forum?id=B_pCIsX8KL_) |  | 0 | Graphical structures estimated by causal learning algorithms from time series data can provide highly misleading causal information if the causal timescale of the generating process fails to match the measurement timescale of the data. Existing algorithms provide limited resources to respond to... | David Danks, Mohammadsajad Abavisani, Sergey M. Plis |  |
| 790 |  |  [Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs](https://openreview.net/forum?id=KwmPfARgOTD) |  | 0 | Despite their widespread success in various domains, Transformer networks have yet to perform well across datasets in the domain of 3D atomistic graphs such as molecules even when 3D-related inductive biases like translational invariance and rotational equivariance are considered. In this paper, we... | Tess E. Smidt, YiLun Liao |  |
| 791 |  |  [MPCFORMER: Fast, Performant and Provate Transformer Inference with MPC](https://openreview.net/forum?id=CWmvjOEhgH-) |  | 0 | Enabling private inference is crucial for many cloud inference services that are based on Transformer models. However, existing private inference solutions can increase the inference latency by more than 60$\times$ or significantly compromise the inference quality. In this paper, we design the... | Dacheng Li, Eric P. Xing, Han Guo, Hao Zhang, Hongyi Wang, Rulin Shao |  |
| 792 |  |  [Disparate Impact in Differential Privacy from Gradient Misalignment](https://openreview.net/forum?id=qLOaeRvteqbx) |  | 0 | As machine learning becomes more widespread throughout society, aspects including data privacy and fairness must be carefully considered, and are crucial for deployment in highly regulated industries. Unfortunately, the application of privacy enhancing technologies can worsen unfair tendencies in... | Atiyeh Ashari Ghomi, Jesse C. Cresswell, Maria S. Esipova, Yaqiao Luo |  |
| 793 |  |  [TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second](https://openreview.net/forum?id=cp5PvcI6w8_) |  | 0 | We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN is fully entailed in the weights of our network, which accepts... | Frank Hutter, Katharina Eggensperger, Noah Hollmann, Samuel Müller |  |
| 794 |  |  [Human Motion Diffusion Model](https://openreview.net/forum?id=SJ1kSyO2jwu) |  | 0 | Natural and expressive human motion generation is the holy grail of computer animation. It is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either... | Amit Haim Bermano, Brian Gordon, Daniel CohenOr, Guy Tevet, Sigal Raab, Yonatan Shafir |  |
| 795 |  |  [Visual Recognition with Deep Nearest Centroids](https://openreview.net/forum?id=CsKwavjr7A) |  | 0 | We devise deep nearest centroids (DNC), a conceptually elegant yet surprisingly effective network for large-scale visual recognition, by revisiting Nearest Centroids, one of the most classic and simple classifiers. Current deep models learn the classifier in a fully parametric manner, ignoring the... | Cheng Han, Dongfang Liu, Tianfei Zhou, Wenguan Wang |  |
| 796 |  |  [Continuous PDE Dynamics Forecasting with Implicit Neural Representations](https://openreview.net/forum?id=B73niNjbPs) |  | 0 | Effective data-driven PDE forecasting methods often rely on fixed spatial and / or temporal discretizations. This raises limitations in real-world applications like weather prediction where flexible extrapolation at arbitrary spatiotemporal locations is required. We address this problem by... | Alain Rakotomamonjy, JeanYves Franceschi, Matthieu Kirchmeyer, Patrick Gallinari, Yuan Yin |  |
| 797 |  |  [No Reason for No Supervision: Improved Generalization in Supervised Models](https://openreview.net/forum?id=3Y5Uhf5KgGK) |  | 0 | We consider the problem of training a deep neural network on a given classification task, e.g., ImageNet-1K (IN1K), so that it excels at both the training task as well as at other (future) transfer tasks. These two seemingly contradictory properties impose a trade-off between improving the model’s... | Diane Larlus, Karteek Alahari, Mert Bülent Sariyildiz, Yannis Kalantidis |  |
| 798 |  |  [EVA3D: Compositional 3D Human Generation from 2D Image Collections](https://openreview.net/forum?id=g7U9jD_2CUr) |  | 0 | Inverse graphics aims to recover 3D models from 2D observations. Utilizing differentiable rendering, recent 3D-aware generative models have shown impressive results of rigid object generation using 2D images. However, it remains challenging to generate articulated objects, like human bodies, due to... | Fangzhou Hong, Liang Pan, Yushi Lan, Zhaoxi Chen, Ziwei Liu |  |
| 799 |  |  [Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction](https://openreview.net/forum?id=DSy8tP4WctmZ) |  | 0 | Neural surface reconstruction aims to reconstruct accurate 3D surfaces based on multi-view images. Previous methods based on neural volume rendering mostly train a fully implicit model with MLPs, which typically require hours of training for a single scene. Recent efforts explore the explicit... | Christian Theobalt, Dahua Lin, Jiaqi Wang, Tong Wu, Xingang Pan, Xudong Xu, Ziwei Liu |  |
| 800 |  |  [Generating Diverse Cooperative Agents by Learning Incompatible Policies](https://openreview.net/forum?id=UkU05GOH7_6) |  | 0 | Training a robust cooperative agent requires diverse partner agents. However, obtaining those agents is difficult. Previous works aim to learn diverse behaviors by changing the state-action distribution of agents. But, without information about the task's goal, the diversified agents are not guided... | Nat Dilokthanakul, Poramate Manoonpong, Rujikorn Charakorn |  |
| 801 |  |  [PEER: A Collaborative Language Model](https://openreview.net/forum?id=KbYevcLjnc) |  | 0 | Textual content is often the output of a collaborative writing process: We start with an initial draft, ask for suggestions, and repeatedly make changes. Agnostic of this process, today’s language models are trained to generate only the final result. As a consequence, they lack several abilities... | Christoforos Nalmpantis, Edouard Grave, Fabio Petroni, Gautier Izacard, Jane A. Yu, Patrick Lewis, Qingfei You, Sebastian Riedel, Timo Schick, Zhengbao Jiang |  |
| 802 |  |  [ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation](https://openreview.net/forum?id=GMRodZ8OlVr) |  | 0 | Text-guided 3D shape generation remains challenging due to the absence of large paired text-shape dataset, the substantial semantic gap between these two modalities, and the structural complexity of 3D shapes. This paper presents a new framework called Image as Stepping Stone (ISS) for the task by... | ChiWing Fu, Peng Dai, Ruihui Li, Xiaojuan Qi, Zhengzhe Liu |  |
| 803 |  |  [STREET: A Multi-Task Structured Reasoning and Explanation Benchmark](https://openreview.net/forum?id=1C_kSW1-k0) |  | 0 | We introduce STREET, a unified multi-task and multi-domain natural language reasoning and explanation benchmark. Unlike most existing question-answering (QA) datasets, we expect models to not only answer questions, but also produce step-by-step structured explanations describing how premises in the... | Anjelica Ramos, Bing Xiang, Dan Roth, Danilo Neves Ribeiro, Deguang Kong, George Karypis, Henghui Zhu, Juliette Burger, Rui Dong, Shen Wang, William Yang Wang, Xiaofei Ma, Zhiheng Huang |  |
| 804 |  |  [Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-Incremental Learning](https://openreview.net/forum?id=y5W8tpojhtJ) |  | 0 | Few-shot class-incremental learning (FSCIL) has been a challenging problem as only a few training samples are accessible for each novel class in the new sessions. Finetuning the backbone or adjusting the classifier prototypes trained in the prior sessions would inevitably cause a misalignment... | Dacheng Tao, Haobo Yuan, Philip H. S. Torr, Xiangtai Li, Yibo Yang, Zhouchen Lin |  |
| 805 |  |  [Neural Networks and the Chomsky Hierarchy](https://openreview.net/forum?id=WbxHAzkeQcn) |  | 0 | Reliable generalization lies at the heart of safe ML and AI. However, understanding when and how neural networks generalize remains one of the most important unsolved problems in the field. In this work, we conduct an extensive empirical study (20'910 models, 15 tasks) to investigate whether... | Anian Ruoss, Chris Cundy, Elliot Catt, Grégoire Delétang, Joel Veness, Jordi GrauMoya, Li Kevin Wenliang, Marcus Hutter, Pedro A. Ortega, Shane Legg, Tim Genewein |  |
| 806 |  |  [Neural ePDOs: Spatially Adaptive Equivariant Partial Differential Operator Based Networks](https://openreview.net/forum?id=D1Iqfm7WTkk) |  | 0 | Endowing deep learning models with symmetry priors can lead to a considerable performance improvement. As an interesting bridge between physics and deep learning, the equivariant partial differential operators (PDOs) have drawn much researchers' attention recently. However, to ensure the PDOs... | Lingshen He, Yibo Yang, Yuxuan Chen, Zhengyang Shen, Zhouchen Lin |  |
| 807 |  |  [An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion](https://openreview.net/forum?id=NAQvF08TcyG) |  | 0 | Text-to-image models offer unprecedented freedom to guide creation through natural language. Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes. In other words, we ask: how can... | Amit Haim Bermano, Daniel CohenOr, Gal Chechik, Or Patashnik, Rinon Gal, Yuval Alaluf, Yuval Atzmon |  |
| 808 |  |  [Is Synthetic Data from Generative Models Ready for Image Recognition?](https://openreview.net/forum?id=nUmCcZ5RKF) |  | 0 | Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. Though the results are astonishing to human eyes, how applicable these generated images are for recognition tasks remains under-explored. In this work, we extensively study... | Chuhui Xue, Philip H. S. Torr, Ruifei He, Shuyang Sun, Song Bai, Wenqing Zhang, Xiaojuan Qi, Xin Yu |  |
| 809 |  |  [MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction](https://openreview.net/forum?id=k7p_YAO7yE) |  | 0 | High-definition (HD) map provides abundant and precise environmental information of the driving scene, serving as a fundamental and indispensable component for planning in autonomous driving system. We present MapTR, a structured end-to-end Transformer for efficient online vectorized HD map... | Bencheng Liao, Chang Huang, Qian Zhang, Shaoyu Chen, Tianheng Cheng, Wenyu Liu, Xinggang Wang |  |
| 810 |  |  [Minimax Optimal Kernel Operator Learning via Multilevel Training](https://openreview.net/forum?id=zEn1BhaNYsC) |  | 0 | Learning mappings between infinite-dimensional function spaces have achieved empirical success in many disciplines of machine learning, including generative modeling, functional data analysis, causal inference, and multi-agent reinforcement learning. In this paper, we study the statistical limit of... | Jikai Jin, José H. Blanchet, Lexing Ying, Yiping Lu |  |
| 811 |  |  [Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling](https://openreview.net/forum?id=NRxydtWup1S) |  | 0 | We identify and overcome two key obstacles in extending the success of BERT-style pre-training, or masked image modeling, to convolutional networks (convnets): (i) convolution operation cannot handle irregular, randomly masked input images; (ii) the single-scale nature of BERT pre-training is... | Chen Lin, Keyu Tian, Liwei Wang, Qishuai Diao, Yi Jiang, Zehuan Yuan |  |
| 812 |  |  [Quantifying and Mitigating the Impact of Label Errors on Model Disparity Metrics](https://openreview.net/forum?id=RUzSobdYy0V) |  | 0 | Errors in labels obtained via human annotation adversely affect a trained model's performance. Existing approaches propose ways to mitigate the effect of label error on a model's downstream accuracy, yet little is known about its impact on a model's group-based disparity... | Bobbie Chern, Bowen Yu, Julius Adebayo, Melissa Hall |  |
| 813 |  |  [Factorized Fourier Neural Operators](https://openreview.net/forum?id=tmIiMPl4IPa) |  | 0 | We propose the Factorized Fourier Neural Operator (F-FNO), a learning-based approach for simulating partial differential equations (PDEs). Starting from a recently proposed Fourier representation of flow fields, the F-FNO bridges the performance gap between pure machine learning approaches to that... | Alasdair Tran, Alexander Patrick Mathews, Cheng Soon Ong, Lexing Xie |  |
| 814 |  |  [DFPC: Data flow driven pruning of coupled channels without data](https://openreview.net/forum?id=mhnHqRqcjYU) |  | 0 | Modern, multi-branched neural network architectures often possess complex interconnections between layers, which we call coupled channels (CCs). Structured pruning of CCs in these multi-branch networks is an under-researched problem, as most existing works are typically designed for pruning... | Chaitanya Murti, Chiranjib Bhattacharyya, Tanay Narshana |  |
| 815 |  |  [TVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning](https://openreview.net/forum?id=sZI1Oj9KBKy) |  | 0 | Achieving structured, data-free sparsity of deep neural networks (DNNs) remains an open area of research. In this work, we address the challenge of pruning filters without access to the original training set or loss function. We propose the discriminative filters hypothesis, that well-trained... | Chaitanya Murti, Chiranjib Bhattacharyya, Tanay Narshana |  |
| 816 |  |  [Finding Actual Descent Directions for Adversarial Training](https://openreview.net/forum?id=I3HCE7Ro78H) |  | 0 | Adversarial Training using a strong first-order adversary (PGD) is the gold standard for training Deep Neural Networks that are robust to adversarial examples. We show that, contrary to the general understanding of the method, the gradient at an optimal adversarial example may increase, rather than... | Fabian Latorre, Igor Krawczuk, Leello Tadesse Dadi, Thomas Pethick, Volkan Cevher |  |
| 817 |  |  [Learning Continuous Normalizing Flows For Faster Convergence To Target Distribution via Ascent Regularizations](https://openreview.net/forum?id=6iEoTr-jeB7) |  | 0 | Normalizing flows (NFs) have been shown to be advantageous in modeling complex distributions and improving sampling efficiency for unbiased sampling. In this work, we propose a new class of continuous NFs, ascent continuous normalizing flows (ACNFs), that makes a base distribution converge faster... | Mårten Björkman, Shuangshuang Chen, Sihao Ding, Yiannis Karayiannidis |  |
| 818 |  |  [Softened Symbol Grounding for Neuro-symbolic Systems](https://openreview.net/forum?id=HTJE5Krui0g) |  | 0 | Neuro-symbolic learning generally consists of two separated worlds, i.e., neural network training and symbolic constraint solving, whose success hinges on symbol grounding, a fundamental problem in AI. This paper presents a novel, softened symbol grounding process, bridging the gap between the two... | Chun Cao, Jian Lü, Jingwei Xu, Taolue Chen, Xiaoxing Ma, Yuan Yao, Zenan Li |  |
| 819 |  |  [Mini-batch k-means terminates within O(d/ϵ) iterations](https://openreview.net/forum?id=jREF4bkfi_S) |  | 0 | We answer the question: "Does \emph{local} progress (on batches) imply \emph{global} progress (on the entire dataset) for mini-batch $k$-means?". Specifically, we consider mini-batch $k$-means which terminates only when the improvement in the quality of the clustering on the sampled batch is below... | Gregory Schwartzman |  |
| 820 |  |  [Learning Uncertainty for Unknown Domains with Zero-Target-Assumption](https://openreview.net/forum?id=pWVASryOyFw) |  | 0 | We introduce our Maximum-Entropy Rewarded Reinforcement Learning (MERRL) framework that selects training data for more accurate Natural Language Processing (NLP). Because conventional data selection methods select training samples based on the test domain knowledge and not on real life data, they... | Hassan Sajjad, Jia Xu, Yu Yu |  |
| 821 |  |  [Transformer-based model for symbolic regression via joint supervised learning](https://openreview.net/forum?id=ULzyv9M1j5) |  | 0 | Symbolic regression (SR) is an important technique for discovering hidden mathematical expressions from observed data. Transformer-based approaches have been widely used for machine translation due to their high performance, and are recently highly expected to be used for SR. They input the data... | Jingyi Liu, Lina Yu, Linjun Sun, Min Wu, Songsong Tian, Weijun Li, Wenqiang Li, Yanjie Li |  |
| 822 |  |  [QAID: Question Answering Inspired Few-shot Intent Detection](https://openreview.net/forum?id=gNI4_85Cyve) |  | 0 | Intent detection with semantically similar fine-grained intents is a challenging task. To address it, we reformulate intent detection as a question-answering retrieval task by treating utterances and intent names as questions and answers. To that end, we utilize a question-answering retrieval... | Asaf Yehudai, Boaz Carmeli, Doron Cohen, Koren Lazar, Matan Vetzler, Yosi Mass |  |
| 823 |  |  [Solving stochastic weak Minty variational inequalities without increasing batch size](https://openreview.net/forum?id=ejR4E1jaH9k) |  | 0 | This paper introduces a family of stochastic extragradient-type algorithms for a class of nonconvex-nonconcave problems characterized by the weak Minty variational inequality (MVI). Unlike existing results on extragradient methods in the monotone setting, employing diminishing stepsizes is no... | Olivier Fercoq, Panagiotis Patrinos, Puya Latafat, Thomas Pethick, Volkan Cevher |  |
| 824 |  |  [Curriculum-based Co-design of Morphology and Control of Voxel-based Soft Robots](https://openreview.net/forum?id=r9fX833CsuN) |  | 0 | Co-design of morphology and control of a Voxel-based Soft Robot (VSR) is challenging due to the notorious bi-level optimization. In this paper, we present a Curriculum-based Co-design (CuCo) method for learning to design and control VSRs through an easy-to-difficult process. Specifically, we expand... | Haobo Fu, Qiang Fu, Shuang Wu, Tiantian Zhang, Xueqian Wang, Yongzhe Chang, Yuxing Wang |  |
| 825 |  |  [WiNeRT: Towards Neural Ray Tracing for Wireless Channel Modelling and Differentiable Simulations](https://openreview.net/forum?id=tPKKXeW33YU) |  | 0 | In this paper, we work towards a neural surrogate to model wireless electro-magnetic propagation effects in indoor environments. Such neural surrogates provide a fast, differentiable, and continuous representation of the environment and enables end-to-end optimization for downstream tasks (e.g.,... | Arash Behboodi, Hao Ye, Joseph Soriaga, Kumar Pratik, Shreya Kadambi, Tribhuvanesh Orekondy |  |
| 826 |  |  [LS-IQ: Implicit Reward Regularization for Inverse Reinforcement Learning](https://openreview.net/forum?id=o3Q4m8jg4BR) |  | 0 | Recent methods for imitation learning directly learn a $Q$-function using an implicit reward formulation rather than an explicit reward function. However, these methods generally require implicit reward regularization to improve stability and often mistreat absorbing states. Previous works show... | Davide Tateo, Firas AlHafez, Guoping Zhao, Jan Peters, Oleg Arenz |  |
| 827 |  |  [Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning](https://openreview.net/forum?id=oJpVVGXu9i) |  | 0 | Repeated parameter sharing in federated learning causes significant information leakage about private data, thus defeating its main purpose: data privacy. Mitigating the risk of this information leakage, using state of the art differentially private algorithms, also does not come for free.... | Anmin Kang, Hamed Hassani, Jiayuan Ye, Reza Shokri, Zebang Shen |  |
| 828 |  |  [EquiMod: An Equivariance Module to Improve Visual Instance Discrimination](https://openreview.net/forum?id=eDLwjKmtYFt) |  | 0 | Recent self-supervised visual representation methods are closing the gap with supervised learning performance. Most of these successful methods rely on maximizing the similarity between embeddings of related synthetic inputs created through data augmentations. This can be seen as a task that... | Alexandre Devillers, Mathieu Lefort |  |
| 829 |  |  [Task-Aware Information Routing from Common Representation Space in Lifelong Learning](https://openreview.net/forum?id=-M0TNnyWFT5) |  | 0 | Intelligent systems deployed in the real world suffer from catastrophic forgetting when exposed to a sequence of tasks. Humans, on the other hand, acquire, consolidate, and transfer knowledge between tasks that rarely interfere with the consolidated knowledge. Accompanied by self-regulated... | Bahram Zonooz, Elahe Arani, Prashant Shivaram Bhat |  |
| 830 |  |  [CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code](https://openreview.net/forum?id=htL4UZ344nF) |  | 0 | Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code. This work investigates another important aspect of... | Nadezhda Chirkova, Sergey Troshin |  |
| 831 |  |  [FairGBM: Gradient Boosting with Fairness Constraints](https://openreview.net/forum?id=x-mXzBgCX3a) |  | 0 | Tabular data is prevalent in many high-stakes domains, such as financial services or public policy. Gradient Boosted Decision Trees (GBDT) are popular in these settings due to their scalability, performance, and low training cost. While fairness in these domains is a foremost concern, existing... | André Ferreira Cruz, Catarina G. Belém, João Bravo, Pedro Bizarro, Pedro Saleiro |  |
| 832 |  |  [Online Bias Correction for Task-Free Continual Learning](https://openreview.net/forum?id=18XzeuYZh_) |  | 0 | Task-free continual learning is the machine-learning setting where a model is trained online with data generated by a nonstationary stream. Conventional wisdom suggests that, in this setting, models are trained using an approach called experience replay, where the risk is computed both with respect... | Aristotelis Chrysakis, MarieFrancine Moens |  |
| 833 |  |  [Don't fear the unlabelled: safe semi-supervised learning via debiasing](https://openreview.net/forum?id=TN9gQ4x0Ep3) |  | 0 | Semi-supervised learning (SSL) provides an effective means of leveraging unlabelled data to improve a model’s performance. Even though the domain has received a considerable amount of attention in the past years, most methods present the common drawback of lacking theoretical guarantees. Our... | Hugo Schmutz, Olivier Humbert, PierreAlexandre Mattei |  |
| 834 |  |  [Making Substitute Models More Bayesian Can Enhance Transferability of Adversarial Examples](https://openreview.net/forum?id=bjPPypbLre) |  | 0 | The transferability of adversarial examples across deep neural networks (DNNs) is the crux of many black-box attacks. Many prior efforts have been devoted to improving the transferability via increasing the diversity in inputs of some substitute models. In this paper, by contrast, we opt for the... | Hao Chen, Qizhang Li, Wangmeng Zuo, Yiwen Guo |  |
| 835 |  |  [Cross-Layer Retrospective Retrieving via Layer Attention](https://openreview.net/forum?id=pvgEL1yS3Ql) |  | 0 | More and more evidence has shown that strengthening layer interactions can enhance the representation power of a deep neural network, while self-attention excels at learning interdependencies by retrieving query-activated information. Motivated by this, we devise a cross-layer attention mechanism,... | Guangjian Tian, Guodong Li, Jingyu Zhao, Jintai Chen, Yanwen Fang, Yuxi Cai |  |
| 836 |  |  [Decision S4: Efficient Sequence-Based RL via State Spaces Layers](https://openreview.net/forum?id=kqHkCVS7wbj) |  | 0 | Recently, sequence learning methods have been applied to the problem of off-policy Reinforcement Learning, including the seminal work on Decision Transformers, which employs transformers for this task. Since transformers are parameter-heavy, cannot benefit from history longer than a fixed window... | Eliya Nachmani, Itamar Zimerman, Lior Wolf, Shmuel BarDavid |  |
| 837 |  |  [Unveiling the sampling density in non-uniform geometric graphs](https://openreview.net/forum?id=mnVf1W6ipGm) |  | 0 | A powerful framework for studying graphs is to consider them as geometric graphs: nodes are randomly sampled from an underlying metric space, and any pair of nodes is connected if their distance is less than a specified neighborhood radius. Currently, the literature mostly focuses on uniform... | Aleksandar Bojchevski, Gitta Kutyniok, Raffaele Paolino, Ron Levie, Stephan Günnemann |  |
| 838 |  |  [Boosting Causal Discovery via Adaptive Sample Reweighting](https://openreview.net/forum?id=LNpMtk15AS4) |  | 0 | Under stringent model type and variable distribution assumptions, score-based causal discovery methods learn the directed acyclic graph (DAG) from observational data by evaluating candidate graphs over an averaged score function. Despite the great success in low-dimensional linear systems, it has... | An Zhang, Fangfu Liu, TatSeng Chua, Wenchang Ma, Xiang Wang, Zhibo Cai |  |
| 839 |  |  [Iterative Circuit Repair Against Formal Specifications](https://openreview.net/forum?id=SEcSahl0Ql) |  | 0 | We present a deep learning approach for repairing sequential circuits against formal specifications given in linear-time temporal logic (LTL). Given a defective circuit and its formal specification, we train Transformer models to output circuits that satisfy the corresponding specification. We... | Bernd Finkbeiner, Christopher Hahn, Frederik Schmitt, Matthias Cosler |  |
| 840 |  |  [Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study](https://openreview.net/forum?id=UazgYBMS9-W) |  | 0 | Large pre-trained language models have helped to achieve state of the art on a variety of NLP tasks, nevertheless, they still suffer from forgetting when incrementally learning a series of sequential tasks. To alleviate this problem, recent works propose several models enhanced by sparse experience... | Dongyan Zhao, Mingxu Tao, Yansong Feng |  |
| 841 |  |  [Behavior Proximal Policy Optimization](https://openreview.net/forum?id=3c13LptpIph) |  | 0 | Offline reinforcement learning (RL) is a challenging setting where existing off-policy actor-critic methods perform poorly due to overestimating of out-of-distribution state-action pairs. Thus, various additional augmentations are proposed to keep the learned policy close to the offline dataset (or... | Donglin Wang, Jinxin Liu, Kun Lei, Yilang Guo, Zifeng Zhuang |  |
| 842 |  |  [Actionable Neural Representations: Grid Cells from Minimal Constraints](https://openreview.net/forum?id=xfqDe72zh41) |  | 0 | To afford flexible behaviour, the brain must build internal representations that mirror the structure of variables in the external world. For example, 2D space obeys rules: the same set of actions combine in the same way everywhere (step north, then south, and you won't have moved, wherever you... | James C. R. Whittington, Peter E. Latham, Tim E. J. Behrens, Will Dorrell |  |
| 843 |  |  [Mole-BERT: Rethinking Pre-training Graph Neural Networks for Molecules](https://openreview.net/forum?id=jevY-DtiZTR) |  | 0 | Recent years have witnessed the prosperity of pre-training graph neural networks (GNNs) for molecules. Typically, atom types as node attributes are randomly masked, and GNNs are then trained to predict masked types as in AttrMask \citep{hu2020strategies}, following the Masked Language Modeling... | Bozhen Hu, Cheng Tan, Chengshuai Zhao, Jun Xia, Siyuan Li, Stan Z. Li, Yue Liu, Zhangyang Gao |  |
| 844 |  |  [Geometrically regularized autoencoders for non-Euclidean data](https://openreview.net/forum?id=_q7A0m3vXH0) |  | 0 | Regularization is almost {\it de rigueur} when designing autoencoders that are sparse and robust to noise. Given the recent surge of interest in machine learning problems involving non-Euclidean data, in this paper we address the regularization of autoencoders on curved spaces. We show that by... | Cheongjae Jang, Frank C. Park, Yonghyeon Lee, YungKyun Noh |  |
| 845 |  |  [A Message Passing Perspective on Learning Dynamics of Contrastive Learning](https://openreview.net/forum?id=VBTJqqWjxMv) |  | 0 | In recent years, contrastive learning achieves impressive results on self-supervised visual representation learning, but there still lacks a rigorous understanding of its learning dynamics. In this paper, we show that if we cast a contrastive objective equivalently into the feature space, then its... | Jiansheng Yang, Qi Zhang, Tianqi Du, Yifei Wang, Yisen Wang, Zhouchen Lin |  |
| 846 |  |  [Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation](https://openreview.net/forum?id=n1bLgxHW6jW) |  | 0 | Zeroth-order (ZO) optimization, in which the derivative is unavailable, has recently succeeded in many important machine learning applications. Existing algorithms rely on finite difference (FD) methods for derivative estimation and gradient descent (GD)-based approaches for optimization. However,... | Arun Verma, Bryan Kian Hsiang Low, Patrick Jaillet, Weicong Sng, Yao Shu, Zhongxiang Dai |  |
| 847 |  |  [Uniform-in-time propagation of chaos for the mean-field gradient Langevin dynamics](https://openreview.net/forum?id=_JScUk9TBUn) |  | 0 | The mean-field Langevin dynamics is characterized by a stochastic differential equation that arises from (noisy) gradient descent on an infinite-width two-layer neural network, which can be viewed as an interacting particle system. In this work, we establish a quantitative weak propagation of chaos... | Atsushi Nitanda, Denny Wu, Taiji Suzuki |  |
| 848 |  |  [Asynchronous Distributed Bilevel Optimization](https://openreview.net/forum?id=_i0-12XqVJZ) |  | 0 | Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches... | Chengtao Jian, Dongjin Song, Kai Yang, Tiancheng Wu, Yang Jiao |  |
| 849 |  |  [Confidence-Based Feature Imputation for Graphs with Partially Known Features](https://openreview.net/forum?id=YPKBIILy-Kt) |  | 0 | This paper investigates a missing feature imputation problem for graph learning tasks. Several methods have previously addressed learning tasks on graphs with missing features. However, in cases of high rates of missing features, they were unable to avoid significant performance degradation. To... | Daeho Um, Jin Young Choi, Jiwoong Park, Seulki Park |  |
| 850 |  |  [LiftedCL: Lifting Contrastive Learning for Human-Centric Perception](https://openreview.net/forum?id=WHlt5tLz12T) |  | 0 | Human-centric perception targets for understanding human body pose, shape and segmentation. Pre-training the model on large-scale datasets and fine-tuning it on specific tasks has become a well-established paradigm in human-centric perception. Recently, self-supervised learning methods have... | Qiang Li, Wankou Yang, Xiaofeng Wang, Ziwei Chen |  |
| 851 |  |  [Individual Privacy Accounting with Gaussian Differential Privacy](https://openreview.net/forum?id=JmC_Tld3v-f) |  | 0 | Individual privacy accounting enables bounding differential privacy (DP) loss individually for each participant involved in the analysis. This can be informative as often the individual privacy losses are considerably smaller than those indicated by the DP bounds that are based on considering... | Antti Honkela, Antti Koskela, Marlon Tobaben |  |
| 852 |  |  [Evolving Populations of Diverse RL Agents with MAP-Elites](https://openreview.net/forum?id=CBfYffLqWqb) |  | 0 | Quality Diversity (QD) has emerged as a powerful alternative optimization paradigm that aims at generating large and diverse collections of solutions, notably with its flagship algorithm MAP-ELITES (ME) which evolves solutions through mutations and crossovers. While very effective for some... | Arthur Flajolet, Thomas Pierrot |  |
| 853 |  |  [Gray-Box Gaussian Processes for Automated Reinforcement Learning](https://openreview.net/forum?id=rmoMvptXK7M) |  | 0 | Despite having achieved spectacular milestones in an array of important real-world applications, most Reinforcement Learning (RL) methods are very brittle concerning their hyperparameters. Notwithstanding the crucial importance of setting the hyperparameters in training state-of-the-art agents, the... | André Biedenkapp, Frank Hutter, Gresa Shala, Josif Grabocka |  |
| 854 |  |  [Protein Sequence and Structure Co-Design with Equivariant Translation](https://openreview.net/forum?id=pRCMXcfdihq) |  | 0 | Proteins are macromolecules that perform essential functions in all living organisms. Designing novel proteins with specific structures and desired functions has been a long-standing challenge in the field of bioengineering. Existing approaches generate both protein sequence and structure using... | Bozitao Zhong, Chence Shi, Chuanrui Wang, Jian Tang, Jiarui Lu |  |
| 855 |  |  [Learning in temporally structured environments](https://openreview.net/forum?id=z0_V5O9cmNw) |  | 0 | Natural environments have temporal structure at multiple timescales. This property is reflected in biological learning and memory but typically not in machine learning systems. We advance a multiscale learning method in which each weight in a neural network is decomposed as a sum of subweights with... | David Mayo, Gamaleldin Fathy Elsayed, Katherine L. Hermann, Matt Jones, Mengye Ren, Michael Curtis Mozer, Tyler R. Scott |  |
| 856 |  |  [RandProx: Primal-Dual Optimization Algorithms with Randomized Proximal Updates](https://openreview.net/forum?id=cB4N3G5udUS) |  | 0 | Proximal splitting algorithms are well suited to solving large-scale nonsmooth optimization problems, in particular those arising in machine learning. We propose a new primal–dual algorithm, in which the dual update is randomized; equivalently, the proximity operator of one of the function in the... | Laurent Condat, Peter Richtárik |  |
| 857 |  |  [Preserving Pre-trained Features Helps Calibrate Fine-tuned Language Models](https://openreview.net/forum?id=NI7StoWHJPT) |  | 0 | Large pre-trained language models (PLMs) have demonstrated strong performance on natural language understanding (NLU) tasks through fine-tuning. However, fine-tuned models still suffer from overconfident predictions, especially in out-of-domain settings. In this paper, we tackle the problem of... | Guande He, Jianfei Chen, Jun Zhu |  |
| 858 |  |  [Fast Nonlinear Vector Quantile Regression](https://openreview.net/forum?id=UxqUgchwXkK) |  | 0 | $$ \newcommand{\rvar}[1]{\mathrm {#1}} \newcommand{\rvec}[1]{\boldsymbol{\mathrm{#1}}} $$ Quantile regression (QR) is a powerful tool for estimating one or more conditional quantiles of a target variable $\rvar{Y}$ given explanatory features $\rvec{X}$. A limitation of QR is that it is only defined... | Alexander M. Bronstein, Aviv A. Rosenberg, Sanketh Vedula, Yaniv Romano |  |
| 859 |  |  [Leveraging Large Language Models for Multiple Choice Question Answering](https://openreview.net/forum?id=yKbprarjc5B) |  | 0 | While large language models (LLMs) like GPT-3 have achieved impressive results on multiple choice question answering (MCQA) tasks in the zero, one, and few-shot settings, they generally lag behind the MCQA state of the art (SOTA). MCQA tasks have traditionally been presented to LLMs like cloze... | David Wingate, Joshua Robinson |  |
| 860 |  |  [Regression with Label Differential Privacy](https://openreview.net/forum?id=h9O0wsmL-cT) |  | 0 | We study the task of training regression models with the guarantee of _label_ differential privacy (DP). Based on a global prior distribution of label values, which could be obtained privately, we derive a label DP randomization mechanism that is optimal under a given regression loss function. We... | Avinash V. Varadarajan, Badih Ghazi, Chiyuan Zhang, Ethan Leeman, Pasin Manurangsi, Pritish Kamath, Ravi Kumar |  |
| 861 |  |  [Hierarchical Abstraction for Combinatorial Generalization in Object Rearrangement](https://openreview.net/forum?id=fGG6vHp3W9W) |  | 0 | Object rearrangement is a challenge for embodied agents because solving these tasks requires generalizing across a combinatorially large set of configurations of entities and their locations. Worse, the representations of these entities are unknown and must be inferred from sensory percepts. We... | Alyssa L. Dayan, Amy Zhang, Franziska Meier, Michael Chang, Sergey Levine, Thomas L. Griffiths |  |
| 862 |  |  [Selective Frequency Network for Image Restoration](https://openreview.net/forum?id=tyZ1ChGZIKO) |  | 0 | Image restoration aims to reconstruct the latent sharp image from its corrupted counterpart. Besides dealing with this long-standing task in the spatial domain, a few approaches seek solutions in the frequency domain in consideration of the large discrepancy between spectra of sharp/degraded image... | Alois Knoll, Kai Huang, Wenqi Ren, Xiaochun Cao, Xinwei Gao, Yi Tao, Yuning Cui, Zhenshan Bing |  |
| 863 |  |  [Improving Differentiable Neural Architecture Search by Encouraging Transferability](https://openreview.net/forum?id=Tl8OmiibP99) |  | 0 | Differentiable neural architecture search methods are increasingly popular due to their computational efficiency. However, these methods have unsatisfactory generalizability and stability. Their searched architectures are often degenerate with a dominant number of skip connections and perform... | Parth Sheth, Pengtao Xie |  |
| 864 |  |  [MA-BERT: Towards Matrix Arithmetic-only BERT Inference by Eliminating Complex Non-Linear Functions](https://openreview.net/forum?id=HtAfbHa7LAL) |  | 0 | Due to their superior results, Transformer-based models such as BERT have become de facto standards in many Natural Language Processing (NLP) applications. However, the intensive use of complex non-linear functions within the Transformer architecture impairs its computing efficiency and complicates... | Cheng Liu, Neo Wei Ming, Rick Siow Mong Goh, Tao Luo, Zhehui Wang |  |
| 865 |  |  [Efficient Certified Training and Robustness Verification of Neural ODEs](https://openreview.net/forum?id=KyoVpYvWWnK) |  | 0 | Neural Ordinary Differential Equations (NODEs) are a novel neural architecture, built around initial value problems with learned dynamics which are solved during inference. Thought to be inherently more robust against adversarial perturbations, they were recently shown to be vulnerable to strong... | Marc Fischer, Mark Niklas Müller, Martin T. Vechev, Mustafa Zeqiri |  |
| 866 |  |  [Arbitrary Virtual Try-on Network: Characteristics Representation and Trade-off between Body and Clothing](https://openreview.net/forum?id=d8mr8lKIZ3n) |  | 0 | Deep learning based virtual try-on system has achieved some encouraging progress recently, but there still remain several big challenges that need to be solved, such as trying on arbitrary clothes of all types, trying on the clothes from one category to another and generating image-realistic... | Jicong Fan, Mingbo Zhao, Shuicheng Yan, Yang Lou, Yu Liu, Zhao Zhang |  |
| 867 |  |  [UL2: Unifying Language Learning Paradigms](https://openreview.net/forum?id=6ruVLB727MC) |  | 0 | Existing pre-trained models are generally geared towards a particular class of problems. To date, there seems to be still no consensus on what the right architecture and pre-training setup should be. This paper presents a unified framework for pre-training models that are universally effective... | Dara Bahri, Denny Zhou, Donald Metzler, Huaixiu Steven Zheng, Hyung Won Chung, Jason Wei, Mostafa Dehghani, Neil Houlsby, Tal Schuster, Vinh Q. Tran, Xavier Garcia, Xuezhi Wang, Yi Tay |  |
| 868 |  |  [CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement](https://openreview.net/forum?id=SVl1w1u3InX) |  | 0 | There are sequence generation tasks where the best order to generate the target sequence is not left-to-right. For example, an answer to the Sudoku game, a structured code like s-expression, and even a logical natural language answer where the analysis may be generated after the decision. We define... | Dongmei Zhang, Hongwei Han, Mengyu Zhou, Shi Han, Xiu Li |  |
| 869 |  |  [Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts](https://openreview.net/forum?id=2QzNuaRHn4Z) |  | 0 | Training machine learning models robust to distribution shifts is critical for real-world applications. Some robust training algorithms (e.g., Group DRO) specialize to group shifts and require group information on all training points. Other methods (e.g., CVaR DRO) that do not need group... | Aditi Raghunathan, Amrith Setlur, Benjamin Eysenbach, Chelsea Finn, Don Kurian Dennis, Sergey Levine, Virginia Smith |  |
| 870 |  |  [Feature selection and low test error in shallow low-rotation ReLU networks](https://openreview.net/forum?id=swEskiem99) |  | 0 | This work establishes low test error of gradient flow (GF) and stochastic gradient descent (SGD) on two-layer ReLU networks with standard initialization scale, in three regimes where key sets of weights rotate little (either naturally due to GF and SGD, or due to an artificial constraint), and... | Matus Telgarsky |  |
| 871 |  |  [Backpropagation through Combinatorial Algorithms: Identity with Projection Works](https://openreview.net/forum?id=JZMR727O29) |  | 0 | Embedding discrete solvers as differentiable layers has given modern deep learning architectures combinatorial expressivity and discrete reasoning capabilities. The derivative of these solvers is zero or undefined, therefore a meaningful replacement is crucial for effective gradient-based learning.... | Anselm Paulus, Georg Martius, Marin Vlastelica, Subham Sekhar Sahoo, Volodymyr Kuleshov, Vít Musil |  |
| 872 |  |  [Coupled Multiwavelet Operator Learning for Coupled Differential Equations](https://openreview.net/forum?id=kIo_C6QmMOM) |  | 0 | Coupled partial differential equations (PDEs) are key tasks in modeling the complex dynamics of many physical processes. Recently, neural operators have shown the ability to solve PDEs by learning the integral kernel directly in Fourier/Wavelet space, so the difficulty of solving the coupled PDEs... | Chenzhong Yin, Defu Cao, Gaurav Gupta, Gengshuo Liu, Paul Bogdan, Radu Balan, Ruochen Yang, Xiongye Xiao |  |
| 873 |  |  [Mid-Vision Feedback](https://openreview.net/forum?id=4oLK1_k71Tz) |  | 0 | Feedback plays a prominent role in biological vision, where perception is modulated based on agents' evolving expectations and world model. We introduce a novel mechanism which modulates perception based on high level categorical expectations: Mid-Vision Feedback (MVF). MVF associates high level... | Cornelia Fermüller, Eadom Dessalene, Michael Maynord, Yiannis Aloimonos |  |
| 874 |  |  [Safe Reinforcement Learning From Pixels Using a Stochastic Latent Representation](https://openreview.net/forum?id=b39dQt_uffW) |  | 0 | We address the problem of safe reinforcement learning from pixel observations. Inherent challenges in such settings are (1) a trade-off between reward optimization and adhering to safety constraints, (2) partial observability, and (3) high-dimensional observations. We formalize the problem in a... | Nils Jansen, Tal Kachman, Thiago D. Simão, Yannick Hogewind |  |
| 875 |  |  [TrojText: Test-time Invisible Textual Trojan Insertion](https://openreview.net/forum?id=ja4Lpp5mqc2) |  | 0 | In Natural Language Processing (NLP), intelligent neuron models can be susceptible to textual Trojan attacks. Such attacks occur when Trojan models behave normally for standard inputs but generate malicious output for inputs that contain a specific trigger. Syntactic-structure triggers, which are... | Bo Feng, Qian Lou, Yepeng Liu |  |
| 876 |  |  [Improved Training of Physics-Informed Neural Networks Using Energy-Based Priors: a Study on Electrical Impedance Tomography](https://openreview.net/forum?id=zqkfJA6R1-r) |  | 0 | Physics-informed neural networks (PINNs) are attracting significant attention for solving partial differential equation (PDE) based inverse problems, including electrical impedance tomography (EIT). EIT is non-linear and especially its inverse problem is highly ill-posed. Therefore, successful... | Akarsh Pokkunuru, Anuj Abhishek, Pedram Rooshenas, Taufiquar Khan, Thilo Strauss |  |
| 877 |  |  [Ordered GNN: Ordering Message Passing to Deal with Heterophily and Over-smoothing](https://openreview.net/forum?id=wKPmPBHSnT6) |  | 0 | Most graph neural networks follow the message passing mechanism. However, it faces the over-smoothing problem when multiple times of message passing is applied to a graph, causing indistinguishable node representations and prevents the model to effectively learn dependencies between farther-away... | Chenghu Zhou, Xinbing Wang, Yunchong Song, Zhouhan Lin |  |
| 878 |  |  [Sparse Distributed Memory is a Continual Learner](https://openreview.net/forum?id=JknGeelZJpHP) |  | 0 | Continual learning is a problem for artificial neural networks that their biological counterparts are adept at solving. Building on work using Sparse Distributed Memory (SDM) to connect a core neural circuit with the powerful Transformer model, we create a modified Multi-Layered Perceptron (MLP)... | Deepak Singh, Dmitry Krotov, Gabriel Kreiman, Trenton Bricken, Xander Davies |  |
| 879 |  |  [FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning](https://openreview.net/forum?id=Xo2E217_M4n) |  | 0 | Federated Learning (FL) is a distributed learning paradigm that enables different parties to train a model together for high quality and strong privacy protection. In this scenario, individual participants may get compromised and perform backdoor attacks by poisoning the data (or gradients).... | Guangyu Shen, Guanhong Tao, Kaiyuan Zhang, PinYu Chen, Qiuling Xu, Shengwei An, Shiqing Ma, Shiwei Feng, Siyuan Cheng, Xiangyu Zhang, Yingqi Liu |  |
| 880 |  |  [UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining](https://openreview.net/forum?id=kXwdL1cWOAi) |  | 0 | Pretrained multilingual large language models have typically used heuristic temperature-based sampling to balance between different languages. However previous work has not systematically evaluated the efficacy of different pretraining language distributions across model scales. In this paper, we... | Adam Roberts, Hyung Won Chung, Noah Constant, Orhan Firat, Sharan Narang, Xavier Garcia, Yi Tay |  |
| 881 |  |  [GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks](https://openreview.net/forum?id=rqq6Dh8t4d) |  | 0 | Recently, Graph Neural Networks (GNNs) have significantly advanced the performance of machine learning tasks on graphs. However, this technological breakthrough makes people wonder: how does a GNN make such decisions, and can we trust its prediction with high confidence? When it comes to some... | HanWei Shen, Xiaoqi Wang |  |
| 882 |  |  [Rethinking Symbolic Regression: Morphology and Adaptability in the Context of Evolutionary Algorithms](https://openreview.net/forum?id=OPGy07PojsZ) |  | 0 | Symbolic Regression (SR) is the well-studied problem of finding closed-form analytical expressions that describe the relationship between variables in a measurement dataset. In this paper, we rethink SR from two perspectives: morphology and adaptability. Morphology: Current SR algorithms typically... | Kei Sen Fong, Mehul Motani, Shelvia Wongso |  |
| 883 |  |  [On Pre-training Language Model for Antibody](https://openreview.net/forum?id=zaq4LV55xHl) |  | 0 | Antibodies are vital proteins offering robust protection for the human body from pathogens. The development of general protein and antibody-specific pre-trained language models both facilitate antibody prediction tasks. However, there have been limited studies that comprehensively explore the... | Danqing Wang, Fei Ye, Hao Zhou |  |
| 884 |  |  [Learning to reason over visual objects](https://openreview.net/forum?id=uR6x8Be7o_M) |  | 0 | A core component of human intelligence is the ability to identify abstract patterns inherent in complex, high-dimensional perceptual data, as exemplified by visual reasoning tasks such as Raven’s Progressive Matrices (RPM). Motivated by the goal of designing AI systems with this capacity, recent... | Jonathan Cohen, Shanka Subhra Mondal, Taylor Whittington Webb |  |
| 885 |  |  [Imitating Graph-Based Planning with Goal-Conditioned Policies](https://openreview.net/forum?id=6lUEy1J5R7p) |  | 0 | Recently, graph-based planning algorithms have gained much attention to solve goal-conditioned reinforcement learning (RL) tasks: they provide a sequence of subgoals to reach the target-goal, and the agents learn to execute subgoal-conditioned policies. However, the sample-efficiency of such RL... | Jinwoo Shin, Junsu Kim, Kyunghwan Son, Sungsoo Ahn, Younggyo Seo |  |
| 886 |  |  [A theoretical study of inductive biases in contrastive learning](https://openreview.net/forum?id=AuEgNlEAmed) |  | 0 | Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of [Saunshi et al.] argues that the model architecture --- a component largely ignored by... | Jeff Z. HaoChen, Tengyu Ma |  |
| 887 |  |  [Combinatorial Pure Exploration of Causal Bandits](https://openreview.net/forum?id=pBBsrPzq7aF) |  | 0 | The combinatorial pure exploration of causal bandits is the following online learning task: given a causal graph with unknown causal inference distributions, in each round we choose a subset of variables to intervene or do no intervention, and observe the random outcomes of all random variables,... | Nuoya Xiong, Wei Chen |  |
| 888 |  |  [Computational Language Acquisition with Theory of Mind](https://openreview.net/forum?id=C2ulri4duIs) |  | 0 | Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in... | Andy Liu, Emmy Liu, Graham Neubig, Hao Zhu, Yonatan Bisk |  |
| 889 |  |  [Pareto Invariant Risk Minimization: Towards Mitigating the Optimization Dilemma in Out-of-Distribution Generalization](https://openreview.net/forum?id=esFxSb_0pSL) |  | 0 | Recently, there has been a growing surge of interest in enabling machine learning systems to generalize well to Out-of-Distribution (OOD) data. Most efforts are devoted to advancing optimization objectives that regularize models to capture the underlying invariance; however, there often are... | Binghui Xie, Bingzhe Wu, Bo Han, Han Yang, James Cheng, Kaili Ma, Kaiwen Zhou, Peilin Zhao, Yatao Bian, Yonggang Zhang, Yongqiang Chen |  |
| 890 |  |  [What Makes Convolutional Models Great on Long Sequence Modeling?](https://openreview.net/forum?id=TGJSPbRpJX-) |  | 0 | Convolutional models have been widely used in multiple domains. However, most existing models only use local convolution, making the model unable to handle long-range dependencies efficiently. Attention overcomes this problem by aggregating global information based on the pair-wise attention score... | Debadeepta Dey, Deming Chen, Tianle Cai, Yi Zhang, Yuhong Li |  |
| 891 |  |  [Editing models with task arithmetic](https://openreview.net/forum?id=6t0Kwf8-jrj) |  | 0 | Changing how pre-trained models behave---e.g., improving their performance on a downstream task or mitigating biases learned during pre-training---is a common practice when developing machine learning systems. In this work, we propose a new paradigm for steering the behavior of neural networks,... | Ali Farhadi, Gabriel Ilharco, Hannaneh Hajishirzi, Ludwig Schmidt, Marco Túlio Ribeiro, Mitchell Wortsman |  |
| 892 |  |  [Neural Systematic Binder](https://openreview.net/forum?id=ZPHE4fht19t) |  | 0 | The key to high-level cognition is believed to be the ability to systematically manipulate and compose knowledge pieces. While token-like structured knowledge representations are naturally provided in text, it is elusive how to obtain them for unstructured modalities such as scene images. In this... | Gautam Singh, Sungjin Ahn, Yeongbin Kim |  |
| 893 |  |  [Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis](https://openreview.net/forum?id=PUIqjT4rzq7) |  | 0 | Large-scale diffusion models have achieved state-of-the-art results on text-to-image synthesis (T2I) tasks. Despite their ability to generate high-quality yet creative images, we observe that attribution-binding and compositional capabilities are still considered major challenging issues,... | Arjun R. Akula, Pradyumna Narayana, Sugato Basu, TsuJui Fu, Varun Jampani, Weixi Feng, William Yang Wang, Xin Eric Wang, Xuehai He |  |
| 894 |  |  [Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories](https://openreview.net/forum?id=ipflrGaf7ry) |  | 0 | In this paper, we evaluate and improve the generalization performance for reinforcement learning (RL) agents on the set of \`\`controllable'' states, where good policies exist on these states to achieve the goal. An RL agent that generally masters a task should reach its goal starting from any... | ChoJui Hsieh, Huan Zhang, LiCheng Lan |  |
| 895 |  |  [CktGNN: Circuit Graph Neural Network for Electronic Design Automation](https://openreview.net/forum?id=NE2911Kq1sp) |  | 0 | The electronic design automation of analog circuits has been a longstanding challenge in the integrated circuit field due to the huge design space and complex design trade-offs among circuit specifications. In the past decades, intensive research efforts have only been paid to automate the... | Dacheng Tao, Muhan Zhang, Weidong Cao, Xuan Zhang, Yixin Chen, Zehao Dong |  |
| 896 |  |  [Specformer: Spectral Graph Neural Networks Meet Transformers](https://openreview.net/forum?id=0pdSt3oyJa1) |  | 0 | Spectral graph neural networks (GNNs) learn graph representations via spectral-domain graph convolutions. However, most existing spectral graph filters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a single filtered value, thus ignoring the global pattern of the spectrum.... | Chuan Shi, Deyu Bo, Lele Wang, Renjie Liao |  |
| 897 |  |  [Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought](https://openreview.net/forum?id=qFVVBzXxR2V) |  | 0 | Large language models (LLMs) have shown remarkable reasoning capabilities given chain-of-thought prompts (examples with intermediate reasoning steps). Existing benchmarks measure reasoning ability indirectly, by evaluating accuracy on downstream tasks such as mathematical reasoning. However, it is... | Abulhair Saparov, He He |  |
| 898 |  |  [Recursive Time Series Data Augmentation](https://openreview.net/forum?id=5lgD4vU-l24s) |  | 0 | Time series observations can be seen as realizations of an underlying dynamical system governed by rules that we typically do not know. For time series learning tasks we create our model using available data. Training on available realizations, where data is limited, often induces severe... | Amine Mohamed Aboussalah, Cheng Chi, ChiGuhn Lee, MinJae Kwon, Raj G. Patel |  |
| 899 |  |  [Auto-Encoding Goodness of Fit](https://openreview.net/forum?id=JjCAdMUlu9v) |  | 0 | For generative autoencoders to learn a meaningful latent representation for data generation, a careful balance must be achieved between reconstruction error and how close the distribution in the latent space is to the prior. However, this balance is challenging to achieve due to a lack of criteria... | Aaron Palmer, Derek Aguiar, Jinbo Bi, Zhiyi Chi |  |
| 900 |  |  [Understanding the Covariance Structure of Convolutional Filters](https://openreview.net/forum?id=WGApODQvwRg) |  | 0 | Neural network weights are typically initialized at random from univariate distributions, controlling just the variance of individual weights even in highly-structured operations like convolutions. Recent ViT-inspired convolutional networks such as ConvMixer and ConvNeXt use large-kernel depthwise... | Asher Trockman, Devin Willmott, J. Zico Kolter |  |
| 901 |  |  [Masked Distillation with Receptive Tokens](https://openreview.net/forum?id=mWRngkvIki3) |  | 0 | Distilling from the feature maps can be fairly effective for dense prediction tasks since both the feature discriminability and localization information can be well transferred. However, not every pixel contributes equally to the performance, and a good student should learn from what really matters... | Chang Xu, Chen Qian, Fei Wang, Jian Cao, Shan You, Tao Huang, Yuan Zhang |  |
| 902 |  |  [Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms](https://openreview.net/forum?id=ctmLBs8lITa) |  | 0 | This work studies the threats of adversarial attack on multivariate probabilistic forecasting models and viable defense mechanisms. Our studies discover a new attack pattern that negatively impact the forecasting of a target time series via making strategic, sparse (imperceptible) modifications to... | Hilaf Hasson, Linbo Liu, Luke Huan, Trong Nghia Hoang, Youngsuk Park |  |
| 903 |  |  [TextShield: Beyond Successfully Detecting Adversarial Sentences in text classification](https://openreview.net/forum?id=xIWfWvKM7aQ) |  | 0 | Adversarial attack serves as a major challenge for neural network models in NLP, which precludes the model's deployment in safety-critical applications. A recent line of work, detection-based defense, aims to distinguish adversarial sentences from benign ones. However, {the core limitation of... | Haiyun Jiang, Lingfeng Shen, Ying Chen, Ze Zhang |  |
| 904 |  |  [Efficient Deep Reinforcement Learning Requires Regulating Overfitting](https://openreview.net/forum?id=14-kr46GvP-) |  | 0 | Deep reinforcement learning algorithms that learn policies by trial-and-error must learn from limited amounts of data collected by actively interacting with the environment. While many prior works have shown that proper regularization techniques are crucial for enabling data-efficient RL, a general... | Aviral Kumar, Ilya Kostrikov, Qiyang Li, Sergey Levine |  |
| 905 |  |  [Offline Reinforcement Learning with Differentiable Function Approximation is Provably Efficient](https://openreview.net/forum?id=6jfbOWzWTcE) |  | 0 | Offline reinforcement learning, which aims at optimizing sequential decision-making strategies with historical data, has been extensively applied in real-life applications. State-Of-The-Art algorithms usually leverage powerful function approximators (e.g. neural networks) to alleviate the sample... | Mengdi Wang, Ming Yin, YuXiang Wang |  |
| 906 |  |  [Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks](https://openreview.net/forum?id=oGDKSt9JrZi) |  | 0 | Auxiliary tasks improve the representations learned by deep reinforcement learning agents. Analytically, their effect is reasonably well-understood; in practice, how-ever, their primary use remains in support of a main learning objective, rather than as a method for learning representations. This... | Charline Le Lan, Jesse Farebrother, Joshua Greaves, Marc G. Bellemare, Pablo Samuel Castro, Rishabh Agarwal, Ross Goroshin |  |
| 907 |  |  [Robust Algorithms on Adaptive Inputs from Bounded Adversaries](https://openreview.net/forum?id=I29Kt0RwChs) |  | 0 | We study dynamic algorithms robust to adaptive input generated from sources with bounded capabilities, such as sparsity or limited interaction. For example, we consider robust linear algebraic algorithms when the updates to the input are sparse but given by an adversary with access to a query... | David P. Woodruff, Fred Zhang, Qiuyi Zhang, Samson Zhou, Sandeep Silwal, Yeshwanth Cherapanamjeri |  |
| 908 |  |  [Chasing All-Round Graph Representation Robustness: Model, Training, and Optimization](https://openreview.net/forum?id=7jk5gWjC18M) |  | 0 | Graph Neural Networks (GNNs) have achieved state-of-the-art results on a variety of graph learning tasks, however, it has been demonstrated that they are vulnerable to adversarial attacks, raising serious security concerns. A lot of studies have been developed to train GNNs in a noisy environment... | Chunhui Zhang, Chuxu Zhang, Mingxuan Ju, Nitesh V. Chawla, Yanfang Ye, Yijun Tian, Zheyuan Liu |  |
| 909 |  |  [On Representing Mixed-Integer Linear Programs by Graph Neural Networks](https://openreview.net/forum?id=4gc3MGZra1d) |  | 0 | While Mixed-integer linear programming (MILP) is NP-hard in general, practical MILP has received roughly 100--fold speedup in the past twenty years. Still, many classes of MILPs quickly become unsolvable as their sizes increase, motivating researchers to seek new acceleration techniques for MILPs.... | Jialin Liu, Wotao Yin, Xinshang Wang, Ziang Chen |  |
| 910 |  |  [On the Importance and Applicability of Pre-Training for Federated Learning](https://openreview.net/forum?id=fWWFv--P0xP) |  | 0 | Pre-training is prevalent in nowadays deep learning to improve the learned model's performance. However, in the literature on federated learning (FL), neural networks are mostly initialized with random weights. These attract our interest in conducting a systematic study to explore pre-training for... | ChengHao Tu, HanWei Shen, HongYou Chen, WeiLun Chao, Ziwei Li |  |
| 911 |  |  [Simple initialization and parametrization of sinusoidal networks via their kernel bandwidth](https://openreview.net/forum?id=yVqC6gCNf4d) |  | 0 | Neural networks with sinusoidal activations have been proposed as an alternative to networks with traditional activation functions. Despite their promise, particularly for learning implicit models, their training behavior is not yet fully understood, leading to a number of empirical design choices... | Filipe de Avila BelbutePeres, J. Zico Kolter |  |
| 912 |  |  [The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation](https://openreview.net/forum?id=29V3AWjVAFi) |  | 0 | Heterogeneity of data distributed across clients limits the performance of global models trained through federated learning, especially in the settings with highly imbalanced class distributions of local datasets. In recent years, personalized federated learning (pFL) has emerged as a potential... | Chianing Wang, Haris Vikalo, Huancheng Chen |  |
| 913 |  |  [Over-Training with Mixup May Hurt Generalization](https://openreview.net/forum?id=JmkjrlVE-DG) |  | 0 | Mixup, which creates synthetic training instances by linearly interpolating random sample pairs, is a simple and yet effective regularization technique to boost the performance of deep models trained with SGD. In this work, we report a previously unobserved phenomenon in Mixup raining: on a number... | Hongyu Guo, Yongyi Mao, Ziqiao Wang, Zixuan Liu |  |
| 914 |  |  [HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention](https://openreview.net/forum?id=0eTTKOOOQkV) |  | 0 | The success of large-scale contrastive vision-language pretraining (CLIP) has benefited both visual recognition and multimodal content understanding. The concise design brings CLIP the advantage in inference efficiency against other vision-language models with heavier cross-attention fusion layers,... | Jianbo Yuan, Shijie Geng, Yongfeng Zhang, Yu Tian, Yuxiao Chen |  |
| 915 |  |  [Quantile Risk Control: A Flexible Framework for Bounding the Probability of High-Loss Predictions](https://openreview.net/forum?id=p6jsTidUkPx) |  | 0 | Rigorous guarantees about the performance of predictive algorithms are necessary in order to ensure their responsible use. Previous work has largely focused on bounding the expected loss of a predictor, but this is not sufficient in many risk-sensitive applications where the distribution of errors... | Jake Snell, Richard S. Zemel, Thomas P. Zollo, Toniann Pitassi, Zhun Deng |  |
| 916 |  |  [The Tilted Variational Autoencoder: Improving Out-of-Distribution Detection](https://openreview.net/forum?id=YlGsTZODyjz) |  | 0 | A problem with using the Gaussian distribution as a prior for the variational autoencoder (VAE) is that the set on which Gaussians have high probability density is small as the latent dimension increases. This is an issue because VAEs try to attain both a high likelihood with respect to a prior... | Griffin Floto, Mihai Nica, Stefan Kremer |  |
| 917 |  |  [Stateful Active Facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning](https://openreview.net/forum?id=B4maZQLLW0_) |  | 0 | In cooperative multi-agent reinforcement learning, a team of agents works together to achieve a common goal. Different environments or tasks may require varying degrees of coordination among agents in order to achieve the goal in an optimal way. The nature of coordination will depend on properties... | Anirudh Goyal, Cristian Meo, Dianbo Liu, Michael Curtis Mozer, Nicolas Heess, Oussama Boussif, Tianmin Shu, Vedant Shah, Yoshua Bengio |  |
| 918 |  |  [Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward](https://openreview.net/forum?id=NDWl9qcUpvy) |  | 0 | We propose Structured Exploration with Achievements (SEA), a multi-stage reinforcement learning algorithm designed for achievement-based environments, a particular type of environment with an internal achievement set. SEA first uses offline data to learn a representation of the known achievements... | Animesh Garg, Zihan Zhou |  |
| 919 |  |  [PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales](https://openreview.net/forum?id=WBXbRs63oVu) |  | 0 | Neural language models (LMs) have achieved impressive results on various language-based reasoning tasks by utilizing latent knowledge encoded in their own pretrained parameters. To make this reasoning process more explicit, recent works retrieve a rationalizing LM's internal knowledge by training... | Aaron Chan, Filip Ilievski, Muhao Chen, Peifeng Wang, Xiang Ren |  |
| 920 |  |  [Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods](https://openreview.net/forum?id=6doXHqwMayf) |  | 0 | While deep learning has outperformed other methods for various tasks, theoretical frameworks that explain its reason have not been fully established. We investigate the excess risk of two-layer ReLU neural networks in a teacher-student regression model, in which a student network learns an unknown... | Shunta Akiyama, Taiji Suzuki |  |
| 921 |  |  [Linearly Mapping from Image to Text Space](https://openreview.net/forum?id=8tYRqb05pVn) |  | 0 | The extent to which text-only language models (LMs) learn to represent the physical, non-linguistic world is an open question. Prior work has shown that pretrained LMs can be taught to \`\`understand'' visual inputs when the models' parameters are updated on image captioning tasks. We test a... | Carsten Eickhoff, Ellie Pavlick, Jack Merullo, Louis Castricato |  |
| 922 |  |  [Characterizing intrinsic compositionality in transformers with Tree Projections](https://openreview.net/forum?id=sAOOeI878Ns) |  | 0 | When trained on language data, do transformers learn some arbitrary computation that utilizes the full capacity of the architecture or do they learn a simpler, tree-like computation, hypothesized to underlie compositional meaning systems like human languages? There is an apparent tension between... | Christopher D. Manning, Jacob Andreas, Pratyusha Sharma, Shikhar Murty |  |
| 923 |  |  [Augmentation Component Analysis: Modeling Similarity via the Augmentation Overlaps](https://openreview.net/forum?id=5vM51iamNeL) |  | 0 | Self-supervised learning aims to learn a embedding space where semantically similar samples are close. Contrastive learning methods pull views of samples together and push different samples away, which utilizes semantic invariance of augmentation but ignores the relationship between samples. To... | DeChuan Zhan, HanJia Ye, Lu Han |  |
| 924 |  |  [Replicable Bandits](https://openreview.net/forum?id=gcD2UtCGMc2) |  | 0 | In this paper, we introduce the notion of replicable policies in the context of stochastic bandits, one of the canonical problems in interactive learning. A policy in the bandit environment is called replicable if it pulls, with high probability, the exact same sequence of arms in two different and... | Alkis Kalavasis, Amin Karbasi, Andreas Krause, Grigoris Velegkas, Hossein Esfandiari, Vahab Mirrokni |  |
| 925 |  |  [Neural Bregman Divergences for Distance Learning](https://openreview.net/forum?id=nJ3Vx78Nf7p) |  | 0 | Many metric learning tasks, such as triplet learning, nearest neighbor retrieval, and visualization, are treated primarily as embedding tasks where the ultimate metric is some variant of the Euclidean distance (e.g., cosine or Mahalanobis), and the algorithm must learn to embed points into the... | Edward Raff, Francis Ferraro, Fred Lu |  |
| 926 |  |  [Bias Propagation in Federated Learning](https://openreview.net/forum?id=V7CYzdruWdm) |  | 0 | We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and... | Hongyan Chang, Reza Shokri |  |
| 927 |  |  [Causal Confusion and Reward Misidentification in Preference-Based Reward Learning](https://openreview.net/forum?id=R0Xxvr_X3ZA) |  | 0 | Learning policies via preference-based reward learning is an increasingly popular method for customizing agent behavior, but has been shown anecdotally to be prone to spurious correlations and reward hacking behaviors. While much prior work focuses on causal confusion in reinforcement learning and... | Anca D. Dragan, Daniel S. Brown, Jeremy Tien, Jerry ZhiYang He, Zackory Erickson |  |
| 928 |  |  [UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph](https://openreview.net/forum?id=Z63RvyAZ2Vh) |  | 0 | Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the answer entities that are multiple hops away from the topic entities mentioned in a natural language question on a large-scale Knowledge Graph (KG). To cope with the vast search space, existing work usually adopts a two-stage... | JiRong Wen, Jinhao Jiang, Kun Zhou, Xin Zhao |  |
| 929 |  |  [Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games](https://openreview.net/forum?id=bRwBpKrNzF7) |  | 0 | Multi-Agent Reinforcement Learning (MARL)---where multiple agents learn to interact in a shared dynamic environment---permeates across a wide range of critical applications. While there has been substantial progress on understanding the global convergence of policy optimization methods in... | Lin Xiao, Shicong Cen, Simon Shaolei Du, Yuejie Chi |  |
| 930 |  |  [Memorization Capacity of Neural Networks with Conditional Computation](https://openreview.net/forum?id=rB3zRN0lBYr) |  | 0 | Many empirical studies have demonstrated the performance benefits of conditional computation in neural networks, including reduced inference time and power consumption. We study the fundamental limits of neural conditional computation from the perspective of memorization capacity. For Rectified... | Erdem Koyuncu |  |
| 931 |  |  [Weighted Clock Logic Point Process](https://openreview.net/forum?id=YfUICnZMwk7) |  | 0 | Datasets involving multivariate event streams are prevalent in numerous applications. We present a novel framework for modeling temporal point processes called clock logic neural networks (CLNN) which learn weighted clock logic (wCL) formulas as interpretable temporal rules by which some events... | Achille Fokoue, Anak Agung Julius, Debarun Bhattacharjya, Ronny Luss, Ruixuan Yan, Tengfei Ma, Yunshi Wen |  |
| 932 |  |  [Simple Emergent Action Representations from Multi-Task Policy Training](https://openreview.net/forum?id=NUl0ylt7SM) |  | 0 | The low-level sensory and motor signals in deep reinforcement learning, which exist in high-dimensional spaces such as image observations or motor torques, are inherently challenging to understand or utilize directly for downstream tasks. While sensory representations have been extensively studied,... | Huazhe Xu, Pu Hua, Yubei Chen |  |
| 933 |  |  [Interaction-Based Disentanglement of Entities for Object-Centric World Models](https://openreview.net/forum?id=JQc2VowqCzz) |  | 0 | Perceiving the world compositionally in terms of space and time is essential to understanding object dynamics and solving downstream tasks. Object-centric learning using generative models has improved in its ability to learn distinct representations of individual objects and predict their... | Akihiro Nakano, Masahiro Suzuki, Yutaka Matsuo |  |
| 934 |  |  [Neural Image-based Avatars: Generalizable Radiance Fields for Human Avatar Modeling](https://openreview.net/forum?id=-ng-FXFlzgK) |  | 0 | We present a method that enables synthesizing novel views and novel poses of arbitrary human performers from sparse multi-view images. A key ingredient of our method is a hybrid appearance blending module that combines the advantages of the implicit body NeRF representation and image-based... | Dahun Kim, Duygu Ceylan, Henry Fuchs, Youngjoong Kwon |  |
| 935 |  |  [Federated Neural Bandits](https://openreview.net/forum?id=38m4h8HcNRL) |  | 0 | Recent works on neural contextual bandits have achieved compelling performances due to their ability to leverage the strong representation power of neural networks (NNs) for reward prediction. Many applications of contextual bandits involve multiple agents who collaborate without sharing raw... | Arun Verma, Bryan Kian Hsiang Low, Flint Xiaofeng Fan, Patrick Jaillet, Yao Shu, Zhongxiang Dai |  |
| 936 |  |  [Compositional Task Representations for Large Language Models](https://openreview.net/forum?id=6axIMJA7ME3) |  | 0 | Large language models have shown a remarkable cross-task generalization ability. Most prior work assumed that prompts effectively extract knowledge from language models to facilitate generalization to new tasks. This perspective led to numerous studies on improving prompts. In contrast, we... | Chonghua Liao, Hanwei Xu, Nan Shao, Yanan Zheng, Zefan Cai, Zhilin Yang |  |
| 937 |  |  [REPAIR: REnormalizing Permuted Activations for Interpolation Repair](https://openreview.net/forum?id=gU5sJ6ZggcX) |  | 0 | In this paper we empirically investigate the conjecture from Entezari et al. (2021) which states that if permutation invariance is taken into account, then there should be no loss barrier to the linear interpolation between SGD solutions. We conduct our investigation using standard computer vision... | Behnam Neyshabur, Hanie Sedghi, Keller Jordan, Olga Saukh, Rahim Entezari |  |
| 938 |  |  [Diffusion-GAN: Training GANs with Diffusion](https://openreview.net/forum?id=HZf7UbpWHuA) |  | 0 | Generative adversarial networks (GANs) are challenging to train stably, and a promising remedy of injecting instance noise into the discriminator input has not been very effective in practice. In this paper, we propose Diffusion-GAN, a novel GAN framework that leverages a forward diffusion chain to... | Huangjie Zheng, Mingyuan Zhou, Pengcheng He, Weizhu Chen, Zhendong Wang |  |
| 939 |  |  [Mind the Pool: Convolutional Neural Networks Can Overfit Input Size](https://openreview.net/forum?id=cWmtUcsYC3V) |  | 0 | We demonstrate how convolutional neural networks can overfit the input size: The accuracy drops significantly when using certain sizes, compared with favorable ones. This issue is inherent to pooling arithmetic, with standard downsampling layers playing a major role in favoring certain input sizes... | Bilal Alsallakh, David Yan, Narine Kokhlikyan, Orion ReblitzRichardson, Pamela Bhattacharya, Vivek Miglani |  |
| 940 |  |  [Reparameterization through Spatial Gradient Scaling](https://openreview.net/forum?id=Kpdewuy7RU6) |  | 0 | Reparameterization aims to improve the generalization of deep neural networks by transforming a convolution operation into equivalent multi-branched structures during training. However, there exists a gap in understanding how reparameterization may change and benefit learning processes for neural... | Alexander Detkov, Di Niu, Jialin Zhang, Mohammad Salameh, Muhammad Fetrat Qharabagh, Robin Luwei, Shangling Jui |  |
| 941 |  |  [Unsupervised Learning for Combinatorial Optimization Needs Meta Learning](https://openreview.net/forum?id=-ENYHCE8zBp) |  | 0 | A general framework of unsupervised learning for combinatorial optimization (CO) is to train a neural network whose output gives a problem solution by directly optimizing the CO objective. Albeit with some advantages over traditional solvers, current frameworks optimize an averaged performance over... | Haoyu Peter Wang, Pan Li |  |
| 942 |  |  [Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models](https://openreview.net/forum?id=r0BrY4BiEXO) |  | 0 | Privacy is a central tenet of Federated learning (FL), in which a central server trains models without centralizing user data. However, gradient updates used in FL can leak user information. While the most industrial uses of FL are for text applications (e.g. keystroke prediction), the majority of... | Jonas Geiping, Liam H. Fowl, Micah Goldblum, Steven Reich, Tom Goldstein, Wojciech Czaja, Yuxin Wen |  |
| 943 |  |  [Adaptive Optimization in the ∞-Width Limit](https://openreview.net/forum?id=zgVDqw9ZUES) |  | 0 | Recent works have developed detailed understanding of large neural networks' behaviors via their infinite-width limits, e.g., the neural tangent kernel (NTK) and the feature learning ($\mu$) limits. These theories were developed for stochastic gradient descent. Yet, in practice, all large NN are... | Etai Littwin, Greg Yang |  |
| 944 |  |  [Broken Neural Scaling Laws](https://openreview.net/forum?id=sckjveqlCZ) |  | 0 | We present a smoothly broken power law functional form (referred to by us as a broken neural scaling law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training,... | David Krueger, Ethan Caballero, Irina Rish, Kshitij Gupta |  |
| 945 |  |  [Avoiding spurious correlations via logit correction](https://openreview.net/forum?id=5BaqCFVh5qL) |  | 0 | Empirical studies suggest that machine learning models trained with empirical risk minimization (ERM) often rely on attributes that may be spuriously correlated with the class labels. Such models typically lead to poor performance during inference for data lacking such correlations. In this work,... | Carlos FernandezGranda, Nitesh Sekhar, Prateek Singhal, Sheng Liu, Xu Zhang, Yue Wu |  |
| 946 |  |  [Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-Free RL](https://openreview.net/forum?id=wNUgn1n6esQ) |  | 0 | Reward-free reinforcement learning (RF-RL), a recently introduced RL paradigm, relies on random action-taking to explore the unknown environment without any reward feedback information. While the primary goal of the exploration phase in RF-RL is to reduce the uncertainty in the estimated model with... | Jing Yang, Ruiquan Huang, Yingbin Liang |  |
| 947 |  |  [Diffusion-based Image Translation using disentangled style and content representation](https://openreview.net/forum?id=Nayau9fwXU) |  | 0 | Diffusion-based image translation guided by semantic texts or a single target image has enabled flexible style transfer which is not limited to the specific domains. Unfortunately, due to the stochastic nature of diffusion models, it is often difficult to maintain the original content of the image... | Gihyun Kwon, Jong Chul Ye |  |
| 948 |  |  [Implicit Regularization for Group Sparsity](https://openreview.net/forum?id=d7Q0vVfJ0wO) |  | 0 | We study the implicit regularization of gradient descent towards structured sparsity via a novel neural reparameterization, which we call a diagonally grouped linear neural network. We show the following intriguing property of our reparameterization: gradient descent over the squared regression... | Chinmay Hegde, Jiangyuan Li, Raymond K. W. Wong, Thanh Van Nguyen |  |
| 949 |  |  [Large Language Models are Human-Level Prompt Engineers](https://openreview.net/forum?id=92gvk82DE-) |  | 0 | By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted... | Andrei Ioan Muresanu, Harris Chan, Jimmy Ba, Keiran Paster, Silviu Pitis, Yongchao Zhou, Ziwen Han |  |
| 950 |  |  [Pruning Deep Neural Networks from a Sparsity Perspective](https://openreview.net/forum?id=i-DleYh34BM) |  | 0 | In recent years, deep network pruning has attracted significant attention in order to enable the rapid deployment of AI into small devices with computation and memory constraints. Pruning is often achieved by dropping redundant weights, neurons, or layers of a deep network while attempting to... | Enmao Diao, Ganghua Wang, Jiawei Zhang, Jie Ding, Vahid Tarokh, Yuhong Yang |  |
| 951 |  |  [Enhancing Meta Learning via Multi-Objective Soft Improvement Functions](https://openreview.net/forum?id=hCmjBJeGXcu) |  | 0 | Meta-learning tries to leverage information from similar learning tasks. In the commonly-used bilevel optimization formulation, the shared parameter is learned in the outer loop by minimizing the average loss over all tasks. However, the converged solution may be comprised in that it only focuses... | James T. Kwok, Runsheng Yu, Weiyu Chen, Xinrun Wang |  |
| 952 |  |  [Discrete Predictor-Corrector Diffusion Models for Image Synthesis](https://openreview.net/forum?id=VM8batVBWvg) |  | 0 | We introduce Discrete Predictor-Corrector diffusion models (DPC), extending predictor-corrector samplers in Gaussian diffusion models to the discrete case. Predictor-corrector samplers are a class of samplers for diffusion models, which improve on ancestral samplers by correcting the sampling... | Huiwen Chang, Irfan Essa, Jonathan Ho, José Lezama, Lu Jiang, Tim Salimans |  |
| 953 |  |  [OPTQ: Accurate Quantization for Generative Pre-trained Transformers](https://openreview.net/forum?id=tcbBPnfwxS) |  | 0 | Generative Pre-trained Transformer models, known as GPT or OPT, set themselves apart through breakthrough performance across complex language modelling tasks, but also by their extremely high computational and storage costs. Specifically, due to their massive size, even inference for large,... | Dan Alistarh, Elias Frantar, Saleh Ashkboos, Torsten Hoefler |  |
| 954 |  |  [A new characterization of the edge of stability based on a sharpness measure aware of batch gradient distribution](https://openreview.net/forum?id=bH-kCY6LdKg) |  | 0 | For full-batch gradient descent (GD), it has been empirically shown that the sharpness, the top eigenvalue of the Hessian, increases and then hovers above $2/\text{(learning rate)}$, and this is called \`\`the edge of stability'' phenomenon. However, it is unclear why the sharpness is somewhat... | Cheongjae Jang, Sungyoon Lee |  |
| 955 |  |  [SE(3)-Equivariant Attention Networks for Shape Reconstruction in Function Space](https://openreview.net/forum?id=RDy3IbvjMqT) |  | 0 | We propose a method for 3D shape reconstruction from unoriented point clouds. Our method consists of a novel SE(3)-equivariant coordinate-based network (TF-ONet), that parametrizes the occupancy field of the shape and respects the inherent symmetries of the problem. In contrast to previous shape... | Edgar Dobriban, Evangelos Chatzipantazis, Kostas Daniilidis, Stefanos Pertigkiozoglou |  |
| 956 |  |  [Continual Pre-training of Language Models](https://openreview.net/forum?id=m_GDIItaI3o) |  | 0 | Language models (LMs) have been instrumental for the rapid advance of natural language processing. This paper studies continual pre-training of LMs, in particular, continual domain-adaptive pre-training (or continual DAP-training). Existing research has shown that further pre-training an LM using a... | Bing Liu, Gyuhak Kim, Haowei Lin, Tatsuya Konishi, Yijia Shao, Zixuan Ke |  |
| 957 |  |  [Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning](https://openreview.net/forum?id=PvDY71zKsvP) |  | 0 | We consider a generic min-max multi-objective bilevel optimization problem with applications in robust machine learning such as representation learning and hyperparameter optimization. We design MORBiT, a novel single-loop gradient descent-ascent bilevel optimization algorithm, to solve the generic... | Alex Gu, Parikshit Ram, Songtao Lu, TsuiWei Weng |  |
| 958 |  |  [Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions](https://openreview.net/forum?id=7h5KSs2PCRi) |  | 0 | Generative adversarial networks (GANs) are among the most successful models for learning high-complexity, real-world distributions. However, in theory, due to the highly non-convex, non-concave landscape of the minmax training objective, GAN remains one of the least understood deep learning models.... | Yuanzhi Li, Zeyuan AllenZhu |  |
| 959 |  |  [Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus](https://openreview.net/forum?id=9yE2xEj0BH7) |  | 0 | Mobile UI understanding is important for enabling various interaction tasks such as UI automation and accessibility. Previous mobile UI modeling often depends on the view hierarchy information of a screen, which directly provides the structural data of the UI, with the hope to bypass challenging... | Gang Li, Yang Li |  |
| 960 |  |  [A Control-Centric Benchmark for Video Prediction](https://openreview.net/forum?id=rimcq1oIFeR) |  | 0 | Video is a promising source of knowledge for embodied agents to learn models of the world's dynamics. Large deep networks have become increasingly effective at modeling complex video data in a self-supervised manner, as evaluated by metrics based on human perceptual similarity or pixel-wise... | Chelsea Finn, Jiajun Wu, Stephen Tian |  |
| 961 |  |  [A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks](https://openreview.net/forum?id=vsMyHUq_C1c) |  | 0 | Unlike conventional grid and mesh based methods for solving partial differential equations (PDEs), neural networks have the potential to break the curse of dimensionality, providing approximate solutions to problems where using classical solvers is difficult or impossible. While global minimization... | Andres Potapczynski, Andrew Gordon Wilson, Marc Anton Finzi, Matthew Choptuik |  |
| 962 |  |  [Noise Is Not the Main Factor Behind the Gap Between Sgd and Adam on Transformers, But Sign Descent Might Be](https://openreview.net/forum?id=a65YK0cqH8g) |  | 0 | The success of the Adam optimizer on a wide array of architectures has made it the default in settings where stochastic gradient descent (SGD) performs poorly. However, our theoretical understanding of this discrepancy is lagging, preventing the development of significant improvements on either... | Frederik Kunstner, Jacques Chen, Jonathan Wilder Lavington, Mark Schmidt |  |
| 963 |  |  [Building Normalizing Flows with Stochastic Interpolants](https://openreview.net/forum?id=li7qeBbCR1t) |  | 0 | A generative model based on a continuous-time normalizing flow between any pair of base and target probability densities is proposed. The velocity field of this flow is inferred from the probability current of a time-dependent density that interpolates between the base and the target in finite... | Eric VandenEijnden, Michael S. Albergo |  |
| 964 |  |  [Dual Student Networks for Data-Free Model Stealing](https://openreview.net/forum?id=VE1s3e5xriA) |  | 0 | Data-free model stealing aims to replicate a target model without direct access to either the training data or the target model. To accomplish this, existing methods use a generator to produce samples in order to train a student model to match the target model outputs. To this end, the two main... | Ajmal Saeed Mian, James Beetham, Mubarak Shah, Navid Kardan |  |
| 965 |  |  [Composite Slice Transformer: An Efficient Transformer with Composition of Multi-Scale Multi-Range Attentions](https://openreview.net/forum?id=nWTzIsgrYNN) |  | 0 | Since the introduction of Transformers, researchers have tackled the notoriously expensive quadratic complexity problem. While significant computational efficiency improvements have been achieved, they come at the cost of reduced accuracy trade-offs. In this paper, we propose Composite Slice... | Christopher Lott, HsinPai Cheng, Joseph Soriaga, Kanghwan Jang, Matthew J. Morse, Mingu Lee, Parham Noorzad, PierreDavid Letourneau, Saurabh Pitre, Tianyu Jiang |  |
| 966 |  |  [Equal Improvability: A New Fairness Notion Considering the Long-term Impact](https://openreview.net/forum?id=dhYUMMy0_Eg) |  | 0 | Devising a fair classifier that does not discriminate against different groups is an important problem in machine learning. Although researchers have proposed various ways of defining group fairness, most of them only focused on the immediate fairness, ignoring the long-term impact of a fair... | Jyyong Sohn, Kangwook Lee, Ozgur Guldogan, Ramtin Pedarsani, Yuchen Zeng |  |
| 967 |  |  [Competitive Physics Informed Networks](https://openreview.net/forum?id=z9SIj-IM7tn) |  | 0 | Neural networks can be trained to solve partial differential equations (PDEs) by using the PDE residual as the loss function. This strategy is called "physics-informed neural networks" (PINNs), but it currently cannot produce high-accuracy solutions, typically attaining about $0.1\%$ relative... | Florian Schäfer, Qi Zeng, Spencer H. Bryngelson, Yash Kothari |  |
| 968 |  |  [Decomposed Prompting: A Modular Approach for Solving Complex Tasks](https://openreview.net/forum?id=_nGgzQjzaRy) |  | 0 | Few-shot prompting is a surprisingly powerful way to use Large Language Models (LLMs) to solve various tasks. However, this approach struggles as the task complexity increases or when the individual reasoning steps of the task themselves are hard to learn, especially when embedded in more complex... | Ashish Sabharwal, Harsh Trivedi, Kyle Richardson, Matthew Finlayson, Peter Clark, Tushar Khot, Yao Fu |  |
| 969 |  |  [Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors](https://openreview.net/forum?id=9MO7bjoAfIA) |  | 0 | As data becomes increasingly vital, a company would be very cautious about releasing data, because the competitors could use it to train high-performance models, thereby posing a tremendous threat to the company's commercial competence. To prevent training good models on the data, we could add... | Geng Yuan, Minghai Qin, Sizhe Chen, Xiaolin Huang, Xinwen Cheng, Yanzhi Wang, Yifan Gong |  |
| 970 |  |  [Effectively Modeling Time Series with Simple Discrete State Spaces](https://openreview.net/forum?id=2EpjkjzdCAa) |  | 0 | Time series modeling is a well-established problem, which often requires that methods (1) expressively represent complicated dependencies, (2) forecast long horizons, and (3) efficiently train over long sequences. State-space models (SSMs) are classical models for time series, and prior works... | Christopher Ré, Karan Goel, Khaled Kamal Saab, Michael Poli, Michael Zhang, Tri Dao |  |
| 971 |  |  [A Time Series is Worth 64 Words: Long-term Forecasting with Transformers](https://openreview.net/forum?id=Jbdc0vTOcol) |  | 0 | We propose an efficient design of Transformer-based models for multivariate time series forecasting and self-supervised representation learning. It is based on two key components: (i) segmentation of time series into subseries-level patches which are served as input tokens to Transformer; (ii)... | Jayant Kalagnanam, Nam H. Nguyen, Phanwadee Sinthong, Yuqi Nie |  |
| 972 |  |  [Fantastic Rewards and How to Tame Them: A Case Study on Reward Learning for Task-oriented Dialogue Systems](https://openreview.net/forum?id=086pmarAris) |  | 0 | When learning task-oriented dialogue (ToD) agents, reinforcement learning (RL) techniques can naturally be utilized to train dialogue strategies to achieve user-specific goals. Prior works mainly focus on adopting advanced RL techniques to train the ToD agents, while the design of the reward... | Caiming Xiong, Huan Wang, Jianguo Zhang, Mingyuan Zhou, Shentao Yang, Shujian Zhang, Yihao Feng |  |
| 973 |  |  [Supervision Complexity and its Role in Knowledge Distillation](https://openreview.net/forum?id=8jU7wy7N7mA) |  | 0 | Despite the popularity and efficacy of knowledge distillation, there is limited understanding of why it helps. In order to study the generalization behavior of a distilled student, we propose a new theoretical framework that leverages supervision complexity: a measure of alignment between... | Aditya Krishna Menon, Ankit Singh Rawat, Hrayr Harutyunyan, Sanjiv Kumar, Seungyeon Kim |  |
| 974 |  |  [Transferable Unlearnable Examples](https://openreview.net/forum?id=-htnolWDLvP) |  | 0 | With more people publishing their personal data online, unauthorized data usage has become a serious concern. The unlearnable examples strategies have been introduced to prevent third parties from training on the data without permission. They add perturbations to the users’ data before publishing,... | Han Xu, Jie Ren, Jiliang Tang, Lichao Sun, Xingjun Ma, Yuxuan Wan |  |
| 975 |  |  [Random Laplacian Features for Learning with Hyperbolic Space](https://openreview.net/forum?id=3pfNb4pZBNp) |  | 0 | Due to its geometric properties, hyperbolic space can support high-fidelity embeddings of tree- and graph-structured data, upon which various hyperbolic networks have been developed. Existing hyperbolic networks encode geometric priors not only for the input, but also at every layer of the network.... | Christopher De Sa, Tao Yu |  |
| 976 |  |  [Replay Memory as An Empirical MDP: Combining Conservative Estimation with Experience Replay](https://openreview.net/forum?id=SjzFVSJUt8S) |  | 0 | Experience replay, which stores transitions in a replay memory for repeated use, plays an important role of improving sample efficiency in reinforcement learning. Existing techniques such as reweighted sampling, episodic learning and reverse sweep update further process the information in the... | Bo Xu, Chenjun Xiao, Han Wang, Hongming Zhang, Jun Jin, Martin Müller |  |
| 977 |  |  [Neural Causal Models for Counterfactual Identification and Estimation](https://openreview.net/forum?id=vouQcZS8KfW) |  | 0 | Evaluating hypothetical statements about how the world would be had a different course of action been taken is arguably one key capability expected from modern AI systems. Counterfactual reasoning underpins discussions in fairness, the determination of blame and responsibility, credit assignment,... | Elias Bareinboim, Kevin Muyuan Xia, Yushu Pan |  |
| 978 |  |  [Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport](https://openreview.net/forum?id=vCJ9-Ri-6xU) |  | 0 | The problem of optimization on Stiefel manifold, i.e., minimizing functions of (not necessarily square) matrices that satisfy orthogonality constraints, has been extensively studied. Yet, a new approach is proposed based on, for the first time, an interplay between thoughtfully designed continuous... | Lingkai Kong, Molei Tao, Yuqing Wang |  |
| 979 |  |  [Information-Theoretic Diffusion](https://openreview.net/forum?id=UvmDCdSPDOW) |  | 0 | Denoising diffusion models have spurred significant gains in density modeling and image generation, precipitating an industrial revolution in text-guided AI art generation. We introduce a new mathematical foundation for diffusion models inspired by classic results in information theory that connect... | Greg Ver Steeg, Rob Brekelmans, Xianghao Kong |  |
| 980 |  |  [SIMPLE: A Gradient Estimator for k-Subset Sampling](https://openreview.net/forum?id=GPJVuyX4p_h) |  | 0 | $k$-subset sampling is ubiquitous in machine learning, enabling regularization and interpretability through sparsity. The challenge lies in rendering $k$-subset sampling amenable to end-to-end learning. This has typically involved relaxing the reparameterized samples to allow for backpropagation,... | Guy Van den Broeck, Kareem Ahmed, Mathias Niepert, Zhe Zeng |  |
| 981 |  |  [Learning Iterative Neural Optimizers for Image Steganography](https://openreview.net/forum?id=gLPkzWjdhBN) |  | 0 | Image steganography is the process of concealing secret information in images through imperceptible changes. Recent work has formulated this task as a classic constrained optimization problem. In this paper, we argue that image steganography is inherently performed on the (elusive) manifold of... | Kilian Q. Weinberger, Varsha Kishore, Xiangyu Chen |  |
| 982 |  |  [How Much Data Are Augmentations Worth? An Investigation into Scaling Laws, Invariance, and Implicit Regularization](https://openreview.net/forum?id=3aQs3MCSexD) |  | 0 | Despite the clear performance benefits of data augmentations, little is known about why they are so effective. In this paper, we disentangle several key mechanisms through which data augmentations operate. Establishing an exchange rate between augmented and additional real data, we find that in... | Andrew Gordon Wilson, Gowthami Somepalli, Jonas Geiping, Micah Goldblum, Ravid ShwartzZiv, Tom Goldstein |  |
| 983 |  |  [Robust Graph Dictionary Learning](https://openreview.net/forum?id=qxRscesArBZ) |  | 0 | Traditional Dictionary Learning (DL) aims to approximate data vectors as sparse linear combinations of basis elements (atoms) and is widely used in machine learning, computer vision, and signal processing. To extend DL to graphs, Vincent-Cuaz et al. 2021 propose a method, called GDL, which... | Chao Zhang, Hui Qian, Jiahao Xie, Makoto Yamada, Nenggan Zheng, Weijie Liu |  |
| 984 |  |  [Fundamental limits on the robustness of image classifiers](https://openreview.net/forum?id=gpmL0D4VjN4) |  | 0 | We prove that image classifiers are fundamentally sensitive to small perturbations in their inputs. Specifically, we show that given some image space of $n$-by-$n$ images, all but a tiny fraction of images in any image class induced over that space can be moved outside that class by adding some... | David Gifford, Zheng Dai |  |
| 985 |  |  [Understanding Influence Functions and Datamodels via Harmonic Analysis](https://openreview.net/forum?id=cxCEOSF99f) |  | 0 | Influence functions estimate effect of individual data points on predictions of the model on test data and were adapted to deep learning in \cite{koh2017understanding}. They have been used for detecting data poisoning, detecting helpful and harmful examples, influence of groups of datapoints, etc.... | Arushi Gupta, Mark Braverman, Nikunj Saunshi, Sanjeev Arora |  |
| 986 |  |  [TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization](https://openreview.net/forum?id=5tKXUZil3X) |  | 0 | Robustness evaluation against adversarial examples has become increasingly important to unveil the trustworthiness of the prevailing deep models in natural language processing (NLP). However, in contrast to the computer vision domain where the first-order projected gradient descent (PGD) is used as... | Bairu Hou, Guanhua Zhang, Jinghan Jia, Shiyu Chang, Sijia Liu, Yang Zhang, Yihua Zhang |  |
| 987 |  |  [Information Plane Analysis for Dropout Neural Networks](https://openreview.net/forum?id=bQB6qozaBw) |  | 0 | The information-theoretic framework promises to explain the predictive power of neural networks. In particular, the information plane analysis, which measures mutual information (MI) between input and representation as well as representation and output, should give rich insights into the training... | Asja Fischer, Bernhard C. Geiger, Linara Adilova |  |
| 988 |  |  [Learning Harmonic Molecular Representations on Riemannian Manifold](https://openreview.net/forum?id=ySCL-NG_I3) |  | 0 | Molecular representation learning plays a crucial role in AI-assisted drug discovery research. Encoding 3D molecular structures through Euclidean neural networks has become the prevailing method in the geometric deep learning community. However, the equivariance constraints and message passing in... | Fei Ye, Hao Zhou, Lihao Wang, Shi Chen, Yiqun Wang, Yuning Shen |  |
| 989 |  |  [Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement](https://openreview.net/forum?id=eSQh8rG8Oa) |  | 0 | Many policy gradient methods are variants of Actor-Critic (AC), where a value function (critic) is learned to facilitate updating the parameterized policy (actor). The update to the actor involves a log-likelihood update weighted by the action-values, with the addition of entropy regularization for... | Adam White, Ajin George Joseph, Martha White, Samuel Neumann, Sungsu Lim, Yangchen Pan |  |
| 990 |  |  [Efficiently Controlling Multiple Risks with Pareto Testing](https://openreview.net/forum?id=cyg2YXn_BqF) |  | 0 | Machine learning applications frequently come with multiple diverse objectives and constraints that can change over time. Accordingly, trained models can be tuned with sets of hyper-parameters that affect their predictive behavior (e.g., their run-time efficiency versus error rate). As the number... | Adam Fisch, Bracha LauferGoldshtein, Regina Barzilay, Tommi S. Jaakkola |  |
| 991 |  |  [Characteristic Neural Ordinary Differential Equation](https://openreview.net/forum?id=loIfC8WHevK) |  | 0 | We propose Characteristic-Neural Ordinary Differential Equations (C-NODEs), a framework for extending Neural Ordinary Differential Equations (NODEs) beyond ODEs. While NODE models the evolution of latent variables as the solution to an ODE, C-NODE models the evolution of the latent variables as the... | Ali Hasan, Jie Ding, Khalil Elkhalil, Vahid Tarokh, Xingzi Xu |  |
| 992 |  |  [Fast Sampling of Diffusion Models with Exponential Integrator](https://openreview.net/forum?id=Loek7hfb46P) |  | 0 | The past few years have witnessed the great success of Diffusion models~(DMs) in generating high-fidelity samples in generative modeling tasks. A major limitation of the DM is its notoriously slow sampling procedure which normally requires hundreds to thousands of time discretization steps of the... | Qinsheng Zhang, Yongxin Chen |  |
| 993 |  |  [Panning for Gold in Federated Learning: Targeted Text Extraction under Arbitrarily Large-Scale Aggregation](https://openreview.net/forum?id=A9WQaxYsfx) |  | 0 | As federated learning (FL) matures, privacy attacks against FL systems in turn become more numerous and complex. Attacks on language models have progressed from recovering single sentences in simple classification tasks to recovering larger parts of user data. Current attacks against federated... | HongMin Chu, Jonas Geiping, Liam H. Fowl, Micah Goldblum, Tom Goldstein |  |
| 994 |  |  [Artificial Neuronal Ensembles with Learned Context Dependent Gating](https://openreview.net/forum?id=dBk3hsg-n6) |  | 0 | Biological neural networks are capable of recruiting different sets of neurons to encode different memories. However, when training artificial neural networks on a set of tasks, typically, no mechanism is employed for selectively producing anything analogous to these neuronal ensembles. Further,... | David Freedman, Matthew J. Tilley, Michelle Miller |  |
| 995 |  |  [Learning Language Representations with Logical Inductive Bias](https://openreview.net/forum?id=rGeZuBRahju) |  | 0 | Transformer architectures have achieved great success in solving natural language tasks, which learn strong language representations from large-scale unlabeled texts. In this paper, we seek to go further beyond and explore a new logical inductive bias for better language representation learning.... | Jianshu Chen |  |
| 996 |  |  [How Does Semi-supervised Learning with Pseudo-labelers Work? A Case Study](https://openreview.net/forum?id=Dzmd-Cc8OI) |  | 0 | Semi-supervised learning is a popular machine learning paradigm that utilizes a large amount of unlabeled data as well as a small amount of labeled data to facilitate learning tasks. While semi-supervised learning has achieved great success in training neural networks, its theoretical understanding... | Quanquan Gu, Yiwen Kou, Yuan Cao, Zixiang Chen |  |
| 997 |  |  [Empowering Graph Representation Learning with Test-Time Graph Transformation](https://openreview.net/forum?id=Lnxl5pr018) |  | 0 | As powerful tools for representation learning on graphs, graph neural networks (GNNs) have facilitated various applications from drug discovery to recommender systems. Nevertheless, the effectiveness of GNNs is immensely challenged by issues related to data quality, such as distribution shift,... | Jiayuan Ding, Jiliang Tang, Neil Shah, Tong Zhao, Wei Jin, Yozen Liu |  |
| 998 |  |  [Provable Robustness against Wasserstein Distribution Shifts via Input Randomization](https://openreview.net/forum?id=HJFVrpCaGE) |  | 0 | Certified robustness in machine learning has primarily focused on adversarial perturbations with a fixed attack budget for each sample in the input distribution. In this work, we present provable robustness guarantees on the accuracy of a model under bounded Wasserstein shifts of the data... | Alexander Levine, Aounon Kumar, Soheil Feizi, Tom Goldstein |  |
| 999 |  |  [Interpretations of Domain Adaptations via Layer Variational Analysis](https://openreview.net/forum?id=YtntjusJV6) |  | 0 | Transfer learning is known to perform efficiently in many applications empirically, yet limited literature reports the mechanism behind the scene. This study establishes both formal derivations and heuristic analysis to formulate the theory of transfer learning in deep learning. Our framework... | HsinYi Lin, HuanHsin Tseng, KuoHsuan Hung, Yu Tsao |  |
| 1000 |  |  [Denoising Diffusion Samplers](https://openreview.net/forum?id=8pvnfTAbu1f) |  | 0 | Denoising diffusion models are a popular class of generative models providing state-of-the-art results in many domains. One adds gradually noise to data using a diffusion to transform the data distribution into a Gaussian distribution. Samples from the generative model are then obtained by... | Arnaud Doucet, Francisco Vargas, Will Sussman Grathwohl |  |
| 1001 |  |  [How I Learned to Stop Worrying and Love Retraining](https://openreview.net/forum?id=_nF5imFKQI) |  | 0 | Many Neural Network Pruning approaches consist of several iterative training and pruning steps, seemingly losing a significant amount of their performance after pruning and then recovering it in the subsequent retraining phase. Recent works of Renda et al. (2020) and Le & Hua (2021) demonstrate the... | Christoph Spiegel, Max Zimmer, Sebastian Pokutta |  |
| 1002 |  |  [Interpretable Geometric Deep Learning via Learnable Randomness Injection](https://openreview.net/forum?id=6u7mf9s2A9) |  | 0 | Point cloud data is ubiquitous in scientific fields. Recently, geometric deep learning (GDL) has been widely applied to solve prediction tasks with such data. However, GDL models are often complicated and hardly interpretable, which poses concerns to scientists who are to deploy these models in... | Mia Liu, Pan Li, Siqi Miao, Yunan Luo |  |
| 1003 |  |  [GOGGLE: Generative Modelling for Tabular Data by Learning Relational Structure](https://openreview.net/forum?id=fPVRcJqspu) |  | 0 | Deep generative models learn highly complex and non-linear representations to generate realistic synthetic data. While they have achieved notable success in computer vision and natural language processing, similar advances have been less demonstrable in the tabular domain. This is partially because... | Jeroen Berrevoets, Mihaela van der Schaar, Tennison Liu, Zhaozhi Qian |  |
| 1004 |  |  [Progressive Prompts: Continual Learning for Language Models](https://openreview.net/forum?id=UJTgQBc91_) |  | 0 | We introduce Progressive Prompts – a simple and efficient approach for continual learning in language models. Our method allows forward transfer and resists catastrophic forgetting, without relying on data replay or a large number of task-specific parameters. Progressive Prompts learns a new soft... | Amjad Almahairi, Anastasia Razdaibiedina, Madian Khabsa, Mike Lewis, Rui Hou, Yuning Mao |  |
| 1005 |  |  [Deep Learning From Crowdsourced Labels: Coupled Cross-Entropy Minimization, Identifiability, and Regularization](https://openreview.net/forum?id=_qVhsWyWB9) |  | 0 | Using noisy crowdsourced labels from multiple annotators, a deep learning-based end-to-end (E2E) system aims to learn the label correction mechanism and the neural classifier simultaneously. To this end, many E2E systems concatenate the neural classifier with multiple annotator-specific label... | Shahana Ibrahim, Tri Nguyen, Xiao Fu |  |
| 1006 |  |  [Projective Proximal Gradient Descent for Nonconvex Nonsmooth Optimization: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property](https://openreview.net/forum?id=yEsj8pGNl1) |  | 0 | Nonconvex and nonsmooth optimization problems are important and challenging for statistics and machine learning. In this paper, we propose Projected Proximal Gradient Descent (PPGD) which solves a class of nonconvex and nonsmooth optimization problems, where the nonconvexity and nonsmoothness come... | Ping Li, Yingzhen Yang |  |
| 1007 |  |  [First Steps Toward Understanding the Extrapolation of Nonlinear Models to Unseen Domains](https://openreview.net/forum?id=7wrq3vHcMM) |  | 0 | Real-world machine learning applications often involve deploying neural networks to domains that are not seen in the training time. Hence, we need to understand the extrapolation of \textit{nonlinear} models---under what conditions on the distributions and function class, models can be guaranteed... | Kefan Dong, Tengyu Ma |  |
| 1008 |  |  [Compositionality with Variation Reliably Emerges in Neural Networks](https://openreview.net/forum?id=-Yzz6vlX7V-) |  | 0 | Human languages enable robust generalization, letting us leverage our prior experience to communicate about novel meanings. This is partly due to language being compositional, where the meaning of a whole expression is a function of its parts. Natural languages also exhibit extensive variation,... | Henry Conklin, Kenny Smith |  |
| 1009 |  |  [Systematic Rectification of Language Models via Dead-end Analysis](https://openreview.net/forum?id=k8_yVW3Wqln) |  | 0 | With adversarial or otherwise normal prompts, existing large language models (LLM) can be pushed to generate toxic discourses. One way to reduce the risk of LLMs generating undesired discourses is to alter the training of the LLM. This can be very restrictive due to demanding computation... | Jackie C. K. Cheung, Mehdi Fatemi, Meng Cao, Samira Shabanian |  |
| 1010 |  |  [Multiple sequence alignment as a sequence-to-sequence learning problem](https://openreview.net/forum?id=8efJYMBrNb) |  | 0 | The sequence alignment problem is one of the most fundamental problems in bioinformatics and a plethora of methods were devised to tackle it. Here we introduce BetaAlign, a methodology for aligning sequences using an NLP approach. BetaAlign accounts for the possible variability of the evolutionary... | Edo Dotan, Elya Wygoda, Gil Loewenthal, Michael Alburquerque, Noa Ecker, Omri Keren, Oren Avram, Tal Pupko, Yonatan Belinkov |  |
| 1011 |  |  [A Mixture-of-Expert Approach to RL-based Dialogue Management](https://openreview.net/forum?id=4FBUihxz5nm) |  | 0 | Despite recent advancements in language models (LMs), their application to dialogue management (DM) problems and ability to carry on rich conversations remain a challenge. We use reinforcement learning (RL) to develop a dialogue agent that avoids being short-sighted (outputting generic utterances)... | Aza Tulepbergenov, Craig Boutilier, Dhawal Gupta, Mohammad Ghavamzadeh, Moonkyung Ryu, Ofir Nachum, Yinlam Chow |  |
| 1012 |  |  [f-DM: A Multi-stage Diffusion Model via Progressive Signal Transformation](https://openreview.net/forum?id=iBdwKIsg4m) |  | 0 | Diffusion models (DMs) have recently emerged as SoTA tools for generative modeling in various domains. Standard DMs can be viewed as an instantiation of hierarchical variational autoencoders (VAEs) where the latent variables are inferred from input-centered Gaussian distributions with fixed scales... | Jiatao Gu, Joshua M. Susskind, Miguel Ángel Bautista, Shuangfei Zhai, Yizhe Zhang |  |
| 1013 |  |  [Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning](https://openreview.net/forum?id=nIMifqu2EO) |  | 0 | How the brain performs credit assignment is a fundamental unsolved problem in neuroscience. Many \`biologically plausible' algorithms have been proposed, which compute gradients that approximate those computed by backpropagation (BP), and which operate in ways that more closely satisfy the... | Beren Millidge, Rafal Bogacz, Thomas Lukasiewicz, Tommaso Salvatori, Yuhang Song |  |
| 1014 |  |  [A Theoretical Framework for Inference and Learning in Predictive Coding Networks](https://openreview.net/forum?id=ZCTvSF_uVM4) |  | 0 | Predictive coding (PC) is an influential theory in computational neuroscience, which argues that the cortex forms unsupervised world models by implementing a hierarchical process of prediction error minimization. PC networks (PCNs) are trained in two phases. First, neural activities are updated to... | Beren Millidge, Rafal Bogacz, Thomas Lukasiewicz, Tommaso Salvatori, Yuhang Song |  |
| 1015 |  |  [The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes](https://openreview.net/forum?id=JLINxPOVTh7) |  | 0 | For small training set sizes $P$, the generalization error of wide neural networks is well-approximated by the error of an infinite width neural network (NN), either in the kernel or mean-field/feature-learning regime. However, after a critical sample size $P^\*$, we empirically find the... | Alexander B. Atanasov, Blake Bordelon, Cengiz Pehlevan, Sabarish Sainathan |  |
| 1016 |  |  [A Simple Approach for Visual Room Rearrangement: 3D Mapping and Semantic Search](https://openreview.net/forum?id=1C6nCCaRe6p) |  | 0 | Physically rearranging objects is an important capability for embodied agents. Visual room rearrangement evaluates an agent's ability to rearrange objects in a room to a desired goal based solely on visual input. We propose a simple yet effective method for this problem: (1) search for and map... | Brandon Trabucco, Gaurav S. Sukhatme, Gunnar A. Sigurdsson, Robinson Piramuthu, Ruslan Salakhutdinov |  |
| 1017 |  |  [Progressive Mix-Up for Few-Shot Supervised Multi-Source Domain Transfer](https://openreview.net/forum?id=H7M_5K5qKJV) |  | 0 | This paper targets at a new and challenging setting of knowledge transfer from multiple source domains to a single target domain, where target data is few shot or even one shot with label. Traditional domain generalization or adaptation methods cannot directly work since there is no sufficient... | Ronghang Zhu, Sheng Li, Xiang Yu |  |
| 1018 |  |  [Neural Compositional Rule Learning for Knowledge Graph Reasoning](https://openreview.net/forum?id=F8VKQyDgRVj) |  | 0 | Learning logical rules is critical to improving reasoning in KGs. This is due to their ability to provide logical and interpretable explanations when used for predictions, as well as their ability to generalize to other tasks, domains, and data. While recent methods have been proposed to learn... | Kewei Cheng, Nesreen K. Ahmed, Yizhou Sun |  |
| 1019 |  |  [Efficient approximation of neural population structure and correlations with probabilistic circuits](https://openreview.net/forum?id=XC_yGI-0j9) |  | 0 | We present a computationally efficient framework to model a wide range of population structures with high order correlations and a large number of neurons. Our method is based on a special type of Bayesian network that has linear inference time and is founded upon the concept of contextual... | Koosha Khalvati, Michael A. Buice, Samantha Johnson, Stefan Mihalas |  |
| 1020 |  |  [Exploring perceptual straightness in learned visual representations](https://openreview.net/forum?id=4cOfD2qL6T) |  | 0 | Humans have been shown to use a ''straightened'' encoding to represent the natural visual world as it evolves in time (Henaff et al. 2019). In the context of discrete video sequences, ''straightened'' means that changes between frames follow a more linear path in representation space at... | Anne Harrington, Ayush Tewari, Mark Hamilton, Ruth Rosenholtz, Simon Stent, Vasha DuTell, William T. Freeman |  |
| 1021 |  |  [Is Forgetting Less a Good Inductive Bias for Forward Transfer?](https://openreview.net/forum?id=dL35lx-mTEs) |  | 0 | One of the main motivations of studying continual learning is that the problem setting allows a model to accrue knowledge from past tasks to learn new tasks more efficiently. However, recent studies suggest that the key metric that continual learning algorithms optimize, reduction in catastrophic... | Arslan Chaudhry, Dilan Görür, Jiefeng Chen, Timothy Nguyen |  |
| 1022 |  |  [Learning Structured Representations by Embedding Class Hierarchy](https://openreview.net/forum?id=7J-30ilaUZM) |  | 0 | Existing models for learning representations in supervised classification problems are permutation invariant with respect to class labels. However, structured knowledge about the classes, such as hierarchical label structures, widely exists in many real-world datasets, e.g., the ImageNet and CIFAR... | Han Zhao, Remi Tachet des Combes, Siqi Zeng |  |
| 1023 |  |  [Promptagator: Few-shot Dense Retrieval From 8 Examples](https://openreview.net/forum?id=gmL46YMpu2J) |  | 0 | Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other retrieval tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However,... | Anton Bakalov, Ji Ma, Jianmo Ni, Jing Lu, Keith B. Hall, Kelvin Guu, MingWei Chang, Vincent Y. Zhao, Yi Luan, Zhuyun Dai |  |
| 1024 |  |  [Brain-like representational straightening of natural movies in robust feedforward neural networks](https://openreview.net/forum?id=mCmerkTCG2S) |  | 0 | Representational straightening refers to a decrease in curvature of visual feature representations of a sequence of frames taken from natural movies. Prior work established straightening in neural representations of the primate primary visual cortex (V1) and perceptual straightening in human... | Elias B. Issa, Tahereh Toosi |  |
| 1025 |  |  [FunkNN: Neural Interpolation for Functional Generation](https://openreview.net/forum?id=BT4N_v7CLrk) |  | 0 | Can we build continuous generative models which generalize across scales, can be evaluated at any coordinate, admit calculation of exact derivatives, and are conceptually simple? Existing MLP-based architectures generate worse samples than the grid-based generators with favorable convolutional... | AmirEhsan Khorashadizadeh, Anadi Chaman, Ivan Dokmanic, Valentin Debarnot |  |
| 1026 |  |  [Label Propagation with Weak Supervision](https://openreview.net/forum?id=aCuFa-RRqtI) |  | 0 | Semi-supervised learning and weakly supervised learning are important paradigms that aim to reduce the growing demand for labeled data in current machine learning applications. In this paper, we introduce a novel analysis of the classical label propagation algorithm (LPA) (Zhu & Ghahramani, 2002)... | Dylan Sam, Nina Balcan, Pradeep Kumar Ravikumar, Rattana Pukdee |  |
| 1027 |  |  [TypeT5: Seq2seq Type Inference using Static Analysis](https://openreview.net/forum?id=4TyNEhI2GdN) |  | 0 | There has been growing interest in automatically predicting missing type annotations in programs written in Python and JavaScript. While prior methods have achieved impressive accuracy when predicting the most common types, they often perform poorly on rare or complex types. In this paper, we... | Greg Durrett, Isil Dillig, Jiayi Wei |  |
| 1028 |  |  [AGRO: Adversarial discovery of error-prone Groups for Robust Optimization](https://openreview.net/forum?id=IrzkT99fDJH) |  | 0 | Models trained via empirical risk minimization (ERM) are known to rely on spurious correlations between labels and task-independent input features, resulting in poor generalization to distributional shifts. Group distributionally robust optimization (G-DRO) can alleviate this problem by minimizing... | Bhargavi Paranjape, Hannaneh Hajishirzi, Luke Zettlemoyer, Pradeep Dasigi, Vivek Srikumar |  |
| 1029 |  |  [LogicDP: Creating Labels for Graph Data via Inductive Logic Programming](https://openreview.net/forum?id=2b2s9vd7wYv) |  | 0 | Graph data, such as scene graphs and knowledge graphs, see wide use in AI systems. In real-world and large applications graph data are usually incomplete, motivating graph reasoning models for missing-fact or missing-relationship inference. While these models can achieve state-of-the-art... | Ali Payani, Faramarz Fekri, James Clayton Kerce, Yuan Yang |  |
| 1030 |  |  [Revisiting Intrinsic Reward for Exploration in Procedurally Generated Environments](https://openreview.net/forum?id=j3GK3_xZydY) |  | 0 | Exploration under sparse rewards remains a key challenge in deep reinforcement learning. Recently, studying exploration in procedurally-generated environments has drawn increasing attention. Existing works generally combine lifelong intrinsic rewards and episodic intrinsic rewards to encourage... | Bingyi Kang, Jiashi Feng, Kaixin Wang, Kuangqi Zhou, Shuicheng Yan |  |
| 1031 |  |  [Transformer-based World Models Are Happy With 100k Interactions](https://openreview.net/forum?id=TdBaDGCpjly) |  | 0 | Deep neural networks have been successful in many reinforcement learning settings. However, compared to human learners they are overly data hungry. To build a sample-efficient world model, we apply a transformer to real-world episodes in an autoregressive manner: not only the compact latent states... | Jan Robine, Marc Höftmann, Stefan Harmeling, Tobias Uelwer |  |
| 1032 |  |  [Can Neural Networks Learn Implicit Logic from Physical Reasoning?](https://openreview.net/forum?id=HVoJCRLByVk) |  | 0 | Despite the success of neural network models in a range of domains, it remains an open question whether they can learn to represent abstract logical operators such as negation and disjunction. We test the hypothesis that neural networks without inherent inductive biases for logical reasoning can... | Aaron Traylor, Ellie Pavlick, Roman Feiman |  |
| 1033 |  |  [ESCHER: Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regret](https://openreview.net/forum?id=35QyoZv8cKO) |  | 0 | Recent techniques for approximating Nash equilibria in very large games leverage neural networks to learn approximately optimal policies (strategies). One promis- ing line of research uses neural networks to approximate counterfactual regret minimization (CFR) or its modern variants. DREAM, the... | Gabriele Farina, Marc Lanctot, Stephen Marcus McAleer, Tuomas Sandholm |  |
| 1034 |  |  [On Achieving Optimal Adversarial Test Error](https://openreview.net/forum?id=fVm3nZMZs9) |  | 0 | We first elucidate various fundamental properties of optimal adversarial predictors: the structure of optimal adversarial convex predictors in terms of optimal adversarial zero-one predictors, bounds relating the adversarial convex loss to the adversarial zero-one loss, and the fact that continuous... | Justin D. Li, Matus Telgarsky |  |
| 1035 |  |  [Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation](https://openreview.net/forum?id=FJXf1FXN8C) |  | 0 | We consider a setting that a model needs to adapt to a new domain under distribution shifts, given that only unlabeled test samples from the new domain are accessible at test time. A common idea in most of the related works is constructing pseudo-labels for the unlabeled test samples and applying... | Andre Wibisono, JunKun Wang |  |
| 1036 |  |  [A VAE for Transformers with Nonparametric Variational Information Bottleneck](https://openreview.net/forum?id=6QkjC_cs03X) |  | 0 | We propose a Variational AutoEncoder (VAE) for Transformers by developing a Variational Information Bottleneck (VIB) regulariser for Transformer embeddings. We formalise such attention-based representations as mixture distributions, and use Bayesian nonparametrics to develop a Nonparametric VIB... | Fabio Fehr, James Henderson |  |
| 1037 |  |  [On The Specialization of Neural Modules](https://openreview.net/forum?id=Fh97BDaR6I) |  | 0 | A number of machine learning models have been proposed with the goal of achieving systematic generalization: the ability to reason about new situations by combining aspects of previous experiences. These models leverage compositional architectures which aim to learn specialized modules dedicated to... | Andrew M. Saxe, Benjamin Rosman, Devon Jarvis, Richard Klein |  |
| 1038 |  |  [HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers](https://openreview.net/forum?id=D7srTrGhAs) |  | 0 | Knowledge distillation has been shown to be a powerful model compression approach to facilitate the deployment of pre-trained language models in practice. This paper focuses on task-agnostic distillation. It produces a compact pre-trained model that can be easily fine-tuned on various tasks with... | Bing Yin, Chen Liang, Haoming Jiang, Tuo Zhao, Xianfeng Tang, Zheng Li |  |
| 1039 |  |  [Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks](https://openreview.net/forum?id=4u42KCQxCn8) |  | 0 | Demonstrations and natural language instructions are two common ways to specify and teach robots novel tasks. However, for many complex tasks, a demonstration or language instruction alone contains ambiguities, preventing tasks from being specified clearly. In such cases, a combination of both a... | Albert Yu, Raymond J. Mooney |  |
| 1040 |  |  [FIGARO: Controllable Music Generation using Learned and Expert Features](https://openreview.net/forum?id=NyR8OZFHw6i) |  | 0 | Recent symbolic music generative models have achieved significant improvements in the quality of the generated samples. Nevertheless, it remains hard for users to control the output in such a way that it matches their expectation. To address this limitation, high-level, human-interpretable... | Dimitri von Rütte, Luca Biggio, Thomas Hofmann, Yannic Kilcher |  |
| 1041 |  |  [Language models are multilingual chain-of-thought reasoners](https://openreview.net/forum?id=fR3wGCk-IXp) |  | 0 | We evaluate the reasoning abilities of large language models in multilingual settings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) into ten typologically diverse languages. We... | Denny Zhou, Dipanjan Das, Freda Shi, Hyung Won Chung, Jason Wei, Markus Freitag, Mirac Suzgun, Sebastian Ruder, Soroush Vosoughi, Suraj Srivats, Xuezhi Wang, Yi Tay |  |
| 1042 |  |  [Recitation-Augmented Language Models](https://openreview.net/forum?id=-cqvvvb-NkI) |  | 0 | We propose a new paradigm to help Large Language Models (LLMs) generate more accurate factual knowledge without retrieving from an external corpus, called RECITation-augmented gEneration (RECITE). Different from retrieval-augmented language models that retrieve relevant documents before generating... | Denny Zhou, Xuezhi Wang, Yi Tay, Yiming Yang, Zhiqing Sun |  |
| 1043 |  |  [KwikBucks: Correlation Clustering with Cheap-Weak and Expensive-Strong Signals](https://openreview.net/forum?id=p0JSSa1AuV) |  | 0 | The unprecedented rate at which the sizes of machine learning (ML) models are growing necessitates novel approaches to enable efficient and scalable solutions. We contribute to this line of work by studying a novel version of the Budgeted Correlation Clustering problem (\bcc) where along with a... | Andrew McCallum, Andrew Nystrom, Deepak Ramachandran, Sandeep Silwal, Sara Ahmadian, Seyed Mehran Kazemi |  |
| 1044 |  |  [Reward Design with Language Models](https://openreview.net/forum?id=10uNUgI5Kl) |  | 0 | Reward design in reinforcement learning (RL) is challenging since specifying human notions of desired behavior may be difficult via reward functions or require many expert demonstrations. Can we instead cheaply design rewards using a natural language interface? This paper explores how to simplify... | Dorsa Sadigh, Kalesha Bullard, Minae Kwon, Sang Michael Xie |  |
| 1045 |  |  [Calibrating the Rigged Lottery: Making All Tickets Reliable](https://openreview.net/forum?id=KdwnGErdT6) |  | 0 | Although sparse training has been successfully used in various deep learning tasks to save memory and reduce inference time, the reliability of the produced sparse models remains unexplored. Previous research has shown that deep neural networks tend to be over-confident, and we find that sparse... | Bani K. Mallick, Bowen Lei, Dongkuan Xu, Ruqi Zhang |  |
| 1046 |  |  [A Statistical Framework for Personalized Federated Learning and Estimation: Theory, Algorithms, and Privacy](https://openreview.net/forum?id=FUiDMCr_W4o) |  | 0 | A distinguishing characteristic of federated learning is that the (local) client data could have statistical heterogeneity. This heterogeneity has motivated the design of personalized learning, where individual (personalized) models are trained, through collaboration. There have been various... | Antonious M. Girgis, Deepesh Data, Kaan Ozkara, Suhas N. Diggavi |  |
| 1047 |  |  [Subsampling in Large Graphs Using Ricci Curvature](https://openreview.net/forum?id=w9WUQkBvpI) |  | 0 | In the past decades, many large graphs with millions of nodes have been collected/constructed. The high computational cost and significant visualization difficulty hinder the analysis of large graphs. To overcome the difficulties, researchers have developed many graph subsampling approaches to... | Huimin Cheng, Jiazhang Cai, Ping Ma, Shushan Wu, Wenxuan Zhong |  |
| 1048 |  |  [Conservative Bayesian Model-Based Value Expansion for Offline Policy Optimization](https://openreview.net/forum?id=dNqxZgyjcYA) |  | 0 | Offline reinforcement learning (RL) addresses the problem of learning a performant policy from a fixed batch of data collected by following some behavior policy. Model-based approaches are particularly appealing in the offline setting since they can extract more learning signals from the logged... | Baher Abdulhai, Hyunwoo Kim, Jihwan Jeong, Michael Gimelfarb, Scott Sanner, Xiaoyu Wang |  |
| 1049 |  |  [Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation](https://openreview.net/forum?id=PYbe4MoHf32) |  | 0 | Differentiable planning promises end-to-end differentiability and adaptivity. However, an issue prevents it from scaling up to larger-scale problems: they need to differentiate through forward iteration layers to compute gradients, which couples forward computation and backpropagation and needs to... | Huazhe Xu, Lawson L. S. Wong, Linfeng Zhao |  |
| 1050 |  |  [Score-based Continuous-time Discrete Diffusion Models](https://openreview.net/forum?id=BYWWwSY2G5s) |  | 0 | Score-based modeling through stochastic differential equations (SDEs) has provided a new perspective on diffusion models, and demonstrated superior performance on continuous data. However, the gradient of the log-likelihood function, \ie, the score function, is not properly defined for discrete... | Bo Dai, Dale Schuurmans, Hanjun Dai, Haoran Sun, Lijun Yu |  |
| 1051 |  |  [Decision Transformer under Random Frame Dropping](https://openreview.net/forum?id=NmZXv4467ai) |  | 0 | Controlling agents remotely with deep reinforcement learning~(DRL) in the real world is yet to come. One crucial stepping stone is to devise RL algorithms that are robust in the face of dropped information from corrupted communication or malfunctioning sensors. Typical RL methods usually require... | Huazhe Xu, Kaizhe Hu, Ray Chen Zheng, Yang Gao |  |
| 1052 |  |  [Adversarial Imitation Learning with Preferences](https://openreview.net/forum?id=bhfp5GlDtGe) |  | 0 | Designing an accurate and explainable reward function for many Reinforcement Learning tasks is a cumbersome and tedious process. Instead, learning policies directly from the feedback of human teachers naturally integrates human domain knowledge into the policy optimization process. However,... | Aleksandar Taranovic, Andras Gabor Kupcsik, Gerhard Neumann, Niklas Freymuth |  |
| 1053 |  |  [Is Model Ensemble Necessary? Model-based RL via a Single Model with Lipschitz Regularized Value Function](https://openreview.net/forum?id=hNyJBk3CwR) |  | 0 | Probabilistic dynamics model ensemble is widely used in existing model-based reinforcement learning methods as it outperforms a single dynamics model in both asymptotic performance and sample efficiency. In this paper, we provide both practical and theoretical insights on the empirical success of... | Furong Huang, Huazhe Xu, Ruijie Zheng, Xiyao Wang |  |
| 1054 |  |  [Synthetic Data Generation of Many-to-Many Datasets via Random Graph Generation](https://openreview.net/forum?id=Q120_4COf-K) |  | 0 | Synthetic data generation (SDG) has become a popular approach to release private datasets. In SDG, a generative model is fitted on the private real data, and samples drawn from the model are released as the protected synthetic data. While real-world datasets usually consist of multiple tables with... | Emile Joubert, Georgi Ganev, Kai Xu, Luke Robinson, Olivier Van Acker, Rees Davison |  |
| 1055 |  |  [Learning Low Dimensional State Spaces with Overparameterized Recurrent Neural Nets](https://openreview.net/forum?id=k9CF4h3muD) |  | 0 | Overparameterization in deep learning refers to settings where a trained Neural Network (NN) has representational capacity to fit the training data in many ways, some of which generalize well, while others do not. In the case of Recurrent Neural Networks (RNNs) there exists an additional layer of... | Amir Globerson, Edo CohenKarlik, Itamar MenuhinGruman, Nadav Cohen, Raja Giryes |  |
| 1056 |  |  [Images as Weight Matrices: Sequential Image Generation Through Synaptic Learning Rules](https://openreview.net/forum?id=ddad0PNUvV) |  | 0 | Work on fast weight programmers has demonstrated the effectiveness of key/value outer product-based learning rules for sequentially generating a weight matrix (WM) of a neural net (NN) by another NN or itself. However, the weight generation steps are typically not visually interpretable by humans,... | Jürgen Schmidhuber, Kazuki Irie |  |
| 1057 |  |  [Why (and When) does Local SGD Generalize Better than SGD?](https://openreview.net/forum?id=svCcui6Drl) |  | 0 | Local SGD is a communication-efficient variant of SGD for large-scale training, where multiple GPUs perform SGD independently and average the model parameters periodically. It has been recently observed that Local SGD can not only achieve the design goal of reducing the communication overhead but... | Kaifeng Lyu, Longbo Huang, Sanjeev Arora, Xinran Gu |  |
| 1058 |  |  [Function-space regularized Rényi divergences](https://openreview.net/forum?id=89GT-S49mGd) |  | 0 | We propose a new family of regularized Rényi divergences parametrized not only by the order $\alpha$ but also by a variational function space. These new objects are defined by taking the infimal convolution of the standard Rényi divergence with the integral probability metric (IPM) associated with... | Jeremiah Birrell, Luc ReyBellet, Markos A. Katsoulakis, Paul Dupuis, Yannis Pantazis |  |
| 1059 |  |  [Analogy-Forming Transformers for Few-Shot 3D Parsing](https://openreview.net/forum?id=SRIQZTh0IK) |  | 0 | We present Analogical Networks, a model that segments 3D object scenes with analogical reasoning: instead of mapping a scene to part segments directly, our model first retrieves related scenes from memory and their corresponding part structures, and then predicts analogous part structures in the... | Katerina Fragkiadaki, Mayank Singh, Nikolaos Gkanatsios, Shubham Tulsiani, Zhaoyuan Fang |  |
| 1060 |  |  [Fake It Until You Make It : Towards Accurate Near-Distribution Novelty Detection](https://openreview.net/forum?id=QWQM0ZwZdRS) |  | 0 | We aim for image-based novelty detection. Despite considerable progress, existing models either fail or face dramatic drop under the so-called \`\`near-distribution" setup, where the differences between normal and anomalous samples are subtle. We first demonstrate existing methods could experience... | Cees G. M. Snoek, Efstratios Gavves, Hossein Mirzaei, Mohammad Hossein Rohban, Mohammad Sabokrou, Mohammadreza Salehi, Sajjad Shahabi |  |
| 1061 |  |  [DySR: Adaptive Super-Resolution via Algorithm and System Co-design](https://openreview.net/forum?id=Pgtn4l6eKjv) |  | 0 | Super resolution (SR) is a promising approach for improving the quality of low resolution steaming services on mobile devices. On mobile devices, the available computing and memory resources change dynamically depending on other running applications. Due to the high computation and memory demands... | Cheng Li, Elton Zheng, Feng Yan, Syed Zawad, Yuxiong He, Zhewei Yao |  |
| 1062 |  |  [Integrating Symmetry into Differentiable Planning with Steerable Convolutions](https://openreview.net/forum?id=n7CPzMPKQl) |  | 0 | To achieve this, we draw inspiration from equivariant convolution networks and model the path planning problem as a set of signals over grids. We demonstrate that value iteration can be treated as a linear equivariant operator, which is effectively a steerable convolution. Building upon Value... | Lawson L. S. Wong, Linfeng Zhao, Lingzhi Kong, Robin Walters, Xupeng Zhu |  |
| 1063 |  |  [Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning](https://openreview.net/forum?id=dcN0CaXQhT) |  | 0 | Latent confounding has been a long-standing obstacle for causal reasoning from observational data. One popular approach is to model the data using acyclic directed mixed graphs (ADMGs), which describe ancestral relations between variables using directed and bidirected edges. However, existing... | Agrin Hilmkil, Chao Ma, Cheng Zhang, Joel Jennings, Matthew Ashman |  |
| 1064 |  |  [O(T-1 Convergence of Optimistic-Follow-the-Regularized-Leader in Two-Player Zero-Sum Markov Games](https://openreview.net/forum?id=VWqiPBB_EM) |  | 0 | We prove that the optimistic-follow-the-regularized-leader (OFTRL) algorithm, together with smooth value updates, finds an $O(T^{−1})$ approximate Nash equilibrium in $T$ iterations for two-player zero-sum Markov games with full information. This improves the $\tilde{O}(T^{−5/6})$ convergence rate... | Cong Ma, Yuepeng Yang |  |
| 1065 |  |  [Bispectral Neural Networks](https://openreview.net/forum?id=xnsg4pfKb7) |  | 0 | We present a neural network architecture, Bispectral Neural Networks (BNNs) for learning representations that are invariant to the actions of compact commutative groups on the space over which a signal is defined. The model incorporates the ansatz of the bispectrum, an analytically defined group... | Bruno A. Olshausen, Christian Shewmake, Christopher J. Hillar, Sophia Sanborn |  |
| 1066 |  |  [Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD](https://openreview.net/forum?id=pOyi9KqE56b) |  | 0 | We provide sharp path-dependent generalization and excess risk guarantees for the full-batch Gradient Descent (GD) algorithm on smooth losses (possibly non-Lipschitz, possibly nonconvex). At the heart of our analysis is an upper bound on the generalization error, which implies that average output... | Amin Karbasi, Dionysios S. Kalogerias, Farzin Haddadpour, Konstantinos E. Nikolakakis |  |
| 1067 |  |  [Hyper-Decision Transformer for Efficient Online Policy Adaptation](https://openreview.net/forum?id=AatUEvC-Wjv) |  | 0 | Decision Transformers (DT) have demonstrated strong performances in offline reinforcement learning settings, but quickly adapting to unseen novel tasks remains challenging. To address this challenge, we propose a new framework, called Hyper-Decision Transformer (HDT), that can generalize to novel... | Chuang Gan, Ding Zhao, Mengdi Xu, Shun Zhang, Yikang Shen, Yuchen Lu |  |
| 1068 |  |  [Solving Continuous Control via Q-learning](https://openreview.net/forum?id=U5XOGxAgccS) |  | 0 | While there has been substantial success for solving continuous control with actor-critic methods, simpler critic-only methods such as Q-learning find limited application in the associated high-dimensional action spaces. However, most actor-critic methods come at the cost of added complexity:... | Daniela Rus, Igor Gilitschenski, Markus Wulfmeier, Martin A. Riedmiller, Peter Werner, Tim Seyde, Wilko Schwarting |  |
| 1069 |  |  [Make-A-Video: Text-to-Video Generation without Text-Video Data](https://openreview.net/forum?id=nJfylDvgzlq) |  | 0 | We propose Make-A-Video -- an approach for directly translating the tremendous recent progress in Text-to-Image (T2I) generation to Text-to-Video (T2V). Our intuition is simple: learn what the world looks like and how it is described from paired text-image data, and learn how the world moves from... | Adam Polyak, Devi Parikh, Harry Yang, Jie An, Oran Gafni, Oron Ashual, Qiyuan Hu, Sonal Gupta, Songyang Zhang, Thomas Hayes, Uriel Singer, Xi Yin, Yaniv Taigman |  |
| 1070 |  |  [Personalized Reward Learning with Interaction-Grounded Learning (IGL)](https://openreview.net/forum?id=wGvzQWFyUB) |  | 0 | In an era of countless content offerings, recommender systems alleviate information overload by providing users with personalized content suggestions. Due to the scarcity of explicit user feedback, modern recommender systems typically optimize for the same fixed combination of implicit feedback... | Akanksha Saran, Cheng Tan, Jessica Maghakian, Kishan Panaganti, Mark Rucker, Paul Mineiro |  |
| 1071 |  |  [Towards convergence to Nash equilibria in two-team zero-sum games](https://openreview.net/forum?id=4BPFwvKOvo5) |  | 0 | Contemporary applications of machine learning raise important and overlooked theoretical questions regarding optimization in two-team games. Formally, two-team zero-sum games are defined as multi-player games where players are split into two competing sets of agents, each experiencing a utility... | Emmanouil V. VlatakisGkaragkounis, Fivos Kalogiannis, Ioannis Panageas |  |
| 1072 |  |  [Discovering Evolution Strategies via Meta-Black-Box Optimization](https://openreview.net/forum?id=mFDU0fP3EQH) |  | 0 | Optimizing functions without access to gradients is the remit of black-box meth- ods such as evolution strategies. While highly general, their learning dynamics are often times heuristic and inflexible — exactly the limitations that meta-learning can address. Hence, we propose to discover effective... | Chris Lu, Robert Tjarko Lange, Satinder Singh, Sebastian Flennerhag, Tom Schaul, Tom Zahavy, Valentin Dalibard, Yutian Chen |  |
| 1073 |  |  [DensePure: Understanding Diffusion Models for Adversarial Robustness](https://openreview.net/forum?id=p7hvOJ6Gq0i) |  | 0 | Diffusion models have been recently employed to improve certified robustness through the process of denoising. However, the theoretical understanding of why diffusion models are able to improve the certified robustness is still lacking, preventing from further improvement. In this study, we close... | Anima Anandkumar, Bo Li, Chaowei Xiao, Dawn Song, Jiongxiao Wang, Kun Jin, Mingyan Liu, Weili Nie, Zhongzhu Chen |  |
| 1074 |  |  [Grounding Graph Network Simulators using Physical Sensor Observations](https://openreview.net/forum?id=jsZsEd8VEY) |  | 0 | Physical simulations that accurately model reality are crucial for many engineering disciplines such as mechanical engineering and robotic motion planning. In recent years, learned Graph Network Simulators produced accurate mesh-based simulations while requiring only a fraction of the computational... | Franziska MathisUllrich, Gerhard Neumann, Jonas Linkerhägner, Niklas Freymuth, Paul Maria Scheikl |  |
| 1075 |  |  [Where to Diffuse, How to Diffuse, and How to Get Back: Automated Learning for Multivariate Diffusions](https://openreview.net/forum?id=osei3IzUia) |  | 0 | Diffusion-based generative models (DBGMs) perturb data to a target noise distribution and reverse this process to generate samples. The choice of noising process, or inference diffusion process, affects both likelihoods and sample quality. For example, extending the inference process with auxiliary... | Mark Goldstein, Raghav Singhal, Rajesh Ranganath |  |
| 1076 |  |  [Contrastive Corpus Attribution for Explaining Representations](https://openreview.net/forum?id=eWKfMBL5to) |  | 0 | Despite the widespread use of unsupervised models, very few methods are designed to explain them. Most explanation methods explain a scalar model output. However, unsupervised models output representation vectors, the elements of which are not good candidates to explain because they lack semantic... | Chanwoo Kim, Chris Lin, Hugh Chen, SuIn Lee |  |
| 1077 |  |  [Spatio-temporal point processes with deep non-stationary kernels](https://openreview.net/forum?id=PsIk0kO3hKd) |  | 0 | Point process data are becoming ubiquitous in modern applications, such as social networks, health care, and finance. Despite the powerful expressiveness of the popular recurrent neural network (RNN) models for point process data, they may not successfully capture sophisticated non-stationary... | Xiuyuan Cheng, Yao Xie, Zheng Dong |  |
| 1078 |  |  [Federated Learning from Small Datasets](https://openreview.net/forum?id=hDDV1lsRV8) |  | 0 | Federated learning allows multiple parties to collaboratively train a joint model without having to share any local data. It enables applications of machine learning in settings where data is inherently distributed and undisclosable, such as in the medical domain. Joint training is usually achieved... | Jilles Vreeken, Jonas Fischer, Michael Kamp |  |
| 1079 |  |  [Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences](https://openreview.net/forum?id=lGz9u1ubUXE) |  | 0 | Generating complex behaviors that satisfy the preferences of non-expert users is a crucial requirement for AI agents. Interactive reward learning from trajectory comparisons (a.k.a. RLHF) is one way to allow non-expert users to convey complex objectives by expressing preferences over short clips of... | Karthik Valmeekam, Lin Guan, Subbarao Kambhampati |  |
| 1080 |  |  [Scalable Batch-Mode Deep Bayesian Active Learning via Equivalence Class Annealing](https://openreview.net/forum?id=GRZtigJljLY) |  | 0 | Active learning has demonstrated data efficiency in many fields. Existing active learning algorithms, especially in the context of batch-mode deep Bayesian active models, rely heavily on the quality of uncertainty estimations of the model, and are often challenging to scale to large batches. In... | Aly A. Khan, Renyu Zhang, Robert L. Grossman, Yuxin Chen |  |
| 1081 |  |  [Semi-Parametric Inducing Point Networks and Neural Processes](https://openreview.net/forum?id=FE99-fDrWd5) |  | 0 | We introduce semi-parametric inducing point networks (SPIN), a general-purpose architecture that can query the training set at inference time in a compute-efficient manner. Semi-parametric architectures are typically more compact than parametric models, but their computational complexity is often... | Alon Hacohen, Ian Lee, Mert R. Sabuncu, Richa Rastogi, Volodymyr Kuleshov, Yair Schiff, Yuntian Deng, Zhaozhi Li |  |
| 1082 |  |  [DAG Learning on the Permutahedron](https://openreview.net/forum?id=m9LCdYgN8-6) |  | 0 | We propose a continuous optimization framework for discovering a latent directed acyclic graph (DAG) from observational data. Our approach optimizes over the polytope of permutation vectors, the so-called Permutahedron, to learn a topological ordering. Edges can be optimized jointly, or learned... | Jean Kaddour, Luca Franceschi, Matt J. Kusner, Valentina Zantedeschi, Vlad Niculae |  |
| 1083 |  |  [Explicitly Minimizing the Blur Error of Variational Autoencoders](https://openreview.net/forum?id=9krnQ-ue9M) |  | 0 | Variational autoencoders (VAEs) are powerful generative modelling methods, however they suffer from blurry generated samples and reconstructions compared to the images they have been trained on. Significant research effort has been spent to increase the generative capabilities by creating more... | Ender Konukoglu, Ertunc Erdil, Gustav Bredell, Krishna Chaitanya, Kyriakos Flouris |  |
| 1084 |  |  [3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction](https://openreview.net/forum?id=kJqXEPXMsE0) |  | 0 | Rich data and powerful machine learning models allow us to design drugs for a specific protein target <em>in silico</em>. Recently, the inclusion of 3D structures during targeted drug design shows superior performance to other target-free models as the atomic interaction in the 3D space is... | Jian Peng, Jianzhu Ma, Jiaqi Guan, Wesley Wei Qian, Xingang Peng, Yufeng Su |  |
| 1085 |  |  [How gradient estimator variance and bias impact learning in neural networks](https://openreview.net/forum?id=EBC60mxBwyw) |  | 0 | There is growing interest in understanding how real brains may approximate gradients and how gradients can be used to train neuromorphic chips. However, neither real brains nor neuromorphic chips can perfectly follow the loss gradient, so parameter updates would necessarily use gradient estimators... | Arna Ghosh, Blake Aaron Richards, Guillaume Lajoie, Konrad P. Körding, Yuhan Helena Liu |  |
| 1086 |  |  [Evaluating Representations with Readout Model Switching](https://openreview.net/forum?id=Fsd-6ax4T1m) |  | 0 | Although much of the success of Deep Learning builds on learning good representations, a rigorous method to evaluate their quality is lacking. In this paper, we treat the evaluation of representations as a model selection problem and propose to use the Minimum Description Length (MDL) principle to... | Jörg Bornschein, Marcus Hutter, Yazhe Li |  |
| 1087 |  |  [Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation](https://openreview.net/forum?id=kPPVmUF6bM_) |  | 0 | Knowledge distillation is one of the primary methods of transferring knowledge from large to small models. However, it requires massive task-specific data, which may not be plausible in many real-world applications. Data augmentation methods such as representation interpolation, token replacement,... | Daogao Liu, Frederick Liu, Heng Ji, Hongkun Yu, Jing Li, Le Hou, Yuexin Wu, Ziqi Wang |  |
| 1088 |  |  [Pseudoinverse-Guided Diffusion Models for Inverse Problems](https://openreview.net/forum?id=9_gsMA8MRKQ) |  | 0 | Diffusion models have become competitive candidates for solving various inverse problems. Models trained for specific inverse problems work well but are limited to their particular use cases, whereas methods that use problem-agnostic models are general but often perform worse empirically. To... | Arash Vahdat, Jan Kautz, Jiaming Song, Morteza Mardani |  |
| 1089 |  |  [Planning with Sequence Models through Iterative Energy Minimization](https://openreview.net/forum?id=cVFD6qE8gnY) |  | 0 | Recent works have shown that language modeling can be effectively used to train reinforcement learning (RL) policies. However, the success of applying existing language models to planning, in which we wish to obtain a trajectory of actions to reach some goal, is less straightforward. The typical... | Hongyi Chen, Joshua B. Tenenbaum, Patricio A. Vela, Yilun Du, Yiye Chen |  |
| 1090 |  |  [Verifying the Union of Manifolds Hypothesis for Image Data](https://openreview.net/forum?id=Rvee9CAX4fi) |  | 0 | Deep learning has had tremendous success at learning low-dimensional representations of high-dimensional data. This success would be impossible if there was no hidden low-dimensional structure in data of interest; this existence is posited by the manifold hypothesis, which states that the data lies... | Anthony L. Caterini, Bradley C. A. Brown, Brendan Leigh Ross, Gabriel LoaizaGanem, Jesse C. Cresswell |  |
| 1091 |  |  [Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning](https://openreview.net/forum?id=zlbci7019Z3) |  | 0 | Humans excel at lifelong learning, as the brain has evolved to be robust to distribution shifts and noise in our ever-changing environment. Deep neural networks (DNNs), however, exhibit catastrophic forgetting and the learned representations drift drastically as they encounter a new task. This... | Bahram Zonooz, Elahe Arani, Fahad Sarfraz |  |
| 1092 |  |  [Don't forget the nullspace! Nullspace occupancy as a mechanism for out of distribution failure](https://openreview.net/forum?id=39z0zPZ0AvB) |  | 0 | Out of distribution (OoD) generalization has received considerable interest in recent years. In this work, we identify a particular failure mode of OoD generalization for discriminative classifiers that is based on test data (from a new domain) lying in the nullspace of features learnt from source... | Daksh Idnani, David J. Schwab, Naman Goyal, Ramakrishna Vedantam, Vivek Madan |  |
| 1093 |  |  [ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond](https://openreview.net/forum?id=SM7XkJouWHm) |  | 0 | Oversmoothing is a common phenomenon in a wide range of Graph Neural Networks (GNNs) and Transformers, where performance degenerates as the layer goes deeper. Instead of characterizing oversmoothing from the view of complete collapse in which representations converge to a single point, we dive into... | Tianqi Du, Xiaojun Guo, Yifei Wang, Yisen Wang |  |
| 1094 |  |  [Accelerated Single-Call Methods for Constrained Min-Max Optimization](https://openreview.net/forum?id=HRwN7IQLUKA) |  | 0 | We study first-order methods for constrained min-max optimization. Existing methods either require two gradient calls or two projections in each iteration, which may be costly in some applications. In this paper, we first show that a variant of the \emph{Optimistic Gradient (OG)} method, a... | Weiqiang Zheng, Yang Cai |  |
| 1095 |  |  [Distributed Extra-gradient with Optimal Complexity and Communication Guarantees](https://openreview.net/forum?id=b3itJyarLM0) |  | 0 | We consider monotone variational inequality (VI) problems in multi-GPU settings where multiple processors/workers/clients have access to local stochastic dual vectors. This setting includes a broad range of important problems from distributed convex minimization to min-max and games.... | Ali RamezaniKebrya, Igor Krawczuk, Justin Deschenaux, Kimon Antonakopoulos, Volkan Cevher |  |
| 1096 |  |  [Performance Bounds for Model and Policy Transfer in Hidden-parameter MDPs](https://openreview.net/forum?id=20gBzEzgtiI) |  | 0 | In the Hidden-Parameter MDP (HiP-MDP) framework, a family of reinforcement learning tasks is generated by varying hidden parameters specifying the dynamics and reward function for each individual task. HiP-MDP is a natural model for families of tasks in which meta- and lifelong-reinforcement... | Finale DoshiVelez, George Konidaris, Haotian Fu, Jiayu Yao, Omer Gottesman |  |
| 1097 |  |  [Composing Task Knowledge With Modular Successor Feature Approximators](https://openreview.net/forum?id=DrtSx1z40Ib) |  | 0 | Recently, the Successor Features and Generalized Policy Improvement (SF&GPI) framework has been proposed as a method for learning, composing and transferring predictive knowledge and behavior. SF&GPI works by having an agent learn predictive representations (SFs) that can be combined for transfer... | Angelos Filos, Honglak Lee, Richard L. Lewis, Satinder Singh, Wilka Carvalho |  |
| 1098 |  |  [DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics](https://openreview.net/forum?id=LIV7-_7pYPl) |  | 0 | In this work, we aim to learn dexterous manipulation of deformable objects using multi-fingered hands. Reinforcement learning approaches for dexterous rigid object manipulation would struggle in this setting due to the complexity of physics interaction with deformable objects. At the same time,... | Chuang Gan, Hao Su, Joshua B. Tenenbaum, Sizhe Li, Tao Chen, Tao Du, Zhiao Huang |  |
| 1099 |  |  [Effective passive membership inference attacks in federated learning against overparameterized models](https://openreview.net/forum?id=QsCSLPP55Ku) |  | 0 | This work considers the challenge of performing membership inference attacks in a federated learning setting ---for image classification--- where an adversary can only observe the communication between the central node and a single client (a passive white-box attack). Passive attacks are one of the... | Bruno Ribeiro, Jiacheng Li, Ninghui Li |  |
| 1100 |  |  [Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning](https://openreview.net/forum?id=9EAQVEINuum) |  | 0 | We present a bi-encoder framework for named entity recognition (NER), which applies contrastive learning to map candidate text spans and entity types into the same vector representation space. Prior work predominantly approaches NER as sequence labeling or span classification. We instead frame NER... | Hao Cheng, Hoifung Poon, Jianfeng Gao, Sheng Zhang |  |
| 1101 |  |  [Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for Deep Neural Networks](https://openreview.net/forum?id=p_jIy5QFB7) |  | 0 | Deep neural network (DNN) classifiers are often overconfident, producing miscalibrated class probabilities. In high-risk applications like healthcare, practitioners require fully calibrated probability predictions for decision-making. That is, conditioned on the prediction vector, every class’... | Jimeng Sun, Shubhendu Trivedi, Zhen Lin |  |
| 1102 |  |  [SemPPL: Predicting Pseudo-Labels for Better Contrastive Representations](https://openreview.net/forum?id=TAVBJ4aHsWt) |  | 0 | Learning from large amounts of unsupervised data and a small amount of supervision is an important open problem in computer vision. We propose a new semi-supervised learning method, Semantic Positives via Pseudo-Labels (SEMPPL), that combines labelled and unlabelled data to learn informative... | Charles Blundell, Felix Hill, Florian Strub, Jacob C. Walker, Jovana Mitrovic, Lars Holger Buesing, Matko Bosnjak, Nenad Tomasev, Pierre Harvey Richemond, Razvan Pascanu |  |
| 1103 |  |  [Differentially Private Adaptive Optimization with Delayed Preconditioners](https://openreview.net/forum?id=j1zQGmQQOX1) |  | 0 | Privacy costs may negate the benefits of using adaptive optimizers in differentially private model training. Prior works typically address this issue by using auxiliary information (e.g., public data) to boost the effectiveness of adaptive optimization. In this work, we explore techniques to... | Hugh Brendan McMahan, Ken Liu, Manzil Zaheer, Sashank J. Reddi, Tian Li, Virginia Smith |  |
| 1104 |  |  [Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions](https://openreview.net/forum?id=vOEXS39nOF) |  | 0 | We present Phenaki, a model capable of realistic video synthesis given a sequence of textual prompts. Generating videos from text is particularly challenging due to the computational cost, limited quantities of high quality text-video data and variable length of videos. To address these issues, we... | Dumitru Erhan, Han Zhang, Hernan Moraldo, Julius Kunze, Mohammad Babaeizadeh, Mohammad Taghi Saffar, PieterJan Kindermans, Ruben Villegas, Santiago Castro |  |
| 1105 |  |  [Long Range Language Modeling via Gated State Spaces](https://openreview.net/forum?id=5MkYIYCbva) |  | 0 | State space models have shown to be effective at modeling long range dependencies, specially on sequence classification tasks. In this work we focus on autoregressive sequence modeling over English books, Github source code and ArXiv mathematics articles. Based on recent developments around the... | Ankit Gupta, Ashok Cutkosky, Behnam Neyshabur, Harsh Mehta |  |
| 1106 |  |  [Bayes-MIL: A New Probabilistic Perspective on Attention-based Multiple Instance Learning for Whole Slide Images](https://openreview.net/forum?id=_geIwiOyUhZ) |  | 0 | Multiple instance learning (MIL) is a popular weakly-supervised learning model on the whole slide image (WSI) for AI-assisted pathology diagnosis. The recent advance in attention-based MIL allows the model to find its region-of-interest (ROI) for interpretation by learning the attention weights for... | Antoni B. Chan, Chun Jason Xue, Cong Wang, TeiWei Kuo, Xiangyu Liu, Xue Liu, Yufei Cui, Ziquan Liu |  |
| 1107 |  |  [Investigating Multi-task Pretraining and Generalization in Reinforcement Learning](https://openreview.net/forum?id=sSt9fROSZRO) |  | 0 | Deep reinforcement learning~(RL) has achieved remarkable successes in complex single-task settings. However, designing RL agents that can learn multiple tasks and leverage prior experience to quickly adapt to a related new task remains challenging. Despite previous attempts to improve on these... | Aaron C. Courville, Adrien Ali Taïga, Jesse Farebrother, Marc G. Bellemare, Rishabh Agarwal |  |
| 1108 |  |  [FIT: A Metric for Model Sensitivity](https://openreview.net/forum?id=PDG4-Y3aboN) |  | 0 | Model compression is vital to the deployment of deep learning on edge devices. Low precision representations, achieved via quantization of weights and activations, can reduce inference time and memory requirements. However, quantifying and predicting the response of a model to the changes... | Adrian Alan Pol, Ben Zandonati, Maurizio Pierini, Olya Sirkin, Tal Kopetz |  |
| 1109 |  |  [Transfer Learning with Deep Tabular Models](https://openreview.net/forum?id=b0RuGUYo8pA) |  | 0 | Recent work on deep learning for tabular data demonstrates the strong performance of deep tabular models, often bridging the gap between gradient boosted decision trees and neural networks. Accuracy aside, a major advantage of neural models is that they are easily fine-tuned in new domains and... | Andrew Gordon Wilson, Arpit Bansal, Avi Schwarzschild, C. Bayan Bruss, Micah Goldblum, Roman Levin, Tom Goldstein, Valeriia Cherepanova |  |
| 1110 |  |  [CrAM: A Compression-Aware Minimizer](https://openreview.net/forum?id=_eTZBs-yedr) |  | 0 | Deep neural networks (DNNs) often have to be compressed, via pruning and/or quantization, before they can be deployed in practical settings. In this work we propose a new compression-aware minimizer dubbed CrAM that modifies the optimization step in a principled way, in order to produce models... | Adrian Vladu, Alexandra Peste, Christoph H. Lampert, Dan Alistarh, Eldar Kurtic |  |
| 1111 |  |  [Understanding Train-Validation Split in Meta-Learning with Neural Networks](https://openreview.net/forum?id=JVlyfHEEm0k) |  | 0 | The goal of meta-learning is to learn a good prior model from a collection of tasks such that the learned prior is able to adapt quickly to new tasks without accessing many data from the new tasks. A common practice in meta-learning is to perform a train-validation split on each task, where the... | Huaxiu Yao, Quanquan Gu, Xinzhe Zuo, Yuan Cao, Zixiang Chen |  |
| 1112 |  |  [Revisiting Robustness in Graph Machine Learning](https://openreview.net/forum?id=h1o7Ry9Zctm) |  | 0 | Many works show that node-level predictions of Graph Neural Networks (GNNs) are unrobust to small, often termed adversarial, changes to the graph structure. However, because manual inspection of a graph is difficult, it is unclear if the studied perturbations always preserve a core assumption of... | Daniel Sturm, Lukas Gosch, Simon Geisler, Stephan Günnemann |  |
| 1113 |  |  [Variational Information Pursuit for Interpretable Predictions](https://openreview.net/forum?id=77lSWa-Tm3Z) |  | 0 | There is a growing interest in the machine learning community in developing predictive algorithms that are interpretable by design. To this end, recent work proposes to sequentially ask interpretable queries about data until a high confidence prediction can be made based on the answers obtained... | Aditya Chattopadhyay, Benjamin David Haeffele, Donald Geman, Kwan Ho Ryan Chan, René Vidal |  |
| 1114 |  |  [Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints](https://openreview.net/forum?id=T5nUQDrM4u) |  | 0 | Training large, deep neural networks to convergence can be prohibitively expensive. As a result, often only a small selection of popular, dense models are reused across different contexts and tasks. Increasingly, sparsely activated models, which seek to decouple model size from computation costs,... | Aran Komatsuzaki, Basil Mustafa, Carlos Riquelme Ruiz, James LeeThorp, Joan Puigcerver, Joshua Ainslie, Mostafa Dehghani, Neil Houlsby, Yi Tay |  |
| 1115 |  |  [Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation](https://openreview.net/forum?id=5IND3TXJRb-) |  | 0 | Recent works have shown that large models pretrained on common visual learning tasks can provide useful representations for a wide range of specialized perception problems, as well as a variety of robotic manipulation tasks. While prior work on robotic manipulation has predominantly used frozen... | Claudio Fantacci, Jon Scholz, Mohit Sharma, Nicolas Heess, Skanda Koppula, Yusuf Aytar, Yuxiang Zhou |  |
| 1116 |  |  [Logical Message Passing Networks with One-hop Inference on Atomic Formulas](https://openreview.net/forum?id=SoyOsp7i_l) |  | 0 | Complex Query Answering (CQA) over Knowledge Graphs (KGs) has attracted a lot of attention to potentially support many applications. Given that KGs are usually incomplete, neural models are proposed to answer the logical queries by parameterizing set operators with complex neural networks. However,... | Ginny Y. Wong, Simon See, Yangqiu Song, Zihao Wang |  |
| 1117 |  |  [Noise-Robust De-Duplication at Scale](https://openreview.net/forum?id=bAz2DBS35i) |  | 0 | Identifying near duplicates within large, noisy text corpora has a myriad of applications that range from de-duplicating training datasets, reducing privacy risk, and evaluating test set leakage, to identifying reproduced news articles and literature within large corpora. Across these diverse... | Emily Silcock, Jinglin Yang, Luca D'AmicoWong, Melissa Dell |  |
| 1118 |  |  [Few-shot Backdoor Attacks via Neural Tangent Kernels](https://openreview.net/forum?id=a70lGJ-rwy) |  | 0 | In a backdoor attack, an attacker injects corrupted examples into the training set. The goal of the attacker is to cause the final trained model to predict the attacker's desired target label when a predefined trigger is added to test inputs. Central to these attacks is the trade-off between the... | Jonathan Hayase, Sewoong Oh |  |
| 1119 |  |  [Hyperparameter Optimization through Neural Network Partitioning](https://openreview.net/forum?id=nAgdXgfmqj) |  | 0 | Well-tuned hyperparameters are crucial for obtaining good generalization behavior in neural networks. They can enforce appropriate inductive biases, regularize the model and improve performance --- especially in the presence of limited data. In this work, we propose a simple and efficient way for... | Bruno Mlodozeniec, Christos Louizos, Matthias Reisser |  |
| 1120 |  |  [Symmetries, Flat Minima, and the Conserved Quantities of Gradient Flow](https://openreview.net/forum?id=9ZpciCOunFb) |  | 0 | Empirical studies of the loss landscape of deep networks have revealed that many local minima are connected through low-loss valleys. Yet, little is known about the theoretical origin of such valleys. We present a general framework for finding continuous symmetries in the parameter space, which... | Bo Zhao, Iordan Ganev, Nima Dehmamy, Robin Walters, Rose Yu |  |
| 1121 |  |  [Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees](https://openreview.net/forum?id=ooxDOe7ZtBe) |  | 0 | Current abstractive summarization models either suffer from a lack of clear interpretability or provide incomplete rationales by only highlighting parts of the source document. To this end, we propose the Summarization Program (SP), an interpretable modular framework consisting of an (ordered) list... | Mohit Bansal, Peter Hase, Shiyue Zhang, Swarnadeep Saha |  |
| 1122 |  |  [Planning with Large Language Models for Code Generation](https://openreview.net/forum?id=Lr8cOOtYbfL) |  | 0 | Existing large language model-based code generation pipelines typically use beam search or sampling algorithms during the decoding process. Although the programs they generate achieve high token-matching-based scores, they often fail to compile or generate incorrect outputs. The main reason is that... | Chuang Gan, Joshua B. Tenenbaum, Mingyu Ding, Shun Zhang, Yikang Shen, Zhenfang Chen |  |
| 1123 |  |  [Equivariance-aware Architectural Optimization of Neural Networks](https://openreview.net/forum?id=a6rCdfABJXg) |  | 0 | Incorporating equivariance to symmetry groups as a constraint during neural network training can improve performance and generalization for tasks exhibiting those symmetries, but such symmetries are often not perfectly nor explicitly present. This motivates algorithmically optimizing the... | Dennis George Wilson, Kaitlin Maile, Patrick Forré |  |
| 1124 |  |  [Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time](https://openreview.net/forum?id=FbRY1XVfwK) |  | 0 | Hamiltonian Monte Carlo (HMC) is a popular method in sampling. While there are quite a few works of studying this method on various aspects, an interesting question is how to choose its integration time to achieve acceleration. In this work, we consider accelerating the process of sampling from a... | Andre Wibisono, JunKun Wang |  |
| 1125 |  |  [Order Matters: Agent-by-agent Policy Optimization](https://openreview.net/forum?id=Q-neeWNVv1) |  | 0 | While multi-agent trust region algorithms have achieved great success empirically in solving coordination tasks, most of them, however, suffer from a non-stationarity problem since agents update their policies simultaneously. In contrast, a sequential scheme that updates policies agent-by-agent... | Jun Wang, Weinan Zhang, Xihuai Wang, Ying Wen, Zheng Tian, Ziyu Wan |  |
| 1126 |  |  [On the Convergence of AdaGrad(Norm) on ℝd: Beyond Convexity, Non-Asymptotic Rate and Acceleration](https://openreview.net/forum?id=ULnHxczCBaE) |  | 0 | Existing analysis of AdaGrad and other adaptive methods for smooth convex optimization is typically for functions with bounded domain diameter. In unconstrained problems, previous works guarantee an asymptotic convergence rate without an explicit constant factor that holds true for the entire... | Alina Ene, Huy L. Nguyen, Ta Duy Nguyen, Zijian Liu |  |
| 1127 |  |  [SP2 : A Second Order Stochastic Polyak Method](https://openreview.net/forum?id=5mqFra2ZSuf) |  | 0 | Recently the SP (Stochastic Polyak step size) method has emerged as a competitive adaptive method for setting the step sizes of SGD. SP can be interpreted as a method specialized to interpolated models, since it solves the interpolation equations. SP solves these equation by using local... | Deanna Needell, Martin Takác, Robert M. Gower, Shuang Li, William J. Swartworth |  |
| 1128 |  |  [Making Better Decision by Directly Planning in Continuous Control](https://openreview.net/forum?id=r8Mu7idxyF) |  | 0 | By properly utilizing the learned environment model, model-based reinforcement learning methods can improve the sample efficiency for decision-making problems. Beyond using the learned environment model to train a policy, the success of MCTS-based methods shows that directly incorporating the... | Houqiang Li, Jinhua Zhu, Lijun Wu, Tao Qin, TieYan Liu, Wengang Zhou, Yue Wang |  |
| 1129 |  |  [HiT-MDP: Learning the SMDP option framework on MDPs with Hidden Temporal Embeddings](https://openreview.net/forum?id=VuuDXDgujAc) |  | 0 | The standard option framework is developed on the Semi-Markov Decision Process (SMDP) which is unstable to optimize and sample inefficient. To this end, we propose the Hidden Temporal MDP (HiT-MDP) and prove that the option-induced HiT-MDP is homomorphic equivalent to the option-induced SMDP. A... | Chang Li, Dacheng Tao, Dongjin Song |  |
| 1130 |  |  [(Certified!!) Adversarial Robustness for Free!](https://openreview.net/forum?id=JLg5aHHv7j) |  | 0 | In this paper we show how to achieve state-of-the-art certified adversarial robustness to 2-norm bounded perturbations by relying exclusively on off-the-shelf pretrained models. To do so, we instantiate the denoised smoothing approach of Salman et al. by combining a pretrained denoising diffusion... | Florian Tramèr, J. Zico Kolter, Krishnamurthy (Dj) Dvijotham, Leslie Rice, Mingjie Sun, Nicholas Carlini |  |
| 1131 |  |  [Heterogeneous Neuronal and Synaptic Dynamics for Spike-Efficient Unsupervised Learning: Theory and Design Principles](https://openreview.net/forum?id=QIRtAqoXwj) |  | 0 | This paper shows that the heterogeneity in neuronal and synaptic dynamics reduces the spiking activity of a Recurrent Spiking Neural Network (RSNN) while improving prediction performance, enabling spike-efficient (unsupervised) learning. We analytically show that the diversity in neurons'... | Biswadeep Chakraborty, Saibal Mukhopadhyay |  |
| 1132 |  |  [MMVAE+: Enhancing the Generative Quality of Multimodal VAEs without Compromises](https://openreview.net/forum?id=sdQGxouELX) |  | 0 | Multimodal VAEs have recently gained attention as efficient models for weakly-supervised generative learning with multiple modalities. However, all existing variants of multimodal VAEs are affected by a non-trivial trade-off between generative quality and generative coherence. In particular... | Emanuele Palumbo, Imant Daunhawer, Julia E. Vogt |  |
| 1133 |  |  [In-Situ Text-Only Adaptation of Speech Models with Low-Overhead Speech Imputations](https://openreview.net/forum?id=T2Ncx_PN2K) |  | 0 | Fast and accurate adaptation of automatic speech recognition (ASR) systems using only text data in the target domain is a problem of long-standing practical relevance. Text-only adaptation was easy in traditional cascaded ASR systems with completely decoupled acoustic and language models. Recently,... | Ashish R. Mittal, Preethi Jyothi, Sunita Sarawagi |  |
| 1134 |  |  [Scaling Laws For Deep Learning Based Image Reconstruction](https://openreview.net/forum?id=op-ceGueqc4) |  | 0 | Deep neural networks trained end-to-end to map a measurement of a (noisy) image to a clean image perform excellent for a variety of linear inverse problems. Current methods are only trained on a few hundreds or thousands of images as opposed to the millions of examples deep networks are trained on... | Reinhard Heckel, Tobit Klug |  |
| 1135 |  |  [Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning](https://openreview.net/forum?id=3oWo92cQyxL) |  | 0 | Multimodal few-shot learning is challenging due to the large domain gap between vision and language modalities. Existing methods are trying to communicate visual concepts as prompts to frozen language models, but rely on hand-engineered task induction to reduce the hypothesis space. To make the... | Ivona Najdenkoska, Marcel Worring, Xiantong Zhen |  |
| 1136 |  |  [SoftZoo: A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments](https://openreview.net/forum?id=Xyme9p1rpZw) |  | 0 | While significant research progress has been made in robot learning for control, unique challenges arise when simultaneously co-optimizing morphology. Existing work has typically been tailored for particular environments or representations. In order to more fully understand inherent design and... | Andrew Everett Spielberg, Chuang Gan, Daniela Rus, Hao Zhang, Joshua B. Tenenbaum, Pingchuan Ma, TsunHsuan Wang, Zhou Xian |  |
| 1137 |  |  [Improved Learning-augmented Algorithms for k-means and k-medians Clustering](https://openreview.net/forum?id=dCSFiAl_VO3) |  | 0 | We consider the problem of clustering in the learning-augmented setting. We are given a data set in $d$-dimensional Euclidean space, and a label for each data point given by a predictor indicating what subsets of points should be clustered together. This setting captures situations where we have... | Anamay Chaturvedi, Huy L. Nguyen, Thy Dinh Nguyen |  |
| 1138 |  |  [Neural Implicit Shape Editing using Boundary Sensitivity](https://openreview.net/forum?id=CMPIBjmhpo) |  | 0 | Neural fields are receiving increased attention as a geometric representation due to their ability to compactly store detailed and smooth shapes and easily undergo topological changes. Compared to classic geometry representations, however, neural representations do not allow the user to exert... | Arturs Berzins, Leif Kobbelt, Moritz Ibing |  |
| 1139 |  |  [Amortised Invariance Learning for Contrastive Self-Supervision](https://openreview.net/forum?id=nXOhmfFu5n) |  | 0 | Contrastive self-supervised learning methods famously produce high quality transferable representations by learning invariances to different data augmentations. Invariances established during pre-training can be interpreted as strong inductive biases. However these may or may not be helpful,... | Calum Heggan, Jan Stuehmer, Mehrdad Yaghoobi, Ruchika Chavhan, Timothy M. Hospedales |  |
| 1140 |  |  [Revisiting Populations in multi-agent Communication](https://openreview.net/forum?id=n-UHRIdPju) |  | 0 | Despite evidence from cognitive sciences that larger groups of speakers tend to develop more structured languages in human communication, scaling up to populations has failed to yield significant benefits in emergent multi-agent communication. In this paper we advocate for an alternate... | Angeliki Lazaridou, Kory Wallace Mathewson, Mathieu Rita, Olivier Tieleman, Paul Michel |  |
| 1141 |  |  [Sequential Gradient Coding For Straggler Mitigation](https://openreview.net/forum?id=-lGvSmht7a) |  | 0 | In distributed computing, slower nodes (stragglers) usually become a bottleneck. Gradient Coding (GC), introduced by Tandon et al., is an efficient technique that uses principles of error-correcting codes to distribute gradient computation in the presence of stragglers. In this paper, we consider... | Ashish J. Khisti, MohammadReza Ebrahimi, Muralee Nikhil Krishnan |  |
| 1142 |  |  [TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation](https://openreview.net/forum?id=EQfeudmWLQ) |  | 0 | This paper proposes a novel batch normalization strategy for test-time adaptation. Recent test-time adaptation methods heavily rely on the modified batch normalization, i.e., transductive batch normalization (TBN), which calculates the mean and the variance from the current test batch rather than... | Byeonggeun Kim, Hyesu Lim, Jaegul Choo, Sungha Choi |  |
| 1143 |  |  [Disentanglement of Correlated Factors via Hausdorff Factorized Support](https://openreview.net/forum?id=OKcJhpQiGiX) |  | 0 | A grand goal in deep learning research is to learn representations capable of generalizing across distribution shifts. Disentanglement is one promising direction aimed at aligning a model's representation with the underlying factors generating the data (e.g. color or background). Existing... | Diane Bouchacourt, Karsten Roth, Mark Ibrahim, Pascal Vincent, Zeynep Akata |  |
| 1144 |  |  [Generating Sequences by Learning to Self-Correct](https://openreview.net/forum?id=hH36JeQZDaO) |  | 0 | Sequence generation applications require satisfying semantic constraints, such as ensuring that programs are correct, using certain keywords, or avoiding undesirable content. Language models, whether fine-tuned or prompted with few-shot demonstrations, frequently violate these constraints, and lack... | Daniel Khashabi, Faeze Brahman, Peter West, Sean Welleck, Tianxiao Shen, Ximing Lu, Yejin Choi |  |
| 1145 |  |  [Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation](https://openreview.net/forum?id=3mlITJRYYbs) |  | 0 | Early sensory systems in the brain rapidly adapt to fluctuating input statistics, which requires recurrent communication between neurons. Mechanistically, such recurrent communication is often indirect and mediated by local interneurons. In this work, we explore the computational benefits of... | Cengiz Pehlevan, David Lipshutz, Dmitri B. Chklovskii |  |
| 1146 |  |  [Understanding DDPM Latent Codes Through Optimal Transport](https://openreview.net/forum?id=6PIrhAx1j4i) |  | 0 | Diffusion models have recently outperformed alternative approaches to model the distribution of natural images. Such diffusion models allow for deterministic sampling via the probability flow ODE, giving rise to a latent space and an encoder map. While having important practical applications, such... | Andrei Chertkov, Gleb V. Ryzhakov, Ivan V. Oseledets, Valentin Khrulkov |  |
| 1147 |  |  [Latent Neural ODEs with Sparse Bayesian Multiple Shooting](https://openreview.net/forum?id=moIlFZfj_1b) |  | 0 | Training dynamic models, such as neural ODEs, on long trajectories is a hard problem that requires using various tricks, such as trajectory splitting, to make model training work in practice. These methods are often heuristics with poor theoretical justifications, and require iterative manual... | Harri Lähdesmäki, Markus Heinonen, Valerii Iakovlev, Çagatay Yildiz |  |
| 1148 |  |  [𝒪-GNN: incorporating ring priors into molecular modeling](https://openreview.net/forum?id=5cFfz6yMVPU) |  | 0 | Cyclic compounds that contain at least one ring play an important role in drug design. Despite the recent success of molecular modeling with graph neural networks (GNNs), few models explicitly take rings in compounds into consideration, consequently limiting the expressiveness of the models. In... | Bohan Wang, Houqiang Li, Jinhua Zhu, Kehan Wu, Lijun Wu, Qi Meng, Shufang Xie, Tao Qin, TieYan Liu, Wengang Zhou, Yingce Xia |  |
| 1149 |  |  [MACTA: A Multi-agent Reinforcement Learning Approach for Cache Timing Attacks and Detection](https://openreview.net/forum?id=CDlHZ78-Xzi) |  | 0 | Security vulnerabilities in computer systems raise serious concerns as computers process an unprecedented amount of private and sensitive data today. Cache timing attacks (CTA) pose an important practical threat as they can effectively breach many protection mechanisms in today’s systems. However,... | Benjamin Lee, G. Edward Suh, Geunbae Lee, HsienHsin S. Lee, Jiaxun Cui, Mulong Luo, Peter Stone, Wenjie Xiong, Xiaomeng Yang, Yuandong Tian |  |
| 1150 |  |  [PAC Reinforcement Learning for Predictive State Representations](https://openreview.net/forum?id=FVW7Mi2ph6C) |  | 0 | In this paper we study online Reinforcement Learning (RL) in partially observable dynamical systems. We focus on the Predictive State Representations (PSRs) model, which is an expressive model that captures other well-known models such as Partially Observable Markov Decision Processes (POMDP). PSR... | Jason D. Lee, Masatoshi Uehara, Wen Sun, Wenhao Zhan |  |
| 1151 |  |  [Decentralized Optimistic Hyperpolicy Mirror Descent: Provably No-Regret Learning in Markov Games](https://openreview.net/forum?id=bn0GZZdDfI1) |  | 0 | We study decentralized policy learning in Markov games where we control a single agent to play with nonstationary and possibly adversarial opponents. Our goal is to develop a no-regret online learning algorithm that (i) takes actions based on the local information observed by the agent and (ii) is... | Jason D. Lee, Wenhao Zhan, Zhuoran Yang |  |
| 1152 |  |  [Robust Scheduling with GFlowNets](https://openreview.net/forum?id=ZBUthI6wK9h) |  | 0 | Finding the best way to schedule operations in a computation graph is a classical NP-hard problem which is central to compiler optimization. However, evaluating the goodness of a schedule on the target hardware can be very time-consuming. Traditional approaches as well as previous machine learning... | Corrado Rainone, David W. Zhang, Markus Peschl, Roberto Bondesan |  |
| 1153 |  |  [Autoregressive Conditional Neural Processes](https://openreview.net/forum?id=OAsXFPBfTBh) |  | 0 | Conditional neural processes (CNPs; Garnelo et al., 2018a) are attractive meta-learning models which produce well-calibrated predictions and are trainable via a simple maximum likelihood procedure. Although CNPs have many advantages, they are unable to model dependencies in their predictions.... | Andrew Y. K. Foong, Anna Vaughan, Anthony Buonomo, J. Scott Hosking, James Requeima, Richard E. Turner, Stratis Markou, Tom R. Andersson, Wessel P. Bruinsma |  |
| 1154 |  |  [$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference](https://openreview.net/forum?id=fe2S7736sNS) |  | 0 | In-Context Learning (ICL), which formulates target tasks as prompt completion conditioned on in-context demonstrations, has become the prevailing utilization of LLMs. In this paper, we first disclose an actual predicament for this typical usage that it can not scale up with training data due to... | Benfeng Xu, Qiaoqiao She, Quan Wang, Yajuan Lyu, Yongdong Zhang, Zhendong Mao |  |
| 1155 |  |  [FIFA: Making Fairness More Generalizable in Classifiers Trained on Imbalanced Data](https://openreview.net/forum?id=zVrw4OH1Lch) |  | 0 | Algorithmic fairness plays an important role in machine learning and imposing fairness constraints during learning is a common approach. However, many datasets are imbalanced in certain label classes (e.g. "healthy") and sensitive subgroups (e.g. "older patients"). Empirically, this imbalance leads... | James Zou, Jiayao Zhang, Linjun Zhang, Ting Ye, Weijie J. Su, Yates Coley, Zhun Deng |  |
| 1156 |  |  [Understanding The Robustness of Self-supervised Learning Through Topic Modeling](https://openreview.net/forum?id=7Cb7Faxa1OB) |  | 0 | Self-supervised learning has significantly improved the performance of many NLP tasks. However, how can self-supervised learning discover useful features, and why is it better than traditional approaches such as probabilistic models are still largely unknown. In this paper, we focus on the context... | Cindy Weng, Mo Zhou, Rong Ge, Shiyou Wu, Zeping Luo |  |
| 1157 |  |  [Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning](https://openreview.net/forum?id=sPgP6aISLTD) |  | 0 | Reinforcement Learning (RL) agents are often unable to generalise well to environment variations in the state space that were not observed during training. This issue is especially problematic for image-based RL, where a change in just one variable, such as the background colour, can change many... | Josiah P. Hanna, Kevin Sebastian Luck, Mhairi Dunion, Stefano V. Albrecht, Trevor McInroe |  |
| 1158 |  |  [Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping](https://openreview.net/forum?id=oze0clVGPeX) |  | 0 | Differentially private deep learning has recently witnessed advances in computational efficiency and privacy-utility trade-off. We explore whether further improvements along the two axes are possible and provide affirmative answers leveraging two instantiations of \emph{group-wise clipping}. To... | Arturs Backurs, Da Yu, Huishuai Zhang, Janardhan Kulkarni, Jiang Bian, Jiyan He, Nenghai Yu, Xuechen Li, Yin Tat Lee |  |
| 1159 |  |  [Strong inductive biases provably prevent harmless interpolation](https://openreview.net/forum?id=7i6OZa7oij) |  | 0 | Classical wisdom suggests that estimators should avoid fitting noise to achieve good generalization. In contrast, modern overparameterized models can yield small test error despite interpolating noise — a phenomenon often called "benign overfitting" or "harmless interpolation". This paper argues... | Fanny Yang, Konstantin Donhauser, Marco Milanta, Michael Aerni |  |
| 1160 |  |  [Bridging the Gap to Real-World Object-Centric Learning](https://openreview.net/forum?id=b9tUk-f_aG) |  | 0 | Humans naturally decompose their environment into entities at the appropriate level of abstraction to act in the world. Allowing machine learning algorithms to derive this decomposition in an unsupervised way has become an important line of research. However, current methods are restricted to... | Andrii Zadaianchuk, Bernhard Schölkopf, CarlJohann SimonGabriel, Dominik Zietlow, Francesco Locatello, Max Horn, Maximilian Seitzer, Thomas Brox, Tianjun Xiao, Tong He, Zheng Zhang |  |
| 1161 |  |  [Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism](https://openreview.net/forum?id=cIbjyd2Vcy) |  | 0 | Recently, a variety of methods under the name of non-contrastive learning (like BYOL, SimSiam, SwAV, DINO) show that when equipped with some asymmetric architectural designs, aligning positive pairs alone is sufficient to attain good performance in self-supervised visual learning. Despite some... | Jinwen Ma, Yifei Wang, Yisen Wang, Zhijian Zhuo |  |
| 1162 |  |  [Stay Moral and Explore: Learn to Behave Morally in Text-based Games](https://openreview.net/forum?id=CtS2Rs_aYk) |  | 0 | Reinforcement learning (RL) in text-based games has developed rapidly and achieved promising results. However, little effort has been expended to design agents that pursue objectives while behaving morally, which is a critical issue in the field of autonomous agents. In this paper, we propose a... | Ling Chen, Meng Fang, Yali Du, Yunqiu Xu, Zijing Shi |  |
| 1163 |  |  [Optimistic Exploration with Learned Features Provably Solves Markov Decision Processes with Neural Dynamics](https://openreview.net/forum?id=9kBCMNb5mc) |  | 0 | Incorporated with the recent advances in deep learning, deep reinforcement learning (DRL) has achieved tremendous success in empirical study. However, analyzing DRL is still challenging due to the complexity of the neural network class. In this paper, we address such a challenge by analyzing the... | Csaba Szepesvári, Lingxiao Wang, Shuang Qiu, Sirui Zheng, Zhaoran Wang, Zhuoran Yang, Zuyue Fu |  |
| 1164 |  |  [Learning to Induce Causal Structure](https://openreview.net/forum?id=hp_RwhKDJ5) |  | 0 | The fundamental challenge in causal induction is to infer the underlying graph structure given observational and/or interventional data. Most existing causal induction algorithms operate by generating candidate graphs and evaluating them using either score-based methods (including continuous... | Anirudh Goyal, Danilo Jimenez Rezende, Jane X. Wang, Jörg Bornschein, Matthew M. Botvinick, Michael Curtis Mozer, Mélanie Rey, Nan Rosemary Ke, Silvia Chiappa, Theophane Weber |  |
| 1165 |  |  [Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning](https://openreview.net/forum?id=AHvFDPi-FA) |  | 0 | Offline reinforcement learning (RL), which aims to learn an optimal policy using a previously collected static dataset, is an important paradigm of RL. Standard RL methods often perform poorly in this regime due to the function approximation errors on out-of-distribution actions. While a variety of... | Jonathan J. Hunt, Mingyuan Zhou, Zhendong Wang |  |
| 1166 |  |  [Achieving Near-Optimal Individual Regret & Low Communications in Multi-Agent Bandits](https://openreview.net/forum?id=QTXKTXJKIh) |  | 0 | Cooperative multi-agent multi-armed bandits (CM2AB) study how distributed agents cooperatively play the same multi-armed bandit game. Most existing CM2AB works focused on maximizing the group performance of all agents---the accumulation of all agents' individual performance (i.e., individual... | Don Towsley, John C. S. Lui, Lin Yang, Mohammad Hajiesmaili, Xuchuang Wang, Xutong Liu, YuZhen Janice Chen |  |
| 1167 |  |  [Online Boundary-Free Continual Learning by Scheduled Data Prior](https://openreview.net/forum?id=qco4ekz2Epm) |  | 0 | Typical continual learning setup assumes that the dataset is split into multiple discrete tasks. We argue that it is less realistic as the streamed data would have no notion of task boundary in real-world data. Here, we take a step forward to investigate more realistic online continual learning –... | Deokki Hong, Hwanjun Song, Hyunseo Koh, Jihwan Bang, Jonghyun Choi, JungWoo Ha, Minhyuk Seo, Seulki Park |  |
| 1168 |  |  [HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization](https://openreview.net/forum?id=kUf4BcWXGJr) |  | 0 | Recently, large-scale text retrieval has made impressive progress, facilitating both information retrieval and downstream knowledge-intensive tasks (e.g., open-domain QA and dialogue). With a moderate amount of data, a neural text retriever can outperform traditional methods such as BM25 by a large... | Can Xu, Chongyang Tao, Daxin Jiang, Liang He, Tao Shen, Xin Alex Lin, Xiubo Geng, Zefeng Cai |  |
| 1169 |  |  [Learning Rationalizable Equilibria in Multiplayer Games](https://openreview.net/forum?id=HjOo2k8lhFl) |  | 0 | A natural goal in multi-agent learning is to learn \emph{rationalizable} behavior, where players learn to avoid any Iteratively Dominated Action (IDA). However, standard no-regret based equilibria-finding algorithms could take exponential samples to find such rationalizable strategies. In this... | Chi Jin, Dingwen Kong, Yu Bai, Yuanhao Wang |  |
| 1170 |  |  [Energy-Based Test Sample Adaptation for Domain Generalization](https://openreview.net/forum?id=3dnrKbeVatv) |  | 0 | In this paper, we propose energy-based sample adaptation at test time for domain generalization. Where previous works adapt their models to target domains, we adapt the unseen target samples to source-trained models. To this end, we design a discriminative energy-based model, which is trained on... | Cees G. M. Snoek, Shengcai Liao, Xiantong Zhen, Zehao Xiao |  |
| 1171 |  |  [Bidirectional Language Models Are Also Few-shot Learners](https://openreview.net/forum?id=wCFB37bzud4) |  | 0 | Large language models such as GPT-3 (Brown et al., 2020) can perform arbitrary tasks without undergoing fine-tuning after being prompted with only a few labeled examples. An arbitrary task can be reformulated as a natural language prompt, and a language model can be asked to generate the... | Ajay Patel, Bryan Li, Chris CallisonBurch, Colin Raffel, Mohammad Sadegh Rasooli, Noah Constant |  |
| 1172 |  |  [EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data](https://openreview.net/forum?id=ytZIYmztET) |  | 0 | Gradient clipping is an important technique for deep neural networks with exploding gradients, such as recurrent neural networks. Recent studies have shown that the loss functions of these networks do not satisfy the conventional smoothness condition, but instead satisfy a relaxed smoothness... | Michael Crawshaw, Mingrui Liu, Yajie Bao |  |
| 1173 |  |  [A Theory of Dynamic Benchmarks](https://openreview.net/forum?id=i8L9qoeZOS) |  | 0 | Dynamic benchmarks interweave model fitting and data collection in an attempt to mitigate the limitations of static benchmarks. In contrast to an extensive theoretical and empirical study of the static setting, the dynamic counterpart lags behind due to limited empirical studies and no apparent... | Ali Shirali, Moritz Hardt, Rediet Abebe |  |
| 1174 |  |  [On the Trade-Off between Actionable Explanations and the Right to be Forgotten](https://openreview.net/forum?id=HWt4BBZjVW) |  | 0 | As machine learning (ML) models are increasingly being deployed in high-stakes applications, policymakers have suggested tighter data protection regulations (e.g., GDPR, CCPA). One key principle is the “right to be forgotten” which gives users the right to have their data deleted. Another key... | Asia Biega, Gjergji Kasneci, Martin Pawelczyk, Tobias Leemann |  |
| 1175 |  |  [Learning What and Where: Disentangling Location and Identity Tracking Without Supervision](https://openreview.net/forum?id=NeDc-Ak-H_) |  | 0 | Our brain can almost effortlessly decompose visual data streams into background and salient objects. Moreover, it can anticipate object motion and interactions, which are crucial abilities for conceptual planning and reasoning. Recent object reasoning datasets, such as CATER, have revealed... | Jannik Thümmel, Manuel Traub, Martin V. Butz, Matthias Karlbauer, Sebastian Otte, Tobias Menge |  |
| 1176 |  |  [BALTO: fast tensor program optimization with diversity-based active learning](https://openreview.net/forum?id=CN223OXgyb5) |  | 0 | Tensor program optimization (TPO) based on pre-trained models can effectively reduce the computing time of deep neural networks. However, training of such models is prohibitively expensive, which highly depends on a large-scale dataset and thus requires tremendous time-consuming performance... | Jun Bi, Qi Guo, Rui Zhang, Xiaqing Li, Xing Hu, Xinkai Song, Yifan Hao, Yuanbo Wen, Yunji Chen, Zidong Du |  |
| 1177 |  |  [Computing all Optimal Partial Transports](https://openreview.net/forum?id=gwcQajoXNF) |  | 0 | We consider the classical version of the optimal partial transport problem. Let $\mu$ (with a mass of $U$) and $\nu$ (with a mass of $S$) be two discrete mass distributions with $S \le U$ and let $n$ be the total number of points in the supports of $\mu$ and $\nu$. For a parameter $\alpha \in... | Abhijeet Phatak, Chittaranjan Tripathy, Kaiyi Zhang, Sharath Raghvendra |  |
| 1178 |  |  [AE-FLOW: Autoencoders with Normalizing Flows for Medical Images Anomaly Detection](https://openreview.net/forum?id=9OmCr1q54Z) |  | 0 | Anomaly detection from medical images is an important task for clinical screening and diagnosis. In general, a large dataset of normal images are available while only few abnormal images can be collected in clinical practice. By mimicking the diagnosis process of radiologists, we attempt to tackle... | Qiaoqiao Ding, Xiaoqun Zhang, Yuzhong Zhao |  |
| 1179 |  |  [A Self-Attention Ansatz for Ab-initio Quantum Chemistry](https://openreview.net/forum?id=xveTeHVlF7j) |  | 0 | We present a novel neural network architecture using self-attention, the Wavefunction Transformer (PsiFormer), which can be used as an approximation (or "Ansatz") for solving the many-electron Schrödinger equation, the fundamental equation for quantum chemistry and material science. This equation... | David Pfau, Ingrid von Glehn, James S. Spencer |  |
| 1180 |  |  [Probabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse](https://openreview.net/forum?id=sC-PmTsiTB) |  | 0 | As machine learning models are increasingly being employed to make consequential decisions in real-world settings, it becomes critical to ensure that individuals who are adversely impacted (e.g., loan denied) by the predictions of these models are provided with a means for recourse. While several... | Gjergji Kasneci, Himabindu Lakkaraju, Johannes van den Heuvel, Martin Pawelczyk, Teresa Datta |  |
| 1181 |  |  [How robust is unsupervised representation learning to distribution shift?](https://openreview.net/forum?id=LiXDW7CF94J) |  | 0 | The robustness of machine learning algorithms to distributions shift is primarily discussed in the context of supervised learning (SL). As such, there is a lack of insight on the robustness of the representations learned from unsupervised methods, such as self-supervised learning (SSL) and... | Amartya Sanyal, Imant Daunhawer, Julia E. Vogt, Philip H. S. Torr, Yuge Shi |  |
| 1182 |  |  [Pseudo-label Training and Model Inertia in Neural Machine Translation](https://openreview.net/forum?id=eXkhH12DTD9) |  | 0 | Like many other machine learning applications, neural machine translation (NMT) benefits from over-parameterized deep neural models. However, these models have been observed to be brittle: NMT model predictions are sensitive to small input changes and can show significant variation across... | Anna Currey, Benjamin Hsu, Georgiana Dinu, Maria Nadejde, Xing Niu |  |
| 1183 |  |  [HyperDeepONet: learning operator with complex target function space using the limited resources via hypernetwork](https://openreview.net/forum?id=OAw6V3ZAhSd) |  | 0 | Fast and accurate predictions for complex physical dynamics are a big challenge across various applications. Real-time prediction on resource-constrained hardware is even more crucial in the real-world problems. The deep operator network (DeepONet) has recently been proposed as a framework for... | Hyung Ju Hwang, Jae Yong Lee, Sung Woong Cho |  |
| 1184 |  |  [Edge Guided GANs with Contrastive Learning for Semantic Image Synthesis](https://openreview.net/forum?id=qcJmsP3oE9) |  | 0 | We propose a novel \underline{e}dge guided \underline{g}enerative \underline{a}dversarial \underline{n}etwork with \underline{c}ontrastive learning (ECGAN) for the challenging semantic image synthesis task. Although considerable improvement has been achieved, the quality of synthesized images is... | Dan Xu, Guolei Sun, Hao Tang, Luc Van Gool, Nicu Sebe, Radu Timofte, Xiaojuan Qi |  |
| 1185 |  |  [CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning](https://openreview.net/forum?id=Kf7Yyf4O0u) |  | 0 | Federated Learning (FL) is a setting for training machine learning models in distributed environments where the clients do not share their raw data but instead send model updates to a server. However, model updates can be subject to attacks and leak private information. Differential Privacy (DP) is... | Alexandre Sablayrolles, Pierre Stock, Samuel Maddock |  |
| 1186 |  |  [A View From Somewhere: Human-Centric Face Representations](https://openreview.net/forum?id=mMaInr0r0c) |  | 0 | Few datasets contain self-identified demographic information, inferring demographic information risks introducing additional biases, and collecting and storing data on sensitive attributes can carry legal risks. Besides, categorical demographic labels do not necessarily capture all the relevant... | Alice Xiang, Jerone Theodore Alexander Andrews, Przemyslaw Joniak |  |
| 1187 |  |  [Identifiability Results for Multimodal Contrastive Learning](https://openreview.net/forum?id=U_2kuqoTcB) |  | 0 | Contrastive learning is a cornerstone underlying recent progress in multi-view and multimodal learning, e.g., in representation learning with image/caption pairs. While its effectiveness is not yet fully understood, a line of recent work reveals that contrastive learning can invert the data... | Alexander Marx, Alice Bizeul, Emanuele Palumbo, Imant Daunhawer, Julia E. Vogt |  |
| 1188 |  |  [Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach](https://openreview.net/forum?id=dZrQR7OR11) |  | 0 | The canonical formulation of federated learning treats it as a distributed optimization problem where the model parameters are optimized against a global loss function that decomposes across client loss functions. A recent alternative formulation instead treats federated learning as a distributed... | Andrew Gelman, Eric P. Xing, Han Guo, Hongyi Wang, Philip Greengard, Yoon Kim |  |
| 1189 |  |  [Latent Graph Inference using Product Manifolds](https://openreview.net/forum?id=JLR_B7n_Wqr) |  | 0 | Graph Neural Networks usually rely on the assumption that the graph topology is available to the network as well as optimal for the downstream task. Latent graph inference allows models to dynamically learn the intrinsic graph structure of problems where the connectivity patterns of data may not be... | Anees Kazi, Federico Barbero, Haitz Sáez de Ocáriz Borde, Pietro Liò |  |
| 1190 |  |  [This Looks Like It Rather Than That: ProtoKNN For Similarity-Based Classifiers](https://openreview.net/forum?id=lh-HRYxuoRr) |  | 0 | Among research on the interpretability of deep learning models, the 'this looks like that' framework with ProtoPNet has attracted significant attention. By combining the strong power of deep learning models with the interpretability of case-based inference, ProtoPNet can achieve high accuracy while... | Hironobu Fujiyoshi, Takayoshi Yamashita, Tsubasa Hirakawa, Yuki Ukai |  |
| 1191 |  |  [Understanding weight-magnitude hyperparameters in training binary networks](https://openreview.net/forum?id=uBKBoix9NXa) |  | 0 | Binary Neural Networks (BNNs) are compact and efficient by using binary weights instead of real-valued weights. Current BNNs use latent real-valued weights during training, where several training hyper-parameters are inherited from real-valued networks. The interpretation of several of these... | Jan van Gemert, Joris Quist, Yunqiang Li |  |
| 1192 |  |  [Imitating Human Behaviour with Diffusion Models](https://openreview.net/forum?id=Pv1GPQzRrC8) |  | 0 | Diffusion models have emerged as powerful generative models in the text-to-image domain. This paper studies their application as observation-to-action models for imitating human behaviour in sequential environments. Human behaviour is stochastic and multimodal, with structured correlations between... | Anssi Kanervisto, David Bignell, Ida Momennejad, Katja Hofmann, Mingfei Sun, Raluca Georgescu, Sam Devlin, Sergio Valcarcel Macua, Shan Zheng Tan, Tabish Rashid, Tim Pearce |  |
| 1193 |  |  [Contrastive Meta-Learning for Partially Observable Few-Shot Learning](https://openreview.net/forum?id=6iVJOtr2zL2) |  | 0 | Many contrastive and meta-learning approaches learn representations by identifying common features in multiple views. However, the formalism for these approaches generally assumes features to be shared across views to be captured coherently. We consider the problem of learning a unified... | Adam Jelley, Amos J. Storkey, Antreas Antoniou, Sam Devlin |  |
| 1194 |  |  [Enhancing the Inductive Biases of Graph Neural ODE for Modeling Physical Systems](https://openreview.net/forum?id=ATLEl_izD87) |  | 0 | Neural networks with physics-based inductive biases such as Lagrangian neural networks (LNNs), and Hamiltonian neural networks (HNNs) learn the dynamics of physical systems by encoding strong inductive biases. Alternatively, Neural ODEs with appropriate inductive biases have also been shown to give... | Jayadeva, N. M. Anoop Krishnan, Ravinder Bhattoo, Sayan Ranu, Suresh Bishnoi |  |
| 1195 |  |  [Efficient Planning in a Compact Latent Action Space](https://openreview.net/forum?id=cA77NrVEuqn) |  | 0 | Planning-based reinforcement learning has shown strong performance in tasks in discrete and low-dimensional continuous action spaces. However, planning usually brings significant computational overhead for decision making, so scaling such methods to high-dimensional action spaces remains... | Edward Grefenstette, Michael Janner, Tianjun Zhang, Tim Rocktäschel, Yuandong Tian, Yueying Li, Zhengyao Jiang |  |
| 1196 |  |  [Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation](https://openreview.net/forum?id=8JsaP7j1cL0) |  | 0 | The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis, which works under the limitation that latent elements are mutually... | Alper Tunga Erdogan, Ates Isfendiyaroglu, Bariscan Bozkurt, Cengiz Pehlevan |  |
| 1197 |  |  [Leveraging Importance Weights in Subset Selection](https://openreview.net/forum?id=9Nj_gNdvqYf) |  | 0 | We present a subset selection algorithm designed to work with arbitrary model families in a practical batch setting. In such a setting, an algorithm can sample examples one at a time but, in order to limit overhead costs, is only able to update its state (i.e. further train model weights) once a... | Afshin Rostamizadeh, Giulia DeSalvo, Gui Citovsky, Sanjiv Kumar, Srikumar Ramalingam, Yunjuan Wang |  |
| 1198 |  |  [Copy is All You Need](https://openreview.net/forum?id=CROlOA9Nd8C) |  | 0 | The dominant text generation models compose the output by sequentially selecting words from a fixed vocabulary. In this paper, we formulate text generation as progressively copying text segments (e.g., words or phrases) from an existing text collection. We compute the contextualized representations... | Deng Cai, Heyan Huang, Tian Lan, XianLing Mao, Yan Wang |  |
| 1199 |  |  [Why adversarial training can hurt robust accuracy](https://openreview.net/forum?id=-CA8yFkPc7O) |  | 0 | Machine learning classifiers with high test accuracy often perform poorly under adversarial attacks. It is commonly believed that adversarial training alleviates this issue. In this paper, we demonstrate that, surprisingly, the opposite can be true for a natural class of perceptible perturbations... | Fanny Yang, Jacob Clarysse, Julia Hörrmann |  |
| 1200 |  |  [Representational Dissimilarity Metric Spaces for Stochastic Neural Networks](https://openreview.net/forum?id=xjb563TH-GH) |  | 0 | Quantifying similarity between neural representations---e.g. hidden layer activation vectors---is a perennial problem in deep learning and neuroscience research. Existing methods compare deterministic responses (e.g. artificial networks that lack stochastic layers) or averaged responses (e.g.,... | Alex H. Williams, Jeroen Olieslagers, Jingyang Zhou, Josue Nassar, Jules Berman, Lyndon R. Duong |  |
| 1201 |  |  [Sequential Learning of Neural Networks for Prequential MDL](https://openreview.net/forum?id=dMMPUvNSYJr) |  | 0 | Minimum Description Length (MDL) provides a framework and an objective for principled model evaluation. It formalizes Occam's Razor and can be applied to data from non-stationary sources. In the prequential formulation of MDL, the objective is to minimize the cumulative next-step log-loss when... | Jörg Bornschein, Marcus Hutter, Yazhe Li |  |
| 1202 |  |  [Learning topology-preserving data representations](https://openreview.net/forum?id=lIu-ixf-Tzf) |  | 0 | We propose a method for learning topology-preserving data representations (dimensionality reduction). The method aims to provide topological similarity between the data manifold and its latent representation via enforcing the similarity in topological features (clusters, loops, 2D voids, etc.) and... | Daniil Cherniavskii, Eduard Tulchinskii, Evgeny Burnaev, Ilya Trofimov, Nikita Balabin, Serguei Barannikov |  |
| 1203 |  |  [The Curious Case of Benign Memorization](https://openreview.net/forum?id=4C8ChYvMYBn) |  | 0 | Despite the empirical advances of deep learning across a variety of learning tasks, our theoretical understanding of its success is still very restricted. One of the key challenges is the overparametrized nature of modern models, enabling complete overfitting of the data even if the labels are... | Gregor Bachmann, Lorenzo Noci, Sotiris Anagnostidis, Thomas Hofmann |  |
| 1204 |  |  [Unbiased Supervised Contrastive Learning](https://openreview.net/forum?id=Ph5cJSfD2XN) |  | 0 | Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in... | Benoit Dufumier, Carlo Alberto Barbano, Enzo Tartaglione, Marco Grangetto, Pietro Gori |  |
| 1205 |  |  [Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video Relation Detection](https://openreview.net/forum?id=mE91GkXYipg) |  | 0 | Prompt tuning with large-scale pretrained vision-language models empowers open-vocabulary prediction trained on limited base categories, e.g., object classification and detection. In this paper, we propose compositional prompt tuning with motion cues: an extended prompt tuning paradigm for... | Hanwang Zhang, Jun Xiao, Kaifeng Gao, Long Chen, Qianru Sun |  |
| 1206 |  |  [Multi-objective optimization via equivariant deep hypervolume approximation](https://openreview.net/forum?id=fSa5IjNMmmi) |  | 0 | Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is... | Bernd Ensing, Jim Boelrijk, Patrick Forré |  |
| 1207 |  |  [DiffusER: Diffusion via Edit-based Reconstruction](https://openreview.net/forum?id=nG9RF9z1yy3) |  | 0 | In text generation, models that generate text from scratch one token at a time are currently the dominant paradigm. Despite being performant, these models lack the ability to revise existing text, which limits their usability in many practical scenarios. We look to address this, with DiffusER... | Graham Neubig, Machel Reid, Vincent Josua Hellendoorn |  |
| 1208 |  |  [DynaMS: Dyanmic Margin Selection for Efficient Deep Learning](https://openreview.net/forum?id=7oPAgqxNb20) |  | 0 | The great success of deep learning is largely driven by training over-parameterized models on massive datasets. To avoid excessive computation, extracting and training only on the most informative subset is drawing increasing attention. Nevertheless, it is still an open question how to select such... | Jiaxing Wang, Jingwei Zhuo, Lixing Gong, Pengzhang Liu, Tong Tao, Weipeng Yan, Weizhong Zhang, Xupeng Shi, Yong Li, Yongjun Bao |  |
| 1209 |  |  [TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization](https://openreview.net/forum?id=n6H86gW8u0d) |  | 0 | Despite their success with unstructured data, deep neural networks are not yet a panacea for structured tabular data. In the tabular domain, their efficiency crucially relies on various forms of regularization to prevent overfitting and provide strong generalization performance. Existing... | Alan Jeffares, Fergus Imrie, Jonathan Crabbé, Mihaela van der Schaar, Tennison Liu |  |
| 1210 |  |  [Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer](https://openreview.net/forum?id=udNhDCr2KQe) |  | 0 | Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as... | Adam Ishay, Joohyung Lee, Zhun Yang |  |
| 1211 |  |  [Improving the imputation of missing data with Markov Blanket discovery](https://openreview.net/forum?id=GrpU6dxFmMN) |  | 0 | The process of imputation of missing data typically relies on generative and regression models. These approaches often operate on the unrealistic assumption that all of the data features are directly related with one another, and use all of the available features to impute missing values. In this... | Anthony C. Constantinou, Yang Liu |  |
| 1212 |  |  [Boosting the Cycle Counting Power of Graph Neural Networks with I$^2$-GNNs](https://openreview.net/forum?id=kDSmxOspsXQ) |  | 0 | Message Passing Neural Networks (MPNNs) are a widely used class of Graph Neural Networks (GNNs). The limited representational power of MPNNs inspires the study of provably powerful GNN architectures. However, knowing one model is more powerful than another gives little insight about what functions... | Jianzhu Ma, Muhan Zhang, Xingang Peng, Yinan Huang |  |
| 1213 |  |  [Fundamental Limits in Formal Verification of Message-Passing Neural Networks](https://openreview.net/forum?id=WlbG820mRH-) |  | 0 | Output reachability and adversarial robustness are among the most relevant safety properties of neural networks. We show that in the context of Message Passing Neural Networks (MPNN), a common Graph Neural Network (GNN) model, formal verification is impossible. In particular, we show that output... | Marco Sälzer, Martin Lange |  |
| 1214 |  |  [Short-Term Memory Convolutions](https://openreview.net/forum?id=4DU_HCijfJp) |  | 0 | The real-time processing of time series signals is a critical issue for many real-life applications. The idea of real-time processing is especially important in audio domain as the human perception of sound is sensitive to any kind of disturbance in perceived signals, especially the lag between... | Artur Szumaczuk, Bartlomiej Jasik, Grzegorz Stefanski, Krzysztof Arendt, Pawel Daniluk |  |
| 1215 |  |  [LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval](https://openreview.net/forum?id=PfpEtB3-csK) |  | 0 | In large-scale retrieval, the lexicon-weighting paradigm, learning weighted sparse representations in vocabulary space, has shown promising results with high quality and low latency. Despite it deeply exploiting the lexicon-representing capability of pre-trained language models, a crucial gap... | Binxing Jiao, Can Xu, Chongyang Tao, Daxin Jiang, Linjun Yang, Tao Shen, Xiaolong Huang, Xiubo Geng |  |
| 1216 |  |  [A GNN-Guided Predict-and-Search Framework for Mixed-Integer Linear Programming](https://openreview.net/forum?id=pHMpgT5xWaE) |  | 0 | Mixed-integer linear programming (MILP) is widely employed for modeling combinatorial optimization problems. In practice, similar MILP instances with only coefficient variations are routinely solved, and machine learning (ML) algorithms are capable of capturing common patterns across these MILP... | Akang Wang, Dong Zhang, Linxin Yang, Qian Chen, Qingyu Han, Ruoyu Sun, Xiang Zhou, Xiaodong Luo |  |
| 1217 |  |  [On Explaining Neural Network Robustness with Activation Path](https://openreview.net/forum?id=piIsx-G3Gux) |  | 0 | Despite their verified performance, neural networks are prone to be misled by maliciously designed adversarial examples. This work investigates the robustness of neural networks from the activation pattern perspective. We find that despite the complex structure of the deep neural network, most of... | Ziping Jiang |  |
| 1218 |  |  [Structure by Architecture: Structured Representations without Regularization](https://openreview.net/forum?id=O_lFCPaF48t) |  | 0 | We study the problem of self-supervised structured representation learning using autoencoders for downstream tasks such as generative modeling. Unlike most methods which rely on matching an arbitrary, relatively unstructured, prior distribution for sampling, we propose a sampling technique that... | Bernhard Schölkopf, Felix Leeb, Giulia Lanzillotta, Michel Besserve, Stefan Bauer, Yashas Annadani |  |
| 1219 |  |  [Understanding Neural Coding on Latent Manifolds by Sharing Features and Dividing Ensembles](https://openreview.net/forum?id=1UCaQYUdE_o) |  | 0 | Systems neuroscience relies on two complementary views of neural data, characterized by single neuron tuning curves and analysis of population activity. These two perspectives combine elegantly in neural latent variable models that constrain the relationship between latent variables and neural... | Benjamin Adric Dunn, Claudia Battistin, David A. Klindt, Kristopher T. Jensen, Lukas Schott, Martin Bjerke |  |
| 1220 |  |  [Learning Fast and Slow for Online Time Series Forecasting](https://openreview.net/forum?id=q-PbpHD3EOk) |  | 0 | Despite the recent success of deep learning for time series forecasting, these methods are not scalable for many real-world applications where data arrives sequentially. Training deep neural forecasters on the fly is notoriously challenging because of their limited ability to adapt to... | Chenghao Liu, Doyen Sahoo, Quang Pham, Steven C. H. Hoi |  |
| 1221 |  |  [Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners](https://openreview.net/forum?id=FtOxgKe_Zg2) |  | 0 | Meta-training, which fine-tunes the language model (LM) on various downstream tasks by maximizing the likelihood of the target label given the task instruction and input instance, has improved the zero-shot task generalization performance. However, meta-trained LMs still struggle to generalize to... | Doyoung Kim, Joel Jang, Joongbo Shin, Minjoon Seo, Seonghyeon Ye |  |
| 1222 |  |  [Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints](https://openreview.net/forum?id=_BoPed4tYww) |  | 0 | Many real-world settings involve costs for performing actions; transaction costs in financial systems and fuel costs being common examples. In these settings, performing actions at each time step quickly accumulates costs leading to vastly suboptimal outcomes. Additionally, repeatedly acting... | Aivar Sootla, David Henry Mguni, Juliusz Ziomek, Jun Wang, Kun Shao, Oliver Slumbers, Zipeng Dai |  |
| 1223 |  |  [DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training](https://openreview.net/forum?id=Lt8bMlhiwx2) |  | 0 | Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong zero-shot transfer capability in many discriminative tasks, e.g., image classification. Their adaptation to zero-shot image-conditioned text generation tasks has drawn increasing interest. Prior arts approach to zero-shot... | Linchao Zhu, Longyin Wen, Wei Li, Yi Yang |  |
| 1224 |  |  [That Label's got Style: Handling Label Style Bias for Uncertain Image Segmentation](https://openreview.net/forum?id=wZ2SVhOTzBX) |  | 0 | Segmentation uncertainty models predict a distribution over plausible segmentations for a given input, which they learn from the annotator variation in the training set. However, in practice these annotations can differ systematically in the way they are generated, for example through the use of... | Aasa Feragen, Eike Petersen, Jes Frellsen, Kilian Zepf |  |
| 1225 |  |  [Holistic Adversarially Robust Pruning](https://openreview.net/forum?id=sAJDi9lD06L) |  | 0 | Neural networks can be drastically shrunk in size by removing redundant parameters. While crucial for the deployment on resource-constraint hardware, oftentimes, compression comes with a severe drop in accuracy and lack of adversarial robustness. Despite recent advances, counteracting both aspects... | Christian Wressnegger, Qi Zhao |  |
| 1226 |  |  [PASHA: Efficient HPO and NAS with Progressive Resource Allocation](https://openreview.net/forum?id=syfgJE6nFRW) |  | 0 | Hyperparameter optimization (HPO) and neural architecture search (NAS) are methods of choice to obtain the best-in-class machine learning models, but in practice they can be costly to run. When models are trained on large datasets, tuning them with HPO or NAS rapidly becomes prohibitively expensive... | Beyza Ermis, Cédric Archambeau, Giovanni Zappella, Lukas Balles, Martin Wistuba, Ondrej Bohdal |  |
| 1227 |  |  [StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random](https://openreview.net/forum?id=3VO1y5N7K1H) |  | 0 | In recommender systems, users always choose the favorite items to rate, which leads to data missing not at random and poses a great challenge for unbiased evaluation and learning of prediction models. Currently, the doubly robust (DR) methods have been widely studied and demonstrate superior... | Chunyuan Zheng, Haoxuan Li, Peng Wu |  |
| 1228 |  |  [Sampling-based inference for large linear models, with application to linearised Laplace](https://openreview.net/forum?id=aoDyX6vSqsd) |  | 0 | Large-scale linear models are ubiquitous throughout machine learning, with contemporary application as surrogate models for neural network uncertainty quantification; that is, the linearised Laplace method. Alas, the computational cost associated with Bayesian linear models constrains this method's... | David Janz, Eric T. Nalisnick, Javier Antorán, José Miguel HernándezLobato, Riccardo Barbano, Shreyas Padhy |  |
| 1229 |  |  [Defending against Adversarial Audio via Diffusion Model](https://openreview.net/forum?id=5-Df3tljit7) |  | 0 | Deep learning models have been widely used in commercial acoustic systems in recent years. However, adversarial audio examples can cause abnormal behaviors for those acoustic systems, while being hard for humans to perceive. Various methods, such as transformation-based defenses and adversarial... | Chaowei Xiao, Jiongxiao Wang, Shutong Wu, Wei Ping, Weili Nie |  |
| 1230 |  |  [Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning](https://openreview.net/forum?id=Jifob4dSh99) |  | 0 | Meta-learning has arisen as a successful method for improving training performance by training over many similar tasks, especially with deep neural networks (DNNs). However, the theoretical understanding of when and why overparameterized models such as DNNs can generalize well in meta-learning is... | Ness B. Shroff, Peizhong Ju, Yingbin Liang |  |
| 1231 |  |  [Robust Explanation Constraints for Neural Networks](https://openreview.net/forum?id=_hHYaKu0jcj) |  | 0 | Post-hoc explanation methods are used with the intent of providing insights about neural networks and are sometimes said to help engender trust in their outputs. However, popular explanations methods have been found to be fragile to minor perturbations of input features or model parameters. Relying... | Adrian Weller, Juyeon Heo, Luca Costabello, Matthew Wicker |  |
| 1232 |  |  [Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling](https://openreview.net/forum?id=42zs3qa2kpy) |  | 0 | In offline reinforcement learning, weighted regression is a common method to ensure the learned policy stays close to the behavior policy and to prevent selecting out-of-sample actions. In this work, we show that due to the limited distributional expressivity of policy models, previous methods... | Cheng Lu, Chengyang Ying, Hang Su, Huayu Chen, Jun Zhu |  |
| 1233 |  |  [CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers](https://openreview.net/forum?id=rB6TpjAuSRy) |  | 0 | In this work, we present CogVideo, a 9B-parameter transformer for text-to-video generation. The CogVideo model has been trained by inheriting a pretrained text-to-image model, CogView2, which significantly reduces the training cost and alleviates the problem of scarcity and weak relevance. We also... | Jie Tang, Ming Ding, Wendi Zheng, Wenyi Hong, Xinghan Liu |  |
| 1234 |  |  [Revisit Finetuning strategy for Few-Shot Learning to Transfer the Emdeddings](https://openreview.net/forum?id=tXc-riXhmx) |  | 0 | Few-Shot Learning (FSL) aims to learn a simple and effective bias on limited novel samples. Recently, many methods have been focused on re-training a randomly initialized linear classifier to adapt it to the novel features extracted by the pre-trained feature extractor (called Linear-Probing-based... | Bohan Li, Heng Wang, Tan Yue, Xiang Ye, Yong Li, Zihang He |  |
| 1235 |  |  [Optimizing Spca-based Continual Learning: A Theoretical Approach](https://openreview.net/forum?id=Vf6WcUDnY7c) |  | 0 | Catastrophic forgetting and the stability-plasticity dilemma are two major obstacles to continual learning. In this paper we first propose a theoretical analysis of a SPCA-based continual learning algorithm using high dimensional statistics. Second, we design OSCL (Optimized Spca-based Continual... | Chunchun Yang, Malik Tiomoko, Zengfu Wang |  |
| 1236 |  |  [Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning](https://openreview.net/forum?id=UYcIheNY9Pf) |  | 0 | Reinforcement Learning (RL) methods are typically applied directly in environments to learn policies. In some complex environments with continuous state-action spaces, sparse rewards, and/or long temporal horizons, learning a good policy in the original environments can be difficult. Focusing on... | Deyao Zhu, Li Erran Li, Mohamed Elhoseiny |  |
| 1237 |  |  [Sampling-free Inference for Ab-Initio Potential Energy Surface Networks](https://openreview.net/forum?id=Tuk3Pqaizx) |  | 0 | Recently, it has been shown that neural networks not only approximate the ground-state wave functions of a single molecular system well but can also generalize to multiple geometries. While such generalization significantly speeds up training, each energy evaluation still requires Monte Carlo... | Nicholas Gao, Stephan Günnemann |  |
| 1238 |  |  [𝒩-WL: A New Hierarchy of Expressivity for Graph Neural Networks](https://openreview.net/forum?id=5cAI0qXxyv) |  | 0 | The expressive power of Graph Neural Networks (GNNs) is fundamental for understanding their capabilities and limitations, i.e., what graph properties can or cannot be learnt by a GNN. Since standard GNNs have been characterised to be upper-bounded by the Weisfeiler-Lehman (1-WL) algorithm, recent... | Asiri Wijesinghe, Dillon Ze Chen, Muhammad Farhan, Qing Wang, Shouheng Li |  |
| 1239 |  |  [Learning Input-agnostic Manipulation Directions in StyleGAN with Text Guidance](https://openreview.net/forum?id=47B_ctC4pJ) |  | 0 | With the advantages of fast inference and human-friendly flexible manipulation, image-agnostic style manipulation via text guidance enables new applications that were not previously available. The state-of-the-art text-guided image-agnostic manipulation method embeds the representation of each... | Eunho Yang, Hyunsu Kim, Junho Kim, Yoonjeon Kim, Yunjey Choi |  |
| 1240 |  |  [DAVA: Disentangling Adversarial Variational Autoencoder](https://openreview.net/forum?id=CW6KmU5wPh) |  | 0 | The use of well-disentangled representations offers many advantages for downstream tasks, e.g. an increased sample efficiency, or better interpretability. However, the quality of disentangled interpretations is often highly dependent on the choice of dataset-specific hyperparameters, in particular... | Benjamin Estermann, Roger Wattenhofer |  |
| 1241 |  |  [TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased Recommendations](https://openreview.net/forum?id=EIgLnNx_lC) |  | 0 | Bias is a common problem inherent in recommender systems, which is entangled with users' preferences and poses a great challenge to unbiased learning. For debiasing tasks, the doubly robust (DR) method and its variants show superior performance due to the double robustness property, that is, DR is... | Chunyuan Zheng, Haoxuan Li, Peng Wu, Yan Lyu |  |
| 1242 |  |  [Domain Generalisation via Domain Adaptation: An Adversarial Fourier Amplitude Approach](https://openreview.net/forum?id=7IG0wsTND7w) |  | 0 | We tackle the domain generalisation (DG) problem by posing it as a domain adaptation (DA) task where we adversarially synthesise the worst-case \`target' domain and adapt a model to that worst-case domain, thereby improving the model’s robustness. To synthesise data that is challenging yet... | Da Li, Minyoung Kim, Timothy M. Hospedales |  |
| 1243 |  |  [Consolidator: Mergable Adapter with Group Connections for Visual Adaptation](https://openreview.net/forum?id=J_Cja7cpgW) |  | 0 | Recently, transformers have shown strong ability as visual feature extractors, surpassing traditional convolution-based models in various scenarios. However, the success of vision transformers largely owes to their capacity to accommodate numerous parameters. As a result, new challenges for... | Guiguang Ding, Hui Chen, Tianxiang Hao, Yuchen Guo |  |
| 1244 |  |  [Statistical Theory of Differentially Private Marginal-based Data Synthesis Algorithms](https://openreview.net/forum?id=hxUwnEGxW87) |  | 0 | Marginal-based methods achieve promising performance in the synthetic data competition hosted by the National Institute of Standards and Technology (NIST). To deal with high-dimensional data, the distribution of synthetic data is represented by a probabilistic graphical model (e.g., a Bayesian... | Chendi Wang, Guang Cheng, Ximing Li |  |
| 1245 |  |  [Anti-Symmetric DGN: a stable architecture for Deep Graph Networks](https://openreview.net/forum?id=J3Y7cgZOOS) |  | 0 | Deep Graph Networks (DGNs) currently dominate the research landscape of learning from graphs, due to their efficiency and ability to implement an adaptive message-passing scheme between the nodes. However, DGNs are typically limited in their ability to propagate and preserve long-term dependencies... | Alessio Gravina, Claudio Gallicchio, Davide Bacciu |  |
| 1246 |  |  [Contrastive Learning for Unsupervised Domain Adaptation of Time Series](https://openreview.net/forum?id=xPkJYRsQGM) |  | 0 | Unsupervised domain adaptation (UDA) aims at learning a machine learning model using a labeled source domain that performs well on a similar yet different, unlabeled target domain. UDA is important in many applications such as medicine, where it is used to adapt risk scores across different patient... | Ce Zhang, Stefan Feuerriegel, Yilmazcan Özyurt |  |
| 1247 |  |  [Online Low Rank Matrix Completion](https://openreview.net/forum?id=47KG_AvNqeZ) |  | 0 | We study the problem of online low-rank matrix completion with $\mathsf{M}$ users, $\mathsf{N}$ items and $\mathsf{T}$ rounds. In each round, the algorithm recommends one item per user, for which it gets a (noisy) reward sampled from a low-rank user-item preference matrix. The goal is to design a... | Prateek Jain, Soumyabrata Pal |  |
| 1248 |  |  [Explaining RL Decisions with Trajectories](https://openreview.net/forum?id=5Egggz1q575) |  | 0 | Explanation is a key component for the adoption of reinforcement learning (RL) in many real-world decision-making problems. In the literature, the explanation is often provided by saliency attribution to the features of the RL agent's state. In this work, we propose a complementary approach to... | Arpan Dasgupta, Balaji Krishnamurthy, Chirag Agarwal, Georgios Theocharous, Jayakumar Subramanian, Nan Jiang, Shripad Vilasrao Deshmukh |  |
| 1249 |  |  [FastFill: Efficient Compatible Model Update](https://openreview.net/forum?id=rnRiiHw8Vy) |  | 0 | In many retrieval systems the original high dimensional data (e.g., images) is mapped to a lower dimensional feature through a learned embedding model. The task of retrieving the most similar data from a gallery set to a given query data is performed through similarity comparison on features. When... | Ali Farhadi, Fartash Faghri, Florian Jaeckle, Hadi Pouransari, Oncel Tuzel |  |
| 1250 |  |  [Learnable Graph Convolutional Attention Networks](https://openreview.net/forum?id=WsUMeHPo-2) |  | 0 | Existing Graph Neural Networks (GNNs) compute the message exchange between nodes by either aggregating uniformly (convolving) the features of all the neighbor- ing nodes, or by applying a non-uniform score (attending) to the features. Recent works have shown the strengths and weaknesses of the... | Adrián Javaloy, Amit Levi, Isabel Valera, Pablo SánchezMartín |  |
| 1251 |  |  [Scaffolding a Student to Instill Knowledge](https://openreview.net/forum?id=N4K5ck-BTT) |  | 0 | We propose a novel knowledge distillation (KD) method to selectively instill teacher knowledge into a student model motivated by situations where the student's capacity is significantly smaller than that of the teachers. In vanilla KD, the teacher primarily sets a predictive target for the student... | Aditya Gangrade, Anil Kag, Durmus Alp Emre Acar, Venkatesh Saligrama |  |
| 1252 |  |  [User-Interactive Offline Reinforcement Learning](https://openreview.net/forum?id=a4COps0uokg) |  | 0 | Offline reinforcement learning algorithms still lack trust in practice due to the risk that the learned policy performs worse than the original policy that generated the dataset or behaves in an unexpected way that is unfamiliar to the user. At the same time, offline RL algorithms are not able to... | Phillip Swazinna, Steffen Udluft, Thomas A. Runkler |  |
| 1253 |  |  [SLTUNET: A Simple Unified Model for Sign Language Translation](https://openreview.net/forum?id=EBS4C77p_5S) |  | 0 | Despite recent successes with neural models for sign language translation (SLT), translation quality still lags behind spoken languages because of the data scarcity and modality gap between sign video and text. To address both problems, we investigate strategies for cross-modality representation... | Biao Zhang, Mathias Müller, Rico Sennrich |  |
| 1254 |  |  [Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization](https://openreview.net/forum?id=iUYpN14qjTF) |  | 0 | Adaptive gradient methods such as Adam have gained increasing popularity in deep learning optimization. However, it has been observed in many deep learning applications such as image classification, Adam can converge to a different solution with a worse test error compared to (stochastic) gradient... | Difan Zou, Quanquan Gu, Yuan Cao, Yuanzhi Li |  |
| 1255 |  |  [A law of adversarial risk, interpolation, and label noise](https://openreview.net/forum?id=0_TxFpAsEI) |  | 0 | In supervised learning, it has been shown that label noise in the data can be interpolated without penalties on test accuracy. We show that interpolating label noise induces adversarial vulnerability, and prove the first theorem showing the relationship between label noise and adversarial risk for... | Amartya Sanyal, Daniel Paleka |  |
| 1256 |  |  [Learning ReLU networks to high uniform accuracy is intractable](https://openreview.net/forum?id=nchvKfvNeX0) |  | 0 | Statistical learning theory provides bounds on the necessary number of training samples needed to reach a prescribed accuracy in a learning problem formulated over a given target class. This accuracy is typically measured in terms of a generalization error, that is, an expected value of a given... | Felix Voigtländer, Julius Berner, Philipp Grohs |  |
| 1257 |  |  [Active Learning for Object Detection with Evidential Deep Learning and Hierarchical Uncertainty Aggregation](https://openreview.net/forum?id=MnEjsw-vj-X) |  | 0 | Despite the huge success of object detection, the training process still requires an immense amount of labeled data. Although various active learning solutions for object detection have been proposed, most existing works do not take advantage of epistemic uncertainty, which is an important metric... | DongJun Han, Jaekyun Moon, Soyeong Kim, Wonjeong Choi, Younghyun Park |  |
| 1258 |  |  [How Sharpness-Aware Minimization Minimizes Sharpness?](https://openreview.net/forum?id=5spDgWmpY6x) |  | 0 | Sharpness-Aware Minimization (SAM) is a highly effective regularization technique for improving the generalization of deep neural networks for various settings. However, the underlying working of SAM remains elusive because of various intriguing approximations in the theoretical characterizations.... | Kaiyue Wen, Tengyu Ma, Zhiyuan Li |  |
| 1259 |  |  [The Implicit Bias of Minima Stability in Multivariate Shallow ReLU Networks](https://openreview.net/forum?id=xtbog7cfsr) |  | 0 | We study the type of solutions to which stochastic gradient descent converges when used to train a single hidden-layer multivariate ReLU network with the quadratic loss. Our results are based on a dynamical stability analysis. In the univariate case, it was shown that linearly stable minima... | Daniel Soudry, Greg Ongie, Mor Shpigel Nacson, Rotem Mulayoff, Tomer Michaeli |  |
| 1260 |  |  [MAST: Masked Augmentation Subspace Training for Generalizable Self-Supervised Priors](https://openreview.net/forum?id=5KUPKjHYD-l) |  | 0 | Recent Self-Supervised Learning (SSL) methods are able to learn feature representations that are invariant to different data augmentations, which can then be transferred to downstream tasks of interest. However, different downstream tasks require different invariances for their best performance, so... | Chen Huang, Hanlin Goh, Jiatao Gu, Joshua M. Susskind |  |
| 1261 |  |  [Graph-based Deterministic Policy Gradient for Repetitive Combinatorial Optimization Problems](https://openreview.net/forum?id=yHIIM9BgOo) |  | 0 | We propose an actor-critic framework for graph-based machine learning pipelines with non-differentiable blocks, and apply it to repetitive combinatorial optimization problems (COPs) under hard constraints. Repetitive COP refers to problems to be solved repeatedly on graphs of the same or slowly... | Ananthram Swami, Santiago Segarra, Zhongyuan Zhao |  |
| 1262 |  |  [Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice Polytopes](https://openreview.net/forum?id=2mvALOAWaxY) |  | 0 | We prove that the set of functions representable by ReLU neural networks with integer weights strictly increases with the network depth while allowing arbitrary width. More precisely, we show that $\lceil\log_2(n)\rceil$ hidden layers are indeed necessary to compute the maximum of $n$ numbers,... | Christian Haase, Christoph Hertrich, Georg Loho |  |
| 1263 |  |  [Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees](https://openreview.net/forum?id=JLLTtEdh1ZY) |  | 0 | Although deep reinforcement learning (DRL) has many success stories, the large-scale deployment of policies learned through these advanced techniques in safety-critical scenarios is hindered by their lack of formal guarantees. Variational Markov Decision Processes (VAE-MDPs) are discrete latent... | Ann Nowé, Florent Delgrange, Guillermo A. Pérez |  |
| 1264 |  |  [Global Explainability of GNNs via Logic Combination of Learned Concepts](https://openreview.net/forum?id=OTbRTIY4YS) |  | 0 | While instance-level explanation of GNN is a well-studied problem with plenty of approaches being developed, providing a global explanation for the behaviour of a GNN is much less explored, despite its potential in interpretability and debugging. Existing solutions either simply list local... | Andrea Passerini, Antonio Longa, Pietro Barbiero, Pietro Liò, Steve Azzolin |  |
| 1265 |  |  [Gradient Gating for Deep Multi-Rate Learning on Graphs](https://openreview.net/forum?id=JpRExTbl1-) |  | 0 | We present Gradient Gating (G$^2$), a novel framework for improving the performance of Graph Neural Networks (GNNs). Our framework is based on gating the output of GNN layers with a mechanism for multi-rate flow of message passing information across nodes of the underlying graph. Local gradients... | Benjamin Paul Chamberlain, Michael M. Bronstein, Michael W. Mahoney, Siddhartha Mishra, T. Konstantin Rusch |  |
| 1266 |  |  [MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning](https://openreview.net/forum?id=sKWlRDzPfd7) |  | 0 | Open-ended learning methods that automatically generate a curriculum of increasingly challenging tasks serve as a promising avenue toward generally capable reinforcement learning agents. Existing methods adapt curricula independently over either environment parameters (in single-agent settings) or... | Akbir Khan, Jack ParkerHolder, Jakob Nicolaus Foerster, Michael Dennis, Mikayel Samvelyan, Minqi Jiang, Roberta Raileanu, Tim Rocktäschel |  |
| 1267 |  |  [Almost Linear Constant-Factor Sketching for $\ell_1$ and Logistic Regression](https://openreview.net/forum?id=gu-SC0dpkvw) |  | 0 | We improve upon previous oblivious sketching and turnstile streaming results for $\ell_1$ and logistic regression, giving a much smaller sketching dimension achieving $O(1)$-approximation and yielding an efficient optimization problem in the sketch space. Namely, we achieve for any constant $c>0$ a... | Alexander Munteanu, David P. Woodruff, Simon Omlor |  |
| 1268 |  |  [Neural-based classification rule learning for sequential data](https://openreview.net/forum?id=7tJyBmu9iCj) |  | 0 | Discovering interpretable patterns for classification of sequential data is of key importance for a variety of fields, ranging from genomics to fraud detection or more generally interpretable decision-making. In this paper, we propose a novel differentiable fully interpretable method to discover... | François Fages, Marine Collery, Philippe Bonnard, Remy Kusters |  |
| 1269 |  |  [Leveraging Unlabeled Data to Track Memorization](https://openreview.net/forum?id=ORp91sAbzI) |  | 0 | Deep neural networks may easily memorize noisy labels present in real-world data, which degrades their ability to generalize. It is therefore important to track and evaluate the robustness of models against noisy label memorization. We propose a metric, called $\textit{susceptibility}$, to gauge... | Hanie Sedghi, Mahsa Forouzesh, Patrick Thiran |  |
| 1270 |  |  [Policy-Based Self-Competition for Planning Problems](https://openreview.net/forum?id=SmufNDN90G) |  | 0 | AlphaZero-type algorithms may stop improving on single-player tasks in case the value network guiding the tree search is unable to approximate the outcome of an episode sufficiently well. One technique to address this problem is transforming the single-player task through self-competition. The main... | Dominik Gerhard Grimm, Jakob Burger, Jonathan Pirnay, Quirin Göttl |  |
| 1271 |  |  [Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy](https://openreview.net/forum?id=KkazG4lgKL) |  | 0 | Out-of-Distribution (OOD) detection is essential for safety-critical applications of deep neural networks. OOD detection is challenging since DNN models may produce very high logits value even for OOD samples. Hence, it is of great difficulty to discriminate OOD data by directly adopting Softmax on... | Dongmei Zhang, Gang Wang, Jinsong Zhang, Lun Du, Qiang Fu, Shi Han, Xiaoguang Liu, Xu Chen, Zelin Li |  |
| 1272 |  |  [Scaling Pareto-Efficient Decision Making via Offline Multi-Objective RL](https://openreview.net/forum?id=Ki4ocDm364) |  | 0 | The goal of multi-objective reinforcement learning (MORL) is to learn policies that simultaneously optimize multiple competing objectives. In practice, an agent's preferences over the objectives may not be known apriori, and hence, we require policies that can generalize to arbitrary preferences at... | Aditya Grover, Baiting Zhu, Meihua Dang |  |
| 1273 |  |  [NAGphormer: A Tokenized Graph Transformer for Node Classification in Large Graphs](https://openreview.net/forum?id=8KYeilT3Ow) |  | 0 | The graph Transformer emerges as a new architecture and has shown superior performance on various graph mining tasks. In this work, we observe that existing graph Transformers treat nodes as independent tokens and construct a single long sequence composed of all node tokens so as to train the... | Gaichao Li, Jinsong Chen, Kaiyuan Gao, Kun He |  |
| 1274 |  |  [Bayesian Oracle for bounding information gain in neural encoding models](https://openreview.net/forum?id=iYC5hOMqUg) |  | 0 | In recent years, deep learning models have set new standards in predicting neural population responses. Most of these models currently focus on predicting the mean response of each neuron for a given input. However, neural variability around this mean is not just noise and plays a central role in... | Edgar Y. Walker, Fabian H. Sinz, KonstantinKlemens Lurz, Mohammad Bashiri |  |
| 1275 |  |  [$\Lambda$-DARTS: Mitigating Performance Collapse by Harmonizing Operation Selection among Cells](https://openreview.net/forum?id=oztkQizr3kk) |  | 0 | Differentiable neural architecture search (DARTS) is a popular method for neural architecture search (NAS), which performs cell-search and utilizes continuous relaxation to improve the search efficiency via gradient-based optimization. The main shortcoming of DARTS is performance collapse, where... | Arezou Keshavarz, Ayyoob Imani, Azadeh Shakery, Babak Nadjar Araabi, Melika Adabinejad, Mostafa Dehghani, Sajad Movahedi |  |
| 1276 |  |  [Learning Vortex Dynamics for Fluid Inference and Prediction](https://openreview.net/forum?id=nYWqxUwFc3x) |  | 0 | We propose a novel differentiable vortex particle (DVP) method to infer and predict fluid dynamics from a single video. Lying at its core is a particle-based latent space to encapsulate the hidden, Lagrangian vortical evolution underpinning the observable, Eulerian flow phenomena. Our... | Bo Zhu, HongXing Yu, Jiajun Wu, Yitong Deng |  |
| 1277 |  |  [Discovering Generalizable Multi-agent Coordination Skills from Multi-task Offline Data](https://openreview.net/forum?id=53FyUAdP7d) |  | 0 | Cooperative multi-agent reinforcement learning (MARL) faces the challenge of adapting to multiple tasks with varying agents and targets. Previous multi-task MARL approaches require costly interactions to simultaneously learn or fine-tune policies in different tasks. However, the situation that an... | Chengxing Jia, Fuxiang Zhang, Lei Yuan, Yang Yu, YiChen Li, Zongzhang Zhang |  |
| 1278 |  |  [Quality-Similar Diversity via Population Based Reinforcement Learning](https://openreview.net/forum?id=bLmSMXbqXr) |  | 0 | Diversity is a growing research topic in Reinforcement Learning (RL). Previous research on diversity has mainly focused on promoting diversity to encourage exploration and thereby improve quality (the cumulative reward), maximizing diversity subject to quality constraints, or jointly maximizing... | Chao Qian, Haobo Fu, Jian Yao, Qiang Fu, Shuang Wu, Wei Yang, Yaodong Yang, Ye Tian |  |
| 1279 |  |  [Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge Distillation](https://openreview.net/forum?id=M0_sUuEyHs) |  | 0 | Knowledge distillation (KD) has shown very promising capabilities in transferring learning representations from large models (teachers) to small models (students). However, as the capacity gap between students and teachers becomes larger, existing KD methods fail to achieve better results. Our work... | Chunya Liu, Jun Hou, Kunlin Yang, Martin Zong, Shuai Yi, Wanli Ouyang, Xinzhu Ma, Zengyu Qiu |  |
| 1280 |  |  [Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams](https://openreview.net/forum?id=rOFKmzNTbC) |  | 0 | Low-rank approximation in data streams is a fundamental and significant task in computing science, machine learning and statistics. Multiple streaming algorithms have emerged over years and most of them are inspired by randomized algorithms, more specifically, sketching methods. However, many... | Chao Yang, Chuanfu Xiao, Cuiyu Liu, Mingshuo Ding |  |
| 1281 |  |  [Language Models are Realistic Tabular Data Generators](https://openreview.net/forum?id=cEygmQNOeI) |  | 0 | Tabular data is among the oldest and most ubiquitous forms of data. However, the generation of synthetic samples with the original data’s characteristics remains a significant challenge for tabular data. While many generative models from the computer vision domain, such as variational autoencoders... | Gjergji Kasneci, Kathrin Seßler, Martin Pawelczyk, Tobias Leemann, Vadim Borisov |  |
| 1282 |  |  [Data augmentation alone can improve adversarial training](https://openreview.net/forum?id=y4uc4NtTWaq) |  | 0 | Adversarial training suffers from the issue of robust overfitting, which seriously impairs its generalization performance. Data augmentation, which is effective at preventing overfitting in standard training, has been observed by many previous works to be ineffective in mitigating overfitting in... | Lin Li, Michael W. Spratling |  |
| 1283 |  |  [CUTS: Neural Causal Discovery from Irregular Time-Series Data](https://openreview.net/forum?id=UG8bQcD3Emv) |  | 0 | Causal discovery from time-series data has been a central task in machine learning. Recently, Granger causality inference is gaining momentum due to its good explainability and high compatibility with emerging deep neural networks. However, most existing methods assume structured input data and... | Jinli Suo, Kunlun He, Qionghai Dai, Runzhao Yang, Tingxiong Xiao, Yuxiao Cheng, Zongren Li |  |
| 1284 |  |  [Quantized Compressed Sensing with Score-Based Generative Models](https://openreview.net/forum?id=OOWLRfAI_V_) |  | 0 | We consider the general problem of recovering a high-dimensional signal from noisy quantized measurements. Quantization, especially coarse quantization such as 1-bit sign measurements, leads to severe information loss and thus a good prior knowledge of the unknown signal is helpful for accurate... | Xiangming Meng, Yoshiyuki Kabashima |  |
| 1285 |  |  [Valid P-Value for Deep Learning-driven Salient Region](https://openreview.net/forum?id=qihMOPw4Sf_) |  | 0 | Various saliency map methods have been proposed to interpret and explain predictions of deep learning models. Saliency maps allow us to interpret which parts of the input signals have a strong influence on the prediction results. However, since a saliency map is obtained by complex computations in... | Daiki Miwa, Ichiro Takeuchi, Vo Nguyen Le Duy |  |
| 1286 |  |  [Complexity-Based Prompting for Multi-step Reasoning](https://openreview.net/forum?id=yf1icZHC-l9) |  | 0 | We study the task of prompting large-scale language models to perform multi-step reasoning. Existing work shows that when prompted with a chain of thoughts (CoT), sequences of short sentences describing intermediate reasoning steps towards a final answer, large language models can generate new... | Ashish Sabharwal, Hao Peng, Peter Clark, Tushar Khot, Yao Fu |  |
| 1287 |  |  [Unsupervised 3D Object Learning through Neuron Activity aware Plasticity](https://openreview.net/forum?id=mXPoBtnpMnuy) |  | 0 | We present an unsupervised deep learning model for 3D object classification. Conventional Hebbian learning, a well-known unsupervised model, suffers from loss of local features leading to reduced performance for tasks with complex geometric objects. We present a deep network with a novel Neuron... | Beomseok Kang, Biswadeep Chakraborty, Saibal Mukhopadhyay |  |
| 1288 |  |  [Visually-Augmented Language Modeling](https://openreview.net/forum?id=8IN-qLkl215) |  | 0 | Human language is grounded on multimodal knowledge including visual knowledge like colors, sizes, and shapes. However, current large-scale pre-trained language models rely on the text-only self-supervised training with massive text data, which precludes them from utilizing relevant visual... | Furu Wei, Hao Cheng, Haoyu Song, Jianfeng Gao, Li Dong, Weizhi Wang, Xiaodong Liu, Xifeng Yan |  |
| 1289 |  |  [Incremental Learning of Structured Memory via Closed-Loop Transcription](https://openreview.net/forum?id=XrgjF5-M3xi) |  | 0 | This work proposes a minimal computational model for learning structured memories of multiple object classes in an incremental setting. Our approach is based on establishing a {\em closed-loop transcription} between the classes and a corresponding set of subspaces, known as a linear discriminative... | Brent Yi, Mingyang Li, Shengbang Tong, Xili Dai, Yi Ma, Ziyang Wu |  |
| 1290 |  |  [When Data Geometry Meets Deep Function: Generalizing Offline Reinforcement Learning](https://openreview.net/forum?id=lMO7TC7cuuh) |  | 0 | In offline reinforcement learning (RL), one detrimental issue to policy learning is the error accumulation of deep \textit{Q} function in out-of-distribution (OOD) areas. Unfortunately, existing offline RL methods are often over-conservative, inevitably hurting generalization performance outside... | Haoran Xu, Jianxiong Li, Jingjing Liu, Xiangyu Zhu, Xianyuan Zhan, YaQin Zhang |  |
| 1291 |  |  [Budgeted Training for Vision Transformer](https://openreview.net/forum?id=sVzBN-DlJRi) |  | 0 | The superior performances of Vision Transformers often come with higher training costs. Compared to their CNN counterpart, Transformer models are hungry for large-scale data and their training schedules are usually prolonged. This sets great restrictions on training Transformers with limited... | Gao Huang, Hui Xue, Shiji Song, Xuan Jin, Xuran Pan, Yuan He, Zhuofan Xia |  |
| 1292 |  |  [Mind's Eye: Grounded Language Model Reasoning through Simulation](https://openreview.net/forum?id=4rXMRuoJlai) |  | 0 | Successful and effective communication between humans and AI relies on a shared experience of the world. By training solely on written text, current language models (LMs) miss the grounded experience of humans in the real-world---their failure to relate language to the physical world causes... | Andrew M. Dai, Claire Cui, Denny Zhou, Jason Wei, Ruibo Liu, Shixiang Shane Gu, Soroush Vosoughi, TeYen Wu |  |
| 1293 |  |  [What Do Self-Supervised Vision Transformers Learn?](https://openreview.net/forum?id=azCKuYyS74) |  | 0 | We present a comparative study on how and why contrastive learning (CL) and masked image modeling (MIM) differ in their representations and in their performance of downstream tasks. In particular, we demonstrate that self-supervised Vision Transformers (ViTs) have the following properties: (1) CL... | Byeongho Heo, Namuk Park, Sangdoo Yun, Taekyung Kim, Wonjae Kim |  |
| 1294 |  |  [Population-size-Aware Policy Optimization for Mean-Field Games](https://openreview.net/forum?id=fB4V-2QvCEm) |  | 0 | In this work, we attempt to bridge the two fields of finite-agent and infinite-agent games, by studying how the optimal policies of agents evolve with the number of agents (population size) in mean-field games, an agent-centric perspective in contrast to the existing works focusing typically on the... | Bo An, Hau Chan, Pengdeng Li, Shuxin Li, Xinrun Wang |  |
| 1295 |  |  [On The Relative Error of Random Fourier Features for Preserving Kernel Distance](https://openreview.net/forum?id=qs2YCziX2o-) |  | 0 | The method of random Fourier features (RFF), proposed in a seminal paper by Rahimi and Recht (NIPS'07), is a powerful technique to find approximate low-dimensional representations of points in (high-dimensional) kernel space, for shift-invariant kernels. While RFF has been analyzed under various... | Kuan Cheng, Luojian Wei, Shaofeng H.C. Jiang, Zhide Wei |  |
| 1296 |  |  [DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing](https://openreview.net/forum?id=sE7-XhLxHA) |  | 0 | This paper presents a new pre-trained language model, NewModel, which improves the original DeBERTa model by replacing mask language modeling (MLM) with replaced token detection (RTD), a more sample-efficient pre-training task. Our analysis shows that vanilla embedding sharing in ELECTRA hurts... | Jianfeng Gao, Pengcheng He, Weizhu Chen |  |
| 1297 |  |  [Squeeze Training for Adversarial Robustness](https://openreview.net/forum?id=Z_tmYu060Kr) |  | 0 | The vulnerability of deep neural networks (DNNs) to adversarial examples has attracted great attention in the machine learning community. The problem is related to non-flatness and non-smoothness of normally obtained loss landscapes. Training augmented with adversarial examples (a.k.a., adversarial... | Hao Chen, Qizhang Li, Wangmeng Zuo, Yiwen Guo |  |
| 1298 |  |  [Pushing the Accuracy-Group Robustness Frontier with Introspective Self-play](https://openreview.net/forum?id=MofT9KEF0kw) |  | 0 | Standard empirical risk minimization (ERM) training can produce deep neural network (DNN) models that are accurate on average but under-perform in under-represented population subgroups, especially when there are imbalanced group distributions in the long-tailed training data. Therefore, approaches... | Balaji Lakshminarayanan, Deepak Ramachandran, Jeremiah Zhe Liu, Jihyeon Lee, Krishnamurthy (Dj) Dvijotham, Quan Yuan |  |
| 1299 |  |  [Max-Margin Works while Large Margin Fails: Generalization without Uniform Convergence](https://openreview.net/forum?id=n-hKHMzBgy) |  | 0 | A major challenge in modern machine learning is theoretically understanding the generalization properties of overparameterized models. Many existing tools rely on uniform convergence (UC), a property that, when it holds, guarantees that the test loss will be close to the training loss, uniformly... | Colin Wei, Margalit Glasgow, Mary Wootters, Tengyu Ma |  |
| 1300 |  |  [Asymptotic Instance-Optimal Algorithms for Interactive Decision Making](https://openreview.net/forum?id=oGVu9spZaJJ) |  | 0 | Past research on interactive decision making problems (bandits, reinforcement learning, etc.) mostly focuses on the minimax regret that measures the algorithm's performance on the hardest instance. However, an ideal algorithm should adapt to the complexity of a particular problem instance and incur... | Kefan Dong, Tengyu Ma |  |
| 1301 |  |  [Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approximation](https://openreview.net/forum?id=SNwH0dDGl7_) |  | 0 | We study the problem of deployment efficient reinforcement learning (RL) with linear function approximation under the \emph{reward-free} exploration setting. This is a well-motivated problem because deploying new policies is costly in real-life RL applications. Under the linear MDP setting with... | Dan Qiao, YuXiang Wang |  |
| 1302 |  |  [An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation](https://openreview.net/forum?id=k5PEHHY4spM) |  | 0 | Open-domain dialogue systems aim to interact with humans through natural language texts in an open-ended fashion. Despite the recent success of super large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue systems remains the common practice as they are more lightweight and... | Lili Mou, Yanshuai Cao, Yongchang Hao, Yuqiao Wen |  |
| 1303 |  |  [The hidden uniform cluster prior in self-supervised learning](https://openreview.net/forum?id=04K3PMtMckp) |  | 0 | A successful paradigm in representation learning is to perform self-supervised pretraining using tasks based on mini-batch statistics; (e.g., SimCLR, VICReg, SwAV, MSN). We show that in the formulation of all these methods is an overlooked prior to learn features that enable uniform clustering of... | Florian Bordes, Ishan Misra, Michael G. Rabbat, Mido Assran, Nicolas Ballas, Pascal Vincent, Piotr Bojanowski, Quentin Duval, Randall Balestriero |  |
| 1304 |  |  [Long-Tailed Partial Label Learning via Dynamic Rebalancing](https://openreview.net/forum?id=sXfWoK4KvSW) |  | 0 | Real-world data usually couples the label ambiguity and heavy imbalance, challenging the algorithmic robustness of partial label learning (PLL) and long-tailed learning (LT). The straightforward combination of LT and PLL, i.e., LT-PLL, suffers from a fundamental dilemma: LT methods build upon a... | Feng Hong, Jiangchao Yao, Ya Zhang, Yanfeng Wang, Zhihan Zhou |  |
| 1305 |  |  [Task Ambiguity in Humans and Language Models](https://openreview.net/forum?id=QrnDe_9ZFd8) |  | 0 | Language models have recently achieved strong performance across a wide range of NLP benchmarks. However, real world tasks are often poorly specified, and agents must deduce the intended behavior from a combination of context, instructions, and examples. We investigate how both humans and models... | Alex Tamkin, Avash Shrestha, Kunal Handa, Noah D. Goodman |  |
| 1306 |  |  [Winning Both the Accuracy of Floating Point Activation and the Simplicity of Integer Arithmetic](https://openreview.net/forum?id=z92lBy1ehjI) |  | 0 | Even though floating point (FP) numbers have been adopted as a de facto standard data format for deep learning computing, the complexity of FP arithmetic impedes a broader deployment of Deep Neural Networks (DNNs). Recent works such as quantization have attempted to replace the FP matrix... | Baeseong Park, Byeongwook Kim, Dongsoo Lee, JaeJoon Kim, Jaeyong Jang, Jehun Lee, Jeonghoon Kim, Jihoon Park, Se Jung Kwon, Yulhwa Kim |  |
| 1307 |  |  [Preference Transformer: Modeling Human Preferences using Transformers for RL](https://openreview.net/forum?id=Peot1SFDX0) |  | 0 | Preference-based reinforcement learning (RL) provides a framework to train agents using human preferences between two behaviors. However, preference-based RL has been challenging to scale since it requires a large amount of human feedback to learn a reward function aligned with human intent. In... | Changyeon Kim, Honglak Lee, Jinwoo Shin, Jongjin Park, Kimin Lee, Pieter Abbeel |  |
| 1308 |  |  [More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization](https://openreview.net/forum?id=znLlSgN-4S0) |  | 0 | In cooperative multi-agent reinforcement learning (MARL), combining value decomposition with actor-critic enables agents to learn stochastic policies, which are more suitable for the partially observable environment. Given the goal of learning local policies that enable decentralized execution,... | Deheng Ye, Jiangxing Wang, Zongqing Lu |  |
| 1309 |  |  [Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks](https://openreview.net/forum?id=2YQrqe4RNv) |  | 0 | Edges in many real-world social/information networks are associated with rich text information (e.g., user-user communications or user-product reviews). However, mainstream network representation learning models focus on propagating and aggregating node attributes, lacking specific designs to... | Bowen Jin, Jiawei Han, Yu Meng, Yu Zhang |  |
| 1310 |  |  [Any-scale Balanced Samplers for Discrete Space](https://openreview.net/forum?id=lEkl0jdSb7B) |  | 0 | The locally balanced informed proposal has proved to be highly effective for sampling from discrete spaces. However, its success relies on the "local'' factor, which ensures that whenever the proposal distribution is restricted to be near the current state, the locally balanced weight functions are... | Bo Dai, Charles Sutton, Dale Schuurmans, Hanjun Dai, Haoran Sun |  |
| 1311 |  |  [Equivariant Shape-Conditioned Generation of 3D Molecules for Ligand-Based Drug Design](https://openreview.net/forum?id=4MbGnp4iPQ) |  | 0 | Shape-based virtual screening is widely used in ligand-based drug design to search chemical libraries for molecules with similar 3D shapes yet novel 2D graph structures compared to known ligands. 3D deep generative models can potentially automate this exploration of shape-conditioned 3D chemical... | Connor W. Coley, Keir Adams |  |
| 1312 |  |  [Imbalanced Semi-supervised Learning with Bias Adaptive Classifier](https://openreview.net/forum?id=rVM8wD2G7Dy) |  | 0 | Pseudo-labeling has proven to be a promising semi-supervised learning (SSL) paradigm. Existing pseudo-labeling methods commonly assume that the class distributions of training data are balanced. However, such an assumption is far from realistic scenarios and thus severely limits the performance of... | Deyu Meng, Quanziang Wang, Renzhen Wang, Xixi Jia, Yichen Wu |  |
| 1313 |  |  [On Compositional Uncertainty Quantification for Seq2seq Graph Parsing](https://openreview.net/forum?id=rJcLocAJpA6) |  | 0 | Recent years have witnessed the success of applying seq2seq models to graph parsing tasks, where the outputs are compositionally structured (e.g., a graph or a tree). However, these seq2seq approaches pose a challenge in quantifying the model’s compositional uncertainty on graph structures due to... | Du Phan, Jeremiah Zhe Liu, Jingbo Shang, Panupong Pasupat, Zi Lin |  |
| 1314 |  |  [Free Lunch for Domain Adversarial Training: Environment Label Smoothing](https://openreview.net/forum?id=GPTjnA57h_3) |  | 0 | A fundamental challenge for machine learning models is how to generalize learned models for out-of-distribution (OOD) data. Among various approaches, exploiting invariant features by Domain Adversarial Training (DAT) received widespread attention. Despite its success, we observe training... | Jian Liang, Liang Wang, Rong Jin, Tieniu Tan, Xue Wang, Yifan Zhang, Zhang Zhang |  |
| 1315 |  |  [Scaling Forward Gradient With Local Losses](https://openreview.net/forum?id=JxpBP1JM15-) |  | 0 | Forward gradient learning computes a noisy directional gradient and is a biologically plausible alternative to backprop for learning deep neural networks. The standard forward gradient algorithm suffers from the curse of dimensionality in the number of parameters. In this paper, we propose to scale... | Geoffrey E. Hinton, Mengye Ren, Renjie Liao, Simon Kornblith |  |
| 1316 |  |  [Understanding Embodied Reference with Touch-Line Transformer](https://openreview.net/forum?id=ugA1HX69sf) |  | 0 | We study embodied reference understanding, the task of locating referents using embodied gestural signals and language references. Human studies have revealed that, contrary to popular belief, objects referred to or pointed to do not lie on the elbow-wrist line, but rather on the so-called virtual... | Federico Rossano, Guyue Zhou, Hao Zhao, Jiangtao Gong, Xiaoxue Chen, Yang Li, Yixin Zhu |  |
| 1317 |  |  [Calibration Matters: Tackling Maximization Bias in Large-scale Advertising Recommendation Systems](https://openreview.net/forum?id=wzlWiO_WY4) |  | 0 | Calibration is defined as the ratio of the average predicted click rate to the true click rate. The optimization of calibration is essential to many online advertising recommendation systems because it directly affects the downstream bids in ads auctions and the amount of money charged to... | Kun Zhang, Nian Si, Yewen Fan |  |
| 1318 |  |  [Memorization-Dilation: Modeling Neural Collapse Under Noise](https://openreview.net/forum?id=cJWxqmmDL2b) |  | 0 | The notion of neural collapse refers to several emergent phenomena that have been empirically observed across various canonical classification problems. During the terminal phase of training a deep neural network, the feature embedding of all examples of the same class tend to collapse to a single... | Duc Anh Nguyen, Eyke Hüllermeier, Gitta Kutyniok, Julian Lienen, Ron Levie |  |
| 1319 |  |  [Spacetime Representation Learning](https://openreview.net/forum?id=qV_M_rhYajc) |  | 0 | Much of the data we encounter in the real world can be represented as directed graphs. In this work, we introduce a general family of representations for directed graphs through connected time-oriented Lorentz manifolds, called "spacetimes" in general relativity. Spacetimes intrinsically contain a... | James Lucas, Marc T. Law |  |
| 1320 |  |  [Learning to Extrapolate: A Transductive Approach](https://openreview.net/forum?id=lid14UkLPd4) |  | 0 | Machine learning systems, especially with overparameterized deep neural networks, can generalize to novel test instances drawn from the same distribution as the training data. However, they fare poorly when evaluated on out-of-support test points. In this work, we tackle the problem of developing... | Abhishek Gupta, Aviv Netanyahu, Kaiqing Zhang, Max Simchowitz, Pulkit Agrawal |  |
| 1321 |  |  [Label-free Concept Bottleneck Models](https://openreview.net/forum?id=FlCg47MNvBA) |  | 0 | Concept bottleneck models (CBM) are a popular way of creating more interpretable neural networks by having hidden layer neurons correspond to human-understandable concepts. However, existing CBMs and their variants have two crucial limitations: first, they need to collect labeled data for each of... | Lam M. Nguyen, Subhro Das, TsuiWei Weng, Tuomas P. Oikarinen |  |
| 1322 |  |  [Multi-level Protein Structure Pre-training via Prompt Learning](https://openreview.net/forum?id=XGagtiJ8XC) |  | 0 | A protein can focus on different structure levels to implement its functions. Each structure has its own merit and driving forces in describing some specific characteristics, and they cannot replace each other. Most existing function prediction methods take the tertiary structure as input,... | Haoran Yu, Huajun Chen, Qiang Zhang, Shuangwei Hu, Xurui Jin, Zeyuan Wang, Zhichen Gong |  |
| 1323 |  |  [GLM-130B: An Open Bilingual Pre-trained Model](https://openreview.net/forum?id=-Aw0rrrPUF) |  | 0 | We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model as good as GPT-3 (davinci) and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we... | Aohan Zeng, Hanyu Lai, Jidong Zhai, Jie Tang, Ming Ding, Peng Zhang, Wendi Zheng, Weng Lam Tam, Wenguang Chen, Xiao Liu, Xiao Xia, Yifan Xu, Yufei Xue, Yuxiao Dong, Zhengxiao Du, Zhiyuan Liu, Zhuoyi Yang, Zihan Wang, Zixuan Ma |  |
| 1324 |  |  [Causal Estimation for Text Data with (Apparent) Overlap Violations](https://openreview.net/forum?id=Ha2MnQM9Ph) |  | 0 | Consider the problem of estimating the causal effect of some attribute of a text document; for example: what effect does writing a polite vs. rude email have on response time? To estimate a causal effect from observational data, we need to adjust for confounding aspects of the text that affect both... | Lin Gui, Victor Veitch |  |
| 1325 |  |  [MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations](https://openreview.net/forum?id=JdTnc9gjVfJ) |  | 0 | Poor sample efficiency continues to be the primary challenge for deployment of deep Reinforcement Learning (RL) algorithms for real-world applications, and in particular for visuo-motor control. Model-based RL has the potential to be highly sample efficient by concurrently learning a world model... | Aravind Rajeswaran, Hao Su, Nicklas Hansen, Vikash Kumar, Xiaolong Wang, Yixin Lin |  |
| 1326 |  |  [PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm](https://openreview.net/forum?id=zS9sRyaPFlJ) |  | 0 | Multi-objective reinforcement learning (MORL) approaches have emerged to tackle many real-world problems with multiple conflicting objectives by maximizing a joint objective function weighted by a preference vector. These approaches find fixed customized policies corresponding to preference vectors... | Suat Gumussoy, Toygun Basaklar, Ümit Y. Ogras |  |
| 1327 |  |  [Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning](https://openreview.net/forum?id=s130rTE3U_X) |  | 0 | While the empirical success of self-supervised learning (SSL) heavily relies on the usage of deep nonlinear models, existing theoretical works on SSL understanding still focus on linear ones. In this paper, we study the role of nonlinearity in the training dynamics of contrastive learning (CL) on... | Yuandong Tian |  |
| 1328 |  |  [M-L2O: Towards Generalizable Learning-to-Optimize by Test-Time Fast Self-Adaptation](https://openreview.net/forum?id=s7oOe6cNRT8) |  | 0 | Learning to Optimize (L2O) has drawn increasing attention as it often remarkably accelerates the optimization procedure of complex tasks by "overfitting" specific task type, leading to enhanced performance compared to analytical optimizers. Generally, L2O develops a parameterized optimization... | Junjie Yang, Tianlong Chen, Xuxi Chen, Yingbin Liang, Zhangyang Wang |  |
| 1329 |  |  [3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical Transformer for Medical Image Segmentation](https://openreview.net/forum?id=wsZsjOSytRA) |  | 0 | The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art performances on several 3D volumetric data benchmarks, including 3D medical image segmentation. Hierarchical transformers (e.g., Swin Transformers) reintroduced several ConvNet priors and further enhanced the practical... | Bennett A. Landman, Ho Hin Lee, Shunxing Bao, Yuankai Huo |  |
| 1330 |  |  [Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small](https://openreview.net/forum?id=NpsVSN6o4ul) |  | 0 | Research in mechanistic interpretability seeks to explain behaviors of ML models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge... | Alexandre Variengien, Arthur Conmy, Buck Shlegeris, Jacob Steinhardt, Kevin Ro Wang |  |
| 1331 |  |  [Equivariant Descriptor Fields: SE(3)-Equivariant Energy-Based Models for End-to-End Visual Robotic Manipulation Learning](https://openreview.net/forum?id=dnjZSPGmY5O) |  | 0 | End-to-end learning for visual robotic manipulation is known to suffer from sample inefficiency, requiring large numbers of demonstrations. The spatial roto-translation equivariance, or the SE(3)-equivariance can be exploited to improve the sample efficiency for learning robotic manipulation. In... | Hongin Lee, Hyunwoo Ryu, JeongHoon Lee, Jongeun Choi |  |
| 1332 |  |  [Explaining Temporal Graph Models through an Explorer-Navigator Framework](https://openreview.net/forum?id=BR_ZhvcYbGJ) |  | 0 | While GNN explanation has recently received significant attention, existing works are consistently designed for static graphs. Due to the prevalence of temporal graphs, many temporal graph models have been proposed, but explaining their predictions remains to be explored. To bridge the gap, in this... | Caihua Shan, Dongsheng Li, Mincai Lai, Wenwen Xia, Xiang Li, Xinnan Dai, Yao Zhang |  |
| 1333 |  |  [Soft Neighbors are Positive Supporters in Contrastive Visual Representation Learning](https://openreview.net/forum?id=l9vM_PaUKz) |  | 0 | Contrastive learning methods train visual encoders by comparing views (e.g., often created via a group of data augmentations on the same instance) from one instance to others. Typically, the views created from one instance are set as positive, while views from other instances are negative. This... | Chongjian Ge, Jiangliu Wang, Ping Luo, Shoufa Chen, Yibing Song, Zhan Tong |  |
| 1334 |  |  [Offline RL for Natural Language Generation with Implicit Language Q Learning](https://openreview.net/forum?id=aBH_DydEvoH) |  | 0 | Large language models distill broad knowledge from text corpora. However, they can be inconsistent when it comes to completing user specified tasks. This issue can be addressed by finetuning such models via supervised learning on curated datasets, or via reinforcement learning. In this work, we... | Charlie Snell, Ilya Kostrikov, Sergey Levine, Sherry Yang, Yi Su |  |
| 1335 |  |  [CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled Videos](https://openreview.net/forum?id=H-T3F0dMbyj) |  | 0 | Recent years have seen progress beyond domain-specific sound separation for speech or music towards universal sound separation for arbitrary sounds. Prior work on universal sound separation has investigated separating a target sound out of an audio mixture given a text query. Such text-queried... | HaoWen Dong, Julian J. McAuley, Naoya Takahashi, Taylor BergKirkpatrick, Yuki Mitsufuji |  |
| 1336 |  |  [On the Soft-Subnetwork for Few-Shot Class Incremental Learning](https://openreview.net/forum?id=z57WK5lGeHd) |  | 0 | Inspired by Regularized Lottery Ticket Hypothesis, which states that competitive smooth (non-binary) subnetworks exist within a dense network, we propose a few-shot class-incremental learning method referred to as Soft-SubNetworks (SoftNet). Our objective is to learn a sequence of sessions... | Chang D. Yoo, Haeyong Kang, Jaehong Yoon, Sultan Rizky Hikmawan Madjid, Sung Ju Hwang |  |
| 1337 |  |  [An Adaptive Policy to Employ Sharpness-Aware Minimization](https://openreview.net/forum?id=6Wl7-M2BC-) |  | 0 | Sharpness-aware minimization (SAM), which searches for flat minima by min-max optimization, has been shown to be useful in improving model generalization. However, since each SAM update requires computing two gradients, its computational cost and training time are both doubled compared to standard... | Hansi Yang, James T. Kwok, Weisen Jiang, Yu Zhang |  |
| 1338 |  |  [Fairness and Accuracy under Domain Generalization](https://openreview.net/forum?id=jBEXnEMdNOL) |  | 0 | As machine learning (ML) algorithms are increasingly used in high-stakes applications, concerns have arisen that they may be biased against certain social groups. Although many approaches have been proposed to make ML models fair, they typically rely on the assumption that data distributions in... | Ping Zhang, ThaiHoang Pham, Xueru Zhang |  |
| 1339 |  |  [Language Models Can Teach Themselves to Program Better](https://openreview.net/forum?id=SaRj2ka1XZ3) |  | 0 | Recent Language Models (LMs) achieve breakthrough performance in code generation when trained on human-authored problems, even solving some competitive-programming problems. Self-play has proven useful in games such as Go, and thus it is natural to ask whether LMs can generate their own instructive... | Adam Tauman Kalai, Matthew Bowers, Patrick Haluptzok |  |
| 1340 |  |  [Latent Bottlenecked Attentive Neural Processes](https://openreview.net/forum?id=yIxtevizEA) |  | 0 | Neural Processes (NPs) are popular methods in meta-learning that can estimate predictive uncertainty on target datapoints by conditioning on a context dataset. Previous state-of-the-art method Transformer Neural Processes (TNPs) achieve strong performance but require quadratic computation with... | Hossein Hajimirsadeghi, Leo Feng, Mohamed Osama Ahmed, Yoshua Bengio |  |
| 1341 |  |  [Represent to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency](https://openreview.net/forum?id=8oJHwb3Sgp) |  | 0 | Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous,... | Lingxiao Wang, Qi Cai, Zhaoran Wang, Zhuoran Yang |  |
| 1342 |  |  [Towards Better Selective Classification](https://openreview.net/forum?id=5gDz_yTcst) |  | 0 | We tackle the problem of Selective Classification where the objective is to achieve the best performance on a predetermined ratio (coverage) of the dataset. Recent state-of-the-art selective methods come with architectural changes either via introducing a separate selection head or an extra... | Amir H. Abdi, Hossein Hajimirsadeghi, Leo Feng, Mohamed Osama Ahmed |  |
| 1343 |  |  [Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment](https://openreview.net/forum?id=-G1kjTFsSs) |  | 0 | Despite the recent advances in communication-efficient distributed bandit learning, most existing solutions are restricted to parametric models, e.g., linear bandits and generalized linear bandits (GLB). In comparison, kernel bandits, which search for non-parametric functions in a reproducing... | Chuanhao Li, Hongning Wang, Huazheng Wang, Mengdi Wang |  |
| 1344 |  |  [Graph Signal Sampling for Inductive One-Bit Matrix Completion: a Closed-form Solution](https://openreview.net/forum?id=G_HSyfLk0m) |  | 0 | Inductive one-bit matrix completion is motivated by modern applications such as recommender systems, where new users would appear at test stage with the ratings consisting of only ones and no zeros. We propose a unified graph signal sampling framework which enjoys the benefits of graph signal... | Chao Chen, Gang Zeng, Haoyu Geng, Hua Chai, Junchi Yan, Xiaokang Yang, Zhaobing Han |  |
| 1345 |  |  [LipsFormer: Introducing Lipschitz Continuity to Vision Transformers](https://openreview.net/forum?id=cHf1DcCwcH3) |  | 0 | We present a Lipschitz continuous Transformer, called LipsFormer, to pursue training stability both theoretically and empirically for Transformer-based models. In contrast to previous practical tricks that address training instability by learning rate warmup, layer normalization, attention... | Jianan Wang, Lei Zhang, Xianbiao Qi, Yihao Chen, Yukai Shi |  |
| 1346 |  |  [Automatic Chain of Thought Prompting in Large Language Models](https://openreview.net/forum?id=5NTt8GFjUHkr) |  | 0 | Large Language Models (LLMs) can carry out complex reasoning tasks by generating intermediate reasoning steps. These steps are triggered by what is called chain-of-thought (CoT) prompting, which comes in two flavors: one leverages a simple prompt like "Let’s think step by step" to facilitate... | Alex Smola, Aston Zhang, Mu Li, Zhuosheng Zhang |  |
| 1347 |  |  [An efficient encoder-decoder architecture with top-down attention for speech separation](https://openreview.net/forum?id=fzberKYWKsI) |  | 0 | Deep neural networks have shown excellent prospects in speech separation tasks. However, obtaining good results while keeping a low model complexity remains challenging in real-world applications. In this paper, we provide a bio-inspired efficient encoder-decoder architecture by mimicking the... | Kai Li, Runxuan Yang, Xiaolin Hu |  |
| 1348 |  |  [Machine Unlearning of Federated Clusters](https://openreview.net/forum?id=VzwfoFyYDga) |  | 0 | Federated clustering (FC) is an unsupervised learning problem that arises in a number of practical applications, including personalized recommender and healthcare systems. With the adoption of recent laws ensuring the "right to be forgotten", the problem of machine unlearning for FC methods has... | Chao Pan, Jin Sima, Olgica Milenkovic, Saurav Prakash, Vishal Rana |  |
| 1349 |  |  [Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning](https://openreview.net/forum?id=7D5EECbOaf9) |  | 0 | Deep learning methods nowadays rely on massive data, resulting in substantial costs of data storage and model training. Data selection is a useful tool to alleviate such costs, where a coreset of massive data is extracted to practically perform on par with full data. Based on carefully-designed... | Bo Han, Jiale Liu, Jun Yu, Tongliang Liu, Xiaobo Xia, Xu Shen |  |
| 1350 |  |  [Federated Nearest Neighbor Machine Translation](https://openreview.net/forum?id=R1U5G2spbLd) |  | 0 | To protect user privacy and meet legal regulations, federated learning (FL) is attracting significant attention. Training neural machine translation (NMT) models with traditional FL algorithm (e.g., FedAvg) typically relies on multi-round model-based interactions. However, it is impractical and... | Bingzhe Wu, Enhong Chen, Lemao Liu, Tong Xu, Yichao Du, Zhirui Zhang |  |
| 1351 |  |  [Latent Variable Representation for Reinforcement Learning](https://openreview.net/forum?id=mQpmZVzXK1h) |  | 0 | Deep latent variable models have achieved significant empirical successes in model-based reinforcement learning (RL) due to their expressiveness in modeling complex transition dynamics. On the other hand, it remains unclear theoretically and empirically how latent variable models may facilitate... | Bo Dai, Chenjun Xiao, Dale Schuurmans, Na Li, Sujay Sanghavi, Tianjun Zhang, Tongzheng Ren, Zhaoran Wang |  |
| 1352 |  |  [ROCO: A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs](https://openreview.net/forum?id=2r6YMqz4Mml) |  | 0 | Solving combinatorial optimization (CO) on graphs has been attracting increasing interests from the machine learning community whereby data-driven approaches were recently devised to go beyond traditional manually-designated algorithms. In this paper, we study the robustness of a combinatorial... | Han Lu, Jia Zeng, Junchi Yan, Mingxuan Yuan, Qibing Ren, Runzhong Wang, Xiaokang Yang, Xijun Li, Zenan Li |  |
| 1353 |  |  [Words are all you need? Language as an approximation for human similarity judgments](https://openreview.net/forum?id=O-G91-4cMdv) |  | 0 | Human similarity judgments are a powerful supervision signal for machine learning applications based on techniques such as contrastive learning, information retrieval, and model alignment, but classical methods for collecting human similarity judgments are too expensive to be used at scale. Recent... | Harin Lee, Ilia Sucholutsky, Nori Jacoby, Pol van Rijn, Raja Marjieh, Theodore R. Sumers, Thomas L. Griffiths |  |
| 1354 |  |  [FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning](https://openreview.net/forum?id=PDrUPTXJI_A) |  | 0 | Semi-supervised Learning (SSL) has witnessed great success owing to the impressive performances brought by various methods based on pseudo labeling and consistency regularization. However, we argue that existing methods might fail to utilize the unlabeled data more effectively since they either use... | Bernt Schiele, Bhiksha Raj, Hao Chen, Jindong Wang, Marios Savvides, Qiang Heng, Takahiro Shinozaki, Wenxin Hou, Xing Xie, Yidong Wang, Yue Fan, Zhen Wu |  |
| 1355 |  |  [Confidence Estimation Using Unlabeled Data](https://openreview.net/forum?id=sOXU-PEJSgQ) |  | 0 | Overconfidence is a common issue for deep neural networks, limiting their deployment in real-world applications. To better estimate confidence, existing methods mostly focus on fully-supervised scenarios and rely on training labels. In this paper, we propose the first confidence estimation method... | Chao Chen, Chen Li, Xiaoling Hu |  |
| 1356 |  |  [Spectral Decomposition Representation for Reinforcement Learning](https://openreview.net/forum?id=FBMLeaXpZN) |  | 0 | Representation learning often plays a critical role in avoiding the curse of dimensionality in reinforcement learning. A representative class of algorithms exploits spectral decomposition of the stochastic transition dynamics to construct representations that enjoy strong theoretical properties in... | Bo Dai, Dale Schuurmans, Joseph E. Gonzalez, Lisa Lee, Tianjun Zhang, Tongzheng Ren |  |
| 1357 |  |  [On Accelerated Perceptrons and Beyond](https://openreview.net/forum?id=fYzLpCsGZVf) |  | 0 | The classical Perceptron algorithm of Rosenblatt can be used to find a linear threshold function to correctly classify $n$ linearly separable data points, assuming the classes are separated by some margin $\gamma > 0$. A foundational result is that Perceptron converges after $\Omega(1/\gamma^{2})$... | Etash Kumar Guha, Guanghui Wang, Jacob D. Abernethy, Rafael Hanashiro |  |
| 1358 |  |  [SoftMatch: Addressing the Quantity-Quality Tradeoff in Semi-supervised Learning](https://openreview.net/forum?id=ymt1zQXBDiF) |  | 0 | The critical challenge of Semi-Supervised Learning (SSL) is how to effectively leverage the limited labeled data and massive unlabeled data to improve the model's generalization performance. In this paper, we first revisit the popular pseudo-labeling methods via a unified sample weighting... | Bernt Schiele, Bhiksha Raj, Hao Chen, Jindong Wang, Marios Savvides, Ran Tao, Xing Xie, Yidong Wang, Yue Fan |  |
| 1359 |  |  [Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication](https://openreview.net/forum?id=dCOL0inGl3e) |  | 0 | Communication is important in many multi-agent reinforcement learning (MARL) problems for agents to share information and make good decisions. However, when deploying trained communicative agents in a real-world application where noise and potential attackers exist, the safety of... | Furong Huang, Parisa Hassanzadeh, Ruijie Zheng, Soheil Feizi, Sumitra Ganesh, Yanchao Sun, Yongyuan Liang |  |
| 1360 |  |  [Disentangling the Mechanisms Behind Implicit Regularization in SGD](https://openreview.net/forum?id=LE5LxBgjB4V) |  | 0 | A number of competing hypotheses have been proposed to explain why small-batch Stochastic Gradient Descent (SGD) leads to improved generalization over the full-batch regime, with recent work crediting the implicit regularization of various quantities throughout training. However, to date, empirical... | Saurabh Garg, Simran Kaur, Tanya Marwah, Zachary Chase Lipton, Zachary Novack |  |
| 1361 |  |  [Sequential Attention for Feature Selection](https://openreview.net/forum?id=TTLLGx3eet) |  | 0 | Feature selection is the problem of selecting a subset of features for a machine learning model that maximizes model quality subject to a budget constraint. For neural networks, prior methods, including those based on $\ell_1$ regularization, attention, and other techniques, typically select the... | Gang Fu, Lin Chen, Matthew Fahrbach, Mohammad Hossein Bateni, Taisuke Yasuda, Vahab Mirrokni |  |
| 1362 |  |  [Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs](https://openreview.net/forum?id=jpsw-KuOi7r) |  | 0 | In reward-free reinforcement learning (RL), an agent explores the environment first without any reward information, in order to achieve certain learning goals afterwards for any given reward. In this paper we focus on reward-free RL under low-rank MDP models, in which both the representation and... | Jing Yang, Ruiquan Huang, Yingbin Liang, Yuan Cheng |  |
| 1363 |  |  [Re-Imagen: Retrieval-Augmented Text-to-Image Generator](https://openreview.net/forum?id=XSEBx0iSjFQ) |  | 0 | Research on text-to-image generation has witnessed significant progress in generating diverse and photo-realistic images, driven by diffusion and auto-regressive models trained on large-scale image-text data. Though state-of-the-art models can generate high-quality images of common entities, they... | Chitwan Saharia, Hexiang Hu, Wenhu Chen, William W. Cohen |  |
| 1364 |  |  [Provably Efficient Lifelong Reinforcement Learning with Linear Representation](https://openreview.net/forum?id=Qd0p0bl-A9t) |  | 0 | We theoretically study lifelong reinforcement learning (RL) with linear representation in a regret minimization setting. The goal of the agent is to learn a multi-task policy based on a linear representation while solving a sequence of tasks that may be adaptively chosen based on the agent's past... | ChingAn Cheng, Lin Yang, Sanae Amani |  |
| 1365 |  |  [Link Prediction with Non-Contrastive Learning](https://openreview.net/forum?id=9Jaz4APHtWD) |  | 0 | Graph neural networks (GNNs) are prominent in the graph machine learning domain, owing to their strong performance across various tasks. A recent focal area is the space of graph self-supervised learning (SSL), which aims to derive useful node representations without labeled data. Notably, many... | Evangelos E. Papalexakis, Neil Shah, Tong Zhao, William Shiao, Yozen Liu, Zhichun Guo |  |
| 1366 |  |  [Distributed Differential Privacy in Multi-Armed Bandits](https://openreview.net/forum?id=cw8FeirkIfU) |  | 0 | We consider the standard $K$-armed bandit problem under a distributed trust model of differential privacy (DP), which enables to guarantee privacy without a trustworthy server. Under this trust model, previous work largely focus on achieving privacy using a shuffle protocol, where a batch of users... | Sayak Ray Chowdhury, Xingyu Zhou |  |
| 1367 |  |  [A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity](https://openreview.net/forum?id=jClGv3Qjhb) |  | 0 | Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, the theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both... | Hongkang Li, Meng Wang, PinYu Chen, Sijia Liu |  |
| 1368 |  |  [Contrastive Learning Can Find An Optimal Basis For Approximately View-Invariant Functions](https://openreview.net/forum?id=AjC0KBjiMu) |  | 0 | Contrastive learning is a powerful framework for learning self-supervised representations that generalize well to downstream supervised tasks. We show that multiple existing contrastive learning methods can be reinterpeted as learning kernel functions that approximate a fixed \*positive-pair... | Ayoub El Hanchi, Chris J. Maddison, Daniel D. Johnson |  |
| 1369 |  |  [Provably Auditing Ordinary Least Squares in Low Dimensions](https://openreview.net/forum?id=DlpCotqdTy) |  | 0 | Auditing the stability of a machine learning model to small changes in the training procedure is critical for engendering trust in practical applications. For example, a model should not be overly sensitive to removing a small fraction of its training data. However, algorithmically validating this... | Ankur Moitra, Dhruv Rohatgi |  |
| 1370 |  |  [Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs](https://openreview.net/forum?id=Qamz7Q_Ta1k) |  | 0 | Temporal networks model a variety of important phenomena involving timed interactions between entities. Existing methods for machine learning on temporal networks generally exhibit at least one of two limitations. First, many methods assume time to be discretized, so if the time data is continuous,... | Cameron Musco, Jane Hoffswell, Nedim Lipka, Ryan A. Rossi, Shunan Guo, Sudhanshu Chanpuriya, Sungchul Kim, Tong Yu |  |
| 1371 |  |  [Neural DAG Scheduling via One-Shot Priority Sampling](https://openreview.net/forum?id=WL8FlAugqQ) |  | 0 | We consider the problem of scheduling operations/nodes, the dependency among which is characterized by a Directed Acyclic Graph (DAG). Due to its NP-hard nature, heuristic algorithms were traditionally used to acquire reasonably good solutions, and more recent works have proposed Machine Learning... | Burak Bartan, Christopher Lott, Harris Teague, Mukul Gagrani, Piero Zappi, Weiliang Will Zeng, Wonseok Jeon |  |
| 1372 |  |  [Meta Temporal Point Processes](https://openreview.net/forum?id=QZfdDpTX1uM) |  | 0 | A temporal point process (TPP) is a stochastic process where its realization is a sequence of discrete events in time. Recent work in TPPs model the process using a neural network in a supervised learning framework, where a training set is a collection of all the sequences. In this work, we propose... | Frederick Tung, Gabriel L. Oliveira, Mohamed Osama Ahmed, Wonho Bae |  |
| 1373 |  |  [Graph Neural Network-Inspired Kernels for Gaussian Processes in Semi-Supervised Learning](https://openreview.net/forum?id=flap0Bo6TK_) |  | 0 | Gaussian processes (GPs) are an attractive class of machine learning models because of their simplicity and flexibility as building blocks of more complex Bayesian models. Meanwhile, graph neural networks (GNNs) emerged recently as a promising class of models for graph-structured data in... | Jie Chen, Mihai Anitescu, Zehao Niu |  |
| 1374 |  |  [Deconstructing Distributions: A Pointwise Framework of Learning](https://openreview.net/forum?id=9IaN4FkVSR1) |  | 0 | In machine learning, we traditionally evaluate the performance of a single model, averaged over a collection of test inputs. In this work, we propose a new approach: we measure the performance of a collection of models when evaluated at \*single input point\*. Specifically, we study a point's... | Boaz Barak, Gal Kaplun, Nikhil Ghosh, Preetum Nakkiran, Saurabh Garg |  |
| 1375 |  |  [Diffusion Models for Causal Discovery via Topological Ordering](https://openreview.net/forum?id=Idusfje4-Wq) |  | 0 | Discovering causal relations from observational data becomes possible with additional assumptions such as considering the functional relations to be constrained as nonlinear with additive noise (ANM). Even with strong assumptions, causal discovery involves an expensive search problem over the space... | Alison Q. O'Neil, Pedro Sanchez, Sotirios A. Tsaftaris, Xiao Liu |  |
| 1376 |  |  [Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO) Convolutions](https://openreview.net/forum?id=eb_cpjZZ3GH) |  | 0 | No existing spherical convolutional neural network (CNN) framework is both computationally scalable and rotationally equivariant. Continuous approaches capture rotational equivariance but are often prohibitively computationally demanding. Discrete approaches offer more favorable computational... | Jason D. McEwen, Jeremy Ocampo, Matthew A. Price |  |
| 1377 |  |  [Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic](https://openreview.net/forum?id=Hu4r-dedqR0) |  | 0 | Natural language inference (NLI) aims to determine the logical relationship between two sentences, such as Entailment, Contradiction, and Neutral. In recent years, deep learning models have become a prevailing approach to NLI, but they lack interpretability and explainability. In this work, we... | Atharva Naik, Lili Mou, Mauajama Firdaus, Zhijian Mei, Zi Xuan Zhang, Zijun Wu |  |
| 1378 |  |  [DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability](https://openreview.net/forum?id=462z-gLgSht) |  | 0 | In representation learning, a common approach is to seek representations which disentangle the underlying factors of variation. Eastwood & Williams (2018) proposed three metrics for quantifying the quality of such disentangled representations: disentanglement (D), completeness (C) and... | Andrea Dittadi, Andrei Liviu Nicolicioiu, Armin Kekic, Bernhard Schölkopf, Cian Eastwood, Frederik Träuble, Julius von Kügelgen |  |
| 1379 |  |  [Faster federated optimization under second-order similarity](https://openreview.net/forum?id=ElC6LYO4MfD) |  | 0 | Federated learning (FL) is a subfield of machine learning where multiple clients try to collaboratively learn a model over a network under communication constraints. We consider finite-sum federated optimization under a second-order function similarity condition and strong convexity, and propose... | Ahmed Khaled, Chi Jin |  |
| 1380 |  |  [Mutual Partial Label Learning with Competitive Label Noise](https://openreview.net/forum?id=EUrxG8IBCrC) |  | 0 | Partial label learning (PLL) is an important weakly supervised learning problem, where each training instance is associated with a set of candidate labels that include both the true label and additional noisy labels. Most existing PLL methods assume the candidate noisy labels are randomly chosen,... | Yan Yan, Yuhong Guo |  |
| 1381 |  |  [Partial Label Unsupervised Domain Adaptation with Class-Prototype Alignment](https://openreview.net/forum?id=jpq0qHggw3t) |  | 0 | Partial label learning (PLL) tackles the problem where each instance is associated with a set of candidate labels, only one of which is the ground-truth label. Most existing PLL approaches assume that both the training and test sets share an identical data distribution. However, this assumption... | Yan Yan, Yuhong Guo |  |
| 1382 |  |  [simpleKT: A Simple But Tough-to-Beat Baseline for Knowledge Tracing](https://openreview.net/forum?id=9HiGqC9C-KA) |  | 0 | Knowledge tracing (KT) is the problem of predicting students' future performance based on their historical interactions with intelligent tutoring systems. Recently, many works present lots of special methods for applying deep neural networks to KT from different perspectives like model... | Jiahao Chen, Qiongqiong Liu, Shuyan Huang, Weiqi Luo, Zitao Liu |  |
| 1383 |  |  [Weighted Ensemble Self-Supervised Learning](https://openreview.net/forum?id=CL-sVR9pvF) |  | 0 | Ensembling has proven to be a powerful technique for boosting model performance, uncertainty estimation, and robustness in supervised learning. Advances in self-supervised learning (SSL) enable leveraging large unlabeled corpora for state-of-the-art few-shot and supervised learning performance. In... | Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, Saurabh Singh, Sergey Ioffe, Warren Richard Morningstar, Yangjun Ruan |  |
| 1384 |  |  [Is a Caption Worth a Thousand Images? A Study on Representation Learning](https://openreview.net/forum?id=cYijsVZhb5) |  | 0 | The development of CLIP [Radford et al., 2021] has sparked a debate on whether adding language supervision can yield vision models with more transferable representations than traditional image-only methods. Our work studies this question through a carefully controlled comparison of two approaches,... | Percy Liang, Rohan Taori, Shibani Santurkar, Tatsunori Hashimoto, Yann Dubois |  |
| 1385 |  |  [Parameter-Efficient Fine-Tuning Design Spaces](https://openreview.net/forum?id=XSRSWxyJIC) |  | 0 | Parameter-efficient fine-tuning aims to achieve comparable performances of fine-tuning with much fewer trainable parameters. Recently, various tuning strategies (e.g., Adapters, Prefix Tuning, BitFit, and LoRA) have been proposed. However, their designs are hand-crafted separately, and it remains... | Alex Smola, Aston Zhang, Diyi Yang, Jiaao Chen, Mu Li, Xingjian Shi |  |
| 1386 |  |  [Concept Gradient: Concept-based Interpretation Without Linear Assumption](https://openreview.net/forum?id=_01dDd3f78) |  | 0 | Concept-based interpretations of black-box models are often more intuitive for humans to understand. The most widely adopted approach for concept-based, gradient interpretation is Concept Activation Vector (CAV). CAV relies on learning a linear relation between some latent representation of a given... | Andrew Bai, ChihKuan Yeh, ChoJui Hsieh, Neil Y. C. Lin, Pradeep Kumar Ravikumar |  |
| 1387 |  |  [Constraining Representations Yields Models That Know What They Don't Know](https://openreview.net/forum?id=1w_Amtk67X) |  | 0 | A well-known failure mode of neural networks is that they may confidently return erroneous predictions. Such unsafe behaviour is particularly frequent when the use case slightly differs from the training context, and/or in the presence of an adversary. This work presents a novel direction to... | David Vázquez, Issam H. Laradji, João Monteiro, Pau Rodríguez, PierreAndré Noël |  |
| 1388 |  |  [An Extensible Multi-modal Multi-task Object Dataset with Materials](https://openreview.net/forum?id=n70oyIlS4g) |  | 0 | We present EMMa, an Extensible, Multimodal dataset of Amazon product listings that contains rich Material annotations. It contains more than 2.8 million objects, each with image(s), listing text, mass, price, product ratings, and position in Amazon’s product-category taxonomy. We also design a... | Dawn Chen, Jiajun Wu, Ruohan Gao, Silvio Savarese, Trevor Scott Standley |  |
| 1389 |  |  [Sampling with Mollified Interaction Energy Descent](https://openreview.net/forum?id=zWy7dqOcel) |  | 0 | Sampling from a target measure whose density is only known up to a normalization constant is a fundamental problem in computational statistics and machine learning. In this paper, we present a new optimization-based method for sampling called mollified interaction energy descent (MIED). MIED... | Anna Korba, Justin Solomon, Lingxiao Li, Mikhail Yurochkin, Qiang Liu |  |
| 1390 |  |  [Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability](https://openreview.net/forum?id=nhKHA59gXz) |  | 0 | Traditional analyses of gradient descent show that when the largest eigenvalue of the Hessian, also known as the sharpness $S(\theta)$, is bounded by $2/\eta$, training is "stable" and the training loss decreases monotonically. Recent works, however, have observed that this assumption does not hold... | Alex Damian, Eshaan Nichani, Jason D. Lee |  |
| 1391 |  |  [TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs](https://openreview.net/forum?id=_X12NmQKvX) |  | 0 | Compared with static knowledge graphs, temporal knowledge graphs (tKG), which can capture the evolution and change of information over time, are more realistic and general. However, due to the complexity that the notion of time introduces to the learning of the rules, an accurate graph reasoning,... | Faramarz Fekri, James Clayton Kerce, Siheng Xiong, Yuan Yang |  |
| 1392 |  |  [Open-Vocabulary Object Detection upon Frozen Vision and Language Models](https://openreview.net/forum?id=MIMwy4kh9lf) |  | 0 | We present F-VLM, a simple open-vocabulary object detection method built uponFrozenVision andLanguageModels. F-VLM simplifies the current multi-stage training pipeline by eliminating the need for knowledge distillation or detection-tailored pretraining. Surprisingly, we observe that a frozen VLM:... | A. J. Piergiovanni, Anelia Angelova, Weicheng Kuo, Xiuye Gu, Yin Cui |  |
| 1393 |  |  [Revisiting the Assumption of Latent Separability for Backdoor Defenses](https://openreview.net/forum?id=_wSHsgrVali) |  | 0 | Recent studies revealed that deep learning is susceptible to backdoor poisoning attacks. An adversary can embed a hidden backdoor into a model to manipulate its predictions by only modifying a few training data, without controlling the training process. Currently, a tangible signature has been... | Prateek Mittal, Saeed Mahloujifar, Tinghao Xie, Xiangyu Qi, Yiming Li |  |
| 1394 |  |  [Restricted Strong Convexity of Deep Learning Models with Smooth Activations](https://openreview.net/forum?id=PINRbk7h01) |  | 0 | We consider the problem of optimization of deep learning models with smooth activation functions. While there exist influential results on the problem from the \`\`near initialization'' perspective, we shed considerable new light on the problem. In particular, we make two key technical... | Arindam Banerjee, Libin Zhu, Mikhail Belkin, Pedro CisnerosVelarde |  |
| 1395 |  |  [Koopman Neural Operator Forecaster for Time-series with Temporal Distributional Shifts](https://openreview.net/forum?id=kUmdmHxK5N) |  | 0 | Temporal distributional shifts, with underlying dynamics changing over time, frequently occur in real-world time series and pose a fundamental challenge for deep neural networks (DNNs). In this paper, we propose a novel deep sequence model based on the Koopman theory for time series forecasting:... | Rose Yu, Rui Wang, Sercan Ö. Arik, Yihe Dong |  |
| 1396 |  |  [MetaGL: Evaluation-Free Selection of Graph Learning Models via Meta-Learning](https://openreview.net/forum?id=C1ns08q9jZ) |  | 0 | Given a graph learning task, such as link prediction, on a new graph, how can we select the best method as well as its hyperparameters (collectively called a model) without having to train or evaluate any model on the new graph? Model selection for graph learning has been largely ad hoc. A typical... | Christos Faloutsos, Namyong Park, Nesreen K. Ahmed, Ryan A. Rossi |  |
| 1397 |  |  [Minimum Description Length Control](https://openreview.net/forum?id=oX3tGygjW1q) |  | 0 | We propose a novel framework for multitask reinforcement learning based on the minimum description length (MDL) principle. In this approach, which we term MDL-control (MDL-C), the agent learns the common structure among the tasks with which it is faced and then distills it into a simpler... | Maneesh Sahani, Matt M. Botvinick, TaChu Kao, Ted Moskovitz |  |
| 1398 |  |  [PerFedMask: Personalized Federated Learning with Optimized Masking Vectors](https://openreview.net/forum?id=hxEIgUXLFF) |  | 0 | Recently, various personalized federated learning (FL) algorithms have been proposed to tackle data heterogeneity. To mitigate device heterogeneity, a common approach is to use masking. In this paper, we first show that using random masking can lead to a bias in the obtained solution of the... | Mehdi Setayesh, Vincent W. S. Wong, Xiaoxiao Li |  |
| 1399 |  |  [Variational Latent Branching Model for Off-Policy Evaluation](https://openreview.net/forum?id=3VFQfAG3vwi) |  | 0 | Model-based methods have recently shown great potential for off-policy evaluation (OPE); offline trajectories induced by behavioral policies are fitted to transitions of Markov decision processes (MDPs), which are used to rollout simulated trajectories and estimate the performance of policies.... | Ge Gao, Min Chi, Miroslav Pajic, Qitong Gao |  |
| 1400 |  |  [Tuning Frequency Bias in Neural Network Training with Nonuniform Data](https://openreview.net/forum?id=oLIZ2jGTiv) |  | 0 | Small generalization errors of over-parameterized neural networks (NNs) can be partially explained by the frequency biasing phenomenon, where gradient-based algorithms minimize the low-frequency misfit before reducing the high-frequency residuals. Using the Neural Tangent Kernel (NTK), one can... | Alex Townsend, Annan Yu, Yunan Yang |  |
| 1401 |  |  [Learning Multimodal Data Augmentation in Feature Space](https://openreview.net/forum?id=6SRDbbvU8s) |  | 0 | The ability to jointly learn from multiple modalities, such as text, audio, and visual data, is a defining feature of intelligent systems. While there have been promising advances in designing neural networks to harness multimodal data, the enormous success of data augmentation currently remains... | Andrew Gordon Wilson, Anshumali Shrivastava, Aston Zhang, Mu Li, Xingjian Shi, Zhiqiang Tang, Zichang Liu |  |
| 1402 |  |  [BigVGAN: A Universal Neural Vocoder with Large-Scale Training](https://openreview.net/forum?id=iTtGCMDEzS_) |  | 0 | Despite recent progress in generative adversarial network (GAN)-based vocoders, where the model generates raw waveform conditioned on acoustic features, it is challenging to synthesize high-fidelity audio for numerous speakers across various recording environments. In this work, we present BigVGAN,... | Boris Ginsburg, Bryan Catanzaro, Sanggil Lee, Sungroh Yoon, Wei Ping |  |
| 1403 |  |  [Achieving Sub-linear Regret in Infinite Horizon Average Reward Constrained MDP with Linear Function Approximation](https://openreview.net/forum?id=zZhX4eYNeeh) |  | 0 | We study the infinite horizon average reward constrained Markov Decision Process (CMDP). In contrast to existing works on model-based, finite state space, we consider the model-free linear CMDP setup. We first propose a computationally inefficient algorithm and show that... | Arnob Ghosh, Ness B. Shroff, Xingyu Zhou |  |
| 1404 |  |  [Causal Imitation Learning via Inverse Reinforcement Learning](https://openreview.net/forum?id=B-z41MBL_tH) |  | 0 | One of the most common ways children learn when unfamiliar with the environment is by mimicking adults. Imitation learning concerns an imitator learning to behave in an unknown environment from an expert's demonstration; reward signals remain latent to the imitator. This paper studies imitation... | Elias Bareinboim, Junzhe Zhang, Kangrui Ruan, Xuan Di |  |
| 1405 |  |  [The Surprising Computational Power of Nondeterministic Stack RNNs](https://openreview.net/forum?id=o58JtGDs6y) |  | 0 | Traditional recurrent neural networks (RNNs) have a fixed, finite number of memory cells. In theory (assuming bounded range and precision), this limits their formal language recognition power to regular languages, and in practice, RNNs have been shown to be unable to learn many context-free... | Brian DuSell, David Chiang |  |
| 1406 |  |  [Agnostic Learning of General ReLU Activation Using Gradient Descent](https://openreview.net/forum?id=EnrY5TOrbQ) |  | 0 | We provide a convergence analysis of gradient descent for the problem of agnostically learning a single ReLU function under Gaussian distributions. Unlike prior work that studies the setting of zero bias, we consider the more challenging scenario when the bias of the ReLU function is non-zero. Our... | Alex Tang, Aravindan Vijayaraghavan, Pranjal Awasthi |  |
| 1407 |  |  [Learning Hyper Label Model for Programmatic Weak Supervision](https://openreview.net/forum?id=aCQt_BrkSjC) |  | 0 | To reduce the human annotation efforts, the programmatic weak supervision (PWS) paradigm abstracts weak supervision sources as labeling functions (LFs) and involves a label model to aggregate the output of multiple LFs to produce training labels. Most existing label models require a parameter... | Jieyu Zhang, Renzhi Wu, ShenEn Chen, Xu Chu |  |
| 1408 |  |  [FedFA: Federated Feature Augmentation](https://openreview.net/forum?id=U9yFP90jU0) |  | 0 | Federated learning is a distributed paradigm that allows multiple parties to collaboratively train deep models without exchanging the raw data. However, the data distribution among clients is naturally non-i.i.d., which leads to severe degradation of the learnt model. The primary goal of this paper... | Ender Konukoglu, Tianfei Zhou |  |
| 1409 |  |  [Offline Congestion Games: How Feedback Type Affects Data Coverage Requirement](https://openreview.net/forum?id=PXVGer7hmJ) |  | 0 | This paper investigates when one can efficiently recover an approximate Nash Equilibrium (NE) in offline congestion games. The existing dataset coverage assumption in offline general-sum games inevitably incurs a dependency on the number of actions, which can be exponentially large in congestion... | Haozhe Jiang, Maryam Fazel, Qiwen Cui, Simon Shaolei Du, Zhihan Xiong |  |
| 1410 |  |  [Does Learning from Decentralized Non-IID Unlabeled Data Benefit from Self Supervision?](https://openreview.net/forum?id=2L9gzS80tA4) |  | 0 | The success of machine learning relies heavily on massive amounts of data, which are usually generated and stored across a range of diverse and distributed data sources. Decentralized learning has thus been advocated and widely deployed to make efficient use of distributed datasets, with an... | Kaiqing Zhang, Lirui Wang, Russ Tedrake, Yonglong Tian, Yunzhu Li |  |
| 1411 |  |  [Malign Overfitting: Interpolation and Invariance are Fundamentally at Odds](https://openreview.net/forum?id=dQNL7Zsta3) |  | 0 | Learned classifiers should often possess certain invariance properties meant to encourage fairness, robustness, or out-of-distribution generalization. However, multiple recent works empirically demonstrate that common invariance-inducing regularizers are ineffective in the over-parameterized... | Gal Yona, Uri Shalit, Yair Carmon, Yoav Wald |  |
| 1412 |  |  [Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness](https://openreview.net/forum?id=aRTKuscKByJ) |  | 0 | The robustness of a deep classifier can be characterized by its margins: the decision boundary's distances to natural data points. However, it is unclear whether existing robust training methods effectively increase the margin for each vulnerable point during training. To understand this, we... | Furong Huang, Micah Goldblum, Tom Goldstein, Yanchao Sun, Yuancheng Xu |  |
| 1413 |  |  [SMART: Sentences as Basic Units for Text Evaluation](https://openreview.net/forum?id=OIe3kpwl40D) |  | 0 | Widely used evaluation metrics for text generation either do not work well with longer texts or fail to evaluate all aspects of text quality. In this paper, we introduce a new metric called SMART to mitigate such limitations. Specifically, we treat sentences as basic units of matching instead of... | Peter J. Liu, Reinald Kim Amplayo, Shashi Narayan, Yao Zhao |  |
| 1414 |  |  [Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors](https://openreview.net/forum?id=SZdfz5k7cd1) |  | 0 | The pursuit of long-term fairness involves the interplay between decision-making and the underlying data generating process. In this paper, through causal modeling with a directed acyclic graph (DAG) on the decision-distribution interplay, we investigate the possibility of achieving long-term... | Kun Zhang, Yang Liu, Yatong Chen, Zeyu Tang |  |
| 1415 |  |  [Anamnesic Neural Differential Equations with Orthogonal Polynomial Projections](https://openreview.net/forum?id=xYWqSjBcGMl) |  | 0 | Neural ordinary differential equations (Neural ODEs) are an effective framework for learning dynamical systems from irregularly sampled time series data. These models provide a continuous-time latent representation of the underlying dynamical system where new observations at arbitrary time points... | Edward De Brouwer, Rahul G. Krishnan |  |
| 1416 |  |  [AutoTransfer: AutoML with Knowledge Transfer - An Application to Graph Neural Networks](https://openreview.net/forum?id=y81ppNf_vg) |  | 0 | AutoML has demonstrated remarkable success in finding an effective neural architecture for a given machine learning task defined by a specific dataset and an evaluation metric. However, most present AutoML techniques consider each task independently from scratch, which requires exploring many... | Jiaju Liu, Jiaxuan You, Jure Leskovec, Kaidi Cao |  |
| 1417 |  |  [Temporal Dependencies in Feature Importance for Time Series Prediction](https://openreview.net/forum?id=C0q9oBc3n4) |  | 0 | Time series data introduces two key challenges for explainability methods: firstly, observations of the same feature over subsequent time steps are not independent, and secondly, the same feature can have varying importance to model predictions over time. In this paper, we propose Windowed Feature... | Clayton Rooke, Jonathan Smith, Kin Kwan Leung, Maksims Volkovs, Saba Zuberi |  |
| 1418 |  |  [Characterizing the spectrum of the NTK via a power series expansion](https://openreview.net/forum?id=Tvms8xrZHyR) |  | 0 | Under mild conditions on the network initialization we derive a power series expansion for the Neural Tangent Kernel (NTK) of arbitrarily deep feedforward networks in the infinite width limit. We provide expressions for the coefficients of this power series which depend on both the Hermite... | Benjamin Bowman, Guido Montúfar, Hui Jin, Michael Murray |  |
| 1419 |  |  [A critical look at the evaluation of GNNs under heterophily: Are we really making progress?](https://openreview.net/forum?id=tJbbQfw-5wv) |  | 0 | Node classification is a classical graph representation learning task on which Graph Neural Networks (GNNs) have recently achieved strong results. However, it is often believed that standard GNNs only work well for homophilous graphs, i.e., graphs where edges tend to connect nodes of the same... | Artem Babenko, Denis Kuznedelev, Liudmila Prokhorenkova, Michael Diskin, Oleg Platonov |  |
| 1420 |  |  [A Non-monotonic Self-terminating Language Model](https://openreview.net/forum?id=vw-5EgYbJZr) |  | 0 | Recent large-scale neural autoregressive sequence models have shown impressive performances on a variety of natural language generation tasks. However, their generated sequences often exhibit degenerate properties such as non-termination, undesirable repetition, and premature termination, when... | Cheolhyoung Lee, Eugene Choi, Kyunghyun Cho |  |
| 1421 |  |  [Learning to Segment from Noisy Annotations: A Spatial Correction Approach](https://openreview.net/forum?id=Qc_OopMEBnC) |  | 0 | Noisy labels can significantly affect the performance of deep neural networks (DNNs). In medical image segmentation tasks, annotations are error-prone due to the high demand in annotation time and in the annotators' expertise. Existing methods mostly tackle label noise in classification tasks.... | Chao Chen, Jiachen Yao, Mayank Goswami, Prateek Prasanna, Songzhu Zheng, Yikai Zhang |  |
| 1422 |  |  [Measuring Forgetting of Memorized Training Examples](https://openreview.net/forum?id=7bJizxLKrR) |  | 0 | Machine learning models exhibit two seemingly contradictory phenomena: training data memorization and various forms of forgetting. In memorization, models overfit specific training examples and become susceptible to privacy attacks. In forgetting, examples which appeared early in training are... | Abhradeep Guha Thakurta, Chiyuan Zhang, Daphne Ippolito, Eric Wallace, Florian Tramèr, Katherine Lee, Matthew Jagielski, Nicholas Carlini, Nicolas Papernot, Om Thakkar, Shuang Song |  |
| 1423 |  |  [MaskViT: Masked Visual Pre-Training for Video Prediction](https://openreview.net/forum?id=QAV2CcLEDh) |  | 0 | The ability to predict future visual observations conditioned on past observations and motor commands can enable embodied agents to plan solutions to a variety of tasks in complex environments. This work shows that we can create good video prediction models by pre-training transformers via masked... | Agrim Gupta, Jiajun Wu, Li FeiFei, Roberto MartínMartín, Stephen Tian, Yunzhi Zhang |  |
| 1424 |  |  [Text Summarization with Oracle Expectation](https://openreview.net/forum?id=HehQobsr0S) |  | 0 | Extractive summarization produces summaries by identifying and concatenating the most important sentences in a document. Since most summarization datasets do not come with gold labels indicating whether document sentences are summary-worthy, different labeling algorithms have been proposed to... | Mirella Lapata, Yumo Xu |  |
| 1425 |  |  [Continuous-time identification of dynamic state-space models by deep subspace encoding](https://openreview.net/forum?id=_4n3k3d1ob) |  | 0 | Continuous-time (CT) modeling has proven to provide improved sample efficiency and interpretability in learning the dynamical behavior of physical systems compared to discrete-time (DT) models. However, even with numerous recent developments, the CT nonlinear state-space (NL-SS) model... | Gerben Izaak Beintema, Maarten Schoukens, Roland Tóth |  |
| 1426 |  |  [How to Train your HIPPO: State Space Models with Generalized Orthogonal Basis Projections](https://openreview.net/forum?id=klK17OQ3KB) |  | 0 | Linear time-invariant state space models (SSM) are a classical model from engineering and statistics, that have recently been shown to be very promising in machine learning through the Structured State Space sequence model (S4). A core component of S4 involves initializing the SSM state matrix to a... | Albert Gu, Aman Timalsina, Atri Rudra, Christopher Ré, Isys Johnson |  |
| 1427 |  |  [Interpretable Debiasing of Vectorized Language Representations with Iterative Orthogonalization](https://openreview.net/forum?id=TkQ1sxd9P4) |  | 0 | We propose a new mechanism to augment a word vector embedding representation that offers improved bias removal while retaining the key information—resulting in improved interpretability of the representation. Rather than removing the information associated with a concept that may induce bias, our... | ChinChia Michael Yeh, Huiyuan Chen, Jack Shunn, Jeff M. Phillips, Junpeng Wang, Liang Wang, Prince Osei Aboagye, Wei Zhang, Yan Zheng, Zhongfang Zhuang |  |
| 1428 |  |  [Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations](https://openreview.net/forum?id=jwdqNwyREyh) |  | 0 | Recently, both Contrastive Learning (CL) and Mask Image Modeling (MIM) demonstrate that self-supervision is powerful to learn good representations. However, naively combining them is far from success. In this paper, we start by making the empirical observation that a naive joint optimization of CL... | Dongdong Chen, Lu Yuan, Mengchen Liu, Xiyang Dai, Yinpeng Chen, Zhangyang Wang, Zicheng Liu, Ziyu Jiang |  |
| 1429 |  |  [Discovering Latent Knowledge in Language Models Without Supervision](https://openreview.net/forum?id=ETKGuby0hcs) |  | 0 | Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose... | Collin Burns, Dan Klein, Haotian Ye, Jacob Steinhardt |  |
| 1430 |  |  [Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation](https://openreview.net/forum?id=H0gdPxSwkPb) |  | 0 | Vessel segmentation in medical images is one of the important tasks in the diagnosis of vascular diseases and therapy planning. Although learning-based segmentation approaches have been extensively studied, a large amount of ground-truth labels are required in supervised methods and confusing... | Boah Kim, Jong Chul Ye, Yujin Oh |  |
| 1431 |  |  [Noise Injection Node Regularization for Robust Learning](https://openreview.net/forum?id=gmSZ-GPNY6) |  | 0 | We introduce Noise Injection Node Regularization (NINR), a method of injecting structured noise into Deep Neural Networks (DNN) during the training stage, resulting in an emergent regularizing effect. We present theoretical and empirical evidence for substantial improvement in robustness against... | Itay M. Bloch, Marat Freytsis, Noam Levi, Tomer Volansky |  |
| 1432 |  |  [Efficient Edge Inference by Selective Query](https://openreview.net/forum?id=jpR98ZdIm2q) |  | 0 | Edge devices provide inference on predictive tasks to many end-users. However, deploying deep neural networks that achieve state-of-the-art accuracy on these devices is infeasible due to edge resource constraints. Nevertheless, cloud-only processing, the de-facto standard, is also problematic,... | Aditya Gangrade, Anil Kag, Igor Fedorov, Paul N. Whatmough, Venkatesh Saligrama |  |
| 1433 |  |  [Human-level Atari 200x faster](https://openreview.net/forum?id=JtC6yOHRoJJ) |  | 0 | The task of building general agents that perform well over a wide range of tasks has been an important goal in reinforcement learning since its inception. The problem has been subject of research of a large body of work, with performance frequently measured by observing scores over the wide range... | Adrià Puigdomènech Badia, Charles Blundell, Hado van Hasselt, Nemanja Rakicevic, Ray Jiang, Steven Kapturowski, Victor Campos |  |
| 1434 |  |  [Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks](https://openreview.net/forum?id=mkJm5Uy4HrQ) |  | 0 | We propose a novel clustering mechanism based on an incompatibility property between subsets of data that emerges during model training. This mechanism partitions the dataset into subsets that generalize only to themselves, i.e., training on one subset does not improve performance on the other... | Charles Jin, Martin C. Rinard, Melinda Sun |  |
| 1435 |  |  [A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games](https://openreview.net/forum?id=DpE5UYUQzZH) |  | 0 | This work studies an algorithm, which we call magnetic mirror descent, that is inspired by mirror descent and the non-Euclidean proximal gradient algorithm. Our contribution is demonstrating the virtues of magnetic mirror descent as both an equilibrium solver and as an approach to reinforcement... | Christian Kroer, Ioannis Mitliagkas, J. Zico Kolter, Marc Lanctot, Nicolas Loizou, Noam Brown, Ryan D'Orazio, Samuel Sokota |  |
| 1436 |  |  [Pitfalls of Gaussians as a noise distribution in NCE](https://openreview.net/forum?id=ovZE0KsbM3S) |  | 0 | Noise Contrastive Estimation (NCE) is a popular approach for learning probability density functions parameterized up to a constant of proportionality. The main idea is to design a classification problem for distinguishing training data from samples from an (easy-to-sample) noise distribution $q$,... | Andrej Risteski, Anish Prasad Sevekari, Chirag Pabbaraju, Holden Lee |  |
| 1437 |  |  [Scaling Laws for a Multi-Agent Reinforcement Learning Model](https://openreview.net/forum?id=ZrEbzL9eQ3W) |  | 0 | The recent observation of neural power-law scaling relations has made a significant impact in the field of deep learning. A substantial amount of attention has been dedicated as a consequence to the description of scaling laws, although mostly for supervised learning and only to a reduced extent... | Claudius Gros, Oren Neumann |  |
| 1438 |  |  [Perfectly Secure Steganography Using Minimum Entropy Coupling](https://openreview.net/forum?id=HQ67mj5rJdR) |  | 0 | Steganography is the practice of encoding secret information into innocuous content in such a manner that an adversarial third party would not realize that there is hidden meaning. While this problem has classically been studied in security literature, recent advances in generative models have led... | Christian Schröder de Witt, J. Zico Kolter, Jakob Nicolaus Foerster, Martin Strohmeier, Samuel Sokota |  |
| 1439 |  |  [Calibrating Transformers via Sparse Gaussian Processes](https://openreview.net/forum?id=jPVAFXHlbL) |  | 0 | Transformer models have achieved profound success in prediction tasks in a wide range of applications in natural language processing, speech recognition and computer vision. Extending Transformer’s success to safety-critical domains requires calibrated uncertainty estimation which remains... | Wenlong Chen, Yingzhen Li |  |
| 1440 |  |  [Red PANDA: Disambiguating Image Anomaly Detection by Removing Nuisance Factors](https://openreview.net/forum?id=z37tDDHHgi) |  | 0 | Anomaly detection methods strive to discover patterns that differ from the norm in a meaningful way. This goal is ambiguous as different human operators may find different attributes meaningful. An image differing from the norm by an attribute such as pose may be considered anomalous by some... | Jonathan Kahana, Niv Cohen, Yedid Hoshen |  |
| 1441 |  |  [Is Attention All That NeRF Needs?](https://openreview.net/forum?id=xE-LtsE-xx) |  | 0 | We present Generalizable NeRF Transformer (GNT), a transformer-based architecture that reconstructs Neural Radiance Fields (NeRFs) and learns to render novel views on the fly from source views. While prior works on NeRFs optimize a scene representation by inverting a handcrafted rendering equation,... | Mukund Varma T., Peihao Wang, Subhashini Venugopalan, Tianlong Chen, Xuxi Chen, Zhangyang Wang |  |
| 1442 |  |  [Stochastic No-regret Learning for General Games with Variance Reduction](https://openreview.net/forum?id=oJZ8bPtCar) |  | 0 | We show that a stochastic version of optimistic mirror descent (OMD), a variant of mirror descent with recency bias, converges fast in general games. More specifically, with our algorithm, the individual regret of each player vanishes at a speed of $O(1/T^{3/4})$ and the sum of all players' regret... | Fang Kong, Shuai Li, Yichi Zhou |  |
| 1443 |  |  [The Dark Side of AutoML: Towards Architectural Backdoor Search](https://openreview.net/forum?id=bsZULlDGXe) |  | 0 | This paper asks the intriguing question: is it possible to exploit neural architecture search (NAS) as a new attack vector to launch previously improbable attacks? Specifically, we present EVAS, a new attack that leverages NAS to find neural architectures with inherent backdoors and exploits such... | Changjiang Li, Ren Pang, Shouling Ji, Ting Wang, Zhaohan Xi |  |
| 1444 |  |  [Generalization and Estimation Error Bounds for Model-based Neural Networks](https://openreview.net/forum?id=9F_xlC7sk9) |  | 0 | Model-based neural networks provide unparalleled performance for various tasks, such as sparse coding and compressed sensing problems. Due to the strong connection with the sensing model, these networks are interpretable and inherit prior structure of the problem. In practice, model-based neural... | Avner Shultzman, Eyar Azar, Miguel R. D. Rodrigues, Yonina C. Eldar |  |
| 1445 |  |  [ChordMixer: A Scalable Neural Attention Model for Sequences with Different Length](https://openreview.net/forum?id=E8mzu3JbdR) |  | 0 | Sequential data naturally have different lengths in many domains, with some very long sequences. As an important modeling tool, neural attention should capture long-range interaction in such sequences. However, most existing neural attention models admit only short sequences, or they have to employ... | Lei Cheng, Ruslan Khalitov, Tong Yu, Zhirong Yang |  |
| 1446 |  |  [Boosting Adversarial Transferability using Dynamic Cues](https://openreview.net/forum?id=SZynfVLGd5) |  | 0 | The transferability of adversarial perturbations between image models has been extensively studied. In this case, an attack is generated from a known surrogate \eg, the ImageNet trained model, and transferred to change the decision of an unknown (black-box) model trained on an image dataset.... | Ahmad Mahmood, Fahad Shahbaz Khan, Muzammal Naseer, Salman Khan |  |
| 1447 |  |  [Static Prediction of Runtime Errors by Learning to Execute Programs with External Resource Descriptions](https://openreview.net/forum?id=lLp-C5nTdJG) |  | 0 | The execution behavior of a program often depends on external resources, such as program inputs or file contents, and so the program cannot be run in isolation. Nevertheless, software developers benefit from fast iteration loops where automated tools identify errors as early as possible, even... | Daniel Tarlow, Daniel Zheng, David Bieber, Hugo Larochelle, Rishab Goel |  |
| 1448 |  |  [Matching receptor to odorant with protein language and graph neural networks](https://openreview.net/forum?id=q9VherQJd8_) |  | 0 | Odor perception in mammals is triggered by interactions between volatile organic compounds and a subset of hundreds of proteins called olfactory receptors (ORs). Molecules activate these receptors in a complex combinatorial coding allowing mammals to discriminate a vast number of chemical stimuli.... | Jérémie Topin, Matej Hladis, Maxence Lalis, Sébastien Fiorucci |  |
| 1449 |  |  [SGDA with shuffling: faster convergence for nonconvex-PŁ minimax optimization](https://openreview.net/forum?id=6xXtM8bFFJ) |  | 0 | Stochastic gradient descent-ascent (SGDA) is one of the main workhorses for solving finite-sum minimax optimization problems. Most practical implementations of SGDA randomly reshuffle components and sequentially use them (i.e., without-replacement sampling); however, there are few theoretical... | Chulhee Yun, Hanseul Cho |  |
| 1450 |  |  [MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models](https://openreview.net/forum?id=H0HGljkxQFN) |  | 0 | This paper presents MOAT, a family of neural networks that build on top of MObile convolution (i.e., inverted residual blocks) and ATtention. Unlike the current works that stack separate mobile convolution and transformer blocks, we effectively merge them into a MOAT block. Starting with a standard... | Alan L. Yuille, Chenglin Yang, Hartwig Adam, LiangChieh Chen, Qihang Yu, Siyuan Qiao, Xiaoding Yuan, Yukun Zhu |  |
| 1451 |  |  [Part-Based Models Improve Adversarial Robustness](https://openreview.net/forum?id=bAMTaeqluh4) |  | 0 | We show that combining human prior knowledge with end-to-end learning can improve the robustness of deep neural networks by introducing a part-based model for object classification. We believe that the richer form of annotation helps guide neural networks to learn more robust features without... | Chawin Sitawarin, David A. Wagner, Kornrapat Pongmala, Nicholas Carlini, Yizheng Chen |  |
| 1452 |  |  [PGrad: Learning Principal Gradients For Domain Generalization](https://openreview.net/forum?id=CgCmwcfgEdH) |  | 0 | Machine learning models fail to perform when facing out-of-distribution (OOD) domains, a challenging task known as domain generalization (DG). In this work, we develop a novel DG training strategy, we call PGrad, to learn a robust gradient direction, improving models' generalization ability on... | Jake Grigsby, Yanjun Qi, Zhe Wang |  |
| 1453 |  |  [Extremely Simple Activation Shaping for Out-of-Distribution Detection](https://openreview.net/forum?id=ndYXTEL6cZz) |  | 0 | The separation between training and deployment of machine learning models implies that not all scenarios encountered in deployment can be anticipated during training, and therefore relying solely on advancements in training has its limits. Out-of-distribution (OOD) detection is an important area... | Andrija Djurisic, Arjun Ashok, Nebojsa Bozanic, Rosanne Liu |  |
| 1454 |  |  [Statistical Guarantees for Consensus Clustering](https://openreview.net/forum?id=kQxry8Z6Fd9) |  | 0 | Consider the problem of clustering $n$ objects. One can apply multiple algorithms to produce $N$ potentially different clustersings of the same objects, that is, partitions of the $n$ objects into $K$ groups. Even a single randomized algorithm can output different clusterings. This often happens... | Arash A. Amini, Gautam Dudeja, Zhixin Zhou |  |
| 1455 |  |  [Expressive Monotonic Neural Networks](https://openreview.net/forum?id=w2P7fMy_RH) |  | 0 | The monotonic dependence of the outputs of a neural network on some of its inputs is a crucial inductive bias in many scenarios where domain knowledge dictates such behavior. This is especially important for interpretability and fairness considerations. In a broader context, scenarios in which... | Mike Williams, Niklas Nolte, Ouail Kitouni |  |
| 1456 |  |  [Active Image Indexing](https://openreview.net/forum?id=K9RHxPpjn2) |  | 0 | Image copy detection and retrieval from large databases leverage two components. First, a neural network maps an image to a vector representation, that is relatively robust to various transformations of the image. Second, an efficient but approximate similarity search algorithm trades scalability... | Hervé Jégou, Matthijs Douze, Pierre Fernandez, Teddy Furon |  |
| 1457 |  |  [Learning Simultaneous Navigation and Construction in Grid Worlds](https://openreview.net/forum?id=NEtep2C7yD) |  | 0 | We propose to study a new learning task, mobile construction, to enable an agent to build designed structures in 1/2/3D grid worlds while navigating in the same evolving environments. Unlike existing robot learning tasks such as visual navigation and object manipulation, this task is challenging... | Alexander Gao, Chen Feng, Eisuke Hirota, Haoran Wu, Lerrel Pinto, Ludovic Righetti, Wenyu Han |  |
| 1458 |  |  [Learning to CROSS exchange to solve min-max vehicle routing problems](https://openreview.net/forum?id=ZcnzsHC10Y) |  | 0 | CROSS exchange (CE), a meta-heuristic that solves various vehicle routing problems (VRPs), improves the solutions of VRPs by swapping the sub-tours of the vehicles. Inspired by CE, we propose Neuro CE (NCE), a fundamental operator of \textit{learned} meta-heuristic, to solve various min-max VRPs... | Jinkyoo Park, Junyoung Park, Minjun Kim |  |
| 1459 |  |  [PandA: Unsupervised Learning of Parts and Appearances in the Feature Maps of GANs](https://openreview.net/forum?id=iUdSB2kK9GY) |  | 0 | Recent advances in the understanding of Generative Adversarial Networks (GANs) have led to remarkable progress in visual editing and synthesis tasks, capitalizing on the rich semantics that are embedded in the latent spaces of pre-trained GANs. However, existing methods are often tailored to... | Christos Tzelepis, Ioannis Patras, James Oldfield, Mihalis Nicolaou, Yannis Panagakis |  |
| 1460 |  |  [Compositional Law Parsing with Latent Random Functions](https://openreview.net/forum?id=PEuxUXIMLlA) |  | 0 | Human cognition has compositionality. We understand a scene by decomposing the scene into different concepts (e.g., shape and position of an object) and learning the respective laws of these concepts, which may be either natural (e.g., laws of motion) or man-made (e.g., laws of a game). The... | Bin Li, Fan Shi, Xiangyang Xue |  |
| 1461 |  |  [LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification](https://openreview.net/forum?id=NVZvalzCLg) |  | 0 | We introduce LilNetX, an end-to-end trainable technique for neural networks that enables learning models with specified accuracy-rate-computation trade-off. Prior works approach these problems one at a time and often require post-processing or multistage training which become less practical and do... | Abhinav Shrivastava, Kamal Gupta, Saurabh Singh, Sharath Girish |  |
| 1462 |  |  [Mitigating Dataset Bias by Using Per-Sample Gradient](https://openreview.net/forum?id=7mgUec-7GMv) |  | 0 | The performance of deep neural networks is strongly influenced by the training dataset setup. In particular, when attributes with a strong correlation with the target attribute are present, the trained model can provide unintended prejudgments and show significant inference errors (i.e., the... | SeYoung Yun, Seongyoon Kim, Sumyeong Ahn |  |
| 1463 |  |  [Efficient Model Updates for Approximate Unlearning of Graph-Structured Data](https://openreview.net/forum?id=fhcu4FBLciL) |  | 0 | With the adoption of recent laws ensuring the \`\`right to be forgotten'', the problem of machine unlearning has become of significant importance. This is particularly the case for graph-structured data, and learning tools specialized for such data, including graph neural networks (GNNs). This work... | Chao Pan, Eli Chien, Olgica Milenkovic |  |
| 1464 |  |  [AudioGen: Textually Guided Audio Generation](https://openreview.net/forum?id=CYK7RfcOzQ4) |  | 0 | In this work, we tackle the problem of generating audio samples conditioned on descriptive text captions. We propose AudioGen, an auto-regressive generative model, operating on a learnt discrete audio representation, that generates audio samples conditioned on text inputs. The task of text-to-audio... | Adam Polyak, Alexandre Défossez, Devi Parikh, Felix Kreuk, Gabriel Synnaeve, Jade Copet, Uriel Singer, Yaniv Taigman, Yossi Adi |  |
| 1465 |  |  [Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid Learning in RNNs](https://openreview.net/forum?id=2WklawyeI08) |  | 0 | Rapidly learning from ongoing experiences and remembering past events with a flexible memory system are two core capacities of biological intelligence. While the underlying neural mechanisms are not fully understood, various evidence supports that synaptic plasticity plays a critical role in memory... | Kaisheng Ma, Qian Li, Yi Zhong, Yu Duan, Zhongfan Jia |  |
| 1466 |  |  [Towards Minimax Optimal Reward-free Reinforcement Learning in Linear MDPs](https://openreview.net/forum?id=U9HW6vyNClg) |  | 0 | We study reward-free reinforcement learning with linear function approximation for episodic Markov decision processes (MDPs). In this setting, an agent first interacts with the environment without accessing the reward function in the exploration phase. In the subsequent planning phase, it is given... | Longbo Huang, Pihe Hu, Yu Chen |  |
| 1467 |  |  [On the Data-Efficiency with Contrastive Image Transformation in Reinforcement Learning](https://openreview.net/forum?id=-nm-rHXi5ga) |  | 0 | Data-efficiency has always been an essential issue in pixel-based reinforcement learning (RL). As the agent not only learns decision-making but also meaningful representations from images. The line of reinforcement learning with data augmentation shows significant improvements in sample-efficiency.... | Jian Cheng, Sicong Liu, Xi Sheryl Zhang, Yifan Zhang, Yushuo Li |  |
| 1468 |  |  [Energy-based Out-of-Distribution Detection for Graph Neural Networks](https://openreview.net/forum?id=zoz7Ze4STUL) |  | 0 | Representation learning on semi-structured data, e.g., graphs, has become a central problem in deep learning community as relational structures are pervasive in real situations and induce data inter-dependence that hinders trivial adaptation of existing approaches in other domains where the inputs... | Chenxiao Yang, Junchi Yan, Qitian Wu, Yiting Chen |  |
| 1469 |  |  [Quasi-optimal Reinforcement Learning with Continuous Actions](https://openreview.net/forum?id=O8Vc52xFSUR) |  | 0 | Many real-world applications of reinforcement learning (RL) require making decisions in continuous action environments. In particular, determining the optimal dose level plays a vital role in developing medical treatment regimes. One challenge in adapting existing RL algorithms to medical... | Ruoqing Zhu, Wenzhuo Zhou, Yuhan Li |  |
| 1470 |  |  [Generalization Bounds for Federated Learning: Fast Rates, Unparticipating Clients and Unbounded Losses](https://openreview.net/forum?id=-EHqoysUYLx) |  | 0 | In {federated learning}, the underlying data distributions may be different across clients. This paper provides a theoretical analysis of generalization error of {federated learning}, which captures both heterogeneity and relatedness of the distributions. In particular, we assume that the... | Shaojie Li, Xiaolin Hu, Yong Liu |  |
| 1471 |  |  [More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity](https://openreview.net/forum?id=bXNl-myZkJl) |  | 0 | Transformers have quickly shined in the computer vision world since the emergence of Vision Transformers (ViTs). The dominant role of convolutional neural networks (CNNs) seems to be challenged by increasingly effective transformer-based models. Very recently, a couple of advanced convolutional... | Boqian Wu, Decebal Constantin Mocanu, Mykola Pechenizkiy, Qiao Xiao, Shiwei Liu, Tianlong Chen, Tommi Kärkkäinen, Xiaohan Chen, Xuxi Chen, Zhangyang Wang |  |
| 1472 |  |  [Which Layer is Learning Faster? A Systematic Exploration of Layer-wise Convergence Rate for Deep Neural Networks](https://openreview.net/forum?id=wlMDF1jQF86) |  | 0 | The deeply hierarchical structures enable deep neural networks (DNNs) to fit extremely complex target functions. However, the complex interaction between layers also makes the learning process of a particular layer poorly understood. This work demonstrates that the shallower layers of DNNs tend to... | Alan L. Yuille, Yixiong Chen, Zongwei Zhou |  |
| 1473 |  |  [A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks](https://openreview.net/forum?id=CJd-BtnwtXq) |  | 0 | Oversmoothing is a central challenge of building more powerful Graph Neural Networks (GNNs). While previous works have only demonstrated that oversmoothing is inevitable when the number of graph convolutions tends to infinity, in this paper, we precisely characterize the mechanism behind the... | Ali Jadbabaie, William Wei Wang, Xinyi Wu, Zhengdao Chen |  |
| 1474 |  |  [Scaleformer: Iterative Multi-scale Refining Transformers for Time Series Forecasting](https://openreview.net/forum?id=sCrnllCtjoE) |  | 0 | The performance of time series forecasting has recently been greatly improved by the introduction of transformers. In this paper, we propose a general multi-scale framework that can be applied to state-of-the-art transformer-based time series forecasting models (FEDformer, Autoformer, etc.). Using... | Amir H. Abdi, Lili Meng, Mohammad Amin Shabani, Tristan Sylvain |  |
| 1475 |  |  [Liquid Structural State-Space Models](https://openreview.net/forum?id=g4OTKRKfS7R) |  | 0 | A proper parametrization of state transition matrices of linear state-space models (SSMs) followed by standard nonlinearities enables them to efficiently learn representations from sequential data, establishing the state-of-the-art on an extensive series of long-range sequence modeling benchmarks.... | Alexander Amini, Daniela Rus, Makram Chahine, Mathias Lechner, Ramin M. Hasani, TsunHsuan Wang |  |
| 1476 |  |  [Equivariant Hypergraph Diffusion Neural Operators](https://openreview.net/forum?id=RiTjKoscnNd) |  | 0 | Hypergraph neural networks (HNNs) using neural networks to encode hypergraphs provide a promising way to model higher-order relations in data and further solve relevant prediction tasks built upon such higher-order relations. However, higher-order relations in practice contain complex patterns and... | Pan Li, Peihao Wang, Shenghao Yang, Yunyu Liu, Zhangyang Wang |  |
| 1477 |  |  [Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework](https://openreview.net/forum?id=sPCKNl5qDps) |  | 0 | Bridging geometry and topology, curvature is a powerful and expressive invariant. While the utility of curvature has been theoretically and empirically confirmed in the context of manifolds and graphs, its generalization to the emerging domain of hypergraphs has remained largely unexplored. On... | Bastian Rieck, Corinna Coupette, Sebastian Dalleiger |  |
| 1478 |  |  [Hard-Meta-Dataset++: Towards Understanding Few-Shot Performance on Difficult Tasks](https://openreview.net/forum?id=wq0luyH3m4) |  | 0 | Few-shot classification is the ability to adapt to any new classification task from only a few training examples. The performance of current top-performing few-shot classifiers varies widely across different tasks where they often fail on a subset of \`difficult' tasks. This phenomenon has... | Daniela Massiceti, John Bronskill, Megan Stanley, Samyadeep Basu, Soheil Feizi |  |
| 1479 |  |  [Compositional Semantic Parsing with Large Language Models](https://openreview.net/forum?id=gJW8hSGBys8) |  | 0 | Humans can reason compositionally when presented with new tasks. Previous research shows that appropriate prompting techniques enable large language models (LLMs) to solve artificial compositional generalization tasks such as SCAN. In this work, we identify additional challenges in more realistic... | Andrew Drozdov, Denny Zhou, Ekin Akyürek, Nathan Scales, Nathanael Schärli, Olivier Bousquet, Xinying Song, Xinyun Chen |  |
| 1480 |  |  [TiAda: A Time-scale Adaptive Algorithm for Nonconvex Minimax Optimization](https://openreview.net/forum?id=zClyiZ5V6sL) |  | 0 | Adaptive gradient methods have shown their ability to adjust the stepsizes on the fly in a parameter-agnostic manner, and empirically achieve faster convergence for solving minimization problems. When it comes to nonconvex minimax optimization, however, current convergence analyses of gradient... | Junchi Yang, Niao He, Xiang Li |  |
| 1481 |  |  [FaiREE: fair classification with finite-sample and distribution-free guarantee](https://openreview.net/forum?id=shzu8d6_YAR) |  | 0 | Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depend on specific data distributional assumptions, often requiring... | James Zou, Linjun Zhang, Puheng Li |  |
| 1482 |  |  [Exponential Generalization Bounds with Near-Optimal Rates for $L_q$-Stable Algorithms](https://openreview.net/forum?id=1_jtWjhSSkr) |  | 0 | The \emph{stability} of learning algorithms to changes in the training sample has been actively studied as a powerful proxy for reasoning about generalization. Recently, exponential generalization and excess risk bounds with near-optimal rates have been obtained under the stringent and... | Ping Li, Xiaotong Yuan |  |
| 1483 |  |  [Disentangling Learning Representations with Density Estimation](https://openreview.net/forum?id=EMvG1Jdhw_8) |  | 0 | Disentangled learning representations have promising utility in many applications, but they currently suffer from serious reliability issues. We present Gaussian Channel Autoencoder (GCAE), a method which achieves reliable disentanglement via scalable non-parametric density estimation of the latent... | Eric C. Yeats, Frank Y. Liu, Hai Helen Li |  |
| 1484 |  |  [Teacher Guided Training: An Efficient Framework for Knowledge Transfer](https://openreview.net/forum?id=GVSf7Z7DbYL) |  | 0 | The remarkable performance gains realized by large pretrained models, e.g., GPT-3, hinge on the massive amounts of data they are exposed to during training. Analogously, distilling such large models to compact models for efficient deployment also necessitates a large amount of (labeled or... | Andreas Veit, Ankit Singh Rawat, Chong You, Himanshu Jain, Manzil Zaheer, Rob Fergus, Sanjiv Kumar, Seungyeon Kim |  |
| 1485 |  |  [Neural Agents Struggle to Take Turns in Bidirectional Emergent Communication](https://openreview.net/forum?id=GULFHQfgw0g) |  | 0 | The spontaneous exchange of turns is a central aspect of human communication. Although turn-taking conventions come to us naturally, artificial dialogue agents struggle to coordinate, and must rely on hard-coded rules to engage in interactive conversations with human interlocutors. In this paper,... | Benoît Sagot, Dieuwke Hupkes, Emmanuel Dupoux, Paul Michel, Valentin Taillandier |  |
| 1486 |  |  [Prompting GPT-3 To Be Reliable](https://openreview.net/forum?id=98p5x51L5af) |  | 0 | Large language models (LLMs) show impressive abilities via few-shot prompting. Commercialized APIs such as OpenAI GPT-3 further increase their use in real-world language applications. However, the crucial problem of how to improve the reliability of GPT-3 is still under-explored. While reliability... | Chenglei Si, Jianfeng Wang, Jordan L. BoydGraber, Lijuan Wang, Shuohang Wang, Zhe Gan, Zhengyuan Yang |  |
| 1487 |  |  [Human alignment of neural network representations](https://openreview.net/forum?id=ReDQ1OUQR0X) |  | 0 | Today’s computer vision models achieve human or near-human level performance across a wide variety of vision tasks. However, their architectures, data, and learning algorithms differ in numerous ways from those that give rise to human vision. In this paper, we investigate the factors that affect... | Jonas Dippel, Lorenz Linhardt, Lukas Muttenthaler, Robert A. Vandermeulen, Simon Kornblith |  |
| 1488 |  |  [Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States](https://openreview.net/forum?id=j3cUWIMsFBN) |  | 0 | Graph Neural Networks (GNNs) are widely used deep learning models that can extract meaningful representations from graph datasets and achieve great success in many machine learning tasks. Among them, graph neural networks with iterative iterations like unfolded GNNs and implicit GNNs can... | Mingjie Li, Yifei Wang, Yisen Wang, Zhouchen Lin |  |
| 1489 |  |  [DiGress: Discrete Denoising diffusion for graph generation](https://openreview.net/forum?id=UaAD-Nu86WX) |  | 0 | This work introduces DiGress, a discrete denoising diffusion model for generating graphs with categorical node and edge attributes. Our model utilizes a discrete diffusion process that progressively edits graphs with noise, through the process of adding or removing edges and changing the... | Antoine Siraudin, Bohan Wang, Clément Vignac, Igor Krawczuk, Pascal Frossard, Volkan Cevher |  |
| 1490 |  |  [How to prepare your task head for finetuning](https://openreview.net/forum?id=gVOXZproe-e) |  | 0 | In the era of deep learning, transferring information from a pretrained network to a downstream task by finetuning has many benefits. The choice of task head plays an important role in fine-tuning, as the pretrained and downstream tasks are usually different. Although there exist many different... | Danica J. Sutherland, Shangmin Guo, Wonho Bae, Yi Ren |  |
| 1491 |  |  [DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models](https://openreview.net/forum?id=jQj-_rLVXsj) |  | 0 | Recently, diffusion models have emerged as a new paradigm for generative models. Despite the success in domains using continuous signals such as vision and audio, adapting diffusion models to natural language is under-explored due to the discrete nature of texts, especially for conditional... | Jiangtao Feng, Lingpeng Kong, Mukai Li, Shansan Gong, Zhiyong Wu |  |
| 1492 |  |  [Policy Expansion for Bridging Offline-to-Online Reinforcement Learning](https://openreview.net/forum?id=-Y34L45JR6z) |  | 0 | Pre-training with offline data and online fine-tuning using reinforcement learning is a promising strategy for learning control policies by leveraging the best of both worlds in terms of sample efficiency and performance. One natural approach is to initialize the policy for online learning with the... | Haichao Zhang, Haonan Yu, Wei Xu |  |
| 1493 |  |  [Mitigating Memorization of Noisy Labels via Regularization between Representations](https://openreview.net/forum?id=6qcYDVlVLnK) |  | 0 | Designing robust loss functions is popular in learning with noisy labels while existing designs did not explicitly consider the overfitting property of deep neural networks (DNNs). As a result, applying these losses may still suffer from overfitting/memorizing noisy labels as training proceeds. In... | Hao Cheng, Xing Sun, Yang Liu, Zhaowei Zhu |  |
| 1494 |  |  [Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs](https://openreview.net/forum?id=dqnNW2omZL6) |  | 0 | Graph neural networks (GNNs), as the de-facto model class for representation learning on graphs, are built upon the multi-layer perceptrons (MLP) architecture with additional message passing layers to allow features to flow across nodes. While conventional wisdom commonly attributes the success of... | Chenxiao Yang, Jiahua Wang, Junchi Yan, Qitian Wu |  |
| 1495 |  |  [Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model](https://openreview.net/forum?id=Zob4P9bRNcK) |  | 0 | Cutting planes (cuts) are important for solving mixed-integer linear programs (MILPs), which formulate a wide range of important real-world applications. Cut selection---which aims to select a proper subset of the candidate cuts to improve the efficiency of solving MILPs---heavily depends on (P1)... | Feng Wu, Jia Zeng, Jie Wang, Mingxuan Yuan, Xijun Li, Yongdong Zhang, Yufei Kuang, Zhihai Wang |  |
| 1496 |  |  [BSTT: A Bayesian Spatial-Temporal Transformer for Sleep Staging](https://openreview.net/forum?id=ZxdkjTgK_Dl) |  | 0 | Sleep staging is helpful in assessing sleep quality and diagnosing sleep disorders. However, how to adequately capture the temporal and spatial relations of the brain during sleep remains a challenge. In particular, existing methods cannot adaptively infer spatial-temporal relations of the brain... | Yuchen Liu, Ziyu Jia |  |
| 1497 |  |  [Improving Deep Policy Gradients with Value Function Search](https://openreview.net/forum?id=6qZC7pfenQm) |  | 0 | Deep Policy Gradient (PG) algorithms employ value networks to drive the learning of parameterized policies and reduce the variance of the gradient estimates. However, value function approximation gets stuck in local optima and struggles to fit the actual return, limiting the variance reduction... | Christopher Amato, Enrico Marchesini |  |
| 1498 |  |  [MEDICAL IMAGE UNDERSTANDING WITH PRETRAINED VISION LANGUAGE MODELS: A COMPREHENSIVE STUDY](https://openreview.net/forum?id=txlWziuCE5W) |  | 0 | The large-scale pre-trained vision language models (VLM) have shown remarkable domain transfer capability on natural images. However, it remains unknown whether this capability can also apply to the medical image domain. This paper thoroughly studies the knowledge transferability of pre-trained... | Huahui Yi, Kang Li, Qicheng Lao, Ziyuan Qin |  |
| 1499 |  |  [Temporal Coherent Test Time Optimization for Robust Video Classification](https://openreview.net/forum?id=-t4D61w4zvQ) |  | 0 | Deep neural networks are likely to fail when the test data is corrupted in real-world deployment (e.g., blur, weather, etc.). Test-time optimization is an effective way that adapts models to generalize to corrupted data during testing, which has been shown in the image domain. However, the... | Alex C. Kot, Chenyu Yi, Haoliang Li, Siyuan Yang, YapPeng Tan, Yufei Wang |  |
| 1500 |  |  [A Learning Based Hypothesis Test for Harmful Covariate Shift](https://openreview.net/forum?id=rdfgqiwz7lZ) |  | 0 | The ability to quickly and accurately identify covariate shift at test time is a critical and often overlooked component of safe machine learning systems deployed in high-risk domains. While methods exist for detecting when predictions should not be made on out-of-distribution test examples,... | Rahul G. Krishnan, Tom Ginsberg, Zhongyuan Liang |  |
| 1501 |  |  [Deep Transformers without Shortcuts: Modifying Self-attention for Faithful Signal Propagation](https://openreview.net/forum?id=NPrsUQgMjKK) |  | 0 | Skip connections and normalisation layers form two standard architectural components that are ubiquitous for the training of Deep Neural Networks (DNNs), but whose precise roles are poorly understood. Recent approaches such as Deep Kernel Shaping have made progress towards reducing our reliance on... | Aleksandar Botev, Andrew Brock, Bobby He, Guodong Zhang, James Martens, Samuel L. Smith, Yee Whye Teh |  |
| 1502 |  |  [Self-Supervised Geometric Correspondence for Category-Level 6D Object Pose Estimation in the Wild](https://openreview.net/forum?id=ZKDUlVMqG_O) |  | 0 | While 6D object pose estimation has wide applications across computer vision and robotics, it remains far from being solved due to the lack of annotations. The problem becomes even more challenging when moving to category-level 6D pose, which requires generalization to unseen instances. Current... | Fatih Porikli, Hong Cai, Kaifeng Zhang, Shubhankar Borse, Xiaolong Wang, Yang Fu |  |
| 1503 |  |  [Non-parametric Outlier Synthesis](https://openreview.net/forum?id=JHklpEZqduQ) |  | 0 | Out-of-distribution (OOD) detection is indispensable for safely deploying machine learning models in the wild. One of the key challenges is that models lack supervision signals from unknown data, and as a result, can produce overconfident predictions on OOD data. Recent work on outlier synthesis... | Jerry Zhu, Leitian Tao, Xuefeng Du, Yixuan Li |  |
| 1504 |  |  [Approximation and non-parametric estimation of functions over high-dimensional spheres via deep ReLU networks](https://openreview.net/forum?id=r90KYcuB7JS) |  | 0 | We develop a new approximation and estimation analysis of deep feed-forward neural networks (FNNs) with the Rectified Linear Unit (ReLU) activation. The functions of interests for the approximation and estimation are assumed to be from Sobolev spaces defined over the $d$-dimensional unit sphere... | Namjoon Suh, TianYi Zhou, Xiaoming Huo |  |
| 1505 |  |  [Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition](https://openreview.net/forum?id=sVU54nyaA9K) |  | 0 | We study reinforcement learning (RL) with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting. Specifically, the unknown transition probability function is a linear mixture model \citep{AyoubJSWY20,ZhouGS21,HeZG22} with a given feature mapping,... | Baoxiang Wang, Canzhe Zhao, Ruofeng Yang, Shuai Li |  |
| 1506 |  |  [Weakly Supervised Knowledge Transfer with Probabilistic Logical Reasoning for Object Detection](https://openreview.net/forum?id=4yqxDCbzS98) |  | 0 | Training object detection models usually requires instance-level annotations, such as the positions and labels of all objects present in each image. Such supervision is unfortunately not always available and, more often, only image-level information is provided, also known as weak supervision.... | Adam Arany, Edward De Brouwer, Martijn Oldenhof, Yves Moreau |  |
| 1507 |  |  [A Neural Mean Embedding Approach for Back-door and Front-door Adjustment](https://openreview.net/forum?id=rLguqxYvYHB) |  | 0 | We consider the estimation of average and counterfactual treatment effects, under two settings: back-door adjustment and front-door adjustment. The goal in both cases is to recover the treatment effect without having an access to a hidden confounder. This objective is attained by first estimating... | Arthur Gretton, Liyuan Xu |  |
| 1508 |  |  [TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation](https://openreview.net/forum?id=UVAmFAtC5ye) |  | 0 | Direct speech-to-speech translation (S2ST) with discrete units leverages recent progress in speech representation learning. Specifically, a sequence of discrete representations derived in a self-supervised manner are predicted from the model and passed to a vocoder for speech reconstruction, while... | Huadai Liu, Jinglin Liu, Jinzheng He, Lichao Zhang, Rongjie Huang, Yi Ren, Zhou Zhao |  |
| 1509 |  |  [Over-parameterized Model Optimization with Polyak-Łojasiewicz Condition](https://openreview.net/forum?id=aBIpZvMdS56) |  | 0 | This work pursues the optimization of over-parameterized deep models for superior training efficiency and test performance. We first theoretically emphasize the importance of two properties of over-parameterized models, i.e., the convergence gap and the generalization gap. Subsequent analyses... | Dongsheng Li, Fan Yang, Li Shang, Mingzhi Dong, Ning Gu, Qin Lv, Robert P. Dick, Xiaochen Yang, Yingying Zhao, Yixuan Chen, Yubin Shi, Yujiang Wang |  |
| 1510 |  |  [Jointly Learning Visual and Auditory Speech Representations from Raw Data](https://openreview.net/forum?id=BPwIgvf5iQ) |  | 0 | We present RAVEn, a self-supervised multi-modal approach to jointly learn visual and auditory speech representations. Our pre-training objective involves encoding masked inputs, and then predicting contextualised targets generated by slowly-evolving momentum encoders. Driven by the inherent... | Alexandros Haliassos, Maja Pantic, Pingchuan Ma, Rodrigo Mira, Stavros Petridis |  |
| 1511 |  |  [Diminishing Return of Value Expansion Methods in Model-Based Reinforcement Learning](https://openreview.net/forum?id=H4Ncs5jhTCu) |  | 0 | Model-based reinforcement learning is one approach to increase sample efficiency. However, the accuracy of the dynamics model and the resulting compounding error over modelled trajectories are commonly regarded as key limitations. A natural question to ask is: How much more sample efficiency can be... | Daniel Palenicek, Jan Peters, Joao Carvalho, Michael Lutter |  |
| 1512 |  |  [CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Alignment](https://openreview.net/forum?id=GNjzMAgawq) |  | 0 | Pre-trained image-text models, like CLIP, have demonstrated the strong power of vision-language representation learned from a large scale of web-collected image-text data. In light of the well-learned visual features, there are works that transfer image representation to the video domain and... | Bei Liu, Hongwei Xue, Houqiang Li, Jianlong Fu, Jiebo Luo, Ruihua Song, Yuchong Sun |  |
| 1513 |  |  [Equivariant Energy-Guided SDE for Inverse Molecular Design](https://openreview.net/forum?id=r0otLtOwYW) |  | 0 | Inverse molecular design is critical in material science and drug discovery, where the generated molecules should satisfy certain desirable properties. In this paper, we propose equivariant energy-guided stochastic differential equations (EEGSDE), a flexible framework for controllable 3D molecule... | Chongxuan Li, Fan Bao, Jun Zhu, Min Zhao, Peiyao Li, Zhongkai Hao |  |
| 1514 |  |  [On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning](https://openreview.net/forum?id=KB1sc5pNKFv) |  | 0 | Reinforcement Learning (RL) algorithms can solve challenging control problems directly from image observations, but they often require millions of environment interactions to do so. Recently, model-based RL algorithms have greatly improved sample-efficiency by concurrently learning an internal... | Hao Su, Nicklas Hansen, Yifan Xu, YungChieh Chan, Zhuowen Tu, Zirui Wang |  |
| 1515 |  |  [A Simple Yet Powerful Deep Active Learning With Snapshots Ensembles](https://openreview.net/forum?id=IVESH65r0Ar) |  | 0 | Given an unlabeled pool of data and the experts who can label them, active learning aims to build an agent that can effectively acquire data to be queried to the experts, maximizing the gain in performance when trained with them. While there are several principles for active learning, a prevailing... | Juho Lee, Sanghyun Kim, Seohyeon Jung |  |
| 1516 |  |  [Decoupled Training for Long-Tailed Classification With Stochastic Representations](https://openreview.net/forum?id=bcYZwYo-0t) |  | 0 | Decoupling representation learning and classifier learning has been shown to be effective in classification with long-tailed data. There are two main ingredients in constructing a decoupled learning scheme; 1) how to train the feature extractor for representation learning so that it provides... | Giung Nam, Juho Lee, Sunguk Jang |  |
| 1517 |  |  [ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency](https://openreview.net/forum?id=2XLRBjY46O6) |  | 0 | Recently, great success has been made in learning visual representations from text supervision, facilitating the emergence of text-supervised semantic segmentation. However, existing works focus on pixel grouping and cross-modal semantic alignment, while ignoring the correspondence among multiple... | Changlin Li, Guangrun Wang, Hang Xu, Jianzhuang Liu, Pengzhen Ren, Xiaodan Liang, Xiaojun Chang, Yi Zhu |  |
| 1518 |  |  [Benchmarking Constraint Inference in Inverse Reinforcement Learning](https://openreview.net/forum?id=vINj_Hv9szL) |  | 0 | When deploying Reinforcement Learning (RL) agents into a physical system, we must ensure that these agents are well aware of the underlying constraints. In many real-world problems, however, the constraints are often hard to specify mathematically and unknown to the RL agents. To tackle these... | Ashish Gaurav, Guiliang Liu, Kasra Rezaee, Pascal Poupart, Yudong Luo |  |
| 1519 |  |  [Memory Gym: Partially Observable Challenges to Memory-Based Agents](https://openreview.net/forum?id=jHc8dCx6DDr) |  | 0 | Memory Gym is a novel benchmark for challenging Deep Reinforcement Learning agents to memorize events across long sequences, be robust to noise, and generalize. It consists of the partially observable 2D and discrete control environments Mortar Mayhem, Mystery Path, and Searing Spotlights. These... | Frank Zimmer, Marco Pleines, Matthias Pallasch, Mike Preuss |  |
| 1520 |  |  [Discovering Policies with DOMiNO: Diversity Optimization Maintaining Near Optimality](https://openreview.net/forum?id=kjkdzBW3b8p) |  | 0 | In this work we propose a Reinforcement Learning (RL) agent that can discover complex behaviours in a rich environment with a simple reward function. We define diversity in terms of state-action occupancy measures, since policies with different occupancy measures visit different states on average.... | Feryal M. P. Behbahani, Kate Baumli, Satinder Singh, Sebastian Flennerhag, Shaobo Hou, Tom Zahavy, Yannick Schroecker |  |
| 1521 |  |  [SpeedyZero: Mastering Atari with Limited Data and Time](https://openreview.net/forum?id=Mg5CLXZgvLJ) |  | 0 | Many recent breakthroughs of deep reinforcement learning (RL) are mainly built upon large-scale distributed training of model-free methods using millions to billions of samples. On the other hand, state-of-the-art model-based RL methods can achieve human-level sample efficiency but often take a... | Jiaxuan Gao, Shaohuai Liu, Weirui Ye, Yang Gao, Yi Wu, Yixuan Mei |  |
| 1522 |  |  [Neural Architecture Design and Robustness: A Dataset](https://openreview.net/forum?id=p8coElqiSDw) |  | 0 | Deep learning models have proven to be successful in a wide range of machine learning tasks. Yet, they are often highly sensitive to perturbations on the input data which can lead to incorrect decisions with high confidence, hampering their deployment for practical use-cases. Thus, finding... | Jovita Lukasik, Margret Keuper, Steffen Jung |  |
| 1523 |  |  [Does Deep Learning Learn to Abstract? A Systematic Probing Framework](https://openreview.net/forum?id=QB1dMPEXau5) |  | 0 | Abstraction is a desirable capability for deep learning models, which means to induce abstract concepts from concrete instances and flexibly apply them beyond the learning context. At the same time, there is a lack of clear understanding about both the presence and further characteristics of this... | Bei Chen, JianGuang Lou, Nanning Zheng, Qiang Fu, Shengnan An, Zeqi Lin |  |
| 1524 |  |  [Improving Out-of-distribution Generalization with Indirection Representations](https://openreview.net/forum?id=0f-0I6RFAch) |  | 0 | We propose a generic module named Indirection Layer (InLay), which leverages indirection and data internal relationships to effectively construct symbolic indirect representations to improve out-of-distribution generalization capabilities of various neural architectures. InLay receives data input... | Hung Le, Kha Pham, Man Ngo, Truyen Tran |  |
| 1525 |  |  [Accelerating Guided Diffusion Sampling with Splitting Numerical Methods](https://openreview.net/forum?id=F0KTk2plQzO) |  | 0 | Guided diffusion is a technique for conditioning the output of a diffusion model at sampling time without retraining the network for each specific task. However, one drawback of diffusion models, whether they are guided or unguided, is their slow sampling process. Recent techniques can accelerate... | Supasorn Suwajanakorn, Suttisak Wizadwongsa |  |
| 1526 |  |  [Batch Multivalid Conformal Prediction](https://openreview.net/forum?id=Dk7QQp8jHEo) |  | 0 | We develop fast distribution-free conformal prediction algorithms for obtaining multivalid coverage on exchangeable data in the batch setting. Multivalid coverage guarantees are stronger than marginal coverage guarantees in two ways: (1) They hold even conditional on group membership---that is, the... | Aaron Roth, Christopher Jung, Georgy Noarov, Ramya Ramalingam |  |
| 1527 |  |  [Accurate Bayesian Meta-Learning by Accurate Task Posterior Inference](https://openreview.net/forum?id=sb-IkS8DQw2) |  | 0 | Bayesian meta-learning (BML) enables fitting expressive generative models to small datasets by incorporating inductive priors learned from a set of related tasks. The Neural Process (NP) is a prominent deep neural network-based BML architecture, which has shown remarkable results in recent years.... | Christian Daniel, Gerhard Neumann, Michael Volpp, Philipp Becker, Philipp Dahlinger |  |
| 1528 |  |  [Learning to Decompose Visual Features with Latent Textual Prompts](https://openreview.net/forum?id=wtcud6HroZr) |  | 0 | Recent advances in pre-training vision-language models like CLIP have shown great potential in learning transferable visual representations. Nonetheless, for downstream inference, CLIP-like models suffer from either 1) degraded accuracy and robustness in the case of inaccurate text descriptions... | Alexander G. Schwing, Feng Wang, Hairong Lv, Heng Ji, Manling Li, Xudong Lin |  |
| 1529 |  |  [Context-enriched molecule representations improve few-shot drug discovery](https://openreview.net/forum?id=XrMWUuEevr) |  | 0 | A central task in computational drug discovery is to construct models from known active molecules to find further promising molecules for subsequent screening. However, typically only very few active molecules are known. Therefore, few-shot learning methods have the potential to improve the... | Daniel Kuhn, Friedrich Rippmann, Günter Klambauer, Johannes Schimunek, Lukas Friedrich, Philipp Seidl, Sepp Hochreiter |  |
| 1530 |  |  [Test-Time Adaptation via Self-Training with Nearest Neighbor Information](https://openreview.net/forum?id=EzLtB4M1SbM) |  | 0 | Test-time adaptation (TTA) aims to adapt a trained classifier using online unlabeled test data only, without any information related to the training procedure. Most existing TTA methods adapt the trained classifier using the classifier's prediction on the test data as pseudo-label. However, under... | Hye Won Chung, Minguk Jang, SaeYoung Chung |  |
| 1531 |  |  [Accurate Neural Training with 4-bit Matrix Multiplications at Standard Formats](https://openreview.net/forum?id=yTbNYYcopd) |  | 0 | Quantization of the weights and activations is one of the main methods to reduce the computational footprint of Deep Neural Networks (DNNs) training. Current methods enable 4-bit quantization of the forward phase. However, this constitutes only a third of the training process. Reducing the... | Brian Chmiel, Daniel Soudry, Elad Hoffer, Hilla BenYaacov, Ron Banner |  |
| 1532 |  |  [Unsupervised Manifold Alignment with Joint Multidimensional Scaling](https://openreview.net/forum?id=lUpjsrKItz4) |  | 0 | We introduce Joint Multidimensional Scaling, a novel approach for unsupervised manifold alignment, which maps datasets from two different domains, without any known correspondences between data instances across the datasets, to a common low-dimensional Euclidean space. Our approach integrates... | Bowen Fan, Carlos G. Oliver, Dexiong Chen, Karsten M. Borgwardt |  |
| 1533 |  |  [Simple and Scalable Nearest Neighbor Machine Translation](https://openreview.net/forum?id=uu1GBD9SlLe) |  | 0 | $k$NN-MT is a straightforward yet powerful approach for fast domain adaptation, which directly plugs the pre-trained neural machine translation (NMT) models with domain-specific token-level $k$-nearest-neighbor ($k$NN) retrieval to achieve domain adaptation without retraining. Despite being... | Qiuzhi Liu, Qu Cui, Tong Xu, Weihua Li, Yichao Du, Yuhan Dai, Zhirui Zhang |  |
| 1534 |  |  [On the Effectiveness of Out-of-Distribution Data in Self-Supervised Long-Tail Learning](https://openreview.net/forum?id=v8JIQdiN9Sh) |  | 0 | Though Self-supervised learning (SSL) has been widely studied as a promising technique for representation learning, it doesn't generalize well on long-tailed datasets due to the majority classes dominating the feature space. Recent work shows that the long-tailed learning performance could be... | Haoji Hu, Hualiang Wang, Huanpeng Chu, Jianhong Bai, Jin Hao, Yang Feng, Zuozhu Liu |  |
| 1535 |  |  [Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting](https://openreview.net/forum?id=ZIkHSXzd9O7) |  | 0 | Early stopping based on the validation set performance is a popular approach to find the right balance between under- and overfitting in the context of supervised learning. However, in reinforcement learning, even for supervised sub-problems such as world model learning, early stopping is not... | Nicolai Dorka, Tim Welschehold, Wolfram Burgard |  |
| 1536 |  |  [Uni-Mol: A Universal 3D Molecular Representation Learning Framework](https://openreview.net/forum?id=6K2RM6wVqKu) |  | 0 | Molecular representation learning (MRL) has gained tremendous attention due to its critical role in learning from limited supervised data for applications like drug design. In most MRL methods, molecules are treated as 1D sequential tokens or 2D topology graphs, limiting their ability to... | Gengmo Zhou, Guolin Ke, Hang Zheng, Hongteng Xu, Linfeng Zhang, Qiankun Ding, Zhewei Wei, Zhifeng Gao |  |
| 1537 |  |  [Learning with Auxiliary Activation for Memory-Efficient Training](https://openreview.net/forum?id=YgC62m4CY3r) |  | 0 | While deep learning has achieved great success in various fields, a large amount of memory is necessary to train deep neural networks, which hinders the development of massive state-of-the-art models. The reason is the conventional learning rule, backpropagation, should temporarily store input... | Dongsuk Jeon, Sunghyeon Woo |  |
| 1538 |  |  [Massively Scaling Heteroscedastic Classifiers](https://openreview.net/forum?id=sIoED-yPK9l) |  | 0 | Heteroscedastic classifiers, which learn a multivariate Gaussian distribution over prediction logits, have been shown to perform well on image classification problems with hundreds to thousands of classes. However, compared to standard classifiers, they introduce extra parameters that scale... | Basil Mustafa, Effrosyni Kokiopoulou, Jesse Berent, Mark Collier, Neil Houlsby, Rodolphe Jenatton |  |
| 1539 |  |  [KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Low-Resource NLP](https://openreview.net/forum?id=2nocgE1m0A) |  | 0 | This paper focuses on data augmentation for low-resource NLP tasks where the training set is limited. The existing solutions either leverage task-independent heuristic rules (e.g., Synonym Replacement) or fine-tune general-purpose pre-trained language models (e.g., GPT2) using the limited training... | Can Xu, Chongyang Tao, Daxin Jiang, Jiayi Zheng, Tao Shen, Xiubo Geng, Yufei Wang |  |
| 1540 |  |  [Finding the Global Semantic Representation in GAN through Fréchet Mean](https://openreview.net/forum?id=9ImtNIZ7bYx) |  | 0 | The ideally disentangled latent space in GAN involves the global representation of latent space using semantic attribute coordinates. In other words, in this disentangled space, there exists the global semantic basis as a vector space where each basis component describes one attribute of generated... | Geonho Hwang, Hyunsoo Cho, Jaewoong Choi, Myungjoo Kang |  |
| 1541 |  |  [MultiViz: Towards Visualizing and Understanding Multimodal Models](https://openreview.net/forum?id=i2_TvOFmEml) |  | 0 | The promise of multimodal models for real-world applications has inspired research in visualizing and understanding their internal mechanics with the end goal of empowering stakeholders to visualize model behavior, perform model debugging, and promote trust in machine learning models. However,... | Gunjan Chhablani, LouisPhilippe Morency, Nihal Jain, Paul Pu Liang, Ruslan Salakhutdinov, Xingbo Wang, Yiwei Lyu, Zihao Deng |  |
| 1542 |  |  [How Informative is the Approximation Error from Tensor Decomposition for Neural Network Compression?](https://openreview.net/forum?id=sKHqgFOaFXI) |  | 0 | Tensor decompositions have been successfully applied to compress neural networks. The compression algorithms using tensor decompositions commonly minimize the approximation error on the weights. Recent work assumes the approximation error on the weights is a proxy for the performance of the model... | Jetze Schuurmans, Julian F. P. Kooij, Kim Batselier |  |
| 1543 |  |  [Blurring Diffusion Models](https://openreview.net/forum?id=OjDkC57x5sz) |  | 0 | Recently, Rissanen et al., (2022) have presented a new type of diffusion process for generative modeling based on heat dissipation, or blurring, as an alternative to isotropic Gaussian diffusion. Here, we show that blurring can equivalently be defined through a Gaussian diffusion process with... | Emiel Hoogeboom, Tim Salimans |  |
| 1544 |  |  [Hyperbolic Self-paced Learning for Self-supervised Skeleton-based Action Representations](https://openreview.net/forum?id=3Bh6sRPKS3J) |  | 0 | Self-paced learning has been beneficial for tasks where some initial knowledge is available, such as weakly supervised learning and domain adaptation, to select and order the training sample sequence, from easy to complex. However its applicability remains unexplored in unsupervised learning,... | Bharti Munjal, Fabio Galasso, Luca Franco, Paolo Mandica |  |
| 1545 |  |  [Efficient Offline Policy Optimization with a Learned Model](https://openreview.net/forum?id=Yt-yM-JbYFO) |  | 0 | MuZero Unplugged presents a promising approach for offline policy learning from logged data. It conducts Monte-Carlo Tree Search (MCTS) with a learned model and leverages Reanalyze algorithm to learn purely from offline data. For good performance, MCTS requires accurate learned models and a large... | Shuicheng Yan, Siyi Li, Wee Sun Lee, Zhongwen Xu, Zichen Liu |  |
| 1546 |  |  [New Insights for the Stability-Plasticity Dilemma in Online Continual Learning](https://openreview.net/forum?id=fxC7kJYwA_a) |  | 0 | The aim of continual learning is to learn new tasks continuously (i.e., plasticity) without forgetting previously learned knowledge from old tasks (i.e., stability). In the scenario of online continual learning, wherein data comes strictly in a streaming manner, the plasticity of online continual... | Dahuin Jung, Dongjin Lee, Ho Bae, Hyemi Jang, Sungroh Yoon, Sunwon Hong |  |
| 1547 |  |  [MixPro: Data Augmentation with MaskMix and Progressive Attention Labeling for Vision Transformer](https://openreview.net/forum?id=dRjWsd3gwsm) |  | 0 | The recently proposed data augmentation TransMix employs attention labels to help visual transformers (ViT) achieve better robustness and performance. However, TransMix is deficient in two aspects: 1) The image cropping method of TransMix may not be suitable for vision transformer. 2) At the early... | Fan Zhang, Jun Liu, Qihao Zhao, Wei Hu, Yangyu Huang |  |
| 1548 |  |  [StyleMorph: Disentangled 3D-Aware Image Synthesis with a 3D Morphable StyleGAN](https://openreview.net/forum?id=Ojpb1y8jflw) |  | 0 | We introduce StyleMorph, a 3D-aware generative model that disentangles 3D shape, camera pose, object appearance, and background appearance for high quality image synthesis. We account for shape variability by morphing a canonical 3D object template, effectively learning a 3D morphable model in an... | Edward Bartrum, EricTuan Le, Iasonas Kokkinos |  |
| 1549 |  |  [Searching Lottery Tickets in Graph Neural Networks: A Dual Perspective](https://openreview.net/forum?id=Dvs-a3aymPe) |  | 0 | Graph Neural Networks (GNNs) have shown great promise in various graph learning tasks. However, the computational overheads of fitting GNNs to large-scale graphs grow rapidly, posing obstacles to GNNs from scaling up to real-world applications. To tackle this issue, Graph Lottery Ticket (GLT)... | Junfeng Fang, Kun Wang, Pengfei Gu, Pengkun Wang, Xu Wang, Yang Wang, Yuxuan Liang |  |
| 1550 |  |  [Video Scene Graph Generation from Single-Frame Weak Supervision](https://openreview.net/forum?id=KLrGlNoxzb4) |  | 0 | Video scene graph generation (VidSGG) aims to generate a sequence of graph-structure representations for the given video. However, all existing VidSGG methods are fully-supervised, i.e., they need dense and costly manual annotations. In this paper, we propose the first weakly-supervised VidSGG task... | Jun Xiao, Long Chen, Siqi Chen |  |
| 1551 |  |  [Unsupervised visualization of image datasets using contrastive learning](https://openreview.net/forum?id=nI2HmVA0hvt) |  | 0 | Visualization methods based on the nearest neighbor graph, such as t-SNE or UMAP, are widely used for visualizing high-dimensional data. Yet, these approaches only produce meaningful results if the nearest neighbors themselves are meaningful. For images represented in pixel space this is not the... | Dmitry Kobak, Jan Niklas Böhm, Philipp Berens |  |
| 1552 |  |  [PowerQuant: Automorphism Search for Non-Uniform Quantization](https://openreview.net/forum?id=s1KljJpAukm) |  | 0 | Deep neural networks (DNNs) are nowadays ubiquitous in many domains such as computer vision. However, due to their high latency, the deployment of DNNs hinges on the development of compression techniques such as quantization which consists in lowering the number of bits used to encode the weights... | Arnaud Dapogny, Edouard Yvinec, Kevin Bailly, Matthieu Cord |  |
| 1553 |  |  [Bayes Risk CTC: Controllable CTC Alignment in Sequence-to-Sequence Tasks](https://openreview.net/forum?id=Bd7GueaTxUz) |  | 0 | Sequence-to-Sequence (seq2seq) tasks transcribe the input sequence to a target sequence. The Connectionist Temporal Classification (CTC) criterion is widely used in multiple seq2seq tasks. Besides predicting the target sequence, a side product of CTC is to predict the alignment, which is the most... | Brian Yan, Chao Weng, Dong Yu, Jianwei Yu, Jinchuan Tian, Shinji Watanabe |  |
| 1554 |  |  [A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein in Graph Data](https://openreview.net/forum?id=0jxPyVWmiiF) |  | 0 | In this work, we present the Bregman Alternating Projected Gradient (BAPG) method, a single-loop algorithm that offers an approximate solution to the Gromov-Wasserstein (GW) distance. We introduce a novel relaxation technique that balances accuracy and computational efficiency, albeit with some... | Anthony ManCho So, Huikang Liu, Jia Li, Jiajin Li, Jianheng Tang, Jose H. Blanchet, Lemin Kong |  |
| 1555 |  |  [Semi-supervised learning with a principled likelihood from a generative model of data curation](https://openreview.net/forum?id=zOHQGKO3WGY) |  | 0 | We currently do not have an understanding of semi-supervised learning (SSL) objectives such as pseudo-labelling and entropy minimization as log-likelihoods, which precludes the development of e.g. Bayesian SSL. Here, we note that benchmark image datasets such as CIFAR-10 are carefully curated, and... | Laurence Aitchison, Stoil Ganev |  |
| 1556 |  |  [E3Bind: An End-to-End Equivariant Network for Protein-Ligand Docking](https://openreview.net/forum?id=sO1QiAftQFv) |  | 0 | In silico prediction of the ligand binding pose to a given protein target is a crucial but challenging task in drug discovery. This work focuses on blind flexible self-docking, where we aim to predict the positions, orientations and conformations of docked molecules. Traditional physics-based... | Chence Shi, Huiyu Cai, Jian Tang, Yangtian Zhang |  |
| 1557 |  |  [Re-weighting Based Group Fairness Regularization via Classwise Robust Optimization](https://openreview.net/forum?id=Q-WfHzmiG9m) |  | 0 | Many existing group fairness-aware training methods aim to achieve the group fairness by either re-weighting underrepresented groups based on certain rules or using weakly approximated surrogates for the fairness metrics in the objective as regularization terms. Although each of the learning... | Sanghyuk Chun, Sangwon Jung, Taeeon Park, Taesup Moon |  |
| 1558 |  |  [Are More Layers Beneficial to Graph Transformers?](https://openreview.net/forum?id=uagC-X9XMi8) |  | 0 | Despite that going deep has proven successful in many neural architectures, the existing graph transformers are relatively shallow. In this work, we explore whether more layers are beneficial to graph transformers, and find that current graph transformers suffer from the bottleneck of improving... | Dongdong Zhang, Furu Wei, Haiteng Zhao, Shuming Ma, ZhiHong Deng |  |
| 1559 |  |  [Simplicial Hopfield networks](https://openreview.net/forum?id=_QLsH8gatwx) |  | 0 | Hopfield networks are artificial neural networks which store memory patterns on the states of their neurons by choosing recurrent connection weights and update rules such that the energy landscape of the network forms attractors around the memories. How many stable, sufficiently-attracting memory... | Thomas F. Burns, Tomoki Fukai |  |
| 1560 |  |  [Versatile Neural Processes for Learning Implicit Neural Representations](https://openreview.net/forum?id=2nLeOOfAjK) |  | 0 | Representing a signal as a continuous function parameterized by neural network (a.k.a. Implicit Neural Representations, INRs) has attracted increasing attention in recent years. Neural Processes (NPs), which model the distributions over functions conditioned on partial observations (context set),... | Cuiling Lan, Yan Lu, Zhibo Chen, Zhizheng Zhang, Zongyu Guo |  |
| 1561 |  |  [Classically Approximating Variational Quantum Machine Learning with Random Fourier Features](https://openreview.net/forum?id=ymFhZxw70uz) |  | 0 | Many applications of quantum computing in the near term rely on variational quantum circuits (VQCs). They have been showcased as a promising model for reaching a quantum advantage in machine learning with current noisy intermediate scale quantum computers (NISQ). It is often believed that the power... | Constantin Dalyac, Elham Kashefi, Hela Mhiri, Jonas Landman, Slimane Thabet |  |
| 1562 |  |  [Distributional Meta-Gradient Reinforcement Learning](https://openreview.net/forum?id=LGkmUauBUL) |  | 0 | Meta-gradient reinforcement learning (RL) algorithms have substantially boosted the performance of RL agents by learning an adaptive return. All the existing algorithms adhere to the same reward learning principle, where the adaptive return is simply formulated in the form of expected cumulative... | Haiyan Yin, Shuicheng Yan, Zhongwen Xu |  |
| 1563 |  |  [A Differential Geometric View and Explainability of GNN on Evolving Graphs](https://openreview.net/forum?id=lRdhvzMpVYV) |  | 0 | Graphs are ubiquitous in social networks and biochemistry, where Graph Neural Networks (GNN) are the state-of-the-art models for prediction. Graphs can be evolving and it is vital to formally model and understand how a trained GNN responds to graph evolution. We propose a smooth parameterization of... | Sihong Xie, Xi Zhang, Yazheng Liu |  |
| 1564 |  |  [$\rm A^2Q$: Aggregation-Aware Quantization for Graph Neural Networks](https://openreview.net/forum?id=7L2mgi0TNEP) |  | 0 | As graph data size increases, the vast latency and memory consumption during inference pose a significant challenge to the real-world deployment of Graph Neural Networks (GNNs). While quantization is a powerful approach to reducing GNNs complexity, most previous works on GNNs quantization fail to... | Fanrong Li, Gang Li, Jian Cheng, Qinghao Hu, Xiaoyao Liang, Zejian Liu, Zeyu Zhu, Zitao Mo |  |
| 1565 |  |  [Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression as a Cherry on the Top](https://openreview.net/forum?id=pfuqQQCB34) |  | 0 | Byzantine-robustness has been gaining a lot of attention due to the growth of the interest in collaborative and federated learning. However, many fruitful directions, such as the usage of variance reduction for achieving robustness and communication compression for reducing communication costs,... | Eduard Gorbunov, Gauthier Gidel, Peter Richtárik, Samuel Horváth |  |
| 1566 |  |  [Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning](https://openreview.net/forum?id=Nk2pDtuhTq) |  | 0 | Prompt tuning, in which a base pretrained model is adapted to each task via conditioning on learned prompt vectors, has emerged as a promising approach for efficiently adapting large language models to multiple downstream tasks. However, existing methods typically learn soft prompt vectors from... | Huan Sun, Leonid Karlinsky, Rameswar Panda, Rogério Feris, Yoon Kim, Zhen Wang |  |
| 1567 |  |  [Better Generative Replay for Continual Federated Learning](https://openreview.net/forum?id=cRxYWKiTan) |  | 0 | Federated Learning (FL) aims to develop a centralized server that learns from distributed clients via communications without accessing the clients’ local data. However, existing works mainly focus on federated learning in a single task sce- nario with static data. In this paper, we introduce the... | Daiqing Qi, Handong Zhao, Sheng Li |  |
| 1568 |  |  [Generative Modelling with Inverse Heat Dissipation](https://openreview.net/forum?id=4PJUBT9f2Ol) |  | 0 | While diffusion models have shown great success in image generation, their noise-inverting generative process does not explicitly consider the structure of images, such as their inherent multi-scale nature. Inspired by diffusion models and the empirical success of coarse-to-fine modelling, we... | Arno Solin, Markus Heinonen, Severi Rissanen |  |
| 1569 |  |  [Self-supervision through Random Segments with Autoregressive Coding (RandSAC)](https://openreview.net/forum?id=Ubc74gTVo3) |  | 0 | Inspired by the success of self-supervised autoregressive representation learning in natural language (GPT and its variants), and advances in recent visual architecture design with Vision Transformers (ViTs), in this paper, we explore the effects various design choices have on the success of... | Hang Zhao, Leonid Sigal, Michalis Raptis, Sucheng Ren, Tianyu Hua, Yonglong Tian |  |
| 1570 |  |  [Transformer-Patcher: One Mistake Worth One Neuron](https://openreview.net/forum?id=4oYUGeGBPm) |  | 0 | Large Transformer-based Pretrained Language Models (PLMs) dominate almost all Natural Language Processing (NLP) tasks. Nevertheless, they still make mistakes from time to time. For a model deployed in an industrial environment, fixing these mistakes quickly and robustly is vital to improve user... | Jie Zhou, Wenge Rong, Xiaofeng Zhang, Yikang Shen, Zeyu Huang, Zhang Xiong |  |
| 1571 |  |  [Sharper Bounds for Uniformly Stable Algorithms with Stationary Mixing Process](https://openreview.net/forum?id=8E5Yazboyh) |  | 0 | Generalization analysis of learning algorithms often builds on a critical assumption that training examples are independently and identically distributed, which is often violated in practical problems such as time series prediction. In this paper, we use algorithmic stability to study the... | Dacheng Tao, Qiong Cao, Shi Fu, Xinmei Tian, Yunwen Lei |  |
| 1572 |  |  [Benign Overfitting in Classification: Provably Counter Label Noise with Larger Models](https://openreview.net/forum?id=UrEwJebCxk) |  | 0 | Studies on benign overfitting provide insights for the success of overparameterized deep learning models. In this work, we examine whether overfitting is truly benign in real-world classification tasks. We start with the observation that a ResNet model overfits benignly on Cifar10 but not benignly... | Jiaye Teng, Jingzhao Zhang, Kaiyue Wen |  |
| 1573 |  |  [Predictive Inference with Feature Conformal Prediction](https://openreview.net/forum?id=0uRm1YmFTu) |  | 0 | Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of... | Chuan Wen, Dinghuai Zhang, Jiaye Teng, Yang Gao, Yang Yuan, Yoshua Bengio |  |
| 1574 |  |  [Recon: Reducing Conflicting Gradients From the Root For Multi-Task Learning](https://openreview.net/forum?id=ivwZO-HnzG_) |  | 0 | A fundamental challenge for multi-task learning is that different tasks may conflict with each other when they are solved jointly, and a cause of this phenomenon is conflicting gradients during optimization. Recent works attempt to mitigate the influence of conflicting gradients by directly... | Guangyuan Shi, Jiaxin Chen, Qimai Li, Wenlong Zhang, XiaoMing Wu |  |
| 1575 |  |  [Measure the Predictive Heterogeneity](https://openreview.net/forum?id=g2oB_k-18b) |  | 0 | As an intrinsic and fundamental property of big data, data heterogeneity exists in a variety of real-world applications, such as in agriculture, sociology, health care, etc. For machine learning algorithms, the ignorance of data heterogeneity will significantly hurt the generalization performance... | Bo Li, Jiashuo Liu, Jiayun Wu, Peng Cui, Renjie Pi, Renzhe Xu, Xingxuan Zhang |  |
| 1576 |  |  [Time to augment self-supervised visual representation learning](https://openreview.net/forum?id=o8xdgmwCP8l) |  | 0 | Biological vision systems are unparalleled in their ability to learn visual representations without supervision. In machine learning, self-supervised learning (SSL) has led to major advances in forming object representations in an unsupervised fashion. Such systems learn representations invariant... | Arthur Aubret, Céline Teulière, Jochen Triesch, Markus Roland Ernst |  |
| 1577 |  |  [Towards Lightweight, Model-Agnostic and Diversity-Aware Active Anomaly Detection](https://openreview.net/forum?id=-vKlt84fHs) |  | 0 | Active Anomaly Discovery (AAD) is flourishing in the anomaly detection research area, which aims to incorporate analysts’ feedback into unsupervised anomaly detectors. However, existing AAD approaches usually prioritize the samples with the highest anomaly scores for user labeling, which hinders... | Dongmei Zhang, Liqun Li, Qingwei Lin, Saravan Rajmohan, Shilin He, Xu Zhang, Yingnong Dang, Yuan Zhao, Ziang Cui |  |
| 1578 |  |  [Q-Pensieve: Boosting Sample Efficiency of Multi-Objective RL Through Memory Sharing of Q-Snapshots](https://openreview.net/forum?id=AwWaBXLIJE) |  | 0 | Many real-world continuous control problems are in the dilemma of weighing the pros and cons, multi-objective reinforcement learning (MORL) serves as a generic framework of learning control policies for different preferences over objectives. However, the existing MORL methods either rely on... | BoKai Huang, PingChun Hsieh, Wei Hung, Xi Liu |  |
| 1579 |  |  [Variance-Aware Sparse Linear Bandits](https://openreview.net/forum?id=tkwP32nsEq) |  | 0 | It is well-known that for sparse linear bandits, when ignoring the dependency on sparsity which is much smaller than the ambient dimension, the worst-case minimax regret is $\widetilde{\Theta}\left(\sqrt{dT}\right)$ where $d$ is the ambient dimension and $T$ is the number of rounds. On the other... | Ruosong Wang, Simon Shaolei Du, Yan Dai |  |
| 1580 |  |  [CircNet: Meshing 3D Point Clouds with Circumcenter Detection](https://openreview.net/forum?id=zQWqV2tzDv) |  | 0 | Reconstructing 3D point clouds into triangle meshes is a key problem in computational geometry and surface reconstruction. Point cloud triangulation solves this problem by providing edge information to the input points. Since no vertex interpolation is involved, it is beneficial to preserve sharp... | Hongdong Li, Huan Lei, Liang Zheng, Ruitao Leng |  |
| 1581 |  |  [In-sample Actor Critic for Offline Reinforcement Learning](https://openreview.net/forum?id=dfDv0WU853R) |  | 0 | Offline reinforcement learning suffers from out-of-distribution issue and extrapolation error. Most methods penalize the out-of-distribution state-action pairs or regularize the trained policy towards the behavior policy but cannot guarantee to get rid of extrapolation error. We propose In-sample... | Boyuan Wang, Hongchang Zhang, Shuncheng He, Xiangyang Ji, Yi Xu, Yixiu Mao |  |
| 1582 |  |  [Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction](https://openreview.net/forum?id=CGBCTp2M6lA) |  | 0 | Understanding the interaction between multiple agents is crucial for realistic vehicle trajectory prediction. Existing methods have attempted to infer the interaction from the observed past trajectories of agents using pooling, attention, or graph-based methods, which rely on a deterministic... | Daehee Park, Hobin Ryu, Jegyeong Cho, Jiwon Kim, KukJin Yoon, Yunseo Yang |  |
| 1583 |  |  [LMSeg: Language-guided Multi-dataset Segmentation](https://openreview.net/forum?id=P44WPn1_aJV) |  | 0 | It’s a meaningful and attractive topic to build a general and inclusive segmentation model that can recognize more categories in various scenarios. A straightforward way is to combine the existing fragmented segmentation datasets and train a multi-dataset network. However, there are two major... | Chaohui Yu, Fan Wang, Jingliang Li, Qiang Zhou, Yuang Liu, Zhibin Wang |  |
| 1584 |  |  [RoPAWS: Robust Semi-supervised Representation Learning from Uncurated Data](https://openreview.net/forum?id=G1H4NSATlr) |  | 0 | Semi-supervised learning aims to train a model using limited labels. State-of-the-art semi-supervised methods for image classification such as PAWS rely on self-supervised representations learned with large-scale unlabeled but curated data. However, PAWS is often less effective when using... | ChihYao Ma, Ishan Misra, JongChyi Su, Licheng Yu, Mido Assran, Sangwoo Mo, Sean Bell |  |
| 1585 |  |  [Treeformer: Dense Gradient Trees for Efficient Attention Computation](https://openreview.net/forum?id=DWn1TEb2fK) |  | 0 | Standard inference and training with transformer based architectures scale quadratically with input sequence length. This is prohibitively large for a variety of applications especially in web-page translation, query-answering etc. Consequently, several approaches have been developed recently to... | Himanshu Jain, Lovish Madaan, Prateek Jain, Srinadh Bhojanapalli |  |
| 1586 |  |  [ODAM: Gradient-based Instance-Specific Visual Explanations for Object Detection](https://openreview.net/forum?id=kJWcI39kXY) |  | 0 | We propose the Gradient-weighted Object Detector Activation Mapping (Grad-ODAM), a visualized explanation technique for interpreting the predictions of object detectors. Utilizing the gradients of detector targets flowing into the intermediate feature maps, Grad-ODAM produces heat maps that show... | Antoni B. Chan, Chenyang Zhao |  |
| 1587 |  |  [Toward Adversarial Training on Contextualized Language Representation](https://openreview.net/forum?id=xZD10GhCvM) |  | 0 | Beyond the success story of adversarial training (AT) in the recent text domain on top of pre-trained language models (PLMs), our empirical study showcases the inconsistent gains from AT on some tasks, e.g. commonsense reasoning, named entity recognition. This paper investigates AT from the... | Hai Zhao, Hanwen Shi, Hongqiu Wu, Min Zhang, Yongxiang Liu |  |
| 1588 |  |  [Gromov-Wasserstein Autoencoders](https://openreview.net/forum?id=sbS10BCtc7) |  | 0 | Variational Autoencoder (VAE)-based generative models offer flexible representation learning by incorporating meta-priors, general premises considered beneficial for downstream tasks. However, the incorporated meta-priors often involve ad-hoc model deviations from the original likelihood... | Miki Haseyama, Nao Nakagawa, Ren Togo, Takahiro Ogawa |  |
| 1589 |  |  [Optimal Activation Functions for the Random Features Regression Model](https://openreview.net/forum?id=ltWade-cpK) |  | 0 | The asymptotic mean squared test error and sensitivity of the Random Features Regression model (RFR) have been recently studied. We build on this work and identify in closed-form the family of Activation Functions (AFs) that minimize a combination of the test error and sensitivity of the RFR under... | Jianxin Wang, José Bento |  |
| 1590 |  |  [Improving Object-centric Learning with Query Optimization](https://openreview.net/forum?id=_-FN9mJsgg) |  | 0 | The ability to decompose complex natural scenes into meaningful object-centric abstractions lies at the core of human perception and reasoning. In the recent culmination of unsupervised object-centric learning, the Slot-Attention module has played an important role with its simple yet effective... | Baoxiong Jia, Siyuan Huang, Yu Liu |  |
| 1591 |  |  [Feature Reconstruction From Outputs Can Mitigate Simplicity Bias in Neural Networks](https://openreview.net/forum?id=zH9GcZ3ZGXu) |  | 0 | Deep Neural Networks are known to be brittle to even minor distribution shifts compared to the training distribution. While one line of work has demonstrated that \emph{Simplicity Bias} (SB) of DNNs -- bias towards learning only the simplest features -- is a key reason for this brittleness, another... | Anshul Nasery, Praneeth Netrapalli, Prateek Jain, Sravanti Addepalli, Venkatesh Babu Radhakrishnan |  |
| 1592 |  |  [EUCLID: Towards Efficient Unsupervised Reinforcement Learning with Multi-choice Dynamics Model](https://openreview.net/forum?id=xQAjSr64PTc) |  | 0 | Unsupervised reinforcement learning (URL) poses a promising paradigm to learn useful behaviors in a task-agnostic environment without the guidance of extrinsic rewards to facilitate the fast adaptation of various downstream tasks. Previous works focused on the pre-training in a model-free manner... | Changjie Fan, Fei Ni, Jianye Hao, Jinyi Liu, Yan Zheng, Yao Mu, Yifu Yuan, Yingfeng Chen, Yujing Hu |  |
| 1593 |  |  [Maximizing Spatio-Temporal Entropy of Deep 3D CNNs for Efficient Video Recognition](https://openreview.net/forum?id=lj1Eb1OPeNw) |  | 0 | 3D convolution neural networks (CNNs) have been the prevailing option for video recognition. To capture the temporal information, 3D convolutions are computed along the sequences, leading to cubically growing and expensive computations. To reduce the computational cost, previous methods resort to... | Dong Gong, Junyan Wang, Maurice Pagnucco, Ming C. Lin, Xiuyu Sun, Yang Song, Yichen Qian, Zhenhong Sun |  |
| 1594 |  |  [Cycle to Clique (Cy2C) Graph Neural Network: A Sight to See beyond Neighborhood Aggregation](https://openreview.net/forum?id=7d-g8KozkiE) |  | 0 | Graph neural networks have been successfully adapted for learning vector representations of graphs through various neighborhood aggregation schemes. Previous researches suggest, however, that they possess limitations in incorporating key non-Euclidean topological properties of graphs. This paper... | Sun Woo Park, U Jin Choi, Youngho Woo, Yun Young Choi |  |
| 1595 |  |  [Latent State Marginalization as a Low-cost Approach for Improving Exploration](https://openreview.net/forum?id=b0UksKFcTOL) |  | 0 | While the maximum entropy (MaxEnt) reinforcement learning (RL) framework -- often touted for its exploration and robustness capabilities -- is usually motivated from a probabilistic perspective, the use of deep probabilistic models have not gained much traction in practice due to their inherent... | Aaron C. Courville, Amy Zhang, Dinghuai Zhang, Qinqing Zheng, Ricky T. Q. Chen, Yoshua Bengio |  |
| 1596 |  |  [Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap](https://openreview.net/forum?id=inU2quhGdNU) |  | 0 | The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a simplex equiangular tight frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We... | Adrian Weller, Bernhard Schölkopf, Longhui Yu, Weiyang Liu |  |
| 1597 |  |  [MaskFusion: Feature Augmentation for Click-Through Rate Prediction via Input-adaptive Mask Fusion](https://openreview.net/forum?id=QzbKH8nNq_V) |  | 0 | Click-through rate (CTR) prediction plays important role in the advertisement, recommendation, and retrieval applications. Given the feature set, how to fully utilize the information from the feature set is an active topic in deep CTR model designs. There are several existing deep CTR works... | Chao Liao, Chengru Song, Jianchao Tan, Jiyuan Jia, Yi Guo |  |
| 1598 |  |  [Rethinking Self-Supervised Visual Representation Learning in Pre-training for 3D Human Pose and Shape Estimation](https://openreview.net/forum?id=8U4joMeLRF) |  | 0 | Recently, a few self-supervised representation learning (SSL) methods have outperformed the ImageNet classification pre-training for vision tasks such as object detection. However, its effects on 3D human body pose and shape estimation (3DHPSE) are open to question, whose target is fixed to a... | Gyeongsik Moon, Hongsuk Choi, Hyeongjin Nam, Kyoung Mu Lee, Taeryung Lee |  |
| 1599 |  |  [Learned Index with Dynamic $\epsilon$](https://openreview.net/forum?id=UiaUEICawgw) |  | 0 | Index structure is a fundamental component in database and facilitates broad data retrieval applications. Recent learned index methods show superior performance by learning hidden yet useful data distribution with the help of machine learning, and provide a guarantee that the prediction error is no... | Bolin Ding, Daoyuan Chen, Defu Lian, Jingren Zhou, Kai Zeng, Wuchao Li, Yaliang Li |  |
| 1600 |  |  [Boosting Multiagent Reinforcement Learning via Permutation Invariant and Permutation Equivariant Networks](https://openreview.net/forum?id=OxNQXyZK-K8) |  | 0 | The state space in Multiagent Reinforcement Learning (MARL) grows exponentially with the agent number. Such a curse of dimensionality results in poor scalability and low sample efficiency, inhibiting MARL for decades. To break this curse, we propose a unified agent permutation framework that... | Dong Li, Hangyu Mao, Jianye Hao, Weixun Wang, Xiaotian Hao, Yan Zheng, Yaodong Yang, Zhen Wang |  |
| 1601 |  |  [wav2tok: Deep Sequence Tokenizer for Audio Retrieval](https://openreview.net/forum?id=v8Mi8KU6056) |  | 0 | Search over audio sequences is a fundamental problem. In this paper, we propose a method to extract concise discrete representations for audio that can be used for efficient retrieval. Our motivation comes from orthography which represents speech of a given language in a concise and distinct... | Adhiraj Banerjee, Vipul Arora |  |
| 1602 |  |  [PV3D: A 3D Generative Model for Portrait Video Generation](https://openreview.net/forum?id=o3yygm3lnzS) |  | 0 | Recent advances in generative adversarial networks (GANs) have demonstrated the capabilities of generating stunning photo-realistic portrait images. While some prior works have applied such image GANs to unconditional 2D portrait video generation and static 3D portrait synthesis, there are few... | Eric Zhongcong Xu, Jianfeng Zhang, Jiashi Feng, Jun Hao Liew, Mike Zheng Shou, Song Bai, Wenqing Zhang |  |
| 1603 |  |  [Characterizing the Influence of Graph Elements](https://openreview.net/forum?id=51GXyzOKOp) |  | 0 | Influence function, a method from the robust statistics, measures the changes of model parameters or some functions about model parameters with respect to the removal or modification of training instances. It is an efficient and useful post-hoc method for studying the interpretability of machine... | Hongfu Liu, Peizhao Li, Pengyu Hong, Zizhang Chen |  |
| 1604 |  |  [SWIFT: Rapid Decentralized Federated Learning via Wait-Free Model Communication](https://openreview.net/forum?id=jh1nCir1R3d) |  | 0 | The decentralized Federated Learning (FL) setting avoids the role of a potentially unreliable or untrustworthy central host by utilizing groups of clients to collaboratively train a model via localized training and model/gradient sharing. Most existing decentralized FL algorithms require... | Amrit S. Bedi, Evan Wang, Furong Huang, Marco Bornstein, Tahseen Rabbani |  |
| 1605 |  |  [Hierarchical Sliced Wasserstein Distance](https://openreview.net/forum?id=CUOaVn6mYEj) |  | 0 | Sliced Wasserstein (SW) distance has been widely used in different application scenarios since it can be scaled to a large number of supports without suffering from the curse of dimensionality. The value of sliced Wasserstein distance is the average of transportation cost between one-dimensional... | Huy Nguyen, Khai Nguyen, Litu Rout, Nhat Ho, Tan Nguyen, Tongzheng Ren |  |
| 1606 |  |  [Prototypical Calibration for Few-shot Learning of Language Models](https://openreview.net/forum?id=nUsP9lFADUF) |  | 0 | In-context learning of GPT-like models has been recognized as fragile across different hand-crafted templates, and demonstration permutations. In this work, we propose prototypical calibration to adaptively learn a more robust decision boundary for zero- and few-shot classification, instead of... | Furu Wei, Li Dong, Yaru Hao, Yutao Sun, Zhixiong Han |  |
| 1607 |  |  [NERDS: A General Framework to Train Camera Denoisers from Raw-RGB Noisy Image Pairs](https://openreview.net/forum?id=NO0ThzteQdI) |  | 0 | We aim to train accurate denoising networks for smartphone/digital cameras from single noisy images. Downscaling is commonly used as a practical denoiser for low-resolution images. Based on this processing, we found that the pixel variance of the natural images is more robust to downscaling than... | Heewon Kim, Kyoung Mu Lee |  |
| 1608 |  |  [Learning Hierarchical Protein Representations via Complete 3D Graph Networks](https://openreview.net/forum?id=9X-hgLDLYkQ) |  | 0 | We consider representation learning for proteins with 3D structures. We build 3D graphs based on protein structures and develop graph networks to learn their representations. Depending on the levels of details that we wish to capture, protein representations can be computed at different levels,... | Haoran Liu, Jerry Kurtin, Limei Wang, Shuiwang Ji, Yi Liu |  |
| 1609 |  |  [RGI: robust GAN-inversion for mask-free image inpainting and unsupervised pixel-wise anomaly detection](https://openreview.net/forum?id=1UbNwQC89a) |  | 0 | Generative adversarial networks (GANs), trained on a large-scale image dataset, can be a good approximator of the natural image manifold. GAN-inversion, using a pre-trained generator as a deep generative prior, is a promising tool for image restoration under corruptions. However, the performance of... | Haoping Bai, Jianjun Shi, Jiulong Shan, Meng Cao, Ping Huang, Shancong Mou, Xiaoyi Gu |  |
| 1610 |  |  [Coverage-centric Coreset Selection for High Pruning Rates](https://openreview.net/forum?id=QwKvL6wC8Yi) |  | 0 | One-shot coreset selection aims to select a representative subset of the training data, given a pruning rate, that can later be used to train future models while retaining high accuracy. State-of-the-art coreset selection methods pick the highest importance examples based on an importance metric... | Atul Prakash, Fan Lai, Haizhong Zheng, Rui Liu |  |
| 1611 |  |  [ILA-DA: Improving Transferability of Intermediate Level Attack with Data Augmentation](https://openreview.net/forum?id=OM7doLjQbOQ) |  | 0 | Adversarial attack aims to generate deceptive inputs to fool a machine learning model. In deep learning, an adversarial input created for a specific neural network can also trick other neural networks. This intriguing property is known as black-box transferability of adversarial examples. To... | Chiu Wai Yan, DitYan Yeung, TszHim Cheung |  |
| 1612 |  |  [Contrastive Alignment of Vision to Language Through Parameter-Efficient Transfer Learning](https://openreview.net/forum?id=x0BPR9iXc1) |  | 0 | Contrastive vision-language models (e.g. CLIP) are typically created by updating all the parameters of a vision model and language model through contrastive training. Can such models be created by a small number of parameter updates to an already-trained language model and vision model? The... | Yun Fu, Zaid Khan |  |
| 1613 |  |  [BEEF: Bi-Compatible Class-Incremental Learning via Energy-Based Expansion and Fusion](https://openreview.net/forum?id=iP77_axu0h3) |  | 0 | Neural networks suffer from catastrophic forgetting when sequentially learning tasks phase-by-phase, making them inapplicable in dynamically updated systems. Class-incremental learning (CIL) aims to enable neural networks to learn different categories at multi-stages. Recently,... | DaWei Zhou, DeChuan Zhan, FuYun Wang, HanJia Ye, Liu Liu, Peilin Zhao, Yatao Bian |  |
| 1614 |  |  [Out-of-distribution Representation Learning for Time Series Classification](https://openreview.net/forum?id=gUZWOE42l6Q) |  | 0 | Time series classification is an important problem in the real world. Due to its non-stationary property that the distribution changes over time, it remains challenging to build models for generalization to unseen distributions. In this paper, we propose to view time series classification from the... | Jindong Wang, Wang Lu, Xing Xie, Xinwei Sun, Yiqiang Chen |  |
| 1615 |  |  [Schema Inference for Interpretable Image Classification](https://openreview.net/forum?id=VGI9dSmTgPF) |  | 0 | In this paper, we study a novel inference paradigm, termed as schema inference, that learns to deductively infer the explainable predictions by rebuilding the prior deep neural network (DNN) forwarding scheme, guided by the prevalent philosophical cognitive concept of schema. We strive to... | Haofei Zhang, Jie Song, Kaixuan Chen, Mengqi Xue, Mingli Song, Xiaokang Liu |  |
| 1616 |  |  [Your Contrastive Learning Is Secretly Doing Stochastic Neighbor Embedding](https://openreview.net/forum?id=XFSCKELP3bp) |  | 0 | Contrastive learning, especially self-supervised contrastive learning (SSCL), has achieved great success in extracting powerful features from unlabeled data. In this work, we contribute to the theoretical understanding of SSCL and uncover its connection to the classic data visualization method,... | Fengwei Zhou, Tianyang Hu, Weiran Huang, Wenjia Wang, Zhili Liu |  |
| 1617 |  |  [Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting](https://openreview.net/forum?id=OhUAblg27z) |  | 0 | Most offline reinforcement learning (RL) algorithms return a target policy maximizing a trade-off between (1) the expected performance gain over the behavior policy that collected the dataset, and (2) the risk stemming from the out-of-distribution-ness of the induced state-action occupancy. It... | Pulkit Agrawal, Remi Tachet des Combes, Romain Laroche, ZhangWei Hong |  |
| 1618 |  |  [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://openreview.net/forum?id=1PL1NIMMrw) |  | 0 | Chain-of-thought prompting combined with pretrained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a... | Aakanksha Chowdhery, Dale Schuurmans, Denny Zhou, Ed H. Chi, Jason Wei, Quoc V. Le, Sharan Narang, Xuezhi Wang |  |
| 1619 |  |  [Spiking Convolutional Neural Networks for Text Classification](https://openreview.net/forum?id=pgU3k7QXuz0) |  | 0 | Spiking neural networks (SNNs) offer a promising pathway to implement deep neural networks (DNNs) in a more energy-efficient manner since their neurons are sparsely activated and inferences are event-driven. However, there have been very few works that have demonstrated the efficacy of SNNs in... | Changze Lv, Jianhan Xu, Xiaoqing Zheng |  |
| 1620 |  |  [Distributionally Robust Recourse Action](https://openreview.net/forum?id=E3ip6qBLF7) |  | 0 | A recourse action aims to explain a particular algorithmic decision by showing one specific way in which the instance could be modified to receive an alternate outcome. Existing recourse generation methods often assume that the machine learning model does not change over time. However, this... | Duy Nguyen, Ngoc Bui, Viet Anh Nguyen |  |
| 1621 |  |  [Write and Paint: Generative Vision-Language Models are Unified Modal Learners](https://openreview.net/forum?id=HgQR0mXQ1_a) |  | 0 | Recent advances in vision-language pre-training have pushed the state-of-the-art on various vision-language tasks, making machines more capable of multi-modal writing (image-to-text generation) and painting (text-to-image generation). However, few studies investigate if these two essential... | Jiawei Wang, Shizhe Diao, Wangchunshu Zhou, Xinsong Zhang |  |
| 1622 |  |  [Progressive Voronoi Diagram Subdivision Enables Accurate Data-free Class-Incremental Learning](https://openreview.net/forum?id=zJXg_Wmob03) |  | 0 | Data-free Class-incremental Learning (CIL) is a challenging problem because rehearsing data from previous phases is strictly prohibited, causing catastrophic forgetting of Deep Neural Networks (DNNs). In this paper, we present \emph{iVoro}, a novel framework derived from computational geometry. We... | Chunwei Ma, Jinhui Xu, Mingchen Gao, Yan Shen, Zhanghexuan Ji, Ziyun Huang |  |
| 1623 |  |  [Data Valuation Without Training of a Model](https://openreview.net/forum?id=XIzO8zr-WbM) |  | 0 | Many recent works on understanding deep learning try to quantify how much individual data instances influence the optimization and generalization of a model. Such attempts reveal characteristics and importance of individual instances, which may provide useful information in diagnosing and improving... | Hoyong Choi, Hye Won Chung, Nohyun Ki |  |
| 1624 |  |  [HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing](https://openreview.net/forum?id=YDJRFWBMNby) |  | 0 | The molecular basis of protein thermal stability is only partially understood and has major significance for drug and vaccine discovery. The lack of datasets and standardized benchmarks considerably limits learning-based discovery methods. We present \texttt{HotProtein}, a large-scale protein... | Adam R. Klivans, Alex Dimakis, Andrew D. Ellington, Chengyue Gong, Daniel Jesus Diaz, Jordan Tyler Wells, Qiang Liu, Tianlong Chen, Xuxi Chen, Zhangyang Wang |  |
| 1625 |  |  [RPM: Generalizable Multi-Agent Policies for Multi-Agent Reinforcement Learning](https://openreview.net/forum?id=HnSceSzlfrY) |  | 0 | Despite the recent advancement in multi-agent reinforcement learning (MARL), the MARL agents easily overfit the training environment and perform poorly in evaluation scenarios where other agents behave differently. Obtaining generalizable policies for MARL agents is thus necessary but challenging... | Bo An, Shuicheng Yan, Svetlana Obraztsova, Wei Qiu, Xiao Ma, Zhongwen Xu |  |
| 1626 |  |  [Behavior Prior Representation learning for Offline Reinforcement Learning](https://openreview.net/forum?id=hQ4K9Bf4G2B) |  | 0 | Offline reinforcement learning (RL) struggles in environments with rich and noisy inputs, where the agent only has access to a fixed dataset without environment interactions. Past works have proposed common workarounds based on the pre-training of state representations, followed by policy training.... | Chen Liu, Hongyu Zang, Jie Yu, Remi Tachet des Combes, Riashat Islam, Romain Laroche, Xin Li |  |
| 1627 |  |  [SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency](https://openreview.net/forum?id=o0LFPcoFKnr) |  | 0 | Deep neural networks (DNNs) are vulnerable to backdoor attacks, where adversaries embed a hidden backdoor trigger during the training process for malicious prediction manipulation. These attacks pose great threats to the applications of DNNs under the real-world machine learning as a service... | Cong Liu, Hanqing Guo, Junfeng Guo, Lichao Sun, Xun Chen, Yiming Li |  |
| 1628 |  |  [On the Perils of Cascading Robust Classifiers](https://openreview.net/forum?id=tQG-o3SeipT) |  | 0 | Ensembling certifiably robust neural networks is a promising approach for improving the \emph{certified robust accuracy} of neural models. Black-box ensembles that assume only query-access to the constituent models (and their robustness certifiers) during prediction are particularly attractive due... | Chi Zhang, Corina S. Pasareanu, Klas Leino, Matt Fredrikson, Ravi Mangal, Zifan Wang |  |
| 1629 |  |  [Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions](https://openreview.net/forum?id=4D4TSJE6-K) |  | 0 | Pretrained language models have shown superior performance on many natural language processing tasks, yet they still struggle at multi-step formal reasoning tasks like grade school math problems. One key challenge of finetuning them to solve such math reasoning problems is that many existing... | Alex Polozov, Ansong Ni, Chenglong Wang, Christopher Meek, Dragomir Radev, Jeevana Priya Inala, Jianfeng Gao |  |
| 1630 |  |  [Adaptive Robust Evidential Optimization For Open Set Detection from Imbalanced Data](https://openreview.net/forum?id=3yJ-hcJBqe) |  | 0 | Open set detection (OSD) aims at identifying data samples of an unknown class ($i.e.$, open set) from those of known classes ($i.e.$, closed set) based on a model trained from closed set samples. However, a closed set may involve a highly imbalanced class distribution. Accurately differentiating... | Hitesh Sapkota, Qi Yu |  |
| 1631 |  |  [Dual Diffusion Implicit Bridges for Image-to-Image Translation](https://openreview.net/forum?id=5HLoTvVGDe) |  | 0 | Common image-to-image translation methods rely on joint training over data from both source and target domains. The training process requires concurrent access to both datasets, which hinders data separation and privacy protection; and existing models cannot be easily adapted for translation of new... | Chenlin Meng, Jiaming Song, Stefano Ermon, Xuan Su |  |
| 1632 |  |  [Average Sensitivity of Decision Tree Learning](https://openreview.net/forum?id=boik01yhssB) |  | 0 | A decision tree is a fundamental model used in data mining and machine learning. In practice, the training data used to construct a decision tree may change over time or contain noise, and a drastic change in the learned tree structure owing to such data perturbation is unfavorable. For example, in... | Satoshi Hara, Yuichi Yoshida |  |
| 1633 |  |  [Stable Target Field for Reduced Variance Score Estimation in Diffusion Models](https://openreview.net/forum?id=WmIwYTd0YTF) |  | 0 | Diffusion models generate samples by reversing a fixed forward diffusion process. Despite already providing impressive empirical results, these diffusion models algorithms can be further improved by reducing the variance of the training targets in their denoising score-matching objective. We argue... | Shangyuan Tong, Tommi S. Jaakkola, Yilun Xu |  |
| 1634 |  |  [Continuous pseudo-labeling from the start](https://openreview.net/forum?id=m3twGT2bAug) |  | 0 | Self-training (ST), or pseudo-labeling has sparked significant interest in the automatic speech recognition (ASR) community recently because of its success in harnessing unlabeled data. Unlike prior semi-supervised learning approaches that relied on iteratively regenerating pseudo-labels (PLs) from... | Dan Berrebbi, Navdeep Jaitly, Ronan Collobert, Samy Bengio, Tatiana Likhomanenko |  |
| 1635 |  |  [GNNDelete: A General Strategy for Unlearning in Graph Neural Networks](https://openreview.net/forum?id=X9yCkmT5Qrl) |  | 0 | Graph unlearning, which involves deleting graph elements such as nodes, node labels, and relationships from a trained graph neural network (GNN) model, is crucial for real-world applications where data elements may become irrelevant, inaccurate, or privacy-sensitive. However, existing methods for... | Chirag Agarwal, George Dasoulas, Huan He, Jiali Cheng, Marinka Zitnik |  |
| 1636 |  |  [Meta-Learning in Games](https://openreview.net/forum?id=uHaWaNhCvZD) |  | 0 | In the literature on game-theoretic equilibrium finding, focus has mainly been on solving a single game in isolation. In practice, however, strategic interactions—ranging from routing problems to online advertising auctions—evolve dynamically, thereby leading to many similar games to be solved. To... | Gabriele Farina, Ioannis Anagnostides, Keegan Harris, Mikhail Khodak, Steven Wu, Tuomas Sandholm |  |
| 1637 |  |  [DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking](https://openreview.net/forum?id=kKF8_K-mBbS) |  | 0 | Predicting the binding structure of a small molecule ligand to a protein---a task known as molecular docking---is critical to drug design. Recent deep learning methods that treat docking as a regression problem have decreased runtime compared to traditional search-based methods but have yet to... | Bowen Jing, Gabriele Corso, Hannes Stärk, Regina Barzilay, Tommi S. Jaakkola |  |
| 1638 |  |  [Constructive TT-representation of the tensors given as index interaction functions with applications](https://openreview.net/forum?id=yLzLfM-Esnu) |  | 0 | This paper presents a method to build explicit tensor-train (TT) representations. We show that a wide class of tensors can be explicitly represented with sparse TT-cores, obtaining, in many cases, optimal TT-ranks. Numerical experiments show that our method outperforms the existing ones in several... | Gleb V. Ryzhakov, Ivan V. Oseledets |  |
| 1639 |  |  [Sparse tree-based Initialization for Neural Networks](https://openreview.net/forum?id=78xgBm6ckZr) |  | 0 | Dedicated neural network (NN) architectures have been designed to handle specific data types (such as CNN for images or RNN for text), which ranks them among state-of-the-art methods for dealing with these data. Unfortunately, no architecture has been found for dealing with tabular data yet, for... | Claire Boyer, Erwan Scornet, Ludovic Arnould, Patrick Lutz |  |
| 1640 |  |  [VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for Analysis-by-Synthesis](https://openreview.net/forum?id=AdPJb9cud_Y) |  | 0 | Differentiable rendering allows the application of computer graphics on vision tasks, e.g. object pose and shape fitting, via analysis-by-synthesis, where gradients at occluded regions are important when inverting the rendering process.To obtain those gradients, state-of-the-art (SoTA)... | Adam Kortylewski, Alan L. Yuille, Angtian Wang, Jian Sun, Peng Wang |  |
| 1641 |  |  [The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers](https://openreview.net/forum?id=TJ2nxciYCk-) |  | 0 | This paper studies a curious phenomenon that machine learning model with Transformer architectures have sparse activation maps. By activation map we refer to the intermediate output of the multi-layer perceptrons (MLPs) after a ReLU activation function, and by "sparse" we mean that on average very... | Ankit Singh Rawat, Chong You, Daliang Li, Felix Chern, Felix X. Yu, Ke Ye, Ruiqi Guo, Sanjiv Kumar, Sashank J. Reddi, Srinadh Bhojanapalli, Zonglin Li |  |
| 1642 |  |  [FoSR: First-order spectral rewiring for addressing oversquashing in GNNs](https://openreview.net/forum?id=3YjQfCLdrzz) |  | 0 | Graph neural networks (GNNs) are able to leverage the structure of graph data by passing messages along the edges of the graph. While this allows GNNs to learn features depending on the graph structure, for certain graph topologies it leads to inefficient information propagation and a problem known... | Guido Montúfar, Kedar Karhadkar, Pradeep Kr. Banerjee |  |
| 1643 |  |  [Generative Modeling Helps Weak Supervision (and Vice Versa)](https://openreview.net/forum?id=3OaBBATwsvP) |  | 0 | Many promising applications of supervised machine learning face hurdles in the acquisition of labeled data in sufficient quantity and quality, creating an expensive bottleneck. To overcome such limitations, techniques that do not depend on ground truth labels have been studied, including weak... | Artur Dubrawski, Benedikt Boecking, Frederic Sala, Nicholas Carl Roberts, Stefano Ermon, Willie Neiswanger |  |
| 1644 |  |  [Provable Memorization Capacity of Transformers](https://openreview.net/forum?id=8JCg5xJCTPR) |  | 0 | Quantifying memorization capacity is essential for understanding the expressiveness and generalizability of deep learning model architectures. However, the memorization capacity of the Transformer architecture has yet to be explored. In this work, we present the first study of the memorization... | Barzan Mozafari, Junghwan Kim, Michelle Kim |  |
| 1645 |  |  [Bridge the Inference Gaps of Neural Processes via Expectation Maximization](https://openreview.net/forum?id=A7v2DqLjZdq) |  | 0 | The neural process (NP) is a family of computationally efficient models for learning distributions over functions. However, it suffers from under-fitting and shows suboptimal performance in practice. Researchers have primarily focused on incorporating diverse structural inductive biases, e.g.... | Herke van Hoof, Marco Federici, Qi Wang |  |
| 1646 |  |  [Masked Vision and Language Modeling for Multi-modal Representation Learning](https://openreview.net/forum?id=ZhuXksSJYWn) |  | 0 | In this paper, we study how to use masked signal modeling in vision and language (V+L) representation learning. Instead of developing masked language modeling (MLM) and masked image modeling (MIM) independently, we propose to build joint masked vision and language modeling, where the masked signal... | Avinash Ravichandran, Erhan Bas, Gukyeong Kwon, Rahul Bhotika, Stefano Soatto, Zhaowei Cai |  |
| 1647 |  |  [Agent-based Graph Neural Networks](https://openreview.net/forum?id=8WTAh0tj2jC) |  | 0 | We present a novel graph neural network we call AgentNet, which is designed specifically for graph-level tasks. AgentNet is inspired by sublinear algorithms, featuring a computational complexity that is independent of the graph size. The architecture of AgentNet differs fundamentally from the... | Benedikt Schesch, Karolis Martinkus, Pál András Papp, Roger Wattenhofer |  |
| 1648 |  |  [On the Performance of Temporal Difference Learning With Neural Networks](https://openreview.net/forum?id=6JMXLWX68Kj) |  | 0 | Neural Temporal Difference (TD) Learning is an approximate temporal difference method for policy evaluation that uses a neural network for function approximation. Analysis of Neural TD Learning has proven to be challenging. In this paper we provide a convergence analysis of Neural TD Learning with... | Alex Olshevsky, Haoxing Tian, Ioannis Ch. Paschalidis |  |
| 1649 |  |  [Certified Defences Against Adversarial Patch Attacks on Semantic Segmentation](https://openreview.net/forum?id=b0JxQC7JLWh) |  | 0 | Adversarial patch attacks are an emerging security threat for real world deep learning applications. We present Demasked Smoothing, the first approach (up to our knowledge) to certify the robustness of semantic segmentation models against this threat model. Previous work on certifiably defending... | Jan Hendrik Metzen, Kaspar Sakmann, Maksym Yatsura, Matthias Hein, N. Grace Hua |  |
| 1650 |  |  [Markup-to-Image Diffusion Models with Scheduled Sampling](https://openreview.net/forum?id=81VJDmOE2ol) |  | 0 | Building on recent advances in image generation, we present a fully data-driven approach to rendering markup into images. The approach is based on diffusion models, which parameterize the distribution of data using a sequence of denoising operations on top of a Gaussian noise distribution. We view... | Alexander M. Rush, Noriyuki Kojima, Yuntian Deng |  |
| 1651 |  |  [How Much Space Has Been Explored? Measuring the Chemical Space Covered by Databases and Machine-Generated Molecules](https://openreview.net/forum?id=Yo06F8kfMa1) |  | 0 | Forming a molecular candidate set that contains a wide range of potentially effective compounds is crucial to the success of drug discovery. While most databases and machine-learning-based generation models aim to optimize particular chemical properties, there is limited literature on how to... | Jiaqi Ma, Qiaozhu Mei, Yutong Xie, Ziqiao Xu |  |
| 1652 |  |  [Understanding new tasks through the lens of training data via exponential tilting](https://openreview.net/forum?id=DBMttEEoLbw) |  | 0 | Deploying machine learning models on new tasks is a major challenge due to differences in distributions of the train (source) data and the new (target) data. However, the training data likely captures some of the properties of the new task. We consider the problem of reweighing the training samples... | Mikhail Yurochkin, Moulinath Banerjee, Subha Maity, Yuekai Sun |  |
| 1653 |  |  [Calibrating Sequence likelihood Improves Conditional Language Generation](https://openreview.net/forum?id=0qSOodKmJaN) |  | 0 | Conditional language models are predominantly trained with maximum likelihood estimation (MLE), giving probability mass to sparsely observed target sequences. While MLE trained models assign high probability to plausible sequences given the context, the model probabilities often do not accurately... | Misha Khalman, Mohammad Saleh, Peter J. Liu, Rishabh Joshi, Shashi Narayan, Yao Zhao |  |
| 1654 |  |  [Learning differentiable solvers for systems with hard constraints](https://openreview.net/forum?id=vdv6CmGksr0) |  | 0 | We introduce a practical method to enforce partial differential equation (PDE) constraints for functions defined by neural networks (NNs), with a high degree of accuracy and up to a desired tolerance. We develop a differentiable PDE-constrained layer that can be incorporated into any NN... | Aditi S. Krishnapriyan, Geoffrey Négiar, Michael W. Mahoney |  |
| 1655 |  |  [FedDAR: Federated Domain-Aware Representation Learning](https://openreview.net/forum?id=6P9Y25Pljl6) |  | 0 | Cross-silo Federated learning (FL) has become a promising tool in machine learning applications for healthcare. It allows hospitals/institutions to train models with sufficient data while the data is kept private. To make sure the FL model is robust when facing heterogeneous data among FL clients,... | Aoxiao Zhong, Hao He, Na Li, Quanzheng Li, Zhaolin Ren |  |
| 1656 |  |  [SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models](https://openreview.net/forum?id=TFbwV6I0VLg) |  | 0 | Understanding dynamics from visual observations is a challenging problem that requires disentangling individual objects from the scene and learning their interactions. While recent object-centric models can successfully decompose a scene into objects, modeling their dynamics effectively still... | Animesh Garg, Klaus Greff, Nikita Dvornik, Thomas Kipf, Ziyi Wu |  |
| 1657 |  |  [Simplifying Model-based RL: Learning Representations, Latent-space Models, and Policies with One Objective](https://openreview.net/forum?id=MQcmfgRxf7a) |  | 0 | While reinforcement learning (RL) methods that learn an internal model of the environment have the potential to be more sample efficient than their model-free counterparts, learning to model raw observations from high dimensional sensors can be challenging. Prior work has addressed this challenge... | Benjamin Eysenbach, Homanga Bharadhwaj, Raj Ghugare, Russ Salakhutdinov, Sergey Levine |  |
| 1658 |  |  [Deep Generative Symbolic Regression](https://openreview.net/forum?id=o7koEEMA1bR) |  | 0 | Symbolic regression (SR) aims to discover concise closed-form mathematical equations from data, a task fundamental to scientific discovery. However, the problem is highly challenging because closed-form equations lie in a complex combinatorial search space. Existing methods, ranging from heuristic... | Mihaela van der Schaar, Samuel Holt, Zhaozhi Qian |  |
| 1659 |  |  [What Can we Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers?](https://openreview.net/forum?id=p66AzKi6Xim) |  | 0 | When deployed for risk-sensitive tasks, deep neural networks must include an uncertainty estimation mechanism. Here we examine the relationship between deep architectures and their respective training regimes, with their corresponding selective prediction and uncertainty estimation performance. We... | Ido Galil, Mohammed Dabbah, Ran ElYaniv |  |
| 1660 |  |  [Predictor-corrector algorithms for stochastic optimization under gradual distribution shift](https://openreview.net/forum?id=2SV2dlfBuE3) |  | 0 | Time-varying stochastic optimization problems frequently arise in machine learning practice (e.g., gradual domain shift, object tracking, strategic classification). Often, the underlying process that drives the distribution shift is continuous in nature. We exploit this underlying continuity by... | Debarghya Mukherjee, Moulinath Banerjee, Subha Maity, Yuekai Sun |  |
| 1661 |  |  [AIM: Adapting Image Models for Efficient Video Action Recognition](https://openreview.net/forum?id=CIoSZ_HKHS7) |  | 0 | Recent vision transformer based video models mostly follow the \`\`image pre-training then finetuning" paradigm and have achieved great success on multiple video benchmarks. However, fully finetuning such a video model could be computationally expensive and unnecessary, given the pre-trained image... | Aston Zhang, Chen Chen, Mu Li, Taojiannan Yang, Yi Zhu, Yusheng Xie |  |
| 1662 |  |  [Impossibly Good Experts and How to Follow Them](https://openreview.net/forum?id=sciA_xgYofB) |  | 0 | We consider the sequential decision making problem of learning from an expert that has access to more information than the learner. For many problems this extra information will enable the expert to achieve greater long term reward than any policy without this privileged information access. We call... | Aaron Walsman, Ali Farhadi, Dieter Fox, Muru Zhang, Sanjiban Choudhury |  |
| 1663 |  |  [Distributionally Robust Post-hoc Classifiers under Prior Shifts](https://openreview.net/forum?id=3KUfbI9_DQE) |  | 0 | The generalization ability of machine learning models degrades significantly when the test distribution shifts away from the training distribution. We investigate the problem of training models that are robust to shifts caused by changes in the distribution of class-priors or group-priors. The... | Abhishek Kumar, Ehsan Amid, Harikrishna Narasimhan, Jiaheng Wei, WenSheng Chu, Yang Liu |  |
| 1664 |  |  [Transformer Meets Boundary Value Inverse Problems](https://openreview.net/forum?id=HnlCZATopvr) |  | 0 | A Transformer-based deep direct sampling method is proposed for electrical impedance tomography, a well-known severely ill-posed nonlinear boundary value inverse problem. A real-time reconstruction is achieved by evaluating the learned inverse operator between carefully designed data and the... | Long Chen, Ruchi Guo, Shuhao Cao |  |
| 1665 |  |  [Unicom: Universal and Compact Representation Learning for Image Retrieval](https://openreview.net/forum?id=3YFDsSRSxB-) |  | 0 | Modern image retrieval methods typically rely on fine-tuning pre-trained encoders to extract image-level descriptors. However, the most widely used models are pre-trained on ImageNet-1K with limited classes. The pre-trained feature representation is therefore not universal enough to generalize well... | Jaiwei Li, Jia Guo, Jiankang Deng, Jing Yang, Kaicheng Yang, Tongliang Liu, Xiang An, Ziyong Feng |  |
| 1666 |  |  [Diffusion Probabilistic Fields](https://openreview.net/forum?id=ik91mY-2GN) |  | 0 | Diffusion probabilistic models have quickly become a major approach for generative modeling of images, 3D geometry, video and other domains. However, to adapt diffusion generative modeling to these domains the denoising network needs to be carefully designed for each domain independently,... | Alexander G. Schwing, Jiatao Gu, Joshua M. Susskind, Miguel Ángel Bautista, Peiye Zhuang, Samira Abnar |  |
| 1667 |  |  [Beyond calibration: estimating the grouping loss of modern neural networks](https://openreview.net/forum?id=6w1k-IixnL8) |  | 0 | The ability to ensure that a classifier gives reliable confidence scores is essential to ensure informed decision-making. To this end, recent work has focused on miscalibration, i.e., the over or under confidence of model scores. Yet calibration is not enough: even a perfectly calibrated classifier... | Alexandre PerezLebel, Gaël Varoquaux, Marine Le Morvan |  |
| 1668 |  |  [Hybrid RL: Using both offline and online data can make RL efficient](https://openreview.net/forum?id=yyBis80iUuU) |  | 0 | We consider a hybrid reinforcement learning setting (Hybrid RL), in which an agent has access to an offline dataset and the ability to collect experience via real-world online interaction. The framework mitigates the challenges that arise in both pure offline and online RL settings, allowing for... | Akshay Krishnamurthy, Ayush Sekhari, Drew Bagnell, Wen Sun, Yifei Zhou, Yuda Song |  |
| 1669 |  |  [Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning](https://openreview.net/forum?id=p0yrSRbN5Bu) |  | 0 | Prompt tuning approaches, which learn task-specific soft prompts for a downstream task conditioning on frozen pre-trained models, have attracted growing interest due to its parameter efficiency. With large language models and sufficient training data, prompt tuning performs comparably to full-model... | Caiming Xiong, Chen Xing, ChienSheng Wu, Prafulla Kumar Choubey, Xiangyu Peng |  |
| 1670 |  |  [GAIN: On the Generalization of Instructional Action Understanding](https://openreview.net/forum?id=RlPmWBiyp6w) |  | 0 | Despite the great success achieved in instructional action understanding by deep learning and mountainous data, deploying trained models to the unseen environment still remains a great challenge, since it requires strong generalizability of models from in-distribution training data to... | Guangyi Chen, Jie Zhou, Jinan Bao, Jiwen Lu, Junlong Li, Kun Zhang, Yansong Tang |  |
| 1671 |  |  [ManyDG: Many-domain Generalization for Healthcare Applications](https://openreview.net/forum?id=lcSfirnflpW) |  | 0 | The vast amount of health data has been continuously collected for each patient, providing opportunities to support diverse healthcare predictive tasks such as seizure detection and hospitalization prediction. Existing models are mostly trained on other patients’ data and evaluated on new patients.... | Chaoqi Yang, Jimeng Sun, M. Brandon Westover |  |
| 1672 |  |  [DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases](https://openreview.net/forum?id=XHc5zRPxqV9) |  | 0 | Question answering over knowledge bases (KBs) aims to answer natural language questions with factual information such as entities and relations in KBs. Previous methods either generate logical forms that can be executed over KBs to obtain final answers or predict answers directly. Empirical results... | Alexander Hanbo Li, Bing Xiang, Donghan Yu, Henghui Zhu, Jun Wang, Patrick Ng, Sheng Zhang, William Yang Wang, Yiqun Hu, Zhiguo Wang |  |
| 1673 |  |  [NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis](https://openreview.net/forum?id=elDEe8LYW7-) |  | 0 | Various applications of voice synthesis have been developed independently despite the fact that they generate “voice” as output in common. In addition, most of the voice synthesis models still require a large number of audio data paired with annotated labels (e.g., text transcription and music... | HyeongSeok Choi, Hyeongju Kim, Jinhyeok Yang, Juheon Lee |  |
| 1674 |  |  [Causality Compensated Attention for Contextual Biased Visual Recognition](https://openreview.net/forum?id=8XqDnrmZQNF) |  | 0 | Visual attention does not always capture the essential object representation desired for robust predictions. Attention modules tend to underline not only the target object but also the common co-occurring context that the module thinks helpful in the training. The problem is rooted in the... | Ge Li, Jingjia Huang, Ruyang Liu, Thomas H. Li |  |
| 1675 |  |  [Multi-Objective Reinforcement Learning: Convexity, Stationarity and Pareto Optimality](https://openreview.net/forum?id=TjEzIsyEsQ6) |  | 0 | In recent years, single-objective reinforcement learning (SORL) algorithms have received a significant amount of attention and seen some strong results. However, it is generally recognized that many practical problems have intrinsic multi-objective properties that cannot be easily handled by SORL... | Daniel Herman, Haoye Lu, Yaoliang Yu |  |
| 1676 |  |  [Fooling SHAP with Stealthily Biased Sampling](https://openreview.net/forum?id=J4mJjotSauh) |  | 0 | SHAP explanations aim at identifying which features contribute the most to the difference in model prediction at a specific input versus a background distribution. Recent studies have shown that they can be manipulated by malicious adversaries to produce arbitrary desired explanations. However,... | Foutse Khomh, Gabriel Laberge, Mario Marchand, Satoshi Hara, Ulrich Aïvodji |  |
| 1677 |  |  [Asynchronous Gradient Play in Zero-Sum Multi-agent Games](https://openreview.net/forum?id=vPXp7K_Yhre) |  | 0 | Finding equilibria via gradient play in competitive multi-agent games has been attracting a growing amount of attention in recent years, with emphasis on designing efficient strategies where the agents operate in a decentralized and symmetric manner with guaranteed convergence. While significant... | Ruicheng Ao, Shicong Cen, Yuejie Chi |  |
| 1678 |  |  [Novel View Synthesis with Diffusion Models](https://openreview.net/forum?id=HtoA0oT30jC) |  | 0 | We present 3DiM (pronounced "three-dim"), a diffusion model for 3D novel view synthesis from as few as a single image. The core of 3DiM is an image-to-image diffusion model -- 3DiM takes a single reference view and their poses as inputs, and generates a novel view via diffusion. 3DiM can then... | Andrea Tagliasacchi, Daniel Watson, Jonathan Ho, Mohammad Norouzi, Ricardo MartinBrualla, William Chan |  |
| 1679 |  |  [DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images](https://openreview.net/forum?id=C_PRLz8bEJx) |  | 0 | In this paper, we study the problem of 3D scene geometry decomposition and manipulation from 2D views. By leveraging the recent implicit neural representation techniques, particularly the appealing neural radiance fields, we introduce an object field component to learn unique codes for all... | Bing Wang, Bo Yang, Lu Chen |  |
| 1680 |  |  [Trading Information between Latents in Hierarchical Variational Autoencoders](https://openreview.net/forum?id=eWtMdr6yCmL) |  | 0 | Variational Autoencoders (VAEs) were originally motivated as probabilistic generative models in which one performs approximate Bayesian inference. The proposal of $\beta$-VAEs breaks this interpretation and generalizes VAEs to application domains beyond generative modeling (e.g., representation... | Robert Bamler, Tim Z. Xiao |  |
| 1681 |  |  [ISAAC Newton: Input-based Approximate Curvature for Newton's Method](https://openreview.net/forum?id=0paCJSFW7j) |  | 0 | We present ISAAC (Input-baSed ApproximAte Curvature), a novel method that conditions the gradient using selected second-order information and has an asymptotically vanishing computational overhead, assuming a batch size smaller than the number of neurons. We show that it is possible to compute a... | Christian Borgelt, Dongsung Huh, Felix Petersen, Hilde Kuehne, Oliver Deussen, Tobias Sutter, Yuekai Sun |  |
| 1682 |  |  [Learning Human-Compatible Representations for Case-Based Decision Support](https://openreview.net/forum?id=r0xte-t40I) |  | 0 | Algorithmic case-based decision support provides examples to help human make sense of predicted labels and aid human in decision-making tasks. Despite the promising performance of supervised learning, representations learned by supervised models may not align well with human intuitions: what models... | Chacha Chen, Chenhao Tan, Han Liu, Shi Feng, Yizhou Tian, Yuxin Chen |  |
| 1683 |  |  [Long-Tailed Learning Requires Feature Learning](https://openreview.net/forum?id=S-h1oFv-mq) |  | 0 | We propose a simple data model inspired from natural data such as text or images, and use it to study the importance of learning features in order to achieve good generalization. Our data model follows a long-tailed distribution in the sense that some rare and uncommon subcategories have few... | James von Brecht, Thomas Laurent, Xavier Bresson |  |
| 1684 |  |  [How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?](https://openreview.net/forum?id=aEFaE0W5pAd) |  | 0 | Out-of-distribution (OOD) detection is a critical task for reliable machine learning. Recent advances in representation learning give rise to distance-based OOD detection, where testing samples are detected as OOD if they are relatively far away from the centroids or prototypes of in-distribution... | Ousmane Dia, Yifei Ming, Yixuan Li, Yiyou Sun |  |
| 1685 |  |  [AnyDA: Anytime Domain Adaptation](https://openreview.net/forum?id=yyLvxYBJV1B) |  | 0 | Unsupervised domain adaptation is an open and challenging problem in computer vision. While existing research shows encouraging results in addressing cross-domain distribution shift on common benchmarks, they are often constrained to testing under a specific target setting, limiting their impact... | Aadarsh Sahoo, Abir Das, Omprakash Chakraborty, Rameswar Panda |  |
| 1686 |  |  [Improving Deep Regression with Ordinal Entropy](https://openreview.net/forum?id=raU07GpP0P) |  | 0 | In computer vision, it is often observed that formulating regression problems as a classification task yields better performance. We investigate this curious phenomenon and provide a derivation to show that classification, with the cross-entropy loss, outperforms regression with a mean squared... | Angela Yao, Linlin Yang, Michael Bi Mi, Shihao Zhang, Xiaoxu Zheng |  |
| 1687 |  |  [Unified Discrete Diffusion for Simultaneous Vision-Language Generation](https://openreview.net/forum?id=8JqINxA-2a) |  | 0 | The recently developed discrete diffusion model performs extraordinarily well in generation tasks, especially in the text-to-image task, showing great potential for modeling multimodal signals. In this paper, we leverage these properties and present a unified multimodal generation model, which can... | Chaoyue Wang, Chuanxia Zheng, Dacheng Tao, Heliang Zheng, Minghui Hu, Ponnuthurai N. Suganthan, TatJen Cham, Zuopeng Yang |  |
| 1688 |  |  [Iterative Patch Selection for High-Resolution Image Recognition](https://openreview.net/forum?id=QCrw0u9LQ7) |  | 0 | High-resolution images are prevalent in various applications, such as autonomous driving and computer-aided diagnosis. However, training neural networks on such images is computationally challenging and easily leads to out-of-memory errors even on modern GPUs. We propose a simple method, Iterative... | Aravindh Mahendran, Benjamin Bergner, Christoph Lippert |  |
| 1689 |  |  [Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive Machine Translation](https://openreview.net/forum?id=LSz-gQyd0zE) |  | 0 | Non-autoregressive translation (NAT) reduces the decoding latency but suffers from performance degradation due to the multi-modality problem. Recently, the structure of directed acyclic graph has achieved great success in NAT, which tackles the multi-modality problem by introducing dependency... | Chenze Shao, Min Zhang, Shangtong Gui, Yang Feng, Zhengrui Ma |  |
| 1690 |  |  [Efficient Federated Domain Translation](https://openreview.net/forum?id=uhLAcrAZ9cJ) |  | 0 | A central theme in federated learning (FL) is the fact that client data distributions are often not independent and identically distributed (IID), which has strong implications on the training process. While most existing FL algorithms focus on the conventional non-IID setting of class imbalance or... | Christopher G. Brinton, David I. Inouye, Sheikh Shams Azam, Zeyu Zhou |  |
| 1691 |  |  [3D Segmenter: 3D Transformer based Semantic Segmentation via 2D Panoramic Distillation](https://openreview.net/forum?id=4dZeBJ83oxk) |  | 0 | Recently, 2D semantic segmentation has witnessed a significant advancement thanks to the huge amount of 2D image datasets available. Therefore, in this work, we propose the first 2D-to-3D knowledge distillation strategy to enhance 3D semantic segmentation model with knowledge embedded in the latent... | Hiroyuki Sato, Lin Gu, Tatsuya Harada, Yang Li, Yifei Huang, Zhennan Wu |  |
| 1692 |  |  [Clifford Neural Layers for PDE Modeling](https://openreview.net/forum?id=okwxL_c4x84) |  | 0 | Partial differential equations (PDEs) see widespread use in sciences and engineering to describe simulation of physical processes as scalar and vector fields interacting and coevolving over time. Due to the computationally expensive nature of their standard solution methods, neural PDE surrogates... | Jayesh K. Gupta, Johannes Brandstetter, Max Welling, Rianne van den Berg |  |
| 1693 |  |  [GOOD: Exploring geometric cues for detecting objects in an open world](https://openreview.net/forum?id=W-nZDQyuy8D) |  | 0 | We address the task of open-world class-agnostic object detection, i.e., detecting every object in an image by learning from a limited number of base object classes. State-of-the-art RGB-based models suffer from overfitting the training classes and often fail at detecting novel-looking objects.... | Andreas Geiger, Dan Zhang, Haiwen Huang |  |
| 1694 |  |  [TabCaps: A Capsule Neural Network for Tabular Data Classification with BoW Routing](https://openreview.net/forum?id=OgbtSLESnI) |  | 0 | Records in a table are represented by a collection of heterogeneous scalar features. Previous work often made predictions for records in a paradigm that processed each feature as an operating unit, which requires to well cope with the heterogeneity. In this paper, we propose to encapsulate all... | Danny Z. Chen, Jian Wu, Jintai Chen, Kuanlun Liao, Yanwen Fang |  |
| 1695 |  |  [An Exact Poly-Time Membership-Queries Algorithm for Extracting a Three-Layer ReLU Network](https://openreview.net/forum?id=-CoNloheTs) |  | 0 | We consider the natural problem of learning a ReLU network from queries, which was recently remotivated by model extraction attacks. In this work, we present a polynomial-time algorithm that can learn a depth-two ReLU network from queries under mild general position assumptions. We also present a... | Amit Daniely, Elad Granot |  |
| 1696 |  |  [Towards Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated Learning](https://openreview.net/forum?id=EXnIyMVTL8s) |  | 0 | Federated learning aims to train models collaboratively across different clients without sharing data for privacy considerations. However, one major challenge for this learning paradigm is the data heterogeneity problem, which refers to the discrepancies between the local data distributions among... | Jian Liang, Song Bai, Vincent Y. F. Tan, Wenqing Zhang, Yujun Shi |  |
| 1697 |  |  [Evidential Uncertainty and Diversity Guided Active Learning for Scene Graph Generation](https://openreview.net/forum?id=xI1ZTtVOtlz) |  | 0 | Scene Graph Generation (SGG) has already shown its great potential in various downstream tasks, but it comes at the price of a prohibitively expensive annotation process. To reduce the annotation cost, we propose using Active Learning (AL) for sampling the most informative data. However, directly... | Janne Heikkilä, Li Liu, Shuaifeng Zhi, Shuzhou Sun |  |
| 1698 |  |  [Anisotropic Message Passing: Graph Neural Networks with Directional and Long-Range Interactions](https://openreview.net/forum?id=socffUzSIlx) |  | 0 | Graph neural networks have shown great potential for the description of a variety of chemical systems. However, standard message passing does not explicitly account for long-range and directional interactions, for instance due to electrostatics. In this work, an anisotropic state based on Cartesian... | Moritz Thürlemann, Sereina Riniker |  |
| 1699 |  |  [SYNC: Safety-Aware Neural Control for Stabilizing Stochastic Delay-Differential Equations](https://openreview.net/forum?id=_8mS2NE-HXN) |  | 0 | Stabilization of the systems described by \textit{stochastic delay}-differential equations (SDDEs) under preset conditions is a challenging task in the control community. Here, to achieve this task, we leverage neural networks to learn control policies using the information of the controlled... | Jingdong Zhang, Qunxi Zhu, Wei Lin, Wei Yang |  |
| 1700 |  |  [Differentiable Mathematical Programming for Object-Centric Representation Learning](https://openreview.net/forum?id=1J-ZTr7aypY) |  | 0 | We propose topology-aware feature partitioning into $k$ disjoint partitions for given scene features as a method for object-centric representation learning. To this end, we propose to use minimum $s$-$t$ graph cuts as a partitioning method which is represented as a linear program. The method is... | Adeel Pervez, Efstratios Gavves, Phillip Lippe |  |
| 1701 |  |  [Scalable Subset Sampling with Neural Conditional Poisson Networks](https://openreview.net/forum?id=p8hMBcPtvju) |  | 0 | A number of problems in learning can be formulated in terms of the basic primitive of sampling $k$ elements out of a universe of $n$ elements. This subset sampling operation cannot directly be included in differentiable models and approximations are essential. Current approaches take an \emph{order... | Adeel Pervez, Efstratios Gavves, Phillip Lippe |  |
| 1702 |  |  [Improved Convergence of Differential Private SGD with Gradient Clipping](https://openreview.net/forum?id=FRLswckPXQ5) |  | 0 | Differential private stochastic gradient descent (DP-SGD) with gradient clipping (DP-SGD-GC) is an effective optimization algorithm that can train machine learning models with a privacy guarantee. Despite the popularity of DP-SGD-GC, its convergence in unbounded domain without the Lipschitz... | Chenglin Fan, Huang Fang, Ping Li, Xiaoyun Li |  |
| 1703 |  |  [Learning to Estimate Single-View Volumetric Flow Motions without 3D Supervision](https://openreview.net/forum?id=2vmGv5wPDBZ) |  | 0 | We address the challenging problem of jointly inferring the 3D flow and volumetric densities moving in a fluid from a monocular input video with a deep neural network. Despite the complexity of this task, we show that it is possible to train the corresponding networks without requiring any 3D... | Aleksandra Franz, Barbara Solenthaler, Nils Thuerey |  |
| 1704 |  |  [ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations](https://openreview.net/forum?id=n0Pb9T5kmb) |  | 0 | Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data for model training. Empirical studies show that SSL can achieve promising performance in distribution shift scenarios, where the downstream and training distributions differ. However, the theoretical understanding of its... | Jun Yao, Tianqi Du, Weiran Huang, Xuyang Zhao, Yisen Wang |  |
| 1705 |  |  [Temperature Schedules for self-supervised contrastive methods on long-tail data](https://openreview.net/forum?id=ejHUr4nfHhD) |  | 0 | Most approaches for self-supervised learning (SSL) are optimised on curated balanced datasets, e.g. ImageNet, despite the fact that natural data usually exhibits long-tail distributions. In this paper, we analyse the behaviour of one of the most popular variants of SSL, i.e. contrastive methods, on... | Anna Kukleva, Bernt Schiele, Christian Rupprecht, Hilde Kuehne, Moritz Böhle |  |
| 1706 |  |  [Deep Learning on Implicit Neural Representations of Shapes](https://openreview.net/forum?id=OoOIW-3uadi) |  | 0 | Implicit Neural Representations (INRs) have emerged in the last few years as a powerful tool to encode continuously a variety of different signals like images, videos, audio and 3D shapes. When applied to 3D shapes, INRs allow to overcome the fragmentation and shortcomings of the popular discrete... | Adriano Cardace, Luca De Luigi, Luigi Di Stefano, Pierluigi Zama Ramirez, Riccardo Spezialetti, Samuele Salti |  |
| 1707 |  |  [ImaginaryNet: Learning Object Detectors without Real Images and Annotations](https://openreview.net/forum?id=9MbhFHqrti9) |  | 0 | Without the demand of training in reality, humans are able of detecting a new category of object simply based on the language description on its visual characteristics. Empowering deep learning with this ability undoubtedly enables the neural network to handle complex vision tasks, e.g., object... | Kailai Feng, Minheng Ni, Wangmeng Zuo, Zitong Huang |  |
| 1708 |  |  [Contextual bandits with concave rewards, and an application to fair ranking](https://openreview.net/forum?id=UT-_SVOyD1H) |  | 0 | We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective bandit problem where the desired trade-off between the rewards is defined by a known concave objective function, and the reward vector depends on an observed stochastic context. We present the first algorithm with... | Alessandro Lazaric, Elvis Dohmatob, Matteo Pirotta, Nicolas Usunier, Virginie Do |  |
| 1709 |  |  [Gradient Boosting Performs Gaussian Process Inference](https://openreview.net/forum?id=3VKiaagxw1S) |  | 0 | This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridge Regression problem. Thus, we obtain the convergence to a Gaussian Process' posterior mean, which, in turn, allows us... | Aleksei Ustimenko, Artem Beliakov, Liudmila Prokhorenkova |  |
| 1710 |  |  [Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased](https://openreview.net/forum?id=TrwE8l9aJzs) |  | 0 | There is a recent trend of applying multi-agent reinforcement learning (MARL) to train an agent that can cooperate with humans in a zero-shot fashion without using any human data. The typical workflow is to first repeatedly run self-play (SP) to build a policy pool and then train the final adaptive... | Botian Xu, Chao Yu, Hao Tang, Jiaqi Yang, Jiaxuan Gao, Weilin Liu, Yi Wu, Yu Wang |  |
| 1711 |  |  [Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN](https://openreview.net/forum?id=ZW5aK4yCRqU) |  | 0 | Performant Convolutional Neural Network (CNN) architectures must be tailored to specific tasks in order to consider the length, resolution, and dimensionality of the input data. In this work, we tackle the need for problem-specific CNN architectures. We present the Continuous Convolutional Neural... | Albert Gu, David M. Knigge, David W. Romero, Efstratios Gavves, Erik J. Bekkers, Jakub Mikolaj Tomczak, JanJakob Sonke, Mark Hoogendoorn |  |
| 1712 |  |  [Planckian Jitter: countering the color-crippling effects of color jitter on self-supervised training](https://openreview.net/forum?id=Pia70sP2Oi1) |  | 0 | Several recent works on self-supervised learning are trained by mapping different augmentations of the same image to the same feature representation. The data augmentations used are of crucial importance to the quality of learned feature representations. In this paper, we analyze how the color... | Alex GomezVilla, Andrew D. Bagdanov, Bartlomiej Twardowski, Joost van de Weijer, Marco Buzzelli, Simone Zini |  |
| 1713 |  |  [GAMR: A Guided Attention Model for (visual) Reasoning](https://openreview.net/forum?id=iLMgk2IGNyv) |  | 0 | Humans continue to outperform modern AI systems in their ability to flexibly parse and understand complex visual scenes. Here, we present a novel module for visual reasoning, the Guided Attention Model for (visual) Reasoning ($\textit{GAMR}$), which instantiates an active vision theory -- positing... | Mohit Vaishnav, Thomas Serre |  |
| 1714 |  |  [Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding](https://openreview.net/forum?id=IpGgfpMucHj) |  | 0 | Multi-view projection methods have demonstrated promising performance on 3D understanding tasks like 3D classification and segmentation. However, it remains unclear how to combine such multi-view methods with the widely available 3D point clouds. Previous methods use unlearned heuristics to combine... | Abdullah Hamdi, Bernard Ghanem, Silvio Giancola |  |
| 1715 |  |  [Approximate Nearest Neighbor Search through Modern Error-Correcting Codes](https://openreview.net/forum?id=-jP_rDkyfpI) |  | 0 | A locality-sensitive hash (or LSH) is a function that can efficiently map dataset points into a latent space while preserving pairwise distances. Such LSH functions have been used in approximate nearest-neighbor search (ANNS) in the following classic way, which we call classic hash clustering... | Nissim Halabi, Noam Touitou |  |
| 1716 |  |  [When to Make and Break Commitments?](https://openreview.net/forum?id=q8vgHfPdoQP) |  | 0 | In many scenarios, decision-makers must commit to long-term actions until their resolution before receiving the payoff of said actions, and usually, staying committed to such actions incurs continual costs. For instance, in healthcare, a newly-discovered treatment cannot be marketed to patients... | Alihan Hüyük, Mihaela van der Schaar, Zhaozhi Qian |  |
| 1717 |  |  [Dense RGB Slam with Neural Implicit Maps](https://openreview.net/forum?id=QUK1ExlbbA) |  | 0 | There is an emerging trend of using neural implicit functions for map representation in Simultaneous Localization and Mapping (SLAM). Some pioneer works have achieved encouraging results on RGB-D SLAM. In this paper, we present a dense RGB SLAM method with neural implicit map representation. To... | Heng Li, Luwei Yang, Ping Tan, Weihao Yuan, Xiaodong Gu, Zilong Dong |  |
| 1718 |  |  [Monocular Scene Reconstruction with 3D SDF Transformers](https://openreview.net/forum?id=-iADdfa4GKH) |  | 0 | Monocular scene reconstruction from posed images is challenging due to the complexity of a large environment. Recent volumetric methods learn to directly predict the TSDF volume and have demonstrated promising results in this task. However, most methods focus on how to extract and fuse the 2D... | Heng Li, Siyu Zhu, Weihao Yuan, Xiaodong Gu, Zilong Dong |  |
| 1719 |  |  [Learning Heterogeneous Interaction Strengths by Trajectory Prediction with Graph Neural Network](https://openreview.net/forum?id=qU6NIcpaSi-) |  | 0 | Dynamical systems with interacting agents are universal in nature, commonly modeled by a graph of relationships between their constituents. Recently, various works have been presented to tackle the problem of inferring those relationships from the system trajectories via deep neural networks, but... | Hawoong Jeong, Seungwoong Ha |  |
| 1720 |  |  [From $t$-SNE to UMAP with contrastive learning](https://openreview.net/forum?id=B8a1FcY0vi) |  | 0 | Neighbor embedding methods $t$-SNE and UMAP are the de facto standard for visualizing high-dimensional datasets. Motivated from entirely different viewpoints, their loss functions appear to be unrelated. In practice, they yield strongly differing embeddings and can suggest conflicting... | Dmitry Kobak, Fred A. Hamprecht, Jan Niklas Böhm, Sebastian Damrich |  |
| 1721 |  |  [D4AM: A General Denoising Framework for Downstream Acoustic Models](https://openreview.net/forum?id=5fvXH49wk2) |  | 0 | The performance of acoustic models degrades notably in noisy environments. Speech enhancement (SE) can be used as a front-end strategy to aid automatic speech recognition (ASR) systems. However, existing training objectives of SE methods are not fully effective at integrating speech-text and... | ChiChang Lee, ChuSong Chen, HsinMin Wang, Yu Tsao |  |
| 1722 |  |  [Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://openreview.net/forum?id=lq62uWRJjiY) |  | 0 | Fine-tuning large pre-trained language models on downstream tasks has become an important paradigm in NLP. However, common practice fine-tunes all of the parameters in a pre-trained model, which becomes prohibitive when a large number of downstream tasks are present. Therefore, many fine-tuning... | Alexander Bukharin, Minshuo Chen, Pengcheng He, Qingru Zhang, Tuo Zhao, Weizhu Chen, Yu Cheng |  |
| 1723 |  |  [Generalize Learned Heuristics to Solve Large-scale Vehicle Routing Problems in Real-time](https://openreview.net/forum?id=6ZajpxqTlQ) |  | 0 | Large-scale Vehicle Routing Problems (VRPs) are widely used in logistics, transportation, supply chain, and robotic systems. Recently, data-driven VRP heuristics are proposed to generate real-time VRP solutions with up to 100 nodes. Despite this progress, current heuristics for large-scale VRPs... | Jingwei Yang, Qingchun Hou, Xiaoqing Wang, Yiqiang Su, Yuming Deng |  |
| 1724 |  |  [Towards the Generalization of Contrastive Self-Supervised Learning](https://openreview.net/forum?id=XDJwuEYHhme) |  | 0 | Recently, self-supervised learning has attracted great attention, since it only requires unlabeled data for model training. Contrastive learning is one popular method for self-supervised learning and has achieved promising empirical performance. However, the theoretical understanding of its... | Mingyang Yi, Weiran Huang, Xuyang Zhao, Zihao Jiang |  |
| 1725 |  |  [CO3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving](https://openreview.net/forum?id=QUaDoIdgo0) |  | 0 | Unsupervised contrastive learning for indoor-scene point clouds has achieved great successes. However, unsupervised representation learning on outdoor-scene point clouds remains challenging because previous methods need to reconstruct the whole scene and capture partial views for the contrastive... | Chenhan Jiang, Hang Xu, Ping Luo, Runjian Chen, Runsen Xu, Wenqi Shao, Yao Mu, Yu Qiao, Zhenguo Li |  |
| 1726 |  |  [Bag of Tricks for Unsupervised Text-to-Speech](https://openreview.net/forum?id=SbR9mpTuBn) |  | 0 | Unsupervised text-to-speech (TTS) aims to train TTS models for a specific language without any paired speech-text training data in that language. Existing methods either use speech and corresponding pseudo text generated by an unsupervised automatic speech recognition (ASR) model as training data,... | Chen Zhang, Shuicheng Yan, Yi Ren |  |
| 1727 |  |  [FedSpeed: Larger Local Interval, Less Communication Round, and Higher Generalization Accuracy](https://openreview.net/forum?id=bZjxxYURKT) |  | 0 | Federated learning (FL) is an emerging distributed machine learning framework which jointly trains a global model via a large number of local devices with data privacy protections. Its performance suffers from the non-vanishing biases introduced by the local inconsistent optimal and the rugged... | Dacheng Tao, Li Shen, Liang Ding, Tiansheng Huang, Yan Sun |  |
| 1728 |  |  [Advancing Radiograph Representation Learning with Masked Record Modeling](https://openreview.net/forum?id=w-x7U26GM7j) |  | 0 | Modern studies in radiograph representation learning (R$^2$L) rely on either self-supervision to encode invariant semantics or associated radiology reports to incorporate medical expertise, while the complementarity between them is barely noticed. To explore this, we formulate the self- and... | Chenyu Lian, HongYu Zhou, Liansheng Wang, Yizhou Yu |  |
| 1729 |  |  [Instance-wise Batch Label Restoration via Gradients in Federated Learning](https://openreview.net/forum?id=FIrQfNSOoTr) |  | 0 | Gradient inversion attacks have posed a serious threat to the privacy of federated learning. The attacks search for the optimal pair of input and label best matching the shared gradients and the search space of the attacks can be reduced by pre-restoring labels. Recently, label restoration... | Dawei Li, Jian Cui, Jianwei Liu, Kailang Ma, Yu Sun, Zhenyu Guan |  |
| 1730 |  |  [Re-parameterizing Your Optimizers rather than Architectures](https://openreview.net/forum?id=B92TMCG_7rp) |  | 0 | The well-designed structures in neural networks reflect the prior knowledge incorporated into the models. However, though different models have various priors, we are used to training them with model-agnostic optimizers such as SGD. In this paper, we propose to incorporate model-specific prior... | Guiguang Ding, Honghao Chen, Jungong Han, Kaiqi Huang, Xiangyu Zhang, Xiaohan Ding |  |
| 1731 |  |  [Protein Representation Learning via Knowledge Enhanced Primary Structure Reasoning](https://openreview.net/forum?id=VbCMhg7MRmj) |  | 0 | Protein representation learning has primarily benefited from the remarkable development of language models (LMs). Accordingly, pre-trained protein models also suffer from a problem in LMs: a lack of factual knowledge. The recent solution models the relationships between protein and associated... | Cheng Bian, HongYu Zhou, Yizhou Yu, Yunxiang Fu, Zhicheng Zhang |  |
| 1732 |  |  [The Provable Benefit of Unsupervised Data Sharing for Offline Reinforcement Learning](https://openreview.net/forum?id=MTTPLcwvqTt) |  | 0 | Self-supervised methods have become crucial for advancing deep learning by leveraging data itself to reduce the need for expensive annotations. However, the question of how to conduct self-supervised offline reinforcement learning (RL) in a principled way remains unclear. In this paper, we address... | Chongjie Zhang, Hao Hu, Qianchuan Zhao, Yiqin Yang |  |
| 1733 |  |  [Modeling Sequential Sentence Relation to Improve Cross-lingual Dense Retrieval](https://openreview.net/forum?id=-bVsNeR56KS) |  | 0 | Recently multi-lingual pre-trained language models (PLM) such as mBERT and XLM-R have achieved impressive strides in cross-lingual dense retrieval. Despite its successes, they are general-purpose PLM while the multilingual PLM tailored for cross-lingual retrieval is still unexplored. Motivated by... | Daxin Jiang, Ming Gong, Nan Duan, Shunyu Zhang, Yaobo Liang |  |
| 1734 |  |  [DepthFL : Depthwise Federated Learning for Heterogeneous Clients](https://openreview.net/forum?id=pf8RIZTMU58) |  | 0 | Federated learning is for training a global model without collecting private local data from clients. As they repeatedly need to upload locally-updated weights or gradients instead, clients require both computation and communication resources enough to participate in learning, but in reality their... | Minjae Kim, Sangyoon Yu, SooMook Moon, Suhyun Kim |  |
| 1735 |  |  [Masked Image Modeling with Denoising Contrast](https://openreview.net/forum?id=1fZd4owfJP6) |  | 0 | Since the development of self-supervised visual representation learning from contrastive learning to masked image modeling (MIM), there is no significant difference in essence, that is, how to design proper pretext tasks for vision dictionary look-up. MIM recently dominates this line of research... | Dian Li, Jianping Wu, Kun Yi, Shusheng Yang, Xiaohu Qie, Xiaotong Li, Ying Shan, Yixiao Ge |  |
| 1736 |  |  [GoBigger: A Scalable Platform for Cooperative-Competitive Multi-Agent Interactive Simulation](https://openreview.net/forum?id=NnOZT_CR26Z) |  | 0 | The emergence of various multi-agent environments has motivated powerful algorithms to explore agents' cooperation or competition. Even though this has greatly promoted the development of multi-agent reinforcement learning (MARL), it is still not enough to support further exploration on the... | Chao Yang, Chuming Li, Hang Zhou, Jinliang Zheng, Lekai Chen, Ming Zhang, Shenghan Zhang, Yazhe Niu, Yu Liu, Zhenjie Yang |  |
| 1737 |  |  [Masked Unsupervised Self-training for Label-free Image Classification](https://openreview.net/forum?id=ZAKkiVxiAM9) |  | 0 | State-of-the-art computer vision models are mostly trained with supervised learning using human-labeled images, which limits their scalability due to the expensive annotation cost. While self-supervised representation learning has achieved impressive progress, it still requires a second stage of... | Junnan Li, Silvio Savarese, Steven C. H. Hoi |  |
| 1738 |  |  [GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://openreview.net/forum?id=YfwMIDhPccD) |  | 0 | Generating photo-realistic video portraits with arbitrary speech audio is a crucial problem in film-making and virtual reality. Recently, several works explore the usage of neural radiance field (NeRF) in this task to improve 3D realness and image fidelity. However, the generalizability of previous... | Jinglin Liu, Jinzheng He, Yi Ren, Zhenhui Ye, Zhou Zhao, Ziyue Jiang |  |
| 1739 |  |  [DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection](https://openreview.net/forum?id=3mRwyG5one) |  | 0 | We present DINO (DETR with Improved deNoising anchOr boxes), a strong end-to-end object detector. DINO improves over previous DETR-like models in performance and efficiency by using a contrastive way for denoising training, a look forward twice scheme for box prediction, and a mixed query selection... | Feng Li, Hang Su, Hao Zhang, HeungYeung Shum, Jun Zhu, Lei Zhang, Lionel M. Ni, Shilong Liu |  |
| 1740 |  |  [Revisiting Graph Adversarial Attack and Defense From a Data Distribution Perspective](https://openreview.net/forum?id=dSYoPjM5J_W) |  | 0 | Recent studies have shown that structural perturbations are significantly effective in degrading the accuracy of Graph Neural Networks (GNNs) in the semi-supervised node classification (SSNC) task. However, why the gradient-based methods are so destructive is rarely explored. In this work, we... | Kuan Li, Qing He, Xiang Ao, Yang Liu |  |
| 1741 |  |  [Provable Sim-to-real Transfer in Continuous Domain with Partial Observations](https://openreview.net/forum?id=S31oTB72m0G) |  | 0 | Sim-to-real transfer, which trains RL agents in the simulated environments and then deploys them in the real world, has been widely used to overcome the limitations of gathering samples in the real world. Despite the empirical success of the sim-to-real transfer, its theoretical foundation is much... | Chi Jin, Han Zhong, Jiachen Hu, Liwei Wang |  |
| 1742 |  |  [Globally Optimal Training of Neural Networks with Threshold Activation Functions](https://openreview.net/forum?id=_9k5kTgyHT) |  | 0 | Threshold activation functions are highly preferable in neural networks due to their efficiency in hardware implementations. Moreover, their mode of operation is more interpretable and resembles that of biological neurons. However, traditional gradient based algorithms such as Gradient Descent... | Halil Ibrahim Gulluk, Jonathan Lacotte, Mert Pilanci, Tolga Ergen |  |
| 1743 |  |  [Molecule Generation For Target Protein Binding with Structural Motifs](https://openreview.net/forum?id=Rq13idF0F73) |  | 0 | Designing ligand molecules that bind to specific protein binding sites is a fundamental problem in structure-based drug design. Although deep generative models and geometric deep learning have made great progress in drug design, existing works either sample in the 2D graph space or fail to generate... | Qi Liu, Shuxin Zheng, Yaosen Min, Zaixi Zhang |  |
| 1744 |  |  [Towards Robustness Certification Against Universal Perturbations](https://openreview.net/forum?id=7GEvPKxjtt) |  | 0 | In this paper, we investigate the problem of certifying neural network robustness against universal perturbations (UPs), which have been widely used in universal adversarial attacks and backdoor attacks. Existing robustness certification methods aim to provide robustness guarantees for each sample... | ChoJui Hsieh, Feiyang Kang, Lingjuan Lyu, Ming Jin, Ruoxi Jia, Yi Zeng, Zhouxing Shi |  |
| 1745 |  |  [Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models](https://openreview.net/forum?id=M9u_ctqFUlg) |  | 0 | Deep generative models (DGMs) are data-eager because learning a complex model on limited data suffers from a large variance and easily overfits. Inspired by the classical perspective of the bias-variance tradeoff, we propose regularized deep generative model (Reg-DGM), which leverages a... | Chongxuan Li, Fan Bao, Hongtao Liu, Weiran Shen, Xiaodong Liu, Yong Zhong |  |
| 1746 |  |  [Basic Binary Convolution Unit for Binarized Image Restoration Network](https://openreview.net/forum?id=h8T5dZWTZ-Z) |  | 0 | Lighter and faster image restoration (IR) models are crucial for the deployment on resource-limited devices. Binary neural network (BNN), one of the most promising model compression methods, can dramatically reduce the computations and parameters of full-precision convolutional neural networks... | Bin Xia, Luc Van Gool, Radu Timofte, Wenming Yang, Yapeng Tian, Yitong Wang, Yulun Zhang |  |
| 1747 |  |  [Multimodal Federated Learning via Contrastive Representation Ensemble](https://openreview.net/forum?id=Hnk1WRMAYqg) |  | 0 | With the increasing amount of multimedia data on modern mobile systems and IoT infrastructures, harnessing these rich multimodal data without breaching user privacy becomes a critical issue. Federated learning (FL) serves as a privacy-conscious alternative to centralized machine learning. However,... | Jingjing Liu, Ke Xu, Qiying Yu, Yang Liu, Yimu Wang |  |
| 1748 |  |  [Eva: Practical Second-order Optimization with Kronecker-vectorized Approximation](https://openreview.net/forum?id=_Mic8V96Voy) |  | 0 | Second-order optimization algorithms exhibit excellent convergence properties for training deep learning models, but often incur significant computation and memory overheads. This can result in lower training efficiency than the first-order counterparts such as stochastic gradient descent (SGD). In... | Bo Li, Lin Zhang, Shaohuai Shi |  |
| 1749 |  |  [Can CNNs Be More Robust Than Transformers?](https://openreview.net/forum?id=TKIFuQHHECj) |  | 0 | The recent success of Vision Transformers is shaking the long dominance of Convolutional Neural Networks (CNNs) in image recognition for a decade. Specifically, in terms of robustness on out-of-distribution samples, recent research finds that Transformers are inherently more robust than CNNs,... | Cihang Xie, Yutong Bai, Yuyin Zhou, Zeyu Wang |  |
| 1750 |  |  [Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation](https://openreview.net/forum?id=-RwZOVybbj) |  | 0 | We study the risk-aware reinforcement learning (RL) problem in the episodic finite-horizon Markov decision process with unknown transition and reward functions. In contrast to the risk-neutral RL problem, we consider minimizing the risk of having low rewards, which arise due to the intrinsic... | Arun Verma, Bryan Kian Hsiang Low, Patrick Jaillet, Thanh Lam |  |
| 1751 |  |  [Bi-level Physics-Informed Neural Networks for PDE Constrained Optimization using Broyden's Hypergradients](https://openreview.net/forum?id=kkpL4zUXtiw) |  | 0 | Deep learning based approaches like Physics-informed neural networks (PINNs) and DeepONets have shown promise on solving PDE constrained optimization (PDECO) problems. However, existing methods are insufficient to handle those PDE constraints that have a complicated or nonlinear dependency on... | Chengyang Ying, Hang Su, Jian Song, Jun Zhu, Ze Cheng, Zhongkai Hao |  |
| 1752 |  |  [On the Saturation Effect of Kernel Ridge Regression](https://openreview.net/forum?id=tFvr-kYWs_Y) |  | 0 | The saturation effect refers to the phenomenon that the kernel ridge regression (KRR) fails to achieve the information theoretical lower bound when the smoothness of the underground truth function exceeds certain level. The saturation effect has been widely observed in practices and a saturation... | Haobo Zhang, Qian Lin, Yicheng Li |  |
| 1753 |  |  [Protein Representation Learning by Geometric Structure Pretraining](https://openreview.net/forum?id=to3qCB3tOh9) |  | 0 | Learning effective protein representations is critical in a variety of tasks in biology such as predicting protein function or structure. Existing approaches usually pretrain protein language models on a large number of unlabeled amino acid sequences and then finetune the models with some labeled... | Arian Rokkum Jamasb, Aurélie C. Lozano, Jian Tang, Minghao Xu, Payel Das, Vijil Chenthamarakshan, Zuobai Zhang |  |
| 1754 |  |  [Trainable Weight Averaging: Efficient Training by Optimizing Historical Solutions](https://openreview.net/forum?id=8wbnpOJY-f) |  | 0 | Stochastic gradient descent (SGD) and its variants are considered as the de-facto methods to train deep neural networks (DNNs). While recent improvements to SGD mainly focus on the descent algorithm itself, few works pay attention to utilizing the historical solutions---as an iterative method, SGD... | Qinghua Tao, Tao Li, Xiaolin Huang, Yingwen Wu, Zhehao Huang |  |
| 1755 |  |  [Deep Declarative Dynamic Time Warping for End-to-End Learning of Alignment Paths](https://openreview.net/forum?id=UClBPxIZqnY) |  | 0 | This paper addresses learning end-to-end models for time series data that include a temporal alignment step via dynamic time warping (DTW). Existing approaches to differentiable DTW either differentiate through a fixed warping path or apply a differentiable relaxation to the min operator found in... | Michael Milford, Ming Xu, Sourav Garg, Stephen Gould |  |
| 1756 |  |  [Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning](https://openreview.net/forum?id=3itjR9QxFw) |  | 0 | We present Bit Diffusion: a simple and generic approach for generating discrete data with continuous state and continuous time diffusion models. The main idea behind our approach is to first represent the discrete data as binary bits, and then train a continuous diffusion model to model these bits... | Geoffrey E. Hinton, Ruixiang Zhang, Ting Chen |  |
| 1757 |  |  [Understanding Edge-of-Stability Training Dynamics with a Minimalist Example](https://openreview.net/forum?id=p7EagBsMAEO) |  | 0 | Recently, researchers observed that gradient descent for deep neural networks operates in an \`\`edge-of-stability'' (EoS) regime: the sharpness (maximum eigenvalue of the Hessian) is often larger than stability threshold $2/\eta$ (where $\eta$ is the step size). Despite this, the loss oscillates... | Mo Zhou, Rong Ge, Xiang Wang, Xingyu Zhu, Zixuan Wang |  |
| 1758 |  |  [Learning Proximal Operators to Discover Multiple Optima](https://openreview.net/forum?id=PzBGIu-llo7) |  | 0 | Finding multiple solutions of non-convex optimization problems is a ubiquitous yet challenging task. Most past algorithms either apply single-solution optimization methods from multiple random initial guesses or search in the vicinity of found solutions using ad hoc heuristics. We present an... | Jiajin Li, Justin Solomon, Kristjan H. Greenewald, Lingxiao Li, Mikhail Yurochkin, Noam Aigerman, Vladimir G. Kim |  |
| 1759 |  |  [Guiding continuous operator learning through Physics-based boundary constraints](https://openreview.net/forum?id=gfWNItGOES6) |  | 0 | Boundary conditions (BCs) are important groups of physics-enforced constraints that are necessary for solutions of Partial Differential Equations (PDEs) to satisfy at specific spatial locations. These constraints carry important physical meaning, and guarantee the existence and the uniqueness of... | Danielle C. Maddix, Gaurav Gupta, Nadim Saad, Shima Alizadeh |  |
| 1760 |  |  [Neural Radiance Field Codebooks](https://openreview.net/forum?id=mX56bKDybu5) |  | 0 | Compositional representations of the world are a promising step towards enabling high-level scene understanding and efficient transfer to downstream tasks. Learning such representations for complex scenes and tasks remains an open challenge. Towards this goal, we introduce Neural Radiance Field... | Aditya Kusupati, Alex Fang, Ali Farhadi, Aniruddha Kembhavi, Matthew Wallingford, Roozbeh Mottaghi, Vivek Ramanujan |  |
| 1761 |  |  [Generalized Precision Matrix for Scalable Estimation of Nonparametric Markov Networks](https://openreview.net/forum?id=qBvBycTqVJ) |  | 0 | A Markov network characterizes the conditional independence structure, or Markov property, among a set of random variables. Existing work focuses on specific families of distributions (e.g., exponential families) and/or certain structures of graphs, and most of them can only handle variables of a... | Ignavier Ng, Kun Zhang, Yewen Fan, Yujia Zheng |  |
| 1762 |  |  [FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification](https://openreview.net/forum?id=9aokcgBVIj1) |  | 0 | Modern deep learning systems are increasingly deployed in situations such as personalization and federated learning where it is necessary to support i) learning on small amounts of data, and ii) communication efficient distributed training protocols. In this work, we develop FiLM Transfer (FiT)... | Aliaksandra Shysheya, John Bronskill, Massimiliano Patacchiola, Richard E. Turner, Sebastian Nowozin |  |
| 1763 |  |  [Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation](https://openreview.net/forum?id=1-MBdJssZ-S) |  | 0 | Diffusion probabilistic models (DPMs) have become a popular approach to conditional generation, due to their promising results and support for cross-modal synthesis. A key desideratum in conditional synthesis is to achieve high correspondence between the conditioning input and generated output.... | Jian Ren, Kyle Olszewski, Sergey Tulyakov, Yan Yan, Ye Zhu, Yu Wu |  |
| 1764 |  |  [Diffusion Probabilistic Modeling of Protein Backbones in 3D for the motif-scaffolding problem](https://openreview.net/forum?id=6TxBxqNME1Y) |  | 0 | Construction of a scaffold structure that supports a desired motif, conferring protein function, shows promise for the design of vaccines and enzymes. But a general solution to this motif-scaffolding problem remains open. Current machine-learning techniques for scaffold design are either limited to... | Brian L. Trippe, David Baker, Doug Tischer, Jason Yim, Regina Barzilay, Tamara Broderick, Tommi S. Jaakkola |  |
| 1765 |  |  [NeRF-SOS: Any-View Self-supervised Object Segmentation on Complex Scenes](https://openreview.net/forum?id=kfOtMqYJlUU) |  | 0 | Neural volumetric representations have shown the potential that Multi-layer Perceptrons (MLPs) can be optimized with multi-view calibrated images to represent scene geometry and appearance without explicit 3D supervision. Object segmentation can enrich many downstream applications based on the... | Dejia Xu, Peihao Wang, Xinyu Gong, Yifan Jiang, Zhangyang Wang, Zhiwen Fan |  |
| 1766 |  |  [Rethinking Graph Lottery Tickets: Graph Sparsity Matters](https://openreview.net/forum?id=fjh7UGQgOB) |  | 0 | Lottery Ticket Hypothesis (LTH) claims the existence of a winning ticket (i.e., a properly pruned sub-network together with original weight initialization) that can achieve competitive performance to the original dense network. A recent work, called UGS, extended LTH to prune graph neural networks... | Bo Hui, Da Yan, WeiShinn Ku, Xiaolong Ma |  |
| 1767 |  |  [Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses](https://openreview.net/forum?id=TVY6GoURrw) |  | 0 | This paper studies federated learning (FL)—especially cross-silo FL—with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person’s data (e.g. medical record),... | Andrew Lowy, Meisam Razaviyayn |  |
| 1768 |  |  [Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning](https://openreview.net/forum?id=cddbeL1HWaD) |  | 0 | By enabling agents to communicate, recent cooperative multi-agent reinforcement learning (MARL) methods have demonstrated better task performance and more coordinated behavior. Most existing approaches facilitate inter-agent communication by allowing agents to send messages to each other through... | Christian Schröder de Witt, Jakob Nicolaus Foerster, Samuel Sokota, Shimon Whiteson, Yat Long Lo |  |
| 1769 |  |  [Reversible Column Networks](https://openreview.net/forum?id=Oc2vlWU0jFY) |  | 0 | We propose a new neural network design paradigm Reversible Column Network (RevCol). The main body of RevCol is composed of multiple copies of subnetworks, named columns respectively, between which multi-level reversible connections are employed. Such architectural scheme attributes RevCol very... | Jianjian Sun, Jun Li, Qi Han, Xiangwen Kong, Xiangyu Zhang, Yizhuang Zhou, Yuxuan Cai |  |
| 1770 |  |  [Modeling Multimodal Aleatoric Uncertainty in Segmentation with Mixture of Stochastic Experts](https://openreview.net/forum?id=KE_wJD2RK4) |  | 0 | Equipping predicted segmentation with calibrated uncertainty is essential for safety-critical applications. In this work, we focus on capturing the data-inherent uncertainty (aka aleatoric uncertainty) in segmentation, typically when ambiguities exist in input images. Due to the high-dimensional... | Chuyu Zhang, Xuming He, Yucong Chen, Zhitong Gao |  |
| 1771 |  |  [On the Robustness of Safe Reinforcement Learning under Observational Perturbations](https://openreview.net/forum?id=jbIYfq4Tr-) |  | 0 | Safe reinforcement learning (RL) trains a policy to maximize the task reward while satisfying safety constraints. While prior works focus on the performance optimality, we find that the optimal solutions of many safe RL problems are not robust and safe against carefully designed observational... | Bo Li, Ding Zhao, Huan Zhang, Jie Tan, Zhepeng Cen, Zijian Guo, Zuxin Liu |  |
| 1772 |  |  [Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis Function Decomposition](https://openreview.net/forum?id=TPiwkItUSu) |  | 0 | This work analyzes the solution trajectory of gradient-based algorithms via a novel basis function decomposition. We show that, although solution trajectories of gradient-based algorithms may vary depending on the learning task, they behave almost monotonically when projected onto an appropriate... | Jianhao Ma, Lingjun Guo, Salar Fattahi |  |
| 1773 |  |  [What Is Missing in IRM Training and Evaluation? Challenges and Solutions](https://openreview.net/forum?id=MjsDeTcDEy) |  | 0 | Invariant risk minimization (IRM) has received increasing attention as a way to acquire environment-agnostic data representations and predictions, and also a principled solution for preventing spurious correlations from being learned and improving models’ out-of-distribution generalization. Yet,... | Kush R. Varshney, Mingyi Hong, Parikshit Ram, Pranay Sharma, Sijia Liu, Yihua Zhang |  |
| 1774 |  |  [Multi-task Self-supervised Graph Neural Networks Enable Stronger Task Generalization](https://openreview.net/forum?id=1tHAZRqftM) |  | 0 | Self-supervised learning (SSL) for graph neural networks (GNNs) has attracted increasing attention from the graph machine learning community in recent years, owing to its capability to learn performant node embeddings without costly label information. One weakness of conventional SSL frameworks for... | Chuxu Zhang, Mingxuan Ju, Neil Shah, Qianlong Wen, Tong Zhao, Wenhao Yu, Yanfang Ye |  |
| 1775 |  |  [Analyzing Tree Architectures in Ensembles via Neural Tangent Kernel](https://openreview.net/forum?id=V_06QV-kZX) |  | 0 | A soft tree is an actively studied variant of a decision tree that updates splitting rules using the gradient method. Although soft trees can take various architectures, their impact is not theoretically well known. In this paper, we formulate and analyze the Neural Tangent Kernel (NTK) induced by... | Mahito Sugiyama, Ryuichi Kanoh |  |
| 1776 |  |  [Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders](https://openreview.net/forum?id=7sn6Vxp92xV) |  | 0 | Masked image modeling (MIM) has become a popular strategy for self-supervised learning (SSL) of visual representations with Vision Transformers. A representative MIM model, the masked auto-encoder (MAE), randomly masks a subset of image patches and reconstructs the masked patches given the unmasked... | Jeffrey Ryan Willette, Jonghee Kim, Juho Lee, Sung Ju Hwang, Youngwan Lee |  |
| 1777 |  |  [Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks](https://openreview.net/forum?id=BrJATVZDWEH) |  | 0 | The field of Natural Language Processing (NLP) has experienced a dramatic leap in capabilities with the recent introduction of huge Language Models (LMs). Despite this success, natural language problems that involve several compounded steps are still practically unlearnable, even by the largest... | Amnon Shashua, Noam Wies, Yoav Levine |  |
| 1778 |  |  [Evaluating Long-Term Memory in 3D Mazes](https://openreview.net/forum?id=yHLvIlE9RGN) |  | 0 | Intelligent agents need to remember salient information to reason in partially-observed environments. For example, agents with a first-person view should remember the positions of relevant objects even if they go out of view. Similarly, to effectively navigate through rooms agents need to remember... | Danijar Hafner, Jurgis Pasukonis, Timothy P. Lillicrap |  |
| 1779 |  |  [Proactive Multi-Camera Collaboration for 3D Human Pose Estimation](https://openreview.net/forum?id=CPIy9TWFYBG) |  | 0 | This paper presents a multi-agent reinforcement learning (MARL) scheme for proactive Multi-Camera Collaboration in 3D Human Pose Estimation in dynamic human crowds. Traditional fixed-viewpoint multi-camera solutions for human motion capture (MoCap) are limited in capture space and susceptible to... | Fangwei Zhong, Hai Ci, Mickel Liu, Xuehai Pan, Yizhou Wang |  |
| 1780 |  |  [Become a Proficient Player with Limited Data through Watching Pure Videos](https://openreview.net/forum?id=Sy-o2N0hF4f) |  | 0 | Recently, RL has shown its strong ability for visually complex tasks. However, it suffers from the low sample efficiency and poor generalization ability, which prevent RL from being useful in real-world scenarios. Inspired by the huge success of unsupervised pre-training methods on language and... | Pieter Abbeel, Weirui Ye, Yang Gao, Yunsheng Zhang |  |
| 1781 |  |  [Human MotionFormer: Transferring Human Motions with Vision Transformers](https://openreview.net/forum?id=lQVpasnQS62) |  | 0 | Human motion transfer aims to transfer motions from a target dynamic person to a source static one for motion synthesis. An accurate matching between the source person and the target motion in both large and subtle motion changes is vital for improving the transferred motion quality. In this paper,... | Chenbin Jin, Faqiang Wang, Haoye Dong, Hongyu Liu, Huawei Wei, Jia Xu, Lihui Qian, Qifeng Chen, Xintong Han, Yibing Song, Zhe Lin |  |
| 1782 |  |  [Backstepping Temporal Difference Learning](https://openreview.net/forum?id=YPChvOgRXRA) |  | 0 | Off-policy learning ability is an important feature of reinforcement learning (RL) for practical applications. However, even one of the most elementary RL algorithms, temporal-difference (TD) learning, is known to suffer form divergence issue when the off-policy scheme is used together with linear... | Donghwan Lee, HanDong Lim |  |
| 1783 |  |  [A General Rank Preserving Framework for Asymmetric Image Retrieval](https://openreview.net/forum?id=dYHYXZ3uGdQ) |  | 0 | Asymmetric image retrieval aims to deploy compatible models on platforms of different resources to achieve a balance between computational efficiency and retrieval accuracy. The most critical issue is how to align the output features of different models. Despite the great progress, existing... | Houqiang Li, Hui Wu, Min Wang, Wengang Zhou |  |
| 1784 |  |  [Mega: Moving Average Equipped Gated Attention](https://openreview.net/forum?id=qNLe3iq2El) |  | 0 | The design choices in the Transformer attention mechanism, including weak inductive bias and quadratic computational complexity, have limited its application for modeling long sequences. In this paper, we introduce Mega, a simple, theoretically grounded, single-head gated attention mechanism... | Chunting Zhou, Graham Neubig, Jonathan May, Junxian He, Liangke Gui, Luke Zettlemoyer, Xiang Kong, Xuezhe Ma |  |
| 1785 |  |  [Parallel Deep Neural Networks Have Zero Duality Gap](https://openreview.net/forum?id=6zrOr_Rdhjs) |  | 0 | Training deep neural networks is a challenging non-convex optimization problem. Recent work has proven that the strong duality holds (which means zero duality gap) for regularized finite-width two-layer ReLU networks and consequently provided an equivalent convex training problem. However,... | Mert Pilanci, Tolga Ergen, Yifei Wang |  |
| 1786 |  |  [Information-Theoretic Analysis of Unsupervised Domain Adaptation](https://openreview.net/forum?id=c5tbxWXU9-y) |  | 0 | This paper uses information-theoretic tools to analyze the generalization error in unsupervised domain adaptation (UDA). We present novel upper bounds for two notions of generalization errors. The first notion measures the gap between the population risk in the target domain and that in the source... | Yongyi Mao, Ziqiao Wang |  |
| 1787 |  |  [Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes](https://openreview.net/forum?id=PbkBDQ5_UbV) |  | 0 | We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state... | Miao Lu, Yifei Min, Zhaoran Wang, Zhuoran Yang |  |
| 1788 |  |  [Understanding Zero-shot Adversarial Robustness for Large-Scale Models](https://openreview.net/forum?id=P4bXCawRi5J) |  | 0 | Pretrained large-scale vision-language models like CLIP have exhibited strong generalization over unseen tasks. Yet imperceptible adversarial perturbations can significantly reduce CLIP's performance on new tasks. In this work, we identify and explore the problem of adapting large-scale models for... | Carl Vondrick, Chengzhi Mao, Junfeng Yang, Scott Geng, Xin Wang |  |
| 1789 |  |  [Can We Faithfully Represent Absence States to Compute Shapley Values on a DNN?](https://openreview.net/forum?id=YV8tP7bW6Kt) |  | 0 | Masking some input variables of a deep neural network (DNN) and computing output changes on the masked input sample represent a typical way to compute attributions of input variables in the sample. People usually mask an input variable using its baseline value. However, there is no theory to... | Jie Ren, Qirui Chen, Quanshi Zhang, Zhanpeng Zhou |  |
| 1790 |  |  [Dataless Knowledge Fusion by Merging Weights of Language Models](https://openreview.net/forum?id=FCnohuR6AnM) |  | 0 | Fine-tuning pre-trained language models has become the prevalent paradigm for building downstream NLP models. Oftentimes fine-tuned models are readily available but their training data is not, due to data privacy or intellectual property concerns. This creates a barrier to fusing knowledge across... | Daniel PreotiucPietro, Pengxiang Cheng, Xiang Ren, Xisen Jin |  |
| 1791 |  |  [Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval](https://openreview.net/forum?id=PQOlkgsBsik) |  | 0 | This paper presents Universal Vision-Language Dense Retrieval (UniVL-DR), which builds a unified model for multi-modal retrieval. UniVL-DR encodes queries and multi-modality resources in an embedding space for searching candidates from different modalities. To learn a unified embedding space for... | Chenyan Xiong, Ge Yu, Yuanhuiyi Lv, Zhenghao Liu, Zhiyuan Liu |  |
| 1792 |  |  [DFlow: Learning to Synthesize Better Optical Flow Datasets via a Differentiable Pipeline](https://openreview.net/forum?id=5O2uzDusEN5) |  | 0 | Comprehensive studies of synthetic optical flow datasets have attempted to reveal what properties lead to accuracy improvement in learning-based optical flow estimation. However, manually identifying and verifying the properties that contribute to accurate optical flow estimation require... | ByungKi Kwon, JiYun Kim, Nam HyeonWoo, TaeHyun Oh |  |
| 1793 |  |  [Sparse Random Networks for Communication-Efficient Federated Learning](https://openreview.net/forum?id=k1FHgri5y3-) |  | 0 | One main challenge in federated learning is the large communication cost of exchanging weight updates from clients to the server at each round. While prior work has made great progress in compressing the weight updates through gradient compression methods, we propose a radically different approach... | Berivan Isik, Deniz Gündüz, Francesco Pase, Michele Zorzi, Tsachy Weissman |  |
| 1794 |  |  [A General Framework For Proving The Equivariant Strong Lottery Ticket Hypothesis](https://openreview.net/forum?id=vVJZtlZB9D) |  | 0 | The Strong Lottery Ticket Hypothesis (SLTH) stipulates the existence of a subnetwork within a sufficiently overparameterized (dense) neural network that---when initialized randomly and without any training---achieves the accuracy of a fully trained target network. Recent works by Da Cunha et. al... | Avishek Joey Bose, Christos Tsirigotis, Damien Ferbach, Gauthier Gidel |  |
| 1795 |  |  [Robust Fair Clustering: A Novel Fairness Attack and Defense Framework](https://openreview.net/forum?id=4LMIZY7gt7h) |  | 0 | Clustering algorithms are widely used in many societal resource allocation applications, such as loan approvals and candidate recruitment, among others, and hence, biased or unfair model outputs can adversely impact individuals that rely on these applications. To this end, many $\textit{fair}$... | Anshuman Chhabra, Hongfu Liu, Peizhao Li, Prasant Mohapatra |  |
| 1796 |  |  [Learning to Jointly Share and Prune Weights for Grounding Based Vision and Language Models](https://openreview.net/forum?id=UMERaIHMwB3) |  | 0 | Transformers have seen growing interest in processing different modalities, including language and image data. As a result, we can process vision and language data using transformers that are architecturally similar. Leveraging this feature of transformers, we propose weight sharing across two... | Burak Uzkent, Heng Huang, Hongxia Jin, Shangqian Gao, Yilin Shen |  |
| 1797 |  |  [Spatial Attention Kinetic Networks with E(n)-Equivariance](https://openreview.net/forum?id=3DIpIf3wQMC) |  | 0 | Neural networks that are equivariant to rotations, translations, reflections, and permutations on $n$-dimensional geometric space have shown promise in physical modeling for tasks such as accurately but inexpensively modeling complex potential energy surfaces to guiding the sampling of complex... | John D. Chodera, Yuanqing Wang |  |
| 1798 |  |  [Graph Domain Adaptation via Theory-Grounded Spectral Regularization](https://openreview.net/forum?id=OysfLgrk8mk) |  | 0 | Transfer learning on graphs drawn from varied distributions (domains) is in great demand across many applications. Emerging methods attempt to learn domain-invariant representations using graph neural networks (GNNs), yet the empirical performances vary and the theoretical foundation is limited.... | Tianlong Chen, Yang Shen, Yuning You, Zhangyang Wang |  |
| 1799 |  |  [CLARE: Conservative Model-Based Reward Learning for Offline Inverse Reinforcement Learning](https://openreview.net/forum?id=5aT4ganOd98) |  | 0 | This work aims to tackle a major challenge in offline Inverse Reinforcement Learning (IRL), namely the reward extrapolation error, where the learned reward function may fail to explain the task correctly and misguide the agent in unseen environments due to the intrinsic covariate shift. Leveraging... | Guanbo Wang, Ju Ren, Junshan Zhang, Sen Lin, Sheng Yue, Wei Shao, Zhaofeng Zhang |  |
| 1800 |  |  [Data-Free One-Shot Federated Learning Under Very High Statistical Heterogeneity](https://openreview.net/forum?id=_hb4vM3jspB) |  | 0 | Federated learning (FL) is an emerging distributed learning framework that collaboratively trains a shared model without transferring the local clients' data to a centralized server. Motivated by concerns stemming from extended communication and potential attacks, one-shot FL limits communication... | Clare Elizabeth Heinbaugh, Emilio LuzRicca, Huajie Shao |  |
| 1801 |  |  [GReTo: Remedying dynamic graph topology-task discordance via target homophily](https://openreview.net/forum?id=8duT3mi_5n) |  | 0 | Dynamic graphs are ubiquitous across disciplines where observations usually change over time. Regressions on dynamic graphs often contribute to diverse critical tasks, such as climate early-warning and traffic controlling. Existing homophily Graph Neural Networks (GNNs) adopt physical connections... | Gengyu Lin, Lei Bai, Qihe Huang, Yang Kuo, Yang Wang, Zhengyang Zhou |  |
| 1802 |  |  [Deep Reinforcement Learning for Cost-Effective Medical Diagnosis](https://openreview.net/forum?id=0WVNuEnqVu) |  | 0 | Dynamic diagnosis is desirable when medical tests are costly or time-consuming. In this work, we use reinforcement learning (RL) to find a dynamic policy that selects lab test panels sequentially based on previous observations, ensuring accurate testing at a low cost. Clinical diagnostic data are... | Joseph C. Kim, Kaixuan Huang, Mengdi Wang, Yikuan Li, Yuan Luo, Zheng Yu |  |
| 1803 |  |  [POPGym: Benchmarking Partially Observable Reinforcement Learning](https://openreview.net/forum?id=chDrutUTs0K) |  | 0 | Real world applications of Reinforcement Learning (RL) are often partially observable, thus requiring memory. Despite this, partial observability is still largely ignored by contemporary RL benchmarks and libraries. We introduce Partially Observable Process Gym (POPGym), a two-part library... | Amanda Prorok, Matteo Bettini, Ryan Kortvelesy, Stephan Liwicki, Steven D. Morad |  |
| 1804 |  |  [Everybody Needs Good Neighbours: An Unsupervised Locality-based Method for Bias Mitigation](https://openreview.net/forum?id=pOnhudsvzR) |  | 0 | Learning models from human behavioural data often leads to outputs that are biased with respect to user demographics, such as gender or race. This effect can be controlled by explicit mitigation methods, but this typically presupposes access to demographically-labelled training data. Such data is... | Timothy Baldwin, Trevor Cohn, Xudong Han |  |
| 1805 |  |  [Particle-based Variational Inference with Preconditioned Functional Gradient Flow](https://openreview.net/forum?id=6OphWWAE3cS) |  | 0 | Particle-based variational inference (VI) minimizes the KL divergence between model samples and the target posterior with gradient flow estimates. With the popularity of Stein variational gradient descent (SVGD), the focus of particle-based VI algorithms has been on the properties of functions in... | Hanze Dong, Tong Zhang, Xi Wang, Yong Lin |  |
| 1806 |  |  [Learning Locality and Isotropy in Dialogue Modeling](https://openreview.net/forum?id=dPs6BGO2QT0) |  | 0 | Existing dialogue modeling methods have achieved promising performance on various dialogue tasks with the aid of Transformer and the large-scale pre-trained language models. However, some recent studies revealed that the context representations produced by these methods suffer the problem of... | Ding Liang, Gangming Zhao, Han Wu, Haochen Tan, Linqi Song, Mingjie Zhan, Shaoqing Lu |  |
| 1807 |  |  [Combating Exacerbated Heterogeneity for Robust Models in Federated Learning](https://openreview.net/forum?id=eKllxpLOOm) |  | 0 | Privacy and security concerns in real-world applications have led to the development of adversarially robust federated models. However, the straightforward combination between adversarial training and federated learning in one framework can lead to the undesired robustness deterioration. We... | Bo Han, Jiangchao Yao, Jianing Zhu, Jianliang Xu, Quanming Yao, Tongliang Liu |  |
| 1808 |  |  [Towards Robust Object Detection Invariant to Real-World Domain Shifts](https://openreview.net/forum?id=vqSyt8D3ny) |  | 0 | Safety-critical applications such as autonomous driving require robust object detection invariant to real-world domain shifts. Such shifts can be regarded as different domain styles, which can vary substantially due to environment changes and sensor noises, but deep models only know the training... | Bernt Schiele, ChiKeung Tang, Dengxin Dai, Fisher Yu, Mattia Segù, Qi Fan, YuWing Tai |  |
| 1809 |  |  [Light Sampling Field and BRDF Representation for Physically-based Neural Rendering](https://openreview.net/forum?id=yYEb8v65X8) |  | 0 | Physically-based rendering (PBR) is key for immersive rendering effects used widely in the industry to showcase detailed realistic scenes from computer graphics assets. A well-known caveat is that producing the same is computationally heavy and relies on complex capture devices. Inspired by the... | Hanyuan Xiao, Jing Yang, Wenbin Teng, Yajie Zhao, Yunxuan Cai |  |
| 1810 |  |  [Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling](https://openreview.net/forum?id=X5SUR7g2vVw) |  | 0 | Witnessing the impressive achievements of pre-training techniques on large-scale data in the field of computer vision and natural language processing, we wonder whether this idea could be adapted in a grab-and-go spirit, and mitigate the sample inefficiency problem for visuomotor driving. Given the... | Hongyang Li, Junchi Yan, Li Chen, Penghao Wu, Xiaosong Jia, Yu Qiao |  |
| 1811 |  |  [TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis](https://openreview.net/forum?id=ju_Uqw384Oq) |  | 0 | Time series analysis is of immense importance in extensive applications, such as weather forecasting, anomaly detection, and action recognition. This paper focuses on temporal variation modeling, which is the common key problem of extensive analysis tasks. Previous methods attempt to accomplish... | Haixu Wu, Hang Zhou, Jianmin Wang, Mingsheng Long, Tengge Hu, Yong Liu |  |
| 1812 |  |  [Learning without Prejudices: Continual Unbiased Learning via Benign and Malignant Forgetting](https://openreview.net/forum?id=gfPUokHsW-) |  | 0 | Although machine learning algorithms have achieved state-of-the-art status in image classification, recent studies have substantiated that the ability of the models to learn several tasks in sequence, termed continual learning (CL), often suffers from abrupt degradation of performance from previous... | Hyoje Lee, Myeongho Jeon, Myungjoo Kang, Yedarm Seong |  |
| 1813 |  |  [FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities](https://openreview.net/forum?id=tLScKVhcCR) |  | 0 | Many real-world dynamical systems are associated with first integrals (a.k.a. invariant quantities), which are quantities that remain unchanged over time. The discovery and understanding of first integrals are fundamental and important topics both in the natural sciences and in industrial... | Takaharu Yaguchi, Takashi Matsubara |  |
| 1814 |  |  [Approximate Vanishing Ideal Computations at Scale](https://openreview.net/forum?id=3ZPESALKXO) |  | 0 | The vanishing ideal of a set of points $X = \{\mathbf{x}_1, \ldots, \mathbf{x}_m\}\subseteq \mathbb{R}^n$ is the set of polynomials that evaluate to $0$ over all points $\mathbf{x} \in X$ and admits an efficient representation by a finite subset of generators. In practice, to accommodate noise in... | Elias Samuel Wirth, Hiroshi Kera, Sebastian Pokutta |  |
| 1815 |  |  [Selective Annotation Makes Language Models Better Few-Shot Learners](https://openreview.net/forum?id=qY1hlv7gwg) |  | 0 | Many recent approaches to natural language tasks are built on the remarkable abilities of large language models. Large language models can perform in-context learning, where they learn a new task from a few task demonstrations, without any parameter updates. This work examines the implications of... | Chen Henry Wu, Hongjin Su, Jiayi Xin, Jungo Kasai, Luke Zettlemoyer, Mari Ostendorf, Noah A. Smith, Rui Zhang, Tao Yu, Tianlu Wang, Weijia Shi |  |
| 1816 |  |  [Switch-NeRF: Learning Scene Decomposition with Mixture of Experts for Large-scale Neural Radiance Fields](https://openreview.net/forum?id=PQ2zoIZqvm) |  | 0 | The Neural Radiance Fields (NeRF) have been recently applied to reconstruct building-scale and even city-scale scenes. To model a large-scale scene efficiently, a dominant strategy is to employ a divide-and-conquer paradigm via performing scene decomposition, which decomposes a complex scene into... | Dan Xu, Zhenxing Mi |  |
| 1817 |  |  [NORM: Knowledge Distillation via N-to-One Representation Matching](https://openreview.net/forum?id=CRNwGauQpb6) |  | 0 | Existing feature distillation methods commonly adopt the One-to-one Representation Matching between any pre-selected teacher-student layer pair. In this paper, we present $N$-to-$O$ne $R$epresentation $M$atching (NORM), a new two-stage knowledge distillation method, which relies on a simpleFeature... | Anbang Yao, Chao Li, Lujun Li, Xiaolong Liu |  |
| 1818 |  |  [Critic Sequential Monte Carlo](https://openreview.net/forum?id=ObtGcyKmwna) |  | 0 | We introduce CriticSMC, a new algorithm for planning as inference built from a composition of sequential Monte Carlo with learned Soft-Q function heuristic factors. These heuristic factors, obtained from parametric approximations of the marginal likelihood ahead, more effectively guide SMC towards... | Adam Scibior, Berend Zwartsenberg, Frank Wood, Jonathan Wilder Lavington, Justice Sefas, Matthew Niedoba, Setareh Dabiri, Vasileios Lioutas, Yunpeng Liu |  |
| 1819 |  |  [Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image Transformers Help 3D Representation Learning?](https://openreview.net/forum?id=8Oun8ZUVe8N) |  | 0 | The success of deep learning heavily relies on large-scale data with comprehensive labels, which is more expensive and time-consuming to fetch in 3D compared to 2D images or natural languages. This promotes the potential of utilizing models pretrained with data more than 3D as teachers for... | Jianjian Sun, Junbo Zhang, Kaisheng Ma, Li Yi, Linfeng Zhang, Runpei Dong, Zekun Qi, Zheng Ge |  |
| 1820 |  |  [Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?](https://openreview.net/forum?id=0Q9H_Pgx132) |  | 0 | We study the theory of neural network (NN) from the lens of classical nonparametric regression problems with a focus on NN’s ability to adaptively estimate functions with heterogeneous smoothness — a property of functions in Besov or Bounded Variation (BV) classes. Existing work on this problem... | Kaiqi Zhang, YuXiang Wang |  |
| 1821 |  |  [Sparse Token Transformer with Attention Back Tracking](https://openreview.net/forum?id=VV0hSE8AxCw) |  | 0 | Despite the success of Transformers in various applications from text, vision, and speech domains, they are yet to become standard architectures for mobile and edge device applications due to their heavy memory and computational requirements. While there exist many different approaches to reduce... | Heejun Lee, Minki Kang, Sung Ju Hwang, Youngwan Lee |  |
| 1822 |  |  [Robust Active Distillation](https://openreview.net/forum?id=ALDM5SN2r7M) |  | 0 | Distilling knowledge from a large teacher model to a lightweight one is a widely successful approach for generating compact, powerful models in the semi-supervised learning setting where a limited amount of labeled data is available. In large-scale applications, however, the teacher tends to... | Cenk Baykal, Erik Vee, Fotis Iliopoulos, Gaurav Menghani, Khoa Trinh |  |
| 1823 |  |  [Kernel Neural Optimal Transport](https://openreview.net/forum?id=Zuc_MHtUma4) |  | 0 | We study the Neural Optimal Transport (NOT) algorithm which uses the general optimal transport formulation and learns stochastic transport plans. We show that NOT with the weak quadratic cost may learn fake plans which are not optimal. To resolve this issue, we introduce kernel weak quadratic... | Alexander Korotin, Daniil Selikhanovych, Evgeny Burnaev |  |
| 1824 |  |  [SeaFormer: Squeeze-enhanced Axial Transformer for Mobile Semantic Segmentation](https://openreview.net/forum?id=-qg8MQNrxZw) |  | 0 | Since the introduction of Vision Transformers, the landscape of many computer vision tasks (e.g., semantic segmentation), which has been overwhelmingly dominated by CNNs, recently has significantly revolutionized. However, the computational cost and memory requirement render these methods... | Gang Yu, Jiachen Lu, Li Zhang, Qiang Wan, Zilong Huang |  |
| 1825 |  |  [Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural Networks](https://openreview.net/forum?id=4UldFtZ_CVF) |  | 0 | Due to the significant computational challenge of training large-scale graph neural networks (GNNs), various sparse learning techniques have been exploited to reduce memory and storage costs. Examples include graph sparsification that samples a subgraph to reduce the amount of data aggregation and... | Meng Wang, Miao Liu, PinYu Chen, Shuai Zhang, Sijia Liu, Songtao Lu |  |
| 1826 |  |  [Learning Sparse and Low-Rank Priors for Image Recovery via Iterative Reweighted Least Squares Minimization](https://openreview.net/forum?id=TXPN6MtdSE4) |  | 0 | In this work we introduce a novel optimization algorithm for image recovery under learned sparse and low-rank constraints, which are parameterized with weighted extensions of the $\ell_p^p$-vector and $\mathcal{S}_p^p$ Schatten-matrix quasi-norms for $0\!<p\!\le1$, respectively. Our proposed... | Iaroslav Koshelev, Stamatios Lefkimmiatis |  |
| 1827 |  |  [Spherical Sliced-Wasserstein](https://openreview.net/forum?id=jXQ0ipgMdU) |  | 0 | Many variants of the Wasserstein distance have been introduced to reduce its original computational burden. In particular the Sliced-Wasserstein distance (SW), which leverages one-dimensional projections for which a closed-form solution of the Wasserstein distance is available, has received a lot... | Clément Bonet, François Septier, Lucas Drumetz, MinhTan Pham, Nicolas Courty, Paul Berg |  |
| 1828 |  |  [InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning](https://openreview.net/forum?id=m6ahb1mpwwX) |  | 0 | Recent state-of-the-art methods in imbalanced semi-supervised learning (SSL) rely on confidence-based pseudo-labeling with consistency regularization. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted. However, it has been shown that softmax-based confidence... | Yin Li, Yong Jae Lee, Zhuoran Yu |  |
| 1829 |  |  [Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam](https://openreview.net/forum?id=-CefY2EOupj) |  | 0 | 1-bit gradient compression and local steps are two representative techniques that enable drastic communication reduction in distributed SGD. Their benefits, however, remain an open question on Adam-based large model pre-training (e.g. BERT and GPT). In this paper, we demonstrate the non-linearity... | Christopher De Sa, Conglong Li, Minjia Zhang, Yucheng Lu, Yuxiong He |  |
| 1830 |  |  [Truthful Self-Play](https://openreview.net/forum?id=WVRb98rwbv9) |  | 0 | We present a general framework for evolutionary learning to emergent unbiased state representation without any supervision. Evolutionary frameworks such as self-play converge to bad local optima in case of multi-agent reinforcement learning in non-cooperative partially observable environments with... | Shohei Ohsawa |  |
| 1831 |  |  [Strategic Classification with Graph Neural Networks](https://openreview.net/forum?id=TuHkVOjSAR) |  | 0 | Strategic classification studies learning in settings where users can modify their features to obtain favorable predictions. Most current works focus on simple classifiers that trigger independent user responses. Here we examine the implications of learning with more elaborate models that break the... | Ben Finkelshtein, Chaim Baskin, Itay Eilat, Nir Rosenfeld |  |
| 1832 |  |  [Continual Transformers: Redundancy-Free Attention for Online Inference](https://openreview.net/forum?id=PolHquob8M7) |  | 0 | Transformers in their common form are inherently limited to operate on whole token sequences rather than on one token at a time. Consequently, their use during online inference on time-series data entails considerable redundancy due to the overlap in successive token sequences. In this work, we... | Alexandros Iosifidis, Arian Bakhtiarnia, Lukas Hedegaard |  |
| 1833 |  |  [Learning Symbolic Models for Graph-structured Physical Mechanism](https://openreview.net/forum?id=f2wN4v_2__W) |  | 0 | Graph-structured physical mechanisms are ubiquitous in real-world scenarios, thus revealing underneath formulas is of great importance for scientific discovery. However, classical symbolic regression methods fail on this task since they can only handle input-output pairs that are not... | Hongzhi Shi, Jingtao Ding, Li Liu, Quanming Yao, Yong Li, Yufan Cao |  |
| 1834 |  |  [Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning](https://openreview.net/forum?id=0v4VkCSkHNm) |  | 0 | The ability to discover behaviours from past experience and transfer them to new tasks is a hallmark of intelligent agents acting sample-efficiently in the real world. Equipping embodied reinforcement learners with the same ability may be crucial for their successful deployment in robotics. While... | Ingmar Posner, Kristian Hartikainen, Sasha Salter, Walter Goodwin |  |
| 1835 |  |  [Self-Supervised Set Representation Learning for Unsupervised Meta-Learning](https://openreview.net/forum?id=kIAx30hYi_p) |  | 0 | Unsupervised meta-learning (UML) essentially shares the spirit of self-supervised learning (SSL) in that their goal aims at learning models without any human supervision so that the models can be adapted to downstream tasks. Further, the learning objective of self-supervised learning, which pulls... | Dong Bok Lee, Jihwan Bang, JungWoo Ha, Kenji Kawaguchi, Seanie Lee, Sung Ju Hwang, Yunji Kim |  |
| 1836 |  |  [Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems](https://openreview.net/forum?id=itZ6ggvMnzS) |  | 0 | Causal representation learning is the task of identifying the underlying causal variables and their relations from high-dimensional observations, such as images. Recent work has shown that one can reconstruct the causal variables from temporal sequences of observations under the assumption that... | Efstratios Gavves, Phillip Lippe, Sara Magliacane, Sindy Löwe, Taco Cohen, Yuki M. Asano |  |
| 1837 |  |  [Visual Imitation Learning with Patch Rewards](https://openreview.net/forum?id=OnM3R47KIiU) |  | 0 | Visual imitation learning enables reinforcement learning agents to learn to behave from expert visual demonstrations such as videos or image sequences, without explicit, well-defined rewards. Previous reseaches either adopt supervised learning techniques or induce simple and coarse scalar rewards... | Minghuan Liu, Shuicheng Yan, Tairan He, Weinan Zhang, Zhongwen Xu |  |
| 1838 |  |  [CodeT: Code Generation with Generated Tests](https://openreview.net/forum?id=ktrw68Cmu9c) |  | 0 | The task of generating code solutions for a given programming problem can benefit from the use of pre-trained language models such as Codex, which can produce multiple diverse samples. However, a major challenge for this task is to select the most appropriate solution from the multiple samples... | Anh Nguyen, Bei Chen, Daoguang Zan, Fengji Zhang, JianGuang Lou, Weizhu Chen, Zeqi Lin |  |
| 1839 |  |  [Learning to Generate Columns with Application to Vertex Coloring](https://openreview.net/forum?id=JHW30A4DXtO) |  | 0 | We present a new column generation approach based on Machine Learning (ML) for solving combinatorial optimization problems. The aim of our method is to generate high-quality columns that belong to an optimal integer solution, in contrast to the traditional approach that aims at solving linear... | Andreas T. Ernst, Jake Weiner, Xiaodong Li, Yuan Sun |  |
| 1840 |  |  [EVC: Towards Real-Time Neural Image Compression with Mask Decay](https://openreview.net/forum?id=XUxad2Gj40n) |  | 0 | Neural image compression has surpassed state-of-the-art traditional codecs (H.266/VVC) for rate-distortion (RD) performance, but suffers from large complexity and separate models for different rate-distortion trade-offs. In this paper, we propose an Efficient single-model Variable-bit-rate Codec... | Bin Li, GuoHua Wang, Jiahao Li, Yan Lu |  |
| 1841 |  |  [Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information](https://openreview.net/forum?id=ICYasJBlZNs) |  | 0 | Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations... | Carlo De Donno, George Karypis, Layne C. Price, Luis F. Voloch, Robert A. Barton, Vassilis N. Ioannidis, Yulun Wu, Zichen Wang |  |
| 1842 |  |  [ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor](https://openreview.net/forum?id=HmPOzJQhbwg) |  | 0 | Long-term engagement is preferred over immediate engagement in sequential recommendation as it directly affects product operational metrics such as daily active users (DAUs) and dwell time. Meanwhile, reinforcement learning (RL) is widely regarded as a promising framework for optimizing long-term... | Bo An, Dong Zheng, Kun Gai, Peng Jiang, Qingpeng Cai, Ruohan Zhan, Wanqi Xue |  |
| 1843 |  |  [Dataset Pruning: Reducing Training Data by Examining Generalization Influence](https://openreview.net/forum?id=4wZiAXD29TQ) |  | 0 | The great success of deep learning heavily relies on increasingly larger training data, which comes at a price of huge computational and infrastructural costs. This poses crucial questions that, do all training data contribute to model's performance? How much does each individual training sample or... | Hanyu Peng, Min Xu, Mingming Sun, Ping Li, Shuo Yang, Zeke Xie |  |
| 1844 |  |  [StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training](https://openreview.net/forum?id=HE_75XY5Ljh) |  | 0 | In this paper, we present StrucTexTv2, an effective document image pre-training framework, by performing masked visual-textual prediction. It consists of two self-supervised pre-training tasks: masked image modeling and masked language modeling, based on text region-level image masking. The... | Chengquan Zhang, Errui Ding, Jingdong Wang, Junyu Han, Kun Yao, Xiameng Qin, Xiaoqiang Zhang, Yuechen Yu, Yulin Li, Zengyuan Guo |  |
| 1845 |  |  [Plateau in Monotonic Linear Interpolation - A "Biased" View of Loss Landscape for Deep Networks](https://openreview.net/forum?id=z289SIQOQna) |  | 0 | Monotonic linear interpolation (MLI) --- on the line connecting a random initialization with the minimizer it converges to, the loss and accuracy are monotonic --- is a phenomenon that is commonly observed in the training of neural networks. Such a phenomenon may seem to suggest that optimization... | Annie N. Wang, Mo Zhou, Rong Ge, Xiang Wang |  |
| 1846 |  |  [The KFIoU Loss for Rotated Object Detection](https://openreview.net/forum?id=qUKsCztWlKq) |  | 0 | Differing from the well-developed horizontal object detection area whereby the computing-friendly IoU based loss is readily adopted and well fits with the detection metrics, rotation detectors often involve a more complicated loss based on SkewIoU which is unfriendly to gradient-based training. In... | Gefan Zhang, Jirui Yang, Junchi Yan, Qi Tian, Wentao Wang, Xiaopeng Zhang, Xue Yang, Yue Zhou |  |
| 1847 |  |  [BrainBERT: Self-supervised representation learning for intracranial recordings](https://openreview.net/forum?id=xmcYx_reUn6) |  | 0 | We create a reusable Transformer, BrainBERT, for intracranial recordings bringing modern representation learning approaches to neuroscience. Much like in NLP and speech recognition, this Transformer enables classifying complex concepts, i.e., decoding neural data, with higher accuracy and with much... | Adam Uri Yaari, Andrei Barbu, Boris Katz, Christopher Wang, Gabriel Kreiman, Ignacio Cases, Vighnesh Subramaniam |  |
| 1848 |  |  [General Neural Gauge Fields](https://openreview.net/forum?id=XWkWK2UagFR) |  | 0 | The recent advance of neural fields, such as neural radiance fields, has significantly pushed the boundary of scene representation learning. Aiming to boost the computation efﬁciency and rendering quality of 3D scenes, a popular line of research maps the 3D coordinate system to another measuring... | Adam Kortylewski, Christian Theobalt, Fangneng Zhan, Lingjie Liu |  |
| 1849 |  |  [Generate rather than Retrieve: Large Language Models are Strong Context Generators](https://openreview.net/forum?id=fB0hRu9GZUS) |  | 0 | Knowledge-intensive tasks, such as open-domain question answering (QA), require access to a large amount of world or domain knowledge. A common approach for knowledge-intensive tasks is to employ a retrieve-then-read pipeline that first retrieves a handful of relevant contextual documents from an... | Chenguang Zhu, Dan Iter, Meng Jiang, Michael Zeng, Mingxuan Ju, Shuohang Wang, Soumya Sanyal, Wenhao Yu, Yichong Xu |  |
| 1850 |  |  [Discovering Informative and Robust Positives for Video Domain Adaptation](https://openreview.net/forum?id=vk-j5pQY3Gv) |  | 0 | Unsupervised domain adaptation for video recognition is challenging where the domain shift includes both spatial variations and temporal dynamics. Previous works have focused on exploring contrastive learning for cross-domain alignment. However, limited variations in intra-domain positives, false... | Chang Liu, Jun Amano, Kunpeng Li, Michael Stopa, Yun Fu |  |
| 1851 |  |  [Understanding Why Generalized Reweighting Does Not Improve Over ERM](https://openreview.net/forum?id=ashPce_W8F-) |  | 0 | Empirical risk minimization (ERM) is known to be non-robust in practice to distributional shift where the training and the test distributions are different. A suite of approaches, such as importance weighting, and variants of distributionally robust optimization (DRO), have been proposed to solve... | Chen Dan, J. Zico Kolter, Pradeep Kumar Ravikumar, Runtian Zhai |  |
| 1852 |  |  [Linear Connectivity Reveals Generalization Strategies](https://openreview.net/forum?id=hY6M0JHl3uL) |  | 0 | In the mode connectivity literature, it is widely accepted that there are common circumstances in which two neural networks, trained similarly on the same data, will maintain loss when interpolated in the weight space. In particular, transfer learning is presumed to ensure the necessary conditions... | Jeevesh Juneja, João Sedoc, Kyunghyun Cho, Naomi Saphra, Rachit Bansal |  |
| 1853 |  |  [Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models](https://openreview.net/forum?id=9DZKk85Z4zA) |  | 0 | Learning energy-based models (EBMs) is known to be difficult especially on discrete data where gradient-based learning strategies cannot be applied directly. Although ratio matching is a sound method to learn discrete EBMs, it suffers from expensive computation and excessive memory requirements,... | Haoran Liu, Meng Liu, Shuiwang Ji |  |
| 1854 |  |  [Composing Ensembles of Pre-trained Models via Iterative Consensus](https://openreview.net/forum?id=gmwDKo-4cY) |  | 0 | Large pre-trained models exhibit distinct and complementary capabilities dependent on the data they are trained on. Language models such as GPT-3 are capable of textual reasoning but cannot understand visual information, while vision models such as DALL-E can generate photorealistic photos but fail... | Antonio Torralba, Igor Mordatch, Joshua B. Tenenbaum, Shuang Li, Yilun Du |  |
| 1855 |  |  [Automated Data Augmentations for Graph Classification](https://openreview.net/forum?id=vTb1JI0Gps_) |  | 0 | Data augmentations are effective in improving the invariance of learning machines. We argue that the core challenge of data augmentations lies in designing data transformations that preserve labels. This is relatively straightforward for images, but much more challenging for graphs. In this work,... | Kanji Uchino, Koji Maruhashi, Michael McThrow, Shuiwang Ji, Tao Komikado, Wing Yee Au, Youzhi Luo |  |
| 1856 |  |  [Riemannian Metric Learning via Optimal Transport](https://openreview.net/forum?id=v3y68gz-WEz) |  | 0 | We introduce an optimal transport-based model for learning a metric tensor from cross-sectional samples of evolving probability measures on a common Riemannian manifold. We neurally parametrize the metric as a spatially-varying matrix field and efficiently optimize our model's objective using a... | Christopher Scarvelis, Justin Solomon |  |
| 1857 |  |  [Reliability of CKA as a Similarity Measure in Deep Learning](https://openreview.net/forum?id=8HRvyxc606) |  | 0 | Comparing learned neural representations in neural networks is a challenging but important problem, which has been approached in different ways. The Centered Kernel Alignment (CKA) similarity metric, particularly its linear variant, has recently become a popular approach and has been widely used to... | Amine Natik, Eugene Belilovsky, Guillaume Lajoie, Guy Wolf, MohammadReza Davari, Stefan Horoi |  |
| 1858 |  |  [Fair Attribute Completion on Graph with Missing Attributes](https://openreview.net/forum?id=9vcXCMp9VEp) |  | 0 | Tackling unfairness in graph learning models is a challenging task, as the unfairness issues on graphs involve both attributes and topological structures. Existing work on fair graph learning simply assumes that attributes of all nodes are available for model training and then makes fair... | Dongliang Guo, Sheng Li, Zhixuan Chu |  |
| 1859 |  |  [Deep Ranking Ensembles for Hyperparameter Optimization](https://openreview.net/forum?id=_ruvo2KCL2x) |  | 0 | Automatically optimizing the hyperparameters of Machine Learning algorithms is one of the primary open questions in AI. Existing work in Hyperparameter Optimization (HPO) trains surrogate models for approximating the response surface of hyperparameters as a regression task. In contrast, we... | Abdus Salam Khazi, Josif Grabocka, Sebastian PinedaArango |  |
| 1860 |  |  [Robustness to corruption in pre-trained Bayesian neural networks](https://openreview.net/forum?id=kUI41mY8bHl) |  | 0 | We develop ShiftMatch, a new training-data-dependent likelihood for robustness to corruption in Bayesian neural networks (BNNs). ShiftMatch is inspired by the training-data-dependent “EmpCov” priors from Izmailov et al. (2021a), and efficiently matches test-time spatial correlations to those at... | Laurence Aitchison, Xi Wang |  |
| 1861 |  |  [Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning](https://openreview.net/forum?id=resApVNcqSB) |  | 0 | Human object interaction (HOI) detection plays a crucial role in human-centric scene understanding and serves as a fundamental building block for many vision tasks. One generalizable and scalable strategy for HOI detection is to use weak supervision, learning from image-level annotations only. This... | Bo Wan, Desen Zhou, Tinne Tuytelaars, Xuming He, Yongfei Liu |  |
| 1862 |  |  [Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction](https://openreview.net/forum?id=KXRSh0sdVTP) |  | 0 | We propose Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for learning deep kernel Gaussian processes (GPs) by interpolating between meta-learning and conventional deep kernel learning. Our approach employs a bilevel optimization objective where we... | Austin Tripp, José Miguel HernándezLobato, Wenlin Chen |  |
| 1863 |  |  [ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation](https://openreview.net/forum?id=FYZCHEtt6H0) |  | 0 | Deep Reinforcement Learning (Deep RL) and Evolutionary Algorithm (EA) are two major paradigms of policy optimization with distinct learning principles, i.e., gradient-based v.s. gradient-free. An appealing research direction is integrating Deep RL and EA to devise new methods by fusing their... | Hongyao Tang, Jianye Hao, Pengyi Li, Xian Fu, Yan Zheng, Zhaopeng Meng |  |
| 1864 |  |  [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://openreview.net/forum?id=WZH7099tgfM) |  | 0 | Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we... | Claire Cui, Dale Schuurmans, Denny Zhou, Ed H. Chi, Jason Wei, Le Hou, Nathan Scales, Nathanael Schärli, Olivier Bousquet, Quoc V. Le, Xuezhi Wang |  |
| 1865 |  |  [Deep Ensembles for Graphs with Higher-order Dependencies](https://openreview.net/forum?id=hZftxQGJ4Re) |  | 0 | Graph neural networks (GNNs) continue to achieve state-of-the-art performance on many graph learning tasks, but rely on the assumption that a given graph is a sufficient approximation of the true neighborhood structure. In the presence of higher-order sequential dependencies, we show that the... | Nitesh V. Chawla, Patrick M. Soga, Steven J. Krieg, William C. Burgis |  |
| 1866 |  |  [Towards Understanding Why Mask Reconstruction Pretraining Helps in Downstream Tasks](https://openreview.net/forum?id=PaEUQiY40Dk) |  | 0 | For unsupervised pretraining, mask-reconstruction pretraining (MRP) approaches, e.g. MAE and data2vec, randomly mask input patches and then reconstruct the pixels or semantic features of these masked patches via an auto-encoder. Then for a downstream task, supervised fine-tuning the pretrained... | Jiachun Pan, Pan Zhou, Shuicheng Yan |  |
| 1867 |  |  [Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance](https://openreview.net/forum?id=20GtJ6hIaPA) |  | 0 | Category-level articulated object pose estimation aims to estimate a hierarchy of articulation-aware object poses of an unseen articulated object from a known category. To reduce the heavy annotations needed for supervised learning methods, we present a novel self-supervised strategy that solves... | Haibin Huang, He Wang, Ji Zhang, Li Yi, Ruizhen Hu, Xueyi Liu |  |
| 1868 |  |  [Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations](https://openreview.net/forum?id=6orC5MvgPBK) |  | 0 | Animals thrive in a constantly changing environment and leverage the temporal structure to learn well-factorized causal representations. In contrast, traditional neural networks suffer from forgetting in changing environments and many methods have been proposed to limit forgetting with different... | Ali Hummos |  |
| 1869 |  |  [Deep Variational Implicit Processes](https://openreview.net/forum?id=8aeSJNbmbQq) |  | 0 | Implicit processes (IPs) are a generalization of Gaussian processes (GPs). IPs may lack a closed-form expression but are easy to sample from. Examples include, among others, Bayesian neural networks or neural samplers. IPs can be used as priors over functions, resulting in flexible models with... | Daniel HernándezLobato, Luis A. Ortega, Simón Rodríguez Santana |  |
| 1870 |  |  [Denoising Masked Autoencoders Help Robust Classification](https://openreview.net/forum?id=zDjtZZBZtqK) |  | 0 | In this paper, we propose a new self-supervised method, which is called denoising masked autoencoders (DMAE), for learning certified robust classifiers of images. In DMAE, we corrupt each image by adding Gaussian noises to each pixel value and randomly masking several patches. A Transformer-based... | Di He, Hang Ye, Huishuai Zhang, Liwei Wang, Quanlin Wu, Yuntian Gu |  |
| 1871 |  |  [Estimating individual treatment effects under unobserved confounding using binary instruments](https://openreview.net/forum?id=ULsuEVQbV-9) |  | 0 | Estimating conditional average treatment effects (CATEs) from observational data is relevant in many fields such as personalized medicine. However, in practice, the treatment assignment is usually confounded by unobserved variables and thus introduces bias. A remedy to remove the bias is the use of... | Dennis Frauen, Stefan Feuerriegel |  |
| 1872 |  |  [Approximate Bayesian Inference with Stein Functional Variational Gradient Descent](https://openreview.net/forum?id=a2-aoqmeYM4) |  | 0 | We propose a general-purpose variational algorithm that forms a natural analogue of Stein variational gradient descent (SVGD) in function space. While SVGD successively updates a set of particles to match a target density, the method introduced here of Stein functional variational gradient descent... | Bernd Bischl, David Rügamer, Tobias Pielok |  |
| 1873 |  |  [SCoMoE: Efficient Mixtures of Experts with Structured Communication](https://openreview.net/forum?id=s-c96mSU0u5) |  | 0 | Mixture-of-Experts (MoE) models are promising architectures for massively multilingual neural machine translation and large language models due to the advantage of sublinear scaling. However, the training of large MoE models is usually bottlenecked by the all-to-all communication (Lepikhin et al.,... | Deyi Xiong, Zhiyuan Zeng |  |
| 1874 |  |  [An Additive Instance-Wise Approach to Multi-class Model Interpretation](https://openreview.net/forum?id=5OygDd-4Eeh) |  | 0 | Interpretable machine learning offers insights into what factors drive a certain prediction of a black-box system. A large number of interpreting methods focus on identifying explanatory input features, which generally fall into two main categories: attribution and selection. A popular... | Dinh Phung, Gholamreza Haffari, Quan Hung Tran, Seyit Camtepe, Trung Le, Van Nguyen, Vy Vo |  |
| 1875 |  |  [LDMIC: Learning-based Distributed Multi-view Image Coding](https://openreview.net/forum?id=ILQVw4cA5F9) |  | 0 | Multi-view image compression plays a critical role in 3D-related applications. Existing methods adopt a predictive coding architecture, which requires joint encoding to compress the corresponding disparity as well as residual information. This demands collaboration among cameras and enforces the... | Jiawei Shao, Jun Zhang, Xinjie Zhang |  |
| 1876 |  |  [Sound Randomized Smoothing in Floating-Point Arithmetic](https://openreview.net/forum?id=HaHCoGcpV9) |  | 0 | Randomized smoothing is sound when using infinite precision. However, we show that randomized smoothing is no longer sound for limited floating-point precision. We present a simple example where randomized smoothing certifies a radius of $1.26$ around a point, even though there is an adversarial... | Matthias Hein, Václav Vorácek |  |
| 1877 |  |  [Collaborative Pure Exploration in Kernel Bandit](https://openreview.net/forum?id=hLbeJ6jObDD) |  | 0 | In this paper, we propose a novel Collaborative Pure Exploration in Kernel Bandit model (CoPE-KB), where multiple agents collaborate to complete different but related tasks with limited communication. Our model generalizes prior CoPE formulation with the single-task and classic MAB setting to allow... | Longbo Huang, Wei Chen, Yihan Du, Yuko Kuroki |  |
| 1878 |  |  [Provably Efficient Risk-Sensitive Reinforcement Learning: Iterated CVaR and Worst Path](https://openreview.net/forum?id=Yn0xg-kHNW-) |  | 0 | In this paper, we study a novel episodic risk-sensitive Reinforcement Learning (RL) problem, named Iterated CVaR RL, which aims to maximize the tail of the reward-to-go at each step, and focuses on tightly controlling the risk of getting into catastrophic situations at each stage. This formulation... | Longbo Huang, Siwei Wang, Yihan Du |  |
| 1879 |  |  [Test-Time Robust Personalization for Federated Learning](https://openreview.net/forum?id=3aBuJEza5sq) |  | 0 | Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalization on FL models additionally adapts the global model to different clients, achieving promising results on consistent local training &... | Liangze Jiang, Tao Lin |  |
| 1880 |  |  [Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference](https://openreview.net/forum?id=BGF9IeDfmlH) |  | 0 | The large number of ReLU non-linearity operations in existing deep neural networks makes them ill-suited for latency-efficient private inference (PI). Existing techniques to reduce ReLU operations often involve manual effort and sacrifice significant accuracy. In this paper, we first present a... | Jacqueline Tiffany Liu, Peter A. Beerel, Shunlin Lu, Souvik Kundu, Yuke Zhang |  |
| 1881 |  |  [Meta Knowledge Condensation for Federated Learning](https://openreview.net/forum?id=TDf-XFAwc79) |  | 0 | Existing federated learning paradigms usually extensively exchange distributed models, rather than original data, at a central solver to achieve a more powerful model. However, this would incur severe communication burden between a server and multiple clients especially when data distributions are... | Joey Tianyi Zhou, Ping Liu, Xin Yu |  |
| 1882 |  |  [Masked Frequency Modeling for Self-Supervised Visual Pre-Training](https://openreview.net/forum?id=9-umxtNPx5E) |  | 0 | We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain.... | Chen Change Loy, Jiahao Xie, Wei Li, Xiaohang Zhan, YewSoon Ong, Ziwei Liu |  |
| 1883 |  |  [Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning](https://openreview.net/forum?id=DHyHRBwJUTN) |  | 0 | Mathematical reasoning, a core ability of human intelligence, presents unique challenges for machines in abstract thinking and logical reasoning. Recent large pre-trained language models such as GPT-3 have achieved remarkable progress on mathematical reasoning tasks written in text form, such as... | Ashwin Kalyan, KaiWei Chang, Liang Qiu, Pan Lu, Peter Clark, SongChun Zhu, Tanmay Rajpurohit, Ying Nian Wu |  |
| 1884 |  |  [Learning Object-Language Alignments for Open-Vocabulary Object Detection](https://openreview.net/forum?id=mjHlitXvReu) |  | 0 | Existing object detection methods are bounded in a fixed-set vocabulary by costly labeled data. When dealing with novel categories, the model has to be retrained with more bounding box annotations. Natural language supervision is an attractive alternative for its annotation-free attributes and... | Chuang Lin, Gholamreza Haffari, Jianfei Cai, Lizhen Qu, Peize Sun, Ping Luo, Yi Jiang, Zehuan Yuan |  |
| 1885 |  |  [Phase transition for detecting a small community in a large network](https://openreview.net/forum?id=iN3Lh-Vy2TH) |  | 0 | How to detect a small community in a large network is an interesting problem, including clique detection as a special case, where a naive degree-based $\chi^2$-test was shown to be powerful in the presence of an Erdös-Renyi (ER) background. Using Sinkhorn's theorem, we show that the signal captured... | Anru Zhang, Jiashun Jin, Paxton Turner, Zheng Tracy Ke |  |
| 1886 |  |  [On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme](https://openreview.net/forum?id=b4t9_XASt6G) |  | 0 | This paper shows that emergent languages in signaling games lack meaningful word boundaries in terms of Harris's Articulation Scheme (HAS), a universal property of natural language. Emergent Languages are artificial communication protocols arising among agents. However, it is not obvious whether... | Ryo Ueda, Taiga Ishii, Yusuke Miyao |  |
| 1887 |  |  [TempCLR: Temporal Alignment Representation with Contrastive Learning](https://openreview.net/forum?id=CIFOsnhZvON) |  | 0 | Video representation learning has been successful in video-text pre-training for zero-shot transfer, where each sentence is trained to be close to the paired video clips in a common feature space. For long videos, given a paragraph of description where the sentences describe different segments of... | Guangxing Han, Jiawei Ma, Long Chen, ShihFu Chang, Shiyuan Huang, Xudong Lin, Yuncong Yang |  |
| 1888 |  |  [Bort: Towards Explainable Neural Networks with Bounded Orthogonal Constraint](https://openreview.net/forum?id=My57qBufZWs) |  | 0 | Deep learning has revolutionized human society, yet the black-box nature of deep neural networks hinders further application to reliability-demanded industries. In the attempt to unpack them, many works observe or impact internal variables to improve the comprehensibility and invertibility of the... | Borui Zhang, Jie Zhou, Jiwen Lu, Wenzhao Zheng |  |
| 1889 |  |  [The Power of Regularization in Solving Extensive-Form Games](https://openreview.net/forum?id=bPiHuNUNv_R) |  | 0 | In this paper, we investigate the power of {\it regularization}, a common technique in reinforcement learning and optimization, in solving extensive-form games (EFGs). We propose a series of new algorithms based on regularizing the payoff functions of the game, and establish a set of convergence... | Asuman E. Ozdaglar, Kaiqing Zhang, Mingyang Liu, Tiancheng Yu |  |
| 1890 |  |  [MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization](https://openreview.net/forum?id=P8YIphWNEGO) |  | 0 | Training graph neural networks (GNNs) on large graphs is complex and extremely time consuming. This is attributed to overheads caused by sparse matrix multiplication, which are sidestepped when training multi-layer perceptrons (MLPs) with only node features. MLPs, by ignoring graph context, are... | Neil Shah, Tong Zhao, Xia Hu, Xiaotian Han, Yozen Liu |  |
| 1891 |  |  [Progressively Compressed Auto-Encoder for Self-supervised Representation Learning](https://openreview.net/forum?id=8T4qmZbTkW7) |  | 0 | As a typical self-supervised learning strategy, Masked Image Modeling (MIM) is driven by recovering all masked patches from visible ones. However, patches from the same image are highly correlated and it is redundant to reconstruct all the masked patches. We find that this redundancy is neglected... | Chenglin Li, Dongsheng Jiang, Hongkai Xiong, Jin Li, Qi Tian, Wenrui Dai, Xiaopeng Zhang, Yabo Chen, Yaoming Wang |  |
| 1892 |  |  [S-NeRF: Neural Radiance Fields for Street Views](https://openreview.net/forum?id=gx2yJS-ENqI) |  | 0 | Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale... | Feihu Zhang, Junge Zhang, Li Zhang, Wenye Li, Ziyang Xie |  |
| 1893 |  |  [Cycle-consistent Masked AutoEncoder for Unsupervised Domain Generalization](https://openreview.net/forum?id=wC98X1qpDBA) |  | 0 | Self-supervised learning methods undergo undesirable performance drops when there exists a significant domain gap between training and testing scenarios. Therefore, unsupervised domain generalization (UDG) is proposed to tackle the problem, which requires the model to be trained on several... | Feng Zhu, Haiyang Yang, Lei Bai, Meilin Chen, Rui Zhao, Shixiang Tang, Wanli Ouyang, Xiaotong Li, Yizhou Wang |  |
| 1894 |  |  [CFlowNets: Continuous Control with Generative Flow Networks](https://openreview.net/forum?id=yAYHho4fATa) |  | 0 | Generative flow networks (GFlowNets), as an emerging technique, can be used as an alternative to reinforcement learning for exploratory control tasks. GFlowNets aims to sample actions with a probability proportional to the reward, similar to sampling different candidates in an active learning... | Haozhi Wang, Jianye Hao, Shuang Luo, Yinchuan Li |  |
| 1895 |  |  [Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models](https://openreview.net/forum?id=OXP9Ns0gnIq) |  | 0 | Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the... | Dongzhuo Li |  |
| 1896 |  |  [DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection](https://openreview.net/forum?id=ZccFLU-Yk65) |  | 0 | Many point-based 3D detectors adopt point-feature sampling strategies to drop some points for efficient inference. These strategies are typically based on fixed and handcrafted rules, making it difficult to handle complicated scenes. Different from them, we propose a Dynamic Ball Query (DBQ)... | Hongbin Sun, Jian Sun, Jinrong Yang, Lin Song, Nanning Zheng, Songtao Liu, Weixin Mao, Xiaoping Li, Zeming Li |  |
| 1897 |  |  [Exploring Low-Rank Property in Multiple Instance Learning for Whole Slide Image Classification](https://openreview.net/forum?id=01KmhBsEPFO) |  | 0 | The classification of gigapixel-sized whole slide images (WSIs) with slide-level labels can be formulated as a multiple-instance-learning (MIL) problem. State-of-the-art models often consist of two decoupled parts: local feature embedding with a pre-trained model followed by a global feature... | Jinxi Xiang, Jun Zhang |  |
| 1898 |  |  [Causal Balancing for Domain Generalization](https://openreview.net/forum?id=F91SROvVJ_6) |  | 0 | While machine learning models rapidly advance the state-of-the-art on various real-world tasks, out-of-domain (OOD) generalization remains a challenging problem given the vulnerability of these models to spurious correlations. We propose a balanced mini-batch sampling strategy to transform a biased... | Hongyang Zhang, Jiachen Li, Kun Zhang, Michael Saxon, William Yang Wang, Xinyi Wang |  |
| 1899 |  |  [Towards Addressing Label Skews in One-Shot Federated Learning](https://openreview.net/forum?id=rzrqh85f4Sc) |  | 0 | Federated learning (FL) has been a popular research area, where multiple clients collaboratively train a model without sharing their local raw data. Among existing FL solutions, one-shot FL is a promising and challenging direction, where the clients conduct FL training with a single communication... | Bingsheng He, Qinbin Li, Yiqun Diao |  |
| 1900 |  |  [Breaking Correlation Shift via Conditional Invariant Regularizer](https://openreview.net/forum?id=-jTaz3CMk72) |  | 0 | Recently, generalization on out-of-distribution (OOD) data with correlation shift has attracted great attentions. The correlation shift is caused by the spurious attributes that correlate to the class label, as the correlation between them may vary in training and test data. For such a problem, we... | Jiacheng Sun, Mingyang Yi, Ruoyu Wang, Zhenguo Li, ZhiMing Ma |  |
| 1901 |  |  [Towards One-shot Neural Combinatorial Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case](https://openreview.net/forum?id=h21yJhdzbwz) |  | 0 | One-shot non-autoregressive neural networks, different from RL-based ones, have been actively adopted for solving combinatorial optimization (CO) problems, which can be trained by the objective score in a self-supervised manner. Such methods have shown their superiority in efficiency (e.g. by... | Dacheng Tao, Junchi Yan, Li Shen, Runzhong Wang, Xiaokang Yang, Yiting Chen |  |
| 1902 |  |  [Block and Subword-Scaling Floating-Point (BSFP) : An Efficient Non-Uniform Quantization For Low Precision Inference](https://openreview.net/forum?id=VWm4o4l3V9e) |  | 0 | In this paper, we propose Block and Subword-Scaling Floating-Point (BSFP), a non-uniform quantization scheme for the skewed and non-uniform distribution of weight vectors in neural networks. By quantizing each weight vector as the superposition of multiple subword vectors (in two's complement) with... | RenShuo Liu, TseKuang Lee, YunChen Lo |  |
| 1903 |  |  [Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning](https://openreview.net/forum?id=0qmwFNJyxCL) |  | 0 | Recent works have shown that self-supervised learning can achieve remarkable robustness when integrated with adversarial training (AT). However, the robustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT) remains significant. Motivated by this observation, we revisit existing... | Rundong Luo, Yifei Wang, Yisen Wang |  |
| 1904 |  |  [Semi-supervised Community Detection via Structural Similarity Metrics](https://openreview.net/forum?id=cxvEGLCHpgl) |  | 0 | Motivated by the interests of social network analysis and network-based recommendation systems, we consider a semi-supervised community detection problem, where the goal is to estimate the community label of a new node by leveraging on the network structure and partially observed community labels... | Tracy Ke, Yicong Jiang |  |
| 1905 |  |  [DDM2: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models](https://openreview.net/forum?id=0vqjc50HfcC) |  | 0 | Magnetic resonance imaging (MRI) is a common and life-saving medical imaging technique. However, acquiring high signal-to-noise ratio MRI scans requires long scan times, resulting in increased costs and patient discomfort, and decreased throughput. Thus, there is great interest in denoising MRI... | Akshay Chaudhari, Ali B. Syed, Kawin Setsompop, Mahmut Yurt, Tiange Xiang |  |
| 1906 |  |  [Multivariate Time-series Imputation with Disentangled Temporal Representations](https://openreview.net/forum?id=rdjeCNUS6TG) |  | 0 | Multivariate time series often faces the problem of missing value. Many time series imputation methods have been developed in the literature. However, these methods all rely on an entangled representation to model dynamics of time series, which may fail to fully exploit the multiple factors (e.g.,... | Gao Cong, Shuai Liu, Xiucheng Li, Yile Chen, Yue Jiang |  |
| 1907 |  |  [Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization](https://openreview.net/forum?id=FvevdI0aA_h) |  | 0 | Recently pre-trained language models (PLMs) have prospered in various natural language generation (NLG) tasks due to their ability to generate fairly fluent text. Nevertheless, these models are observed to capture and reproduce harmful contents in training corpora, typically toxic language and... | Peng Li, Xiaoyuan Yi, Xing Xie, Yang Liu, Zonghan Yang |  |
| 1908 |  |  [Automating Nearest Neighbor Search Configuration with Constrained Optimization](https://openreview.net/forum?id=KfptQCEKVW4) |  | 0 | The approximate nearest neighbor (ANN) search problem is fundamental to efficiently serving many real-world machine learning applications. A number of techniques have been developed for ANN search that are efficient, accurate, and scalable. However, such techniques typically have a number of... | Philip Sun, Ruiqi Guo, Sanjiv Kumar |  |
| 1909 |  |  [Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders](https://openreview.net/forum?id=HDxgaKk956l) |  | 0 | Employing a forward diffusion chain to gradually map the data to a noise distribution, diffusion-based generative models learn how to generate the data by inferring a reverse diffusion chain. However, this approach is slow and costly because it needs many forward and reverse steps. We propose a... | Huangjie Zheng, Mingyuan Zhou, Pengcheng He, Weizhu Chen |  |
| 1910 |  |  [NTK-SAP: Improving neural network pruning by aligning training dynamics](https://openreview.net/forum?id=-5EWhW_4qWP) |  | 0 | Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent... | Dawei Li, Ruoyu Sun, Yite Wang |  |
| 1911 |  |  [Effective Self-supervised Pre-training on Low-compute Networks without Distillation](https://openreview.net/forum?id=cbpRzMy-UZH) |  | 0 | Despite the impressive progress of self-supervised learning (SSL), its applicability to low-compute networks has received limited attention. Reported performance has trailed behind standard supervised pre-training by a large margin, barring self-supervised learning from making an impact on models... | Brais Martínez, Fatemeh Sadat Saleh, Fuwen Tan |  |
| 1912 |  |  [CoRTX: Contrastive Framework for Real-time Explanation](https://openreview.net/forum?id=L2MUOUp0beo) |  | 0 | Recent advancements in explainable machine learning provide effective and faithful solutions for interpreting model behaviors. However, many explanation methods encounter efficiency issues, which largely limit their deployments in practical scenarios. Real-time explainer (RTX) frameworks have thus... | Fan Yang, Guanchu Wang, Pushkar Tripathi, Quan Zhou, Xia Ben Hu, Xuanting Cai, YuNeng Chuang |  |
| 1913 |  |  [OTOv2: Automatic, Generic, User-Friendly](https://openreview.net/forum?id=7ynoX1ojPMt) |  | 0 | The existing model compression methods via structured pruning typically require complicated multi-stage procedures. Each individual stage necessitates numerous engineering efforts and domain-knowledge from the end-users which prevent their wider applications onto broader scenarios. We propose the... | Ilya Zharkov, Luming Liang, Tianyi Chen, Tianyu Ding, Zhihui Zhu |  |
| 1914 |  |  [Filter-Recovery Network for Multi-Speaker Audio-Visual Speech Separation](https://openreview.net/forum?id=fiB2RjmgwQ6) |  | 0 | In this paper, we systematically study the audio-visual speech separation task in a multi-speaker scenario. Given the facial information of each speaker, the goal of this task is to separate the corresponding speech from the mixed speech. The existing works are designed for speech separation in a... | Haoyue Cheng, Limin Wang, Wayne Wu, Zhaoyang Liu |  |
| 1915 |  |  [Can discrete information extraction prompts generalize across language models?](https://openreview.net/forum?id=sbWVtxq8-zE) |  | 0 | We study whether automatically-induced prompts that effectively extract information from a language model can also be used, out-of-the-box, to probe other language models for the same information. After confirming that discrete prompts induced with the AutoPrompt algorithm outperform manual and... | Fabio Petroni, Marco Baroni, Nathanaël Carraz Rakotonirina, Roberto Dessì, Sebastian Riedel |  |
| 1916 |  |  [A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions, benefit from negative momenta](https://openreview.net/forum?id=bzaPGEllsjE) |  | 0 | Mini-batch SGD with momentum is a fundamental algorithm for learning large predictive models. In this paper we develop a new analytic framework to analyze noise-averaged properties of mini-batch SGD for linear models at constant learning rates, momenta and sizes of batches. Our key idea is to... | Denis Kuznedelev, Dmitry Yarotsky, Maksim Velikanov |  |
| 1917 |  |  [Bridging the Gap between ANNs and SNNs by Calibrating Offset Spikes](https://openreview.net/forum?id=PFbzoWZyZRX) |  | 0 | Spiking Neural Networks (SNNs) have attracted great attention due to their distinctive characteristics of low power consumption and temporal information processing. ANN-SNN conversion, as the most commonly used training method for applying SNNs, can ensure that converted SNNs achieve comparable... | Jianhao Ding, Tiejun Huang, Tong Bu, Zecheng Hao, Zhaofei Yu |  |
| 1918 |  |  [ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure](https://openreview.net/forum?id=bHW9njOSON) |  | 0 | Studies have shown that modern neural networks tend to be poorly calibrated due to over-confident predictions. Traditionally, post-processing methods have been used to calibrate the model after training. In recent years, various trainable calibration measures have been proposed to incorporate them... | Chang D. Yoo, Eunseop Yoon, Gwangsu Kim, Hee Suk Yoon, Joshua Tian Jin Tee, Sunjae Yoon, Yingzhen Li |  |
| 1919 |  |  [Interactive Portrait Harmonization](https://openreview.net/forum?id=AP0iZoaRaS) |  | 0 |  | He Zhang, Jeya Maria Jose Valanarasu, Jianming Zhang, Jose Echevarria, Kalyan Sunkavalli, Vishal Patel, Yilin Wang, Yinglan Ma, Zhe Lin, Zijun Wei |  |
| 1920 |  |  [Self-Distillation for Further Pre-training of Transformers](https://openreview.net/forum?id=kj6oK_Hj40) |  | 0 | Pre-training a large transformer model on a massive amount of unlabeled data and fine-tuning it on labeled datasets for diverse downstream tasks has proven to be a successful strategy, for a variety of vision and natural language processing tasks. However, direct fine-tuning of the pre-trained... | Juho Lee, Kenji Kawaguchi, Minki Kang, Seanie Lee, Sung Ju Hwang |  |
| 1921 |  |  [Contextual Convolutional Networks](https://openreview.net/forum?id=PldynS56bN) |  | 0 | This paper presents a new Convolutional Neural Network, named Contextual Convolutional Network, that capably serves as a general-purpose backbone for visual recognition. Most existing convolutional backbones follow the representation-to-classification paradigm, where representations of the input... | Shuxian Liang, Tongliang Liu, XianSheng Hua, Xu Shen |  |
| 1922 |  |  [Statistical Inference for Fisher Market Equilibrium](https://openreview.net/forum?id=KemSBwOYJC) |  | 0 | Statistical inference under market equilibrium effects has attracted increasing attention recently. In this paper we focus on the specific case of linear Fisher markets. They have been widely use in fair resource allocation of food/blood donations and budget management in large-scale Internet ad... | Christian Kroer, Luofeng Liao, Yuan Gao |  |
| 1923 |  |  [Scenario-based Question Answering with Interacting Contextual Properties](https://openreview.net/forum?id=tPrRs6YB2P) |  | 0 | In the scenario-based Question Answering (QA) task, models are asked to find answers that are appropriate to the user scenarios associated with the question and identify information that is missing from the scenarios but is necessary for the answers to hold. Scenarios commonly include multiple... | Haitian Sun, Ruslan Salakhutdinov, William W. Cohen |  |
| 1924 |  |  [Easy Differentially Private Linear Regression](https://openreview.net/forum?id=rSUCajhLsQ) |  | 0 | Linear regression is a fundamental tool for statistical analysis. This has motivated the development of linear regression methods that also satisfy differential privacy and thus guarantee that the learned model reveals little about any one data point used to construct it. However, existing... | Kareem Amin, Matthew Joseph, Mónica Ribero, Sergei Vassilvitskii |  |
| 1925 |  |  [LPT: Long-tailed Prompt Tuning for Image Classification](https://openreview.net/forum?id=8pOVAeo8ie) |  | 0 | For long-tailed classification tasks, most works often pretrain a big model on a large-scale (unlabeled) dataset, and then fine-tune the whole pretrained model for adapting to long-tailed data. Though promising, fine-tuning the whole pretrained model tends to suffer from high cost in computation... | Bowen Dong, Pan Zhou, Shuicheng Yan, Wangmeng Zuo |  |
| 1926 |  |  [DamoFD: Digging into Backbone Design on Face Detection](https://openreview.net/forum?id=NkJOhtNKX91) |  | 0 | Face detection (FD) has achieved remarkable success over the past few years, yet, these leaps often arrive when consuming enormous computation costs. Moreover, when considering a realistic situation, i.e., building a lightweight face detector under a computation-scarce scenario, such heavy... | Baigui Sun, Fei Wang, Jiankang Deng, Lei Shang, Xuansong Xie, Yang Liu |  |
| 1927 |  |  [Towards Smooth Video Composition](https://openreview.net/forum?id=W918Ora75q) |  | 0 | Video generation, with the purpose of producing a sequence of frames, requires synthesizing consistent and persistent dynamic contents over time. This work investigates how to model the temporal relations for composing a video with arbitrary number of frames, from a few to even infinite, using... | Bolei Zhou, Ceyuan Yang, Qihang Zhang, Yinghao Xu, Yujun Shen |  |
| 1928 |  |  [DiffMimic: Efficient Motion Mimicking with Differentiable Physics](https://openreview.net/forum?id=06mk-epSwZ) |  | 0 | Motion mimicking is a foundational task in physics-based character animation. However, most existing motion mimicking methods are built upon reinforcement learning (RL) and suffer from heavy reward engineering, high variance, and slow convergence with hard explorations. Specifically, they usually... | Cunjun Yu, Jiawei Ren, Liang Pan, Siwei Chen, Xiao Ma, Ziwei Liu |  |
| 1929 |  |  [Towards Inferential Reproducibility of Machine Learning Research](https://openreview.net/forum?id=li4GQCQWkv) |  | 0 | Reliability of machine learning evaluation --- the consistency of observed evaluation scores across replicated model training runs --- is affected by several sources of nondeterminism which can be regarded as measurement noise. Current tendencies to remove noise in order to enforce reproducibility... | Michael Hagmann, Philipp Meier, Stefan Riezler |  |
| 1930 |  |  [Knowledge Distillation based Degradation Estimation for Blind Super-Resolution](https://openreview.net/forum?id=Fg3mYW8owg) |  | 0 |  | Bin Xia, Luc Van Gool, Radu Timofte, Wenming Yang, Yapeng Tian, Yitong Wang, Yulun Zhang |  |
| 1931 |  |  [Graph Contrastive Learning for Skeleton-based Action Recognition](https://openreview.net/forum?id=PLUXnnxUdr4) |  | 0 | In the field of skeleton-based action recognition, current top-performing graph convolutional networks (GCNs) exploit intra-sequence context to construct adaptive graphs for feature aggregation. However, we argue that such context is still $\textit{local}$ since the rich cross-sequence relations... | Bin Feng, Errui Ding, Hao Zhou, Haocheng Feng, Jian Wang, Jingdong Wang, Junyu Han, Wenyu Liu, Xiaohu Huang, Xinggang Wang |  |
| 1932 |  |  [Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation](https://openreview.net/forum?id=s4WVupnJjmX) |  | 0 | This paper presents a novel end-to-end framework with Explicit box Detection for multi-person Pose estimation, called ED-Pose, where it unifies the contextual learning between human-level (global) and keypoint-level (local) information. Different from previous one-stage methods, ED-Pose... | Ailing Zeng, Feng Li, Jie Yang, Lei Zhang, Ruimao Zhang, Shilong Liu |  |
| 1933 |  |  [Spikformer: When Spiking Neural Network Meets Transformer](https://openreview.net/forum?id=frE4fUwz_h) |  | 0 | We consider two biologically plausible structures, the Spiking Neural Network (SNN) and the self-attention mechanism. The former offers an energy-efficient and event-driven paradigm for deep learning, while the latter has the ability to capture feature dependencies, enabling Transformer to achieve... | Chao He, Li Yuan, Shuicheng Yan, Yaowei Wang, Yonghong Tian, Yuesheng Zhu, Zhaokun Zhou |  |
| 1934 |  |  [Multimodal Analogical Reasoning over Knowledge Graphs](https://openreview.net/forum?id=NRHajbzg8y0P) |  | 0 | Analogical reasoning is fundamental to human cognition and holds an important place in various fields. However, previous studies mainly focus on single-modal analogical reasoning and ignore taking advantage of structure knowledge. Notably, the research in cognitive psychology has demonstrated that... | Huajun Chen, Lei Li, Ningyu Zhang, Shumin Deng, Xiang Chen, Xiaozhuan Liang |  |
| 1935 |  |  [MECTA: Memory-Economic Continual Test-Time Model Adaptation](https://openreview.net/forum?id=N92hjSf5NNh) |  | 0 | Continual Test-time Adaptation (CTA) is a promising art to secure accuracy gains in continually-changing environments. The state-of-the-art adaptations improve out-of-distribution model accuracy via computation-efficient online test-time gradient descents but meanwhile cost about times of memory... | Jiayu Zhou, Junyuan Hong, Lingjuan Lyu, Michael Spranger |  |
| 1936 |  |  [Interpretability with full complexity by constraining feature information](https://openreview.net/forum?id=R_OL5mLhsv) |  | 0 | Interpretability is a pressing issue for machine learning. Common approaches to interpretable machine learning constrain interactions between features of the input, sacrificing model complexity in order to render more comprehensible the effects of those features on the model's output. We approach... | Danielle S. Bassett, Kieran A. Murphy |  |
| 1937 |  |  [What shapes the loss landscape of self supervised learning?](https://openreview.net/forum?id=3zSn48RUO8M) |  | 0 | Prevention of complete and dimensional collapse of representations has recently become a design principle for self-supervised learning (SSL). However, questions remain in our theoretical understanding: When do those collapses occur? What are the mechanisms and causes? We answer these questions by... | Ekdeep Singh Lubana, Hidenori Tanaka, Liu Ziyin, Masahito Ueda |  |
| 1938 |  |  [Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies](https://openreview.net/forum?id=-z9hdsyUwVQ) |  | 0 | We consider infinite-horizon discounted Markov decision processes and study the convergence rates of the natural policy gradient (NPG) and the Q-NPG methods with the log-linear policy class. Using the compatible function approximation framework, both methods with log-linear policies can be written... | Alessandro Lazaric, Lin Xiao, Robert M. Gower, Rui Yuan, Simon Shaolei Du |  |
| 1939 |  |  [Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game](https://openreview.net/forum?id=UP_GHHPw7rP) |  | 0 | Offline reinforcement learning (RL) aims at learning an optimal strategy using a pre-collected dataset without further interactions with the environment. While various algorithms have been proposed for offline RL in the previous literature, the minimax optimality has only been (nearly) established... | Chengshuai Shi, Cong Shen, Han Zhong, Liwei Wang, Tong Zhang, Wei Xiong |  |
| 1940 |  |  [Conditional Positional Encodings for Vision Transformers](https://openreview.net/forum?id=3KWnuT-R1bh) |  | 0 | We propose a conditional positional encoding (CPE) scheme for vision Transformers. Unlike previous fixed or learnable positional encodings that are predefined and independent of input tokens, CPE is dynamically generated and conditioned on the local neighborhood of the input tokens. As a result,... | Bo Zhang, Chunhua Shen, Xiangxiang Chu, Xinlong Wang, Zhi Tian |  |
| 1941 |  |  [ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills](https://openreview.net/forum?id=b_CQDy9vrD1) |  | 0 | Generalizable manipulation skills, which can be composed to tackle long-horizon and complex daily chores, are one of the cornerstones of Embodied AI. However, existing benchmarks, mostly composed of a suite of simulatable environments, are insufficient to push cutting-edge research works because... | Fanbo Xiang, Hao Su, Jiayuan Gu, Pengwei Xie, Rui Chen, Stone Tao, Tongzhou Mu, Xiaodi Yuan, Xinyue Wei, Xiqiang Liu, Xuanlin Li, Yihe Tang, Yunchao Yao, Zhan Ling, Zhiao Huang |  |
| 1942 |  |  [Deja Vu: Continual Model Generalization for Unseen Domains](https://openreview.net/forum?id=L8iZdgeKmI6) |  | 0 |  | Chen Sun, Chenxi Liu, Lingjuan Lyu, Lixu Wang, Qi Zhu, Xiao Wang |  |
| 1943 |  |  [A Graph Neural Network Approach to Automated Model Building in Cryo-EM Maps](https://openreview.net/forum?id=65XDF_nwI61) |  | 0 | Electron cryo-microscopy (cryo-EM) produces three-dimensional (3D) maps of the electrostatic potential of biological macromolecules, including proteins. At sufficient resolution, the cryo-EM maps, along with some knowledge about the imaged molecules, allow de novo atomic modelling. Typically, this... | Dari Kimanius, Kiarash Jamali, Sjors H. W. Scheres |  |
| 1944 |  |  [Distilling Cognitive Backdoor Patterns within an Image](https://openreview.net/forum?id=S3D9NLzjnQ5) |  | 0 |  | Hanxun Huang, James Bailey, Sarah Monazam Erfani, Xingjun Ma |  |
| 1945 |  |  [Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching](https://openreview.net/forum?id=QjQibO3scV_) |  | 0 | Graph matching (GM) has been a building block in various areas including computer vision and pattern recognition. Despite recent impressive progress, existing deep GM methods often have obvious difficulty in handling outliers, which are ubiquitous in practice. We propose a deep reinforcement... | Chang Liu, Junchi Yan, Lingxiao Huang, Pinyan Lu, Runzhong Wang, Zetian Jiang |  |
| 1946 |  |  [One Transformer Can Understand Both 2D & 3D Molecular Data](https://openreview.net/forum?id=vZTp1oPV3PC) |  | 0 | Unlike vision and language data which usually has a unique format, molecules can naturally be characterized using different chemical formulations. One can view a molecule as a 2D graph or define it as a collection of atoms located in a 3D space. For molecular representation learning, most previous... | Di He, Liwei Wang, Shengjie Luo, Shuxin Zheng, Tianlang Chen, TieYan Liu, Yixian Xu |  |
| 1947 |  |  [Mind the Gap: Offline Policy Optimization for Imperfect Rewards](https://openreview.net/forum?id=WumysvcMvV6) |  | 0 | Reward function is essential in reinforcement learning (RL), serving as the guiding signal to incentivize agents to solve given tasks, however, is also notoriously difficult to design. In many cases, only imperfect rewards are available, which inflicts substantial performance loss for RL agents. In... | Haoran Xu, Jianxiong Li, Jingjing Liu, QingShan Jia, Xianyuan Zhan, Xiao Hu, YaQin Zhang |  |
| 1948 |  |  [Learning to Compose Soft Prompts for Compositional Zero-Shot Learning](https://openreview.net/forum?id=S8-A2FXnIh) |  | 0 | We introduce compositional soft prompting (CSP), a parameter-efficient learning technique to improve the zero-shot compositionality of large-scale pretrained vision-language models (VLMs) like CLIP. We develop CSP for compositional zero-shot learning, the task of predicting unseen attribute-object... | Nihal V. Nayak, Peilin Yu, Stephen H. Bach |  |
| 1949 |  |  [SQA3D: Situated Question Answering in 3D Scenes](https://openreview.net/forum?id=IDJx97BC38) |  | 0 | We propose a new task to benchmark scene understanding of embodied agents: Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g., 3D scan), SQA3D requires the tested agent to first understand its situation (position, orientation, etc.) in the 3D scene as described by text,... | Qing Li, Silong Yong, Siyuan Huang, SongChun Zhu, Xiaojian Ma, Yitao Liang, Zilong Zheng |  |
| 1950 |  |  [Empowering Networks With Scale and Rotation Equivariance Using A Similarity Convolution](https://openreview.net/forum?id=NJENsJ37sQ) |  | 0 |  | Thierry Blu, Zikai Sun |  |
| 1951 |  |  [Robust and Controllable Object-Centric Learning through Energy-based Models](https://openreview.net/forum?id=wcNtbEtcGIC) |  | 0 | Humans are remarkably good at understanding and reasoning about complex visual scenes. The capability of decomposing low-level observations into discrete objects allows us to build a grounded abstract representation and identify the compositional structure of the world. Thus it is a crucial step... | Boris Ivanovic, Liam Paull, Marco Pavone, Renhao Wang, Ruixiang Zhang, Tong Che, Yoshua Bengio |  |
| 1952 |  |  [Topology-aware Robust Optimization for Out-of-Distribution Generalization](https://openreview.net/forum?id=ylMq8MBnAp) |  | 0 | Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications. Existing methods suffer from overly pessimistic modeling with low generalization confidence. As generalizing to arbitrary test distributions is impossible, we... | Fengchun Qiao, Xi Peng |  |
| 1953 |  |  [EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers](https://openreview.net/forum?id=mfIX4QpsARJ) |  | 0 | Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed... | Aurélien Béneteau, Christian Wolf, Julie Digne, Madiha Nadri, Nicolas Thome, Steeven Janny |  |
| 1954 |  |  [Limitless Stability for Graph Convolutional Networks](https://openreview.net/forum?id=XqcQhVUr2h0) |  | 0 |  | Christian Koke |  |
| 1955 |  |  [De Novo Molecular Generation via Connection-aware Motif Mining](https://openreview.net/forum?id=Q_Jexl8-qDi) |  | 0 | De novo molecular generation is an essential task for science discovery. Recently, fragment-based deep generative models have attracted much research attention due to their flexibility in generating novel molecules based on existing molecule fragments. However, the motif vocabulary, i.e., the... | Feng Wu, Jie Wang, Lijun Wu, Shufang Xie, Tao Qin, TieYan Liu, Yingce Xia, Yongdong Zhang, Zijie Geng |  |
| 1956 |  |  [Revisiting the Entropy Semiring for Neural Speech Recognition](https://openreview.net/forum?id=SNgLnzFQeiD) |  | 0 | In streaming settings, speech recognition models have to map sub-sequences of speech to text before the full audio stream becomes available. However, since alignment information between speech and text is rarely available during training, models need to learn it in a completely self-supervised way.... | Dongseong Hwang, Olivier Siohan, Oscar Chang |  |
| 1957 |  |  [Rethinking skip connection model as a learnable Markov chain](https://openreview.net/forum?id=yQdBtFfleh6) |  | 0 | Over the past few years afterward the birth of ResNet, skip connection has become the defacto standard for the design of modern architectures due to its widespread adoption, easy optimization, and proven performance. Prior work has explained the effectiveness of the skip connection mechanism from... | Dengsheng Chen, Enhua Wu, Jie Hu, Wenwen Qiang, Xiaoming Wei |  |
| 1958 |  |  [Measuring axiomatic soundness of counterfactual image models](https://openreview.net/forum?id=lZOUQQvwI3q) |  | 0 | We present a general framework for evaluating image counterfactuals. The power and flexibility of deep generative models make them valuable tools for learning mechanisms in structural causal models. However, their flexibility makes counterfactual identifiability impossible in the general case.... | Ben Glocker, Daniel C. Castro, Fabio De Sousa Ribeiro, Miguel Monteiro, Nick Pawlowski |  |
| 1959 |  |  [Alternating Differentiation for Optimization Layers](https://openreview.net/forum?id=KKBMz-EL4tD) |  | 0 |  | Dacheng Tao, H. Vincent Poor, Haixiang Sun, Hoang Duong Tuan, Jingya Wang, Ye Shi |  |
| 1960 |  |  [Out-of-distribution Detection with Implicit Outlier Transformation](https://openreview.net/forum?id=hdghx6wbGuD) |  | 0 |  | Bo Han, Feng Liu, Jianye Hao, Junjie Ye, Marcus Kalander, Qizhou Wang, Quanyu Dai, Tongliang Liu |  |
| 1961 |  |  [Extracting Robust Models with Uncertain Examples](https://openreview.net/forum?id=cMAjKYftNwx) |  | 0 |  | Guanlin Li, Guowen Xu, Han Qiu, Jiwei Li, Shangwei Guo, Tianwei Zhang |  |
| 1962 |  |  [Neural Groundplans: Persistent Neural Scene Representations from a Single Image](https://openreview.net/forum?id=Pza24zf9FpS) |  | 0 |  | Adrien Gaidon, Ayush Tewari, Frédo Durand, Joshua B. Tenenbaum, Prafull Sharma, Rares Andrei Ambrus, Sergey Zakharov, Vincent Sitzmann, William T. Freeman, Yilun Du |  |
| 1963 |  |  [E-CRF: Embedded Conditional Random Field for Boundary-caused Class Weights Confusion in Semantic Segmentation](https://openreview.net/forum?id=g1GnnCI1OrC) |  | 0 |  | Banghuai Li, Huabin Huang, Jie Zhu, Leye Wang |  |
| 1964 |  |  [Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Networks](https://openreview.net/forum?id=9x3CO0ZU9LR) |  | 0 |  | Mengdi Wang, Minshuo Chen, Tuo Zhao, Xiang Ji |  |
| 1965 |  |  [Stochastic Differentially Private and Fair Learning](https://openreview.net/forum?id=3nM5uhPlfv6) |  | 0 |  | Andrew Lowy, Devansh Gupta, Meisam Razaviyayn |  |
| 1966 |  |  [On The Inadequacy of Optimizing Alignment and Uniformity in Contrastive Learning of Sentence Representations](https://openreview.net/forum?id=MxvHVNukama) |  | 0 | Contrastive learning is widely used in areas such as visual representation learning (VRL) and sentence representation learning (SRL). Considering the differences between VRL and SRL in terms of negative sample size and evaluation focus, we believe that the solid findings obtained in VRL may not be... | Richong Zhang, Yongyi Mao, Zhijie Nie |  |
| 1967 |  |  [Volumetric Optimal Transportation by Fast Fourier Transform](https://openreview.net/forum?id=EVrz7UM-ZDm) |  | 0 |  | Dongsheng An, Min Zhang, Na Lei, Xianfeng David Gu, Xiaoyin Xu |  |
| 1968 |  |  [GFlowNets and variational inference](https://openreview.net/forum?id=uKiE0VIluA-) |  | 0 | This paper builds bridges between two families of probabilistic algorithms: (hierarchical) variational inference (VI), which is typically used to model distributions over continuous spaces, and generative flow networks (GFlowNets), which have been used for distributions over discrete structures... | Dinghuai Zhang, Edward J. Hu, Katie Everett, Nikolay Malkin, Salem Lahlou, Tristan Deleu, Xu Ji, Yoshua Bengio |  |
| 1969 |  |  [Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion](https://openreview.net/forum?id=zlwBI2gQL3K) |  | 0 | Knowledge graphs (KGs) are powerful in terms of their inference abilities, but are also notorious for their incompleteness and long-tail distribution of relations. To address these challenges and expand the coverage of KGs, few-shot KG completion aims to make predictions for triplets involving... | Bala Rajaratnam, Han Wu, Jianyuan Guo, Jie Yin |  |
| 1970 |  |  [Function-Consistent Feature Distillation](https://openreview.net/forum?id=pgHNOcxEdRI) |  | 0 | Feature distillation makes the student mimic the intermediate features of the teacher. Nearly all existing feature-distillation methods use L2 distance or its slight variants as the distance metric between teacher and student features. However, while L2 distance is isotropic w.r.t. all dimensions,... | Dongyang Liu, Meina Kan, Shiguang Shan, Xilin Chen |  |
| 1971 |  |  [The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition](https://openreview.net/forum?id=xLr0I_xYGAs) |  | 0 | Open-set Recognition (OSR) aims to identify test samples whose classes are not seen during the training process. Recently, Unified Open-set Recognition (UOSR) has been proposed to reject not only unknown samples but also known but wrongly classified samples, which tends to be more practical in... | Deli Zhao, Di Luan, Jun Cen, Qifeng Chen, Shaojie Shen, Shiwei Zhang, Yingya Zhang, Yixuan Pei |  |
| 1972 |  |  [MCAL: Minimum Cost Human-Machine Active Labeling](https://openreview.net/forum?id=1FxRPKrH8bw) |  | 0 |  | Hang Qiu, Krishna Chintalapudi, Ramesh Govindan |  |
| 1973 |  |  [Learnable Topological Features For Phylogenetic Inference via Graph Neural Networks](https://openreview.net/forum?id=hVVUY7p64WL) |  | 0 | Structural information of phylogenetic tree topologies plays an important role in phylogenetic inference. However, finding appropriate topological structures for specific phylogenetic inference tasks often requires significant design effort and domain expertise. In this paper, we propose a novel... | Cheng Zhang |  |
| 1974 |  |  [Fairness-aware Contrastive Learning with Partially Annotated Sensitive Attributes](https://openreview.net/forum?id=woa783QMul) |  | 0 |  | Chao Wu, Fengda Zhang, Jun Xiao, Kun Kuang, Long Chen, Yuxuan Liu |  |
| 1975 |  |  [Rotamer Density Estimator is an Unsupervised Learner of the Effect of Mutations on Protein-Protein Interaction](https://openreview.net/forum?id=_X9Yl1K2mD) |  | 0 | Protein-protein interactions are crucial to many biological processes, and predicting the effect of amino acid mutations on binding is important for protein engineering. While data-driven approaches using deep learning have shown promise, the scarcity of annotated experimental data remains a major... | Chenpeng Su, Jian Peng, Jianzhu Ma, Shitong Luo, Yufeng Su, Zuofan Wu |  |
| 1976 |  |  [Dilated convolution with learnable spacings](https://openreview.net/forum?id=Q3-1vRh3HOA) |  | 0 |  | Ismail Khalfaoui Hassani, Thomas Pellegrini, Timothée Masquelier |  |
| 1977 |  |  [PatchDCT: Patch Refinement for High Quality Instance Segmentation](https://openreview.net/forum?id=t9Zd7Oi5JPl) |  | 0 | High-quality instance segmentation has shown emerging importance in computer vision. Without any refinement, DCT-Mask directly generates high-resolution masks by compressed vectors. To further refine masks obtained by compressed vectors, we propose for the first time a compressed vector based... | Jirui Yang, Kewei Liang, Qinrou Wen, Xue Yang |  |
| 1978 |  |  [ChiroDiff: Modelling chirographic data with Diffusion Models](https://openreview.net/forum?id=1ROAstc9jv) |  | 0 |  | Ayan Das, Tao Xiang, Timothy M. Hospedales, YiZhe Song, Yongxin Yang |  |
| 1979 |  |  [Real-Time Image Demoiréing on Mobile Devices](https://openreview.net/forum?id=PmP_sf3JkrH) |  | 0 | Moir$\acute{e}$ patterns appear frequently when taking photos of digital screens, drastically degrading the image quality. Despite the advance of CNNs in image demoir$\acute{e}$ing, existing networks are with heavy design, causing massive computation burden for mobile devices. In this paper, we... | Fei Chao, Guozhi Wang, Han Liu, Mingbao Lin, Rongrong Ji, Shuai Ren, Xiaoxin Chen, Xunchao Li, Yafei Wen, Yuxin Zhang |  |
| 1980 |  |  [Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot Classification](https://openreview.net/forum?id=Kn-HA8DFik) |  | 0 |  | Asako Kanezaki, Hao Zheng, Jianzhuang Liu, Runqi Wang |  |
| 1981 |  |  [Delta: Degradation-Free Fully Test-Time Adaptation](https://openreview.net/forum?id=eGm22rqG93) |  | 0 |  | Bowen Zhao, Chen Chen, ShuTao Xia |  |
| 1982 |  |  [Bit-Pruning: A Sparse Multiplication-Less Dot-Product](https://openreview.net/forum?id=YUDiZcZTI8) |  | 0 |  | Shingo Yashima, Yusuke Sekikawa |  |
| 1983 |  |  [kNN-Diffusion: Image Generation via Large-Scale Retrieval](https://openreview.net/forum?id=x5mtJD2ovc) |  | 0 |  | Adam Polyak, Eliya Nachmani, Oran Gafni, Oron Ashual, Shelly Sheynin, Uriel Singer, Yaniv Taigman |  |
| 1984 |  |  [Decompose to Generalize: Species-Generalized Animal Pose Estimation](https://openreview.net/forum?id=nQai_B1Zrt) |  | 0 |  | Guangrui Li, Yi Yang, Yifan Sun, Zongxin Yang |  |
| 1985 |  |  [IDEAL: Query-Efficient Data-Free Learning from Black-Box Models](https://openreview.net/forum?id=ConT6H7MWL) |  | 0 |  | Chen Chen, Jie Zhang, Lingjuan Lyu |  |
| 1986 |  |  [Trainability Preserving Neural Pruning](https://openreview.net/forum?id=AZFvpnnewr) |  | 0 |  | Huan Wang, Yun Fu |  |
| 1987 |  |  [Diagnosing and Rectifying Vision Models using Language](https://openreview.net/forum?id=D-zfUK7BR6c) |  | 0 |  | James Zou, Jeff Z. HaoChen, KuanChieh Wang, Serena Yeung, ShihCheng Huang, Yuhui Zhang |  |
| 1988 |  |  [Harnessing Out-Of-Distribution Examples via Augmenting Content and Style](https://openreview.net/forum?id=boNyg20-JDm) |  | 0 |  | Bo Han, Chen Gong, Li Shen, Mingming Gong, Tongliang Liu, Xiaobo Xia, Zhuo Huang |  |
| 1989 |  |  [DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training](https://openreview.net/forum?id=Kn6i2BZW69w) |  | 0 |  | Angela Yao, Joya Chen, Kai Xu, Yifei Cheng, Yuhui Wang |  |
| 1990 |  |  [A Unified Framework for Soft Threshold Pruning](https://openreview.net/forum?id=cCFqcrq0d8) |  | 0 |  | Wei Fang, Xiawu Zheng, Yanqi Chen, Yonghong Tian, Zhaofei Yu, Zhengyu Ma |  |
| 1991 |  |  [TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding](https://openreview.net/forum?id=-CwPopPJda) |  | 0 |  | Dan Xu, Hanrong Ye |  |
| 1992 |  |  [Learning Domain-Agnostic Representation for Disease Diagnosis](https://openreview.net/forum?id=-HHJZlRpGb) |  | 0 |  | Churan Wang, Fandong Zhang, Jing Li, Xinwei Sun, Yizhou Wang, Yizhou Yu |  |
| 1993 |  |  [Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning](https://openreview.net/forum?id=JdgO-ht1uTN) |  | 0 |  | Charles Yu, Chi Han, Hanghang Tong, Heng Ji, Qizheng He, Xinya Du |  |
| 1994 |  |  [BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection](https://openreview.net/forum?id=-2zfgNS917) |  | 0 |  | Feng Zhao, Liangji Fang, Qinhong Jiang, Shiquan Zhang, Zehui Chen, Zhenyu Li |  |
| 1995 |  |  [A Multi-Grained Self-Interpretable Symbolic-Neural Model For Single/Multi-Labeled Text Classification](https://openreview.net/forum?id=MLJ5TF5FtXH) |  | 0 |  | Kewei Tu, Xiang Hu, Xinyu Kong |  |
| 1996 |  |  [Suppressing the Heterogeneity: A Strong Feature Extractor for Few-shot Segmentation](https://openreview.net/forum?id=CGuvK3U09LH) |  | 0 |  | Yi Yang, Yifan Sun, Zhengdong Hu |  |
| 1997 |  |  [Achieve the Minimum Width of Neural Networks for Universal Approximation](https://openreview.net/forum?id=hfUJ4ShyDEU) |  | 0 |  | Yongqiang Cai |  |
| 1998 |  |  [H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection](https://openreview.net/forum?id=NPfDKT9OUJ3) |  | 0 |  | Gefan Zhang, Junchi Yan, Wentong Li, Xue Yang, Xuehui Wang, Yue Zhou |  |
| 1999 |  |  [Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore](https://openreview.net/forum?id=xzmqxHdZAwO) |  | 0 |  | Feng Zheng, Guoyang Xie, Jiaqi Liu, Jinbao Wang, Yaochu Jin |  |
| 2000 |  |  [Representation Learning for Low-rank General-sum Markov Games](https://openreview.net/forum?id=8FroynZv4C) |  | 0 |  | Chengzhuo Ni, Chi Jin, Mengdi Wang, Xuezhou Zhang, Yuda Song, Zihan Ding |  |
| 2001 |  |  [Surgical Fine-Tuning Improves Adaptation to Distribution Shifts](https://openreview.net/forum?id=APuPRxjHvZ) |  | 0 |  | Ananya Kumar, Annie S. Chen, Chelsea Finn, Fahim Tajwar, Huaxiu Yao, Percy Liang, Yoonho Lee |  |
| 2002 |  |  [Diversify and Disambiguate: Out-of-Distribution Robustness via Disagreement](https://openreview.net/forum?id=RVTOp3MwT3n) |  | 0 |  | Chelsea Finn, Huaxiu Yao, Yoonho Lee |  |
| 2003 |  |  [On amortizing convex conjugates for optimal transport](https://openreview.net/forum?id=TQ5WUwS_4ai) |  | 0 |  | Brandon Amos |  |
| 2004 |  |  [DualAfford: Learning Collaborative Visual Affordance for Dual-gripper Manipulation](https://openreview.net/forum?id=I_YZANaz5X) |  | 0 |  | Hao Dong, Kaichun Mo, Qingnan Fan, Ruihai Wu, Yan Zhao, Yourong Zhang, Zhehuan Chen |  |
| 2005 |  |  [Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance Matching](https://openreview.net/forum?id=CjTHVo1dvR) |  | 0 |  | Hongyu Guo, Jian Tang, Shengchao Liu |  |
| 2006 |  |  [SIMPLE: Specialized Model-Sample Matching for Domain Generalization](https://openreview.net/forum?id=BqrPeZ_e5P) |  | 0 |  | Dongsheng Li, Haipeng Zhang, Kan Ren, Xinyang Jiang, Yifei Shen, Ziyue Li |  |
| 2007 |  |  [The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from a Single Image](https://openreview.net/forum?id=6kxApT2r2i) |  | 0 |  | Aaqib Saeed, Yuki M. Asano |  |
| 2008 |  |  [Delving into Semantic Scale Imbalance](https://openreview.net/forum?id=07tc5kKRIo) |  | 0 |  | Fang Liu, Licheng Jiao, Shuyuan Yang, Xu Liu, Yanbiao Ma, Yuxin Li |  |
| 2009 |  |  [DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks](https://openreview.net/forum?id=jgmuRzM-sb6) |  | 0 |  | Jianye Hao, Wenqian Li, Yan Pang, Yinchuan Li, Zhigang Li |  |
| 2010 |  |  [Contextual Image Masking Modeling via Synergized Contrasting without View Augmentation for Faster and Better Visual Pretraining](https://openreview.net/forum?id=A3sgyt4HWp) |  | 0 |  | Feng Zhu, Junchi Yan, Rui Zhao, Shaofeng Zhang |  |
| 2011 |  |  [Patch-Level Contrasting without Patch Correspondence for Accurate and Dense Contrastive Representation Learning](https://openreview.net/forum?id=10R_bcjFwJ) |  | 0 |  | Feng Zhu, Junchi Yan, Rui Zhao, Shaofeng Zhang |  |
| 2012 |  |  [Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins](https://openreview.net/forum?id=P5Z-Zl9XJ7) |  | 0 |  | Hehe Fan, Mohan S. Kankanhalli, Yi Yang, Zhangyang Wang |  |
| 2013 |  |  [Guiding Safe Exploration with Weakest Preconditions](https://iclr.cc/virtual/2023/poster/12258) |  | 0 |  | Greg Anderson, Isil Dillig, Swarat Chaudhuri |  |

# KDD2025

## 会议论文列表

本会议共有 250 篇论文

| 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- |
|  |  [RankElectra: Semi-supervised Pre-training of Learning-to-Rank Electra for Web-scale Search](https://doi.org/10.1145/3690624.3709395) |  | 0 | While representation learning has been used to boost the performance of Learning-to-Rank (LTR) models through distilling key features for webpage ranking, the weak supervision signals extracted from users' sparse click-through data lead to inadequate representation of query-webpage pairs for ranking score prediction. Recent studies in generative LTR pre-training demonstrate the feasibility of incorporating reconstruction loss for enhanced ranking score prediction. However, LTR is afterall a regression task and it might be reasonable to find an alternate route that pre-trains LTR models with discriminative losses. Following the success of Electra in representation learning for natural language processing (NLP), this work proposes RankElectra that pre-trains the LTR model as a discriminator module inside a generative learning framework. Specifically, RankElectra first structures sparsely-annotated query-webpage pairs into a bipartite graph, with query and webpage feature vectors as node types and ranking scores as the connecting edges, and then leverages positive and negative extension strategies to densify the graph by link predictions. Later, this work proposes a novel Electra module that pre-trains the LTR model as a discriminator module for node reconstruction tasks, where node features of selected edges would be randomly masked and reconstructed by a generator, and the discriminator learns to classify whether the reconstructed features are the original or replaced as well as perform correct ranking. Finally, the pre-trained discriminator module, rather than the generator, would be fine-tuned on the labeled graph. We carried out extensive offline and online evaluations using the real-world web traffic of Baidu search engine. The results show that RankElectra could significantly boost the ranking performance of Baidu Search compared with numbers of competitor systems. | Yuchen Li, Haoyi Xiong, Yongqi Zhang, Jiang Bian, Tianhao Peng, Xuhong Li, Shuaiqiang Wang, Linghe Kong, Dawei Yin | Shanghai Jiao Tong University, Shanghai, China; Baidu Inc., Beijing, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China |
|  |  [Towards Web-scale Recommendations with LLMs: From Quality-aware Ranking to Candidate Generation](https://doi.org/10.1145/3690624.3709413) |  | 0 | Explore Further @ Bing is a webpage-to-webpage recommendation product, enhancing the search experience on Bing by surfacing engaging webpage recommendations tied to the search result URLs. In this paper, we present our approach for leveraging Large Language Models (LLMs) for enhancing our web-scale recommendation system. We describe the development and validation of our LLM-powered recommendation quality metric RecoDCG. We discuss our core techniques for utilizing LLMs to make our ranking stage quality-aware. Furthermore, we detail Q' recall, a recall path that enhances our system's candidate generation stage by leveraging LLMs to produce complementary and engaging recommendation candidates. We also address how we optimize our system for multiple objectives, balancing recommendation quality with click metrics. We deploy our work to production, achieving a significant improvement in recommendation quality. We share results from offline and online experiments as well as insights and steps we took to ensure our approaches scale effectively for our web-scale needs. | Jaidev Shah, Iman Barjasteh, Amey Barapatre, Rana Forsati, Gang Luo, Fan Wu, Yuan Fang, Xue Deng, Blake Shepard, Ronak Shah, Linjun Yang, Hongzhi Li | Microsoft AI, Santa Clara, CA, USA; Microsoft AI, Redmond, WA, USA; Microsoft AI, Suzhou, Suzhou, China |
|  |  [Multi-granularity Interest Retrieval and Refinement Network for Long-Term User Behavior Modeling in CTR Prediction](https://doi.org/10.1145/3690624.3709438) |  | 0 | Click-through Rate (CTR) prediction is crucial for online personalization platforms. Recent advancements have shown that modeling rich user behaviors can significantly improve the performance of CTR prediction. Current long-term user behavior modeling algorithms predominantly follow two cascading stages. The first stage retrieves subsequence related to the target item from the long-term behavior sequence, while the second stage models the relationship between the subsequence and the target item. Despite significant progress, these methods have two critical flaws. First, the retrieval query typically includes only target item information, limiting the ability to capture the user's diverse interests. Second, relational information, such as sequential and interactive information within the subsequence, is frequently overlooked. Therefore, it requires to be further mined to more accurately model user interests. To this end, we propose Multi-granularity Interest Retrieval and Refinement Network (MIRRN). Specifically, we first construct queries based on behaviors observed at different time scales to obtain subsequences, each capturing users' interest at various granularities. We then introduce an noval multi-head Fourier transformer to efficiently learn sequential and interactive information within the subsequences, leading to more accurate modeling of user interests. Finally, we employ multi-head target attention to adaptively assess the impact of these multi-granularity interests on the target item. Extensive experiments have demonstrated that MIRRN significantly outperforms state-of-the-art baselines. Furthermore, an A/B test shows that MIRRN increases the average number of listening songs by 1.32 0.55 available at https://github.com/psycho-demon/MIRRN. | Xiang Xu, Hao Wang, Wei Guo, Luankang Zhang, Wanshan Yang, Runlong Yu, Yong Liu, Defu Lian, Enhong Chen |  |
|  |  [MOPI-HFRS: A Multi-objective Personalized Health-aware Food Recommendation System with LLM-enhanced Interpretation](https://doi.org/10.1145/3690624.3709382) |  | 0 | The prevalence of unhealthy eating habits has become an increasingly concerning issue in the United States. However, major food recommendation platforms (e.g., Yelp) continue to prioritize users' dietary preferences over the healthiness of their choices. Although efforts have been made to develop health-aware food recommendation systems, the personalization of such systems based on users' specific health conditions remains under-explored. In addition, few research focus on the interpretability of these systems, which hinders users from assessing the reliability of recommendations and impedes the practical deployment of these systems. In response to this gap, we first establish two large-scale personalized health-aware food recommendation benchmarks at the first attempt. We then develop a novel framework, Multi-Objective Personalized Interpretable Health-aware Food Recommendation System (MOPI-HFRS), which provides food recommendations by jointly optimizing the three objectives: user preference, personalized healthiness and nutritional diversity, along with an large language model (LLM)-enhanced reasoning module to promote healthy dietary knowledge through the interpretation of recommended results. Specifically, this holistic graph learning framework first utilizes two structure learning and a structure pooling modules to leverage both descriptive features and health data. Then it employs Pareto optimization to achieve designed multi-facet objectives. Finally, to further promote the healthy dietary knowledge and awareness, we exploit an LLM by utilizing knowledge-infusion, prompting the LLMs with knowledge obtained from the recommendation model for interpretation. | Zheyuan Zhang, Zehong Wang, Tianyi Ma, Varun Sameer Taneja, Sofia Nelson, Nhi Ha Lan Le, Keerthiram Murugesan, Mingxuan Ju, Nitesh V. Chawla, Chuxu Zhang, Yanfang Ye |  |
|  |  [CATER: A Cluster-Based Alternative-Term Recommendation Framework for Large-Scale Web Search at NAVER](https://doi.org/10.1145/3690624.3709426) |  | 0 | Recently, searching for information by using search engines such as Google, Bing, and NAVER has become ubiquitous. While they attempt to provide information based on the search queries that users enter, it is not trivial to accurately capture the search intent of users. Motivated by this situation, NAVER Corp., the largest portal company in Korea, has developed a framework named as CATER (Cluster-based Alternative TErm Recommendation) framework that suggests alternative terms ("al-terms,'' in short) for better search outcomes relevant to a user's search intent. We introduce four design considerations (DCs) that were considered when designing and implementing CATER. Then, we describe how our CATER addresses the four DCs by using a clustering stage that dynamically maintains a pool of topic-oriented clusters containing terms, and a recommendation stage that identifies the top-k clusters (i.e., topics) and the top-k al-terms for each cluster. Furthermore, we present the scalable architecture adopted by CATER. Through various offline and online A/B tests using real-world datasets from NAVER, we validate that CATER successfully incorporates all DCs and that all design choices help improve the recommendation accuracy. | Jiwon Son, Jaeyoon Kim, Taekin Kim, YeonChang Lee, SangWook Kim | Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Hanyang University, Seoul, Republic of Korea; Naver Corporation, Seongnam, Republic of Korea |
|  |  [Learning Attribute as Explicit Relation for Sequential Recommendation](https://doi.org/10.1145/3690624.3709267) |  | 0 | The data on user behaviors is sparse given the vast array of user-item combinations. Attributes related to users (e.g., age), items (e.g., brand), and behaviors (e.g., co-purchase) serve as crucial input sources for item-item transitions of user's behavior prediction. While recent Transformer-based sequential recommender systems learn the attention matrix for each attribute to update item representations, the attention of a specific attribute is optimized by gradients from all input sources, leading to potential information mixture. Besides, Transformers mainly focus on intra-sequence attention for item attributes, neglecting cross-sequence relations and user attributes. Addressing these challenges, we propose the Attribute Transformer (AttrFormer) to learn attributes as explicit relations. This model transforms each type of attribute into an explicit relation defined in the feature space, and it ensures no information mixing among different input sources. Explicit relations introduce cross-sequence and intra-sequence relations. AttrFormer has novel relation-augmented heads to handle them at both the item and behavioral levels, seamlessly integrating the augmented heads into the multi-head attention mechanism. Furthermore, we employ position-to-position aggregation to refine behavior representation for users with similar patterns at the sequence level. To capture the subjective nature of user preferences, AttrFormer is trained using posterior targets where upcoming user behaviors follow a multinomial distribution with a Dirichlet prior. Our evaluations on four popular datasets, including Amazon (Toys & Games and Beauty) and MovieLens (1M and 25M versions), reveal that AttrFormer outperforms leading Transformer baselines, achieving around 20% improvement in NDCG@20 scores. Extensive ablation studies also demonstrate the efficiency of AttrFormer in managing long behavior sequences and inter-sequence relations. | Gang Liu, Fan Yang, Yang Jiao, Alireza Bagheri Garakani, Tian Tong, Yan Gao, Meng Jiang | University of Notre Dame, Notre Dame, IN, USA; Amazon, Seattle, WA, USA |
|  |  [From Missteps to Mastery: Enhancing Low-Resource Dense Retrieval through Adaptive Query Generation](https://doi.org/10.1145/3690624.3709225) |  | 0 | Document retrieval, designed to recall query-relevant documents from expansive collections, is essential for information-seeking tasks, such as web search and open-domain question-answering. Advances in representation learning and pretrained language models (PLMs) have driven a paradigm shift from traditional sparse retrieval methods to more effective dense retrieval approaches, forging enhanced semantic connections between queries and documents and establishing new performance benchmarks. However, reliance on extensive annotated document-query pairs limits their competitiveness in low-resource scenarios. Recent research efforts employing the few-shot capabilities of large language models (LLMs) and prompt engineering for synthetic data generation have emerged as a promising solution. Nonetheless, these approaches are hindered by the generation of lower-quality data within the conventional dense retrieval training process. To this end, in this paper, we introduce iGFT, a framework aimed at enhancing low-resource dense retrieval by integrating a three-phase process --- Generation, Filtering, and Tuning --- coupled with an iterative optimization strategy. Specifically, we first employ supervised fine-tuning on limited ground truth data, enabling an LLM to function as the generator capable of producing potential queries from given documents. Subsequently, we present a multi-stage filtering module to minimize noise in the generated data while retaining samples poised to significantly improve the dense retrieval model's performance in the follow-up fine-tuning process. Furthermore, we design a novel iterative optimization strategy that dynamically optimizes the query generator for producing more informative queries, thereby enhancing the efficacy of the entire framework. Finally, extensive experiments conducted on a series of publicly available retrieval benchmark datasets have demonstrated the effectiveness of the proposed iGFT. | Zhenyu Tong, Chuan Qin, Chuyu Fang, Kaichun Yao, Xi Chen, Jingshuai Zhang, Chen Zhu, Hengshu Zhu | Baidu Inc., Beijing, China; Computer Network Information Center, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; University of Science and Technology of China, Hefei, Anhui, China; University of the Chinese Academy of Sciences, Beijing, China |
|  |  [Embedding Prior Task-specific Knowledge into Language Models for Context-aware Document Ranking](https://doi.org/10.1145/3690624.3709282) |  | 0 | Exploiting users' contextual behaviors in the current session has been proven favorable to the document ranking task. Recently, the context-aware document ranking task has benefited from pre-trained language models (PLMs) due to their superior ability in language modeling. Most PLM-based context-aware document ranking models implicitly learn task-specific knowledge by fine-tuning PLMs on historical search logs. However, since search log data is noisy and contains various user intents and search patterns, such a black-box way may prevent models from fully mastering effective context-aware search knowledge. To solve this problem, we propose LOCK, a PLM-based context-aware document ranking model that explicitly embeds task-specific prior knowledge into PLMs to guide the model optimization. From local to global, we identify three types of task-specific knowledge, including intra-turn signals, inter-turn signals, and global session signals. LOCK formulates such prior knowledge into prior attention biases for impacting the fine-tuning of PLMs. This operation can guide the ranking model by task-specific prior knowledge, thereby improving model convergence and ranking ability. Additionally, we introduce a task-specific pre-training stage that involves masked language modeling and the soft reconstruction of the prior attention matrix, which helps the PLMs adapt to our task. Extensive experiments validate the effectiveness and convergence of our method. | Shuting Wang, Yutao Zhu, Zhicheng Dou | Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China |
|  |  [GLINT-RU: Gated Lightweight Intelligent Recurrent Units for Sequential Recommender Systems](https://doi.org/10.1145/3690624.3709304) |  | 0 | Transformer-based models have gained significant traction in sequential recommender systems (SRSs) for their ability to capture user-item interactions effectively. However, these models often suffer from high computational costs and slow inference. Meanwhile, existing efficient SRS approaches struggle to embed high-quality semantic and positional information into latent representations. To tackle these challenges, this paper introduces GLINT-RU, a lightweight and efficient SRS leveraging a single-layer dense selective Gated Recurrent Units (GRU) module to accelerate inference. By incorporating a dense selective gate, GLINT-RU adaptively captures temporal dependencies and fine-grained positional information, generating high-quality latent representations. Additionally, a parallel mixing block infuses fine-grained positional features into user-item interactions, enhancing both recommendation quality and efficiency. Extensive experiments on three datasets demonstrate that GLINT-RU achieves superior prediction accuracy and inference speed, outperforming baselines based on RNNs, Transformers, MLPs, and SSMs. These results establish GLINT-RU as a powerful and efficient solution for SRSs. | Sheng Zhang, Maolin Wang, Wanyu Wang, Jingtong Gao, Xiangyu Zhao, Yu Yang, Xuetao Wei, Zitao Liu, Tong Xu |  |
|  |  [Scenario Shared Instance Modeling for Click-through Rate Prediction](https://doi.org/10.1145/3690624.3709390) |  | 0 | Multi-scenario recommendation (MSR) is a popular training paradigm in industrial platforms for uniformly integrating information from multiple scenarios and serving them simultaneously. A key challenge in MSR research is accurately identifying the commonalities and distinctive information between scenarios. Currently, most existing MSR methods focus on implicitly extracting this information from the architectural level. However, this continues to increase the complexity and training overhead of MSR. Furthermore, the custom components responsible for extracting implicit information in each MSR method are too dependent on the specific MSR architecture and are not easily reused in other methods. Given these challenges, we first show in a motivating experiment that it may be beneficial to explicitly select a reasonable set of shared instances that can affect parameter optimization in all scenarios during the training of MSR, i.e., to explicitly obtain the critical information required for MSR from the data level. Then, this paper proposes SSIM with an adaptive selection network. Specifically, SSIM can be integrated with existing MSR methods in a lightweight way to adaptively select an informative and shareable subset of instances from each scenario to improve recommendations. In particular, the selected multi-scenario shared subset has extraordinary reusability and can be easily saved to benefit model training of various future MSR models. Finally, we evaluate SSIM and demonstrate its effectiveness through experiments on two public multi-scenario benchmarks and an online A/B test. | Dugang Liu, Chaohua Yang, Yuwen Fu, Xing Tang, Gongfu Li, Fuyuan Lyu, Xiuqiang He, Zhong Ming | Shenzhen Technology University, Shenzhen, Guangdong, China; FiT, Tencent, Shenzhen, Guangdong, China; McGill University, Montreal, Quebec, Canada |
|  |  [Multi-Branch Collaborative Learning Network for Video Quality Assessment in Industrial Video Search](https://doi.org/10.1145/3690624.3709408) |  | 0 | Video Quality Assessment (VQA) is vital for large-scale video retrieval systems, aimed at identifying quality issues to prioritize high-quality videos. In industrial systems, low-quality video characteristics fall into four categories: visual-related issues like mosaics and black boxes, textual issues from video titles and OCR content, and semantic issues like frame incoherence and frame-text mismatch from AI-generated videos. Despite their prevalence in industrial settings, these low-quality videos have been largely overlooked in academic research, posing a challenge for accurate identification. To address this, we introduce the Multi-Branch Collaborative Network (MBCN) tailored for industrial video retrieval systems. MBCN features four branches, each designed to tackle one of the aforementioned quality issues. After each branch independently scores videos, we aggregate these scores using a weighted approach and a squeeze-and-excitation mechanism to dynamically address quality issues across different scenarios. We implement point-wise and pair-wise optimization objectives to ensure score stability and reasonableness. Extensive offline and online experiments on a world-level video search engine demonstrate MBCN's effectiveness in identifying video quality issues, significantly enhancing the retrieval system's ranking performance. Detailed experimental analyses confirm the positive contribution of all four evaluation branches. Furthermore, MBCN significantly improves recognition accuracy for low-quality AI-generated videos compared to the baseline. | Hengzhu Tang, Zefeng Zhang, Zhiping Li, Zhenyu Zhang, Xing Wu, Li Gao, Suqi Cheng, Dawei Yin |  |
|  |  [Generative Retrieval for Book Search](https://doi.org/10.1145/3690624.3709435) |  | 0 | In book search, relevant book information should be returned in response to a query. Books contain complex, multi-faceted information such as metadata, outlines, and main text, where the outline provides hierarchical information between chapters and sections. Generative retrieval (GR) is a new retrieval paradigm that consolidates corpus information into a single model to generate identifiers of documents that are relevant to a given query. How can GR be applied to book search? Directly applying GR to book search is a challenge due to the unique characteristics of book search: The model needs to retain the complex, multi-faceted information of the book, which increases the demand for labeled data. Splitting book information and treating it as a collection of separate segments for learning might result in a loss of hierarchical information. We propose an effective Generative retrieval framework for Book Search (GBS) that features two main components: data augmentation and outline-oriented book encoding. For data augmentation, GBS constructs multiple query-book pairs for training; it constructs multiple book identifiers based on the outline, various forms of book contents, and simulates real book retrieval scenarios with varied pseudo-queries. This includes coverage-promoting book identifier augmentation, allowing the model to learn to index effectively, and diversity-enhanced query augmentation, allowing the model to learn to retrieve effectively. Outline-oriented book encoding improves length extrapolation through bi-level positional encoding and retentive attention mechanisms to maintain context over long sequences. Experiments on a proprietary Baidu dataset demonstrate that GBS outperforms strong baselines, achieving a 9.8% improvement in terms of MRR@20, over the state-of-the-art RIPOR method... | Yubao Tang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Shihao Liu, Shuaiqiang Wang, Dawei Yin, Xueqi Cheng |  |
|  |  [Online Item Cold-Start Recommendation with Popularity-Aware Meta-Learning](https://doi.org/10.1145/3690624.3709336) |  | 0 | With the rise of e-commerce and short videos, online recommender systems that can capture users' interests and update new items in real-time play an increasingly important role. In both online and offline recommendation systems, the cold-start problem caused by interaction sparsity has been impacting the effectiveness of recommendations for cold-start items. Many cold-start scheme based on fine-tuning or knowledge transferring shows excellent performance on offline recommendation. Yet, these schemes are infeasible for online recommendation on streaming data pipelines due to different training method, computational overhead and time constraints. Inspired by the above questions, we propose a model-agnostic recommendation algorithm called Popularity-Aware Meta-learning (PAM), to address the item cold-start problem under streaming data settings. PAM divides the incoming data into different meta-learning tasks by predefined item popularity thresholds. The model can distinguish and reweight behavior-related and content-related features in each task based on their different roles in different popularity levels, thus adapting to recommendations for cold-start samples. These task-fixing design significantly reduces additional computation and storage costs compared to offline methods. Furthermore, PAM also introduced data augmentation and an additional self-supervised loss specifically designed for low-popularity tasks, leveraging insights from high-popularity samples. This approach effectively mitigates the issue of inadequate supervision due to the scarcity of cold-start samples. Experimental results across multiple public datasets demonstrate the superiority of our approach over other baseline methods in addressing cold-start challenges in online streaming data scenarios. | Yunze Luo, Yuezihan Jiang, Yinjie Jiang, Gaode Chen, Jingchi Wang, Kaigui Bian, Peiyi Li, Qi Zhang |  |
|  |  [Achieving Nearly-Optimal Regret and Sample Complexity in Dueling Bandits with Applications in Online Recommendations](https://doi.org/10.1145/3690624.3709279) |  | 0 | We focus on the dueling bandits problem, which has recently drawn significant attention due to its wide-ranging applications in online recommendation systems and the alignment of large language models (LLMs), considers an online preference learning scenario where the learner iteratively selects arms based on pairwise comparison feedback to infer user preferences. Two primary objectives are typically considered in dueling bandits: Regret Minimization (RM), which aims to improve the overall quality of selected arms over time, and Best Arm Identification (BAI), which seeks to efficiently identify the best item with minimal user feedback. For instance, RM is exemplified by the objective of consistently providing high-quality items, while BAI reduces the required human feedback by minimizing the number of necessary comparisons. Conventional research treats RM and BAI as two conflicting objectives, optimizing one at the expense of the other. In this paper, we propose a novel framework that demonstrates the near-consistency of RM and BAI in dueling bandits by reducing the BAI in dueling bandits into a sequential noisy identification problem. Based on our formulation, we propose a black-box reduction technique that transforms any RM algorithm into a BAI algorithm, and prove that such reduction with optimal RM algorithm achieves optimal sample complexity and nearly-optimal cumulative weak regret simultaneously. Our proposed algorithm acheives a nearly-optimal BAI sample complexity and attains a cumulative weak regret that is order-wise equivalent to the best-known result simultaneously. Experiments on both synthetic benchmarks and real-world online recommendation tasks validate the effectiveness of the proposed method, providing empirical evidences for our theoretical findings. | Lanjihong Ma, YaoXiang Ding, ZhenYu Zhang, ZhiHua Zhou | State Key Lab of CAD & CG, Zhejiang University, Hangzhou, Zhejiang, China; Center for Advanced Intelligence Project, RIKEN, Tokyo, Tokyo, Japan |
|  |  [Beyond Item Dissimilarities: Diversifying by Intent in Recommender Systems](https://doi.org/10.1145/3690624.3709429) |  | 0 | It has become increasingly clear that recommender systems that overly focus on short-term engagement prevents users from exploring diverse interests, ultimately hurting long-term user experience. To tackle this challenge, numerous diversification algorithms have been proposed. These algorithms typically rely on measures of item similarity, aiming to maximize the dissimilarity across items in the final set of recommendations. However, in this work, we demonstrate the benefits of going beyond item-level similarities by utilizing higher-level user understanding–specifically, user intents that persist across multiple interactions–in diversification. Our approach is motivated by the observation that user behaviors on online platforms are largely driven by their underlying intents. Therefore, recommendations should ensure that diverse user intents are accurately represented. While intent has primarily been studied in the context of search, it is less clear how to incorporate real-time dynamic intent predictions into recommender systems. To address this gap, we develop a probabilistic intent-based whole-page diversification framework for the final stage of a recommender system. Starting with a prior belief of user intents, the proposed framework sequentially selects items for each position based on these beliefs and subsequently updates posterior beliefs about the intents. This approach ensures that different user intents are represented on a page, towards optimizing long-term user experience. We experiment with the intent diversification framework on YouTube, the world's largest video recommendation platform, serving billions of users daily. Live experiments on a diverse set of intents show that the proposed framework increases Daily Active Users (DAU) and overall user enjoyment, validating its effectiveness in facilitating long-term planning. | Yuyan Wang, Cheenar Banerjee, Samer Chucri, Fabio Soldo, Sriraj Badam, Ed H. Chi, Minmin Chen | Google, Inc. Mountain View; Google DeepMind Mountain View; Stanford University Stanford |
|  |  [TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear Travelling Salesman Model](https://doi.org/10.1145/3690624.3709234) |  | 0 | Traditional Learning-To-Rank (LETOR) approaches, including pairwise methods like RankNet and LambdaMART, often fall short by solely focusing on pairwise comparisons, leading to sub-optimal global rankings. Conversely, deep learning based listwise methods, while aiming to optimise entire lists, require complex tuning and yield only marginal improvements over robust pairwise models. To overcome these limitations, we introduce Travelling Salesman Problem Rank (TSPRank), a hybrid pairwise-listwise ranking method. TSPRank reframes the ranking problem as a Travelling Salesman Problem (TSP), a well-known combinatorial optimisation challenge that has been extensively studied for its numerous solution algorithms and applications. This approach enables the modelling of pairwise relationships and leverages combinatorial optimisation to determine the listwise ranking. This approach can be directly integrated as an additional component into embeddings generated by existing backbone models to enhance ranking performance. Our extensive experiments across three backbone models on diverse tasks, including stock ranking, information retrieval, and historical events ordering, demonstrate that TSPRank significantly outperforms both pure pairwise and listwise methods. Our qualitative analysis reveals that TSPRank's main advantage over existing methods is its ability to harness global information better while ranking. TSPRank's robustness and superior performance across different domains highlight its potential as a versatile and effective LETOR solution. The code and preprocessed data are available at https://github.com/waylonli/TSPRank-KDD2025. | Weixian Waylon Li, Yftah Ziser, Yifei Xie, Shay B. Cohen, Tiejun Ma |  |
|  |  [Exploring Preference-Guided Diffusion Model for Cross-Domain Recommendation](https://doi.org/10.1145/3690624.3709220) |  | 0 | Cross-domain recommendation (CDR) has been proven as a promising way to alleviate the cold-start issue, in which the most critical problem is how to draw an informative user representation in the target domain via the transfer of user preference existing in the source domain. Prior efforts mostly follow the embedding-and-mapping paradigm, which first integrate the preference into user representation in the source domain, and then perform a mapping function on this representation to the target domain. However, they focus on mapping features across domains, neglecting to explicitly model the preference integration process, which may lead to learning coarse user representation. Diffusion models (DMs), which contribute to more accurate user/item representations due to their explicit information injection capability, have achieved promising performance in recommendation systems. Nevertheless, these DMs-based methods cannot directly account for valuable user preference in other domains, leading to challenges in adapting to the transfer of preference for cold-start users. Consequently, the feasibility of DMs for CDR remains underexplored. To this end, we explore to utilize the explicit information injection capability of DMs for user preference integration and propose a Preference-Guided Diffusion Model for CDR to cold-start users, termed as DMCDR. Specifically, we leverage a preference encoder to establish the preference guidance signal with the user's interaction history in the source domain. Then, we explicitly inject the preference guidance signal into the user representation step by step to guide the reverse process, and ultimately generate the personalized user representation in the target domain, thus achieving the transfer of user preference across domains. Furthermore, we comprehensively explore the impact of six DMs-based variants on CDR. | Xiaodong Li, Hengzhu Tang, Jiawei Sheng, Xinghua Zhang, Li Gao, Suqi Cheng, Dawei Yin, Tingwen Liu |  |
|  |  [Exploring Feature-based Knowledge Distillation for Recommender System: A Frequency Perspective](https://doi.org/10.1145/3690624.3709248) |  | 0 | In this paper, we analyze the feature-based knowledge distillation for recommendation from the frequency perspective. By defining knowledge as different frequency components of the features, we theoretically demonstrate that regular feature-based knowledge distillation is equivalent to equally minimizing losses on all knowledge and further analyze how this equal loss weight allocation method leads to important knowledge being overlooked. In light of this, we propose to emphasize important knowledge by redistributing knowledge weights. Furthermore, we propose FreqD, a lightweight knowledge reweighting method, to avoid the computational cost of calculating losses on each knowledge. Extensive experiments demonstrate that FreqD consistently and significantly outperforms state-of-the-art knowledge distillation methods for recommender systems. Our code is available at https://github.com/woriazzc/KDs. | Zhangchi Zhu, Wei Zhang |  |
|  |  [Personalized Language Model Learning on Text Data Without User Identifiers](https://doi.org/10.1145/3690624.3709211) |  | 0 | In many practical natural language applications, user data are highly sensitive, requiring anonymous uploads of text data from mobile devices to the cloud without user identifiers. However, the absence of user identifiers restricts the ability of cloud-based language models to provide personalized services, which are essential for catering to diverse user needs. The trivial method of replacing an explicit user identifier with a static user embedding as model input still compromises data anonymization. In this work, we propose to let each mobile device maintain a user-specific distribution to dynamically generate user embeddings, thereby breaking the one-to-one mapping between an embedding and a specific user. We further theoretically demonstrate that to prevent the cloud from tracking users via uploaded embeddings, the local distributions of different users should either be derived from a linearly dependent space to avoid identifiability or be close to each other to prevent accurate attribution. Evaluation on both public and industrial datasets using different language models reveals a remarkable improvement in accuracy from incorporating anonymous user embeddings, while preserving real-time inference requirement. | Yucheng Ding, Yangwenjian Tan, Xiangyu Liu, Chaoyue Niu, Fandong Meng, Jie Zhou, Ning Liu, Fan Wu, Guihai Chen |  |
|  |  [Large-Scale Spectral Graph Neural Networks via Laplacian Sparsification](https://doi.org/10.1145/3690624.3709241) |  | 0 | Graph Neural Networks (GNNs) play a pivotal role in graph-based tasks for their proficiency in representation learning. Among the various GNN methods, spectral GNNs employing polynomial filters have shown promising performance on both homophilous and heterophilous graph structures. The scalability of spectral GNNs is limited because forward propagation requires multiple graph propagation executions, corresponding to the degree of the polynomial. On the other hand, scalable spectral GNNs detach the graph propagation and linear layers, allowing the message-passing phase to be pre-computed and ensuring effective scalability on large graphs. However, this pre-computation can disrupt end-to-end training, possibly impacting performance, and becomes impractical when dealing with high-dimensional input features. In response to these challenges, we propose a novel graph spectral sparsification method to approximate the propagation pattern of spectral GNNs. We prove that our proposed methods generate Laplacian sparsifiers for the random-walk matrix polynomial, incorporating both static and learnable polynomial coefficients. By considering multi-hop neighbor interactions into one-hop operations, our approach facilitates the use of scalable techniques. To empirically validate the effectiveness of our methods, we conduct an extensive experimental analysis on datasets spanning various graph scales and properties. The results show that our method yields superior results in comparison with the corresponding approximated base models. | Haipeng Ding, Zhewei Wei, Yuhang Ye | Full Professor, Renmin University of China; Researcher, Huawei Poisson Lab, Huawei Technologies Ltd.; PhD student, Gaoling School of Artificial Intelligence, Renmin University of China |
|  |  [Why Not Together? A Multiple-Round Recommender System for Queries and Items](https://doi.org/10.1145/3690624.3709261) |  | 0 | A fundamental technique of recommender systems involves modeling user preferences, where queries and items are widely used as symbolic representations of user interests. Queries delineate user needs at an abstract level, providing a high-level description, whereas items operate on a more specific and concrete level, representing the granular facets of user preference. While practical, both query and item recommendations encounter the challenge of sparse user feedback. To this end, we propose a novel approach named Multiple-round Auto Guess-and-Update System (MAGUS) that capitalizes on the synergies between both types, allowing us to leverage both query and item information to form user interests. This integrated system introduces a recursive framework that could be applied to any recommendation method to exploit queries and items in historical interactions and to provide recommendations for both queries and items in each interaction round. Empirical results from testing 12 different recommendation methods demonstrate that integrating queries into item recommendations via MAGUS significantly enhances the efficiency, with which users can identify their preferred items during multiple-round interactions. | Jiarui Jin, Xianyu Chen, Weinan Zhang, Yong Yu, Jun Wang |  |
|  |  [Attribute-Enhanced Similarity Ranking for Sparse Link Prediction](https://doi.org/10.1145/3690624.3709314) |  | 0 | Link prediction is a fundamental problem in graph data. In its most realistic setting, the problem consists of predicting missing or future links between random pairs of nodes from the set of disconnected pairs. Graph Neural Networks (GNNs) have become the predominant framework for link prediction. GNN-based methods treat link prediction as a binary classification problem and handle the extreme class imbalance---real graphs are very sparse---by sampling (uniformly at random) a balanced number of disconnected pairs not only for training but also for evaluation. However, we show that the reported performance of GNNs for link prediction in the balanced setting does not translate to the more realistic imbalanced setting and that simpler topology-based approaches are often better at handling sparsity. These findings motivate Gelato, a similarity-based link-prediction method that applies (1) graph learning based on node attributes to enhance a topological heuristic, (2) a ranking loss for addressing class imbalance, and (3) a negative sampling scheme that efficiently selects hard training pairs via graph partitioning. Experiments show that Gelato is more accurate and faster than GNN-based alternatives. | João Mattos, Zexi Huang, Mert Kosan, Ambuj Singh, Arlei Silva | PhD student, Computer Science, Rice University; Researcher, VISA; Researcher, TikTok Inc.; Assistant Professor, Computer Science, Rice University |
|  |  [Combinatorial Optimization Perspective based Framework for Multi-behavior Recommendation](https://doi.org/10.1145/3690624.3709278) |  | 0 | In real-world recommendation scenarios, users engage with items through various types of behaviors. Leveraging diversified user behavior information for learning can enhance the recommendation of target behaviors (e.g., buy), as demonstrated by recent multi-behavior methods. The mainstream multi-behavior recommendation framework consists of two steps: fusion and prediction. Recent approaches utilize graph neural networks for multi-behavior fusion and employ multi-task learning paradigms for joint optimization in the prediction step, achieving significant success. However, these methods have limited perspectives on multi-behavior fusion, which leads to inaccurate capture of user behavior patterns in the fusion step. Moreover, when using multi-task learning for prediction, the relationship between the target task and auxiliary tasks is not sufficiently coordinated, resulting in negative information transfer. To address these problems, we propose a novel multi-behavior recommendation framework based on the combinatorial optimization perspective, named COPF. Specifically, we treat multi-behavior fusion as a combinatorial optimization problem, imposing different constraints at various stages of each behavior to restrict the solution space, thus significantly enhancing fusion efficiency (COGCN). In the prediction step, we improve both forward and backward propagation during the generation and aggregation of multiple experts to mitigate negative transfer caused by differences in both feature and label distributions (DFME). Comprehensive experiments on three real-world datasets indicate the superiority of COPF. Further analyses also validate the effectiveness of the COGCN and DFME modules. Our code is available at https://github.com/1918190/COPF. | Chenhao Zhai, Chang Meng, Yu Yang, Kexin Zhang, Xuhao Zhao, Xiu Li |  |
|  |  [HyperZero: A Customized End-to-End Auto-Tuning System for Recommendation with Hourly Feedback](https://doi.org/10.1145/3690624.3709409) |  | 0 | Modern recommendation systems can be broadly divided into two key stages: the ranking stage, where the system predicts various user engagements (e.g., click-through rate, like rate, follow rate, watch time), and the value model stage, which aggregates these predictive scores through a function (e.g., a linear combination defined by a weight vector) to measure the value of each content by a single numerical score. Both stages play roughly equally important roles in real industrial systems; however, how to optimize the model weights for the second stage still lacks systematic study. This paper focuses on optimizing the second stage through auto-tuning technology. Although general auto-tuning systems and solutions - both from established production practices and open-source solutions - can address this problem, they typically require weeks or even months to identify a feasible solution. Such prolonged tuning processes are unacceptable in production environments for recommendation systems, as suboptimal value models can severely degrade user experience. An effective auto-tuning solution is required to identify a viable model within 2-3 days, rather than the extended timelines typically associated with existing approaches. In this paper, we introduce a practical auto-tuning system named HyperZero that addresses these time constraints while effectively solving the unique challenges inherent in modern recommendation systems. Moreover, this framework has the potential to be expanded to broader tuning tasks within recommendation systems. | Xufeng Cai, Ziwei Guan, Lei Yuan, Ali Selman Aydin, Tengyu Xu, Boying Liu, Wenbo Ren, Renkai Xiang, Songyi He, Haichuan Yang, Serena Li, Mingze Gao, Yue Weng, Ji Liu |  |
|  |  [Multi-Task Combinatorial Bandits for Budget Allocation](https://doi.org/10.1145/3690624.3709434) |  | 0 | Today's top advertisers typically manage hundreds of campaigns simultaneously and consistently launch new ones throughout the year. A crucial challenge for marketing managers is determining the optimal allocation of limited budgets across various ad lines in each campaign to maximize cumulative returns, especially given the huge uncertainty in return outcomes. In this paper, we propose to formulate budget allocation as a multi-task combinatorial bandit problem and introduce a novel online budget allocation system. The proposed system: i) integrates a Bayesian hierarchical model to intelligently utilize the metadata of campaigns and ad lines and budget size, ensuring efficient information sharing; ii) provides the flexibility to incorporate diverse modeling techniques such as Linear Regression, Gaussian Processes, and Neural Networks, catering to diverse environmental complexities; and iii) employs the Thompson sampling (TS) technique to strike a balance between exploration and exploitation. Through offline evaluation and online experiments, our system demonstrates robustness and adaptability, effectively maximizing the overall cumulative returns. A Python implementation of the proposed procedure is available at https://anonymous.4open.science/r/MCMAB. | Lin Ge, Yang Xu, Jianing Chu, David Cramer, Fuhong Li, Kelly Paulson, Rui Song |  |
|  |  [MerRec: A Large-scale Multipurpose Mercari Dataset for Consumer-to-Consumer Recommendation Systems](https://doi.org/10.1145/3690624.3709394) |  | 0 | In the evolving e-commerce field, recommendation systems crucially shape userexperience and engagement. The rise of Consumer-to-Consumer (C2C)recommendation systems, noted for their flexibility and ease of access forcustomer vendors, marks a significant trend. However, the academic focusremains largely on Business-to-Consumer (B2C) models, leaving a gap filled bythe limited C2C recommendation datasets that lack in item attributes, userdiversity, and scale. The intricacy of C2C recommendation systems is furtheraccentuated by the dual roles users assume as both sellers and buyers,introducing a spectrum of less uniform and varied inputs. Addressing this, weintroduce MerRec, the first large-scale dataset specifically for C2Crecommendations, sourced from the Mercari e-commerce platform, coveringmillions of users and products over 6 months in 2023. MerRec not only includesstandard features such as user_id, item_id, and session_id, but also uniqueelements like timestamped action types, product taxonomy, and textual productattributes, offering a comprehensive dataset for research. This dataset,extensively evaluated across six recommendation tasks, establishes a newbenchmark for the development of advanced recommendation algorithms inreal-world scenarios, bridging the gap between academia and industry andpropelling the study of C2C recommendations. | Lichi Li, Zainul Abi Din, Zhen Tan, Sam London, Tianlong Chen, Ajay H. Daptardar | Arizona State University; University of North Carolina at Chapel Hill; Mercari, Inc |
|  |  [Breaker: Removing Shortcut Cues with User Clustering for Single-slot Recommendation System](https://doi.org/10.1145/3690624.3709387) |  | 0 | In a single-slot recommendation system, users are only exposed to one item at a time, and the system cannot collect user feedback on multiple items simultaneously. Therefore, only pointwise modeling solutions can be adopted, focusing solely on modeling the likelihood of clicks or conversions for items by users to learn user-item preferences, without the ability to capture the ranking information among different items directly. However, since user-side information is often much more abundant than item-side information, the model can quickly learn the differences in user intrinsic tendencies, which are independent of the items they are exposed to. This can cause these intrinsic tendencies to become a shortcut bias for the model, leading to insufficient mining of the most concerned user-item preferences. To solve this challenge, we introduce the Breaker model. Breaker integrates an auxiliary task of user representation clustering with a multi-tower structure for cluster-specific preference modeling. By clustering user representations, we ensure that users within each cluster exhibit similar characteristics, which increases the complexity of the pointwise recommendation task on the user side. This forces the multi-tower structure with cluster-driven parameter learning to better model user-item preferences, ultimately eliminating shortcut biases related to user intrinsic tendencies. In terms of training, we propose a delayed parameter update mechanism to enhance training stability and convergence, enabling end-to-end joint training of the auxiliary clustering and classification tasks. Both offline and online experiments demonstrate that our method surpasses the baselines. It has already been deployed and is actively serving tens of millions of users daily on Meituan, one of the most popular e-commerce platforms for services. | Chao Wang, Yue Zheng, Yujing Zhang, Yan Feng, Zhe Wang, Xiaowei Shi, An You, Yu Chen |  |
|  |  [Producer-Side Experiments Based on Counterfactual Interleaving Designs for Online Recommender Systems](https://doi.org/10.1145/3690624.3709428) |  | 0 | Recommender systems have become an integral part of online platforms, providing personalized recommendations for purchases, content consumption, and interpersonal connections. These systems consist of two sides: the producer side comprises product sellers, content creators, or service providers, etc., and the consumer side includes buyers, viewers, or customers, etc. To optimize online recommender systems, A/B tests serve as the golden standard for comparing different ranking models and evaluating their impact on both the consumers and producers. While consumer-side experiments is relatively straightforward to design and commonly employed to assess the impact of ranking changes on the behavior of consumers (buyers, viewers, etc.), designing producer-side experiments for an online recommender/ranking system is notably more intricate because producer items in the treatment and control groups need to be ranked by different models and then merged into a unified ranking to be presented to each consumer. Current design solutions in the literature are ad hoc and lacking rigorous guiding principles. In this paper, we examine limitations of these existing methods and propose the principle of consistency and principle of monotonicity for designing producer-side experiments of online recommender systems. Building upon these principles, we also present a systematic solution based on counterfactual interleaving designs to accurately measure the impacts of ranking changes on the producers (sellers, creators, etc.). | Yan Wang, Shan Ba | LinkedIn Corporation |
|  |  [Mutual Information-aware Knowledge Distillation for Short Video Recommendation](https://doi.org/10.1145/3690624.3709403) |  | 0 | Short-video sharing platforms engaging billions of users have attracted intense interest recently. A key insight is that user feedback on these platforms is heavily influenced by preceding exposed videos in the same request, called context cumulative effects. For example, multiple repeated videos in a request often cause user fatigue and influence user feedback. However, related factors, such as the other exposed items in the same request, are available during model training but not accessible during online serving. Vanilla distillation methods mitigate the training-inference inconsistency, struggling to capture the dynamic dependence between context cumulative effects and user feedback. To address this problem, we propose the Mutual Information-aware Knowledge Distillation (MIKD) framework, which fuses such effects and user-item matching degrees by evaluating their impacts on user feedback based on mutual information estimation. Rigorous analysis and extensive experiments demonstrate that MIKD precisely extracts personal interests and consistently improves performance. We conduct online A/B testing on a leading short-video sharing mobile app, and the results demonstrate the effectiveness of the proposed method. MIKD has been successfully deployed online to serve the main traffic and optimize user experiences. | Han Xu, Taoxing Pan, Zhiqiang Liu, Xiaoxiao Xu | Kuaishou Technology, Beijing, China |
|  |  [Large-scale Human Mobility Data Regeneration for Open Urban Research](https://doi.org/10.1145/3690624.3709380) |  | 0 | Large-scale human mobility data contains rich spatial and temporal information for urban sensing, crowd flow modeling, and urban planning. However, it is usually difficult to access wide-coverage, long-term, and consistent-time human mobility data. Most of the publicly available datasets are actually only records of discontinuous trajectories of a very small portion of urban citizens in asynchronous time due to the limited usage of apps for location data collection or the limited number of volunteers. To address this problem and empower open urban research, this paper constructs a high-quality human mobility dataset by generating large-scale citizen trajectories based on massive cellular signaling data. Particularly, we first propose a heatmap diffusion module to generate a probability heatmap that produces plausible trajectories at both the individual and city scales. Then, we propose a masked trajectory AutoEncoder, which can generate individual trajectory embeddings from partially given or empty trajectories. Third, a flexible framework is provided to incorporate the heatmap diffusion module with the masked trajectory embeddings, demonstrating significant flexibility in handling both fully masked trajectories for city-wide analysis and partially masked trajectories for specific locations. We have conducted extensive experiments to validate the utility of the regenerated trajectories at both individual and region levels for various applications. Numerous case studies further illustrate that our model learns not only the distribution of the trajectories but also the semantics of different urban areas. In summary, this paper provides a Heatmap Diffusion framework based on a Masked Trajectory AutoEncoder to regenerate flexible trajectories for open urban research. Correspondingly, we will try to open a large-scale human mobility data service for open urban research. Further information can be found at https://github.com/Rising0321/FinalOpenUR. | Ruixing Zhang, Yunqi Liu, Liangzhe Han, Leilei Sun, Chuanren Liu, Jibin Wang, Weifeng Lv |  |
|  |  [Chainlet Orbits: Topological Address Embedding for Blockchain](https://doi.org/10.1145/3690624.3709322) |  | 0 | The rise of cryptocurrencies like Bitcoin, which enable transactions with a degree of pseudonymity, has led to a surge in various illicit activities, including ransomware payments and transactions on darknet markets. These illegal activities often utilize Bitcoin as the preferred payment method. However, current tools for detecting illicit behavior either rely on a few heuristics and laborious data collection processes or employ computationally inefficient graph neural network (GNN) models that are challenging to interpret. To overcome the computational and interpretability limitations of existing techniques, we introduce an effective solution called Chainlet Orbits. This approach embeds Bitcoin addresses by leveraging their topological characteristics in transactions. By employing our innovative address embedding, we investigate e-crime in Bitcoin networks by focusing on distinctive substructures that arise from illicit behavior. The results of our node classification experiments demonstrate superior performance compared to state-of-the-art methods, including both topological and GNN-based approaches. Moreover, our approach enables the use of interpretable and explainable machine learning models in as little as 15 minutes for most days on the Bitcoin transaction network. | Poupak Azad, Baris Coskunuzer, Murat Kantarcioglu, Cuneyt Gurcan Akcora |  |
|  |  [Advancing Confidence Calibration and Quantification in Medication Recommendation](https://doi.org/10.1145/3690624.3709232) |  | 0 | Medication recommendation (MR) has undergone rapid advancement in recent years, driven by its significant practical implications in healthcare. However, such high-risk scenarios still experience two critical yet overlooked challenges: the prevalent overconfidence in raw confidence for individual medications and the lack of a robust solution for confidence quantification in medication combinations. This paper represents the first in-depth study addressing this gap. We introduce two innovative methodologies tailored to the unique challenges of MR scenarios: 1) A discernible binning-based calibration method with theoretical guarantees for the confidence of individual medication. It guarantees distinct accuracy levels between adjacent bins and maintains consistent statistical reliability across calibration and test data, enabling calibrated confidence to reflect the correctness of medication recommendations distinctively. 2) A sample-based quantification method for the set confidence of medication combination, which is applicable for various existing performance metrics in MR. Utilizing representative deep MR models as backbones and conducting extensive experiments on the widely recognized MIMIC datasets, we empirically prove the effectiveness and robustness of our proposed methods. Our approaches not only improve the reliability of MR but also pave the way for more informed decision-making in clinical settings. | Qianyu Chen, Xin Li, Yujie Fang, Mingzhong Wang | University of the Sunshine Coast, Sippy Downs, QLD, Australia; Beijing Institute of Technology, Beijing, China |
|  |  [Scalable Link Recommendation for Influence Maximization](https://doi.org/10.1145/3690624.3709190) |  | 0 | The rise of link recommendation systems in online social networks has sparked significant research interest in strategically adding links to enhance social influence. This paper delves into the influence maximization with augmentation (IMA) problem that aims to add k edges connecting seed nodes and ordinary nodes to boost the influence propagation of the given seed set. IMA is a monotone submodular maximization problem so that the greedy algorithm provides a (1-1/e-ε)-approximate solution, where ε is an error term caused by the intractable nature of influence spread computation. Previous work often utilizes an unbiased estimator that relies on the chosen edges for influence estimation, resulting in non-submodular estimate with respect to edge selection. To ensure the overall error being bounded by ε, such an estimator requires Θ(ε/k) multiplicative error for each estimation, incurring prohibitive overhead. Meanwhile, some other work approximates IMA via conventional influence maximization (IM) on an augmented graph by adding a new node for every edge candidate, leading to heavy extra sampling due to a significant increase in graph size. To address these challenges, we design a novel unbiased estimator on the original graph that is independent of the chosen edges by leveraging the tractability of one-hop influence computation. We show that the estimate via our estimator is submodular so that it enables the estimate of all k edges in a whole with a bounded estimation error of Θ(ε), saving O(k2) time compared to the chosen-edge-dependent estimator while retaining the same graph size. Moreover, we propose several techniques based on the properties of our estimator to further speed up the greedy selection. Putting it together, we develop a scalable algorithm for the IMA problem, namely ScaLIM. Finally, extensive experiments are conducted to validate the effectiveness and efficiency of our proposed approach, e.g., ScaLIM is faster than baselines by nearly two orders of magnitude. | Xiaolong Chen, Jing Tang | The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China |
|  |  [Seeing the Unseen in Micro-Video Popularity Prediction: Self-Correlation Retrieval for Missing Modality Generation](https://doi.org/10.1145/3690624.3709308) |  | 0 | Micro-video popularity prediction (MVPP) plays a crucial role in numerous real-world applications, including product marketing and recommendation systems. While existing methodologies predominantly assume complete modalities during multimodal learning, this assumption often fails to hold in practical scenarios due to various constraints, such as privacy concerns or data integrity issues. To address this limitation, we propose SCRAG, a novel Self-Correlation Retrieval-Augmented Generative framework designed to enhance missing-modality robustness in MVPP. SCRAG operates in a retrieval-guided generation manner that explores relevant knowledge to enhance the reconstruction of missing content, which consists of two primary components: (1) a self-correlation retriever and (2) a multimodal mixture-of-experts generator. It first acquires instances pertinent to the missing content through multimodal prompt alignment. Subsequently, the generator extracts contextual modal information from the retrieved context-rich instances. By learning the joint distribution of modalities, SCRAG effectively recovers missing content and addresses the modal heterogeneity challenge inherent in cross-modal generation approaches. Extensive experiments conducted on three real-world datasets demonstrate that SCRAG consistently outperforms state-of-the-art baselines, underscoring its effectiveness in handling incomplete modalities and improving the accuracy of micro-video popularity prediction. | Zhangtao Cheng, Jian Lang, Ting Zhong, Fan Zhou | University of Electronic Science and Technology of China, Chengdu, Sichuan, China |
|  |  [Controlling Diversity at Inference: Guiding Diffusion Recommender Models with Targeted Category Preferences](https://doi.org/10.1145/3690624.3709216) |  | 0 | Diversity control is an important task to alleviate bias amplification and filter bubble problems. The desired degree of diversity may fluctuate based on users' daily moods or business strategies. However, existing methods for controlling diversity often lack flexibility, as diversity is decided during training and cannot be easily modified during inference. We propose D3Rec (Disentangled Diffusion model for Diversified Recommendation), an end-to-end method that controls the accuracy-diversity trade-off at inference. D3Rec meets our three desiderata by (1) generating recommendations based on category preferences, (2) controlling category preferences during the inference phase, and (3) adapting to arbitrary targeted category preferences. In the forward process, D3Rec removes category preferences lurking in user interactions by adding noises. Then, in the reverse process, D3Rec generates recommendations through denoising steps while reflecting desired category preferences. Extensive experiments on real-world and synthetic datasets validate the effectiveness of D3Rec in controlling diversity at inference. | Gwangseok Han, Wonbin Kweon, Minsoo Kim, Hwanjo Yu |  |
|  |  [Multi-level Matching Network for Multimodal Entity Linking](https://doi.org/10.1145/3690624.3709306) |  | 0 | Multimodal entity linking (MEL) aims to link ambiguous mentions within multimodal contexts to corresponding entities in a multimodal knowledge base. Most existing approaches to MEL are based on representation learning or vision-and-language pre-training mechanisms for exploring the complementary effect among multiple modalities. However, these methods suffer from two limitations. On the one hand, they overlook the possibility of considering negative samples from the same modality. On the other hand, they lack mechanisms to capture bidirectional cross-modal interaction. To address these issues, we propose a Multi-level Matching network for Multimodal Entity Linking (M3EL). Specifically, M3EL is composed of three different modules: (i) a Multimodal Feature Extraction module, which extracts modality-specific representations with a multimodal encoder and introduces an intra-modal contrastive learning sub-module to obtain better discriminative embeddings based on uni-modal differences; (ii) an Intra-modal Matching Network module, which contains two levels of matching granularity: Coarse-grained Global-to-Global and Fine-grained Global-to-Local, to achieve local and global level intra-modal interaction; (iii) a Cross-modal Matching Network module, which applies bidirectional strategies, Textual-to-Visual and Visual-to-Textual matching, to implement bidirectional cross-modal interaction. Extensive experiments conducted on WikiMEL, RichpediaMEL, and WikiDiverse datasets demonstrate the outstanding performance of M3EL when compared to the state-of-the-art baselines. | Zhiwei Hu, Víctor GutiérrezBasulto, Ru Li, Jeff Z. Pan |  |
|  |  [Forward Once for All: Structural Parameterized Adaptation for Efficient Cloud-coordinated On-device Recommendation](https://doi.org/10.1145/3690624.3709178) |  | 0 | In cloud-centric recommender system, regular data exchanges between user devices and cloud could potentially elevate bandwidth demands and privacy risks. On-device recommendation emerges as a viable solution by performing reranking locally to alleviate these concerns. Existing methods primarily focus on developing local adaptive parameters, while potentially neglecting the critical role of tailor-made model architecture. Insights from broader research domains suggest that varying data distributions might favor distinct architectures for better fitting. In addition, imposing a uniform model structure across heterogeneous devices may result in risking inefficacy on less capable devices or sub-optimal performance on those with sufficient capabilities. In response to these gaps, our paper introduces Forward-OFA, a novel approach for the dynamic construction of device-specific networks (both structure and parameters). Forward-OFA employs a structure controller to selectively determine whether each block needs to be assembled for a given device. However, during the training of the structure controller, these assembled heterogeneous structures are jointly optimized, where the co-adaption among blocks might encounter gradient conflicts. To mitigate this, Forward-OFA is designed to establish a structure-guided mapping of real-time behaviors to the parameters of assembled networks. Structure-related parameters and parallel components within the mapper prevent each part from receiving heterogeneous gradients from others, thus bypassing the gradient conflicts for coupled optimization. Besides, direct mapping enables Forward-OFA to achieve adaptation through only one forward pass, allowing for swift adaptation to changing interests and eliminating the requirement for on-device backpropagation. Experiments on real-world datasets demonstrate the effectiveness and efficiency of Forward-OFA. | Kairui Fu, Zheqi Lv, Shengyu Zhang, Fan Wu, Kun Kuang |  |
|  |  [Progressive Dependency Representation Learning for Stock Ranking in Uncertain Risk Contrasting](https://doi.org/10.1145/3690624.3709189) |  | 0 | The practice of ranking a list of stocks to facilitate investment decisions has garnered a lot of attention in the fintech field, aiming at minimizing investment risk while maximizing profitable returns. With recent developments in deep representation learning such as temporal/relational dependency, prior efforts either strive to explore the temporal dynamics behind distinct stocks or expect to expose the collaborative signals from predefined relations, resulting in promising achievements in stock ranking. However, owing to the profound or intricate fluctuations of stock markets, existing insights rarely consider the uncertain risks underlying the learning of dependency representation, which could bring a narrow perspective on how to perceive market laws and ultimately yield an unprofitable decision-making procedure. In this study, we introduce a novel Progressive Dependency representation learning solution with Uncertain risk contrasting (PDU), primarily seeking to progressively uncover multiple dependency dynamics from historical trading signals for stock ranking in addition to addressing the uncertain risks. Specifically, we devise a Progressive Dependency learning block (or PD) in PDU that can progressively capture the temporal and relational dependencies besides multi-term dependencies in the latent space, allowing a coupled exposure of diffusion impacts over historical trading. Furthermore, we introduce an uncertain risk contrasting mechanism in PDU by placing the PD block in a contrastive environment (i.e., certainty vs. uncertainty), aiming to stably enhance dependency learning in the latent space. The experimental results conducted on four real-world stock market datasets demonstrate the superiority of PDU over several baselines. | Li Huang, Yanzhe Xie, Qiang Gao, Kunpeng Zhang, Guisong Liu, Xueqin Chen | University of Maryland, College Park, Maryland, USA; Kash Institute of Electronics and Information Industry, Kashgar, Xinjiang, China |
|  |  [Path Complex Neural Networks for Sequential Process Activities Classification](https://doi.org/10.1145/3690624.3709193) |  | 0 | Process mining aims to uncover, track, and enhance real-world workflows by deriving insights from event logs commonly found in modern information systems. With the growing focus on improving productivity within complex business operations, recent research has looked into developing process models to improve business performance metrics. As such, this study aims to enhance process mining from event logs by proposing a novel path-complex construction based on process mining sequential data and a path-complex-based message-passing mechanism for higher-order structural information. We adopt path-complex representations for event logs and their temporal connections developed from instance graphs. Representations are identified and optimised for 0-paths (events), 1-paths (two events in chronological order) and 2-paths (three consecutive events) to characterise intrinsic higher-order information among events. The proposed framework, Path Complex Neural Networks (PCNN), leverages the advantages of topological deep learning and obtains representations for higher-order complexes inductively. Additionally, we evaluated the results with four real-world benchmark datasets and found that PCNN outperforms existing models in analysing sequential and complex process data. | Liang Huang, Kelin Xia, ChuanShen Hu | Nanyang Technological University, Singapore, Singapore & HP Inc., Singapore, Singapore; Nanyang Technological University, Singapore, Singapore |
|  |  [PipeRAG: Fast Retrieval-Augmented Generation via Adaptive Pipeline Parallelism](https://doi.org/10.1145/3690624.3709194) |  | 0 | Retrieval-augmented generation (RAG) can enhance the generation quality of large language models (LLMs) by incorporating external token databases. However, retrievals from large databases can constitute a substantial portion of the overall generation time, particularly when retrievals are periodically performed to align the retrieved content with the latest states of generation. In this paper, we introduce PipeRAG, a novel algorithm-system co-design approach to reduce generation latency and enhance generation quality. PipeRAG integrates (1) pipeline parallelism to enable concurrent retrieval and generation processes, (2) flexible retrieval intervals to maximize the efficiency of pipeline parallelism, and (3) a performance model to automatically balance retrieval quality and latency based on the generation states and underlying hardware. Our evaluation shows that, by combining the three aforementioned methods, PipeRAG achieves up to 2.6× speedup in end-to-end generation latency while improving generation quality. These promising results showcase the effectiveness of co-designing algorithms with underlying systems, paving the way for the adoption of PipeRAG in future RAG systems. | Wenqi Jiang, Shuai Zhang, Boran Han, Jie Wang, Bernie Wang, Tim Kraska | Amazon Web Services, Santa Clara, CA, USA; Meta, Santa Clara, CA, USA; Massachusetts Institute of Technology, Boston, MA, USA; ETH Zurich, Zurich, Zurich, Switzerland |
|  |  [MGS3: A Multi-Granularity Self-Supervised Code Search Framework](https://doi.org/10.1145/3690624.3709263) |  | 0 | In the pursuit of enhancing software reusability and developer productivity, code search has emerged as a key area, aimed at retrieving code snippets relevant to functionalities based on natural language queries. Despite significant progress in self-supervised code pre-training utilizing the vast amount of code data in repositories, existing methods have primarily focused on leveraging contrastive learning to align natural language with function-level code snippets. These studies have overlooked the abundance of fine-grained (such as block-level and statement-level) code snippets prevalent within the function-level code snippets, which results in suboptimal performance across all levels of granularity. To address this problem, we first construct a multi-granularity code search dataset called MGCodeSearchNet, which contains 536K+ pairs of natural language and code snippets. Subsequently, we introduce a novel Multi-Granularity Self-Supervised contrastive learning code Search framework (MGS$^{3}$}). First, MGS$^{3}$ features a Hierarchical Multi-Granularity Representation module (HMGR), which leverages syntactic structural relationships for hierarchical representation and aggregates fine-grained information into coarser-grained representations. Then, during the contrastive learning phase, we endeavor to construct positive samples of the same granularity for fine-grained code, and introduce in-function negative samples for fine-grained code. Finally, we conduct extensive experiments on code search benchmarks across various granularities, demonstrating that the framework exhibits outstanding performance in code search tasks of multiple granularities. These experiments also showcase its model-agnostic nature and compatibility with existing pre-trained code representation models. | Rui Li, Junfeng Kang, Qi Liu, Liyang He, Zheng Zhang, Yunhao Sha, Linbo Zhu, Zhenya Huang |  |
|  |  [APEX2: Adaptive and Extreme Summarization for Personalized Knowledge Graphs](https://doi.org/10.1145/3690624.3709213) |  | 0 | Knowledge graphs (KGs), which store an extensive number of relational facts, serve various applications. Recently, personalized knowledge graphs (PKGs) have emerged as a solution to optimize storage costs by customizing their content to align with users' specific interests within particular domains. In the real world, on the one hand, user queries and their underlying interests are inherently evolving, requiring PKGs to adapt continuously; on the other hand, the summarization is constantly expected to be as small as possible in terms of storage cost. However, the existing PKG summarization methods implicitly assume that the user's interests are constant and do not shift. Furthermore, when the size constraint of PKG is extremely small, the existing methods cannot distinguish which facts are more of immediate interest and guarantee the utility of the summarized PKG. To address these limitations, we propose APEX2, a highly scalable PKG summarization framework designed with robust theoretical guarantees to excel in adaptive summarization tasks with extremely small size constraints. To be specific, after constructing an initial PKG, APEX2 continuously tracks the interest shift and adjusts the previous summary. The experiments show that APEX outperforms state-of-the-art baselines in terms of both query-answering accuracy and efficiency. | Zihao Li, Dongqi Fu, Mengting Ai, Jingrui He | Meta AI, Meta, Sunnyvale, CA, USA; University of Illinois Urbana-Champaign, Champaign, IL, USA |
|  |  [Spectral Subspace Clustering for Attributed Graphs](https://doi.org/10.1145/3690624.3709207) |  | 0 | Subspace clustering seeks to identify subspaces that segment a set of n data points into k (k<<n) groups, which has emerged as a powerful tool for analyzing data from various domains, especially images and videos. Recently, several studies have demonstrated the great potential of subspace clustering models for partitioning vertices in attributed graphs, referred to as SCAG. However, these works either demand significant computational overhead for constructing the nxn self-expressive matrix, or fail to incorporate graph topology and attribute data into the subspace clustering framework effectively, and thus, compromise result quality. Motivated by this, this paper presents two effective and efficient algorithms, S2CAG and M-S2CAG, for SCAG computation. Particularly, S2CAG obtains superb performance through three major contributions. First, we formulate a new objective function for SCAG with a refined representation model for vertices and two non-trivial constraints. On top of that, an efficient linear-time optimization solver is developed based on our theoretically grounded problem transformation and well-thought-out adaptive strategy. We then conduct an in-depth analysis to disclose the theoretical connection of S2CAG to conductance minimization, which further inspires the design of M-S2CAG that maximizes the modularity. Our extensive experiments, comparing S2CAG and M-S2CAG against 17 competitors over 8 benchmark datasets, exhibit that our solutions outperform all baselines in terms of clustering quality measured against the ground truth while delivering high efficiency | Xiaoyang Lin, Renchi Yang, Haoran Zheng, Xiangyu Ke |  |
|  |  [Dynamic Deep Clustering of High-Dimensional Directional Data via Hyperspherical Embeddings with Bayesian Nonparametric Mixtures](https://doi.org/10.1145/3690624.3709230) |  | 0 | Clustering high-dimensional directional data (i.e., L2 normalized vectors) presents significant challenges due to the intricate spherical representations of latent embeddings and the limitations of classical (non-deep) clustering techniques. Moreover, dynamically inferring the number of clusters remains a fundamental issue in existing deep clustering methods, especially those involving complex model-selection criteria. This paper addresses these challenges by introducing a novel deep nonparametric clustering framework that employs hyperspherical latent embeddings within a Variational Autoencoder architecture, enhanced by an infinite Von Mises-Fisher Mixture Model as a dynamic prior. This approach enables automatic adaptation of cluster numbers during training, eliminating the need for predefined clusters and traditional model selection processes. Our scalable architecture effectively integrates In-vMFMM with hyperspherical embeddings to tackle the complexities of directional data. Utilizing a joint training strategy, our method alternates between updating neural network parameters and adjusting mixture model priors via nonparametric variational Bayes. Empirical evaluations on benchmark datasets, including complex ImageNet-50, demonstrate that our approach significantly outperforms state-of-the-art deep nonparametric clustering methods. It also robustly estimates the number of clusters, showcasing its effectiveness and versatility in handling high-dimensional directional data. | Zhiwen Luo, Wentao Fan, Manar Amayri, Nizar Bouguila |  |
|  |  [Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation](https://doi.org/10.1145/3690624.3709335) |  | 0 | Large Language Models (LLMs) for Recommendation (LLM4Rec) is a promising research direction that has demonstrated exceptional performance in this field. However, its inability to capture real-time user preferences greatly limits the practical application of LLM4Rec because (i) LLMs are costly to train and infer frequently, and (ii) LLMs struggle to access real-time data (its large number of parameters poses an obstacle to deployment on devices). Fortunately, small recommendation models (SRMs) can effectively supplement these shortcomings of LLM4Rec diagrams by consuming minimal resources for frequent training and inference, and by conveniently accessing real-time data on devices. In light of this, we designed the Device-Cloud LLM-SRM Collaborative Recommendation Framework (LSC4Rec) under a device-cloud collaboration setting. LSC4Rec aims to integrate the advantages of both LLMs and SRMs, as well as the benefits of cloud and edge computing, achieving a complementary synergy. We enhance the practicability of LSC4Rec by designing three strategies: collaborative training, collaborative inference, and intelligent request. During training, LLM generates candidate lists to enhance the ranking ability of SRM in collaborative scenarios and enables SRM to update adaptively to capture real-time user interests. During inference, LLM and SRM are deployed on the cloud and on the device, respectively. LLM generates candidate lists and initial ranking results based on user behavior, and SRM get reranking results based on the candidate list, with final results integrating both LLM's and SRM's scores. The device determines whether a new candidate list is needed by comparing the consistency of the LLM's and SRM's sorted lists. Our comprehensive and extensive experimental analysis validates the effectiveness of each strategy in LSC4Rec. | Zheqi Lv, Tianyu Zhan, Wenjie Wang, Xinyu Lin, Shengyu Zhang, Wenqiao Zhang, Jiwei Li, Kun Kuang, Fei Wu |  |
|  |  [AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting](https://doi.org/10.1145/3690624.3709323) |  | 0 | Spatio-temporal forecasting is a critical component of various smart city applications, such as transportation optimization, energy management, and socio-economic analysis. Recently, several automated spatio-temporal forecasting methods have been proposed to automatically search the optimal neural network architecture for capturing complex spatio-temporal dependencies. However, the existing automated approaches suffer from expensive neural architecture search overhead, which hinders their practical use and the further exploration of diverse spatio-temporal operators in a finer granularity. In this paper, we propose AutoSTF, a decoupled automatic neural architecture search framework for cost-effective automated spatio-temporal forecasting. From the efficiency perspective, we first decouple the mixed search space into temporal space and spatial space and respectively devise representation compression and parameter-sharing schemes to mitigate the parameter explosion. The decoupled spatio-temporal search not only expedites the model optimization process but also leaves new room for more effective spatio-temporal dependency modeling. From the effectiveness perspective, we propose a multi-patch transfer module to jointly capture multi-granularity temporal dependencies and extend the spatial search space to enable finer-grained layer-wise spatial dependency search. Extensive experiments on eight datasets demonstrate the superiority of AutoSTF in terms of both accuracy and efficiency. Specifically, our proposed method achieves up to 13.48x speed-up compared to state-of-the-art automatic spatio-temporal forecasting methods while maintaining the best forecasting accuracy. | Tengfei Lyu, Weijia Zhang, Jinliang Deng, Hao Liu |  |
|  |  [Enhancing Black-Box Adversarial Attacks on Discrete Sequential Data via Bilevel Bayesian Optimization in Hybrid Spaces](https://doi.org/10.1145/3690624.3709265) |  | 0 | Black-box attacks have emerged as a significant threat to deep neural networks. This challenge is particularly difficult in discrete sequential data compared to continuous data. Recently, the Blockwise Bayesian Attack (BBA) leveraging discrete Bayesian optimization with an adapted RBF kernel has gained prominence as a cutting-edge solution. However, it relies solely on alignment information (i.e., positional differences) within the RBF kernel, which may not fully capture the information (such as statistical, structural, and semantic information) inherent in discrete sequential data and potentially lacks the desired inductive bias necessary to approximate the target function accurately. To overcome this limitation, this paper proposes a novel bilevel Bayesian optimization approach to adaptively learn a hybrid space that better captures the similarity between discrete sequences. Specifically, we introduce a multi-kernel mechanism that incorporates multiple types of information, creating a more comprehensive similarity measure. Moreover, we develop a bilevel Bayesian optimization algorithm, where the outer-level objective determines the optimal weights of the multiple kernels, while the inner-level objective identifies the optimal adversarial sequence. Extensive experiments conducted on discrete sequential data demonstrate that our approach ensures secure multi-kernel selection and achieves a higher attack success rate with only a few additional queries, compared to BBA and other traditional optimization strategies. | Tianxing Man, Xingchen Li, Zhaogeng Liu, Haozhen Zhang, Bin Gu, Yi Chang | School of Artificial Intelligence, Jilin University, Changchun, Jilin, China |
|  |  [Electron-Informed Coarse-Graining Molecular Representation Learning for Real-World Molecular Physics](https://doi.org/10.1145/3690624.3709270) |  | 0 | Various representation learning methods for molecular structures have been devised to accelerate data-driven chemistry. However, the representation capabilities of existing methods are essentially limited to atom-level information, which is not sufficient to describe real-world molecular physics. Although electron-level information can provide fundamental knowledge about chemical compounds beyond the atom-level information, obtaining the electron-level information in real-world molecules is computationally impractical and sometimes infeasible. We propose a method for learning electron-informed molecular representations without additional computation costs by transferring readily accessible electron-level information about small molecules to large molecules of our interest. The proposed method achieved state-of-the-art prediction accuracy on extensive benchmark datasets containing experimentally observed molecular physics. The source code for HEDMoL is available at https://github.com/ngs00/HEDMoL. | Gyoung S. Na, Chanyoung Park | Korea Research Institute of Chemical Technology, Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea |
|  |  [Understanding the Effect of Loss Functions on the Generalization of Recommendations](https://doi.org/10.1145/3690624.3709169) |  | 0 | The two-tower model has become prevalent in recommender systems for its computational efficiency and robust predictive capabilities. The model usually employs two independent neural networks to encode user and item data separately, and predicts the similarity score with inner product or cosine functions, depending on which the Top-k ranked item list is generated. The optimization process typically involves a multi-label classification objective, often guided by surrogate loss functions like Softmax and One-vs-All (OvA), to enhance the recommendation performance. Despite both Softmax and OvA losses being Bayes-consistent, empirical observations reveal a significant performance gap in evaluation metrics, suggesting limitations in Bayes-consistency for analyzing loss effectiveness. To address this, we introduce ℋ-consistency into the discussion, which provides non-asymptotic and hypothesis-specific guarantees for Top-k classification within the two-tower model's hypothesis space. Through theoretical analysis, we demonstrate that Softmax and Cosine Contrastive Loss exhibit ℋ-consistency, while the OvA loss does not, explaining the observed performance discrepancies. Our findings bridge the gap between theoretical properties and practical outcomes, offering deeper insights into the optimization of two-tower models and contributing to the development of more effective recommendation systems. | Yuanhao Pu, Defu Lian, Xiaolong Chen, Jin Chen, Ze Liu, Enhong Chen | Hong Kong University of Science and Technology, Hong Kong, Hong Kong |
|  |  [Fast Causal Discovery by Approximate Kernel-based Generalized Score Functions with Linear Computational Complexity](https://doi.org/10.1145/3690624.3709338) |  | 0 | Score-based causal discovery methods can effectively identify causal relationships by evaluating candidate graphs and selecting the one with the highest score. One popular class of scores is kernel-based generalized score functions, which can adapt to a wide range of scenarios and work well in practice because they circumvent assumptions about causal mechanisms and data distributions. Despite these advantages, kernel-based generalized score functions pose serious computational challenges in time and space, with a time complexity of 𝒪(n^3) and a memory complexity of 𝒪(n^2), where n is the sample size. In this paper, we propose an approximate kernel-based generalized score function with 𝒪(n) time and space complexities by using low-rank technique and designing a set of rules to handle the complex composite matrix operations required to calculate the score, as well as developing sampling algorithms for different data types to benefit the handling of diverse data types efficiently. Our extensive causal discovery experiments on both synthetic and real-world data demonstrate that compared to the state-of-the-art method, our method can not only significantly reduce computational costs, but also achieve comparable accuracy, especially for large datasets. | Yixin Ren, Haocheng Zhang, Yewei Xia, Hao Zhang, Jihong Guan, Shuigeng Zhou |  |
|  |  [R2MR: Review and Rewrite Modality for Recommendation](https://doi.org/10.1145/3690624.3709250) |  | 0 | With the explosive growth of online multimodal content, multimodal recommender systems(MRSs) have brought significant benefits to multimedia platforms. As MRSs evolve, many studies incorporate advanced technologies like graph neural networks(GNNs) and self-supervised learning(SSL), achieving remarkable results. However, these efforts still suffer from the quality disparity problem. It refers to the mixture of high and low quality across items' multiple modalities, owing to disparities in construction costs or design levels. These low-quality modalities often lack crucial details or introduce noise to the depiction of item, leading to insufficient or polluted item representation. Therefore, we propose a novel framework R2MR: Review and Rewrite Modality for Recommendation to tackle this issue. Specifically, R2MR is composed of two key components: Modality Reviewer and Modality Rewriter. The Modality Reviewer introduces a Consensus Review Mechanism. It performs perspective decomposition based on user representations and learns the consensus quality scores for modalities from diverse perspectives of multiple users. The Modality Rewriter proposes a Latent Mapping Model, which improves the quality of inferior modalities by learning various mapping patterns from high-quality modalities. Comprehensive experiments across three benchmark datasets reveal that R2MR substantially outperforms state-of-the-art methods, achieving an average improvement of 9.20%. The implementations are available at https://github.com/gutang-97/R2MR. | Gu Tang, Jinghe Wang, Xiaoying Gan, Bin Lu, Ze Zhao, Luoyi Fu, Xinbing Wang, Chenghu Zhou | Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong Universityy, Shanghai, China; Chinese Academy of Sciences, Beijing, China |
|  |  [Scaling the Vocabulary of Non-autoregressive Models for Fast Generative Retrieval](https://doi.org/10.1145/3690624.3709330) |  | 0 |  | Ravisri Valluri, Akash Kumar Mohankumar, Kushal Dave, Amit Singh, Jian Jiao, Manik Varma, Gaurav Sinha |  |
|  |  [Mitigating Redundancy in Deep Recommender Systems: A Field Importance Distribution Perspective](https://doi.org/10.1145/3690624.3709275) |  | 0 | In the realm of recommender systems, accurately predicting Click-Through Rate (CTR) is a critical task that involves learning user-item interaction features. Many researchers propose novel models to mine interaction signals, but they neglect that redundancy itself causes high computational cost and leads to suboptimal performance. Some tried to remove redundancy by dropping useless features, or shrinking the size of embedding table. However, current feature selection methods are vulnerable to training stochasticity and data dynamics, while embedding size assignment techniques neglect the importance relationships between feature fields. The simple combination of the two optimization ways will also yield poor performance due to the inherent gap in their optimization targets. Hence, there is no effective paradigm that can optimize feature fields from the two aspects in a simultaneous and coordinated way. In this paper, we identify the core issue as the lack of a practical score to measure the contribution of feature fields, and propose a distribution-based field optimization framework that adopts importance distribution to provide a comprehensive view for both methods. We innovatively design a learner for each field to acquire the stable and comprehensive importance situation. Then, based on this, we eliminate noise features, and assign adaptive embedding sizes for different feature fields according to the similarity of importance. With this field optimization, our proposed framework has extremely low pre-training overhead, greatly reduces training and inference time, and even achieves more accurate prediction results with fewer feature fields. | Xianquan Wang, Likang Wu, Zhi Li, Haitao Yuan, Shuanghong Shen, Huibo Xu, Yu Su, Chenyi Lei | Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Hefei, China; Hefei Normal University, Hefei, China; Kuaishou Technology, Hangzhou, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; University of Science and Technology of China, Hefei, China; Tianjin University, Tianjin, China; Nanyang Technological University, Singapore, Singapore |
|  |  [Mixed Blessing: Class-Wise Embedding guided Instance-Dependent Partial Label Learning](https://doi.org/10.1145/3690624.3709276) |  | 0 | In partial label learning (PLL), every sample is associated with a candidate label set comprising the ground-truth label and several noisy labels. The conventional PLL assumes the noisy labels are randomly generated (instance-independent), while in practical scenarios, the noisy labels are always instance-dependent and are highly related to the sample features, leading to the instance-dependent partial label learning (IDPLL) problem. Instance-dependent noisy label is a double-edged sword. On one side, it may promote model training as the noisy labels can depict the sample to some extent. On the other side, it brings high label ambiguity as the noisy labels are quite undistinguishable from the ground-truth label. To leverage the nuances of IDPLL effectively, for the first time we create class-wise embeddings for each sample, which allow us to explore the relationship of instance-dependent noisy labels, i.e., the class-wise embeddings in the candidate label set should have high similarity, while the class-wise embeddings between the candidate label set and the non-candidate label set should have high dissimilarity. Moreover, to reduce the high label ambiguity, we introduce the concept of class prototypes containing global feature information to disambiguate the candidate label set. Extensive experimental comparisons with twelve methods on six benchmark data sets, including four fine-grained data sets, demonstrate the effectiveness of the proposed method. The code implementation is publicly available at https://github.com/Yangfc-ML/CEL. | Fuchao Yang, Jianhong Cheng, Hui Liu, Yongqiang Dong, Yuheng Jia, Junhui Hou |  |
|  |  [GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning](https://doi.org/10.1145/3690624.3709186) |  | 0 | Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in handling a range of graph analytical tasks across various domains, such as e-commerce and social networks. Despite their versatility, GNNs face significant challenges in transferability, limiting their utility in real-world applications. Existing research in GNN transfer learning overlooks discrepancies in distribution among various graph datasets, facing challenges when transferring across different distributions. How to effectively adopt a well-trained GNN to new graphs with varying feature and structural distributions remains an under-explored problem. Taking inspiration from the success of Low-Rank Adaptation (LoRA) in adapting large language models to various domains, we propose GraphLoRA, an effective and parameter-efficient method for transferring well-trained GNNs to diverse graph domains. Specifically, we first propose a Structure-aware Maximum Mean Discrepancy (SMMD) to align divergent node feature distributions across source and target graphs. Moreover, we introduce low-rank adaptation by injecting a small trainable GNN alongside the pre-trained one, effectively bridging structural distribution gaps while mitigating the catastrophic forgetting. Additionally, a structure-aware regularization objective is proposed to enhance the adaptability of the pre-trained GNN to target graph with scarce supervision labels. Extensive experiments on six real-world datasets demonstrate the effectiveness of GraphLoRA against eleven baselines by tuning only 20 parameters, even across disparate graph domains. The code is available at https://anonymous.4open.science/r/GraphLoRA. | ZheRui Yang, Jindong Han, ChangDong Wang, Hao Liu |  |
|  |  [Generalizable Recommender System During Temporal Popularity Distribution Shifts](https://doi.org/10.1145/3690624.3709299) |  | 0 | Many modern recommender systems represent user and item attributes as embedding vectors, relying on them for accurate recommendations. However, entangled embeddings often capture not only intrinsic property factors (e.g., user interest in item property) but also popularity factors (e.g., user conformity to item popularity) indistinguishably. These embeddings, influenced by popularity distribution, may face challenges when the popularity distribution at test time differs from historical distribution. Existing remedies in the literature involve disentangled embedding learning, which aims to separately capture intrinsic and popularity factors, demonstrating plausible generalization during popularity distribution shifts. However, we highlight that these methods often overlook a crucial aspect of popularity shifts-their temporal nature-in both training and inference phases. To address this, we propose Temporal Popularity distribution shift generalizABle recommender system (TPAB), a novel disentanglement framework incorporating temporal popularity. TPAB introduce a new (1) temporal-aware embedding design for users and items. Within this design, (2) popularity coarsening and (3) popularity bootstrapping are proposed to enhance generalization further. We also provide theoretical analysis showing that the bootstrapping loss eliminates the effect of popularity on the learned model. During inference, we infer test-time popularity and corresponding embeddings, using them alongside property embeddings for prediction. Extensive experiments on real-world datasets validate TPAB, showcasing its outstanding generalization ability during temporal popularity distribution shifts. | Hyunsik Yoo, Ruizhong Qiu, Charlie Xu, Fei Wang, Hanghang Tong | Amazon.com, Inc., Seattle, WA, USA; Amazon.com, Inc., Sunnyvale, CA, USA; University of Illinois Urbana-Champaign, Urbana, IL, USA |
|  |  [DimCL: Dimension-Aware Augmentation in Contrastive Learning for Recommendation](https://doi.org/10.1145/3690624.3709200) |  | 0 | Contrastive learning (CL) has achieved remarkable success in addressing data sparsity issues in collaborative filtering (CF) for recommender systems (RSs). The key principle is to generate different augmented views given a user-item interaction graph. However, prior endeavors mainly focus on performing augmentation via stochastic functions, e.g., by injecting perturbations into different hidden dimensions uniformly. Without fine control, the hidden representations of augmentations may contain noisy dimensions that are harmful to CL and irrelevant to RSs. Removing dimension-specific noise is a challenging task due to the following two major bottlenecks. It is difficult to (i) distinguish different dimensions' efficacy for CL and (ii) bridge the semantic gap between CL and RSs. Overlooking these limitations may cause redundant, false-positive, and irrelevant noise in hidden dimensions of the augmented views. In this paper, we solve the above challenges from the perspective of robust learning and curriculum learning, and propose a novel Dimension-aware augmentation in Ceontrastive Leearning for recommendation (DimCL). In DimCL, we first theoretically analyze the easiness and hardness of different dimensions for CL and RSs. With thorough analysis, we propose two propositions, which reveal that the gradients of different dimensions of augmented views are potentially related to the learning difficulty of optimizing CL and RSs. The comparison of gradients can provide detectable signals to reflect the efficacy of different dimensions for CL and the semantic gap between CL and RSs. Based on the analysis results, we devise three denoising factors, which can help DimCL to identify hard-to-learn dimensions as redundant or false-positive noise and pinpoint dimensions in different augmented views with inconsistent difficulties of RSs as irrelevant noise without requiring additional supervised labels. After denoising, DimCL can remove dimension-level noise to reduce unnecessary difficulty, making CL easier and maintaining more consistent difficulty in RSs. Extensive experiments on four public datasets demonstrate DimCL's superiority and flexible applications over various traditional and CL-based CF methods. The source code is publicly available online at https://github.com/zc-97/DimCL. | Chi Zhang, Qilong Han, Qiaoyu Tan, Shengjie Wang, Xiangyu Zhao, Rui Chen | Harbin Engineering University, Harbin, China; City University of Hong Kong, Hong Kong, Hong Kong; Shanghai Frontiers Science Center of Artificial Intelligence and Deep Learning, Shanghai, China |
|  |  [Generalizing Personalized Federated Graph Augmentation via Min-max Adversarial Learning](https://doi.org/10.1145/3690624.3709311) |  | 0 | Federated learning (FL) enables the training of a global machine learning model among multiple local clients in a collaborative fashion without directly sharing the details of their data. Due to this advantage, it has been utilized in a wide range of applications where privacy is a critical concern and has attracted great attention for graph representation learning (GRL). Despite the offered advances, there still exist two major challenges in the FL for GRL across distributed graph data, including heterogeneity and complementarity. In order to tackle these challenges, a novel personalized federated graph augmentation (PFGA) framework is proposed in this work. Unlike existing techniques, it utilizes generative models as bridges to enable information sharing among clients, thereby facilitating the collaborative training of GRL models. Instead of directly using the generative model trained on each client individually, we aggregate them into the globally generative model to gain a global view of the entire graph, which effectively alleviates the heterogeneity and complementarity issues simultaneously. We formulate the training of the generative and GRL models as a min-max adversarial learning problem and theoretically prove the convergence. Furthermore, the effectiveness of the method is demonstrated using experimental results on six real-world datasets. | Liang Zhang, Tao Long, Yang Liu, Lei Zhang, Laizhong Cui, Qingjiang Shi | Data Science Research Center, Dukekunshan University, Kunshan, Jiangsu, China; Shenzhen Research Institute of Big Data, Shenzhen, Guangdong, China; School of Software Engineering, Tongji University, Yangpu, Shanghai, China |
|  |  [PrivDPR: Synthetic Graph Publishing with Deep PageRank under Differential Privacy](https://doi.org/10.1145/3690624.3709334) |  | 0 | The objective of privacy-preserving synthetic graph publishing is to safeguard individuals' privacy while retaining the utility of original data. Most existing methods focus on graph neural networks under differential privacy (DP), and yet two fundamental problems in generating synthetic graphs remain open. First, the current research often encounters high sensitivity due to the intricate relationships between nodes in a graph. Second, DP is usually achieved through advanced composition mechanisms that tend to converge prematurely when working with a small privacy budget. In this paper, inspired by the simplicity, effectiveness, and ease of analysis of PageRank, we design PrivDPR, a novel privacy-preserving deep PageRank for graph synthesis. In particular, we achieve DP by adding noise to the gradient for a specific weight during learning. Utilizing weight normalization as a bridge, we theoretically reveal that increasing the number of layers in PrivDPR can effectively mitigate the high sensitivity and privacy budget splitting. Through formal privacy analysis, we prove that the synthetic graph generated by PrivDPR satisfies node-level DP. Experiments on real-world graph datasets show that PrivDPR preserves high data utility across multiple graph structural properties. | Sen Zhang, Haibo Hu, Qingqing Ye, Jianliang Xu |  |
|  |  [IDentity with Locality: An Ideal Hash for Gene Sequence Search](https://doi.org/10.1145/3690624.3709233) |  | 0 | Gene sequence search is a fundamental operation in computational genomics.Due to the petabyte scale of genome archives, most gene search systems now usehashing-based data structures such as Bloom Filters (BF). The state-of-the-artsystems such as Compact bit-slicing signature index (COBS) and Repeated AndMerged Bloom filters (RAMBO) use BF with Random Hash (RH) functions for generepresentation and identification. The standard recipe is to cast the genesearch problem as a sequence of membership problems testing if each subsequentgene substring (called kmer) of Q is present in the set of kmers of the entiregene database D. We observe that RH functions, which are crucial to the memoryand the computational advantage of BF, are also detrimental to the systemperformance of gene-search systems. While subsequent kmers being queried arelikely very similar, RH, oblivious to any similarity, uniformly distributes thekmers to different parts of potentially large BF, thus triggering excessivecache misses and causing system slowdown. We propose a novel hash functioncalled the Identity with Locality (IDL) hash family, which co-locates the keysclose in input space without causing collisions. This approach ensures bothcache locality and key preservation. IDL functions can be a drop-in replacementfor RH functions and help improve the performance of information retrievalsystems. We give a simple but practical construction of IDL function familiesand show that replacing the RH with IDL functions reduces cache misses by afactor of 5x, thus improving query and indexing times of SOTA methods such asCOBS and RAMBO by factors up to 2x without compromising their quality. We alsoprovide a theoretical analysis of the false positive rate of BF with IDLfunctions. Our hash function is the first study that bridges Locality SensitiveHash (LSH) and RH to obtain cache efficiency. | Tianyi Zhang, Gaurav Gupta, Aditya Desai, Anshumali Shrivastava |  |
|  |  [Enhancing Graph Contrastive Learning with Reliable and Informative Augmentation for Recommendation](https://doi.org/10.1145/3690624.3709214) |  | 0 | Graph neural network (GNN) has been a powerful approach in collaborative filtering (CF) due to its ability to model high-order user-item relationships. Recently, to alleviate the data sparsity and enhance representation learning, many efforts have been conducted to integrate contrastive learning (CL) with GNNs. Despite the promising improvements, the contrastive view generation based on structure and representation perturbations in existing methods potentially disrupts the collaborative information in contrastive views, resulting in limited effectiveness of positive alignment. To overcome this issue, we propose CoGCL, a novel framework that aims to enhance graph contrastive learning by constructing contrastive views with stronger collaborative information via discrete codes. The core idea is to map users and items into discrete codes rich in collaborative information for reliable and informative contrastive view generation. To this end, we initially introduce a multi-level vector quantizer in an end-to-end manner to quantize user and item representations into discrete codes. Based on these discrete codes, we enhance the collaborative information of contrastive views by considering neighborhood structure and semantic relevance respectively. For neighborhood structure, we propose virtual neighbor augmentation by treating discrete codes as virtual neighbors, which expands an observed user-item interaction into multiple edges involving discrete codes. Regarding semantic relevance, we identify similar users/items based on shared discrete codes and interaction targets to generate the semantically relevant view. Through these strategies, we construct contrastive views with stronger collaborative information and develop a triple-view graph contrastive learning approach. Extensive experiments on four public datasets demonstrate the effectiveness of our proposed approach. | Bowen Zheng, Junjie Zhang, Hongyu Lu, Yu Chen, Ming Chen, Wayne Xin Zhao, JiRong Wen |  |
|  |  [ECGrecover: A Deep Learning Approach for Electrocardiogram Signal Completion](https://doi.org/10.1145/3690624.3709405) |  | 0 | In this work, we address the challenge of reconstructing the complete 12-lead ECG signal from its incomplete parts. We focus on two main scenarios: (i) reconstructing missing signal segments within an ECG lead and (ii) recovering entire leads from signal in another unique lead. Two emerging clinical applications emphasize the relevance of our work. The first is the increasing need to digitize paper-stored ECGs for utilization in AI-based applications, often limited to digital 12 lead 10s ECGs. The second is the widespread use of wearable devices that record ECGs but typically capture only one or a few leads. In both cases, a non-negligible amount of information is lost or not recorded. Our approach aims to recover this missing signal. We propose ECGrecover, a U-Net neural network model trained on a novel composite objective function to address the reconstruction problem. This function incorporates both spatial and temporal features of the ECG by combining the distance in amplitude and sycnhronization through time between the reconstructed and the real digital signals. We used real-life ECG datasets and through comprehensive assessments compared ECGrecover with three state-of-the-art methods based on generative adversarial networks (EKGAN, Pix2Pix) as well as the CopyPaste strategy. The results demonstrated that ECGrecover consistently outperformed state-of-the-art methods in standard distortion metrics as well as in preserving critical ECG characteristics, particularly the P, QRS, and T wave coordinates. | Alex Lence, Federica Granese, Ahmad Fall, Blaise Hanczar, JoeElie Salem, JeanDaniel Zucker, Edi Prifti |  |
|  |  [LinkSAGE: Optimizing Job Matching Using Graph Neural Networks](https://doi.org/10.1145/3690624.3709396) |  | 0 | We present LinkSAGE, an innovative framework that integrates Graph NeuralNetworks (GNNs) into large-scale personalized job matching systems, designed toaddress the complex dynamics of LinkedIns extensive professional network. Ourapproach capitalizes on a novel job marketplace graph, the largest and mostintricate of its kind in industry, with billions of nodes and edges. This graphis not merely extensive but also richly detailed, encompassing member and jobnodes along with key attributes, thus creating an expansive and interwovennetwork. A key innovation in LinkSAGE is its training and serving methodology,which effectively combines inductive graph learning on a heterogeneous,evolving graph with an encoder-decoder GNN model. This methodology decouplesthe training of the GNN model from that of existing Deep Neural Nets (DNN)models, eliminating the need for frequent GNN retraining while maintainingup-to-date graph signals in near realtime, allowing for the effectiveintegration of GNN insights through transfer learning. The subsequent nearlineinference system serves the GNN encoder within a real-world setting,significantly reducing online latency and obviating the need for costlyreal-time GNN infrastructure. Validated across multiple online A/B tests indiverse product scenarios, LinkSAGE demonstrates marked improvements in memberengagement, relevance matching, and member retention, confirming itsgeneralizability and practical impact. | Ping Liu, Haichao Wei, Xiaochen Hou, Jianqiang Shen, Shihai He, Qianqi Shen, Zhujun Chen, Fedor Borisyuk, Daniel Hewlett, Liang Wu, Srikant Veeraraghavan, Alex Tsun, Chengming Jiang, Wenjing Zhang | LinkedIn Corporation Mountain View |
|  |  [Roadside Multi-LiDAR Data Fusion for Enhanced Traffic Safety](https://doi.org/10.1145/3690624.3709410) |  | 0 | Roadside LiDAR (Light Detection and Ranging) sensors promise safer and faster traffic management and vehicular operations. However, occlusion and small view angles are significant challenges to widespread use of roadside LiDARs. We consider fusing data from multiple LiDARs at a traffic intersection to better estimate traffic parameters than one can estimate from a single LiDAR. The key challenge is to calibrate multiple LiDARs both in time and space. The problem is more complex when heterogeneous sensors differ in resolution and are positioned arbitrarily on a traffic intersection. We propose a calibration technique to fuse multiple LiDARs. We show that our technique works on various data granularity and enables real-time analytics for roadside traffic monitoring. We evaluate on a large number of simulated traffic scenarios and show that fusion improves accuracy of vehicle counting and near-collision detection. We apply our algorithm on real traffic data and demonstrate utility in classifying vehicles and detecting occluded traffic participants. | Md. Parvez Mollah, Biplob Debnath, Murugan Sankaradas, Srimat Chakradhar, Abdullah Mueen | The University of New Mexico, Albuquerque, New Mexico, USA; NEC Laboratories America, Inc., Princeton, New Jersey, USA |
|  |  [AntAkso: Claims Management System for Health Insurance in Alipay](https://doi.org/10.1145/3690624.3709398) |  | 0 | The rapid growth of health insurance and the rising incidence of fraudulent claims underscore the necessity for an efficient and professional claims management system. However, there is a noticeable lack of shared relevant experience from previous research in this field. In response to this challenge, we introduce AntAkso, a robust claims management system specifically designed for health insurance operations within Alipay. AntAkso incorporates a digital and professional management system, achieving a notable decrease in the volume of false claims, reduction in administrative costs, and heightened satisfaction among its policyholders. We begin by highlighting the core components of this system, including the case stratification, hospital recommendation, and case dispatch modules, along with the pivotal algorithms employed, i.e., the fraud detection, recommendation, and robust satisficing algorithms. We also detail the system's implementation and deployment. We substantiate the proposed system's effectiveness and efficiency with empirical evidence from experiments on a large set of real-world health insurance claims data. | Qitao Shi, Jun Zhou, YaLin Zhang, Longfei Li, Chaoyi Ma, Yifan Wu, Xiaobo Qin | Ant Group, Hangzhou, Zhejiang, China; Ant Group, Beijing, China; Ant Group, Shanghai, China |
|  |  [HoME: Hierarchy of Multi-Gate Experts for Multi-Task Learning at Kuaishou](https://doi.org/10.1145/3690624.3709416) |  | 0 | In this paper, we present the practical problems and the lessons learned at short-video services from Kuaishou. In industry, a widely-used multi-task framework is the Mixture-of-Experts (MoE) paradigm, which always introduces some shared and specific experts for each task and then uses gate networks to measure related experts' contributions. Although the MoE achieves remarkable improvements, we still observe three anomalies that seriously affect model performances in our iteration: (1) Expert Collapse: We found that experts' output distributions are significantly different, and some experts have over 90 weights to balance experts. (2) Expert Degradation: Ideally, the shared-expert aims to provide predictive information for all tasks simultaneously. Nevertheless, we find that some shared-experts are occupied by only one task, which indicates that shared-experts lost their ability but degenerated into some specific-experts. (3) Expert Underfitting: In our services, we have dozens of behavior tasks that need to be predicted, but we find that some data-sparse prediction tasks tend to ignore their specific-experts and assign large weights to shared-experts. The reason might be that the shared-experts can perceive more gradient updates and knowledge from dense tasks, while specific-experts easily fall into underfitting due to their sparse behaviors. Motivated by those observations, we propose HoME to achieve a simple, efficient and balanced MoE system for multi-task learning. | Xu Wang, Jiangxia Cao, Zhiyi Fu, Kun Gai, Guorui Zhou |  |
|  |  [NoteLLM-2: Multimodal Large Representation Models for Recommendation](https://doi.org/10.1145/3690624.3709440) |  | 0 | Large Language Models (LLMs) have demonstrated exceptional proficiency in text understanding and embedding tasks. However, their potential in multimodal representation, particularly for item-to-item (I2I) recommendations, remains underexplored. While leveraging existing Multimodal Large Language Models (MLLMs) for such tasks is promising, challenges arise due to their delayed release compared to corresponding LLMs and the inefficiency in representation tasks. To address these issues, we propose an end-to-end fine-tuning method that customizes the integration of any existing LLMs and vision encoders for efficient multimodal representation. Preliminary experiments revealed that fine-tuned LLMs often neglect image content. To counteract this, we propose NoteLLM-2, a novel framework that enhances visual information. Specifically, we propose two approaches: first, a prompt-based method that segregates visual and textual content, employing a multimodal In-Context Learning strategy to balance focus across modalities; second, a late fusion technique that directly integrates visual information into the final representations. Extensive experiments, both online and offline, demonstrate the effectiveness of our approach. Code is available at https://github.com/Applied-Machine-Learning-Lab/NoteLLM. | Chao Zhang, Haoxin Zhang, Shiwei Wu, Di Wu, Tong Xu, Xiangyu Zhao, Yan Gao, Yao Hu, Enhong Chen |  |
|  |  [Safe Online Bid Optimization with Return on Investment and Budget Constraints](https://doi.org/10.1145/3690624.3709288) |  | 0 | In online marketing, the advertisers' goal is a tradeoff between achieving high volumes and high profitability. The companies business units address this tradeoff by maximizing the volumes while guaranteeing a minimum Return On Investment (ROI) level. Technically speaking, such a task can be naturally modeled as a combinatorial optimization problem subject to ROI and budget constraints that can be solved online. In this picture, the uncertainty over the constraints' parameters plays a crucial role since they can be arbitrarily violated during the learning process due to an uncontrolled algorithms' exploration. Such violations represent a major obstacle to adopting online techniques in real-world applications. Thus, controlling the algorithms' exploration during learning is paramount to making humans trust online learning tools. This paper studies the nature of both optimization and learning problems. In particular, we show that the learning problem is inapproximable within any factor (unless $\textsf{P} = \textsf{NP}$) and provide a pseudo-polynomial-time algorithm to solve its discretized version. Subsequently, we prove that no online learning algorithm can violate the (ROI or budget) constraints a sublinear number of times during the learning process while guaranteeing a sublinear regret. We provide the $\textsf{GCB}$ algorithm that guarantees sublinear regret at the cost of a linear number of constraint violations, and $\textsf{GCB}{safe}$ that guarantees w.h.p. a constant upper bound on the number of constraints violations at the cost of a linear regret. Moreover, we designed $\textsf{GCB}{safe}(\psi,\phi)$, which guarantees both sublinear regret and safety w.h.p. at the cost of accepting tolerances $\psi$ and $\phi$ in the satisfaction of the ROI and budget constraints, respectively. Finally, we provide experimental results to compare the regret and constraint violations of $\textsf{GCB}$ and $\textsf{GCB}{safe}$. | Matteo Castiglioni, Alessandro Nuara, Giulia Romano, Giorgio Spadaro, Francesco Trovò, Nicola Gatti | Assistant Professor, Politecnico di Milano; Postdoc, Politecnico di Milano; Full Professor, Polytechnic Institute of Milan |
|  |  [Mixing Time Matters: Accelerating Effective Resistance Estimation via Bidirectional Method](https://doi.org/10.1145/3690624.3709298) |  | 0 | We study the problem of efficiently approximating the effective resistance (ER) on undirected graphs, where ER is a widely used node proximity measure with applications in graph spectral sparsification, multi-class graph clustering, network robustness analysis, graph machine learning, and more. Specifically, given any nodes s and t in an undirected graph G, we aim to efficiently estimate the ER value R(s,t) between nodes s and t, ensuring a small absolute error ϵ. The previous best algorithm for this problem has a worst-case computational complexity of Õ(L_max^3/ϵ^2 d^2), where the value of L_max depends on the mixing time of random walks on G, d = min{d(s), d(t)}, and d(s), d(t) denote the degrees of nodes s and t, respectively. We improve this complexity to Õ(min{L_max^7/3/ϵ^2/3, L_max^3/ϵ^2d^2, mL_max}), achieving a theoretical improvement of Õ(max{L_max^2/3/ϵ^4/3 d^2, 1, L_max^2/ϵ^2 d^2 m}) over previous results. Here, m denotes the number of edges. Given that L_max is often very large in real-world networks (e.g., L_max > 10^4), our improvement on L_max is significant, especially for real-world networks. We also conduct extensive experiments on real-world and synthetic graph datasets to empirically demonstrate the superiority of our method. The experimental results show that our method achieves a 10× to 1000× speedup in running time while maintaining the same absolute error compared to baseline methods. | Guanyu Cui, Hanzhi Wang, Zhewei Wei |  |
|  |  [D-Tracker: Modeling Interest Diffusion in Social Activity Tensor Data Streams](https://doi.org/10.1145/3690624.3709192) |  | 0 | Large quantities of social activity data, such as weekly web search volumes and the number of new infections with infectious diseases, reflect peoples' interests and activities. It is important to discover temporal patterns from such data and to forecast future activities accurately. However, modeling and forecasting social activity data streams is difficult because they are high-dimensional and composed of multiple time-varying dynamics such as trends, seasonality, and interest diffusion. In this paper, we propose D-Tracker, a method for continuously capturing time-varying temporal patterns within social activity tensor data streams and forecasting future activities. Our proposed method has the following properties: (a) Interpretable: it incorporates the partial differential equation into a tensor decomposition framework and captures time-varying temporal patterns such as trends, seasonality, and interest diffusion between locations in an interpretable manner; (b) Automatic: it has no hyperparameters and continuously models tensor data streams fully automatically; (c) Scalable: the computation time of D-Tracker is independent of the time series length. Experiments using web search volume data obtained from GoogleTrends, and COVID-19 infection data obtained from COVID-19 Open Data Repository show that our method can achieve higher forecasting accuracy in less computation time than existing methods while extracting the interest diffusion between locations. Our source code and datasets are available at {https://github.com/Higashiguchi-Shingo/D-Tracker. | Shingo Higashiguchi, Yasuko Matsubara, Koki Kawabata, Taichi Murayama, Yasushi Sakurai |  |
|  |  [On the Hyperparameter Loss Landscapes of Machine Learning Models: An Exploratory Study](https://doi.org/10.1145/3690624.3709229) |  | 0 | Previous efforts on hyperparameter optimization (HPO) of machine learning(ML) models predominately focus on algorithmic advances, yet little is knownabout the topography of the underlying hyperparameter (HP) loss landscape,which plays a fundamental role in governing the search process of HPO. Whileseveral works have conducted fitness landscape analysis (FLA) on various MLsystems, they are limited to properties of isolated landscape withoutinterrogating the potential structural similarities among them. The explorationof such similarities can provide a novel perspective for understanding themechanism behind modern HPO methods, but has been missing, possibly due to theexpensive cost of large-scale landscape construction, and the lack of effectiveanalysis methods. In this paper, we mapped 1,500 HP loss landscapes of 6representative ML models on 63 datasets across different fidelity levels, with11M+ configurations. By conducting exploratory analysis on these landscapeswith fine-grained visualizations and dedicated FLA metrics, we observed asimilar landscape topography across a wide range of models, datasets, andfidelities, and shed light on several central topics in HPO. | Mingyu Huang, Ke Li | University of Exeter Department of Computer Science; University of Electronic Science and Technology of China Xiyuan Avenue College of Computer Science and Engineering |
|  |  [Robust Uplift Modeling with Large-Scale Contexts for Real-time Marketing](https://doi.org/10.1145/3690624.3709293) |  | 0 | Improving user engagement and platform revenue is crucial for online marketing platforms. Uplift modeling is proposed to solve this problem, which applies different treatments (e.g., discounts, bonus) to satisfy corresponding users. Despite progress in this field, limitations persist. Firstly, most of them focus on scenarios where only user features exist. However, in real-world scenarios, there are rich contexts available in the online platform (e.g., short videos, news), and the uplift model needs to infer an incentive for each user on the specific item, which is called real-time marketing. Thus, only considering the user features will lead to biased prediction of the responses, which may cause the cumulative error for uplift prediction. Moreover, due to the large-scale contexts, directly concatenating the context features with the user features will cause a severe distribution shift in the treatment and control groups. Secondly, capturing the interaction relationship between the user features and context features can better predict the user response. To solve the above limitations, we propose a novel model-agnostic Robust Uplift Modeling with Large-Scale Contexts (UMLC) framework for Real-time Marketing. Our UMLC includes two customized modules. 1) A response-guided context grouping module for extracting context features information and condensing value space through clusters. 2) A feature interaction module for obtaining better uplift prediction. Specifically, this module contains two parts: a user-context interaction component for better modeling the response; a treatment-feature interaction component for discovering the treatment assignment sensitive feature of each instance to better predict the uplift. Moreover, we conduct extensive experiments on a synthetic dataset and a real-world product dataset to verify the effectiveness and compatibility of our UMLC. | Zexu Sun, Qiyu Han, Minqin Zhu, Hao Gong, Dugang Liu, Chen Ma |  |
|  |  [Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization](https://doi.org/10.1145/3690624.3709280) |  | 0 | Distribution shifts between training and testing datasets, contrary to classical machine learning assumptions, frequently occur in practice and impede model generalization performance. Studies on domain generalization (DG) thereby arise, aiming to predict the label on unseen target domain data by only using data from source domains. In the meanwhile, the contrastive learning (CL) technique, which prevails in self-supervised pre-training, can align different augmentation of samples to obtain invariant representation. It is intuitive to consider the class-separated representations learned in CL are able to improve domain generalization, while the reality is quite the opposite: people observe directly applying CL deteriorates the performance. We analyze the phenomenon with the CL theory and discover the lack of domain connectivity in the DG setting causes the deficiency. Thus we propose domain-connecting contrastive learning (\model) to enhance the conceptual connectivity across domains and obtain generalizable representations for DG. Specifically, more aggressive data augmentation and cross-domain positive samples are introduced into self-contrastive learning to improve domain connectivity. Furthermore, to better embed the unseen test domains, we propose model anchoring to exploit the domain connectivity in pre-trained representations and complement it with generative transformation loss. Extensive experiments on five standard DG benchmarks are provided. The results verify that \model~outperforms state-of-the-art baselines even without domain supervision. | Tianxin Wei, Yifan Chen, Xinrui He, Wenxuan Bao, Jingrui He | PhD student, University of Illinois, Urbana-Champaign; Full Professor, School of Information Sciences, University of Illinois at Urbana-Champaign; PhD student, Department of Computer Science |
|  |  [An Adaptable Budget Planner for Enhancing Budget-Constrained Auto-Bidding in Online Advertising](https://doi.org/10.1145/3690624.3709414) |  | 0 | In online advertising, advertisers commonly utilize auto-bidding services to bid for impression opportunities. A typical objective of the auto-bidder is to optimize the advertiser's cumulative value of winning impressions within specified budget constraints. However, such a problem is challenging due to the complex bidding environment faced by diverse advertisers. To address this challenge, we introduce ABPlanner, a few-shot adaptable budget planner designed to improve budget-constrained auto-bidding. ABPlanner is based on a hierarchical bidding framework that decomposes the bidding process into shorter, manageable stages. Within this framework, ABPlanner allocates the budget across all stages, allowing a low-level auto-bidder to bids based on the budget allocation plan. The adaptability of ABPlanner is achieved through a sequential decision-making approach, inspired by in-context reinforcement learning. For each advertiser, ABPlanner adjusts the budget allocation plan episode by episode, using data from previous episodes as prompt for current decisions. This enables ABPlanner to quickly adapt to different advertisers with few-shot data, providing a sample-efficient solution. Extensive simulation experiments and real-world A/B testing validate the effectiveness of ABPlanner, demonstrating its capability to enhance the cumulative value achieved by auto-bidders. | Zhijian Duan, Yusen Huo, Tianyu Wang, Zhilin Zhang, Yeshu Li, Chuan Yu, Jian Xu, Bo Zheng, Xiaotie Deng |  |
|  |  [Experimenting, Fast and Slow: Bayesian Optimization of Long-term Outcomes with Online Experiments](https://doi.org/10.1145/3690624.3709419) |  | 0 | Online experiments in internet systems, also known as A/B tests, are used for a wide range of system tuning problems, such as optimizing recommender system ranking policies and learning adaptive streaming controllers. Decision-makers generally wish to optimize for long-term treatment effects of the system changes, which often requires running experiments for a long time as short-term measurements can be misleading due to non-stationarity in treatment effects over time. The sequential experimentation strategies–which typically involve several iterations–can be prohibitively long in such cases. We describe a novel approach that combines fast experiments (e.g., biased experiments run only for a few hours or days) and/or offline proxies (e.g., off-policy evaluation) with long-running, slow experiments to perform sequential, Bayesian optimization over large action spaces in a short amount of time. | Qing Feng, Samuel Daulton, Benjamin Letham, Maximilian Balandat, Eytan Bakshy |  |
|  |  [SWaT: Statistical Modeling of Video Watch Time through User Behavior Analysis](https://doi.org/10.1145/3690624.3709415) |  | 0 | The significance of estimating video watch time has been highlighted by the rising importance of (short) video recommendation, which has become a core product of mainstream social media platforms. Modeling video watch time, however, has been challenged by the complexity of user-video interaction, such as different user behavior modes in watching the recommended videos and varying watching probabilities over the video horizon. Despite the importance and challenges, existing literature on modeling video watch time mostly focuses on relatively black-box mechanical enhancement of the classical regression/classification losses, without factoring in user behavior in a principled manner. In this paper, we for the first time take on a user-centric perspective to model video watch time, from which we propose a white-box statistical framework that directly translates various user behavior assumptions in watching (short) videos into statistical watch time models. These behavior assumptions are portrayed by our domain knowledge on users' behavior modes in video watching. We further employ bucketization to cope with user's non-stationary watching probability over the video horizon, which additionally helps to respect the constraint of video length and facilitate the practical compatibility between the continuous regression event of watch time and other binary classification events. We test our models extensively on two public datasets, a large-scale offline industrial dataset, and an online A/B test on a short video platform with hundreds of millions of daily-active users. On all experiments, our models perform competitively against strong relevant baselines, demonstrating the efficacy of our user-centric perspective and proposed framework. | Shentao Yang, Haichuan Yang, Linna Du, Adithya Ganesh, Bo Peng, Boying Liu, Serena Li, Ji Liu |  |
|  |  [Modeling Time-evolving Causality over Data Streams](https://doi.org/10.1145/3690624.3709283) |  | 0 | Given an extensive, semi-infinite collection of multivariate coevolving data sequences (e.g., sensor/web activity streams) whose observations influence each other, how can we discover the time-changing cause-and-effect relationships in co-evolving data streams? How efficiently can we reveal dynamical patterns that allow us to forecast future values? In this paper, we present a novel streaming method, ModePlait, which is designed for modeling such causal relationships (i.e., time-evolving causality) in multivariate co-evolving data streams and forecasting their future values. The solution relies on characteristics of the causal relationships that evolve over time in accordance with the dynamic changes of exogenous variables. ModePlait has the following properties: (a) Effective: it discovers the time-evolving causality in multivariate co-evolving data streams by detecting the transitions of distinct dynamical patterns adaptively. (b) Accurate: it enables both the discovery of time-evolving causality and the forecasting of future values in a streaming fashion. (c) Scalable: our algorithm does not depend on data stream length and thus is applicable to very large sequences. Extensive experiments on both synthetic and real-world datasets demonstrate that our proposed model outperforms state-of-the-art methods in terms of discovering the time-evolving causality as well as forecasting. | Naoki Chihara, Yasuko Matsubara, Ren Fujiwara, Yasushi Sakurai |  |
|  |  [Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial Data Management Perspective](https://doi.org/10.1145/3690624.3709177) |  | 0 | Road traffic forecasting is crucial in real-world intelligent transportation scenarios like traffic dispatching and path planning in city management and personal traveling. Spatio-temporal graph neural networks (STGNNs) stand out as the mainstream solution in this task. Nevertheless, the quadratic complexity of remarkable dynamic spatial modeling-based STGNNs has become the bottleneck over large-scale traffic data. From the spatial data management perspective, we present a novel Transformer framework called PatchSTG to efficiently and dynamically model spatial dependencies for large-scale traffic forecasting with interpretability and fidelity. Specifically, we design a novel irregular spatial patching to reduce the number of points involved in the dynamic calculation of Transformer. The irregular spatial patching first utilizes the leaf K-dimensional tree (KDTree) to recursively partition irregularly distributed traffic points into leaf nodes with a small capacity, and then merges leaf nodes belonging to the same subtree into occupancy-equaled and non-overlapped patches through padding and backtracking. Based on the patched data, depth and breadth attention are used interchangeably in the encoder to dynamically learn local and global spatial knowledge from points in a patch and points with the same index of patches. Experimental results on four real world large-scale traffic datasets show that our PatchSTG achieves train speed and memory utilization improvements up to 10× and 4× with the state-of-the-art performance. | Yuchen Fang, Yuxuan Liang, Bo Hui, Zezhi Shao, Liwei Deng, Xu Liu, Xinke Jiang, Kai Zheng |  |
|  |  [UniGraph: Learning a Unified Cross-Domain Foundation Model for Text-Attributed Graphs](https://doi.org/10.1145/3690624.3709277) |  | 0 | Foundation models like ChatGPT and GPT-4 have revolutionized artificial intelligence, exhibiting remarkable abilities to generalize across a wide array of tasks and applications beyond their initial training objectives. However, graph learning has predominantly focused on single-graph models, tailored to specific tasks or datasets, lacking the ability to transfer learned knowledge to different domains. This limitation stems from the inherent complexity and diversity of graph structures, along with the different feature and label spaces specific to graph data. In this paper, we recognize text as an effective unifying medium and employ Text-Attributed Graphs (TAGs) to leverage this potential. We present our UniGraph framework, designed to learn a foundation model for TAGs, which is capable of generalizing to unseen graphs and tasks across diverse domains. Unlike single-graph models that use pre-computed node features of varying dimensions as input, our approach leverages textual features for unifying node representations, even for graphs such as molecular graphs that do not naturally have textual features. We propose a novel cascaded architecture of Language Models (LMs) and Graph Neural Networks (GNNs) as backbone networks. Additionally, we propose the first pre-training algorithm specifically designed for large-scale self-supervised learning on TAGs, based on Masked Graph Modeling. We introduce graph instruction tuning using Large Language Models (LLMs) to enable zero-shot prediction ability. Our comprehensive experiments across various graph learning tasks and domains demonstrate the model's effectiveness in self-supervised representation learning on unseen graphs, few-shot in-context transfer, and zero-shot transfer, even surpassing or matching the performance of GNNs that have undergone supervised training on target datasets. | Yufei He, Yuan Sui, Xiaoxin He, Bryan Hooi | National Univer-sity of Singapore School of Computing; National University of Sin-gapore Institute of Data Science |
|  |  [Adaptive Domain Inference Attack with Concept Hierarchy](https://doi.org/10.1145/3690624.3709332) |  | 0 | As deep neural networks are increasingly deployed in sensitive application domains, such as healthcare and security, it's necessary to understand what kind of sensitive information can be inferred from these models. Existing model-targeted attacks all assume the attacker has known the application domain or training data distribution, which plays an essential role in successful attacks. Can removing the domain information from model APIs protect models from these attacks? This paper studies this critical problem. Unfortunately, even with minimal knowledge, i.e., accessing the model as an unnamed function without leaking the meaning of input and output, the proposed adaptive domain inference attack (ADI) can still successfully estimate relevant subsets of training data. We show that the extracted relevant data can significantly improve, for instance, the performance of model-inversion attacks. Specifically, the ADI method utilizes a concept hierarchy built on top of a large collection of available public and private datasets and a novel algorithm to adaptively tune the likelihood of leaf concepts showing up in the unseen training data. The ADI attack not only extracts partial training data at the concept level, but also converges fast and requires much fewer target-model accesses than another domain inference attack, GDI. | Yuechun Gu, Jiajie He, Keke Chen | Marquette University |
|  |  [InvDiff: Invariant Guidance for Bias Mitigation in Diffusion Models](https://doi.org/10.1145/3690624.3709165) |  | 0 | As one of the most successful generative models, diffusion models have demonstrated remarkable efficacy in synthesizing high-quality images. These models learn the underlying high-dimensional data distribution in an unsupervised manner. Despite their success, diffusion models are highly data-driven and prone to inheriting the imbalances and biases present in real-world data. Some studies have attempted to address these issues by designing text prompts for known biases or using bias labels to construct unbiased data. While these methods have shown improved results, real-world scenarios often contain various unknown biases, and obtaining bias labels is particularly challenging. In this paper, we emphasize the necessity of mitigating bias in pre-trained diffusion models without relying on auxiliary bias annotations. To tackle this problem, we propose a framework, InvDiff, which aims to learn invariant semantic information for diffusion guidance. Specifically, we propose identifying underlying biases in the training data and designing a novel debiasing training objective. Then, we employ a lightweight trainable module that automatically preserves invariant semantic information and uses it to guide the diffusion model's sampling process toward unbiased outcomes simultaneously. Notably, we only need to learn a small number of parameters in the lightweight learnable module without altering the pre-trained diffusion model. Furthermore, we provide a theoretical guarantee that the implementation of InvDiff is equivalent to reducing the error upper bound of generalization. Extensive experimental results on three publicly available benchmarks demonstrate that InvDiff effectively reduces biases while maintaining the quality of image generation. Our code is available at https://github.com/Hundredl/InvDiff. | Min Hou, Yueying Wu, Chang Xu, YuHao Huang, Chenxi Bai, Le Wu, Jiang Bian |  |
|  |  [DIPS: Optimal Dynamic Index for Poisson πps Sampling](https://doi.org/10.1145/3690624.3709162) |  | 0 | This paper addresses the Poisson πps sampling problem, a topic of significant academic interest in various domains and with practical data mining applications, such as influence maximization. The problem includes a set 𝒮 of n elements, where each element v is assigned a weight w(v) reflecting its importance. The goal is to generate a random subset X of 𝒮, where each element v ∈𝒮 is included in X independently with probability c· w(v)/∑_v ∈𝒮 w(v), where 0<c≤ 1 is a constant. The subsets must be independent across different queries. While the Poisson πps sampling problem can be reduced to the well-studied subset sampling problem, updates in Poisson πps sampling, such as adding a new element or removing an element, would cause the probabilities of all n elements to change in the corresponding subset sampling problem, making this approach impractical for dynamic scenarios. To address this, we propose a dynamic index specifically tailored for the Poisson πps sampling problem, supporting optimal expected 𝒪(1) query time and 𝒪(1) index update time, with an optimal 𝒪(n) space cost. Our solution involves recursively partitioning the set by weights and ultimately using table lookup. The core of our solution lies in addressing the challenges posed by weight explosion and correlations between elements. Empirical evaluations demonstrate that our approach achieves significant speedups in update time while maintaining consistently competitive query time compared to the subset-sampling-based methods. | Jinchao Huang, Sibo Wang |  |
|  |  [Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning Problem](https://doi.org/10.1145/3690624.3709268) |  | 0 | SMOTE is the established geometric approach to random oversampling to balance classes in the imbalanced classes learning problem, followed by many extensions. Its idea is to introduce synthetic data points of the minor class, with each new point being the convex combination of an existing data point and one of its k-nearest neighbors. This could be viewed as a sampling from the edges of a geometric neighborhood graph. Borrowing tools from the topological data analysis, we propose a generalization of the sampling approach, thus sampling from the simplices of the geometric neighborhood simplicial complex. That is, a new point is defined by the barycentric coordinates with respect to a simplex spanned by an arbitrary number of data points being sufficiently close, rather than a pair. We evaluate the generalized technique which we call Simplicial SMOTE on 23 benchmark datasets, and conclude that it outperforms the original SMOTE and its extensions. Moreover, we show how simplicial sampling can be integrated into several popular SMOTE extensions, with our simplicial generalization of Borderline SMOTE further improves the performance on benchmarks datasets. | Oleg Kachan, Andrey V. Savchenko, Gleb Gusev | Principal Researcher, Sber AI Lab; Principal Researcher, ARTIFICIAL INTELLIGENCE RESEARCH INSTITUTE (AIRI); Researcher, HSE University |
|  |  [Learnable Prompt as Pseudo-Imputation: Rethinking the Necessity of Traditional EHR Data Imputation in Downstream Clinical Prediction](https://doi.org/10.1145/3690624.3709166) |  | 0 | Analyzing the health status of patients based on Electronic Health Records (EHR) is a fundamental research problem in medical informatics. The presence of extensive missing values in EHR makes it challenging for deep neural networks (DNNs) to directly model the patient's health status. Existing DNNs training protocols, including Impute-then-Regress Procedure and Jointly Optimizing of Impute-n-Regress Procedure, require the additional imputation models to reconstruction missing values. However, Impute-then-Regress Procedure introduces the risk of injecting imputed, non-real data into downstream clinical prediction tasks, resulting in power loss, biased estimation, and poorly performing models, while Jointly Optimizing of Impute-n-Regress Procedure is also difficult to generalize due to the complex optimization space and demanding data requirements. Inspired by the recent advanced literature of learnable prompt in the fields of NLP and CV, in this work, we rethought the necessity of the imputation model in downstream clinical tasks, and proposed Learnable Prompt as Pseudo-Imputation (PAI) as a new training protocol to assist EHR analysis. PAI no longer introduces any imputed data but constructs a learnable prompt to model the implicit preferences of the downstream model for missing values, resulting in a significant performance improvement for all state-of-the-arts EHR analysis models on four real-world datasets across two clinical prediction tasks. Further experimental analysis indicates that PAI exhibits higher robustness in situations of data insufficiency and high missing rates. More importantly, as a plug-and-play protocol, PAI can be easily integrated into any existing or even imperceptible future EHR analysis models. | Weibin Liao, Yinghao Zhu, Zhongji Zhang, Yuhang Wang, Zixiang Wang, Xu Chu, Yasha Wang, Liantao Ma | Beihang University Institute of Artificial Intelligence; Peking University School of Computer Science; Peking University National Engineering Research Center for Software Engineering |
|  |  [Language Representation Favored Zero-Shot Cross-Domain Cognitive Diagnosis](https://doi.org/10.1145/3690624.3709281) |  | 0 | Cognitive diagnosis aims to infer students' mastery levels based on their historical response logs. However, existing cognitive diagnosis models (CDMs), which rely on ID embeddings, often have to train specific models on specific domains. This limitation may hinder their directly practical application in various target domains, such as different subjects (e.g., Math, English and Physics) or different education platforms (e.g., ASSISTments, Junyi Academy and Khan Academy). To address this issue, this paper proposes the language representation favored zero-shot cross-domain cognitive diagnosis (LRCD). Specifically, LRCD first analyzes the behavior patterns of students, exercises and concepts in different domains, and then describes the profiles of students, exercises and concepts using textual descriptions. Via recent advanced text-embedding modules, these profiles can be transformed to vectors in the unified language space. Moreover, to address the discrepancy between the language space and the cognitive diagnosis space, we propose language-cognitive mappers in LRCD to learn the mapping from the former to the latter. Then, these profiles can be easily and efficiently integrated and trained with existing CDMs. Extensive experiments show that training LRCD on real-world datasets can achieve commendable zero-shot performance across different target domains, and in some cases, it can even achieve competitive performance with some classic CDMs trained on the full response data on target domains. Notably, we surprisingly find that LRCD can also provide interesting insights into the differences between various subjects (such as humanities and sciences) and sources (such as primary and secondary education). | Shuo Liu, Zihan Zhou, Yuanhao Liu, Jing Zhang, Hong Qian |  |
|  |  [Fine-tuning Multimodal Large Language Models for Product Bundling](https://doi.org/10.1145/3690624.3709255) |  | 0 | Recent advances in product bundling have leveraged multimodal information through sophisticated encoders, but remain constrained by limited semantic understanding and a narrow scope of knowledge. Therefore, some attempts employ In-context Learning (ICL) to explore the potential of large language models (LLMs) for their extensive knowledge and complex reasoning abilities. However, these efforts are inadequate in understanding mulitmodal data and exploiting LLMs' knowledge for product bundling. To bridge the gap, we introduce Bundle-MLLM, a novel framework that fine-tunes LLMs through a hybrid item tokenization approach within a well-designed optimization strategy. Specifically, we integrate textual, media, and relational data into a unified tokenization, introducing a soft separation token to distinguish between textual and non-textual tokens. Additionally, a streamlined yet powerful multimodal fusion module is employed to embed all non-textual features into a single, informative token, significantly boosting efficiency. To tailor product bundling tasks for LLMs, we reformulate the task as a multiple-choice question with candidate items as options. We further propose a progressive optimization strategy that fine-tunes LLMs for disentangled objectives: learning bundle patterns and enhancing multimodal semantic understanding specific to product bundling. Extensive experiments demonstrate that our approach outperforms a range of state-of-the-art (SOTA) methods. Codes are available at https://github.com/Xiaohao-Liu/Bundle-MLLM | Xiaohao Liu, Jie Wu, Zhulin Tao, Yunshan Ma, Yinwei Wei, TatSeng Chua | Communication University of China, Beijing, China; Shandong University, Jinan, Shandong, China; National University of Singapore, Singapore, Singapore |
|  |  [Diffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing](https://doi.org/10.1145/3690624.3709317) |  | 0 | Computerized Adaptive Testing (CAT) aims to select the most appropriate questions based on the examinee's ability and is widely used in online education. However, existing CAT systems often lack initial understanding of the examinee's ability, requiring random probing questions. This can lead to poorly matched questions, extending the test duration and negatively impacting the examinee's mindset, a phenomenon referred to as the Cold Start with Insufficient Prior (CSIP) task. This issue occurs because CAT systems do not effectively utilize the abundant prior information about the examinee available from other courses on online platforms. These response records, due to the commonality of cognitive states across different knowledge domains, can provide valuable prior information for the target domain. However, no prior work has explored solutions for the CSIP task. In response to this gap, we propose Diffusion Cognitive States TransfeR Framework (DCSR), a novel domain transfer framework based on Diffusion Models (DMs) to address the CSIP task. Specifically, we construct a cognitive state transition bridge between domains, guided by the common cognitive states of examinees, encouraging the model to reconstruct the initial ability state in the target domain. To enrich the expressive power of the generated data, we analyze the causal relationships in the generation process from a causal perspective. Redundant and extraneous cognitive states can lead to limited transfer and negative transfer effects. Our DCSR can seamlessly apply the generated initial ability states in the target domain to existing question selection algorithms, thus improving the cold start performance of the CAT system. Extensive experiments conducted on five real-world datasets demonstrate that DCSR significantly outperforms existing baseline methods in addressing the CSIP task. | Haiping Ma, Aoqing Xia, Changqian Wang, Hai Wang, Xingyi Zhang |  |
|  |  [Adapting to Generalized Online Label Shift by Invariant Representation Learning](https://doi.org/10.1145/3690624.3709182) |  | 0 | The problem of online label shift, where label distribution evolves over time while the label-conditional density remains unchanged, has attracted increasing attentions. Although existing approaches have achieved sound theoretical guarantees and encouraging performance, the assumption of an unchanged conditional distribution may limit its application in broader tasks. In this paper, we investigate an extended variant named generalized online label shift (GOLS) problem, in which we relax the label shift assumption on the raw feature space and instead assume the existence of an unknown invariant representation such that conditional distribution of this representation given the label remains constant. To handle GOLS, our main idea involves capturing the inherently stable information from non-stationary streams, in the form of learning an invariant representation. Specifically, we design a novel objective to learn the invariant representation, which exploits the unique structure in GOLS. To optimize this objective, we propose an algorithm employing online ensemble paradigm to perform multi-resolution updates using various historical data windows, thereby enhancing the stability of the representation. This approach is theoretically guaranteed to achieve an optimal convergence rate. To improve the efficiency of the ensemble framework, we further propose a mask-based implementation for ensembling with DNNs. Experiments on benchmarks and real-world tasks validate the effectiveness of our approach. | YuYang Qian, YiHan Wang, ZhenYu Zhang, Yuan Jiang, ZhiHua Zhou | Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan |
|  |  [Exploring Heterogeneity and Uncertainty for Graph-based Cognitive Diagnosis Models in Intelligent Education](https://doi.org/10.1145/3690624.3709264) |  | 0 | Graph-based Cognitive Diagnosis (CD) has attracted much research interest due to its strong ability on inferring students' proficiency levels on knowledge concepts. While graph-based CD models have demonstrated remarkable performance, we contend that they still cannot achieve optimal performance due to the neglect of edge heterogeneity and uncertainty. Edges involve both correct and incorrect response logs, indicating heterogeneity. Meanwhile, a response log can have uncertain semantic meanings, e.g., a correct log can indicate true mastery or fortunate guessing, and a wrong log can indicate a lack of understanding or a careless mistake. In this paper, we propose an Informative Semantic-aware Graph-based Cognitive Diagnosis model (ISG-CD), which focuses on how to utilize the heterogeneous graph in CD and minimize effects of uncertain edges. Specifically, to explore heterogeneity, we propose a semantic-aware graph neural networks based CD model. To minimize effects of edge uncertainty, we propose an Informative Edge Differentiation layer from an information bottleneck perspective, which suggests keeping a minimal yet sufficient reliable graph for CD in an unsupervised way. We formulate this process as maximizing mutual information between the reliable graph and response logs, while minimizing mutual information between the reliable graph and the original graph. After that, we prove that mutual information maximization can be theoretically converted to the classic binary cross entropy loss function, while minimizing mutual information can be realized by the Hilbert-Schmidt Independence Criterion. Finally, we adopt an alternating training strategy for optimizing learnable parameters of both the semantic-aware graph neural networks based CD model and the edge differentiation layer. Extensive experiments on three real-world datasets have demonstrated the effectiveness of ISG-CD. | Pengyang Shao, Yonghui Yang, Chen Gao, Lei Chen, Kun Zhang, Chenyi Zhuang, Le Wu, Yong Li, Meng Wang |  |
|  |  [HeavyLocker: Lock Heavy Hitters in Distributed Data Streams](https://doi.org/10.1145/3690624.3709167) |  | 0 | In recent years, sketching has emerged as a pivotal technique for identifying heavy hitters (items with high frequency) in large-scale data streams. Despite this progress, the majority of existing sketch algorithms are tailored primarily for detecting local heavy hitters within a single data stream, with only a few capable of extending their application to global heavy hitters across distributed data streams. A common challenge encountered by these algorithms is balancing performance with accuracy. To address this challenge, we introduce HeavyLocker, a novel sketch algorithm that takes advantage of a distinct feature of real data streams: the separability of heavy hitters. By leveraging this attribute, HeavyLocker precisely locks and protects potential heavy hitters during the data stream processing, ensuring accuracy in local heavy hitter detection without compromising on speed. This unique capability also facilitates its application to global detection tasks. Through theoretical analysis, we validate the efficacy of HeavyLocker's locking mechanism. Our extensive experiments show that HeavyLocker outperforms five benchmarked algorithms in accuracy and maintains fast speed for both local and global heavy hitter detection, significantly reducing errors by up to an order of magnitude compared to the renowned Double-Anonymous Sketch. | Qilong Shi, Xirui Li, Hanyue Zheng, Tong Yang, Yangyang Wang, Mingwei Xu | Tsinghua University, Beijing, China; Peking University, Beijing, China |
|  |  [MLDGG: Meta-Learning for Domain Generalization on Graphs](https://doi.org/10.1145/3690624.3709188) |  | 0 | Domain generalization on graphs aims to develop models with robust generalization capabilities, ensuring effective performance on the testing set despite disparities between testing and training distributions. However, existing methods often rely on static encoders directly applied to the target domain, constraining its flexible adaptability. In contrast to conventional methodologies, which concentrate on developing specific generalized models, our framework, MLDGG, endeavors to achieve adaptable generalization across diverse domains by integrating cross-multi-domain meta-learning with structure learning and semantic identification. Initially, it introduces a generalized structure learner to mitigate the adverse effects of task-unrelated edges, enhancing the comprehensiveness of representations learned by Graph Neural Networks (GNNs) while capturing shared structural information across domains. Subsequently, a representation learner is designed to disentangle domain-invariant semantic and domain-specific variation information in node embedding by leveraging causal reasoning for semantic identification, further enhancing generalization. In the context of meta-learning, meta-parameters for both learners are optimized to facilitate knowledge transfer and enable effective adaptation to graphs through fine-tuning within the target domains, where target graphs are inaccessible during training. Our empirical results demonstrate that MLDGG surpasses baseline methods, showcasing its effectiveness in three different distribution shift settings. | Qin Tian, Chen Zhao, Minglai Shao, Wenjun Wang, Yujie Lin, Dong Li |  |
|  |  [Dynamic Causal Structure Discovery and Causal Effect Estimation](https://doi.org/10.1145/3690624.3709345) |  | 0 | To represent the causal relationships between variables, a directed acyclic graph (DAG) is widely utilized in many areas, such as social sciences, epidemics, and genetics. Many causal structure learning approaches are developed to learn the hidden causal structure utilizing deep-learning approaches. However, these approaches have a hidden assumption that the causal relationship remains unchanged over time, which may not hold in real life. In this paper, we develop a new framework to model the dynamic causal graph where the causal relations are allowed to be time-varying. We incorporate the basis approximation method into the score-based causal discovery approach to capture the dynamic pattern of the causal graphs. Utilizing the autoregressive model structure, we could capture both contemporaneous and time-lagged causal relationships while allowing them to vary with time. We propose an algorithm that could provide both past-time estimates and future-time predictions on the causal graphs, and conduct simulations to demonstrate the usefulness of the proposed method. We also apply the proposed method for the covid-data analysis, and provide causal estimates on how policy restriction's effect changes. | Jianian Wang, Rui Song |  |
|  |  [Progressive Generalization Risk Reduction for Data-Efficient Causal Effect Estimation](https://doi.org/10.1145/3690624.3709305) |  | 0 | Causal effect estimation (CEE) provides a crucial tool for predicting the unobserved counterfactual outcome for an entity. As CEE relaxes the requirement for “perfect” counterfactual samples (e.g., patients with identical attributes and only differ in treatments received) that are impractical to obtain and can instead operate on observational data, it is usually used in high-stake domains like medical treatment effect prediction. Nevertheless, in those high-stake domains, gathering a decently sized, fully labelled observational dataset remains challenging due to hurdles associated with costs, ethics, expertise and time needed, etc., of which medical treatment surveys are a typical example. Consequently, if the training dataset is small in scale, low generalization risks can hardly be achieved on any CEE algorithms. Unlike existing CEE methods that assume the constant availability of a dataset with abundant samples, in this paper, we study a more realistic CEE setting where the labelled data samples are scarce at the beginning, while more can be gradually acquired over the course of training – assuredly under a limited budget considering their expensive nature. Then, the problem naturally comes down to actively selecting the best possible samples to be labelled, e.g., identifying the next subset of patients to conduct the treatment survey. However, acquiring quality data for reducing the CEE risk under limited labelling budgets remains under-explored until now. To fill the gap, we theoretically analyse the generalization risk from an intriguing perspective of progressively shrinking its upper bound, and develop a principled label acquisition pipeline exclusively for CEE tasks. With our analysis, we propose the Model Agnostic Causal Active Learning (MACAL) algorithm for batch-wise label acquisition, which aims to reduce both the CEE model's uncertainty and the post-acquisition ... | Hechuan Wen, Tong Chen, Guanhua Ye, Li Kheng Chai, Shazia Sadiq, Hongzhi Yin |  |
|  |  [Brain Effective Connectivity Estimation via Fourier Spatiotemporal Attention](https://doi.org/10.1145/3690624.3709226) |  | 0 | Estimating brain effective connectivity (EC) from functional magnetic resonance imaging (fMRI) data can aid in comprehending the neural mechanisms underlying human behavior and cognition, providing a foundation for disease diagnosis. However, current spatiotemporal attention modules handle temporal and spatial attention separately, extracting temporal and spatial features either sequentially or in parallel. These approaches overlook the inherent spatiotemporal correlations present in real world fMRI data. Additionally, the presence of noise in fMRI data further limits the performance of existing methods. In this paper, we propose a novel brain effective connectivity estimation method based on Fourier spatiotemporal attention (FSTA-EC), which combines Fourier attention and spatiotemporal attention to simultaneously capture inter-series (spatial) dynamics and intra-series (temporal) dependencies from high-noise fMRI data. Specifically, Fourier attention is designed to convert the high-noise fMRI data to frequency domain, and map the denoised fMRI data back to physical domain, and spatiotemporal attention is crafted to simultaneously learn spatiotemporal dynamics. Furthermore, through a series of proofs, we demonstrate that incorporating learnable filter into fast Fourier transform and inverse fast Fourier transform processes is mathematically equivalent to performing cyclic convolution. The experimental results on simulated and real-resting-state fMRI datasets demonstrate that the proposed method exhibits superior performance when compared to state-of-the-art methods. | Wen Xiong, Jinduo Liu, Junzhong Ji, Fenglong Ma |  |
|  |  [CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events](https://doi.org/10.1145/3690624.3709231) |  | 0 | Large-scale human mobility exhibits spatial and temporal patterns that can assist policymakers in decision making. Although traditional prediction models attempt to capture these patterns, they often interfered by non-periodic public events, such as disasters and occasional celebrations. Since regular human mobility patterns are heavily affected by these events, estimating their causal effects is critical to accurate mobility predictions. Although news articles provide unique perspectives on these events in an unstructured format, processing is a challenge. In this study, we propose a causality-augmented prediction model, called CausalMob, to analyze the causal effects of public events. We first utilize large language models (LLMs) to extract human intentions from news articles and transform them into features that act as causal treatments. Next, the model learns representations of spatio-temporal regional covariates from multiple data sources to serve as confounders for causal inference. Finally, we present a causal effect estimation framework to ensure event features remain independent of confounders during prediction. Based on large-scale real-world data, the experimental results show that the proposed model excels in human mobility prediction, outperforming state-of-the-art models. | Xiaojie Yang, Hangli Ge, Jiawei Wang, Zipei Fan, Renhe Jiang, Ryosuke Shibasaki, Noboru Koshizuka |  |
|  |  [Inductive Link Prediction on N-ary Relational Facts via Semantic Hypergraph Reasoning](https://doi.org/10.1145/3690624.3709195) |  | 0 | N-ary relational facts represent semantic correlations among more than two entities. While recent studies have developed link prediction (LP) methods to infer missing relations for knowledge graphs (KGs) containing n-ary relational facts, they are generally limited to transductive settings. Fully inductive settings, where predictions are made on previously unseen entities, remain a significant challenge. As existing methods are mainly entity embedding-based, they struggle to capture entity-independent logical rules. To fill in this gap, we propose an n-ary subgraph reasoning framework for fully inductive link prediction (ILP) on n-ary relational facts. This framework reasons over local subgraphs and has a strong inductive inference ability to capture n-ary patterns. Specifically, we introduce a novel graph structure, the n-ary semantic hypergraph, to facilitate subgraph extraction. Moreover, we develop a subgraph aggregating network, NS-HART, to effectively mine complex semantic correlations within subgraphs. Theoretically, we provide a thorough analysis from the score function optimization perspective to shed light on NS-HART's effectiveness for n-ary ILP tasks. Empirically, we conduct extensive experiments on a series of inductive benchmarks, including transfer reasoning (with and without entity features) and pairwise subgraph reasoning. The results highlight the superiority of the n-ary subgraph reasoning framework and the exceptional inductive ability of NS-HART. The source code of this paper has been made publicly available at https://github.com/yin-gz/Nary-Inductive-SubGraph. | Gongzhu Yin, Hongli Zhang, Yuchen Yang, Yi Luo |  |
|  |  [Annotation-guided Protein Design with Multi-Level Domain Alignment](https://doi.org/10.1145/3690624.3709199) |  | 0 | The core challenge of de novo protein design lies in creating proteins with specific functions or properties, guided by certain conditions. Current models explore to generate protein using structural and evolutionary guidance, which only provide indirect conditions concerning functions and properties. However, textual annotations of proteins, especially the annotations for protein domains, which directly describe the protein's high-level functionalities, properties, and their correlation with target amino acid sequences, remain unexplored in the context of protein design tasks. In this paper, we propose Protein-Annotation Alignment Generation, PAAG, a multi-modality protein design framework that integrates the textual annotations extracted from protein database for controllable generation in sequence space. Specifically, within a multi-level alignment module, PAAG can explicitly generate proteins containing specific domains conditioned on the corresponding domain annotations, and can even design novel proteins with flexible combinations of different kinds of annotations. Our experimental results underscore the superiority of the aligned protein representations from PAAG over 7 prediction tasks. Furthermore, PAAG demonstrates a significant increase in generation success rate (24.7 in zinc finger, and 54.3 to the existing model. We anticipate that PAAG will broaden the horizons of protein design by leveraging the knowledge from between textual annotation and proteins. | Chaohao Yuan, Songyou Li, Geyan Ye, Yikun Zhang, LongKai Huang, Wenbing Huang, Wei Liu, Jianhua Yao, Yu Rong | Renmin University of China; Peking University; Tsinghua University; Tencent AI Lab |
|  |  [Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph](https://doi.org/10.1145/3690624.3709187) |  | 0 | Large language models (LLMs) have demonstrated exceptional performance across a wide variety of domains. Nonetheless, generalist LLMs continue to fall short in reasoning tasks necessitating specialized knowledge. Prior investigations into specialized LLMs focused on domain-specific training, which entails substantial efforts in domain data acquisition and model parameter fine-tuning. To address these challenges, this paper proposes the Way-to-Specialist (WTS) framework, which synergizes retrieval-augmented generation with knowledge graphs (KGs) to enhance the specialized capability of LLMs in the absence of specialized training. In distinction to existing paradigms that merely utilize external knowledge from general KGs or static domain KGs to prompt LLM for enhanced domain-specific reasoning, WTS proposes an innovative "LLM↻KG" paradigm, which achieves bidirectional enhancement between specialized LLM and domain knowledge graph (DKG). The proposed paradigm encompasses two closely coupled components: the DKG-Augmented LLM and the LLM-Assisted DKG Evolution. The former retrieves question-relevant domain knowledge from DKG and uses it to prompt LLM to enhance the reasoning capability for domain-specific tasks; the latter leverages LLM to generate new domain knowledge from processed tasks and use it to evolve DKG. WTS closes the loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling continuous improvement in the domain specialization as it progressively answers and learns from domain-specific questions. We validate the performance of WTS on 6 datasets spanning 5 domains. The experimental results show that WTS surpasses the previous SOTA in 4 specialized domains and achieves a maximum performance improvement of 11.3 | Yutong Zhang, Lixing Chen, Shenghong Li, Nan Cao, Yang Shi, Jiaxin Ding, Zhe Qu, Pan Zhou, Yang Bai |  |
|  |  [Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting](https://doi.org/10.1145/3690624.3709210) |  | 0 | Time series forecasting always faces the challenge of concept drift, where data distributions evolve over time, leading to a decline in forecast model performance. Existing solutions are based on online learning, which continually organize recent time series observations as new training samples and update model parameters according to the forecasting feedback on recent data. However, they overlook a critical issue: obtaining ground-truth future values of each sample should be delayed until after the forecast horizon. This delay creates a temporal gap between the training samples and the test sample. Our empirical analysis reveals that the gap can introduce concept drift, causing forecast models to adapt to outdated concepts. In this paper, we present Proceed, a novel proactive model adaptation framework for online time series forecasting. Proceed first operates by estimating the concept drift between the recently used training samples and the current test sample. It then employs an adaptation generator to efficiently translate the estimated drift into parameter adjustments, proactively adapting the model to the test sample. To enhance the generalization capability of the framework, Proceed is trained on synthetic diverse concept drifts. We conduct extensive experiments on five real-world datasets across various forecast models. The empirical study demonstrates that our proposed Proceed brings more performance improvements than the state-of-the-art online learning methods, significantly facilitating forecast models' resilience against concept drifts. | Lifan Zhao, Yanyan Shen |  |
|  |  [Variational Graph Autoencoder for Heterogeneous Information Networks with Missing and Inaccurate Attributes](https://doi.org/10.1145/3690624.3709251) |  | 0 | Heterogeneous Information Networks (HINs), which consist of various types of nodes and edges, have recently demonstrated excellent performance in graph mining. However, most existing heterogeneous graph neural networks (HGNNs) ignore the problems of missing attributes, inaccurate attributes and scarce labels for nodes, which limits their expressiveness. In this paper, we propose a generative self-supervised model GraMI to address these issues simultaneously. Specifically, GraMI first initializes all the nodes in the graph with a low-dimensional representation matrix. After that, based on the variational graph autoencoder framework, GraMI learns both node-level and attribute-level embeddings in the encoder, which can provide fine-grained semantic information to construct node attributes. In the decoder, GraMI reconstructs both links and attributes. Instead of directly reconstructing raw features for attributed nodes, GraMI generates the initial low-dimensional representation matrix for all the nodes, based on which raw features of attributed nodes are further reconstructed to leverage accurate attributes. In this way, GraMI can not only complete informative features for non-attributed nodes, but rectify inaccurate ones for attributed nodes. Finally, we conduct extensive experiments to show the superiority of GraMI in tackling HINs with missing and inaccurate attributes. | Yige Zhao, Jianxiang Yu, Yao Cheng, Chengcheng Yu, Yiding Liu, Xiang Li, Shuaiqiang Wang |  |
|  |  [A Two-Stage Pretraining-Finetuning Framework for Treatment Effect Estimation with Unmeasured Confounding](https://doi.org/10.1145/3690624.3709161) |  | 0 | Estimating the conditional average treatment effect (CATE) from observational data plays a crucial role in areas such as e-commerce, healthcare, and economics. Existing studies mainly rely on the strong ignorability assumption that there are no unmeasured confounders, whose presence cannot be tested from observational data and can invalidate any causal conclusion. In contrast, data collected from randomized controlled trials (RCT) do not suffer from confounding, but are usually limited by a small sample size. In this paper, we propose a two-stage pretraining-finetuning (TSPF) framework using both large-scale observational data and small-scale RCT data to estimate the CATE in the presence of unmeasured confounding. In the first stage, a foundational representation of covariates is trained to estimate counterfactual outcomes through large-scale observational data. In the second stage, we propose to train an augmented representation of the covariates, which is concatenated to the foundational representation obtained in the first stage to adjust for the unmeasured confounding. To avoid overfitting caused by the small-scale RCT data in the second stage, we further propose a partial parameter initialization approach, rather than training a separate network. The superiority of our approach is validated on two public datasets with extensive experiments. The code is available at https://github.com/zhouchuanCN/KDD25-TSPF. | Chuan Zhou, Yaxuan Li, Chunyuan Zheng, Haiteng Zhang, Min Zhang, Haoxuan Li, Mingming Gong | Peking University, Beijing, China, and MBZUAI, Abu Dhabi, United Arab Emirates; East China Normal University, Shanghai, China, and MBZUAI, Abu Dhabi, United Arab Emirates; The University of Melbourne, Melbourne, VIC, Australia, and MBZUAI, Abu Dhabi, United Arab Emirates; Peking University, Beijing, China |
|  |  [HRSTORY: Historical News Review Based Online Story Discovery](https://doi.org/10.1145/3690624.3709198) |  | 0 | Story discovery on news streams can help people quickly find story from vast amounts of news, improving the efficiency of information acquisition. Recent online story discovery methods encode text topics and then cluster articles into stories based on similarity. However, the results obtained by these methods are one-time, and clustered news cannot adaptively update in a continuous news stream. Additionally, the inadequate quality of article encoding and the presence of noise data deteriorate the performance of story discovery. To this end, we propose HRSTORY for online story discovery on news streams, which employs a historical news review method to enable news to continuously adapt to the latest environment in the stream data and make corrections and updates. Furthermore, HRSTORY captures better article embeddings through modeling multi-layer relational dependencies within the text. By using sentence-level noise masking, HRSTORY improves the relevance of news article representation to core topics and reduces the interference of noise data. Experiments on real news datasets show that HRSTORY outperforms the state-of-the-art algorithms in unsupervised online story discovery performance. | Renjie Zhou, Haoran Ye, Jian Wan, Yong Liao | Zhejiang University of Science and Technology, Hangzhou, Zhejiang, China; University of Science and Technology of China, Hefei, Anhui, China |
|  |  [Contextual Generative Auction with Permutation-level Externalities for Online Advertising](https://doi.org/10.1145/3690624.3709313) |  | 0 | Online advertising has become a core revenue driver for the internet industry, with ad auctions playing a crucial role in ensuring platform revenue and advertiser incentives. Traditional auction mechanisms, like GSP, rely on the independent CTR assumption and fail to account for the influence of other displayed items, termed externalities. Recent advancements in learning-based auctions have enhanced the encoding of high-dimensional contextual features. However, existing methods are constrained by the "allocation-after-prediction" design paradigm, which models set-level externalities within candidate ads and fails to consider the sequential context of the final allocation, leading to suboptimal results. This paper introduces the Contextual Generative Auction (CGA), a novel framework that incorporates permutation-level externalities in multi-slot ad auctions. Built on the structure of our theoretically derived optimal solution, CGA decouples the optimization of allocation and payment. We construct an autoregressive generative model for allocation and reformulate the incentive compatibility (IC) constraint into minimizing ex-post regret that supports gradient computation, enabling end-to-end learning of the optimal payment rule. Extensive offline and online experiments demonstrate that CGA significantly enhances platform revenue and CTR compared to existing methods, while effectively approximating the optimal auction with nearly maximal revenue and minimal regret. | Ruitao Zhu, Yangsu Liu, Dagui Chen, Zhenjia Ma, Chufeng Shi, Zhenzhe Zheng, Jie Zhang, Jian Xu, Bo Zheng, Fan Wu |  |
|  |  [ForTune: Running Offline Scenarios to Estimate Impact on Business Metrics](https://doi.org/10.1145/3690624.3709431) |  | 0 | Making ideal decisions as a product leader in a web-facing company is extremely difficult. In addition to navigating the ambiguity of customer satisfaction and achieving business goals, one must also pave a path forward for ones' products and services to remain relevant, desirable, and profitable. Data and experimentation to test product hypotheses are key to informing product decisions. Online controlled experiments by A/B testing may provide the best data to support such decisions with high confidence, but can be time-consuming and expensive, especially when one wants to understand impact to key business metrics such as retention or long-term value. Offline experimentation allows one to rapidly iterate and test, but often cannot provide the same level of confidence, and cannot easily shine a light on impact on business metrics. We introduce a novel, lightweight, and flexible approach to investigating hypotheses, called scenario analysis, that aims to support product leaders' decisions using data about users and estimates of business metrics. Its strengths are that it can provide guidance on trade-offs that are incurred by growing or shifting consumption, estimate trends in long-term outcomes like retention and other important business metrics, and can generate hypotheses about relationships between metrics at scale. | Georges Dupret, Konstantin Sozinov, Carmen Barcena Gonzalez, Ziggy Zacks, Amber Yuan, Ben Carterette, Manuel Mai, Andrey Gatash, Gwo Liang Lien, Shubham Bansal, Roberto SanchisOjeda, Mounia Lalmas |  |
|  |  [TEMPER: Capturing Consistent and Fluctuating TEMPoral User Behaviour for EtheReum Phishing Scam Detection](https://doi.org/10.1145/3690624.3709399) |  | 0 | Phishing scams on the Ethereum network have become a serious threat, especially with the influx of new users into the cryptocurrency market. Current detection methods are mainly focused on long-term consistent transaction patterns with smooth temporal dynamics. However, these methods often struggle to differentiate between phishing and non-phishing users, whose behaviours may appear deceptively similar. Additionally, they face challenges such as network sparsity and data leakage, leading to significant performance limitations. To address these issues, we introduce TEMPER, a novel sequential learning framework designed to jointly capture the subtle distinctions between long- and short-term user behaviours and their correlations to provide more comprehensive insights. TEMPER effectively generates distinguishable user embeddings, enabling the accurate identification of phishing users. Unlike previous approaches, TEMPER mitigates data leakage through a novel sequential transaction sampling algorithm and addresses network sparsity with short-term temporal learning. Through extensive experimentation on three real-world Ethereum datasets, TEMPER demonstrates its efficacy by achieving a 3-4% improvement in the F1-Score compared to existing baseline models, representing a significant advancement in Ethereum phishing user detection. | Medhasree Ghosh, Chirag Dinesh Jain, Raju Halder, Joydeep Chandra | Computer Science and Engineering, University of California, San Diego, San Diego, USA; Computer Science and Engineering, Indian Institute of Technology, Patna, Patna, Bihar, India; Computer Science and Engineering, Indian Institute of Technology, Patna, Bihta, Bihar, India |
|  |  [TGDataset: Collecting and Exploring the Largest Telegram Channels Dataset](https://doi.org/10.1145/3690624.3709397) |  | 0 | Telegram is one of the most popular instant messaging apps in today's digital age. In addition to providing a private messaging service, Telegram, with its channels, represents a valid medium for rapidly broadcasting content to a large audience (COVID-19 announcements), but, unfortunately, also for disseminating radical ideologies and coordinating attacks (Capitol Hill riot). This paper presents the TGDataset, a new dataset that includes 120,979 Telegram channels and over 400 million messages, making it the largest collection of Telegram channels to the best of our knowledge. After a brief introduction to the data collection process, we analyze the languages spoken within our dataset and the topic covered by English channels. Finally, we discuss some use cases in which our dataset can be extremely useful to understand better the Telegram ecosystem, as well as to study the diffusion of questionable news. In addition to the raw dataset, we released the scripts we used to analyze the dataset and the list of channels belonging to the network of a new conspiracy theory called Sabmyk. | Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini |  |
|  |  [Session-Level Dynamic Ad Load Optimization using Offline Robust Reinforcement Learning](https://doi.org/10.1145/3690624.3709437) |  | 0 | Session-level dynamic ad load optimization aims to personalize the density and types of delivered advertisements in real time during a user's online session by dynamically balancing user experience quality and ad monetization. Traditional causal learning-based approaches struggle with key technical challenges, especially in handling confounding bias and distribution shifts. In this paper, we develop an offline deep Q-network (DQN)-based framework that effectively mitigates confounding bias in dynamic systems and demonstrates more than 80 baseline. Moreover, to improve the framework's robustness against unanticipated distribution shifts, we further enhance our framework with a novel offline robust dueling DQN approach. This approach achieves more stable rewards on multiple OpenAI-Gym datasets as perturbations increase, and provides an additional 5 Deployed across multiple production systems, our approach has achieved outsized topline gains. Post-launch online A/B tests have shown double-digit improvements in the engagement-ad score trade-off efficiency, significantly enhancing our platform's capability to serve both consumers and advertisers. | Tao Liu, Qi Xu, Wei Shi, Zhigang Hua, Shuang Yang |  |
|  |  [SSE: Multimodal Semantic Data Selection and Enrichment for Industrial-scale Data Assimilation](https://doi.org/10.1145/3690624.3709417) |  | 0 | In recent years, the data collected for artificial intelligence has grown to an unmanageable amount. Particularly within industrial applications, such as autonomous vehicles, model training computation budgets are being exceeded while model performance is saturating – and yet more data continues to pour in. To navigate the flood of data, we propose a framework to select the most semantically diverse and important dataset portion. Then, we further semantically enrich it by discovering meaningful new data from a massive unlabeled data pool. Importantly, we can provide explainability by leveraging foundation models to generate semantics for every data point. We quantitatively show that our Semantic Selection and Enrichment framework (SSE) can a) successfully maintain model performance with a smaller training dataset and b) improve model performance by enriching the smaller dataset without exceeding the original dataset size. Consequently, we demonstrate that semantic diversity is imperative for optimal data selection and model performance. | Maying Shen, Nadine Chang, Sifei Liu, José M. Álvarez |  |
|  |  [A Framework for Leveraging Partially-Labeled Data for Product Attribute-Value Identification](https://doi.org/10.1145/3690624.3709427) |  | 0 | In the e-commerce domain, the accurate extraction of attribute-value pairs (e.g., Brand: Apple) from product titles and user search queries is crucial for enhancing search and recommendation systems. A major challenge with neural models for this task is the lack of high-quality training data, as the annotations for attribute-value pairs in the available datasets are often incomplete. To address this, we introduce GenToC, a model designed for training directly with partially-labeled data, eliminating the necessity for a fully annotated dataset. GenToC employs a marker-augmented generative model to identify potential attributes, followed by a token classification model that determines the associated values for each attribute. GenToC outperforms existing state-of-the-art models, exhibiting upto 56.3% increase in the number of accurate extractions. Furthermore, we utilize GenToC to regenerate the training dataset to expand attribute-value annotations. This bootstrapping substantially improves the data quality for training other standard NER models, which are typically faster but less capable in handling partially-labeled data, enabling them to achieve comparable performance to GenToC. Our results demonstrate GenToC's unique ability to learn from a limited set of partially-labeled data and improve the training of more efficient models, advancing the automated extraction of attribute-value pairs. Finally, our model has been successfully integrated into IndiaMART, India's largest B2B e-commerce platform, achieving a significant increase of 20.2% in the number of correctly identified attribute-value pairs over the existing deployed system while achieving a high precision of 89.5%. | D. Subhalingam, Keshav Kolluru, Mausam, Saurabh Singal |  |
|  |  [Instruction Semantics Enhanced Dual-Flow Graph Model for GPU Error Resilience Prediction](https://doi.org/10.1145/3690624.3709424) |  | 0 | As GPUs are widely deployed in High Performance Computing systems, it is critical to ensure that these systems can perform reliably. To improve system reliability, researchers estimate the error resilience of GPU programs by understanding resilience characteristics or modeling error propagation. However, features indicative of resilience rely on manual extraction from simulations of numerous faults, and error propagation analysis cannot target fine-grained bit-level faults. To address those problems, this paper introduces a novel paradigm, namely InstrDGM, for efficiently predicting GPU error resilience. Specifically, InstrDGM first fine-tunes a large language model using extensive sequences of GPU assembly instructions for extracting the semantic representation of instructions automatically. Meanwhile, we consider the propagation of bit-level faults during instruction execution and data transfer processes, and leverage graph neural networks to capture their distinct error propagation patterns. Then, the fault embeddings extracted from these error propagation patterns are integrated for error resilience prediction. Additionally, this paper releases a new dataset for GPU error resilience assessment, containing 1.2 million fault samples. Finally, extensive experiments show that InstrDGM significantly outperforms existing methods. | Pengfei Yu, Jingjing Gu, Dazhong Shen, Xin Dong, Yang Liu, Hui Xiong | Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Nanjing University of Aeronautics and Astronautics, Nanjing, China |
|  |  [Prices Do Matter: Modeling Price Competitiveness for Online Hotel Industry](https://doi.org/10.1145/3690624.3709420) |  | 0 | Broad adoption of Online Travel Platforms (OTPs) has led to increasing interest in accurately predicting users' hotel purchase behavior, with price being a key influencer in user decision-making and receiving significant focus. In examining the hotel purchasing process, we identify a pervasive trend that users make extensive price comparisons before making decisions. Existing research primarily focuses on a hotel's own price, neglecting the complex dynamics of market-driven price competition. In this paper, we propose the concept of Marketplace-oriented Hotel Price Competitiveness (MHPC) to model a hotel's pricing competitiveness within the marketplace. Being independent of specific user preferences, MHPC can be applied to and improve various downstream operations in the online hotel industry, such as hotel ranking and pricing, ultimately benefiting hoteliers, users, and OTPs. Furthermore, a novel Hotel Price Competitiveness-aware Purchase Prediction Model (HP3M) is constructed by incorporating MHPC and demand dynamics into a multi-task learning framework, featuring three distinct submodules to encompass the tri-dimensional facets of MHPC. Extensive offline and online experiments demonstrate HP3M's effectiveness in predicting hotel purchase probability and enhancing the performance of hotel ranking and pricing compared to the state-of-the-art methods. HP3M has been fully deployed on Fliggy, a leading OTP in China, serving thousands of hoteliers and tens of millions of users. | Ruitao Zhu, Wendong Xiao, Yao Yu, Yangsu Liu, Zhenzhe Zheng, Shuqi Zhang, Dong Li, Fan Wu | Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China |
|  |  [Hypergraph Motif Representation Learning](https://doi.org/10.1145/3690624.3709274) |  | 0 | Hypergraphs have emerged as a powerful tool for representing high-order connections in real-world complex systems. Similar to graphs, local structural patterns in hypergraphs, known as high-order motifs (h-motifs), play a crucial role in network dynamics and serve as fundamental building blocks across various domains. For this reason, predicting h-motifs can be highly beneficial in different fields. In this paper, we aim to advance our understanding of such complex high-order dynamics by introducing and formalizing the problem of h-motifs prediction. To address this task, we propose a novel solution that leverages both high-order and pairwise information by combining hypergraph and graph convolutions to capture hyperedges correlation within h-motifs, along with an innovative negative sampling approach designed to generate close-to-positive negative samples. To evaluate the effectiveness of our approach, we defined several baselines inspired by existing literature on hyperedge prediction methods. Our extensive experimental assessments demonstrate that our approach consistently outperforms all the considered baselines, showcasing its superior performance and robustness in predicting h-motifs. | Alessia Antelmi, Gennaro Cordasco, Daniele De Vinco, Valerio Di Pasquale, Mirko Polato, Carmine Spagnuolo | Università degli Studi di Torino, Turin, Italy; Università della Campania "Luigi Vanvitelli", Caserta, Italy; Università degli Studi di Salerno, Fisciano, Italy |
|  |  [ResMoE: Space-efficient Compression of Mixture of Experts LLMs via Residual Restoration](https://doi.org/10.1145/3690624.3709196) |  | 0 | Mixture-of-Experts (MoE) Transformer, the backbone architecture of multiple phenomenal language models, leverages sparsity by activating only a fraction of model parameters for each input token. The sparse structure, while allowing constant time costs, results in space inefficiency: we still need to load all the model parameters during inference. We introduce ResMoE, an innovative MoE approximation framework that utilizes Wasserstein barycenter to extract a common expert (barycenter expert) and approximate the residuals between this barycenter expert and the original ones. ResMoE enhances the space efficiency for inference of large-scale MoE Transformers in a one-shot and data-agnostic manner without retraining while maintaining minimal accuracy loss, thereby paving the way for broader accessibility to large language models. We demonstrate the effectiveness of ResMoE through extensive experiments on Switch Transformer, Mixtral, and DeepSeekMoE models. The results show that ResMoE can reduce the number of parameters in an expert by up to 75 comparable performance. The code is available at https://github.com/iDEA-iSAIL-Lab-UIUC/ResMoE. | Mengting Ai, Tianxin Wei, Yifan Chen, Zhichen Zeng, Ritchie Zhao, Girish Varatkar, Bita Darvish Rouhani, Xianfeng Tang, Hanghang Tong, Jingrui He |  |
|  |  [Fast and Effective GNN Training through Sequences of Random Path Graphs](https://doi.org/10.1145/3690624.3709301) |  | 0 | We present GERN, a novel scalable framework for training GNNs in node classification tasks, based on effective resistance, a standard tool in spectral graph theory. Our method progressively refines the GNN weights on a sequence of random spanning trees suitably transformed into path graphs which, despite their simplicity, are shown to retain essential topological and node information of the original input graph. The sparse nature of these path graphs substantially lightens the computational burden of GNN training. This not only enhances scalability but also improves accuracy in subsequent test phases, especially under small training set regimes, which are of great practical importance, as in many real-world scenarios labels may be hard to obtain. In these settings, our framework yields very good results as it effectively counters the training deterioration caused by overfitting when the training set is small. Our method also addresses common issues like over-squashing and over-smoothing while avoiding under-reaching phenomena. Although our framework is flexible and can be deployed in several types of GNNs, in this paper we focus on graph convolutional networks and carry out an extensive experimental investigation on a number of real-world graph benchmarks, where we achieve simultaneous improvement of training speed and test accuracy over a wide pool of representative baselines. | Francesco Bonchi, Claudio Gentile, Francesco Paolo Nerini, André Panisson, Fabio Vitale |  |
|  |  [Correlation-Aware Graph Convolutional Networks for Multi-Label Node Classification](https://doi.org/10.1145/3690624.3709197) |  | 0 | Multi-label node classification is an important yet under-explored domain in graph mining as many real-world nodes belong to multiple categories rather than just a single one. Although a few efforts have been made by utilizing Graph Convolution Networks (GCNs) to learn node representations and model correlations between multiple labels in the embedding space, they still suffer from the ambiguous feature and ambiguous topology induced by multiple labels, which reduces the credibility of the messages delivered in graphs and overlooks the label correlations on graph data. Therefore, it is crucial to reduce the ambiguity and empower the GCNs for accurate classification. However, this is quite challenging due to the requirement of retaining the distinctiveness of each label while fully harnessing the correlation between labels simultaneously. To address these issues, in this paper, we propose a Correlation-aware Graph Convolutional Network (CorGCN) for multi-label node classification. By introducing a novel Correlation-Aware Graph Decomposition module, CorGCN can learn a graph that contains rich label-correlated information for each label. It then employs a Correlation-Enhanced Graph Convolution to model the relationships between labels during message passing to further bolster the classification process. Extensive experiments on five datasets demonstrate the effectiveness of our proposed CorGCN. | Yuanchen Bei, Weizhi Chen, Hao Chen, Sheng Zhou, Carl Ji Yang, Jiapei Fan, Longtao Huang, Jiajun Bu |  |
|  |  [NodeImport: Imbalanced Node Classification with Node Importance Assessment](https://doi.org/10.1145/3690624.3709215) |  | 0 | In real-world applications, node classification on graphs often faces the challenge of class imbalance, where majority classes dominate training, resulting in biased model performance. Traditional Graph Neural Networks (GNNs) often struggle in such scenarios, as they tend to overfit to majority classes while underrepresenting minority classes. Existing solutions, which either prioritize nodes based on class size or synthesize new nodes for minority classes, often fall short of effectively addressing this imbalance issue. This paper introduces a novel approach to class-imbalanced node classification by utilizing a balanced meta-set for importance measurement, where a training node is considered significant if it enhances model performance under an unbiased setting. Our method identifies important nodes that can counteract class imbalance and utilizes them for model training, allowing for fine-grained and dynamic node selection throughout the training process. We theoretically derive a formula to directly assess node importance, reducing computational overhead and providing an intuitive threshold for node selection. Guided by this metric, we develop a novel framework that filters valuable labeled, unlabeled, and synthetic nodes that enhance model performance in an unbiased context. A key advantage of this framework is its separation of the synthetic node generation process from the filtering process, ensuring compatibility with various node generation techniques. Furthermore, we introduce a strategy to construct a high-quality meta-set that closely approximates the overall feature distribution, ensuring robust representation of each class. We evaluate our framework, NodeImport, across multiple benchmark datasets using popular GNN architectures, demonstrating its superiority over state-of-the-art baselines. Our results highlight the flexibility and effectiveness of the framework in mitigating class imbalance, leading to improved node classification outcomes. The source code is available at https://github.com/NanChanNN/NodeImport. | Nan Chen, Zemin Liu, Bryan Hooi, Bingsheng He, Jun Hu, Jia Chen | Johns Hopkins University, Baltimore, Maryland, USA; Grabtaxi Holdings Pte Ltd, Singapore, Singapore; Zhejiang University, Hangzhou, Zhejiang, China; National University of Singapore, Singapore, Singapore |
|  |  [How to use Graph Data in the Wild to Help Graph Anomaly Detection?](https://doi.org/10.1145/3690624.3709320) |  | 0 | In recent years, graph anomaly detection has found extensive applications in various domains such as social, financial, and communication networks. However, anomalies in graph-structured data present unique challenges, including label scarcity, ill-defined anomalies, and varying anomaly types, making supervised or semi-supervised methods unreliable. Researchers often adopt unsupervised approaches to address these challenges, assuming that anomalies deviate significantly from the normal data distribution. Yet, when the available data is insufficient, capturing the normal distribution accurately and comprehensively becomes difficult. To overcome this limitation, we propose to utilize external graph data (i.e., graph data in the wild) to help anomaly detection tasks. This naturally raises the question: How can we use external data to help graph anomaly detection tasks? To answer this question, we propose a framework called Wild-GAD. It is built upon a unified database, UniWildGraph, which comprises a large and diverse collection of graph data with broad domain coverage, ample data volume, and a unified feature space. Further, we develop selection criteria based on representativity and diversity to identify the most suitable external data for anomaly detection task. Extensive experiments on six real-world datasets demonstrate the effectiveness of Wild-GAD. Compared to the baseline methods, our framework has an average 18 improvement over the best-competing methods. | Yuxuan Cao, Jiarong Xu, Chen Zhao, Jiaan Wang, Carl Ji Yang, Chunping Wang, Yang Yang |  |
|  |  [Probabilistic Hypergraph Recurrent Neural Networks for Time-series Forecasting](https://doi.org/10.1145/3690624.3709202) |  | 0 | Leveraging graph structures for time-series forecasting has garnered significant attention due to their effective relationship modeling between nodes and their associated time-series. However, in scenarios entities communicate in a broadcasting manner, graph models fall short of pairwise modeling. Hypergraph models address this by capturing beyond-pairwise interactions among node time-series. Nevertheless, most hypergraph models overlook the dynamics between nodes and their incident hyperedges, assuming constant node-hyperedge connections. In this paper, we introduce a novel model, Probabilistic Hypergraph Recurrent Neural Networks (PHRNN), which leverages node-hyperedge dynamics for accurate time-series forecasting. PHRNN associates each time-series with a node and models node interactions on a hypergraph, capturing beyond-pairwise interactions. Moreover, PHRNN learns a probabilistic hypergraph in which node-hyperedge relations are modeled as probabilistic distributions instead of fixed values, capturing dynamic node-hyperedge relations. PHRNN further integrates a prior knowledge KNN hypergraph as regularization when learning the probabilistic hypergraph structure. To the best of our knowledge, PHRNN is the first time-series forecasting model that incorporates hypergraph modeling and probabilistic relationship modeling. Forecasting results from extensive experiments show that PHRNN outperforms state-of-the-art graph and hypergraph baselines on real-world datasets. | Hongjie Chen, Ryan A. Rossi, Sungchul Kim, Kanak Mahadik, Hoda Eldardiry | Dolby Laboratories, Atlanta, GA, USA; Adobe Research, San Jose, CA, USA; Virginia Tech, Blacksburg, VA, USA |
|  |  [Locally Balancing Signed Graphs](https://doi.org/10.1145/3690624.3709342) |  | 0 | Signed graphs capture both positive and negative relationships between entities, with balance being a fundamental concept. In these graphs, a vertex is considered balanced if all cycles it belongs to contain an even number of negative edges. On the other hand, unbalanced vertices often experience cognitive dissonance and emotional disturbance, motivating efforts to modify the graph to achieve balance for these vertices. Yet, most existing research emphasizes global balance, focusing on lengthy cycles that represent distant interactions. In contrast, this paper shifts the focus to local balance, where a vertex is deemed balanced when the triangles (length-three cycles) it participates in are positive, reflecting more immediate relationships. Building on this, we introduce the Locally Balancing Signed Graph (LBS) problem, which aims to maximize the number of locally balanced vertices through graph modification. Despite the NP-hard nature of the LBS problem and the absence of properties such as monotonicity and submodularity, our novel greedy method effectively addresses these challenges. We further enhance our method with dynamic computation and pruning techniques. Extensive experiments show the efficacy of our greedy method in solving the LBS problem and underscore the substantial runtime reductions achieved through our optimization techniques. | Weizhe Chen, Wentao Li, Min Gao, Dong Wen, Maolin Cai, Wei Wang | University of New South Wales, Sydney, NSW, Australia; Chongqing University, Chongqing, China |
|  |  [CSPI-MT: Calibrated Safe Policy Improvement with Multiple Testing for Threshold Policies](https://doi.org/10.1145/3690624.3709176) |  | 0 | When modifying existing policies in high-risk settings, it is often necessary to ensure with high certainty that the newly proposed policy improves upon a baseline, such as the status quo. In this work, we consider the problem of safe policy improvement, where one only adopts a new policy if it is deemed to be better than the specified baseline with at least pre-specified probability. We focus on threshold policies, a ubiquitous class of policies with applications in economics, healthcare, and digital advertising. Existing methods rely on potentially underpowered safety checks and limit the opportunities for finding safe improvements, so too often they must revert to the baseline to maintain safety. We overcome these issues by leveraging the most powerful safety test in the asymptotic regime and allowing for multiple candidates to be tested for improvement over the baseline. We show that in adversarial settings, our approach controls the rate of adopting a policy worse than the baseline to the pre-specified error level, even in moderate sample sizes. We present CSPI and CSPI-MT, two novel heuristics for selecting cutoff(s) to maximize the policy improvement from baseline. We demonstrate through both synthetic and external datasets that our approaches improve both the detection rates of safe policies and the realized improvement, particularly under stringent safety requirements and low signal-to-noise conditions. | Brian Cho, AnaRoxana Pop, Kyra Gan, Sam CorbettDavies, Israel Nir, Ariel Evnine, Nathan Kallus |  |
|  |  [Revisiting Synthetic Human Trajectories: Imitative Generation and Benchmarks Beyond Datasaurus](https://doi.org/10.1145/3690624.3709180) |  | 0 | Human trajectory data, which plays a crucial role in various applications such as crowd management and epidemic prevention, is challenging to obtain due to practical constraints and privacy concerns. In this context, synthetic human trajectory data is generated to simulate as close as possible to real-world human trajectories, often under summary statistics and distributional similarities. However, the complexity of human mobility patterns is oversimplified by these similarities (a.k.a. “Datasaurus”), resulting in intrinsic biases in both generative model design and benchmarks of the generated trajectories. Against this background, we propose MIRAGE, a huMan-Imitative tRAjectory GenErative model designed as a neural Temporal Point Process integrating an Exploration and Preferential Return model. It imitates the human decision-making process in trajectory generation, rather than fitting any specific statistical distributions as traditional methods do, thus avoiding the Datasaurus issue. Moreover, we also propose a comprehensive task-based evaluation protocol beyond Datasaurus to systematically benchmark trajectory generative models on four typical downstream tasks, integrating multiple techniques and evaluation metrics for each task, to comprehensively assess the ultimate utility of the generated trajectories. We conduct a thorough evaluation of MIRAGE on three real-world user trajectory datasets against a sizeable collection of baselines. Results show that compared to the best baselines, MIRAGE-generated trajectory data not only achieves the best statistical and distributional similarities with 59.0-71.5 also yields the best performance in the task-based evaluation with 10.9-33.4 improvement. | Bangchao Deng, Xin Jing, Tianyue Yang, Bingqing Qu, Dingqi Yang, Philippe CudréMauroux |  |
|  |  [Stabilizing Modality Gap & Lowering Gradient Norms Improve Zero-Shot Adversarial Robustness of VLMs](https://doi.org/10.1145/3690624.3709296) |  | 0 | Contemporary Vision-Language Models (VLMs) such as CLIP offer an attractive zero-shot classification functionality facilitated by large-scale vision-language pre-training. However, they remain vulnerable to adversarial attacks, a critical security threat in realistic deployment. Adversarially robust fine-tuning provides generalizable robustness on new datasets while preserving natural performance by fine-tuning the pre-trained models. Fine-tuning robust CLIP typically relies on adversaries generated solely from the vision branch. However, this singular focus on the vision modality, coupled with static text prompts used as fixed category prototypes, limits the robustness achieved through dual-modality fine-tuning. We observe for CLIP fine-tuning that zero-shot adversarial robustness improves when we (i) stabilize the modality gap (a phenomenon where image and text features occupy different feature space regions) and (ii) lower/stabilize gradient norms. Both these steps enjoy further improvement of robustness if one fine-tunes with both visual and text adversaries. For both modalities, we leverage (i) the maximization of an effective rank of features and (ii) noise modulation of features. We show that maximizing the effective rank helps lower and stabilize the modality gap over adversaries with varying perturbation radii. The noise modulation of features, achieved by the so-called count sketching, lowers/stabilizes gradient norms. We outperform the state of the art on 15 datasets. We provide the first insights into the effects of modality gap & gradient norms in VLM fine-tuning. | Junhao Dong, Piotr Koniusz, Xinghua Qu, YewSoon Ong | Data61, CSIRO, Canberra, ACT, Australia; Bytedance, Singapore, Singapore |
|  |  [Conditional Generative Modeling for High-dimensional Marked Temporal Point Processes](https://doi.org/10.1145/3690624.3709258) |  | 0 | Point processes offer a versatile framework for sequential event modeling. However, the computational challenges and constrained representational power of the existing point process models have impeded their potential for wider applications. This limitation becomes especially pronounced when dealing with event data that is associated with multi-dimensional or high-dimensional marks such as texts or images. To address this challenge, this study proposes a novel event-generation framework for modeling point processes with high-dimensional marks. We aim to capture the distribution of events without explicitly specifying the conditional intensity or probability density function. Instead, we use a conditional generator that takes the history of events as input and generates the high-quality subsequent event that is likely to occur given the prior observations. The proposed framework offers a host of benefits, including considerable representational power to capture intricate dynamics in multi- or even high-dimensional event space, as well as exceptional efficiency in learning the model and generating samples. Our numerical results demonstrate superior performance compared to other state-of-the-art baselines. | Zheng Dong, Zekai Fan, Shixiang Zhu | Georgia Institute of Technology; Carnegie Mellon University |
|  |  [The k-Trine Cohesive Subgraph and Its Efficient Algorithms](https://doi.org/10.1145/3690624.3709174) |  | 0 | In this paper, we introduce and study a novel cohesive subgraph model, named k-trine, to address the defects in the classical k-core and k-truss models. Our analysis shows that the k-trine is a more feasible model for capturing cohesive subgraphs by containing the strongly connected vertices. We analyze the theoretical properties of k-trine and propose efficient algorithms to compute the k-trine. Particularly, we design batch processing algorithms to update the decomposition of k-trine against highly dynamic graphs. Extensive experiments on real-world networks validate the effectiveness of the k-trine model and the efficiency of our algorithms. | Jinyu Duan, Haicheng Guo, Fan Zhang, Kai Wang, Zhengping Qian, Zhihong Tian | Antai College of Economics and Management, Shanghai Jiao Tong University, Shanghai, China; CIAT & Huangpu Research School, Guangzhou University, Guangzhou, Guangdong, China; Alibaba Cloud, Alibaba Group, Hangzhou, Zhejiang, China |
|  |  [Bi-Dynamic Graph ODE for Opinion Evolution](https://doi.org/10.1145/3690624.3709297) |  | 0 | Modeling opinion dynamics in social networks has been the focus of multiple disciplines in recent decades. Previous studies have often modeled the opinion dynamics as a discrete and homogeneous process, neglecting its continuous and complex nature. To fill this gap, we propose a Bi-Dynamics Graph Ordinary Differential Equation (BDG-ODE) framework, which models complex opinion dynamics as the result of two dynamical processes: the evolution of positive and negative opinions. The proposed model incorporates a dual opinion encoder that processes positive and negative opinions independently. Furthermore, the temporal opinion evolution is modeled through bidirectional graph ordinary differential equations, which allows the model to capture the changes in opinion in continuous time. We introduce an opinion synthesis decoder that effectively maps the evolved representations from the latent space back to the opinion space. Extensive experiments conducted on six datasets with varying characteristics highlight the superiority of BDG-ODE in forecasting opinion evolution within social networks. It achieved an average accuracy improvement of 23.16%, an average enhancement of 29.46% in the F1 score, and an average mean square error of difference improvement of 90. 30%, and an average correlation coefficient improvement of 45.93%, significantly outperforming eight state-of-the-art models. The code for reproduction is available: https://github.com/tsinghua-fib-lab/Bi-Dynamic-Graph-ODE-for-Opinion-Evolution. | Bowen Duan, Henggang Deng, Jinghua Piao, Huandong Wang, Yue Wang | Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China |
|  |  [IN-Flow: Instance Normalization Flow for Non-stationary Time Series Forecasting](https://doi.org/10.1145/3690624.3709260) |  | 0 | Due to the non-stationarity of time series, the distribution shift problem largely hinders the performance of time series forecasting. Existing solutions either rely on using certain statistics to specify the shift, or developing specific mechanisms for certain network architectures. However, the former would fail for the unknown shift beyond simple statistics, while the latter has limited compatibility on different forecasting models. To overcome these problems, we first propose a decoupled formulation for time series forecasting, with no reliance on fixed statistics and no restriction on forecasting architectures. This formulation regards the removing-shift procedure as a special transformation between a raw distribution and a desired target distribution and separates it from the forecasting. Such a formulation is further formalized into a bi-level optimization problem, to enable the joint learning of the transformation (outer loop) and forecasting (inner loop). Moreover, the special requirements of expressiveness and bi-direction for the transformation motivate us to propose instance normalization flow (IN-Flow), a novel invertible network for time series transformation. Different from the classic "normalizing flow" models, IN-Flow does not aim for normalizing input to the prior distribution (e.g., Gaussian distribution) for generation, but creatively transforms time series distribution by stacking normalization layers and flow-based invertible networks, which is thus named "normalization" flow. Finally, we have conducted extensive experiments on both synthetic data and real-world data, which demonstrate the superiority of our method. | Wei Fan, Shun Zheng, Pengyang Wang, Rui Xie, Kun Yi, Qi Zhang, Jiang Bian, Yanjie Fu |  |
|  |  [Dynamic Localisation of Spatial-Temporal Graph Neural Network](https://doi.org/10.1145/3690624.3709331) |  | 0 | Spatial-temporal data, fundamental to many intelligent applications, reveals dependencies indicating causal links between present measurements at specific locations and historical data at the same or other locations. Within this context, adaptive spatial-temporal graph neural networks (ASTGNNs) have emerged as valuable tools for modelling these dependencies, especially through a data-driven approach rather than pre-defined spatial graphs. While this approach offers higher accuracy, it presents increased computational demands. Addressing this challenge, this paper delves into the concept of localisation within ASTGNNs, introducing an innovative perspective that spatial dependencies should be dynamically evolving over time. We introduce DynAGS, a localised ASTGNN framework aimed at maximising efficiency and accuracy in distributed deployment. This framework integrates dynamic localisation, time-evolving spatial graphs, and personalised localisation, all orchestrated around the Dynamic Graph Generator, a light-weighted central module leveraging cross attention. The central module can integrate historical information in a node-independent manner to enhance the feature representation of nodes at the current moment. This improved feature representation is then used to generate a dynamic sparse graph without the need for costly data exchanges, and it supports personalised localisation. Performance assessments across two core ASTGNN architectures and nine real-world datasets from various applications reveal that DynAGS outshines current benchmarks, underscoring that the dynamic modelling of spatial dependencies can drastically improve model expressibility, flexibility, and system efficiency, especially in distributed settings. | Wenying Duan, Shujun Guo, Zimu Zhou, Wei Huang, Hong Rao, Xiaoxi He |  |
|  |  [FABind+: Enhancing Molecular Docking through Improved Pocket Prediction and Pose Generation](https://doi.org/10.1145/3690624.3709253) |  | 0 | Molecular docking is a pivotal process in drug discovery. While traditional techniques rely on extensive sampling and simulation governed by physical principles, these methods are often slow and costly. The advent of deep learning-based approaches has shown significant promise, offering increases in both accuracy and efficiency. Building upon the foundational work of FABind, a model designed with a focus on speed and accuracy, we present FABind+, an enhanced iteration that largely boosts the performance of its predecessor. We identify pocket prediction as a critical bottleneck in molecular docking and propose a novel methodology that significantly refines pocket prediction, thereby streamlining the docking process. Furthermore, we introduce modifications to the docking module to enhance its pose generation capabilities. In an effort to bridge the gap with conventional sampling/generative methods, we incorporate a simple yet effective sampling technique coupled with a confidence model, requiring only minor adjustments to the regression framework of FABind. Experimental results and analysis reveal that FABind+ remarkably outperforms the original FABind, achieves competitive state-of-the-art performance, and delivers insightful modeling strategies. This demonstrates FABind+ represents a substantial step forward in molecular docking and drug discovery. Our code is in https://github.com/QizhiPei/FABind. | Kaiyuan Gao, Qizhi Pei, Gongbo Zhang, Jinhua Zhu, Kun He, Lijun Wu |  |
|  |  [Wedjat: Detecting Sophisticated Evasion Attacks via Real-time Causal Analysis](https://doi.org/10.1145/3690624.3709218) |  | 0 | Traffic encryption has been widely adopted to protect the confidentiality and integrity of Internet traffic. However, attackers can also abuse such mechanism to deliver malicious traffic. Particularly, existing methods detecting encrypted malicious traffic are not robust against evasion attacks that manipulate traffic to obfuscate traffic features. Robust detection against evasion attacks remains an open problem. To the end, we develop Wedjat, which utilizes a causal network to model benign packet interactions among relevant flows, such that it recognizes abnormal causality that represents malicious traffic and disrupted causality incurred by evasion attacks. We extensively evaluate Wedjat with millions of flows collected from a real-world enterprise. The experimental results demonstrate that Wedjat achieves an accuracy of 0.957 F1-score when detecting various advanced attacks. Notably, five sophisticated evasion attacks, which have successfully evaded all existing methods, are accurately detected by Wedjat with over 0.915 F1. It demonstrates that Wedjat achieves exceptional robustness against evasions. Meanwhile, Wed- jat maintains an outstanding detection latency, i.e., it can predict each packet in less than 0.125 seconds. | Li Gao, Chuanpu Fu, Xinhao Deng, Ke Xu, Qi Li | Tsinghua University, Bejing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China & Zhongguancun Lab, Beijing, China; Tsinghua University, BeiJing, China & Zhongguancun Lab, Beijing, China |
|  |  [Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor](https://doi.org/10.1145/3690624.3709172) |  | 0 | Programming Knowledge Tracking (PKT) aims to dynamically diagnose learners' mastery levels of programming knowledge based on their coding activities, facilitating more effective and personalized programming education. However, current PKT studies primarily focus on the implicit relationship between code content and knowledge assessment, often overlooking two types of noise signals in long-term programming activities: unwanted signals from unrelated submissions and weak signals from minor modifications. This practical challenge significantly limits model performance and application. To address this issue, we propose Coda, a Code graph-based tuning adaptor designed to enhance existing PKT models by identifying and mitigating the impact of noise. Specifically, Coda first transforms the loose code sequences submitted by each learner into a compact code graph. By leveraging this code graph, unwanted signals can be identified from a semantic similarity perspective. We then apply a cluster-aware GCN to the code graph, which improves the discrimination of weak signals and enables their clustering for identification. Finally, a lightweight yet effective adaptor is incorporated into the PKT task through optimization with two noise feature-based constraints and a navigational regularization term, to correct knowledge states affected by noise. It is worth mentioning that the Coda framework is model-agnostic and can be adapted to most existing PKT solutions. Extensive experimental results on four real-world datasets demonstrate that Coda effectively performs the PKT task in the presence of noisy programming records, outperforming typical baselines. | Weibo Gao, Qi Liu, Rui Li, Yuze Zhao, Hao Wang, Linan Yue, Fangzhou Yao, Zheng Zhang |  |
|  |  [Benchmarking Fraud Detectors on Private Graph Data](https://doi.org/10.1145/3690624.3709170) |  | 0 | We introduce the novel problem of benchmarking fraud detectors on private graph-structured data. Currently, many types of fraud are managed in part by automated detection algorithms that operate over graphs. We consider the scenario where a data holder wishes to outsource development of fraud detectors to third parties (e.g., vendors or researchers). The third parties submit their fraud detectors to the data holder, who evaluates these algorithms on a private dataset and then publicly communicates the results. We propose a realistic privacy attack on this system that allows an adversary to de-anonymize individuals' data based only on the evaluation results. In simulations of a privacy-sensitive benchmark for facial recognition algorithms by the National Institute of Standards and Technology (NIST), our attack achieves near perfect accuracy in identifying whether individuals' data is present in a private dataset, with a True Positive Rate of 0.98 at a False Positive Rate of 0.00. We then study how to benchmark algorithms while satisfying a formal differential privacy (DP) guarantee. We empirically evaluate two classes of solutions: subsample-and-aggregate and DP synthetic graph data. We demonstrate through extensive experiments that current approaches do not provide utility when guaranteeing DP. Our results indicate that the error arising from DP trades off between bias from distorting graph structure and variance from adding random noise. Current methods lie on different points along this bias-variance trade-off, but more complex methods tend to require high-variance noise addition, undermining utility. | Alexander Goldberg, Giulia Fanti, Nihar B. Shah, Steven Wu |  |
|  |  [Detecting Interpretable Subgroup Drifts](https://doi.org/10.1145/3690624.3709259) |  | 0 | The ability to detect and adapt to changes in data distributions is crucial to maintain the accuracy and reliability of machine learning models. Detection is generally approached by observing the drift of model performance from a global point of view. However, drifts occurring in (fine-grained) data subgroups may go unnoticed when monitoring global drift. We take a different perspective, and introduce methods for observing drift at the finer granularity of subgroups. Relevant data subgroups are identified during training and monitored efficiently throughout the model's life. Performance drifts in any subgroup are detected, quantified and characterized so as to provide an interpretable summary of the model behavior over time. Experimental results confirm that our subgroup-level drift analysis identifies drifts that do not show at the (coarser) global dataset level. The proposed approach provides a valuable tool for monitoring model performance in dynamic real-world applications, offering insights into the evolving nature of data and ultimately contributing to more robust and adaptive models. | Flavio Giobergia, Eliana Pastor, Luca de Alfaro, Elena Baralis |  |
|  |  [Augmented Contrastive Clustering with Uncertainty-Aware Prototyping for Time Series Test Time Adaptation](https://doi.org/10.1145/3690624.3709239) |  | 0 | Test-time adaptation aims to adapt pre-trained deep neural networks using solely online unlabelled test data during inference. Although TTA has shown promise in visual applications, its potential in time series contexts remains largely unexplored. Existing TTA methods, originally designed for visual tasks, may not effectively handle the complex temporal dynamics of real-world time series data, resulting in suboptimal adaptation performance. To address this gap, we propose Augmented Contrastive Clustering with Uncertainty-aware Prototyping (ACCUP), a straightforward yet effective TTA method for time series data. Initially, our approach employs augmentation ensemble on the time series data to capture diverse temporal information and variations, incorporating uncertainty-aware prototypes to distill essential characteristics. Additionally, we introduce an entropy comparison scheme to selectively acquire more confident predictions, enhancing the reliability of pseudo labels. Furthermore, we utilize augmented contrastive clustering to enhance feature discriminability and mitigate error accumulation from noisy pseudo labels, promoting cohesive clustering within the same class while facilitating clear separation between different classes. Extensive experiments conducted on three real-world time series datasets and an additional visual dataset demonstrate the effectiveness and generalization potential of the proposed method, advancing the underexplored realm of TTA for time series data. | Peiliang Gong, Mohamed Ragab, Min Wu, Zhenghua Chen, Yongyi Su, Xiaoli Li, Daoqiang Zhang |  |
|  |  [Revisiting Cognition in Neural Cognitive Diagnosis](https://doi.org/10.1145/3690624.3709319) |  | 0 | Cognitive diagnosis is a fundamental task in intelligent education, aiming to measure students' proficiency on knowledge concepts based on practice data. Traditional methods utilize a broadly-defined latent trait θ to represent knowledge proficiency with some cognitive factors like skill or ability. However, existing methods simplify this to a narrowly-defined latent trait θ, which focuses only on knowledge or treats these cognitive factors as implicit features inferred from data. They fail to explicitly model these cognitive factors, resulting in limited performance and interpretability. To this end, we revisit essence of cognition in Educational Psychology Theory and propose a novel Cognition-aware Cognitive Diagnosis (CCD) model, where we first introduce the Cognition factor as a bridge into the long-standing three-basic-factors (Student, Exercise, Knowledge concept) paradigm. CCD has two main parts: cognition representations and a two-stage diagnostic process. In the first part, we explicitly model cognitive process (CP) dimensions from Bloom's Taxonomy of Educational Objectives, leading to two innovative concepts proposed: the student's Subjective Cognitive Ability (SCA) and the exercise's Objective Cognitive Attribute (OCA), derived by regulating the CP through S-K and E-K interactions, respectively. Then, the SCA and OCA are formed into a new cognition-aware latent trait θ. In the second part, we employ a basic interaction function and a slip and guess influence function, inputting our new θ, a continuous Q-matrix (generated by a siamese PLMs), and other features to obtain the ideal result, followed by feeding it into the slip and guess influence function to obtain the actual result. Extensive experiments on real-world datasets demonstrates the superior effectiveness and good interpretability. | Hengnian Gu, Guoqian Luo, Xiaoxiao Dong, Shulin Li, Dongdai Zhou | Northeast Normal University, Changchun, Jilin, China; Ludong University, Yantai, Shandong, China |
|  |  [Lorentzian Residual Neural Networks](https://doi.org/10.1145/3690624.3709292) |  | 0 | Hyperbolic neural networks have emerged as a powerful tool for modeling hierarchical data structures prevalent in real-world datasets. Notably, residual connections, which facilitate the direct flow of information across layers, have been instrumental in the success of deep neural networks. However, current methods for constructing hyperbolic residual networks suffer from limitations such as increased model complexity, numerical instability, and errors due to multiple mappings to and from the tangent space. To address these limitations, we introduce LResNet, a novel Lorentzian residual neural network based on the weighted Lorentzian centroid in the Lorentz model of hyperbolic geometry. Our method enables the efficient integration of residual connections in Lorentz hyperbolic neural networks while preserving their hierarchical representation capabilities. We demonstrate that our method can theoretically derive previous methods while offering improved stability, efficiency, and effectiveness. Extensive experiments on both graph and vision tasks showcase the superior performance and robustness of our method compared to state-of-the-art Euclidean and hyperbolic alternatives. Our findings highlight the potential of for building more expressive neural networks in hyperbolic embedding space as a generally applicable method to multiple architectures, including CNNs, GNNs, and graph Transformers. | Neil He, Menglin Yang, Rex Ying |  |
|  |  [TransPlace: Transferable Circuit Global Placement via Graph Neural Network](https://doi.org/10.1145/3690624.3709185) |  | 0 | Global placement, a critical step in designing the physical layout of computer chips, is essential to optimize chip performance. Prior global placement methods optimize each circuit design individually from scratch. Their neglect of transferable knowledge limits solution efficiency and chip performance as circuit complexity drastically increases. This study presents TransPlace, a global placement framework that learns to place millions of mixed-size cells in continuous space. TransPlace introduces i) Netlist Graph to efficiently model netlist topology, ii) Cell-flow and relative position encoding to learn SE(2)-invariant representation, iii) a tailored graph neural network architecture for informed parameterization of placement knowledge, and iv) a two-stage strategy for coarse-to-fine placement. Compared to state-of-the-art placement methods, TransPlace-trained on a few high-quality placements-can place unseen circuits with 1.2x speedup while reducing congestion by 30 | Yunbo Hou, Haoran Ye, Shuwen Yang, Yingxue Zhang, Siyuan Xu, Guojie Song |  |
|  |  [AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation](https://doi.org/10.1145/3690624.3709321) |  | 0 | Large Language Model-based agents have garnered significant attention and are becoming increasingly popular. Furthermore, planning ability is a crucial component of an LLM-based agent, which generally entails achieving a desired goal from an initial state. This paper investigates enhancing the planning abilities of LLMs through instruction tuning, referred to as agent training. Recent studies have demonstrated that utilizing expert-level trajectory for instruction-tuning LLMs effectively enhances their planning capabilities. However, existing work primarily focuses on synthesizing trajectories from manually designed planning tasks and environments. The labor-intensive nature of creating these environments and tasks impedes the generation of sufficiently varied and extensive trajectories. To address this limitation, this paper explores the automated synthesis of diverse environments and a gradual range of planning tasks, from easy to difficult. We introduce a framework, AgentGen, that leverages LLMs first to generate environments and subsequently generate planning tasks conditioned on these environments. Specifically, to improve environmental diversity, we propose using an inspiration corpus composed of various domain-specific text segments as the context for synthesizing environments. Moreover, to increase the difficulty diversity of generated planning tasks, we propose a bidirectional evolution method, Bi-Evol, that evolves planning tasks from easier and harder directions to synthesize a task set with a smoother difficulty curve. The evaluation results derived from AgentBoard show that AgentGen greatly improves LLMs' planning ability, e.g., the AgentGen instruction-tuned Llama-3.1-8B surpasses GPT-3.5 in overall performance. Moreover, the AgentGen-tuned Llama-3.1-70B model achieves state-of-the-art results in planning tasks. | Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, JianGuang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan |  |
|  |  [Fair Set Cover](https://doi.org/10.1145/3690624.3709184) |  | 0 | The potential harms of algorithmic decisions have ignited algorithmicfairness as a central topic in computer science. One of the fundamentalproblems in computer science is Set Cover, which has numerous applications withsocietal impacts, such as assembling a small team of individuals thatcollectively satisfy a range of expertise requirements. However, despite itsbroad application spectrum and significant potential impact, set cover has yetto be studied through the lens of fairness. Therefore, in this paper, weintroduce Fair Set Cover, which aims not only to cover with a minimum-size setbut also to satisfy demographic parity in its selection of sets. To this end,we develop multiple versions of fair set cover, study their hardness, anddevise efficient approximation algorithms for each variant. Notably, undercertain assumptions, our algorithms always guarantees zero-unfairness, withonly a small increase in the approximation ratio compared to regular set cover.Furthermore, our experiments on various data sets and across different settingsconfirm the negligible price of fairness, as (a) the output size increases onlyslightly (if any) and (b) the time to compute the output does not significantlyincrease. | Mohsen Dehghankar, Rahul Raychaudhury, Stavros Sintos, Abolfazl Asudeh | University of Illinois Chicago Chicago; Duke University Durham |
|  |  [Partial Pre-Post Code Tree: A Memory-Efficient Tree Structure for Conjunctive Rule Mining](https://doi.org/10.1145/3690624.3709303) |  | 0 | State-of-the-art rule mining algorithms rely on summarizing the training set into efficient data structures which allow to quickly answer arbitrary conjunctive queries about the data. The key limitation of such techniques is their memory consumption. Pre-post code trees (PPC-trees) which are the basis of several efficient association and classification rule mining algorithms, are only constructed as an intermediate representation and subsequently converted into a much more efficient N-lists structure. In this paper, we introduce partial pre-post code trees (P3C-trees), which are based on the idea that partial trees are iteratively constructed, and immediately converted into N-lists. This tight integration of these phases allows to avoid the memory bottleneck of a full PPC-tree construction, and thus enables these algorithms to tackle the memory scalability problem posed by large-scale datasets. Our experiments with big datasets confirm that the memory used by P3C-tree is orders of magnitude smaller than the memory consumed by PPC-tree, and the generated N-lists are also more effective than alternative structures such as Tidset or Diffset. Moreover, the N-list construction can also be considerably sped up with the P3C-tree structure. | Van Quoc Phuong Huynh, Florian Beck, Johannes Fürnkranz | Johannes Kepler University Linz, Linz, Austria |
|  |  [Seeing the Unseen: Learning Basis Confounder Representations for Robust Traffic Prediction](https://doi.org/10.1145/3690624.3709201) |  | 0 | Traffic prediction is essential for intelligent transportation systems and urban computing. It aims to establish a relationship between historical traffic data X and future traffic states Y by employing various statistical or deep learning methods. However, the relations of X -> Y are often influenced by external confounders that simultaneously affect both X and Y , such as weather, accidents, and holidays. Existing deep-learning traffic prediction models adopt the classic front-door and back-door adjustments to address the confounder issue. However, these methods have limitations in addressing continuous or undefined confounders, as they depend on predefined discrete values that are often impractical in complex, real-world scenarios. To overcome this challenge, we propose the Spatial-Temporal sElf-superVised confoundEr learning (STEVE) model. This model introduces a basis vector approach, creating a base confounder bank to represent any confounder as a linear combination of a group of basis vectors. It also incorporates self-supervised auxiliary tasks to enhance the expressive power of the base confounder bank. Afterward, a confounder-irrelevant relation decoupling module is adopted to separate the confounder effects from direct X -> Y relations. Extensive experiments across four large-scale datasets validate our model's superior performance in handling spatial and temporal distribution shifts and underscore its adaptability to unseen confounders. Our model implementation is available at https://github.com/bigscity/STEVE_CODE. | Jiahao Ji, Wentao Zhang, Jingyuan Wang, Chao Huang | Tsinghua University CST; University of Hong Kong Hong Kong CS & IDS; Beihang University SCSE |
|  |  [On Measuring Unnoticeability of Graph Adversarial Attacks: Observations, New Measure, and Applications](https://doi.org/10.1145/3690624.3709163) |  | 0 | Adversarial attacks are allegedly unnoticeable. Prior studies have designed attack noticeability measures on graphs, primarily using statistical tests to compare the topology of original and (possibly) attacked graphs. However, we observe two critical limitations in the existing measures. First, because the measures rely on simple rules, attackers can readily enhance their attacks to bypass them, reducing their attack "noticeability" and, yet, maintaining their attack performance. Second, because the measures naively leverage global statistics, such as degree distributions, they may entirely overlook attacks until severe perturbations occur, letting the attacks be almost "totally unnoticeable." To address the limitations, we introduce HideNSeek, a learnable measure for graph attack noticeability. First, to mitigate the bypass problem, HideNSeek learns to distinguish the original and (potential) attack edges using a learnable edge scorer (LEO), which scores each edge on its likelihood of being an attack. Second, to mitigate the overlooking problem, HideNSeek conducts imbalance-aware aggregation of all the edge scores to obtain the final noticeability score. Using six real-world graphs, we empirically demonstrate that HideNSeek effectively alleviates the observed limitations, and LEO (i.e., our learnable edge scorer) outperforms eleven competitors in distinguishing attack edges under five different attack methods. For an additional application, we show that LEO boost the performance of robust GNNs by removing attack-like edges. | Hyeonsoo Jo, Hyunjin Hwang, Fanchen Bu, Soo Yong Lee, Chanyoung Park, Kijung Shin |  |
|  |  [LH-Mix: Local Hierarchy Correlation Guided Mixup over Hierarchical Prompt Tuning](https://doi.org/10.1145/3690624.3709326) |  | 0 | Hierarchical text classification (HTC) aims to assign one or more labels in the hierarchy for each text. Many methods represent this structure as a global hierarchy, leading to redundant graph structures. To address this, incorporating a text-specific local hierarchy is essential. However, existing approaches often model this local hierarchy as a sequence, focusing on explicit parent-child relationships while ignoring implicit correlations among sibling/peer relationships. In this paper, we first integrate local hierarchies into a manual depth-level prompt to capture parent-child relationships. We then apply Mixup to this hierarchical prompt tuning scheme to improve the latent correlation within sibling/peer relationships. Notably, we propose a novel Mixup ratio guided by local hierarchy correlation to effectively capture intrinsic correlations. This Local Hierarchy Mixup (LH-Mix) model demonstrates remarkable performance across three widely-used datasets. | Fanshuang Kong, Richong Zhang, Ziqiao Wang |  |
|  |  [CAPER: Enhancing Career Trajectory Prediction using Temporal Knowledge Graph and Ternary Relationship](https://doi.org/10.1145/3690624.3709329) |  | 0 | The problem of career trajectory prediction (CTP) aims to predict one's future employer or job position. While several CTP methods have been developed for this problem, we posit that none of these methods (1) jointly considers the mutual ternary dependency between three key units (i.e., user, position, and company) of a career and (2) captures the characteristic shifts of key units in career over time, leading to an inaccurate understanding of the job movement patterns in the labor market. To address the above challenges, we propose a novel solution, named as CAPER, that solves the challenges via sophisticated temporal knowledge graph (TKG) modeling. It enables the utilization of a graph-structured knowledge base with rich expressiveness, effectively preserving the changes in job movement patterns. Furthermore, we devise an extrapolated career reasoning task on TKG for a realistic evaluation. The experiments on a real-world career trajectory dataset demonstrate that CAPER consistently and significantly outperforms four baselines, two recent TKG reasoning methods, and five state-of-the-art CTP methods in predicting one's future companies and positions-i.e., on average, yielding 6.80 accurate predictions, respectively. | YeonChang Lee, JaeHyun Lee, Michiharu Yamashita, Dongwon Lee, SangWook Kim |  |
|  |  [Reasoning-Enhanced Object-Centric Learning for Videos](https://doi.org/10.1145/3690624.3709168) |  | 0 | Object-centric learning aims to break down complex visual scenes into moremanageable object representations, enhancing the understanding and reasoningabilities of machine learning systems toward the physical world. Recently,slot-based video models have demonstrated remarkable proficiency in segmentingand tracking objects, but they overlook the importance of the effectivereasoning module. In the real world, reasoning and predictive abilities play acrucial role in human perception and object tracking; in particular, theseabilities are closely related to human intuitive physics. Inspired by this, wedesigned a novel reasoning module called the Slot-based Time-Space Transformerwith Memory buffer (STATM) to enhance the model's perception ability in complexscenes. The memory buffer primarily serves as storage for slot information fromupstream modules, the Slot-based Time-Space Transformer makes predictionsthrough slot-based spatiotemporal attention computations and fusion. Ourexperiment results on various datasets show that STATM can significantlyenhance object-centric learning capabilities of slot-based video models. | Jian Li, Pu Ren, Yang Liu, Hao Sun | Associate Professor, University of Chinese Academy of Sciences; PhD student, Renmin University of China; Postdoc, Lawrence Berkeley National Lab |
|  |  [TSINR: Capturing Temporal Continuity via Implicit Neural Representations for Time Series Anomaly Detection](https://doi.org/10.1145/3690624.3709266) |  | 0 | Time series anomaly detection aims to identify unusual patterns in data or deviations from systems' expected behavior. The reconstruction-based methods are the mainstream in this task, which learn point-wise representation via unsupervised learning. However, the unlabeled anomaly points in training data may cause these reconstruction-based methods to learn and reconstruct anomalous data, resulting in the challenge of capturing normal patterns. In this paper, we propose a time series anomaly detection method based on implicit neural representation (INR) reconstruction, named TSINR, to address this challenge. Due to the property of spectral bias, TSINR enables prioritizing low-frequency signals and exhibiting poorer performance on high-frequency abnormal data. Specifically, we adopt INR to parameterize time series data as a continuous function and employ a transformer-based architecture to predict the INR of given data. As a result, the proposed TSINR method achieves the advantage of capturing the temporal continuity and thus is more sensitive to discontinuous anomaly data. In addition, we further design a novel form of INR continuous function to learn inter- and intra-channel information, and leverage a pre-trained large language model to amplify the intense fluctuations in anomalies. Extensive experiments demonstrate that TSINR achieves superior overall performance on both univariate and multivariate time series anomaly detection benchmarks compared to other state-of-the-art reconstruction-based methods. Our codes are available. | Mengxuan Li, Ke Liu, Hongyang Chen, Jiajun Bu, Hongwei Wang, Haishuai Wang |  |
|  |  [Diversity Optimization for Travelling Salesman Problem via Deep Reinforcement Learning](https://doi.org/10.1145/3690624.3709181) |  | 0 | Existing neural methods for the Travelling Salesman Problem (TSP) mostly aim at finding a single optimal solution. To discover diverse yet high-quality solutions for Multi-Solution TSP (MSTSP), we propose a novel deep reinforcement learning based neural solver, which is primarily featured by an encoder-decoder structured policy. Concretely, on the one hand, a Relativization Filter (RF) is designed to enhance the robustness of the encoder to affine transformations of the instances, so as to potentially improve the quality of the found solutions. On the other hand, a Multi-Attentive Adaptive Active Search (MA3S) is tailored to allow the decoders to strike a balance between the optimality and diversity. Experimental evaluations on benchmark instances demonstrate the superiority of our method over recent neural baselines across different metrics, and its competitive performance against state-of-the-art traditional heuristics with significantly reduced computational time, ranging from 1.3× to 15× faster. Furthermore, we demonstrate that our method can also be applied to the Capacitated Vehicle Routing Problem (CVRP). | Qi Li, Zhiguang Cao, Yining Ma, Yaoxin Wu, YueJiao Gong |  |
|  |  [Harnessing Scale and Physics: A Multi-Graph Neural Operator Framework for PDEs on Arbitrary Geometries](https://doi.org/10.1145/3690624.3709173) |  | 0 | Partial Differential Equations (PDEs) underpin many scientific phenomena, yet traditional computational approaches often struggle with complex, nonlinear systems and irregular geometries. This paper introduces the AMG method, a Multi-Graph neural operator approach designed for efficiently solving PDEs on Arbitrary geometries. AMG leverages advanced graph-based techniques and dynamic attention mechanisms within a novel GraphFormer architecture, enabling precise management of diverse spatial domains and complex data interdependencies. By constructing multi-scale graphs to handle variable feature frequencies and a physics graph to encapsulate inherent physical properties, AMG significantly outperforms previous methods, which are typically limited to uniform grids. We present a comprehensive evaluation of AMG across six benchmarks, demonstrating its consistent superiority over existing state-of-the-art models. Our findings highlight the transformative potential of tailored graph neural operators in surmounting the challenges faced by conventional PDE solvers. Our code and datasets are available on . | Zhihao Li, Haoze Song, Di Xiao, Zhilu Lai, Wei Wang |  |
|  |  [DistPred: A Distribution-Free Probabilistic Inference Method for Regression and Forecasting](https://doi.org/10.1145/3690624.3709286) |  | 0 | Traditional regression and prediction tasks often only provide deterministic point estimates. To estimate the uncertainty or distribution information of the response variable, methods such as Bayesian inference, model ensembling, or MC Dropout are typically used. These methods either assume that the posterior distribution of samples follows a Gaussian process or require thousands of forward passes for sample generation. We propose a novel approach called DistPred for regression and forecasting tasks, which overcomes the limitations of existing methods while remaining simple and powerful. Specifically, we transform proper scoring rules that measure the discrepancy between the predicted distribution and the target distribution into a differentiable discrete form and use it as a loss function to train the model end-to-end. This allows the model to sample numerous samples in a single forward pass to estimate the potential distribution of the response variable. We have compared our method with several existing approaches on multiple datasets and achieved state-of-the-art performance. Additionally, our method significantly improves computational efficiency. For example, compared to state-of-the-art models, DistPred has a 90x faster inference speed. Experimental results can be reproduced through https://github.com/Anoise/DistPred. | Daojun Liang |  |
|  |  [Stealing Training Graphs from Graph Neural Networks](https://doi.org/10.1145/3690624.3709289) |  | 0 | Graph Neural Networks (GNNs) have shown promising results in modeling graphs in various tasks. The training of GNNs, especially on specialized tasks such as bioinformatics, demands extensive expert annotations, which are expensive and usually contain sensitive information of data providers. The trained GNN models are often shared for deployment in the real world. As neural networks can memorize the training samples, the model parameters of GNNs have a high risk of leaking private training data. Our theoretical analysis shows the strong connections between trained GNN parameters and the training graphs used, confirming the training graph leakage issue. However, explorations into training data leakage from trained GNNs are rather limited. Therefore, we investigate a novel problem of stealing graphs from trained GNNs. To obtain high-quality graphs that resemble the target training set, a graph diffusion model with diffusion noise optimization is deployed as a graph generator. Furthermore, we propose a selection method that effectively leverages GNN model parameters to identify training graphs from samples generated by the graph diffusion model. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed framework in stealing training graphs from the trained GNN. | Minhua Lin, Enyan Dai, Junjie Xu, Jinyuan Jia, Xiang Zhang, Suhang Wang |  |
|  |  [SEPTQ: A Simple and Effective Post-Training Quantization Paradigm for Large Language Models](https://doi.org/10.1145/3690624.3709287) |  | 0 | Large language models (LLMs) have shown remarkable performance in various domains, but they are constrained by massive computational and storage costs. Quantization, an effective technique for compressing models to fit resource-limited devices while preserving generative quality, encompasses two primary methods: quantization aware training (QAT) and post-training quantization (PTQ). QAT involves additional retraining or fine-tuning, thus inevitably resulting in high training cost and making it unsuitable for LLMs. Consequently, PTQ has become the research hotspot in recent quantization methods. However, existing PTQ methods usually rely on various complex computation procedures and suffer from considerable performance degradation under low-bit quantization settings. To alleviate the above issues, we propose a simple and effective post-training quantization paradigm for LLMs, named SEPTQ. Specifically, SEPTQ first calculates the importance score for each element in the weight matrix and determines the quantization locations in a static global manner. Then it utilizes the mask matrix which represents the important locations to quantize and update the associated weights column-by-column until the appropriate quantized weight matrix is obtained. Compared with previous methods, SEPTQ simplifies the post-training quantization procedure into only two steps, and considers the effectiveness and efficiency simultaneously. Experimental results on various datasets across a suite of models ranging from millions to billions in different quantization bit-levels demonstrate that SEPTQ significantly outperforms other strong baselines, especially in low-bit quantization scenarios. | Han Liu, Haotian Gao, Xiaotong Zhang, Changya Li, Feng Zhang, Wei Wang, Fenglong Ma, Hong Yu | Peking University, Beijing, China; The Pennsylvania State University, University Park, USA; Shenzhen MSU-BIT University, Shenzhen, China; Dalian University of Technology, Dalian, China |
|  |  [SCode: A Spherical Code Metric Learning Approach to Continuously Monitoring Predictive Events in Networked Data](https://doi.org/10.1145/3690624.3709246) |  | 0 | Dynamic graphs are common in many applications to conveniently model heterogeneous data integrated from multiple sources. We study the monitoring of predictive events in dynamic graphs. Treating the problem as a continuous multi-label classification, we use deep metric learning to manage the embedding space and to create spherical codes where each codeword is an embedding vector representing a cluster of data state embeddings with the same results of the predictive events. By continuously training data embeddings from a dynamic graph neural network (DGNN) model and a code generator together, our method, called SCode, achieves significantly better accuracy than DGNN baselines. Moreover, SCode is also about twice as fast as the DGNN baselines, owing to its efficient matching between data state embedding and codewords for multiple events together. Finally, our training sample complexity analysis also sheds light on the generalizability of the online learning. | Qu Liu, Emil Zulawnik, Tingjian Ge | University of Massachusetts, Lowell, Lowell, Massachusetts, USA |
|  |  [3DGraphX: Explaining 3D Molecular Graph Models via Incorporating Chemical Priors](https://doi.org/10.1145/3690624.3709302) |  | 0 | We consider the explanation of 3D graph neural networks (GNNs) in the field of molecular learning. Recent studies have modeled molecules as 3D graphs, but there exist formidable challenges for 3D graph explanation. In this work, we propose a novel and principled paradigm, known as 3DGraphX, for 3D molecular graph explanation. Unlike existing 2D GNN explanation methods, 3DGraphX focuses on 3D motifs, which are subgraphs showing great occurrence and function significance in molecular activities. Once generated, 3D motifs are fixed in the explanation model; hence, 3DGraphX produces more accurate and chemically plausible explanations in an efficient manner. 3DGraphX contains two branches with several novel methods for instance-level and geometry-level explanations, respectively. Two novel components, known as the mask pooling component and mask unpooling component, are developed to discover important motifs for each 3D molecule as the instance-level explanation. Local spherical coordinate systems are built to investigate the relative positions among motifs for geometry-level explanation. Altogether, 3DGraphX sheds light on the characteristics of molecules as well as the behaviors of 3D GNNs in molecular learning. Experimental results show that 3DGraphX significantly outperforms baselines in instance-level explanation with various explanation budgets. Additional experiments show that 3DGraphX reveals the important geometries taken by 3D GNNs for accurate molecular learning. The code is publicly available at https://github.com/xufliu/3DGraphX. | Xufeng Liu, Dongsheng Luo, Wenhan Gao, Yi Liu | State University of New York at Stony Brook, Stony Brook, NY, USA; Florida International University, Miami, FL, USA |
|  |  [Enhancing Unsupervised Graph Few-shot Learning via Set Functions and Optimal Transport](https://doi.org/10.1145/3690624.3709208) |  | 0 | Graph few-shot learning has garnered significant attention for its ability to rapidly adapt to downstream tasks with limited labeled data, sparking considerable interest among researchers. Recent advancements in graph few-shot learning models have exhibited superior performance across diverse applications. Despite their successes, several limitations still exist. First, existing models in the meta-training phase predominantly focus on instance-level features within tasks, neglecting crucial set-level features essential for distinguishing between different categories. Second, these models often utilize query sets directly on classifiers trained with support sets containing only a few labeled examples, overlooking potential distribution shifts between these sets and leading to suboptimal performance. Finally, previous models typically require necessitate abundant labeled data from base classes to extract transferable knowledge, which is typically infeasible in real-world scenarios. To address these issues, we propose a novel model named STAR, which leverages Set funcTions and optimAl tRansport for enhancing unsupervised graph few-shot learning. Specifically, STAR utilizes expressive set functions to obtain set-level features in an unsupervised manner and employs optimal transport principles to align the distributions of support and query sets, thereby mitigating distribution shift effects. Theoretical analysis demonstrates that STAR can capture more task-relevant information and enhance generalization capabilities. Empirically, extensive experiments across multiple datasets validate the effectiveness of STAR. Our code can be found here. | Yonghao Liu, Fausto Giunchiglia, Ximing Li, Lan Huang, Xiaoyue Feng, Renchu Guan |  |
|  |  [MobileSteward: Integrating Multiple App-Oriented Agents with Self-Evolution to Automate Cross-App Instructions](https://doi.org/10.1145/3690624.3709171) |  | 0 | Mobile phone agents can assist people in automating daily tasks on their phones, which have emerged as a pivotal research spotlight. However, existing procedure-oriented agents struggle with cross-app instructions, due to the following challenges: (1) complex task relationships, (2) diverse app environment, and (3) error propagation and information loss in multi-step execution. Drawing inspiration from object-oriented programming principles, we recognize that object-oriented solutions is more suitable for cross-app instruction. To address these challenges, we propose a self-evolving multi-agent framework named MobileSteward, which integrates multiple app-oriented StaffAgents coordinated by a centralized StewardAgent. We design three specialized modules in MobileSteward: (1) Dynamic Recruitment generates a scheduling graph guided by information flow to explicitly associate tasks among apps. (2) Assigned Execution assigns the task to app-oriented StaffAgents, each equipped with app-specialized expertise to address the diversity between apps. (3) Adjusted Evaluation conducts evaluation to provide reflection tips or deliver key information, which alleviates error propagation and information loss during multi-step execution. To continuously improve the performance of MobileSteward, we develop a Memory-based Self-evolution mechanism, which summarizes the experience from successful execution, to improve the performance of MobileSteward. We establish the first English Cross-APP Benchmark (CAPBench) in the real-world environment to evaluate the agents' capabilities of solving complex cross-app instructions. Experimental results demonstrate that MobileSteward achieves the best performance compared to both single-agent and multi-agent frameworks, highlighting the superiority of MobileSteward in better handling user instructions with diverse complexity. | Yuxuan Liu, Hongda Sun, Wei Liu, Jian Luan, Bo Du, Rui Yan |  |
|  |  [A Universal Model for Human Mobility Prediction](https://doi.org/10.1145/3690624.3709236) |  | 0 | Predicting human mobility is crucial for urban planning, traffic control, and emergency response. Mobility behaviors can be categorized into individual and collective, and these behaviors are recorded by diverse mobility data, such as individual trajectory and crowd flow. As different modalities of mobility data, individual trajectory and crowd flow have a close coupling relationship. Crowd flows originate from the bottom-up aggregation of individual trajectories, while the constraints imposed by crowd flows shape these individual trajectories. Existing mobility prediction methods are limited to single tasks due to modal gaps between individual trajectory and crowd flow. In this work, we aim to unify mobility prediction to break through the limitations of task-specific models. We propose a universal human mobility prediction model (named UniMob), which can be applied to both individual trajectory and crowd flow. UniMob leverages a multi-view mobility tokenizer that transforms both trajectory and flow data into spatiotemporal tokens, facilitating unified sequential modeling through a diffusion transformer architecture. To bridge the gap between the different characteristics of these two data modalities, we implement a novel bidirectional individual and collective alignment mechanism. This mechanism enables learning common spatiotemporal patterns from different mobility data, facilitating mutual enhancement of both trajectory and flow predictions. Extensive experiments on real-world datasets validate the superiority of our model over state-of-the-art baselines in trajectory and flow prediction. Especially in noisy and scarce data scenarios, our model achieves the highest performance improvement of more than 14 Accuracy@5. | Qingyue Long, Yuan Yuan, Yong Li |  |
|  |  [Future Matters for Present: Towards Effective Physical Simulation over Meshes](https://doi.org/10.1145/3690624.3709340) |  | 0 | This paper investigates the problem of learning mesh-based physical simulations, which is a crucial task with applications in fluid mechanics and aerodynamics. Recent works typically utilize graph neural networks (GNNs) to produce next-time states on irregular meshes by modeling interacting dynamics, and then adopt iterative rollouts for the whole trajectories. However, these methods cannot achieve satisfactory performance in long-term predictions due to the failure of capturing long-term dependency and potential error accumulations. To tackle this, we introduce a new future-to-present learning perspective, and further develop a simple yet effective approach named Foresight And Interpolation (FAIR) for long-term mesh-based simulations. The main idea of our FAIR is to first learn a graph ODE model for coarse long-term predictions and then refine short-term predictions via interpolation. Specifically, FAIR employs a continuous graph ODE model that incorporates past states into the evolution of interacting node representations, which is capable of learning coarse long-term trajectories under a multi-task learning framework. Then, we leverage a channel aggregation strategy to summarize the trajectories for refined short-term predictions, which can be illustrated using an interpolation process. Through pyramid-like alternative propagation between the foresight step and refinement step, our proposed framework FAIR can generate accurate long-term trajectories, achieving a significant error reduction compared with the best baseline on four benchmark datasets. Extensive ablation studies and visualization further validate the superiority of our proposed FAIR. | Xiao Luo, Junyu Luo, Huiyu Jiang, Hang Zhou, Zhiping Xiao, Wei Ju, Carl Ji Yang, Ming Zhang, Yizhou Sun | University of California, Los Angeles, Los Angeles, CA, USA; University of California, Santa Barbara, Santa Barbara, CA, USA; University of Washington, Seattle, WA, USA; Peking University, Beijing, China; University of California, Davis, Davis, CA, USA; Emory University, Atlanta, GA, USA |
|  |  [Fairness without Demographics through Learning Graph of Gradients](https://doi.org/10.1145/3690624.3709160) |  | 0 | Machine learning systems are notoriously prone to biased predictions about certain demographic groups, leading to algorithmic fairness issues. Due to privacy concerns and data quality problems, some demographic information may not be available in the training data and the complex interaction of different demographics can lead to a lot of unknown minority subpopulations, which all limit the applicability of group fairness. Many existing works on fairness without demographics assume the correlation between groups and features. However, we argue that the model gradients are also valuable for fairness without demographics. In this paper, we show that the correlation between gradients and groups can help identify and improve group fairness. With an adversarial weighting architecture, we construct a graph where samples with similar gradients are connected and learn the weights of different samples from it. Unlike the surrogate grouping methods that cluster groups from features and labels as proxy sensitive attribute, our method leverages the graph structure as a soft grouping mechanism, which is much more robust to noises. The results show that our method is robust to noise and can improve fairness significantly without decreasing the overall accuracy too much. | Yingtao Luo, Zhixun Li, Qiang Liu, Jun Zhu |  |
|  |  [Towards Controllable Hybrid Fairness in Graph Neural Networks](https://doi.org/10.1145/3690624.3709224) |  | 0 | Graph Neural Networks (GNNs) have shown remarkable capabilities in mining graph-structured data. However, conventional GNNs often encounter various fairness issues, such as predictions with prejudices when dealing with nodes with different sensitive attributes like genders or races, or significantly different prediction performance when facing nodes with different degrees. Existing studies mainly focus on addressing one specific fairness issue, neglecting the fact that a GNN model may face multiple unfairness simultaneously in reality, and addressing only one specific fairness may still leave the GNNs in an unfair status. In this paper, we focus on achieving multiple fairness on GNNs simultaneously, which we call hybrid fairness. To achieve this objective, we propose a novel GNN framework called LibraGNN. Specifically, we adopt a multi-teacher knowledge distillation training framework that successfully unifies the learning paradigms for multiple fairness. To ensure LibraGNN strikes a better trade-off among different fairness, we transform the multi-teacher knowledge distillation into a multi-objective optimization problem and further employ Pareto efficiency for optimization guidance. Finally, a controllable preference vector is introduced to assist LibraGNN in modulating its capability towards various forms of fairness, thereby achieving controllable hybrid fairness. Extensive experiments on three real-world datasets demonstrate the effectiveness of LibraGNN on both hybrid fairness and utility. | Zihan Luo, Hong Huang, Jianxun Lian, Xiran Song, Hai Jin | Microsoft Research Asia, Beijing, China; Huazhong University of Science and Technology, Wuhan, China; Washington University in St. Louis, Saint Louis, USA |
|  |  [Task Diversity in Bayesian Federated Learning: Simultaneous Processing of Classification and Regression](https://doi.org/10.1145/3690624.3709341) |  | 0 | This work addresses a key limitation in current federated learning approaches, which predominantly focus on homogeneous tasks, neglecting the task diversity on local devices. We propose a principled integration of multi-task learning using multi-output Gaussian processes (MOGP) at the local level and federated learning at the global level. MOGP handles correlated classification and regression tasks, offering a Bayesian non-parametric approach that naturally quantifies uncertainty. The central server aggregates the posteriors from local devices, updating a global MOGP prior redistributed for training local models until convergence. Challenges in performing posterior inference on local devices are addressed through the Pólya-Gamma augmentation technique and mean-field variational inference, enhancing computational efficiency and convergence rate. Experimental results on both synthetic and real data demonstrate superior predictive performance, OOD detection, uncertainty calibration and convergence rate, highlighting the method's potential in diverse applications. Our code is publicly available at https://github.com/JunliangLv/task_diversity_BFL. | Junliang Lyu, Yixuan Zhang, Xiaoling Lu, Feng Zhou |  |
|  |  [On the Support Vector Effect in DNNs: Rethinking Data Selection and Attribution](https://doi.org/10.1145/3690624.3709295) |  | 0 | In Deep Neural Networks (DNNs), manipulating gradients is central to various algorithms, including data subset selection and instance attribution. For better tractability, practitioners often resort to using only the gradients of the last layer as a heuristic, instead of the full gradient across all model parameters, which we show is detrimental due to the Support Vector Effect (SVE). We introduce SVE, a max-margin-like behavior in the last layer(s) of DNNs and employ it to thoroughly scrutinize prevalent data selection and attribution methods relying on last layer gradients. Our investigation exposes limitations in these techniques and not only provides explanations for previously observed pitfalls, like lack of diversity and temporal performance degradation, but also offers fresh insights, including the vulnerability of existing methods to basic poisoning attacks and the potential for competitive performance using much simpler alternatives. Based on insights from SVE, we craft new methods RandE and PAE for data subset selection and instance attribution, respectively, which often outperform the purported state-of-the-art at a fraction of the cost, emphasizing the practical advantages of more efficient and less complex approaches. | Syed Hasan Amin Mahmood, Ming Yin, Rajiv Khanna | Purdue University, West Lafayette, IN, USA |
|  |  [Conservation-informed Graph Learning for Spatiotemporal Dynamics Prediction](https://doi.org/10.1145/3690624.3709244) |  | 0 | Data-centric methods have shown great potential in understanding and predicting spatiotemporal dynamics, enabling better design and control of the object system. However, deep learning models often lack interpretability, fail to obey intrinsic physics, and struggle to cope with the various domains. While geometry-based methods, e.g., graph neural networks (GNNs), have been proposed to further tackle these challenges, they still need to find the implicit physical laws from large datasets and rely excessively on rich labeled data. In this paper, we herein introduce the conservation-informed GNN (CiGNN), an end-to-end explainable learning framework, to learn spatiotemporal dynamics based on limited training data. The network is designed to conform to the general conservation law via symmetry, where conservative and non-conservative information passes over a multiscale space enhanced by a latent temporal marching strategy. The efficacy of our model has been verified in various spatiotemporal systems based on synthetic and real-world datasets, showing superiority over baseline models. Results demonstrate that CiGNN exhibits remarkable accuracy and generalizability, and is readily applicable to learning for prediction of various spatiotemporal dynamics in a spatial domain with complex geometry. | Yuan Mi, Pu Ren, Hongteng Xu, Hongsheng Liu, Zidong Wang, Yike Guo, JiRong Wen, Hao Sun, Yang Liu |  |
|  |  [Data Glitches Discovery using Influence-based Model Explanations](https://doi.org/10.1145/3690624.3709285) |  | 0 | We address the problem of detecting data glitches in ML training sets, specifically mislabeled and anomalous samples. Detection of data glitches provides insights into the quality of the data sampling. Their repair may improve the reliability and the performance of the model. The proposed methodology is based on exploiting influence functions that estimate how much the loss of the model (or a given sample) is affected when a sample is removed from the training set. We introduce three novel signals for detecting, characterizing, and repairing data glitches in a training set based on sample influences. Influence-based signals form an explainable-by-design data glitch detection framework, producing intuitively explainable signals of the actual predictive model built. In contrast, specialized algorithms that are agnostic to the target ML model (e.g., anomaly detectors) replicate the work of fitting the data distribution and may detect glitches that are inconsistent with the decision boundary of the predictive model. Computational experiments on tabular and image data modalities demonstrate that the proposed signals outperform, in some cases up to a factor of 6, all existing influence-based signals, and generalize across different datasets and ML models. In addition, they often outperform specialized glitch detectors (e.g., mislabeled and anomaly detectors) and provide accurate label repairs for mislabeled samples. | Nikolaos Myrtakis, Ioannis Tsamardinos, Vassilis Christophides | ETIS Lab, ENSEA, Cergy, France & University of Crete, Crete, Greece; University of Crete, Crete, Greece; ETIS Lab, ENSEA, Cergy, France |
|  |  [Weight-Constrained Simple Path Enumeration in Weighted Graph](https://doi.org/10.1145/3690624.3709310) |  | 0 | Path enumeration is a fundamental problem and has been extensively studied in the literature. Given two query vertices and a weight threshold, the problem aims to identify all simple paths with weight not exceeding the threshold. Existing studies on path enumeration include DFS-based solutions and join-based solutions, where the join-based solutions only work for unweighted graphs. In this paper, we are the first to propose a join-based framework for weighted graphs. By observing the characteristics of DFS, we design a series of novel data structures and operations based on the join-based framework. In this way, our final solution combines the advantages of both join and DFS. We conduct experiments on several real large graphs. For weighted graphs, our method is much more efficient than existing algorithms. For unweighted graphs, our method is still competitive compared with the state-of-the-art solution which only works for unweighted graphs. | Dian Ouyang, Dong Wen, Jianye Yang, Wentao Li, Xuemin Lin | University of New South Wales, Sydney, NSW, Australia; Guangzhou University, Guangzhou, China; Shanghai Jiao Tong University, Shanghai, China; University of Leicester, Leicester, United Kingdom |
|  |  [Distributional Prototype Learning for Out-of-distribution Detection](https://doi.org/10.1145/3690624.3709294) |  | 0 | Out-of-distribution (OOD) detection has emerged as a pivotal approach for enhancing the reliability of machine learning models, considering the potential for test data to be sampled from classes disparate from in-distribution (ID) data employed during model training. Detecting those OOD data is typically realized as a distance measurement problem, where those deviating far away from the training distribution in the learned feature space are considered OOD samples. Advanced works have shown great success in learning with prototypes for feature-based OOD detection methods, where each ID class is represented with single or multiple prototypes. However, modeling with a finite number of prototypes would fail to maximally capture intra-class variations. In view of this, this paper extends the existing prototype-based learning paradigm to an infinite setting. This motivates us to design two feasible formulations for the Distributional Prototype Learning (DPL) objective, where, to avoid intractable computation and exploding parameters caused by the infinity nature, our key idea is to model an infinite number of discrete prototypes of each ID class with a class-wise continuous distribution. We theoretically analyze both alternatives, identifying the more stable-converging version of the learning objective. We show that, by sampling prototypes from a mixture of class-conditioned Gaussian distributions, the objective can be efficiently computed in a closed form without resorting to the computationally expensive Monte-Carlo approximation of the involved expectation terms. Extensive evaluations across mainstream OOD detection benchmarks empirically manifest that our proposed DPL has established a new state-of-the-art in various OOD settings. | Bo Peng, Jie Lu, Yonggang Zhang, Guangquan Zhang, Zhen Fang | University of Technology Sydney, Sydney, NSW, Australia; Hong Kong Baptist University, Hong Kong, China |
|  |  [On the Necessity of World Knowledge for Mitigating Missing Labels in Extreme Classification](https://doi.org/10.1145/3690624.3709290) |  | 0 | Extreme Classification (XC) aims to map a query to the most relevant documents from a very large document set. XC algorithms used in real-world applications learn this mapping from datasets curated from implicit feedback, such as user clicks. However, these datasets inevitably suffer from missing labels. In this work, we observe that systematic missing labels lead to missing knowledge, which is critical for accurately modelling relevance between queries and documents. We formally show that this absence of knowledge cannot be recovered using existing methods such as propensity weighting and data imputation strategies that solely rely on the training dataset. While LLMs provide an attractive solution to augment the missing knowledge, leveraging them in applications with low latency requirements and large document sets is challenging. To incorporate missing knowledge at scale, we propose SKIM (Scalable Knowledge Infusion for Missing Labels), an algorithm that leverages a combination of small LM and abundant unstructured meta-data to effectively mitigate the missing label problem. We show the efficacy of our method on large-scale public datasets through exhaustive unbiased evaluation ranging from human annotations to simulations inspired from industrial settings. SKIM outperforms existing methods on Recall@100 by more than 10 absolute points. Additionally, SKIM scales to proprietary query-ad retrieval datasets containing 10 million documents, outperforming contemporary methods by 12 evaluation and increased ad click-yield by 1.23 conducted on a popular search engine. We release our code, prompts, trained XC models and finetuned SLMs at: https://github.com/bicycleman15/skim | Jatin Prakash, Anirudh Buvanesh, Bishal Santra, Deepak Saini, Sachin Yadav, Jian Jiao, Yashoteja Prabhu, Amit Sharma, Manik Varma |  |
|  |  [Input Snapshots Fusion for Scalable Discrete-Time Dynamic Graph Neural Networks](https://doi.org/10.1145/3690624.3709316) |  | 0 | In recent years, there has been a surge in research on dynamic graph representation learning, primarily focusing on modeling the evolution of temporal-spatial patterns in real-world applications. However, within the domain of discrete-time dynamic graphs, the exploration of temporal edges remains underexplored. Existing approaches often rely on additional sequential models to capture dynamics, leading to high computational and memory costs, particularly for large-scale graphs. To address this limitation, we propose the Input Snapshots Fusion based Dynamic Graph Neural Network (SFDyG), which combines Hawkes processes with graph neural networks to capture temporal and structural patterns in dynamic graphs effectively. By fusing multiple snapshots into a single temporal graph, SFDyG decouples computational complexity from the number of snapshots, enabling efficient full-batch and mini-batch training. Experimental evaluations on eight diverse dynamic graph datasets for future link prediction tasks demonstrate that SFDyG consistently outperforms existing methods. | QingGuo Qi, Hongyang Chen, Minhao Cheng, Han Liu |  |
|  |  [Tackling the Length Barrier: Dynamic Context Browsing for Knowledge-Intensive Task](https://doi.org/10.1145/3690624.3709240) |  | 0 | Knowledge-intensive tasks often require complex reasoning and contextual understanding over long contexts. However, the learning and deployment of long-LLMs remains a challenging problem despite recent progresses. In this work, we propose that the short LLMs have great potentiality for solving knowledge-intensive tasks that have long context, i.e. they can be solved by purely working with oracle short-contexts within the input long-context. On top of this argument, we propose a framework called DCISO DynamiC knowledge-Intensive task S>Olver), which enables a short-LLM to address the knowledge-intensive tasks with long context via dynamic context browsing. In our framework, the short-LLM prompts itself to reason for two critical decisions: 1) how to access to the appropriate part of context within the input, 2) how to make effective use of the accessed context. By adaptively accessing and utilizing the context based on the presented tasks, DCISO can serve as a general framework to handle diversified knowledge-intensive long-context problems. We comprehensively evaluate different types of tasks from popular long-context benchmarks, where DCISO is able to achieve a substantially improved performance. Our codes will be released at this repository. | Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Yujia Zhou, Xu Chen, Zhicheng Dou | Hong Kong Polytechnic University, Hong Kong, China; Peking University, Beijing, China and Beijing Academy of Artificial Intelligence, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China |
|  |  [Quantum Time-index Models with Reservoir for Time Series Forecasting](https://doi.org/10.1145/3690624.3709228) |  | 0 | The time-index models are a class of time series forecasting models that map time-index features to forecasts in continuous space. Compared to the historical-value models, the time-index models can avoid the effect of data sampling frequency and are usually more expressive. However, the vanilla deep time-index model is weak in modeling the high-frequency components of time series and often requires the introduction of many parameters to enhance the modeling capability. Moreover, the time-index model learns only a mapping relationship and ignores the sequence relationship between temporal features, leading to a weak extrapolation capability in the forecast horizon. In this paper, inspired by the ability of quantum implicit neural representations to model the high-frequency components of signals with fewer parameters, we propose Quantum Time-Index Models with Reservoir (QuantumTime). Specifically, we introduce variational quantum circuits to address the challenge of representing high-frequency components in time series. Then, we introduce a reservoir that empowers QuantumTime with powerful extrapolation capabilities by exploiting the rich dynamical properties of reservoir computing. Ultimately, experiments conducted on chaotic datasets and various real-world datasets demonstrate that QuantumTime achieves highly competitive results compared to the state-of-the-art deep time-index model while reducing training parameters by at least 95%. Our approach provides a paradigm for utilizing potential quantum advantage in practical tasks. | Wenbo Qiao, Jiaming Zhao, Peng Zhang | School of New Media and Communication, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China |
|  |  [DUET: Dual Clustering Enhanced Multivariate Time Series Forecasting](https://doi.org/10.1145/3690624.3709325) |  | 0 | Multivariate time series forecasting is crucial for various applications, such as financial investment, energy management, weather forecasting, and traffic optimization. However, accurate forecasting is challenging due to two main factors. First, real-world time series often show heterogeneous temporal patterns caused by distribution shifts over time. Second, correlations among channels are complex and intertwined, making it hard to model the interactions among channels precisely and flexibly. In this study, we address these challenges by proposing a general framework called \textbf{DUET}, which introduces \underline{DU}al clustering on the temporal and channel dimensions to \underline{E}nhance multivariate \underline{T}ime series forecasting. First, we design a Temporal Clustering Module (TCM) that clusters time series into fine-grained distributions to handle heterogeneous temporal patterns. For different distribution clusters, we design various pattern extractors to capture their intrinsic temporal patterns, thus modeling the heterogeneity. Second, we introduce a novel Channel-Soft-Clustering strategy and design a Channel Clustering Module (CCM), which captures the relationships among channels in the frequency domain through metric learning and applies sparsification to mitigate the adverse effects of noisy channels. Finally, DUET combines TCM and CCM to incorporate both the temporal and channel dimensions. Extensive experiments on 25 real-world datasets from 10 application domains, demonstrate the state-of-the-art performance of DUET. | Xiangfei Qiu, Xingjian Wu, Yan Lin, Chenjuan Guo, Jilin Hu, Bin Yang |  |
|  |  [ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting](https://doi.org/10.1145/3690624.3709254) |  | 0 | Forecasting complex time series is an important yet challenging problem that involves various industrial applications. Recently, masked time-series modeling has been proposed to effectively model temporal dependencies for forecasting by reconstructing masked segments from unmasked ones. However, since the semantic information in time series is involved in intricate temporal variations generated by multiple time series components, simply masking a raw time series ignores the inherent semantic structure, which may cause MTM to learn spurious temporal patterns present in the raw data. To capture distinct temporal semantics, we show that masked modeling techniques should address entangled patterns through a decomposition approach. Specifically, we propose ST-MTM, a masked time-series modeling framework with seasonal-trend decomposition, which includes a novel masking method for the seasonal-trend components that incorporates different temporal variations from each component. ST-MTM uses a period masking strategy for seasonal components to produce multiple masked seasonal series based on inherent multi-periodicity and a sub-series masking strategy for trend components to mask temporal regions that share similar variations. The proposed masking method presents an effective pre-training task for learning intricate temporal variations and dependencies. Additionally, ST-MTM introduces a contrastive learning task to support masked modeling by enhancing contextual consistency among multiple masked seasonal representations. Experimental results show that our proposed ST-MTM achieves consistently superior forecasting performance compared to existing masked modeling, contrastive learning, and supervised forecasting methods. | Hyunwoo Seo, Chiehyeon Lim |  |
|  |  [Abductive Learning for Neuro-Symbolic Grounded Imitation](https://doi.org/10.1145/3690624.3709344) |  | 0 | Recent learning-to-imitation methods have shown promise in planning by imitating within the observation-action space, yet they remain constrained in open environments, especially for long-horizon tasks. In contrast, while traditional symbolic planning excels in such tasks through logical reasoning over human-defined symbolic spaces, it struggles with high-dimensional visual inputs encountered in real-world scenarios. In this work, we draw inspiration from abductive learning and introduce a novel framework ABductive Imitation Learning (ABIL) that integrates the benefits of data-driven learning and symbolic-based reasoning, enabling long-horizon planning. Specifically, we employ abductive reasoning to understand the demonstrations in symbolic space and design the principles of sequential consistency to resolve the conflicts between perception and reasoning. ABIL generates predicate candidates to facilitate the perception from raw observations to symbolic space without laborious predicate annotations, providing a groundwork for symbolic planning. With the symbolic understanding, we develop a policy ensemble with base policies designed around different logical objectives, managed through symbolic reasoning. Experiments demonstrate that our method successfully comprehends observations with task-relevant symbolics to aid imitation learning. Importantly, ABIL demonstrates improved data efficiency and generalization across various long-horizon tasks, highlighting it as a promising solution for long-horizon planning. Project website: https://www.lamda.nju.edu.cn/shaojj/KDD25_ABIL/. | JieJing Shao, HaoRan Hao, XiaoWen Yang, YuFeng Li | National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China |
|  |  [Off-Policy Evaluation and Learning for the Future under Non-Stationarity](https://doi.org/10.1145/3690624.3709237) |  | 0 | We study the novel problem of future off-policy evaluation (F-OPE) and learning (F-OPL) for estimating and optimizing the future value of policies in non-stationary environments, where distributions vary over time. In e-commerce recommendations, for instance, our goal is often to estimate and optimize the policy value for the upcoming month using data collected by an old policy in the previous month. A critical challenge is that data related to the future environment is not observed in the historical data. Existing methods assume stationarity or depend on restrictive reward-modeling assumptions, leading to significant bias. To address these limitations, we propose a novel estimator named Off-Policy Estimator for the Future Value (OPFV), designed for accurately estimating policy values at any future time point. The key feature of OPFV is its ability to leverage the useful structure within time-series data. While future data might not be present in the historical log, we can leverage, for example, seasonal, weekly, or holiday effects that are consistent in both the historical and future data. Our estimator is the first to exploit these time-related structures via a new type of importance weighting, enabling effective F-OPE. Theoretical analysis identifies the conditions under which OPFV becomes low-bias. In addition, we extend our estimator to develop a new policy-gradient method to proactively learn a good future policy using only historical data. Empirical results show that our methods substantially outperform existing methods in estimating and optimizing the future policy value under non-stationarity for various experimental setups. | Tatsuhiro Shimizu, Kazuki Kawamura, Takanori Muroi, Yusuke Narita, Kei Tateno, Takuma Udagawa, Yuta Saito |  |
|  |  [Covering Cracks in Content Moderation: Delexicalized Distant Supervision for Illicit Drug Jargon Detection](https://doi.org/10.1145/3690624.3709183) |  | 0 | In light of rising drug-related concerns and the increasing role of social media, sales and discussions of illicit drugs have become commonplace online. Social media platforms hosting user-generated content must therefore perform content moderation, which is a difficult task due to the vast amount of jargon used in drug discussions. Previous works on drug jargon detection were limited to extracting a list of terms, but these approaches have fundamental problems in practical application. First, they are trivially evaded using word substitutions. Second, they cannot distinguish whether euphemistic terms such as "pot" or "crack" are being used as drugs or in their benign meanings. We argue that drug content moderation should be done using contexts rather than relying on a banlist. However, manually annotated datasets for training such a task are not only expensive but also prone to becoming obsolete. We present JEDIS, a framework for detecting illicit drug jargon terms by analyzing their contexts. JEDIS utilizes a novel approach that combines distant supervision and delexicalization, which allows JEDIS to be trained without human-labeled data while being robust to new terms and euphemisms. Experiments on two manually annotated datasets show JEDIS significantly outperforms state-of-the-art word-based baselines in terms of F1-score and detection coverage in drug jargon detection. We also conduct qualitative analysis that demonstrates JEDIS is robust against pitfalls faced by existing approaches. | Minkyoo Song, Eugene Jang, Jaehan Kim, Seungwon Shin |  |
|  |  [Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change](https://doi.org/10.1145/3690624.3709300) |  | 0 | Counterfactual explanations (CFEs) guide users on how to adjust inputs to machine learning models to achieve desired outputs. While existing research primarily addresses static scenarios, real-world applications often involve data or model changes, potentially invalidating previously generated CFEs and rendering user-induced input changes ineffective. Current methods addressing this issue often support only specific models or change types, require extensive hyperparameter tuning, or fail to provide probabilistic guarantees on CFE robustness to model changes. This paper proposes a novel approach for generating CFEs that provides probabilistic guarantees for any model and change type, while offering interpretable and easy-to-select hyperparameters. We establish a theoretical framework for probabilistically defining robustness to model change and demonstrate how our BetaRCE method directly stems from it. BetaRCE is a post-hoc method applied alongside a chosen base CFE generation method to enhance the quality of the explanation beyond robustness. It facilitates a transition from the base explanation to a more robust one with user-adjusted probability bounds. Through experimental comparisons with baselines, we show that BetaRCE yields robust, most plausible, and closest to baseline counterfactual explanations. | Ignacy Stepka, Jerzy Stefanowski, Mateusz Lango |  |
|  |  [Handling Feature Heterogeneity with Learnable Graph Patches](https://doi.org/10.1145/3690624.3709242) |  | 0 | In recent years, the rapid development of foundation models and graph pre-training technologies has spurred increasing interest in constructing a universal pre-trained graph model or Graph Foundation Model (GFM). However, a significant challenge is that existing models are unable to address feature heterogeneity in graph data without textual information, which hinders the transferability of graph models across different datasets. To bridge this gap, we propose the concept of learnable graph patches, which we regard as the smallest semantic units of any graph data. We decompose the graph into learnable graph patches by unfolding the node features and constructing corresponding patch structures separately. We then design PatchNet, a framework that mines transferable information from graph data across domains. Specifically, after extracting graph patches, we propose a patch encoder to extract knowledge from each unit and a patch aggregator to learn how the units are combined into a whole. Due to its domain-agnostic nature, the model can be applied to downstream data across different domains. Furthermore, we analyze the connection between PatchNet and existing graph models, as well as the transferability of the node embeddings it generates. Empirically, our method not only achieves the capability to use multi-domain graphs for pre-training, but also shows enhanced performance across various downstream datasets and tasks. Moreover, we observe consistent improvement in downstream performance as the volume of pre-training data increases. | Yifei Sun, Yang Yang, Xiao Feng, Zijun Wang, Haoyang Zhong, Chunping Wang, Lei Chen | Zhejiang University, Hangzhou, China; Finvolution Group, Shanghai, China; Huazhong University of Science and Technology, Wuhan, China |
|  |  [A Unified Invariant Learning Framework for Graph Classification](https://doi.org/10.1145/3690624.3709203) |  | 0 | Invariant learning demonstrates substantial potential for enhancing the generalization of graph neural networks (GNNs) with out-of-distribution (OOD) data. It aims to recognize stable features in graph data for classification, based on the premise that these features causally determine the target label, and their influence is invariant to changes in distribution. Along this line, most studies have attempted to pinpoint these stable features by emphasizing explicit substructures in the graph, such as masked or attentive subgraphs, and primarily enforcing the invariance principle in the semantic space, i.e., graph representations. However, we argue that focusing only on the semantic space may not accurately identify these stable features. To address this, we introduce the Unified Invariant Learning (UIL) framework for graph classification. It provides a unified perspective on invariant graph learning, emphasizing both structural and semantic invariance principles to identify more robust stable features. In the graph space, UIL adheres to the structural invariance principle by reducing the distance between graphons over a set of stable features across different environments. Simultaneously, to confirm semantic invariance, UIL underscores that the acquired graph representations should demonstrate exemplary performance across diverse environments. We present both theoretical and empirical evidence to confirm our method's ability to recognize superior stable features. Moreover, through a series of comprehensive experiments complemented by in-depth analyses, we demonstrate that UIL considerably enhances OOD generalization, surpassing the performance of leading baseline methods. Our codes are available at https://github.com/yongduosui/UIL. | Yongduo Sui, Jie Sun, Shuyao Wang, Zemin Liu, Qing Cui, Longfei Li, Xiang Wang |  |
|  |  [CLEAR: Addressing Representation Contamination in Multimodal Healthcare Analytics](https://doi.org/10.1145/3690624.3709164) |  | 0 | Electronic health records (EHRs) are the de facto standard for analyzing comprehensive patient conditions. Existing methods mainly employ specialized neural networks to extract modality-specific information, followed by modality correlation modeling to support clinical decision-making. However, these methods generally overlook the issue of ''contaminated'' representations inherent in routine EHR data, which can undermine the model's discriminative ability, as less relevant representations associated with false positive correlations may impede the recognition of truly effective representations. To address the issue of representation contamination, we propose CLEAR, a counterfactual disparity learning model for explicit multimodal EHR analytics. The core idea is to first model the contamination in representations, and subsequently perform calibration and enhancement to construct highly discriminative representations. Specifically, CLEAR first proposes the Counterfactual Prompt Learning Module to capture the representation discrepancy to model representation contamination. Subsequently, an Adaptive Dynamic Imputation Module is devised to decouple the elementwise representations for representation calibration, while a gating mechanism is further proposed to incorporate discriminative discrepancy information for representation enhancement. Finally, the Multimodal Representation Fusion Module establishes intra- and inter-modality correlations, thereby creating a seamless integration towards downstream analytic tasks. To our knowledge, CLEAR is the first to model and resolve representation contamination in multimodal EHR analytics. Experimental results on two real-world datasets demonstrate that CLEAR consistently outperforms state-of-the-art baselines in facilitating multimodal healthcare analytics. | Ge Su, Kaiping Zheng, Tiancheng Zhao, Jianwei Yin | Binjiang Institute of Zhejiang University, Hangzhou, Zhejiang, China; Zhejiang University, Hangzhou, Zhejiang, China; National University of Singapore, Singapore, Singapore |
|  |  [Spatially Compact Dense Block Mining in Spatial Tensors](https://doi.org/10.1145/3690624.3709221) |  | 0 | Spatial tensors have been extensively used in a wide range of applications, including remote sensing, geospatial information systems, conservation planning, and urban planning. We study the problem of Spatially Compact Dense (SCD) block mining in a spatial tensor, which targets for discovering dense blocks that cover small spatial regions. However, most of existing dense block mining (DBM) algorithms cannot solve the SCD-block mining problem since they only focus on maximizing the density of candidate blocks, so that the discovered blocks are spatially loose, i.e., covering large spatial regions. Therefore, we first formulate the problem of mining top-k Spatially Compact Dense blocks (SCD-blocks) in spatial tensors, which ranks SCD-blocks based on a new scoring function that takes both the density value and the spatial coverage into account. Then, we adopt a filter-refinement framework that first generates candidate SCD-blocks with good scores in the filtering phase and then uses the traditional DBM algorithm to further maximize the density values of the candidates in the refinement phase. Due to the NP-hardness of the problem, we develop two types of solutions in the filtering phase, namely the top-down solution and the bottom-up solution, which can find good candidate SCD-blocks by approximately solving the new scoring function. The evaluations on four real datasets verify that compared with the dense blocks returned by existing DBM algorithms, the proposed solutions are able to find SCD-blocks with comparable density values and significantly smaller spatial coverage. | Weike Tang, Dingming Wu, Tsz Nam Chan, Kezhong Lu | College of Computer Science & Software Engineering, Shenzhen University, Shenzhen, China |
|  |  [GROOT: Effective Design of Biological Sequences with Limited Experimental Data](https://doi.org/10.1145/3690624.3709291) |  | 0 | Latent space optimization (LSO) is a powerful method for designing discrete, high-dimensional biological sequences that maximize expensive black-box functions, such as wet lab experiments. This is accomplished by learning a latent space from available data and using a surrogate model to guide optimization algorithms toward optimal outputs. However, existing methods struggle when labeled data is limited, as training the surrogate model with few labeled data points can lead to subpar outputs, offering no advantage over the training data itself. We address this challenge by introducing GROOT, a Graph-based Latent Smoothing for Biological Sequence Optimization. In particular, GROOT generates pseudo-labels for neighbors sampled around the training latent embeddings. These pseudo-labels are then refined and smoothed by Label Propagation. Additionally, we theoretically and empirically justify our approach, demonstrate GROOT's ability to extrapolate to regions beyond the training set while maintaining reliability within an upper bound of their expected distances from the training regions. We evaluate GROOT on various biological sequence design tasks, including protein optimization (GFP and AAV) and three tasks with exact oracles from Design-Bench. The results demonstrate that GROOT equalizes and surpasses existing methods without requiring access to black-box oracles or vast amounts of labeled data, highlighting its practicality and effectiveness. We release our code at https://anonymous.4open.science/r/GROOT-D554 | Thanh V. T. Tran, Nhat Khang Ngo, Viet Anh Nguyen, Truong Son Hy |  |
|  |  [How Well Calibrated are Extreme Multi-label Classifiers? An Empirical Analysis](https://doi.org/10.1145/3690624.3709333) |  | 0 | Extreme multilabel classification (XMLC) problems occur in settings such as related product recommendation, large-scale document tagging, or ad prediction, and are characterized by a label space that can span millions of possible labels. There are two implicit tasks that the classifier performs: Evaluating each potential label for its expected worth, and then selecting the best candidates. For the latter task, only the relative order of scores matters, and this is what is captured by the standard evaluation procedure in the XMLC literature. However, in many practical applications, it is important to have a good estimate of the actual probability of a label being relevant, e.g., to decide whether to pay the fee to be allowed to display the corresponding ad. To judge whether an extreme classifier is indeed suited to this task, one can look, for example, to whether it returns calibrated probabilities, which has hitherto not been done in this field. Therefore, this paper aims to establish the current status quo of calibration in XMLC by providing a systematic evaluation, comprising nine models from four different model families across seven benchmark datasets. As naive application of Expected Calibration Error (ECE) leads to meaningless results in long-tailed XMC datasets, we instead introduce the notion of calibration@k (e.g., ECE@k), which focusses on the top-k probability mass, offering a more appropriate measure for evaluating probability calibration in XMLC scenarios. While we find that different models can exhibit widely varying reliability plots, we also show that post-training calibration via a computationally efficient isotonic regression method enhances model calibration without sacrificing prediction accuracy. Thus, the practitioner can choose the model family based on accuracy considerations, and leave calibration to isotonic regression. | Nasib Ullah, Erik Schultheis, Jinbin Zhang, Rohit Babbar | University of Bath, Bath, United Kingdom, and Aalto University, Espoo, Finland; Aalto University, Espoo, Finland |
|  |  [Interpretable Prediction and Feature Selection for Survival Analysis](https://doi.org/10.1145/3690624.3709245) |  | 0 | Survival analysis is widely used as a technique to model time-to-event data when some data is censored, particularly in healthcare for predicting future patient risk. In such settings, survival models must be both accurate and interpretable so that users (such as doctors) can trust the model and understand model predictions. While most literature focuses on discrimination, interpretability is equally as important. A successful interpretable model should be able to describe how changing each feature impacts the outcome, and should only use a small number of features. In this paper, we present DyS (pronounced \`\`dice''), a new survival analysis model that achieves both strong discrimination and interpretability. DyS is a feature-sparse Generalized Additive Model, combining feature selection and interpretable prediction into one model. While DyS works well for all survival analysis problems, it is particularly useful for large (in $n$ and $p$) survival datasets such as those commonly found in observational healthcare studies. Empirical studies show that DyS competes with other state-of-the-art machine learning models for survival analysis, while being highly interpretable. | Mike Van Ness, Madeleine Udell | Stanford University Stanford |
|  |  [Asymmetrical Reciprocity-based Federated Learning for Resolving Disparities in Medical Diagnosis](https://doi.org/10.1145/3690624.3709235) |  | 0 | Geographic health disparities pose a pressing global challenge, particularly in underserved regions of low- and middle-income nations. Addressing this issue requires a collaborative approach to enhance healthcare quality, leveraging support from medically more developed areas. Federated learning emerges as a promising tool for this purpose. However, the scarcity of medical data and limited computation resources in underserved regions make collaborative training of powerful machine learning models challenging. Furthermore, there exists an asymmetrical reciprocity between underserved and developed regions. To overcome these challenges, we propose a novel cross-silo federated learning framework, named FedHelp, aimed at alleviating geographic health disparities and fortifying the diagnostic capabilities of underserved regions. Specifically, FedHelp leverages foundational model knowledge via one-time API access to guide the learning process of underserved small clients, addressing the challenge of insufficient data. Additionally, we introduce a novel asymmetric dual knowledge distillation module to manage the issue of asymmetric reciprocity, facilitating the exchange of necessary knowledge between developed large clients and underserved small clients. We validate the effectiveness and utility of FedHelp through extensive experiments on both medical image classification and segmentation tasks. The experimental results demonstrate significant performance improvement compared to state-of-the-art baselines, particularly benefiting clients in underserved regions. | Jiaqi Wang, Ziyi Yin, Quanzeng You, Lingjuan Lyu, Fenglong Ma |  |
|  |  [CoopRide: Cooperate All Grids in City-Scale Ride-Hailing Dispatching with Multi-Agent Reinforcement Learning](https://doi.org/10.1145/3690624.3709205) |  | 0 | Ride-hailing services offer convenient travel options in urban transportation. To improve passengers' experience and platforms' revenue, plentiful studies use multi-agent reinforcement learning (MARL) for efficient order dispatching, controlling each grid with one agent to balance the supply-demand (drivers-orders) distribution. However, despite the critical role of cooperation among grids for efficient dispatching strategies, existing works neglect it or limit it within neighboring grids. There exist three key challenges in scaling the cooperation to the whole city: (1) cooperative strategies cause complex interactions among grids, making the grids' states coupled and complicating the information extraction from the states for decision-making; (2) cooperation among grids requires both within- and cross-grid dispatching, where the priorities of these two types of actions are difficult to balance; (3) the value of cooperation is not only heterogeneous over different pairs of grids, but also varies temporally, adding difficulty to dynamically determine the intensities of cooperation for each pair of grids and obtain the global cooperation rewards. In this paper, we propose the CoopRide framework to solve the above challenges. We model the interactions among agents with graphs and utilize graph neural network (GNN) for efficient information extraction. We uniformly encode both within- and cross-grid dispatching, enabling flexible choice of both types of actions in the embedding space. We also design to automatically learn the cooperation intensities among grids, thereby obtaining the cooperative rewards to drive the learning of global cooperation actions. We conduct experiments in three real-world datasets with millions of orders, and extensive results demonstrate the superior performance of CoopRide, outperforming the state-of-the-art baselines by up to 12.4%. Our source codes are available at https://github.com/tsinghua-fib-lab/CoopRide. | Jingwei Wang, Qianyue Hao, Wenzhen Huang, Xiaochen Fan, Qin Zhang, Zhentao Tang, Bin Wang, Jianye Hao, Yong Li | College of Computer Science and Software Engineering, Shenzhen University, Shenzhen City, China; Huawei Noah's Ark Lab, Beijing, China; IEIT in Tianjin, Department of EE, BNRist, Tsinghua University, Tianjin, China; Department of EE, BNRist, Tsinghua University, Beijing, China; Tianjin University, Tianjin, China & Huawei Noah's Ark Lab, Beijing, China |
|  |  [Robust Fast Adaptation from Adversarially Explicit Task Distribution Generation](https://doi.org/10.1145/3690624.3709337) |  | 0 | Meta-learning is a practical learning paradigm to transfer skills across tasks from a few examples. Nevertheless, the existence of task distribution shifts tends to weaken meta-learners' generalization capability, particularly when the task distribution is naively hand-crafted or based on simple priors that fail to cover typical scenarios sufficiently. Here, we consider explicitly generative modeling task distributions placed over task identifiers and propose robustifying fast adaptation from adversarial training. Our approach, which can be interpreted as a model of a Stackelberg game, not only uncovers the task structure during problem-solving from an explicit generative model but also theoretically increases the adaptation robustness in worst cases. This work has practical implications, particularly in dealing with task distribution shifts in meta-learning, and contributes to theoretical insights in the field. Our method demonstrates its robustness in the presence of task subpopulation shifts and improved performance over SOTA baselines in extensive experiments. The project is available at https://sites.google.com/view/ar-metalearn. | Qi (Cheems) Wang, Yiqin Lv, Yixiu Mao, Yun Qu, Yi Xu, Xiangyang Ji |  |
|  |  [An Efficient Diffusion-based Non-Autoregressive Solver for Traveling Salesman Problem](https://doi.org/10.1145/3690624.3709343) |  | 0 | Recent advances in neural models have shown considerable promise in solving Traveling Salesman Problems (TSPs) without relying on much hand-crafted engineering. However, while non-autoregressive (NAR) approaches benefit from faster inference through parallelism, they typically deliver solutions of inferior quality compared to autoregressive ones. To enhance the solution quality while maintaining fast inference, we propose DEITSP, a diffusion model with efficient iterations tailored for TSP that operates in a NAR manner. Firstly, we introduce a one-step diffusion model that integrates the controlled discrete noise addition process with self-consistency enhancement, enabling optimal solution prediction through simultaneous denoising of multiple solutions. Secondly, we design a dual-modality graph transformer to bolster the extraction and fusion of features from node and edge modalities, while further accelerating the inference with fewer layers. Thirdly, we develop an efficient iterative strategy that alternates between adding and removing noise to improve exploration compared to previous diffusion methods. Additionally, we devise a scheduling framework to progressively refine the solution space by adjusting noise levels, facilitating a smooth search for optimal solutions. Extensive experiments on real-world and large-scale TSP instances demonstrate that DEITSP performs favorably against existing neural approaches in terms of solution quality, inference latency, and generalization ability. Our code is available at $\href{https://github.com/DEITSP/DEITSP}{https://github.com/DEITSP/DEITSP}$. | Mingzhao Wang, You Zhou, Zhiguang Cao, Yubin Xiao, Xuan Wu, Wei Pang, Yuan Jiang, Hui Yang, Peng Zhao, Yuanshu Li |  |
|  |  [GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction](https://doi.org/10.1145/3690624.3709238) |  | 0 | Large language models (LLMs) have been demonstrated to possess the capabilities to understand fundamental graph properties and address various graph reasoning tasks. Existing methods fine-tune LLMs to understand and execute graph reasoning tasks by specially designed task instructions. However, these Text-Instruction methods generally exhibit poor performance. Inspired by tool learning, researchers propose Tool-Instruction methods to solve various graph problems by special tool calling (e.g., function, API and model), achieving significant improvements in graph reasoning tasks. Nevertheless, current Tool-Instruction approaches focus on the tool information and ignore the graph structure information, which leads to significantly inferior performance on small-scale LLMs (less than 13B). To tackle this issue, we propose GraphTool-Instruction, an innovative Instruction-tuning approach that decomposes the graph reasoning task into three distinct subtasks (i.e., graph extraction, tool name identification and tool parameter extraction), and design specialized instructions for each subtask. Our GraphTool-Instruction can be used as a plug-and-play prompt for different LLMs without fine-tuning. Moreover, building on GraphTool-Instruction, we develop GTools, a dataset that includes twenty graph reasoning tasks, and create a graph reasoning LLM called GraphForge based on Llama3-8B. We conduct extensive experiments on twenty graph reasoning tasks with different graph types (e.g., graph size or graph direction), and we find that GraphTool-Instruction achieves SOTA compared to Text-Instruction and Tool-Instruction methods. Fine-tuned on GTools, GraphForge gets further improvement of over 30 GPT-3.5-turbo, and it performs comparably to the high-cost GPT-4o. Our codes and data are available at https://anonymous.4open.science/r/GraphTool-Instruction. | Rongzheng Wang, Shuang Liang, Qizhi Chen, Jiasheng Zhang, Ke Qin |  |
|  |  [Graph Triple Attention Networks: A Decoupled Perspective](https://doi.org/10.1145/3690624.3709223) |  | 0 | Graph Transformers (GTs) have recently achieved significant success in the graph domain by effectively capturing both long-range dependencies and graph inductive biases. However, these methods face two primary challenges: (1) multi-view chaos, which results from coupling multi-view information (positional, structural, attribute), thereby impeding flexible usage and the interpretability of the propagation process. (2) local-global chaos, which arises from coupling local message passing with global attention, leading to issues of overfitting and over-globalizing. To address these challenges, we propose a high-level decoupled perspective of GTs, breaking them down into three components and two interaction levels: positional attention, structural attention, and attribute attention, alongside local and global interaction. Based on this decoupled perspective, we design a decoupled graph triple attention network named DeGTA, which separately computes multi-view attentions and adaptively integrates multi-view local and global information. This approach offers three key advantages: enhanced interpretability, flexible design, and adaptive integration of local and global information. Through extensive experiments, DeGTA achieves state-of-the-art performance across various datasets and tasks, including node classification and graph classification. Comprehensive ablation studies demonstrate that decoupling is essential for improving performance and enhancing interpretability. Our code is available at: https://github.com/wangxiaotang0906/DeGTA | Xiaotang Wang, Yun Zhu, Haizhou Shi, Yongchao Liu, Chuntao Hong |  |
|  |  [Runtime-Aware Pipeline for Vertical Federated Learning with Bounded Model Staleness](https://doi.org/10.1145/3690624.3709243) |  | 0 | Vertical federated learning (VFL) enables a privacy-preserving collaboration among various parties to train a global model by melding their geo-distributed data features. Communication has been recognized as the primary bottleneck that impairs training efficiency due to frequent cross-party statistics exchange over wide area network. Existing synchronous VFL works often suffer from excessive communication overhead, while asynchronous schemes may introduce significant model staleness, potentially eroding the learning accuracy. In this paper, we propose BS-VFL, an asynchronous VFL with bounded staleness, to pipeline local computation and statistics transmission, substantially reducing the communication overhead while ensuring favorable model performance. Specifically, all data parties will give precedence to local model updates before generating embeddings to curtail model staleness. By analyzing convergence error, we show that BS-VFL can achieve a comparable result to synchronous VFL. Then, we develop a general framework to derive the closed-form wall-clock time of BS-VFL, offering a measure of its runtime efficiency and highlighting a marked communication reduction. Utilizing this convergence and time analysis, we refine learning parameters to minimize the convergence error for optimizing BS-VFL performance without compromising training efficiency. Extensive experiments on real-world datasets validate the superiority of BS-VFL over leading-edge methods, evidencing a reduction in training duration by 48%-90% while preserving model accuracy. | Xiong Wang, Yi Zhang, Yuxin Chen, Yuqing Li, Chuanhu Ma, Bo Li, Hai Jin | School of Cyber Science and Engineering, Wuhan University, Wuhan, Hubei, China |
|  |  [Noise-Resilient Point-wise Anomaly Detection in Time Series Using Weak Segment Labels](https://doi.org/10.1145/3690624.3709257) |  | 0 | Detecting anomalies in temporal data has gained significant attention across various real-world applications, aiming to identify unusual events and mitigate potential hazards. In practice, situations often involve a mix of segment-level labels (detected abnormal events with segments of time points) and unlabeled data (undetected events), while the ideal algorithmic outcome should be point-level predictions. Therefore, the huge label information gap between training data and targets makes the task challenging. In this study, we formulate the above imperfect information as noisy labels and propose NRdetector, a noise-resilient framework that incorporates confidence-based sample selection, robust segment-level learning, and data-centric point-level detection for multivariate time series anomaly detection. Particularly, to bridge the information gap between noisy segment-level labels and missing point-level labels, we develop a novel loss function that can effectively mitigate the label noise and consider the temporal features. It encourages the smoothness of consecutive points and the separability of points from segments with different labels. Extensive experiments on real-world multivariate time series datasets with 11 different evaluation metrics demonstrate that NRdetector consistently achieves robust results across multiple real-world datasets, outperforming various baselines adapted to operate in our setting. | Yaxuan Wang, Hao Cheng, Jing Xiong, Qingsong Wen, Han Jia, Ruixuan Song, Liyuan Zhang, Zhaowei Zhu, Yang Liu |  |
|  |  [FLMarket: Enabling Privacy-preserved Pre-training Data Pricing for Federated Learning](https://doi.org/10.1145/3690624.3709346) |  | 0 | Federated Learning (FL), as a mainstream privacy-preserving machine learning paradigm, offers promising solutions for privacy-critical domains such as healthcare and finance. Although extensive efforts have been dedicated from both academia and industry to improve the vanilla FL, little work focuses on the data pricing mechanism. In contrast to the straightforward in/post-training pricing techniques, we study a more difficult problem of pre-training pricing without direct information from the learning process. We propose FLMarket that integrates a two-stage, auction-based pricing mechanism with a security protocol to address the utility-privacy conflict. Through comprehensive experiments, we show that the client selection according to FLMarket can achieve more than 10 state-of-the-art methods. In addition, it outperforms the in-training baseline with more than 2 | Zhenyu Wen, Wanglei Feng, Di Wu, Haozhen Hu, Chang Xu, Bin Qian, Zhen Hong, Cong Wang, Shouling Ji |  |
|  |  [Feature Selection for Network Intrusion Detection](https://doi.org/10.1145/3690624.3709339) |  | 0 | Network intrusion detection is the process of identifying malicious activity in a network by analyzing the network traffic behavior. Data mining techniques are widely used in Intrusion Detection System (IDS) to detect anomalies. Dimensionality reduction plays a vital role in IDS, since detecting anomalies from high dimensional network traffic feature is time-consuming process. Feature selection influences the speed of the analysis and the proposed work, deploys filter and wrapper based method with firefly algorithm in the wrapper for selecting the features. The resulting features are subjected to C4.5 and Bayesian Networks (BN) based classifier with KDD CUP 99 dataset. The experimental results show that 10 features are sufficient to detect the intrusion showing improved accuracy. The proposed work is compared with the existing work showing promising improvements. | Charles Westphal, Stephen Hailes, Mirco Musolesi | Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Sivakasi, Tamil Nadu, India |
|  |  [Classifying Treatment Responders: Bounds and Algorithms](https://doi.org/10.1145/3690624.3709191) |  | 0 | Treatment responders are individuals whose outcomes would change from negative to positive if treated, and learning a classifier to predict responders would help causal decision-making in real applications. Although many treatment effect estimation methods have been proposed to identify treatment responders, there are fundamental differences between treatment effect estimation and treatment responder classification, including: (1) accurate causal effect estimation is not necessary for optimal intervention decisions; (2) methods for accurate causal effect estimation do not directly optimize classification loss; (3) treatment responder classification requires identifying joint potential outcomes, while treatment effect estimation focuses on marginal distributions. To fill this gap, we tackle the treatment responder classification problem without assuming monotonicity. We derive sharp bounds of the probability that an individual is a responder and determine a sharp upper bound on the weighted classification risk to measure the worst classification performance. Based on these findings, we further propose a Classifying Treatment Responder Learning (CTRL) algorithm to accurately identify the treatment responders, and theoretically demonstrate the superiority of jointly learning over two-stage learning. Extensive experiments on semi-synthetic and real-world datasets show that our method better predicts treatment responders and adaptively trades off false-positives and false-negatives with varying weight coefficients. | Anpeng Wu, Haoxuan Li, Chunyuan Zheng, Kun Kuang, Kun Zhang | Zhejiang University, Hangzhou, China; CMU, Pittsburgh, USA & MBZUAI, Abu Dhabi, United Arab Emirates; Zhejiang University, Hangzhou, China & MBZUAI, Abu Dhabi, United Arab Emirates; Peking University, Beijing, China & MBZUAI, Abu Dhabi, United Arab Emirates |
|  |  [Breaking the Memory Wall for Heterogeneous Federated Learning via Progressive Training](https://doi.org/10.1145/3690624.3709284) |  | 0 | This paper presents ProFL, a new framework that effectively addresses the memory constraints in FL. Rather than updating the full model during local training, ProFL partitions the model into blocks based on its original architecture and trains each block in a progressive fashion. It first trains the front blocks and safely freezes them after convergence. Training of the next block is then triggered. This process progressively grows the model to be trained until the training of the full model is completed. In this way, the peak memory footprint is effectively reduced for feasible deployment on heterogeneous devices. In order to preserve the feature representation of each block, the training process is divided into two stages: model shrinking and model growing. During the model shrinking stage, we meticulously design corresponding output modules to assist each block in learning the expected feature representation and obtain the initialization model parameters. Subsequently, the obtained output modules and initialization model parameters are utilized in the corresponding model growing stage, which progressively trains the full model. Additionally, a novel metric from the scalar perspective is proposed to assess the learning status of each block, enabling us to securely freeze it after convergence and initiate the training of the next one. Finally, we theoretically prove the convergence of ProFL and conduct extensive experiments on representative models and datasets to evaluate its effectiveness. The results demonstrate that ProFL effectively reduces the peak memory footprint by up to 57.4 | Yebo Wu, Li Li, ChengZhong Xu | University of Macau State Key Lab of IoTSC |
|  |  [ProgDiffusion: Progressively Self-encoding Diffusion Models](https://doi.org/10.1145/3690624.3709222) |  | 0 | Learning low-dimensional semantic representations in diffusion models (DMs) is an open task, since in standard DMs, the dimensions of its intermediate latents are the same as that of the observations and thus are unable to represent low-dimensional semantics. Existing methods address this task either by encoding observations into semantics which makes it difficult to generate samples without observations, or by synthesizing the U-Net's layers of pre-trained DMs into low-dimensional semantics, which is mainly used for downstream tasks rather than using semantics to facilitate the training process. Further, those generated static representations might not be aligned with dynamic timestep-wise intermediate latents. This work introduces a Progressive self-encoded Diffusion model (ProgDiffusion), which simultaneously learns semantic representations and reconstructs observations, does efficient unconditional generation, and produces progressively structured semantic representations. These benefits are gained by a novel self-encoder mechanism which takes the U-Net's upsampling features, intermediate latent and the denoising timestep as conditions to generate time-specific semantic representations, differing from existing work of conditioning on observations only. As a result, the learned intermediate latents are dynamic and mapped to a series of semantic representations that capture their gradual changes. Notably, our proposed encoder operates independently of the observations, making it feasible for unconditional generation as observations are not required. To evaluate ProgDiffusion, we design tasks to visualise the learned progressive semantic representations, in addition to other common tasks, which validate the effectiveness of ProgDiffusion against the state-of-the-art. The code is available at https://github.com/amasawa/ProgDiffusion. | Zhangkai Wu, Xuhui Fan, Longbing Cao | Macquarie University, Sydney, NSW, Australia |
|  |  [ProST: Prompt Future Snapshot on Dynamic Graphs for Spatio-Temporal Prediction](https://doi.org/10.1145/3690624.3709273) |  | 0 | Spatio-temporal prediction focuses on jointly modeling spatial correlations and temporal evolution and has a wide range of applications. Due to the heterogeneity of spatio-temporal data, accurate prediction relies on effectively integrating topological structures and sequential patterns. Although recurrent graph learning methods excel at capturing dynamic graph patterns, explicitly inferring future snapshots from historical dynamic graphs remains a significant challenge. Recently, prompt-based graph learning has shown the potential to improve future snapshot inference by leveraging node or task-specific prompts. However, these methods fail to fully capture edge information resulting in incomplete and less accurate representations of future snapshot structures. To bridge this gap, we propose ProST, a framework that Prompts future snapshots on dynamic graphs for Spatio-Temporal prediction, which leverages dynamic graph pre-training to generate a premise graph containing historical graph information and then employs prompts on the premise graph to infer explicit future snapshots. Specifically, this framework comprises three steps: Firstly, dynamic graph pre-training is performed using multi-granularity evolution graph convolution to obtain the premise graph with both local and global features of dynamic graphs. Secondly, prompt subgraphs are used to prompt node pairs and edge features within the premise graph. The subgraph prompt aggregation mechanism propagates this information to generate future snapshots. Finally, we freeze the parameters of the pre-trained model and update the subgraph prompt parameters using meta-learning to adapt to downstream spatio-temporal prediction tasks. Extensive experiments on real-world datasets validate that ProST achieves state-of-the-art performance. | Kaiwen Xia, Li Lin, Shuai Wang, Qi Zhang, Shuai Wang, Tian He | Southeast University, Nanjing, China, and JD Logistics, Beijing, China; Southeast University, Nanjing, China; JD Logistics, Beijing, China |
|  |  [ScalaGBM: Memory Efficient GBDT Training for High-Dimensional Data on GPU](https://doi.org/10.1145/3690624.3709271) |  | 0 | Gradient Boosted Decision Trees (GBDTs) are classical machine learning algorithms widely employed in recommendation systems, database queries, etc. Due to the extensive memory access involved in histogram-based GBDT training methods, high-bandwidth GPUs have been widely adopted to accelerate the training. However, when handling millions of feature data, it requires significant memory to store the training data and histograms, posing challenges for training on limited GPU memories. In this paper, we develop a GPU-based GBDT framework named ScalaGBM, aiming to accelerate high-dimensional data training with less memory usage. We first employ a CSR-like data format and CSR-based histogram construction to reduce the memory occupation of the training data. Then, we reorganize the training workflow with a double buffer structure to reduce the overall memory consumption for the histogram. Finally, we develop multi-dimensional parallel histogram construction and global optimal split point reduction to speed up the training process. Experimental results demonstrate that ScalaGBM handles real-world datasets with over 100 million instances of 50 million features with a single commercial GPU while existing GBDT frameworks all run into out-of-memory errors. Meanwhile, ScalaGBM achieves a maximum speedup of 39× over state-of-the-art GBDT counterparts without sacrificing the training quality. The code is available at https://github.com/Xtra-Computing/thundergbm. | Borui Xu, Zeyi Wen, Yao Chen, Weiguo Liu, WengFai Wong, Bingsheng He | Shandong University, Jinan, Shandong, China; Shandong University, Jinan, Shandong Province, China; National University of Singapore, Singapore, Singapore |
|  |  [Incremental Label Distribution Learning](https://doi.org/10.1145/3690624.3709318) |  | 0 | Label distribution learning (LDL) has large practical application potentials due to its superiority in dealing with ambiguous label information. Most existing LDL methods are designed in a closed environment, wherein all the elements, e.g., feature and label space, are fixed. Nevertheless, in reality, data are dynamically acquired in the open environment, wherein the feature space can accumulate over time and the label space can be further enriched and refined accordingly with the accumulated feature space. Conducting LDL for such simultaneous augmentation of feature and label is crucial but rarely studied, particularly when the labeled samples with full observations are limited. In this paper, we propose a novel Incremental Label Distribution Learning (ILDL) method to tackle this brand new LDL problem by continuously transiting discriminative information from the previous model to the current one. Concretely, a prior compensation regularization is designed for such discriminative information transitivity. In this manner, the current model has the capacity to reuse the previous model to guide its own training. Furthermore, we present the theoretical analyses about the generalization bound, which provides guarantees for model inheritance. Comprehensive experimental studies validate the effectiveness of our proposal. | Chao Xu, Xijia Tang, Hong Tao, Chenping Hou | National University of Defense Technology, Changsha, Hunan, China |
|  |  [Neural Network Pruning for Invariance Learning](https://doi.org/10.1145/3690624.3709262) |  | 0 | Model scaling laws have driven the development of neural networks with more-and-more parameters. As a result, there is a growing need for neural network pruning to enable the efficient deployment during inference. We take a deeper look at neural network pruning from the lens of invariance preservation. We argue that successfully pruned neural networks should be invariant to transformations which do not alter the data's underlying semantics (ex. translations). To this goal, we first show existing post-pruning algorithms do not perserve desired invariances. We then propose a framework to discover novel architectures that do capture desired invariances from data via pruning. Specifically, we show contrastive learning with small initialization can effectively transfer invariance preservation encoded in the model weights to the pruning mask. Our approach consistently outperform traditional pruning algorithms on fully-connected, convolutional, and transformer networks across 3 vision, 40 tabular, and 1 natural language datasets. | Derek Xu, Yuanzhou Chen, Yizhou Sun, Wei Wang | University of California, Los Angeles, Los Angeles, CA, USA |
|  |  [Succinct Interaction-Aware Explanations](https://doi.org/10.1145/3690624.3709175) |  | 0 | SHAP is a popular approach to explain black-box models by revealing theimportance of individual features. As it ignores feature interactions, SHAPexplanations can be confusing up to misleading. NSHAP, on the other hand,reports the additive importance for all subsets of features. While this doesinclude all interacting sets of features, it also leads to an exponentiallysized, difficult to interpret explanation. In this paper, we propose to combinethe best of these two worlds, by partitioning the features into parts thatsignificantly interact, and use these parts to compose a succinct,interpretable, additive explanation. We derive a criterion by which to measurethe representativeness of such a partition for a models behavior, traded offagainst the complexity of the resulting explanation. To efficiently find thebest partition out of super-exponentially many, we show how to prunesub-optimal solutions using a statistical test, which not only improves runtimebut also helps to detect spurious interactions. Experiments on synthetic andreal world data show that our explanations are both more accurate resp. moreeasily interpretable than those of SHAP and NSHAP. | Sascha Xu, Joscha Cüppers, Jilles Vreeken | CISPA Helmholtz Center for Information Security |
|  |  [MM-Path: Multi-modal, Multi-granularity Path Representation Learning](https://doi.org/10.1145/3690624.3709209) |  | 0 | Developing effective path representations has become increasingly essential across various fields within intelligent transportation. Although pre-trained path representation learning models have shown improved performance, they predominantly focus on the topological structures from single modality data, i.e., road networks, overlooking the geometric and contextual features associated with path-related images, e.g., remote sensing images. Similar to human understanding, integrating information from multiple modalities can provide a more comprehensive view, enhancing both representation accuracy and generalization. However, variations in information granularity impede the semantic alignment of road network-based paths (road paths) and image-based paths (image paths), while the heterogeneity of multi-modal data poses substantial challenges for effective fusion and utilization. In this paper, we propose a novel Multi-modal, Multi-granularity Path Representation Learning Framework (MM-Path), which can learn a generic path representation by integrating modalities from both road paths and image paths. To enhance the alignment of multi-modal data, we develop a multi-granularity alignment strategy that systematically associates nodes, road sub-paths, and road paths with their corresponding image patches, ensuring the synchronization of both detailed local information and broader global contexts. To address the heterogeneity of multi-modal data effectively, we introduce a graph-based cross-modal residual fusion component designed to comprehensively fuse information across different modalities and granularities. Finally, we conduct extensive experiments on two large-scale real-world datasets under two downstream tasks, validating the effectiveness of the proposed MM-Path. This is an extended version of the paper accepted by KDD 2025. | Ronghui Xu, Hanyin Cheng, Chenjuan Guo, Hongfan Gao, Jilin Hu, Bin Yang |  |
|  |  [Fast and Accurate Temporal Hypergraph Representation for Hyperedge Prediction](https://doi.org/10.1145/3690624.3709327) |  | 0 | Temporal hypergraph representation learning is a concept that integrates high-order structure learning with temporal dynamics, enabling more accurate analysis of temporal and high-order interactions. To enhance model expressiveness, the latest work samples multi-hop hyperedge-centric neighbors directly from temporal hypergraphs and encodes them for high-order structure learning, achieving promising performance. Such modeling, however, incurs prohibitive computational complexity, which increases exponentially with model depth and quadratically with average hyperedge cardinality, thereby limiting model scalability. In this paper, we propose FastHeP, a fast and accurate approach for temporal hyperedge prediction, which can handle large temporal hypergraphs. The key idea is to minimize computational complexity while maintaining model expressiveness. Concretely, we design an online hyperedge-centric neighbor store, which can store time-aware and redundancy-aware neighbors for nodes with rational theoretical guarantees. Upon the neighbor store, we propose a novel hybrid message passing to model temporal high-order structures, theoretically preserving strong expressive power. This explicitly learns local high-order structures for nodes of each hyperedge via graph attention, generating the node-wise structure features. These structure features are then fused into global correlations modeling among hyperedges, with a theoretical guarantee of permutation invariance. Last, FastHeP leverages local and global high-order semantics to generate temporal hyperedge embeddings, which is efficient in a linear complexity w.r.t. model depth and average hyperedge cardinality. Extensive experiments show that FastHeP achieves up to two orders of magnitude speed-up against baselines, with an average accuracy improvement of 5.1%. | Yuanyuan Xu, Wenjie Zhang, Ying Zhang, Xiwei Xu, Xuemin Lin | University of New South Wales, Sydney, NSW, Australia; Shanghai Jiao Tong University, Shanghai, China; Zhejiang Gongshang University, Hangzhou, Zhejiang, China; CSIRO Data61, Eveleigh, NSW, Australia |
|  |  [Learning Universal Multi-level Market Irrationality Factors to Improve Stock Return Forecasting](https://doi.org/10.1145/3690624.3709328) |  | 0 | Recent years have witnessed the perfect encounter of deep learning and quantitative trading has achieved great success in stock investment. Numerous deep learning-based models have been developed for forecasting stock returns, leveraging the powerful representation capabilities of neural networks to identify patterns and factors influencing stock prices. These models can effectively capture general patterns in the market, such as stock price trends, volume-price relationships, and time variations. However, the impact of special irrationality factors – such as market sentiment, speculative behavior, market manipulation, and psychological biases – have not been fully considered in existing deep stock forecasting models due to their relative abstraction as well as lack of explicit labels and data description. To fill this gap, we propose UMI, a Universal multi-level Market Irrationality factor model to enhance stock return forecasting. The UMI model learns factors that can reflect irrational behaviors in market from both individual stock and overall market levels. For the stock-level, UMI construct an estimated rational price for each stock, which is cointegrated with the stock's actual price. The discrepancy between the actual and the rational prices serves as a factor to indicate stock-level irrational events. Additionally, we define market-level irrational behaviors as anomalous synchronous fluctuations of stocks within a market. Using two self-supervised representation learning tasks, i.e., sub-market comparative learning and market synchronism prediction, the UMI model incorporates market-level irrationalities into a market representation vector, which is then used as the market-level irrationality factor. | Chen Yang, Jingyuan Wang, Xiaohan Jiang, Junjie Wu |  |
|  |  [Causal Discovery from Shifted Multiple Environments](https://doi.org/10.1145/3690624.3709247) |  | 0 | A fundamental problem in many science domains is learning the causal structure of a system from observed data. The observed data canonically come from multiple environments (i.e. different times, locations, and measurements), and causal models may have unobserved shifts. Although the causal graphs can be identified by modeling the distribution changes among different environments, existing solutions can only learn causal structures when given environmental information. In contrast, we propose a causal discovery approach (CausalSME) which automatically identifies pseudo environments and unobserved distribution shifts. Specifically, CausalSME learns a causal model containing unobserved variables, which can correct the distribution shifts with mixed environments. The heart of CausalSME is a variational autoencoder that infers shifted causal effects of unobserved variables and guides the identification of environment information. It further divides the shifted samples by the identified environments to jointly learn an invariant causal model. We prove the structure identifiability of CausalSME with the causal additive model. In our extensive experiments we show that CausalSME achieves state-of-the-art performance. | Dezhi Yang, Guoxian Yu, Jun Wang, Jinglin Zhang, Carlotta Domeniconi | Department of Computer Science, George Mason University, Fairfax, VA, USA; School of Software, Shandong University, Jinan, Shandong, China; School of Control Science and Engineering, Shandong University, Jinan, Shandong, China |
|  |  [PraFFL: A Preference-Aware Scheme in Fair Federated Learning](https://doi.org/10.1145/3690624.3709217) |  | 0 | Fairness in federated learning has emerged as a critical concern, aiming to develop an unbiased model for any special group (e.g., male or female) of sensitive features. However, there is a trade-off between model performance and fairness, i.e., improving model fairness will decrease model performance. Existing approaches have characterized such a trade-off by introducing hyperparameters to quantify client's preferences for model fairness and model performance. Nevertheless, these approaches are limited to scenarios where each client has only a single pre-defined preference, and fail to work in practical systems where each client generally have multiple preferences. The key challenge is to design a method that allows the model to adapt to diverse preferences of each client in real time. To this end, we propose a Preference-aware scheme in Fair Federated Learning paradigm (called PraFFL) to generate preference-wise model in real time. PraFFL can adaptively adjust the model based on each client's preferences to meet their needs. We theoretically prove that PraFFL can offer the optimal model tailored to an arbitrary preference of each client, and show its linear convergence. Experimental results show that our proposed PraFFL outperforms five fair federated learning algorithms in terms of the model's capability of adapting to clients' different preferences. | Rongguang Ye, WeiBin Kou, Ming Tang |  |
|  |  [Benchmarking and Defending against Indirect Prompt Injection Attacks on Large Language Models](https://doi.org/10.1145/3690624.3709179) |  | 0 | The integration of large language models with external content has enabled applications such as Microsoft Copilot but also introduced vulnerabilities to indirect prompt injection attacks. In these attacks, malicious instructions embedded within external content can manipulate LLM outputs, causing deviations from user expectations. To address this critical yet under-explored issue, we introduce the first benchmark for indirect prompt injection attacks, named BIPIA, to assess the risk of such vulnerabilities. Using BIPIA, we evaluate existing LLMs and find them universally vulnerable. Our analysis identifies two key factors contributing to their success: LLMs' inability to distinguish between informational context and actionable instructions, and their lack of awareness in avoiding the execution of instructions within external content. Based on these findings, we propose two novel defense mechanisms-boundary awareness and explicit reminder-to address these vulnerabilities in both black-box and white-box settings. Extensive experiments demonstrate that our black-box defense provides substantial mitigation, while our white-box defense reduces the attack success rate to near-zero levels, all while preserving the output quality of LLMs. We hope this work inspires further research into securing LLM applications and fostering their safe and reliable use. | Jingwei Yi, Yueqi Xie, Bin Zhu, Emre Kiciman, Guangzhong Sun, Xing Xie, Fangzhao Wu | University of Science and Technology of China ‡ Hong Kong University of Science and Technology § Microsoft |
|  |  [Non-Homophilic Graph Pre-Training and Prompt Learning](https://doi.org/10.1145/3690624.3709219) |  | 0 | Graphs are ubiquitous for modeling complex relationships between objects across various fields. Graph neural networks (GNNs) have become a mainstream technique for graph-based applications, but their performance heavily relies on abundant labeled data. To reduce labeling requirement, pre-training and prompt learning has become a popular alternative. However, most existing prompt methods do not differentiate homophilic and heterophilic characteristics of real-world graphs. In particular, many real-world graphs are non-homophilic, not strictly or uniformly homophilic with mixing homophilic and heterophilic patterns, exhibiting varying non-homophilic characteristics across graphs and nodes. In this paper, we propose ProNoG, a novel pre-training and prompt learning framework for such non-homophilic graphs. First, we analyze existing graph pre-training methods, providing theoretical insights into the choice of pre-training tasks. Second, recognizing that each node exhibits unique non-homophilic characteristics, we propose a conditional network to characterize the node-specific patterns in downstream tasks. Finally, we thoroughly evaluate and analyze ProNoG through extensive experiments on ten public datasets. | Xingtong Yu, Jie Zhang, Yuan Fang, Renhe Jiang |  |
|  |  [Boosting Explainability through Selective Rationalization in Pre-trained Language Models](https://doi.org/10.1145/3690624.3709212) |  | 0 | The widespread application of pre-trained language models (PLMs) in natural language processing (NLP) has led to increasing concerns about their explainability. Selective rationalization is a self-explanatory framework that selects human-intelligible input subsets as rationales for predictions. Recent studies have shown that applying existing rationalization frameworks to PLMs will result in severe degeneration and failure problems, producing sub-optimal or meaningless rationales. Such failures severely damage trust in rationalization methods and constrain the application of rationalization techniques on PLMs. In this paper, we find that the homogeneity of tokens in the sentences produced by PLMs is the primary contributor to these problems. To address these challenges, we propose a method named Pre-trained Language Model's Rationalization (PLMR), which splits PLMs into a generator and a predictor to deal with NLP tasks while providing interpretable rationales. The generator in PLMR also alleviates homogeneity by pruning irrelevant tokens, while the predictor uses full-text information to standardize predictions. Experiments conducted on two widely used datasets across multiple PLMs demonstrate the effectiveness of the proposed method PLMR in addressing the challenge of applying selective rationalization to PLMs. Codes: https://github.com/ylb777/PLMR. | Libing Yuan, Shuaibo Hu, Kui Yu, Le Wu |  |
|  |  [A Structure-aware Invariant Learning Framework for Node-level Graph OOD Generalization](https://doi.org/10.1145/3690624.3709227) |  | 0 | Graph Neural Networks (GNNs) have been proven effective in modeling graph data, mostly depending on the in-distribution assumption. While in the out-of-distribution (OOD) scenarios, especially for the more challenging node-level task, the feature and structure distribution shifts between training and test nodes lead to performance degradation. To improve node-level OOD generalization, typical approaches introduce graph augmentation to enrich the training environments and conduct invariant learning to learn stable representations across various augmented environments. However, their graph augmentations emphasize diversity but neglect the preservation of invariant patterns which are fundamental to invariant learning. Moreover, most of them simply conduct the classic invariant learning objective but lack the consideration of the graph-specific structure information. Therefore, to mitigate their weakness, we propose a Structure-aware Invariant learning framework for Node-level Graph OOD generalization (SING). Specifically, we develop the invariance constraint regularization terms during the optimization of augmentations. Additionally, we define the structure embedding to elucidate the structural property and design the structure embedding alignment loss to optimize the augmentations and the invariant representations. By introducing the structure information, we further integrate the unique structural property into invariant learning, thereby boosting the invariant message-passing GNNs. The extensive experiments on the transductive GOOD benchmark and the inductive datasets empirically validate our superior OOD generalization performance to baselines. | Ruiwen Yuan, Yongqiang Tang, Wensheng Zhang | Institute of Automation, Chinese Academy of Sciences, Beijing, China |
|  |  [Semi-supervised Multi-view Clustering with Active Constraints](https://doi.org/10.1145/3690624.3709204) |  | 0 | Multi-view clustering has attracted increasing attention in recent years. However, most existing multi-view clustering approaches are performed in a purely unsupervised manner, while ignoring the valuable weak supervision information that can be obtained (e.g., active query) in many real applications. This paper considers the weak pairwise constraints among samples to enhance the clustering performance, and proposes a Semi-supervised Multi-view Clustering method with Active Constraints, SMCAC for short. SMCAC consists of two stages, clustering (C-stage) and active query (A-stage). In the C-stage, we design a tensor based multi-view graph learning model equipped with sample pairwise constraints regularization to facilitate the discriminative graph learning and fusion. An effective optimization algorithm based on alternating direction minimization is devised to solve the clustering model. In the A-stage, the most uncertain or difficult sample pairs are actively selected to query the constraints, based on the divergence of multi-view similarities learned in the C-stage. The two processes alternate iteratively until the maximum number of queries is reached. Extensive experiments on several popular datasets well validate the effectiveness of the proposed method. | Chao Zhang, Deng Xu, Chunlin Chen, Huaxiong Li | Nanjing University, Nanjing, Jiangsu, China |
|  |  [LLM-Eraser: Optimizing Large Language Model Unlearning through Selective Pruning](https://doi.org/10.1145/3690624.3709312) |  | 0 | We focus on unlearning unwanted knowledge in autoregressive large language models (LLMs) through pruning. Our goal is to selectively remove undesirable information (e.g., harmful responses, privacy-sensitive data) while ensuring the preservation of desirable knowledge (e.g., positive responses and objective facts). Previous approaches use gradient ascent (GA) over undesired knowledge to inversely optimize LLMs, which compromises the model's performance on desired knowledge. To address this limitation, we introduce a novel two-stage approach, named LLM-Eraser, for selectively identifying and editing parameters specifically associated with undesirable knowledge. LLM-Eraser operates in two stages: localization and unlearning. During the localization stage, we utilize neuron scores and trainable soft masks to identify parameters crucial to the undesired knowledge. In the unlearning stage, we prune these identified parameters and apply a selective post-training process to enhance the model's selectiveness. Our experiments, conducted across five task datasets, demonstrate that LLM-Eraser effectively unlearns undesirable knowledge-evidenced by the model's near-random performance on multiple-choice questions related to the erased knowledge-while maintaining high proficiency in desirable knowledge, with an average performance deficit of only 2.5%. | Shengming Zhang, Le Zhang, Jingbo Zhou, Zhi Zheng, Hui Xiong | Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; University of Science and Technology of China, Hefei, Anhui, China; Baidu Research, Beijing, China; Chinese Academy of Medical Sciences & Peking Union Medical College, Beijing, China |
|  |  [Understanding and Mitigating Hyperbolic Dimensional Collapse in Graph Contrastive Learning](https://doi.org/10.1145/3690624.3709249) |  | 0 | Learning generalizable self-supervised graph representations for downstream tasks is challenging. To this end, Contrastive Learning (CL) has emerged as a leading approach. The embeddings of CL are arranged on a hypersphere where similarity is measured by the cosine distance. However, many real-world graphs, especially of hierarchical nature, cannot be embedded well in the Euclidean space. Although the hyperbolic embedding is suitable for hierarchical representation learning, naively applying CL to the hyperbolic space may result in the so-called dimension collapse, i.e., features will concentrate mostly within few density regions, leading to poor utilization of the whole feature space. Thus, we propose a novel contrastive learning framework to learn high-quality graph embeddings in hyperbolic space. Specifically, we design the alignment metric that effectively captures the hierarchical data-invariant information, as well as we propose a substitute of the uniformity metric to prevent the so-called dimensional collapse. We show that in the hyperbolic space one has to address the leaf- and height-level uniformity related to properties of trees. In the ambient space of the hyperbolic manifold these notions translate into imposing an isotropic ring density towards boundaries of Poincaré ball. Our experiments support the efficacy of our method. | Yifei Zhang, Hao Zhu, Menglin Yang, Jiahong Liu, Rex Ying, Irwin King, Piotr Koniusz | Data61CSIRO, Sydney, Australia; The Chinese University of Hong Kong, Hong Kong SAR, China; Yale University, New Haven, USA; Data61CSIRO, Canberra, Australia & Australian National University, Canberra, Australia |
|  |  [Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?](https://doi.org/10.1145/3690624.3709256) |  | 0 | Graph neural networks (GNNs) are vulnerable to adversarial perturbations, especially for topology attacks, and many methods that improve the robustness of GNNs have received considerable attention. Recently, we have witnessed the significant success of large language models (LLMs), leading many to explore the great potential of LLMs on GNNs. However, they mainly focus on improving the performance of GNNs by utilizing LLMs to enhance the node features. Therefore, we ask: Will the robustness of GNNs also be enhanced with the powerful understanding and inference capabilities of LLMs? By presenting the empirical results, we find that despite that LLMs can improve the robustness of GNNs, there is still an average decrease of 23.1 the GNNs remain extremely vulnerable against topology attack. Therefore, another question is how to extend the capabilities of LLMs on graph adversarial robustness. In this paper, we propose an LLM-based robust graph structure inference framework, LLM4RGNN, which distills the inference capabilities of GPT-4 into a local LLM for identifying malicious edges and an LM-based edge predictor for finding missing important edges, so as to recover a robust graph structure. Extensive experiments demonstrate that LLM4RGNN consistently improves the robustness across various GNNs. Even in some cases where the perturbation ratio increases to 40 that on the clean graph. | Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi |  |
|  |  [Stable Representation Learning on Graphs from Multiple Environments with Structure Distribution Shift](https://doi.org/10.1145/3690624.3709269) |  | 0 | In recent years, Graph Neural Networks (GNNs) become very effective methods to utilize graphs and have been applied to many real-world applications, including recommendation, advertisement, and financial fraud detection. In fact, GNNs are mostly trained and test in the environments with the same distribution. However, in the real cases, selection bias are inevitably existed in both the node features and the graph structures, which will lead to serious impact on the GNN performance. Several works of literature have investigated the out-of-distribution (OOD) problem on the feature distribution, but little research specifically studies the effect caused by the bias of graph structure. However, graph structure is very fundamental for GNNs since it greatly affects the message propagation mechanism. In order to solve the above problem, we propose an unsupervised Stable Graph Representation learning (SGR) framework to obtain stable graphs from multiple environments with graph structure bias, and to improve the stability ability of GNN model across environments. Comprehensive experiments have been carried out on 4 public benchmark dataset and a real-world financial dataset. The experimental results show that the proposed stable learning method significantly improves the stability of GNN model in varying test environments. | Tong Zhao, Daixin Wang, Zhiqiang Zhang, Yulin Kang, Jun Zhou | Ant Group, Hangzhou, Zhejiang, China; Ant Group, Shanghai, China; Ant Group, Beijing, China |
|  |  [Understanding Oversmoothing in Diffusion-Based GNNs From the Perspective of Operator Semigroup Theory](https://doi.org/10.1145/3690624.3709324) |  | 0 | This paper presents an analytical study of the oversmoothing issue in diffusion-based Graph Neural Networks (GNNs). Generalizing beyond extant approaches grounded in random walk analysis or particle systems, we approach this problem through operator semigroup theory. This theoretical framework allows us to rigorously prove that oversmoothing is intrinsically linked to the ergodicity of the diffusion operator. Relying on semigroup method, we can quantitatively analyze the dynamic of graph diffusion and give a specific mathematical form of the smoothing feature by ergodicity and invariant measure of operator, which improves previous works only show existence of oversmoothing. This finding further poses a general and mild ergodicity-breaking condition, encompassing the various specific solutions previously offered, thereby presenting a more universal and theoretically grounded approach to relieve oversmoothing in diffusion-based GNNs. Additionally, we offer a probabilistic interpretation of our theory, forging a link with prior works and broadening the theoretical horizon. Our experimental results reveal that this ergodicity-breaking term effectively mitigates oversmoothing measured by Dirichlet energy, and simultaneously enhances performance in node classification tasks. | Weichen Zhao, Chenguang Wang, Xinyan Wang, Congying Han, Tiande Guo, Tianshu Yu | Chinese Academy of Sciences Academy of Mathematics and Systems Science; University of Chinese Academy of Sciences School of Mathematical Sciences; Nankai University School of Statistics and Data Science; The Chinese University of Hong Kong School of Data Science |
|  |  [Graph Learning with Distributional Edge Layouts](https://doi.org/10.1145/3690624.3709206) |  | 0 | Graph Neural Networks (GNNs) learn from graph-structured data by passinglocal messages between neighboring nodes along edges on certain topologicallayouts. Typically, these topological layouts in modern GNNs aredeterministically computed (e.g., attention-based GNNs) or locally sampled(e.g., GraphSage) under heuristic assumptions. In this paper, we for the firsttime pose that these layouts can be globally sampled via Langevin dynamicsfollowing Boltzmann distribution equipped with explicit physical energy,leading to higher feasibility in the physical world. We argue that such acollection of sampled/optimized layouts can capture the wide energydistribution and bring extra expressivity on top of WL-test, therefore easingdownstream tasks. As such, we propose Distributional Edge Layouts (DELs) toserve as a complement to a variety of GNNs. DEL is a pre-processing strategyindependent of subsequent GNN variants, thus being highly flexible.Experimental results demonstrate that DELs consistently and substantiallyimprove a series of GNN baselines, achieving state-of-the-art performance onmultiple datasets. | Xinjian Zhao, Chaolong Ying, Yaoyao Xu, Tianshu Yu | The Chinese University of Hong Kong School of Data Science |
|  |  [Towards Context-Aware Traffic Classification via Time-Wavelet Fusion Network](https://doi.org/10.1145/3690624.3709315) |  | 0 | Encrypted traffic classification occupies a significant role in cybersecurity and network management. The existing encrypted traffic classification technology mostly relies on intra-flow semantics for extracting features. However, considering that some attack behaviors inherently have similar patterns to legitimate behaviors, and powerful adversaries could simulate benign users to conceal their attack intentions, intra-flow features may be similar between different categories. In this paper, we propose TrafficScope, a time-wavelet fusion network based on Transformer to enhance the performance of encrypted traffic classification. Specifically, in addition to using intra-flow semantics, TrafficScope also extracts contextual information to construct more comprehensive representations. Moreover, to cope with the non-stationary and dynamic contextual traffic, we employ wavelet transform to extract invariant features. For feature fusion, the cross-attention mechanism is adopted to inline combine temporal and wavelet-domain features. We extensively evaluate TrafficScope compared with 7 state-of-the-art baselines based on four groups of real-world traffic datasets, the results show that TrafficScope outperforms existing methods. We conduct a series of experiments in terms of similar intra-flow feature evaluation, data pollution, flow manipulations, and dynamic context to demonstrate the robustness and stability of the proposed method. Furthermore, we produce additional experiments to present the potential of TrafficScope in cross-dataset scenarios. | Ziming Zhao, Zhuoxue Song, Xiaofei Xie, Zhaoxuan Li, Jiongchi Yu, Fan Zhang, Tingting Li | Institute of Information Engineering, CAS, Beijing, China; Singapore Management University, Singapore, Singapore; Zhejiang University, Hangzhou, Zhejiang, China |
|  |  [Graph Contrastive Learning with Progressive Augmentations](https://doi.org/10.1145/3690624.3709307) |  | 0 | To be still yet still moving. - Do Hyun Choe Graph contrastive learning (GCL) has recently gained prominence in unsupervised graph representation learning. Traditional GCL approaches generally focus on creating a single contrastive view alongside the main graph view, targeting invariant representation learning in a static framework. Our study introduces a novel manner: despite using static graphs, we aim to learn invariant representations by generating a series of evolving contrastive views with temporal coherence and multi-viewpoint insights at various granularities. In this context, we propose the Progressive Augmentation framework for Graph Contrastive Learning (PaGCL). This framework advances beyond traditional methods by producing a sequence of augmented views, each evolving from the previous one, and assigning timestamps based on piecewise smoothness. This approach enables our model to more effectively extract invariant features from these dynamic views, capturing multi-grained structural and temporal information. Our experiments on diverse benchmark datasets demonstrate that PaGCL significantly outperforms current state-of-the-art methods. | Yuhai Zhao, Yejiang Wang, Zhengkui Wang, Wen Shan, Miaomiao Huang, Xingwei Wang | InfoComm Technology Cluster, Singapore Institute of Technology, Singapore, Singapore; School of Computer Science and Engineering, Northeastern University, Shenyang, Liaoning, China; Singapore University of Social Sciences, Singapore, Singapore |
|  |  [Grid and Road Expressions Are Complementary for Trajectory Representation Learning](https://doi.org/10.1145/3690624.3709272) |  | 0 | Trajectory representation learning (TRL) maps trajectories to vectors that can be used for many downstream tasks. Existing TRL methods use either grid trajectories, capturing movement in free space, or road trajectories, capturing movement in a road network, as input. We observe that the two types of trajectories are complementary, providing either region and location information or providing road structure and movement regularity. Therefore, we propose a novel multimodal TRL method, dubbed GREEN, to jointly utilize Grid and Road trajectory Expressions for Effective representatioN learning. In particular, we transform raw GPS trajectories into both grid and road trajectories and tailor two encoders to capture their respective information. To align the two encoders such that they complement each other, we adopt a contrastive loss to encourage them to produce similar embeddings for the same raw trajectory and design a mask language model (MLM) loss to use grid trajectories to help reconstruct masked road trajectories. To learn the final trajectory representation, a dual-modal interactor is used to fuse the outputs of the two encoders via cross-attention. We compare GREEN with 7 state-of-the-art TRL methods for 3 downstream tasks, finding that GREEN consistently outperforms all baselines and improves the accuracy of the best-performing baseline by an average of 15.99%. | Silin Zhou, Shuo Shang, Lisi Chen, Peng Han, Christian S. Jensen |  |
|  |  [BTFL: A Bayesian-based Test-Time Generalization Method for Internal and External Data Distributions in Federated learning](https://doi.org/10.1145/3690624.3709309) |  | 0 | Federated Learning (FL) enables multiple clients to collaboratively develop a global model while maintaining data privacy. However, online FL deployment faces challenges due to distribution shifts and evolving test samples. Personalized Federated Learning (PFL) tailors the global model to individual client distributions, but struggles with Out-Of-Distribution (OOD) samples during testing, leading to performance degradation. In real-world scenarios, balancing personalization and generalization during online testing is crucial and existing methods primarily focus on training-phase generalization. To address the test-time trade-off, we introduce a new scenario: Test-time Generalization for Internal and External Distributions in Federated Learning (TGFL), which evaluates adaptability under Internal Distribution (IND) and External Distribution (EXD). We propose BTFL, a Bayesian-based test-time generalization method for TGFL, which balances generalization and personalization at the sample level during testing. BTFL employs a two-head architecture to store local and global knowledge, interpolating predictions via a dual-Bayesian framework that considers both historical test data and current sample characteristics with theoretical guarantee and faster speed. Our experiments demonstrate that BTFL achieves improved performance across various datasets and models with less time cost. The source codes are made publicly available at https://github.com/ZhouYuCS/BTFL . | Yu Zhou, Bingyan Liu |  |
|  |  [RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning](https://doi.org/10.1145/3690624.3709252) |  | 0 | The advent of the "pre-train, prompt" paradigm has recently extended its generalization ability and data efficiency to graph representation learning, following its achievements in Natural Language Processing (NLP). Initial graph prompt tuning approaches tailored specialized prompting functions for Graph Neural Network (GNN) models pre-trained with specific strategies, such as edge prediction, thus limiting their applicability. In contrast, another pioneering line of research has explored universal prompting via adding prompts to the input graph's feature space, thereby removing the reliance on specific pre-training strategies. However, the necessity to add feature prompts to all nodes remains an open question. Motivated by findings from prompt tuning research in the NLP domain, which suggest that highly capable pre-trained models need less conditioning signal to achieve desired behaviors, we advocate for strategically incorporating necessary and lightweight feature prompts to certain graph nodes to enhance downstream task performance. This introduces a combinatorial optimization problem, requiring a policy to decide 1) which nodes to prompt and 2) what specific feature prompts to attach. We then address the problem by framing the prompt incorporation process as a sequential decision-making problem and propose our method, RELIEF, which employs Reinforcement Learning (RL) to optimize it. At each step, the RL agent selects a node (discrete action) and determines the prompt content (continuous action), aiming to maximize cumulative performance gain. Extensive experiments on graph and node-level tasks with various pre-training strategies in few-shot scenarios demonstrate that our RELIEF outperforms fine-tuning and other prompt-based approaches in classification performance and data efficiency. | Jiapeng Zhu, Zichen Ding, Jianxiang Yu, Jiaqi Tan, Xiang Li, Weining Qian |  |
|  |  [Powerformer: A Section-adaptive Transformer for Power Flow Adjustment](https://doi.org/10.1145/3690624.3709433) |  | 0 | In this paper, we present a novel transformer architecture tailored forlearning robust power system state representations, which strives to optimizepower dispatch for the power flow adjustment across different transmissionsections. Specifically, our proposed approach, named Powerformer, develops adedicated section-adaptive attention mechanism, separating itself from theself-attention used in conventional transformers. This mechanism effectivelyintegrates power system states with transmission section information, whichfacilitates the development of robust state representations. Furthermore, byconsidering the graph topology of power system and the electrical attributes ofbus nodes, we introduce two customized strategies to further enhance theexpressiveness: graph neural network propagation and multi-factor attentionmechanism. Extensive evaluations are conducted on three power system scenarios,including the IEEE 118-bus system, a realistic 300-bus system in China, and alarge-scale European system with 9241 buses, where Powerformer demonstrates itssuperior performance over several baseline methods. | Kaixuan Chen, Wei Luo, Shunyu Liu, Yaoquan Wei, Yihe Zhou, Yunpeng Qing, Quan Zhang, Yong Wang, Jie Song, Mingli Song | Zhejiang University Polytechnic Institute; Zhejiang University College of Electrical Engineering; Zhejiang University College of Computer Science and Technology; Zhejiang University College of Software |
|  |  [Efficient Multi-Expert Tabular Language Model for Banking](https://doi.org/10.1145/3690624.3709400) |  | 0 | Pre-training large Tabular Language Models (TaLMs) on tabular data has shown effectiveness for table understanding tasks. However, training proprietary large TaLMs on a company's private databases requires substantial computational resources. This paper presents an efficient multi-expert TaLM architecture and training method tailored for multi-domain databases and modest infrastructure. This architecture leverages a divide-and-conquer pretraining approach and a sparsely activated fine-tuning paradigm to reduce computation. Using this architecture, we pre-train and fine-tune a TaLM with 10 billion parameters on a banking database under simple computational infrastructures. We apply our TaLM to support various important banking applications, including risk assessment, information prediction, and profit assessment. Compared with previous baselines, our model achieves +29.3% in [email protected]% on risk assessment and +16.5% in accuracy on information prediction, showing great effectiveness and profitability of our model. This model is successfully deployed in WeBank and now supports many real business scenarios. | Yue Guo, Wentao Zhang, Xiaojun Zhang, Vincent W. Zheng, Yi Yang | WeBank, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, China |
|  |  [Learning Adaptive Reserve Price in Display Advertising](https://doi.org/10.1145/3690624.3709439) |  | 0 | Real-Time Bidding (RTB) is a trading mechanism that allocates advertising (ad) requests through online auctions. Participants in these auctions typically include an ad exchange (AdX) and several demand-side platforms (DSPs). When an RTB auction begins, the AdX first establishes the reserve price set by publishers as the starting bid, after which the DSPs bid to compete for potential ad impressions. The reserve price strategy is crucial to the ad revenue of publishers; however, due to the strategic and dynamic bidding behavior of DSPs, optimizing the reserve price presents a significant challenge. In this work, we report a novel adaptive reserve price strategy based on reinforcement learning (RL). In our scheme, value bucket identification is leveraged to estimate the intrinsic values of ad inventories. Following this estimation, specialized reward functions are utilized to generate informative reward signals for RL models. Furthermore, we study the issue of risk management on the publisher side and develop a risk-aware instantiation to model risk tendency, considering both empirical expert knowledge and real-time trading conditions. Extensive experiments using real-world datasets collected from operational environments have demonstrated the effectiveness of the proposed method. | Kun Hu, Shumin Zhang, Lixia Wu, Yongjun Dai, Minfang Lu, Yuting Qiang, Minglong Li | Cainiao network, Alibaba group, Hangzhou, China |
|  |  [Synthetic Survey Data Generation and Evaluation](https://doi.org/10.1145/3690624.3709421) |  | 0 | Survey data are common and invaluable in social science research for understanding population processes and supporting policymaking and planning. Depending on the nature and scale, survey data sharing comes with privacy risks, and data collectors and agencies are constrained by disclosure permissions, limiting usage across research groups and institutes. Previous methods for synthetic data generation and deidentification may not entirely prevent information disclosures, or they may sacrifice data quality and granularity. Using a large-scale national voter file at both national and state levels, this paper introduces an end-to-end pipeline to streamline synthetic data generation and evaluation for survey researchers. This study selects four generative approaches based on different statistical assumptions: the regression-based Synthpop, the generative deep learning-based CTGAN and TVAE, and the large language model-based REaLDTabFormer, and compares them to the baseline synthetic minority oversampling technique (SMOTE). We consider three key dimensions of evaluation (utility, fidelity, and privacy) to highlight the strengths and weaknesses of each approach, and systematically evaluate across various datasets and training sizes. The results reveal that Synthpop is optimized for general utility (i.e., fidelity), while TVAE excels in downstream applications (i.e., target-specific utility) but compromises on general utility and potentially risks data overfitting. REaLDTabFormer demonstrates a balanced performance in both general and target-specific utility, whereas CTGAN offers the best privacy protection. We recommend that future researchers select a generative method by considering the trade-offs between performance across various evaluation dimensions, training size, data type, and computational infrastructure. | Yanru Jiang, Siyu Liang, Junwon Choi | University of California, Davis, Davis, CA, USA; University of California, Los Angeles, Los Angeles, CA, USA |
|  |  [Large Vison-Language Foundation Model in Baidu AIGC Image Advertising](https://doi.org/10.1145/3690624.3709401) |  | 0 | Recent advances in generative artificial intelligence have revolutionized information retrieval and content generation, opening up new opportunities for the e-commerce industry. Alignment learning between small models and parallel corpora cannot meet current needs. The success of ChatGPT demonstrates that large models need to first establish a fundamental understanding, and then utilize high-quality corpora for generation. Having a large model foundation is indispensable. In this paper, we establish a fundamental 10B multimodal model foundation for multimodal generation tasks and propose a scene-based alignment learning approach called conditional sample supervised fine-tuning for downstream generation tasks. Meanwhile, diffusion models are known to be vulnerable to outliers in training data. To address this, we utilize an alternative diffusion loss function that preserves the high quality of generated data like the original squared L2 loss while being robust to outliers.In practical test sets, the multimodal foundation fully demonstrates its alignment and comprehension abilities for graphic and textual content. Additionally, conditional fine-tuning and the design of the loss function significantly enhance the quality of generated content. The quality rate of images has increased by 34.3 percentage points, and prompt control has improved by 19.8 percentage points. The application of our framework in Baidu Search Ads has led to significant revenue growth. For instance, ads with generated image creatives have achieved a 29% higher click-through rate (CTR), resulting in a daily consumption of 3 million yuan. | Zhipeng Jin, Wen Tao, Yafei Li, Yi Yang, Cong Han, Shuanglong Li, Lin Liu | Baidu Inc., Beijing, China |
|  |  [YaART: Yet Another ART Rendering Technology](https://doi.org/10.1145/3690624.3709404) |  | 0 | In the rapidly progressing field of generative models, the development ofefficient and high-fidelity text-to-image diffusion systems represents asignificant frontier. This study introduces YaART, a novel production-gradetext-to-image cascaded diffusion model aligned to human preferences usingReinforcement Learning from Human Feedback (RLHF). During the development ofYaART, we especially focus on the choices of the model and training datasetsizes, the aspects that were not systematically investigated for text-to-imagecascaded diffusion models before. In particular, we comprehensively analyze howthese choices affect both the efficiency of the training process and thequality of the generated images, which are highly important in practice.Furthermore, we demonstrate that models trained on smaller datasets ofhigher-quality images can successfully compete with those trained on largerdatasets, establishing a more efficient scenario of diffusion models training.From the quality perspective, YaART is consistently preferred by users overmany existing state-of-the-art models. | Sergey Kastryulin, Artem Konev, Alexander Shishenya, Eugene Lyapustin, Artem Khurshudov, Alexander Tselousov, Nikita Vinokurov, Denis Kuznedelev, Alexander Markovich, Grigoriy Livshits, Alexey Kirillov, Anastasiia Tabisheva, Liubov Chubarova, Marina Kaminskaia, Alexander Ustyuzhanin, Artemii Shvetsov, Daniil Shlenskii, Valerii Startsev, Dmitrii Kornilov, Mikhail Romanov, Dmitry Baranchuk, Artem Babenko, Sergei Ovcharenko, Valentin Khrulkov |  |
|  |  [LLMLight: Large Language Models as Traffic Signal Control Agents](https://doi.org/10.1145/3690624.3709379) |  | 0 | Traffic Signal Control (TSC) is a crucial component in urban trafficmanagement, aiming to optimize road network efficiency and reduce congestion.Traditional methods in TSC, primarily based on transportation engineering andreinforcement learning (RL), often exhibit limitations in generalization acrossvaried traffic scenarios and lack interpretability. This paper presentsLLMLight, a novel framework employing Large Language Models (LLMs) asdecision-making agents for TSC. Specifically, the framework begins byinstructing the LLM with a knowledgeable prompt detailing real-time trafficconditions. Leveraging the advanced generalization capabilities of LLMs,LLMLight engages a reasoning and decision-making process akin to humanintuition for effective traffic control. Moreover, we build LightGPT, aspecialized backbone LLM tailored for TSC tasks. By learning nuanced trafficpatterns and control strategies, LightGPT enhances the LLMLight frameworkcost-effectively. Extensive experiments on nine real-world and syntheticdatasets showcase the remarkable effectiveness, generalization ability, andinterpretability of LLMLight against nine transportation-based and RL-basedbaselines. | Siqi Lai, Zhao Xu, Weijia Zhang, Hao Liu, Hui Xiong |  |
|  |  [A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data](https://doi.org/10.1145/3690624.3709418) |  | 0 | Drug repurposing identifies new therapeutic uses for existing drugs, reducing the time and costs compared to traditional de novo drug discovery. Most existing drug repurposing studies using real-world patient data often treat the entire population as homogeneous, ignoring the heterogeneity of treatment responses across patient subgroups. This approach may overlook promising drugs that benefit specific subgroups but lack notable treatment effects across the entire population, potentially limiting the number of repurposable candidates identified. To address this, we introduce STEDR, a novel drug repurposing framework that integrates subgroup analysis with treatment effect estimation. Our approach first identifies repurposing candidates by emulating multiple clinical trials on real-world patient data and then characterizes patient subgroups by learning subgroup-specific treatment effects. We deploy STEDR to Alzheimer's Disease (AD), a condition with few approved drugs and known heterogeneity in treatment responses. We emulate trials for over one thousand medications on a large-scale real-world database covering over 8 million patients, identifying 14 drug candidates with beneficial effects to AD in characterized subgroups. Experiments demonstrate STEDR's superior capability in identifying repurposing candidates compared to existing approaches. Additionally, our method can characterize clinically relevant patient subgroups associated with important AD-related risk factors, paving the way for precision drug repurposing. | Seungyeon Lee, Ruoqi Liu, Feixiong Cheng, Ping Zhang | The Ohio State University Ohio, USA.; Cleveland Clinic Ohio, USA. |
|  |  [Contrastive Learning for Inventory Add Prediction at Fliggy](https://doi.org/10.1145/3690624.3709384) |  | 0 | Online Travel Platforms (OTPs) serve as crucial bridges between hotels and users, hotel staff can synchronize room inventory information with OTPs through manual and auto modes. In the manual mode, the hotel staff must manually maintain the inventory information on the OTPs. This mode often leads to the "inventory synchronization delay'' phenomenon where OTPs show no availability while hotels still have available rooms, seriously affecting the competitiveness of OTPs and hotel sales. To address this issue, Fliggy uses inventory add prediction (IAP) to determine whether to add an inventory for the sold-out room type. However, in practice, accurate modeling of IAP faces significant challenges due to the data sparsity. In this paper, we propose a Contrastive Learning framework for Inventory Add Prediction at Fliggy (CL4IAP), which consists of the Joint Pay-Accept Prediction Module, the Data Augmentation Module, and the Contrastive Learning Module. Specifically, the Joint Pay-Accept Prediction Module aims to predict the likelihood of generating an order and the hotel acceptance after adding an inventory. It also includes a specially designed correlation enhancement component that facilitates the expert prediction network's learning through knowledge transfer based on inter-task correlation. In the Data Augmentation Module, we design three novel data augmentation strategies for the first time based on the correlation and importance of features. In the Contrastive Learning Module, we design instance-level and cluster-level contrastive losses, which aim to minimize the distance between positive sample pairs and mitigate the negative impact of false negative sample pairs, respectively. Both offline and online experiments demonstrate the effectiveness of CL4IAP, and CL4IAP has been successfully deployed on Fliggy. | Manwei Li, Detao Lv, Yao Yu, Zihao Jiao | Alibaba Group, Hangzhou, ZheJiang, China; Alibaba Group, Hangzhou, Zhejiang, China |
|  |  [FuzzyLight: A Robust Two-Stage Fuzzy Approach for Traffic Signal Control Works in Real Cities](https://doi.org/10.1145/3690624.3709393) |  | 0 | Effective traffic signal control (TSC) is crucial in mitigating urban congestion and reducing emissions. Recently, reinforcement learning (RL) has been the research trend for TSC. However, existing RL algorithms face several real-world challenges that hinder their practical deployment in TSC: (1) Sensor accuracy deteriorates with increased sensor detection range, and data transmission is prone to noise, potentially resulting in unsafe TSC decisions. (2) During the training of online RL, interactions with the environment could be unstable, potentially leading to inappropriate traffic signal phase (TSP) selection and traffic congestion. (3) Most current TSC algorithms focus only on TSP decisions, overlooking the critical aspect of phase duration, affecting safety and efficiency. To overcome these challenges, we propose a robust two-stage fuzzy approach called FuzzyLight, which integrates compressed sensing and RL for TSC deployment. FuzzyLight offers several key contributions: (1) It employs fuzzy logic and compressed sensing to address sensor noise and enhances the efficiency of TSP decisions. (2) It maintains stable performance during training and combines fuzzy logic with RL to generate precise phases. (3) It works in real cities across 22 intersections and demonstrates superior performance in both real-world and simulated environments. Experimental results indicate that FuzzyLight enhances traffic efficiency by 48 expert-designed timings in the real world. Furthermore, it achieves state-of-the-art (SOTA) performance in simulated environments using six real-world datasets with transmission noise. The code and deployment video are available at the URL1 | Mingyuan Li, Jiahao Wang, Bo Du, Jun Shen, Qiang Wu |  |
|  |  [Improving Synthetic Image Detection Towards Generalization: An Image Transformation Perspective](https://doi.org/10.1145/3690624.3709392) |  | 0 | With recent generative models facilitating photo-realistic image synthesis, the proliferation of synthetic images has also engendered certain negative impacts on social platforms, thereby raising an urgent imperative to develop effective detectors. Current synthetic image detection (SID) pipelines are primarily dedicated to crafting universal artifact features, accompanied by an oversight about SID training paradigm. In this paper, we re-examine the SID problem and identify two prevalent biases in current training paradigms, i.e., weakened artifact features and overfitted artifact features. Meanwhile, we discover that the imaging mechanism of synthetic images contributes to heightened local correlations among pixels, suggesting that detectors should be equipped with local awareness. In this light, we propose SAFE, a lightweight and effective detector with three simple image transformations. Firstly, for weakened artifact features, we substitute the down-sampling operator with the crop operator in image pre-processing to help circumvent artifact distortion. Secondly, for overfitted artifact features, we include ColorJitter and RandomRotation as additional data augmentations, to help alleviate irrelevant biases from color discrepancies and semantic differences in limited training samples. Thirdly, for local awareness, we propose a patch-based random masking strategy tailored for SID, forcing the detector to focus on local regions at training. Comparative experiments are conducted on an open-world dataset, comprising synthetic images generated by 26 distinct generative models. Our pipeline achieves a new state-of-the-art performance, with remarkable improvements of 4.5 methods. | Ouxiang Li, Jiayin Cai, Yanbin Hao, Xiaolong Jiang, Yao Hu, Fuli Feng |  |
|  |  [Automatic Radiotherapy Treatment Planning with Deep Functional Reinforcement Learning](https://doi.org/10.1145/3690624.3709430) |  | 0 | Intensity-modulated radiation therapy (IMRT) is one of the most important modern radiotherapy techniques and is often modeled as an optimization problem. The objective function and constraints consist of multiple clinical requirements designed for different clinical settings. When a tightly constrained optimization problem has no solution, the planner can empirically relax certain constraint parameters and re-solve the problem until a more satisfactory solution is obtained. This process is time-consuming and laborious. Several inverse planning studies have been devoted to automated radiotherapy planning schemes. Reinforcement learning has been used by many studies to model this process, but they suffer from two important drawbacks: 1) designing a sub-network for each organ, which makes it difficult to extend the model to other patients with a different number of organs. Clinically, it is common for different patients to have inconsistent numbers of organs considered for radiotherapy, even for the same type of cancer; 2) directly feeding low signal-to-noise DVH curves as states into the reinforcement learning network, which ignores its functional characteristics and leads to low training efficiency. In this study, within the framework of deep reinforcement learning, a DVH function-based embedding layer was designed to directly extract the effective information of DVH and allow different organs to share a strategic network. The test results on a dataset of 135 patients with cervical cancer find that our proposed model can be applied to radiotherapy planning in real-world scenarios. | Bin Liu, Yu Liu, Zhiqian Li, Jianghong Xiao, Guosheng Yin, Huazhen Lin |  |
|  |  [Using Instruction-Tuned LMs for Scalable Use Case-Based Shopping - Where Customers Meet Their Needs](https://doi.org/10.1145/3690624.3709411) |  | 0 | Products on e-commerce platforms are usually organized based on seller-provided product attributes. Customers looking for a product typically have certain needs or use cases in mind, such as headphones for gym classes, or a printer for school projects. However, they often struggle to map these use cases to product attributes, thereby failing to find the product they need. To help customers shop online confidently, we propose a Use case-Based Shopping (UBS) system that facilitates customer experiences based on use cases (Fig. 1). UBS consists of three steps: 1) use case phrase extraction from product reviews, 2) clustering the extracted use case phrases to identify the dominant ones, and 3) mapping products in a given category to one or more of these dominant use cases. In this work, we utilize instruction-tuned LMs to primarily focus on the first two steps. However, the way we design them also helps us to seamlessly solve the third step to complete the design of our proposed system. First, we define the novel task of joint Use Uase, Uentiment Uxtraction (UCSE) from product reviews which can be used for both steps 1 and 3. We harness the task adaptation capability of instruction-tuned FLAN-T5 models and gradually improve their zero-shot UCSE performance through instruction tuning, multi-task training, and few-shot iterative re-training for new categories, achieving around ~90% reduction in annotation bandwidth. We then employ Anthropic's Claude 2 LLM to propose an unsupervised approach for hierarchical use case phrase clustering that demonstrates better clustering and cluster naming capabilities when compared to K-Means and LDA. In an online experiment targeting the top 7 product categories, UBS recommendations on search, browse, and product pages resulted in a revenue lift of 0.77%, 0.94%, and 0.44% respectively, and an average click rate lift of 0.15%. | Rajdeep Mukherjee, Sonali Singh, Sachin Farfade | Indian Institute of Technology, Kharagpur, India; Amazon, Bengaluru, India |
|  |  [Understanding Team Collapse via Probabilistic Graphical Models](https://doi.org/10.1145/3690624.3709386) |  | 0 | In this work, we develop a graphical model to capture team dynamics. Weanalyze the model and show how to learn its parameters from data. Using ourmodel we study the phenomenon of team collapse from a computationalperspective. We use simulations and real-world experiments to find the maincauses of team collapse. We also provide the principles of building resilientteams, i.e., teams that avoid collapsing. Finally, we use our model to analyzethe structure of NBA teams and dive deeper into games of interest. | Iasonas Nikolaou, Konstantinos Pelechrinis, Evimaria Terzi | University of Pittsburgh Pittsburgh; Boston University |
|  |  [Explainable LiDAR 3D Point Cloud Segmentation and Clustering for Detecting Airplane-Generated Wind Turbulence](https://doi.org/10.1145/3690624.3709436) |  | 0 | Wake vortices - strong, coherent air turbulences created by aircraft - pose a significant risk to aviation safety and therefore require accurate and reliable detection methods. In this paper, we present an advanced, explainable machine learning method that utilizes Light Detection and Ranging (LiDAR) data for effective wake vortex detection. Our method leverages a dynamic graph CNN (DGCNN) with semantic segmentation to partition a 3D LiDAR point cloud into meaningful segments. Further refinement is achieved through clustering techniques. A novel feature of our research is the use of a perturbation-based explanation technique, which clarifies the model's decision-making processes for air traffic regulators and controllers, increasing transparency and building trust. Our experimental results, based on measured and simulated LiDAR scans compared against four baseline methods, underscore the effectiveness and reliability of our approach. This combination of semantic segmentation and clustering for real-time wake vortex tracking significantly advances aviation safety measures, ensuring that these are both effective and comprehensible. | Zhan Qu, Shuzhou Yuan, Michael Färber, Marius Brennfleck, Niklas Wartha, Anton Stephan |  |
|  |  [Unifying Adversarial Multi-Deconfounded Learning Paradigm for Fake News Detection](https://doi.org/10.1145/3690624.3709406) |  | 0 | In the task of fake news detection, ensuring authenticity and accuracy is of paramount importance. This task, however, is susceptible to the influence of confounders, necessitating effective confounder debiasing strategies. Conventional methods are typically designed to address specific confounders, resulting in frameworks that relatively lack generalization and overlook potential correlations among confounders. The presence of multiple confounders further escalates the complexity and challenges of debiasing learning. To tackle this issue, we introduce the Adversarial Multi-Deconfounded (AMD) Learning Paradigm, a generic training framework designed to eliminate biases from multiple confounders. Our approach leverages adversarial networks to extract confounder-invariant feature representations, guiding the model to ignore potential biases introduced by confounders and extract stable representations independent of these confounders, thereby enhancing generalization. Comprehensive experiments demonstrate that our approach outperforms state-of-the-art methods on the Weibo and GossipCop datasets, and significantly exceeds other methods in generalization evaluation on CHEF. Additionally, we validate that our AMD framework exhibits improved robustness against confounders. | Zixun Sun, Mingye Xu, Guanming Liang, Qi Liu | Interactive Entertainment Group, Tencent Inc., Shenzhen, China |
|  |  [Struct-X: Enhancing the Reasoning Capabilities of Large Language Models in Structured Data Scenarios](https://doi.org/10.1145/3690624.3709381) |  | 0 | Conducting reasoning tasks with large language models (LLMs) on structured and redundant data poses significant challenges, primarily due to the complexity introduced by the structured markdown tokens and the presence of extraneous contextual information. These elements can overburden and disrupt the generation process of LLMs, complicating the extraction of relevant insights and the production of coherent outputs. To address this, we propose Struct-X, a novel framework that operates through five key phases: ''read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize structured data. It begins by encoding structured data into a topological space using graph embeddings, followed by filling in missing entity information with knowledge retrieval modules, and filtering out irrelevant tokens via a self-supervised module. The final phase involves constructing a topological network with selected tokens to further reduce the total token length for more effective LLM inference. Additionally, Struct-X includes an Auxiliary Module trained to generate prompts, aiding LLMs in analyzing structured data. Extensive experiments on open-source benchmarks, including the knowledge graph question-answer task and the long document reading comprehension task, show that Struct-X notably improves LLM reasoning in complex structured input context. Finally, we deployed Struct-X in a real-world financial report analysis task, where it exhibits enhanced reasoning capabilities when applied to authentic scenario. The code has been undergoing open-source development to facilitate easy replication. | Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Leijun Cheng, Yuan Cheng, Wei Chu, Yinghui Xu, Yuan Qi | AI3 Institute, Fudan University, Shanghai, China; INF Technology (Shanghai) Co., Ltd., Shanghai, China; Shanghai University of Engineering Science, Shanghai, China |
|  |  [Cross-Species Insights: Transforming Drug Efficacy from Rats to Humans Using Tissue-Specific Generative Models](https://doi.org/10.1145/3690624.3709389) |  | 0 | Within the realm of drug development, the transition from successful animal trials to human clinical efficacy remains a daunting challenge. While initial outcomes may appear promising in animal studies, ensuring similar effectiveness in humans, especially across specific target tissues, presents a significant obstacle. To address this pressing concern, we introduce a novel generative model tailored to optimize molecules that have demonstrated efficacy in rats for enhanced performance in specific human tissues. Central to our solution is the transformer architecture, enhanced with intricate mechanisms such as molecule self-attention within the encoder and a novel dedicated tissue-specific generator. Intuitively, by learning to generate molecules simultaneously from multiple tissues, the generative model enhances its ability to perform the necessary adaptations from rats to humans. Through rigorous empirical evaluation across various tissues, our model consistently exhibits remarkable efficacy compared to existing methods. We anticipate that this model has the potential to minimize the requirement for lengthy and inconclusive trials, thereby streamlining the drug development process. | Sally Turutov, Kira Radinsky | Technion - Israel Institute of Technology, Haifa, Israel |
|  |  [SoAy: A Solution-based LLM API-using Methodology for Academic Information Seeking](https://doi.org/10.1145/3690624.3709412) |  | 0 | Applying large language models (LLMs) for academic API usage shows promise inreducing researchers' academic information seeking efforts. However, currentLLM API-using methods struggle with complex API coupling commonly encounteredin academic queries. To address this, we introduce SoAy, a solution-based LLMAPI-using methodology for academic information seeking. It uses code with asolution as the reasoning method, where a solution is a pre-constructed APIcalling sequence. The addition of the solution reduces the difficulty for themodel to understand the complex relationships between APIs. Code improves theefficiency of reasoning. To evaluate SoAy, we introduce SoAyBench, an evaluation benchmark accompaniedby SoAyEval, built upon a cloned environment of APIs from AMiner. Experimentalresults demonstrate a 34.58-75.99% performance improvement compared tostate-of-the-art LLM API-based baselines. All datasets, codes, tuned models,and deployed online services are publicly accessible athttps://github.com/RUCKBReasoning/SoAy. | Yuanchun Wang, Jifan Yu, Zijun Yao, Jing Zhang, Yuyang Xie, Shangqing Tu, Yiyang Fu, Youhe Feng, Jinkai Zhang, Jingyao Zhang, Bowen Huang, Yuanyao Li, Huihui Yuan, Lei Hou, Juanzi Li, Jie Tang |  |
|  |  [DynST: Dynamic Sparse Training for Resource-Constrained Spatio-Temporal Forecasting](https://doi.org/10.1145/3690624.3709391) |  | 0 | The ever-increasing sensor service, though opening a precious path and providing a deluge of earth system data for deep-learning-oriented earth science, sadly introduce a daunting obstacle to their industrial level deployment. Concretely, earth science systems rely heavily on the extensive deployment of sensors, however, the data collection from sensors is constrained by complex geographical and social factors, making it challenging to achieve comprehensive coverage and uniform deployment. To alleviate the obstacle, traditional approaches to sensor deployment utilize specific algorithms to design and deploy sensors. These methods dynamically adjust the activation times of sensors to optimize the detection process across each sub-region. Regrettably, formulating an activation strategy generally based on historical observations and geographic characteristics, which make the methods and resultant models were neither simple nor practical. Worse still, the complex technical design may ultimately lead to a model with weak generalizability. In this paper, we introduce for the first time the concept of spatio-temporal data dynamic sparse training and are committed to adaptively, dynamically filtering important sensor distributions. To our knowledge, this is the first proposal (termed DynST) of an industry-level deployment optimization concept at the data level. However, due to the existence of the temporal dimension, pruning of spatio-temporal data may lead to conflicts at different timestamps. To achieve this goal, we employ dynamic merge technology, along with ingenious dimensional mapping to mitigate potential impacts caused by the temporal aspect. During the training process, DynST utilize iterative pruning and sparse training, repeatedly identifying and dynamically removing sensor perception areas that contribute the least to future predictions. | Hao Wu, Haomin Wen, Guibin Zhang, Yutong Xia, Yuxuan Liang, Yu Zheng, Qingsong Wen, Kun Wang |  |
|  |  [LDMapNet-U: An End-to-End System for City-Scale Lane-Level Map Updating](https://doi.org/10.1145/3690624.3709383) |  | 0 | An up-to-date city-scale lane-level map is an indispensable infrastructure and a key enabling technology for ensuring the safety and user experience of autonomous driving systems. In industrial scenarios, reliance on manual annotation for map updates creates a critical bottleneck. Lane-level updates require precise change information and must ensure consistency with adjacent data while adhering to strict standards. Traditional methods utilize a three-stage approach-construction, change detection, and updating-which often necessitates manual verification due to accuracy limitations. This results in labor-intensive processes and hampers timely updates. To address these challenges, we propose LDMapNet-U, which implements a new end-to-end paradigm for city-scale lane-level map updating. By reconceptualizing the update task as an end-to-end map generation process grounded in historical map data, we introduce a paradigm shift in map updating that simultaneously generates vectorized maps and change information. To achieve this, a Prior-Map Encoding (PME) module is introduced to effectively encode historical maps, serving as a critical reference for detecting changes. Additionally, we incorporate a novel Instance Change Prediction (ICP) module that learns to predict associations with historical maps. Consequently, LDMapNet-U simultaneously achieves vectorized map element generation and change detection. To demonstrate the superiority and effectiveness of LDMapNet-U, extensive experiments are conducted using large-scale real-world datasets. In addition, LDMapNet-U has been successfully deployed in production at Baidu Maps since April 2024, supporting map updating for over 360 cities and significantly shortening the update cycle from quarterly to weekly. The updated maps serve hundreds of millions of users and are integrated into the autonomous driving systems of several leading vehicle companies. | Deguo Xia, Weiming Zhang, Xiyan Liu, Wei Zhang, Chenting Gong, Xiao Tan, Jizhou Huang, Mengmeng Yang, Diange Yang |  |
|  |  [Effective AOI-level Parcel Volume Prediction: When Lookahead Parcels Matter](https://doi.org/10.1145/3690624.3709441) |  | 0 | Last-mile Delivery Parcel Volume (LDPV) quantifies the number of parcels destined for a specific region, particularly a manually divided Area-Of-Interest (AOI). Accurate prediction of AOI-level LDPV is crucial for the efficient management of logistics resources. However, the straightforward adaptation of existing prediction models often falls short, primarily due to (I) a lack of consideration for the intuition behind AOI divisions, and (II) a reliance solely on fully observed historical data, which may not inform future trends. To overcome the above pitfalls, leveraging rich AOI data and advanced parcel travel time estimation services in JD Logistics, this paper introduces a novel framework called Dual-view Prediction Networks (DualPNs). It combines a Vector-Quantified AutoEncoder (VQ-AE) and a Template-Augmented Zero-Inflated Poisson (TA-ZIP), enabling both point and probabilistic distribution predictions of AOI-level LDPV. Specifically, VQ-AE utilizes a vector quantization technique to distill a large number of AOIs into representative templates, thereby addressing the first pitfall. Subsequently, TA-ZIP dynamically integrates fully observed and lookahead features, aligning them with template-specific decoders to parameterize the probabilistic distributions, thus resolving the second pitfall. We conduct extensive experiments in two cities, comprising over 47,000 and 126,000 AOIs respectively, to demonstrate the superiority of our DualPNs over other baselines. Moreover, a real-world case study highlights the effectiveness of DualPNs for enhancing downstream courier allocation by yielding an average improvement of 1.51% in the on-time delivery rate. | Yinfeng Xiang, Jiangyi Fang, Chao Li, Haitao Yuan, Yiwei Song, Jiming Chen | Zhejiang University, Hangzhou, China; JD Logisitcs, Beijing, China; National Technological University, Singapore, Singapore; Peking University, Beijing, China |
|  |  [Scalable Area Difficulty Assessment with Knowledge-enhanced AI for Nationwide Logistics Systems](https://doi.org/10.1145/3690624.3709407) |  | 0 | Logistics services have become a core business in online-to-offline e-commerce like Amazon, Alibaba, and JD. In logistics services, a city is partitioned into distinct geographical areas, and each area is assigned a worker, responsible for all delivery tasks within it. Due to varying geographic conditions (e.g., high-rise buildings, buildings without elevators), the difficulty of completing tasks can differ significantly between areas, which results in unbalanced workloads and salaries for workers. The necessity for scalable data-driven methods to assess area difficulty in logistics is well-recognized. However, the significant expenses associated with ground truth data collection limit the capabilities of current machine learning methods. In this paper, we consider a frequently overlooked resource, i.e., the workers' firsthand knowledge of areas, to address this problem in a human-AI collaboration fashion. In particular, we design RAICA (Ranking-Aggregated Isotonic Calibration Assessment) framework, which includes two key modules: (i) a Judgment Rank Aggregation module, which aggregates individual workers' judgment rankings collected from surveys into an overall ranking to mitigate personal biases and inconsistency between different workers; (ii) an Isotonic Calibration module, which calibrates the assessment from existing machine learning models with the aggregated ranking through Isotonic regression to enhance the accuracy of area difficulty assessment with theoretical guarantees. Extensive evaluation based on real-world data including over 2 million orders collected from 97 areas during 6 months by one of the largest logistics companies in the world shows that RAICA outperforms existing methods, increasing F1 score by 0.25. More importantly, RAICA has been deployed by this logistics company, which significantly improved crowdsourcing couriers' salary fairness with a 0.2 decrease in the Gini coefficient across over 1,200 delivery stations nationwide and increased the on-time delivery rates for full-time couriers by 1.67%. | Zejun Xie, Wenjun Lyu, Yiwei Song, Haotian Wang, Guang Yang, Yunhuai Liu, Tian He, Desheng Zhang, Guang Wang | Florida State University, Tallahassee, FL, USA; Rutgers University, Piscataway, NJ, USA; JD Logistics, Beijing, China; Peking University, Beijing, China |
|  |  [Disclosing Actual Controller based on Equity Knowledge Graph Learning](https://doi.org/10.1145/3690624.3709432) |  | 0 | Disclosing Actual Controllers (ACs) of a company has been the basis for financial risk governance. A shareholder in a winning stable coalition, where members make consistent decisions and win in votes, is considered an AC. However, existing methods fail to discover stable coalitions due to the ignorance of various relations other than the shareholding relation among shareholders, such as kinship, subsidiary and so on. Moreover, the above relations form a large-scale equity network, which brings challenges for efficiently identifying winning stable coalitions. We construct an Equity Knowledge Graph (EKG) to represent the semantic and structural information of the equity network. In this paper, we propose an AC disclosure method based on Equity Knowledge Graph Learning (EKGL). Specifically, to discover stable coalitions, EKGL designs a multi-relational aggregation module to aggregate the information of different relations horizontally. Based on the aggregated information, EKGL leverages a metapath-based aggregation module to encode the shareholding structure by capturing different shareholding paths on EKG vertically. To identify winning stable coalitions, we propose a control neural network to simulate the voting process of shareholders. Experiments and a case study on the EKG constructed from real datasets demonstrate that EKGL outperforms baselines by achieving 0.33 improvement in F1 score and reducing time cost. | Qingying Xu, Liang Hong, Mingxuan Shen, Baokun Yi | School of Information Management, Wuhan University, Wuhan, China |
|  |  [AddrLLM: Address Rewriting via Large Language Model on Nationwide Logistics Data](https://doi.org/10.1145/3690624.3709425) |  | 0 | Textual description of a physical location, commonly known as an address, plays an important role in location-based services(LBS) such as on-demand delivery and navigation. However, the prevalence of abnormal addresses, those containing inaccuracies that fail to pinpoint a location, have led to significant costs. Address rewriting has emerged as a solution to rectify these abnormal addresses. Despite the critical need, existing address rewriting methods are limited, typically tailored to correct specific error types, or frequently require retraining to process new address data effectively. In this study, we introduce AddrLLM, an innovative framework for address rewriting that is built upon a retrieval augmented large language model. AddrLLM overcomes aforementioned limitations through a meticulously designed Supervised Fine-Tuning module, an Address-centric Retrieval Augmented Generation module and a Bias-free Objective Alignment module. To the best of our knowledge, this study pioneers the application of LLM-based address rewriting approach to solve the issue of abnormal addresses. Through comprehensive offline testing with real-world data on a national scale and subsequent online deployment, AddrLLM has demonstrated superior performance in integration with existing logistics system. It has significantly decreased the rate of parcel re-routing by approximately 43%, underscoring its exceptional efficacy in real-world applications. | Qinchen Yang, Zhiqing Hong, Dongjiang Cao, Haotian Wang, Zejun Xie, Tian He, Yunhuai Liu, Yu Yang, Desheng Zhang |  |
|  |  [SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction](https://doi.org/10.1145/3690624.3709402) |  | 0 | Sepsis is an organ dysfunction caused by a deregulated immune response to an infection. Early sepsis prediction and identification allow for timely intervention, leading to improved clinical outcomes. Clinical calculators (e.g., the six-organ dysfunction assessment of SOFA in Figure 1) play a vital role in sepsis identification within clinicians' workflow, providing evidence-based risk assessments essential for sepsis diagnosis. However, artificial intelligence (AI) sepsis prediction models typically generate a single sepsis risk score without incorporating clinical calculators for assessing organ dysfunctions, making the models less convincing and transparent to clinicians. To bridge the gap, we propose to mimic clinicians' workflow with a novel framework SepsisCalc to integrate clinical calculators into the predictive model, yielding a clinically transparent and precise model for utilization in clinical settings. Practically, clinical calculators usually combine information from multiple component variables in Electronic Health Records (EHR), and might not be applicable when the variables are (partially) missing. We mitigate this issue by representing EHRs as temporal graphs and integrating a learning module to dynamically add the accurately estimated calculator to the graphs. Experimental results on real-world datasets show that the proposed model outperforms state-of-the-art methods on sepsis prediction tasks. Moreover, we developed a system to identify organ dysfunctions and potential sepsis risks, providing a human-AI interaction tool for deployment, which can help clinicians understand the prediction outputs and prepare timely interventions for the corresponding dysfunctions, paving the way for actionable clinical decision-making support for early intervention. | Changchang Yin, Shihan Fu, Bingsheng Yao, ThaiHoang Pham, Weidan Cao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang | The Ohio State University Wexner, Medical Center, Columbus, Ohio, USA.; Northestern University, Boston, Massachusetts, USA.; The Ohio State University, Columbus, Ohio, USA. |
|  |  [BackdoorMBTI: A Backdoor Learning Multimodal Benchmark Tool Kit for Backdoor Defense Evaluation](https://doi.org/10.1145/3690624.3709385) |  | 0 | We introduce BackdoorMBTI, the first backdoor learning toolkit and benchmark designed for multimodal evaluation across three representative modalities from eleven commonly used datasets. BackdoorMBTI provides a systematic backdoor learning pipeline, encompassing data processing, data poisoning, backdoor training, and evaluation. The generated poison datasets and backdoor models enable detailed evaluation of backdoor defense methods. Given the diversity of modalities, BackdoorMBTI facilitates systematic evaluation across different data types. Furthermore, BackdoorMBTI offers a standardized approach to handling practical factors in backdoor learning, such as issues related to data quality and erroneous labels. We anticipate that BackdoorMBTI will expedite future research in backdoor defense methods within a multimodal context. Code is available at https://anonymous.4open.science/r/BackdoorMBTI-D6A1/README.md. | Haiyang Yu, Tian Xie, Jiaping Gui, Pengyang Wang, Pengzhou Cheng, Ping Yi, Yue Wu |  |
|  |  [MentorPDM: Learning Data-Driven Curriculum for Multi-Modal Predictive Maintenance](https://doi.org/10.1145/3690624.3709388) |  | 0 | Predictive Maintenance (PDM) systems are essential for preemptive monitoring of sensor signals to detect potential machine component failures in industrial assets such as bearings in rotating machinery. Existing PDM systems face two primary challenges: 1) Irregular Signal Acquisition, where data collection from the sensors is intermittent, and 2) Signal Heterogeneity, where the full spectrum of sensor modalities is not effectively integrated. To address these challenges, we propose a Curriculum Learning Framework for Multi-Modal Predictive Maintenance - MentorPDM. MentorPDM consists of 1) a graph-augmented pretraining module that captures intrinsic and structured temporal correlations across time segments via a temporal contrastive learning objective and 2) a bi-level curriculum learning module that captures task complexities for weighing the importance of signal modalities and samples via modality and sample curricula. Empirical results from MentorPDM show promising performance with better generalizability in PDM tasks compared to existing benchmarks. The efficacy of the MentorPDM model will be further demonstrated in real industry testbeds and platforms. | Shuaicheng Zhang, Tuo Wang, Stephen Adams, Sanmitra Bhattacharya, Sunil Reddy Tiyyagura, Edward Bowen, Balaji Veeramani, Dawei Zhou | Virginia Tech, Blacksburg, VA, USA; Deloitte & Touche LLP, New York City, NY, USA; Virginia Tech National Security Institute, Arlington, VA, USA; Deloitte & Touche Assurance & Enterprise Risk Services India Private Limited, Hyderabad, India; Virginia Tech, Blacksburg, Virginia, USA |
|  |  [Multi-period Learning for Financial Time Series Forecasting](https://doi.org/10.1145/3690624.3709422) |  | 0 | Time series forecasting is important in finance domain. Financial time series (TS) patterns are influenced by both short-term public opinions and medium-/long-term policy and market trends. Hence, processing multi-period inputs becomes crucial for accurate financial time series forecasting (TSF). However, current TSF models either use only single-period input, or lack customized designs for addressing multi-period characteristics. In this paper, we propose a Multi-period Learning Framework (MLF) to enhance financial TSF performance. MLF considers both TSF's accuracy and efficiency requirements. Specifically, we design three new modules to better integrate the multi-period inputs for improving accuracy: (i) Inter-period Redundancy Filtering (IRF), that removes the information redundancy between periods for accurate self-attention modeling, (ii) Learnable Weighted-average Integration (LWI), that effectively integrates multi-period forecasts, (iii) Multi-period self-Adaptive Patching (MAP), that mitigates the bias towards certain periods by setting the same number of patches across all periods. Furthermore, we propose a Patch Squeeze module to reduce the number of patches in self-attention modeling for maximized efficiency. MLF incorporates multiple inputs with varying lengths (periods) to achieve better accuracy and reduces the costs of selecting input lengths during training. The codes and datasets are available at https://github.com/Meteor-Stars/MLF. | Xu Zhang, Zhengang Huang, Yunzhi Wu, Xun Lu, Erpeng Qi, Yunkai Chen, Zhongya Xue, Qitong Wang, Peng Wang, Wei Wang | School of Computer Science, Fudan University, Shanghai, China; Université Paris Cité, Paris, France; Ant Group, Shanghai, China |
|  |  [Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination](https://doi.org/10.1145/3690624.3709423) |  | 0 | The vast pre-existing slides serve as rich and important materials to carry lecture knowledge. However, effectively leveraging lecture slides to serve students is difficult due to the multi-modal nature of slide content and the heterogeneous teaching actions. We study the problem of discovering effective designs that convert a slide into an interactive lecture. We develop Slide2Lecture, a tuning-free and knowledge-regulated intelligent tutoring system that can (1) effectively convert an input lecture slide into a structured teaching agenda consisting of a set of heterogeneous teaching actions; (2) create and manage an interactive lecture that generates responsive interactions catering to student learning demands while regulating the interactions to follow teaching actions. Slide2Lecture contains a complete pipeline for learners to obtain an interactive classroom experience to learn the slide. For teachers and developers, Slide2Lecture enables customization to cater to personalized demands. The evaluation rated by annotators and students shows that Slide2Lecture is effective in outperforming the remaining implementation. Slide2Lecture's online deployment has made more than 200K interaction with students in the 3K lecture sessions. We open source Slide2Lecture's implementation in https://anonymous.4open.science/r/slide2lecture-4210/. | Daniel ZhangLi, Zheyuan Zhang, Jifan Yu, Joy Lim Jia Yin, Shangqing Tu, Linlu Gong, Haohua Wang, Zhiyuan Liu, Huiqin Liu, Lei Hou, Juanzi Li |  |

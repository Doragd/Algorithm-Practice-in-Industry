# CIKM2022

## 会议论文列表

本会议共有 652 篇论文

| 标题 | 链接 | 推荐理由 | 推荐度 | 摘要 | 作者 | 组织 |
| --- | --- | --- | --- | --- | --- | --- |
|  |  [Pre-training Tasks for User Intent Detection and Embedding Retrieval in E-commerce Search](https://doi.org/10.1145/3511808.3557670) |  | 0 | BERT-style models pre-trained on the general corpus (e.g., Wikipedia) and fine-tuned on specific task corpus, have recently emerged as breakthrough techniques in many NLP tasks: question answering, text classification, sequence labeling and so on. However, this tech- nique may not always work, especially for two scenarios: a corpus that contains very different text from the general corpus Wikipedia, or a task that learns embedding spacial distribution for a specific purpose (e.g., approximate nearest neighbor search). In this paper, to tackle the above two scenarios that we have encountered in an industrial e-commerce search system, we propose customized and novel pre-training tasks for two critical modules: user intent detec- tion and semantic embedding retrieval. The customized pre-trained models after fine-tuning, being less than 10% of BERT-base's size in order to be feasible for cost-efficient CPU serving, significantly improve the other baseline models: 1) no pre-training model and 2) fine-tuned model from the official pre-trained BERT using general corpus, on both offline datasets and online system. We have open sourced our datasets 1 for the sake of reproducibility and future works. | Yiming Qiu, Chenyu Zhao, Han Zhang, Jingwei Zhuo, Tianhao Li, Xiaowei Zhang, Songlin Wang, Sulong Xu, Bo Long, WenYun Yang | JD Com, Beijing, Peoples R China |
|  |  [Hierarchically Fusing Long and Short-Term User Interests for Click-Through Rate Prediction in Product Search](https://doi.org/10.1145/3511808.3557351) |  | 0 | Estimating Click-Through Rate (CTR) is a vital yet challenging task in personalized product search. However, existing CTR methods still struggle in the product search settings due to the following three challenges including how to more effectively extract users' short-term interests with respect to multiple aspects, how to extract and fuse users' long-term interest with short-term interests, how to address the entangling characteristic of long and short-term interests. To resolve these challenges, in this paper, we propose a new approach named Hierarchical Interests Fusing Network (HIFN), which consists of four basic modules namely Short-term Interests Extractor (SIE), Long-term Interests Extractor (LIE), Interests Fusion Module (IFM) and Interests Disentanglement Module (IDM). Specifically, SIE is proposed to extract user's short-term interests by integrating three fundamental interests encoders within it namely query-dependent, target-dependent and causal-dependent interest encoder, respectively, followed by delivering the resultant representation to the module LIE, where it can effectively capture user longterm interests by devising an attention mechanism with respect to the short-term interests from SIE module. In IFM, the achieved long and short-term interests are further fused in an adaptive manner, followed by concatenating it with original raw context features for the final prediction result. Last but not least, considering the entangling characteristic of long and short-term interests, IDM further devises a self-supervised framework to disentangle long and short-term interests. Extensive offline and online evaluations on a real-world e-commerce platform demonstrate the superiority of HIFN over state-of-the-art methods. | Qijie Shen, Hong Wen, Jing Zhang, Qi Rao | Univ Sydney, Darlington, NSW 2008, Australia; Alibaba Grp, Hangzhou, Peoples R China |
|  |  [Beyond Learning from Next Item: Sequential Recommendation via Personalized Interest Sustainability](https://doi.org/10.1145/3511808.3557415) |  | 0 | Sequential recommender systems have shown effective suggestions by capturing users' interest drift. There have been two groups of existing sequential models: user- and item-centric models. The user-centric models capture personalized interest drift based on each user's sequential consumption history, but do not explicitly consider whether users' interest in items sustains beyond the training time, i.e., interest sustainability. On the other hand, the item-centric models consider whether users' general interest sustains after the training time, but it is not personalized. In this work, we propose a recommender system taking advantages of the models in both categories. Our proposed model captures personalized interest sustainability, indicating whether each user's interest in items will sustain beyond the training time or not. We first formulate a task that requires to predict which items each user will consume in the recent period of the training time based on users' consumption history. We then propose simple yet effective schemes to augment users' sparse consumption history. Extensive experiments show that the proposed model outperforms 10 baseline models on 11 real-world datasets. The codes are available at: https://github.com/dmhyun/PERIS. | Dongmin Hyun, Chanyoung Park, Junsu Cho, Hwanjo Yu | Pohang Univ Sci & Technol, Pohang, South Korea; Korea Adv Inst Sci & Technol, Daejeon, South Korea |
|  |  [Approximate Nearest Neighbor Search under Neural Similarity Metric for Large-Scale Recommendation](https://doi.org/10.1145/3511808.3557098) |  | 0 | Model-based methods for recommender systems have been studied extensively for years. Modern recommender systems usually resort to 1) representation learning models which define user-item preference as the distance between their embedding representations, and 2) embedding-based Approximate Nearest Neighbor (ANN) search to tackle the efficiency problem introduced by large-scale corpus. While providing efficient retrieval, the embedding-based retrieval pattern also limits the model capacity since the form of user-item preference measure is restricted to the distance between their embedding representations. However, for other more precise user-item preference measures, e.g., preference scores directly derived from a deep neural network, they are computationally intractable because of the lack of an efficient retrieval method, and an exhaustive search for all user-item pairs is impractical. In this paper, we propose a novel method to extend ANN search to arbitrary matching functions, e.g., a deep neural network. Our main idea is to perform a greedy walk with a matching function in a similarity graph constructed from all items. To solve the problem that the similarity measures of graph construction and user-item matching function are heterogeneous, we propose a pluggable adversarial training task to ensure the graph search with arbitrary matching function can achieve fairly high precision. Experimental results in both open source and industry datasets demonstrate the effectiveness of our method. The proposed method has been fully deployed in the Taobao display advertising platform and brings a considerable advertising revenue increase. We also summarize our detailed experiences in deployment in this paper. | Rihan Chen, Bin Liu, Han Zhu, Yaoxuan Wang, Qi Li, Buting Ma, Qingbo Hua, Jun Jiang, Yunlong Xu, Hongbo Deng, Bo Zheng | Alibaba Grp, Beijing, Peoples R China |
|  |  [Personalized Query Suggestion with Searching Dynamic Flow for Online Recruitment](https://doi.org/10.1145/3511808.3557416) |  | 0 | Employing query suggestion techniques to assist users in articulating their needs during online search has become increasingly vital for search engines in an age of exponential information growth. The success of a query suggestion system lies in understanding and modeling user search intent behind each query accurately, which can hardly be achieved without personalization efforts on taking advantage of dynamic user feedback behaviors and rich contextual information. This valuable area, however, has been still largely untapped by current query suggestion systems. In this work, we propose Dynamic Searching Flow Model (DSFM), a query suggestion framework that is capable of modeling and refining user search intent progressively in recruitment scenarios by leveraging a dynamic flow mechanism. Here the concepts of local flow and global flow are introduced to capture the real-time intention of users and the overall influence of a session, respectively. By utilizing rich semantic information contained in resumes and job requirements, DSFM enables the personalization of query suggestions. In addition, weighted contrast learning is introduced into the training process to produce more extensive targeted query samples and partially alleviate the exposure bias. The adoption of attention mechanism allows the selection of the most relevant information to compose the final intention representation. Extensive experimental results on different categories of real-world datasets demonstrate the effectiveness of our proposed approach on the task of query suggestion for online recruitment platforms. | Zile Zhou, Xiao Zhou, Mingzhe Li, Yang Song, Tao Zhang, Rui Yan | Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Peking Univ, Wangxuan Inst Comp Technol, Beijing, Peoples R China; BOSS Zhipin, Beijing, Peoples R China; BOSS Zhipin NLP Ctr, Beijing, Peoples R China |
|  |  [SASNet: Stage-aware Sequential Matching for Online Travel Recommendation](https://doi.org/10.1145/3511808.3557126) |  | 0 | Sequential matching, which aims to predict the item a user will next interact with in the sequential context of the user's historical behaviors, is widely adopted in recommender systems. Existing works mainly characterize the sequential context as the dependencies of user interactions, which is less effective for online travel recommendation where users' behaviors are highly correlated with their stages in the travel life cycle. Specifically, users on an online travel platform (OTP) usually go through different stages (e.g., exploring a destination, planning an itinerary), and make several correlated interactions (e.g., booking a flight, reserving a hotel, renting a car) at each stage. In this paper, we propose to capture the deep sequential context by modeling the evolving of user stages, and develop a novel stage-aware deep sequential matching network (SASNet) that incorporates inter-stage and intra-stage dependencies over stage-augmented interaction sequence for more accurate and interpretable recommendation. Extensive experiments on real-world datasets validate the superiority of our model for both online travel recommendation and general next-item recommendation. Our model has been successfully deployed at Fliggy, one of the most popular OTPs in China, and shows good performance in serving online traffic. | Fanwei Zhu, Zulong Chen, Fan Zhang, Jiazhen Lou, Hong Wen, Shui Liu, Qi Rao, Tengfei Yuan, Shenghua Ni, Jinxin Hu, Fuzhen Sun, Quan Lu | Shandong Univ Technol, Zibo, Peoples R China; Zhejiang Univ City Coll, Hangzhou, Peoples R China; Alibaba Grp, Hangzhou, Peoples R China |
|  |  [Approximated Doubly Robust Search Relevance Estimation](https://doi.org/10.1145/3511808.3557145) |  | 0 | Extracting query-document relevance from the sparse, biased click-through log is among the most fundamental tasks in the web search system. Prior art mainly learns a relevance judgment model with semantic features of the query and document and ignores directly counterfactual relevance evaluation from the clicking log. Though the learned semantic matching models can provide relevance signals for tail queries as long as the semantic feature is available. However, such a paradigm lacks the capability to introspectively adjust the biased relevance estimation whenever it conflicts with massive implicit user feedback. The counterfactual evaluation methods, on the contrary, ensure unbiased relevance estimation with sufficient click information. However, they suffer from the sparse or even missing clicks caused by the long-tailed query distribution. In this paper, we propose to unify the counterfactual evaluating and learning approaches for unbiased relevance estimation on search queries with various popularities. Specifically, we theoretically develop a doubly robust estimator with low bias and variance, which intentionally combines the benefits of existing relevance evaluating and learning approaches. We further instantiate the proposed unbiased relevance estimation framework in Baidu search, with comprehensive practical solutions designed regarding the data pipeline for click behavior tracking and online relevance estimation with an approximated deep neural network. Finally, we present extensive empirical evaluations to verify the effectiveness of our proposed framework, finding that it is robust in practice and manages to improve online ranking performance substantially. | Lixin Zou, Changying Hao, Hengyi Cai, Shuaiqiang Wang, Suqi Cheng, Zhicong Cheng, Wenwen Ye, Simiu Gu, Dawei Yin | Baidu Inc, Beijing, Peoples R China |
|  |  [Multi-Interest Refinement by Collaborative Attributes Modeling for Click-Through Rate Prediction](https://doi.org/10.1145/3511808.3557652) |  | 0 | Learning interest representation plays a core role in click-through rate prediction task. Existing Transformer-based approaches learn multi-interests from a sequence of interacted items with rich attributes. The attention weights explain how relevant an item's specific attribute sequence is to the user's interest. However, it implicitly assumes the independence of attributes regarding the same item, which may not always hold in practice. Empirically, the user places varied emphasis on different attributes to consider whether interacting with one item, which is unobserved. Independently modeling each attribute may allow attention to assign probability mass to some unimportant attributes. Collaborative attributes of varied emphasis can be incorporated to help the model more reasonably approximate attributes' relevance to others and generate refined interest representations. To this end, we novelly propose to integrate a dynamic collaborative attribute routing module into Transformer. The module assigns collaborative scores to each attribute of clicked items and induces the extended Transformer to prioritize the influential attributes. To learn collaborative scores without labels, we design a diversity loss to facilitate score differentiation. The comparison with baselines on two real-world benchmark datasets and one industrial dataset validates the effectiveness of the framework. | Huachi Zhou, Jiaqi Fan, Xiao Huang, Ka Ho Li, Zhenyu Tang, Dahai Yu | TCL Corp Res Hong Kong Co Ltd, Sha Tin, Hong Kong, Peoples R China; Hong Kong Polytech Univ, Hung Hom, Hong Kong, Peoples R China |
|  |  [Spherical Graph Embedding for Item Retrieval in Recommendation System](https://doi.org/10.1145/3511808.3557704) |  | 0 | One of the challenging problems in large-scale recommendation systems is to retrieve relevant candidates accurately and efficiently. Graph-based retrievals have been widely deployed in industrial recommendation systems. Previous graph-based methods depend on integrated graph infrastructures because of inherent data dependency in graph learning. However, it could be expensive to develop a graph infrastructure. In this paper, we present a simple and effective graph-based retrieval method, which does not need any graph infrastructures. We conduct extensive offline evaluations and online tests in a real-world recommendation system. The results show that the proposed method outperforms the existing methods. The source code of our algorithm is available online. | Wenqiao Zhu, Yesheng Xu, Xin Huang, Qiyang Min, Xun Zhou | Bytedance Inc, Beijing, Peoples R China |
|  |  [From Product Searches to Conversational Agents for E-Commerce](https://doi.org/10.1145/3511808.3557514) |  | 0 | As consumers' demand for online shopping substantially increased in the last few years, e-commerce companies are still far from providing a high-quality user experience that may compete with in-store experiences. On the one hand, matching search queries with highly relevant products for discovery and browsing is still a challenge within existing search technologies. Available e-commerce solutions hardly provide tools to optimize product search relevance and fail to integrate user behavior signals into the search optimization pipeline. On the other hand, accessing the rich and complex information concealed in an e-commerce catalog through a search bar has not evolved far since its initial adoption. In this talk, we illustrate how the VUI conversational AI platform has been successfully adopted to both improve the user's experience quality with highly relevant search and discovery results and expand the traditional search bar with conversational agents' technology, enriching the user's experience at each stage of the e-commerce product life cycle. We review in depth some of the key deep learning models as part of the query understanding component and discuss the overall conversation architecture as it integrates with an existing e-commerce catalog. We include real-life demonstrations derived from use cases extracted from deployed systems. | Giuseppe Di Fabbrizio | VUI Inc, Boston, MA 02111 USA |
|  |  [OptEmbed: Learning Optimal Embedding Table for Click-through Rate Prediction](https://doi.org/10.1145/3511808.3557411) |  | 0 | Click-through rate (CTR) prediction model usually consists of three components: embedding table, feature interaction layer, and classifier. Learning embedding table plays a fundamental role in CTR prediction from the view of the model performance and memory usage. The embedding table is a two-dimensional tensor, with its axes indicating the number of feature values and the embedding dimension, respectively. To learn an efficient and effective embedding table, recent works either assign various embedding dimensions for feature fields and reduce the number of embeddings respectively or mask the embedding table parameters. However, all these existing works cannot get an optimal embedding table. On the one hand, various embedding dimensions still require a large amount of memory due to the vast number of features in the dataset. On the other hand, decreasing the number of embeddings usually suffers from performance degradation, which is intolerable in CTR prediction. Finally, pruning embedding parameters will lead to a sparse embedding table, which is hard to be deployed. To this end, we propose an optimal embedding table learning framework OptEmbed, which provides a practical and general method to find an optimal embedding table for various base CTR models. Specifically, we propose pruning the redundant embeddings regarding corresponding features' importance by learnable pruning thresholds. Furthermore, we consider assigning various embedding dimensions as one single candidate architecture. To efficiently search the optimal embedding dimensions, we design a uniform embedding dimension sampling scheme to equally train all candidate architectures, meaning architecture-related parameters and learnable thresholds are trained simultaneously in one supernet. We then propose an evolution search method based on the supernet to find the optimal embedding dimensions for each field. Experiments on public datasets show that OptEmbed can learn a compact embedding table which can further improve the model performance. | Fuyuan Lyu, Xing Tang, Hong Zhu, Huifeng Guo, Yingxue Zhang, Ruiming Tang, Xue Liu | McGill Univ, Montreal, PQ, Canada; Huawei Noahs Ark Lab, Shenzhen, Peoples R China; Huawei Noahs Ark Lab, Montreal, PQ, Canada |
|  |  [A Relevant and Diverse Retrieval-enhanced Data Augmentation Framework for Sequential Recommendation](https://doi.org/10.1145/3511808.3557071) |  | 0 | Within online platforms, it is critical to capture the semantics of sequential user behaviors for accurately predicting user interests. Recently, significant progress has been made in sequential recommendation with deep learning. However, existing neural sequential recommendation models may not perform well in practice due to the sparsity of the real-world data especially in cold-start scenarios. To tackle this problem, we propose the model ReDA, which stands for Retrieval-enhanced Data Augmentation for modeling sequential user behaviors. The main idea of our approach is to leverage the related information from similar users for generating both relevant and diverse augmentation. First, we train a neural retriever to retrieve the augmentation users according to the semantic similarity between user representations, and then conduct two types of data augmentation to generate augmented user representations. Furthermore, these augmented data are incorporated in a contrastive learning framework for learning more capable representations. Extensive experiments conducted on both public and industry datasets demonstrate the superiority of our proposed method over existing state-of-the-art methods, especially when only limited training data is available. | Shuqing Bian, Wayne Xin Zhao, Jinpeng Wang, JiRong Wen | Meituan Grp, Beijing, Peoples R China; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Renmin Univ China, Sch Informat, Beijing, Peoples R China |
|  |  [Query Rewriting in TaoBao Search](https://doi.org/10.1145/3511808.3557068) |  | 0 | In the realm of e-commerce search, the significance of semantic matchingcannot be overstated, as it directly impacts both user experience and companyrevenue. Along this line, query rewriting, serving as an important technique tobridge the semantic gaps inherent in the semantic matching process, hasattached wide attention from the industry and academia. However, existing queryrewriting methods often struggle to effectively optimize long-tail queries andalleviate the phenomenon of "few-recall" caused by semantic gap. In this paper,we present BEQUE, a comprehensive framework that Bridges the sEmantic gap forlong-tail QUEries. In detail, BEQUE comprises three stages: multi-instructionsupervised fine tuning (SFT), offline feedback, and objective alignment. Wefirst construct a rewriting dataset based on rejection sampling and auxiliarytasks mixing to fine-tune our large language model (LLM) in a supervisedfashion. Subsequently, with the well-trained LLM, we employ beam search togenerate multiple candidate rewrites, and feed them into Taobao offline systemto obtain the partial order. Leveraging the partial order of rewrites, weintroduce a contrastive learning method to highlight the distinctions betweenrewrites, and align the model with the Taobao online objectives. Offlineexperiments prove the effectiveness of our method in bridging semantic gap.Online A/B tests reveal that our method can significantly boost grossmerchandise volume (GMV), number of transaction (#Trans) and unique visitor(UV) for long-tail queries. BEQUE has been deployed on Taobao, one of mostpopular online shopping platforms in China, since October 2023. | Sen Li, Fuyu Lv, Taiwei Jin, Guiyang Li, Yukun Zheng, Tao Zhuang, Qingwen Liu, Xiaoyi Zeng, James T. Kwok, Qianli Ma | University of Science and Technology of China Hefei; Taotian Group Hangzhou; Taobao and Tmall Group, Hangzhou, Zhejiang, China; CHN Guiyang Li Yue Jiang Zilong Wang |
|  |  [Learning-to-Spell: Weak Supervision based Query Correction in E-Commerce Search with Small Strong Labels](https://doi.org/10.1145/3511808.3557113) |  | 0 | For an E-commerce search engine, users finding the right product critically depend on spell correction. A misspelled query can fetch totally unrelated results which in turn leads to a bad customer experience. Around 32% of queries have spelling mistakes on our e-commerce search engine. The spell problem becomes more challenging when most spell errors arise from customers with little or no exposure to the English language besides the usual source of accidental mistyping on keyboard. These spell errors are heavily influenced by the colloquial and spoken accents of the customers. This limits the benefit from using generic spell correction systems which are learnt from cleaner English sources like Brown Corpus and Wikipedia with a very low focus on phonetic/vernacular spell errors. In this work, we present a novel approach towards spell correction that effectively solves a very diverse set of spell errors and outperforms several state-of-the-art systems in the domain of E-commerce search. Our strategy combines Learning-to-Rank on a small strongly labelled data with multiple learners trained with weakly labelled data. We report the effectiveness of our solution WellSpell (Weak and strong Labels for Learning to Spell) with both the offline evaluations and online A/B experiment. | Madhura Pande, Vishal Kakkar, Manish Bansal, Surender Kumar, Chinmay Sharma, Himanshu Malhotra, Praneet Mehta | Flipkart, Bangalore, Karnataka, India |
|  |  [TripJudge: A Relevance Judgement Test Collection for TripClick Health Retrieval](https://doi.org/10.1145/3511808.3557714) |  | 0 | Robust test collections are crucial for Information Retrieval research. Recently there is a growing interest in evaluating retrieval systems for domain-specific retrieval tasks, however these tasks often lack a reliable test collection with human-annotated relevance assessments following the Cranfield paradigm. In the medical domain, the TripClick collection was recently proposed, which contains click log data from the Trip search engine and includes two click-based test sets. However the clicks are biased to the retrieval model used, which remains unknown, and a previous study shows that the test sets have a low judgement coverage for the Top-10 results of lexical and neural retrieval models. In this paper we present the novel, relevance judgement test collection TripJudge for TripClick health retrieval. We collect relevance judgements in an annotation campaign and ensure the quality and reusability of TripJudge by a variety of ranking methods for pool creation, by multiple judgements per query-document pair and by an at least moderate inter-annotator agreement. We compare system evaluation with TripJudge and TripClick and find that that click and judgement-based evaluation can lead to substantially different system rankings. | Sophia Althammer, Sebastian Hofstätter, Suzan Verberne, Allan Hanbury | Leiden Univ, Leiden, Netherlands; Vienna Univ Technol, Vienna, Austria |
|  |  [Query-Aware Sequential Recommendation](https://doi.org/10.1145/3511808.3557677) |  | 0 | Sequential recommenders aim to capture users' dynamic interests from their historical action sequences, but remain challenging due to data sparsity issues, as well as the noisy and complex relationships among items in a sequence. Several approaches have sought to alleviate these issues using side-information , such as item content (e.g., images), action types (e.g., click, purchase). While useful, we argue one of the main contextual signals is largely ignored-namely users' queries . When users browse and consume products (e.g., music, movies), their sequential interactions are usually a combination of queries, clicks (etc.). Most interaction datasets discard queries, and corresponding methods simply model sequential behaviors over items and thus ignore this critical context of user interactions. In this work, we argue that user queries should be an important contextual cue for sequential recommendation. First, we propose a new query-aware sequential recommendation setting, i.e. incorpo- rating explicit user queries to model users' intent. Next, we propose a model, namely Query-SeqRec , to (1) incorporate query information into user behavior sequences; and (2) improve model generalization ability using query-item co-occurrence information. Last, we demonstrate the effectiveness of incorporating query features in sequential recommendation on three datasets. 1 | Zhankui He, Handong Zhao, Zhaowen Wang, Zhe Lin, Ajinkya Kale, Julian J. McAuley | Univ Calif San Diego, San Diego, CA USA; Adobe Res, San Francisco, CA 94107 USA |
|  |  [AMinerGNN: Heterogeneous Graph Neural Network for Paper Click-through Rate Prediction with Fusion Query](https://doi.org/10.1145/3511808.3557544) |  | 0 | Paper recommendation with user-generated keyword is to suggest papers that simultaneously meet user's interests and are relevant to the input keyword. This is a recommendation task with two queries, a.k.a. user ID and keyword. However, existing methods focus on recommendation according to one query, a.k.a. user ID, and are not applicable to solving this problem. In this paper, we propose a novel click-through rate (CTR) prediction model with heterogeneous graph neural network, called AMinerGNN, to recommend papers with two queries. Specifically, AMinerGNN constructs a heterogeneous graph to project user, paper, and keyword into the same embedding space by graph representation learning. To process two queries, a novel query attentive fusion layer is designed to recognize their importances dynamically and then fuse them as one query to build a unified and end-to-end recommender system. Experimental results on our proposed dataset and online A/B tests prove the superiority of AMinerGNN. | Zepeng Huai, Zhe Wang, Yifan Zhu, Peng Zhang | Zhipu AI Lab, Beijing, Peoples R China; ByteDance Inc, Mountain View, CA USA; Tsinghua Univ, Beijing, Peoples R China; UCAS, Sch Artificial Intelligence, Beijing, Peoples R China |
|  |  [A Hierarchical User Behavior Modeling Framework for Cross-Domain Click-Through Rate Prediction](https://doi.org/10.1145/3511808.3557531) |  | 0 | Click-through rate (CTR) prediction is a long-standing problem in advertising systems. Existing single-domain CTR prediction methods suffer from the data sparsity problem since few users can click advertisements on many items. Recently, cross-domain CTR prediction leverages the relatively richer information from a source domain to improve the performance on a target domain with sparser information, but it cannot explicitly capture users' diverse interests in different domains. In this paper, we propose a novel hierarchical user behavior modeling framework for cross-domain CTR prediction, named HBMNet. HBMNet contains two main components: an element-wise behavior transfer(EWBT) layer and a user representation layer. EWBT layer transfers the information collected from one domain by element-level masks to dynamically highlight the informative elements in another domain. The user representation layer performs behavior-level attention between these behavior representations and the ranking item representation. Extensive experimental results on two cross-domain datasets show that the proposed HBMNet outperforms SOTA models. | Hai Li, Xin Dong, Lei Cheng, Linjian Mo | Ant Grp, Shanghai, Peoples R China; Ant Grp, Hangzhou, Peoples R China |
|  |  [A Multi-Interest Evolution Story: Applying Psychology in Query-based Recommendation for Inferring Customer Intention](https://doi.org/10.1145/3511808.3557221) |  | 0 | The query-based recommendation now is becoming a basic research topic in the e-commerce scenario. Generally, given a query that a user typed, it aims to provide a set of items that the user may be interested in. In this task, the customer intention ( i.e. , browsing or purchase) is an important factor to configure the corresponding recommendation strategy for better shopping experiences (i.e., providing diverse items when the user prefers to browse or recommending specific items when detecting the user is willing to purchase). Though necessary, this is usually overlooked in previous works. In addition, the diversity and evolution of user interests also bring challenges to inferring user intentions correctly. In this paper, we propose a predecessor task to infer two important customer intentions, which are purchasing and browsing respectively, and we introduce a novel P sychological I ntention P rediction M odel ( PIPM for short) to address this issue. Inspired by cognitive psychology, we first devise a multi-interest extraction module to adaptively extract interests from the user-item interaction sequence. After this, we design an interest evolution layer to model the evolution of the mined multiple interests. Finally, we aggregate all evolved multiple interests to infer users' intentions in his/her next visit. Extensive experiments are conducted on a large-scale Taobao industrial dataset. The results demonstrate that PIPM gains a significant improvement on AUC and GAUC than state-of-the-art baselines. Notably, PIPM has been deployed on the Taobao e-commerce platform and obtained over 10% improvement on PCTR. | Yuqi Qin, Pengfei Wang, Biyu Ma, Zhe Zhang | Xidian Univ, Xian, Peoples R China; Zhejiang Univ, Hangzhou, Peoples R China; Beijing University of Posts and Telecommunications, Beijing, China |
|  |  [Graph Based Long-Term And Short-Term Interest Model for Click-Through Rate Prediction](https://doi.org/10.1145/3511808.3557336) |  | 0 | Click-through rate (CTR) prediction aims to predict the probability that the user will click an item, which has been one of the key tasks in online recommender and advertising systems. In such systems, rich user behavior (viz. long- and short-term) has been proved to be of great value in capturing user interests. Both industry and academy have paid much attention to this topic and propose different approaches to modeling with long-term and short-term user behavior data. But there are still some unresolved issues. More specially, (1) rule and truncation based methods to extract information from long-term behavior are easy to cause information loss, and (2) single feedback behavior regardless of scenario to extract information from short-term behavior lead to information confusion and noise. To fill this gap, we propose a Graph based Long-term and Short-term interest Model, termed GLSM. It consists of a multi-interest graph structure for capturing long-term user behavior, a multi-scenario heterogeneous sequence model for modeling short-term information, then an adaptive fusion mechanism to fused information from long-term and short-term behaviors. Comprehensive experiments on real-world datasets, GLSM achieved SOTA score on offline metrics. At the same time, the GLSM algorithm has been deployed in our industrial application, bringing 4.9% CTR and 4.3% GMV lift, which is significant to the business. | Huinan Sun, Guangliang Yu, Pengye Zhang, Bo Zhang, Xingxing Wang, Dong Wang | Meituan, Beijing, Peoples R China |
|  |  [A Biased Sampling Method for Imbalanced Personalized Ranking](https://doi.org/10.1145/3511808.3557218) |  | 0 | Pairwise ranking models have been widely used to address recommendation problems. The basic idea is to learn the rank of users' preferred items through separating items into positive samples if user-item interactions exist, and negative samples otherwise. Due to the limited number of observable interactions, pairwise ranking models face serious class-imbalance issues. Our theoretical analysis shows that current sampling-based methods cause the vertex-level imbalance problem, which makes the norm of learned item embeddings towards infinite after a certain training iterations, and consequently results in vanishing gradient and affects the model inference results. We thus propose an efficient Vital Negative Sampler (VINS) to alleviate the class-imbalance issue for pairwise ranking model, in particular for deep learning models optimized by gradient methods. The core of VINS is a bias sampler with reject probability that will tend to accept a negative candidate with a larger degree weight than the given positive item. Evaluation results on several real datasets demonstrate that the proposed sampling method speeds up the training procedure 30% to 50% for ranking models ranging from shallow to deep, while maintaining and even improving the quality of ranking results in top-N item recommendations. | Lu Yu, Shichao Pei, Feng Zhu, Longfei Li, Jun Zhou, Chuxu Zhang, Xiangliang Zhang | Univ Notre Dame, Notre Dame, IN 46556 USA; Ant Grp, Hangzhou, Peoples R China; Brandeis Univ, Waltham, MA 02254 USA |
|  |  [Tiger: Transferable Interest Graph Embedding for Domain-Level Zero-Shot Recommendation](https://doi.org/10.1145/3511808.3557472) |  | 0 | Recommender systems play a significant role in online services and have attracted wide attention from both academia and industry. In this paper, we focus on an important, practical, but often overlooked task: domain-level zero-shot recommendation (DZSR). The challenge of DZSR mainly lies in the absence of collaborative behaviors in the target domain, which may be caused by various reasons, such as the domain being newly launched without existing user-item interactions, or users' behaviors being too sensitive to collect for training. To address this challenge, we propose a T ransferable I nterest G raph E mbedding technique for R ecommendations (Tiger). The key idea is to connect isolated collaborative filtering datasets with a knowledge graph tailored to recommendations, then propagate collaborative signals from public domains to the zero-shot target domain. The backbone of Tiger is the transferable interest extractor, which is a simple yet effective graph convolutional network (GCN) aggregating multiple hops of neighbors on a shared interest graph. We find that the bottom layers of GCN preserve more domain-specific information while the upper layers represent universal interest better. Thus, in Tiger, we discard the bottom layers of GCN to reconstruct user interest so that collaborative signals can be successfully propagated to other domains, and retain the bottom layers of GCN to include domain-specific information for items. Extensive experiments with four public datasets demonstrate that Tiger can effectively make recommendations for a zero-shot domain and outperform several alternative baselines. | Jianhuan Zhuo, Jianxun Lian, Lanling Xu, Ming Gong, Linjun Shou, Daxin Jiang, Xing Xie, Yinliang Yue | Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Microsoft Res Asia, Beijing, Peoples R China; Microsoft STC Asia, Beijing, Peoples R China; Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China |
|  |  [E-Commerce Promotions Personalization via Online Multiple-Choice Knapsack with Uplift Modeling](https://doi.org/10.1145/3511808.3557100) |  | 0 | Promotions and discounts are essential components of modern e-commerce platforms, where they are often used to incentivize customers towards purchase completion. Promotions also affect revenue and may incur a monetary loss that is often limited by a dedicated promotional budget. We propose an Online Constrained Multiple-Choice Promotions Personalization framework, driven by causal incremental estimations achieved by uplift modeling. Our work formalizes the problem as an Online Multiple-Choice Knapsack Problem and extends the existent literature by addressing cases with negative weights and values as a result from causal estimations. Our real-time adaptive method guarantees budget constraints compliance achieving above 99.7% of the potential optimal impact on various datasets. It was deployed in a large-scale experimental study at Booking.com - one of the leading online travel platforms in the world. The application resulted in 162% improvement in sales while complying a zero-budget constraint, enabling long-term self-sponsored promotional campaigns. | Javier Albert, Dmitri Goldenberg | Booking Com, Tel Aviv, Israel |
|  |  [Best Practices for Top-N Recommendation Evaluation: Candidate Set Sampling and Statistical Inference Techniques](https://doi.org/10.1145/3511808.3557816) |  | 0 | ABSTRACTTop-N recommendation evaluation experiments are complex, with many decisions needed. These decisions are often made inconsistently, and we don't have clear best practices for many of them. The goal of this project, is to identify, substantiate, and document best practices to improve evaluations. | Ngozi Ihemelandu | Boise State University, Boise, ID, USA |
|  |  [Hard Negatives or False Negatives: Correcting Pooling Bias in Training Neural Ranking Models](https://doi.org/10.1145/3511808.3557343) |  | 0 | Neural ranking models (NRMs) have become one of the most important techniques in information retrieval (IR). Due to the limitation of relevance labels, the training of NRMs heavily relies on negative sampling over unlabeled data. In general machine learning scenarios, it has shown that training with hard negatives (i.e., samples that are close to positives) could lead to better performance. Surprisingly, we find opposite results from our empirical studies in IR. When sampling top-ranked results (excluding the labeled positives) as negatives from a stronger retriever, the performance of the learned NRM becomes even worse. Based on our investigation, the superficial reason is that there are more false negatives (i.e., unlabeled positives) in the top-ranked results with a stronger retriever, which may hurt the training process; The root is the existence of pooling bias in the dataset constructing process, where annotators only judge and label very few samples selected by some basic retrievers. Therefore, in principle, we can formulate the false negative issue in training NRMs as learning from labeled datasets with pooling bias. To solve this problem, we propose a novel Coupled Estimation Technique (CET) that learns both a relevance model and a selection model simultaneously to correct the pooling bias for training NRMs. Empirical results on three retrieval benchmarks show that NRMs trained with our technique can achieve significant gains on ranking effectiveness against other baseline strategies. | Yinqiong Cai, Jiafeng Guo, Yixing Fan, Qingyao Ai, Ruqing Zhang, Xueqi Cheng | Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, Dept CS&T, Beijing, Peoples R China; Univ Chinese Acad Sci, CAS Key Lab Network Data Sci & Technol, ICT, CAS, Beijing, Peoples R China |
|  |  [Contrastive Cross-Domain Sequential Recommendation](https://doi.org/10.1145/3511808.3557262) |  | 0 | Cross-Domain Sequential Recommendation (CDSR) aims to predict future interactions based on user's historical sequential interactions from multiple domains. Generally, a key challenge of CDSR is how to mine precise cross-domain user preference based on the intra-sequence and inter-sequence item interactions. Existing works first learn single-domain user preference only with intra-sequence item interactions, and then build a transferring module to obtain cross-domain user preference. However, such a pipeline and implicit solution can be severely limited by the bottleneck of the designed transferring module, and ignores to consider inter-sequence item relationships. In this paper, we propose C2DSR to tackle the above problems to capture precise user preferences. The main idea is to simultaneously leverage the intra- and inter- sequence item relationships, and jointly learn the single- and cross- domain user preferences. Specifically, we first utilize a graph neural network to mine inter-sequence item collaborative relationship, and then exploit sequential attentive encoder to capture intra-sequence item sequential relationship. Based on them, we devise two different sequential training objectives to obtain user single-domain and cross-domain representations. Furthermore, we present a novel contrastive cross-domain infomax objective to enhance the correlation between single- and cross- domain user representations by maximizing their mutual information. Additionally, we point out a serious information leak issue in prior datasets. We correct this issue and release the corrected datasets. Extensive experiments demonstrate the effectiveness of our approach C2DSR. | Jiangxia Cao, Xin Cong, Jiawei Sheng, Tingwen Liu, Bin Wang | Univ Chinese Acad Sci, Sch Cyber Secur, Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China; Xiaomi Inc, Xiaomi AI Lab, Beijing, Peoples R China |
|  |  [Contrastive Learning with Bidirectional Transformers for Sequential Recommendation](https://doi.org/10.1145/3511808.3557266) |  | 0 | Contrastive learning with Transformer-based sequence encoder has gained predominance for sequential recommendation due to its ability to mitigate the data noise and the data sparsity issue. However, existing contrastive learning approaches for sequential recommendation still suffer from two limitations. First, they mainly center on left-to-right unidirectional Transformers as base encoders, which are suboptimal for sequential recommendation because user behaviors may not be a rigid left-to-right sequence. Second, they devise contrastive learning objectives only from the sequence level, neglecting the rich self-supervision signals from the feature level. To address these limitations, we propose a novel framework called Feature-aware Contrastive Learning with bidirectional Transformers for sequential Recommendation (FCLRec) to effectively leverage feature information for sequential recommendation. Specifically, we first augment bidirectional Transformers with a novel feature-aware self-attention module that is able to simultaneously model the complex relationships between sequences and features. Next, we propose a novel feature-aware contrastive learning objective that generates a collection of positive samples via three types of augmentations from three different levels. Finally, we adopt feature prediction as an auxiliary task to strengthen the connections between items and features. Our experimental results on four public benchmark datasets show that FCLRec outperforms the state-of-the-art methods for sequential recommendation. | Hanwen Du, Hui Shi, Pengpeng Zhao, Deqing Wang, Victor S. Sheng, Yanchi Liu, Guanfeng Liu, Lei Zhao | Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China; Rutgers State Univ, New Brunswick, NJ 08854 USA; Soochow Univ, Sch Comp Sci & Technol, Suzhou 215003, Peoples R China; Texas Tech Univ, Dept Comp Sci, Lubbock, TX 79409 USA; Macquarie Univ, Sydney 2109, Australia |
|  |  [Quantifying and Mitigating Popularity Bias in Conversational Recommender Systems](https://doi.org/10.1145/3511808.3557423) |  | 0 | Conversational recommender systems (CRS) have shown great success in accurately capturing a user's current and detailed preference through the multi-round interaction cycle while effectively guiding users to a more personalized recommendation. Perhaps surprisingly, conversational recommender systems can be plagued by popularity bias, much like traditional recommender systems. In this paper, we systematically study the problem of popularity bias in CRSs. We demonstrate the existence of popularity bias in existing state-of-the-art CRSs from an exposure rate, a success rate, and a conversational utility perspective, and propose a suite of popularity bias metrics designed specifically for the CRS setting. We then introduce a debiasing framework with three unique features: (i) Popularity-Aware Focused Learning to reduce the popularity-distorting impact on preference prediction; (ii) Cold-Start Item Embedding Reconstruction via Attribute Mapping, to improve the modeling of cold-start items; and (iii) Dual-Policy Learning, to better guide the CRS when dealing with either popular or unpopular items. Through extensive experiments on two frequently used CRS datasets, we find the proposed model-agnostic debiasing framework not only mitigates the popularity bias in state-of-the-art CRSs but also improves the overall recommendation performance. | Allen Lin, Jianling Wang, Ziwei Zhu, James Caverlee | George Mason Univ, Fairfax, VA USA; Texas A&M Univ, College Stn, TX 77843 USA |
|  |  [Dual-Task Learning for Multi-Behavior Sequential Recommendation](https://doi.org/10.1145/3511808.3557298) |  | 0 | Recently, sequential recommendation has become a research hotspot while multi-behavior sequential recommendation (MBSR) that exploits users' heterogeneous interactions in sequences has received relatively little attention. Existing works often overlook the complementary effect of different perspectives when addressing the MBSR problem. In addition, there are two specific challenges remained to be addressed. One is the heterogeneity of a user's intention and the context information, the other one is the sparsity of the interactions of target behavior. To release the potential of multi-behavior interaction sequences, we propose a novel framework named NextIP that adopts a dual-task learning strategy to convert the problem to two specific tasks, i.e., next-item prediction and purchase prediction. For next-item prediction, we design a target-behavior aware context aggregator (TBCG), which utilizes the next behavior to guide all kinds of behavior-specific item sub-sequences to jointly predict the next item. For purchase prediction, we design a behavior-aware self-attention (BSA) mechanism to extract a user's behavior-specific interests and treat them as negative samples to learn the user's purchase preferences. Extensive experimental results on two public datasets show that our NextIP performs significantly better than the state-of-the-art methods. | Jinwei Luo, Mingkai He, Xiaolin Lin, Weike Pan, Zhong Ming | Shenzhen Univ, Shenzhen, Peoples R China |
|  |  [Learning Chinese Word Embeddings By Discovering Inherent Semantic Relevance in Sub-characters](https://doi.org/10.1145/3511808.3557376) |  | 0 | Learning Chinese word embeddings is important in many tasks of Chinese language information processing, such as entity linking, entity extraction, and knowledge graph. A Chinese word consists of Chinese characters, which can be decomposed into sub-characters (radical, component, stroke, etc). Similar to roots in English words, sub-characters also indicate the origins and basic semantics of Chinese characters. So, many researches follow the approaches designed for learning embeddings of English words to improve Chinese word embeddings. However, some Chinese characters sharing the same sub-characters have different meanings. Furthermore, with more cultural interaction and the popularization of the Internet and web, many neologisms, such as transliterated loanwords and network terms, are emerging, which are only close to the pronunciation of their characters, but far from their semantics. Here, a tripartite weighted graph is proposed to model the semantic relationship among words, characters, and sub-characters, in which the semantic relationship is evaluated according to the Chinese linguistic information. So, the semantic relevance hidden in lower components (sub-characters, characters) can be used to further distinguish the semantics of corresponding higher components (characters, words). Then, the tripartite weighted graph is fed into our Chinese word embedding model insideCC to reveal the semantic relationship among different language components, and learn the embeddings of words. Extensive experimental results on multiple corpora and datasets verify that our proposed methods outperform the state-of-the-art counterparts by a significant margin. | Wei Lu, Zhaobo Zhang, Pingpeng Yuan, Hai Jin, QiangSheng Hua | Huazhong Univ Sci & Technol, Serv Comp Technol & Syst Lab, Natl Engn Res Ctr Big Data Technol & Syst, Cluster & Grid Comp Lab,Sch Comp Sci & Technol, Wuhan, Peoples R China |
|  |  [ContrastVAE: Contrastive Variational AutoEncoder for Sequential Recommendation](https://doi.org/10.1145/3511808.3557268) |  | 0 | Aiming at exploiting the rich information in user behaviour sequences, sequential recommendation has been widely adopted in real-world recommender systems. However, current methods suffer from the following issues: 1) sparsity of user-item interactions, 2) uncertainty of sequential records, 3) long-tail items. In this paper, we propose to incorporate contrastive learning into the framework of Variational AutoEncoders to address these challenges simultaneously. Firstly, we introduce ContrastELBO, a novel training objective that extends the conventional single-view ELBO to two-view case and theoretically builds a connection between VAE and contrastive learning from a two-view perspective. Then we propose Contrastive Variational AutoEncoder (ContrastVAE in short), a two-branched VAE model with contrastive regularization as an embodiment of ContrastELBO for sequential recommendation. We further introduce two simple yet effective augmentation strategies named model augmentation and variational augmentation to create a second view of a sequence and thus making contrastive learning possible. Experiments on four benchmark datasets demonstrate the effectiveness of ContrastVAE and the proposed augmentation methods. Codes are available at https://github.com/YuWang-1024/ContrastVAE | Yu Wang, Hengrui Zhang, Zhiwei Liu, Liangwei Yang, Philip S. Yu | Univ Illinois, Chicago, IL 60607 USA; Salesforce, San Francisco, CA USA |
|  |  [Adapting Triplet Importance of Implicit Feedback for Personalized Recommendation](https://doi.org/10.1145/3511808.3557229) |  | 0 | Implicit feedback is frequently used for developing personalized recommendation services due to its ubiquity and accessibility in real-world systems. In order to effectively utilize such information, most research adopts the pairwise ranking method on constructed training triplets (user, positive item, negative item) and aims to distinguish between positive items and negative items for each user. However, most of these methods treat all the training triplets equally, which ignores the subtle difference between different positive or negative items. On the other hand, even though some other works make use of the auxiliary information (e.g., dwell time) of user behaviors to capture this subtle difference, such auxiliary information is hard to obtain. To mitigate the aforementioned problems, we propose a novel training framework named Triplet Importance Learning (TIL), which adaptively learns the importance score of training triplets. We devise two strategies for the importance score generation and formulate the whole procedure as a bilevel optimization, which does not require any rule-based design. We integrate the proposed training procedure with several Matrix Factorization (MF)- and Graph Neural Network (GNN)-based recommendation models, demonstrating the compatibility of our framework. Via a comparison using three real-world datasets with many state-of-the-art methods, we show that our proposed method outperforms the best existing models by 3-21% in terms of Recall@k for the top-k recommendation. | Haolun Wu, Chen Ma, Yingxue Zhang, Xue Liu, Ruiming Tang, Mark Coates | McGill Univ, Montreal, PQ, Canada; City Univ Hong Kong, Hong Kong, Peoples R China; Huawei Noahs Ark Lab, Shenzhen, Peoples R China; Huawei Noahs Ark Lab, Montreal, PQ, Canada |
|  |  [Dually Enhanced Propensity Score Estimation in Sequential Recommendation](https://doi.org/10.1145/3511808.3557299) |  | 0 | Sequential recommender systems train their models based on a large amount of implicit user feedback data and may be subject to biases when users are systematically under/over-exposed to certain items. Unbiased learning based on inverse propensity scores (IPS), which estimate the probability of observing a user-item pair given the historical information, has been proposed to address the issue. In these methods, propensity score estimation is usually limited to the view of item, that is, treating the feedback data as sequences of items that interacted with the users. However, the feedback data can also be treated from the view of user, as the sequences of users that interact with the items. Moreover, the two views can jointly enhance the propensity score estimation. Inspired by the observation, we propose to estimate the propensity scores from the views of user and item, called Dually Enhanced Propensity Score Estimation (DEPS). Specifically, given a target user-item pair and the corresponding item and user interaction sequences, DEPS firstly constructs a time-aware causal graph to represent the user-item observational probability. According to the graph, two complementary propensity scores are estimated from the views of item and user, respectively, based on the same set of user feedback data. Finally, two transformers are designed to make the final preference prediction. Theoretical analysis showed the unbiasedness and variance of DEPS. Experimental results on three publicly available and an industrial datasets demonstrated that DEPS can significantly outperform the state-of-the-art baselines. | Chen Xu, Jun Xu, Xu Chen, Zhenhua Dong, JiRong Wen | Renmin University of China, Beijing, China; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Huawei Noahs Ark Lab, Montreal, PQ, Canada |
|  |  [Hierarchical Item Inconsistency Signal Learning for Sequence Denoising in Sequential Recommendation](https://doi.org/10.1145/3511808.3557348) |  | 0 | Sequential recommender systems aim to recommend the next items in which target users are most interested based on their historical interaction sequences. In practice, historical sequences typically contain some inherent noise (e.g., accidental interactions), which is harmful to learn accurate sequence representations and thus misleads the next-item recommendation. However, the absence of supervised signals (i.e., labels indicating noisy items) makes the problem of sequence denoising rather challenging. To this end, we propose a novel sequence denoising paradigm for sequential recommendation by learning hierarchical item inconsistency signals. More specifically, we design a hierarchical sequence denoising (HSD) model, which first learns two levels of inconsistency signals in input sequences, and then generates noiseless subsequences (i.e., dropping inherent noisy items) for subsequent sequential recommenders. It is noteworthy that HSD is flexible to accommodate supervised item signals, if any, and can be seamlessly integrated with most existing sequential recommendation models to boost their performance. Extensive experiments on five public benchmark datasets demonstrate the superiority of HSD over state-of-the-art denoising methods and its applicability over a wide variety of mainstream sequential recommendation models. The implementation code is available at https://github.com/zc-97/HSD | Chi Zhang, Yantong Du, Xiangyu Zhao, Qilong Han, Rui Chen, Li Li | Harbin Engn Univ, Harbin, Peoples R China; City Univ Hong Kong, Hong Kong, Peoples R China; Univ Delaware, Newark, DE USA |
|  |  [Two-Level Graph Path Reasoning for Conversational Recommendation with User Realistic Preference](https://doi.org/10.1145/3511808.3557482) |  | 0 | Conversational recommender systems model user dynamic preferences and recommend items based on multi-turn interactions. Though the conversational recommender system has achieved good performance, it has two limitations. On the one hand, researchers usually random select an anchor item from user's historical interactions to simulate the interaction with the real user, but some items in the historical interactions do not fit the user realistic preferences (item noise). On the other hand, it pays too much attention to user dynamic preferences, but nurses some static preferences that are difficult to change over a short period. In fact, when there is no explicit attribute preference in user's conversation, the user static preferences can also be used to make recommendations. To address the aforementioned issues, a novel method that combines graph path reasoning with multi-turn conversation is proposed, called Graph Path reasoning for conversational Recommendation (GPR). In GPR, a soft-clustering is designed to classify items and then set operations are utilized to filter the noise in the user's historical interactions. To capture user dynamic preferences and take account of the user inherent static preferences, GPR asks questions about attributes in the attribute-level reasoning and asks whether the items fit user static preferences in the item-level reasoning on a heterogeneous graph. In the multi-turn of two-level graph path reasoning, a reinforcement learning is used to obtain the optimal path and accurately recommend items to users. Extensive experiments conducted on two benchmark datasets verify that GPR can significantly improve recommendation performance and reduce the turn of path reasoning. | Rongmei Zhao, Shenggen Ju, Jian Peng, Ning Yang, Fanli Yan, Siyu Sun | Sichuan Univ, Sch Comp Sci, Chengdu, Peoples R China |
|  |  [GIFT: Graph-guIded Feature Transfer for Cold-Start Video Click-Through Rate Prediction](https://doi.org/10.1145/3511808.3557120) |  | 0 | Short video has witnessed rapid growth in the past few years in e-commerce platforms like Taobao. To ensure the freshness of the content, platforms need to release a large number of new videos every day, making conventional click-through rate (CTR) prediction methods suffer from the item cold-start problem. In this paper, we propose GIFT, an efficient Graph-guIded Feature Transfer system, to fully take advantages of the rich information of warmed-up videos to compensate for the cold-start ones. Specifically, we establish a heterogeneous graph that contains physical and semantic linkages to guide the feature transfer process from warmed-up video to cold-start videos.Specifically, we establish a heterogeneous graph that contains physical and semantic linkages to guide the feature transfer process. The physical linkages consist of the explicit relationships (e.g., produced by the same author, or showcasing the same product etc.), and the semantic linkages measure the proximity of multi-modal representations of two videos. We elaborately design the feature transfer function to make aware of different parts of transferred features (e.g., id representations and historical statistics) from different types of nodes and edges along the metapath on the graph. We conduct extensive experiments on a large real-world dataset, and the results show that our GIFT system outperforms SOTA methods significantly and brings a 6.82% lift on CTR in the homepage of Taobao App. | Yi Cao, Sihao Hu, Yu Gong, Zhao Li, Yazheng Yang, Qingwen Liu, Shouling Ji | Alibaba Grp, Beijing, Peoples R China; Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China |
|  |  [Knowledge Enhanced Multi-Interest Network for the Generation of Recommendation Candidates](https://doi.org/10.1145/3511808.3557114) |  | 0 | Candidate generation task requires that candidates related to user interests need to be extracted in realtime. Previous works usually transform a user's behavior sequence to a unified embedding, which can not reflect the user's multiple interests. Some recent works like Comirec and Octopus use multi-channel structures to capture users' diverse interests. They cluster users' historical behaviors into several groups, claiming that one group represents one interest. However, these methods have some limitations. First, an item may correspond to multiple interests of users, thereby simply allocating it to just one interest group will make the modeling of users' interests coarse-grained and inaccurate. Second, explaining user interests at the level of items is rather vague and not convincing. In this paper, we propose a Knowledge Enhanced Multi-Interest Network: KEMI, which exploits knowledge graphs to help learn users' diverse interest representations via heterogeneous graph neural networks (HGNNs) and a novel dual memory network. Specifically, we use HGNNs to capture the semantic representation of knowledge entities and a novel dual memory network to learn a user's diverse interests from his behavior sequence. Through memory slots of the user memory network and the item memory network, we can learn multiple interests for each user and each item. Meanwhile, by binding the entities to the channels of memory networks, we enable it to be explained from the perspective of the knowledge graph, which enhances the interpretability and understanding of user interests. We conduct extensive experiments on two industrial and publicly available datasets. Experimental results demonstrate that our model achieves significant improvements over state-of-the-art baseline models. | Danyang Liu, Yuji Yang, Mengdi Zhang, Wei Wu, Xing Xie, Guangzhong Sun | Meituan, Hefei, Peoples R China; Univ Sci & Technol China, Hefei, Peoples R China; Microsoft Res, Beijing, Peoples R China |
|  |  [Multimodal Meta-Learning for Cold-Start Sequential Recommendation](https://doi.org/10.1145/3511808.3557101) |  | 0 | In this paper, we study the task of cold-start sequential recommendation, where new users with very short interaction sequences come with time. We cast this problem as a few-shot learning problem and adopt a meta-learning approach to developing our solution. For our task, a major obstacle of effective knowledge transfer that is there exists significant characteristic divergence between old and new interaction sequences for meta-learning. To address the above issues, we purpose a Multimodal Meta-Learning (denoted as MML) approach that incorporates multimodal side information of items (e.g., text and image) into the meta-learning process, to stabilize and improve the meta-learning process for cold-start sequential recommendation. In specific, we design a group of multimodal meta-learners corresponding to each kind of modality, where ID features are used to develop the main meta-learner and the rest text and image features are used to develop auxiliary meta-learners. Instead of simply combing the predictions from different meta-learners, we design an adaptive, learnable fusion layer to integrate the predictions based on different modalities. Meanwhile, we design a cold-start item embedding generator, which utilize multimodal side information to warm up the ID embeddings of new items. Extensive offline and online experiments demonstrate that MML can significantly improve the recommendation performance for cold-start users compared with baseline models. Our code is released at https://github.com/RUCAIBox/MML. | Xingyu Pan, Yushuo Chen, Changxin Tian, Zihan Lin, Jinpeng Wang, He Hu, Wayne Xin Zhao | Meituan Grp, Beijing, Peoples R China; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Renmin Univ China, Sch Informat, Beijing, Peoples R China |
|  |  [Graph-based Weakly Supervised Framework for Semantic Relevance Learning in E-commerce](https://doi.org/10.1145/3511808.3557143) |  | 0 | Product searching is fundamental in online e-commerce systems, it needs to quickly and accurately find the products that users required. Relevance is essential for e-commerce search, which role is avoiding displaying products that do not match search intent and optimizing user experience. Measuring semantic relevance is necessary because distributional biases between search queries and product titles may lead to large lexical differences between relevant textual expressions. Several problems limit the performance of semantic relevance learning, including extremely long-tail product distribution and low-quality labeled data. Recent works attempt to conduct relevance learning through user behaviors. However, noisy user behavior can easily cause inadequately semantic modeling. Therefore, it is valuable but challenging to utilize user behavior in relevance learning. In this paper, we first propose a weakly supervised contrastive learning framework that focuses on how to provide effective semantic supervision and generate reasonable representation. We utilize topology structure information contained in a user behavior heterogeneous graph to design a semantically aware data construction strategy. Besides, we propose a contrastive learning framework suitable for e-commerce scenarios with targeted improvements in data augmentation and training objectives. For relevance calculation, we propose a novel hybrid method that combines fine-tuning and transfer learning. It eliminates the negative impacts caused by distributional bias and guarantees semantic matching capabilities. Extensive experiments and analyses show the promising performance of proposed methods in relevance learning. | Zhiyuan Zeng, Yuzhi Huang, Tianshu Wu, Hongbo Deng, Jian Xu, Bo Zheng | Alibaba Grp, Hangzhou, Zhejiang, Peoples R China |
|  |  [A Multi-Domain Benchmark for Personalized Search Evaluation](https://doi.org/10.1145/3511808.3557536) |  | 0 | Personalization in Information Retrieval has been a hot topic in both academia and industry for the past two decades. However, there is still a lack of high-quality standard benchmark datasets for conducting offline comparative evaluations in this context. To mitigate this problem, in the past few years, approaches to derive synthetic datasets suited for evaluating Personalized Search models have been proposed. In this paper, we put forward a novel evaluation benchmark for Personalized Search with more than 18 million documents and 1.9 million queries across four domains. We present a detailed description of the benchmark construction procedure, highlighting its characteristics and challenges. We provide baseline performance including pre-trained neural models, opening room for the evaluation of personalized approaches, as well as domain adaptation and transfer learning scenarios. We make both datasets and models available for future research. | Elias Bassani, Pranav Kasela, Alessandro Raganato, Gabriella Pasi | Univ Milano Bicocca, C2T, Milan, Italy; Univ Milano Bicocca, Milan, Italy |
|  |  [KuaiRand: An Unbiased Sequential Recommendation Dataset with Randomly Exposed Videos](https://doi.org/10.1145/3511808.3557624) |  | 0 | Recommender systems deployed in real-world applications can have inherent exposure bias, which leads to the biased logged data plaguing the researchers. A fundamental way to address this thorny problem is to collect users' interactions on randomly expose items, i.e., the missing-at-random data. A few works have asked certain users to rate or select randomly recommended items, e.g., Yahoo!, Coat, and OpenBandit. However, these datasets are either too small in size or lack key information, such as unique user ID or the features of users/items. In this work, we present KuaiRand, an unbiased sequential recommendation dataset containing millions of intervened interactions on randomly exposed videos, collected from the video-sharing mobile App, Kuaishou. Different from existing datasets, KuaiRand records 12 kinds of user feedback signals (e.g., click, like, and view time) on randomly exposed videos inserted in the recommendation feeds in two weeks. To facilitate model learning, we further collect rich features of users and items as well as users' behavior history. By releasing this dataset, we enable the research of advanced debiasing large-scale recommendation scenarios for the first time. Also, with its distinctive features, KuaiRand can support various other research directions such as interactive recommendation, long sequential behavior modeling, and multi-task learning. The dataset is available at https://kuairand.com. | Chongming Gao, Shijun Li, Yuan Zhang, Jiawei Chen, Biao Li, Wenqiang Lei, Peng Jiang, Xiangnan He | Kuaishou Technol Co Ltd, Hong Kong, Peoples R China; Sichuan Univ, Chengdu, Peoples R China; Zhejiang Univ, Hangzhou, Peoples R China; Univ Sci & Technol China, Hefei, Peoples R China |
|  |  [Prototypical Contrastive Learning and Adaptive Interest Selection for Candidate Generation in Recommendations](https://doi.org/10.1145/3511808.3557674) |  | 0 | Deep Candidate Generation plays an important role in large-scale recommender systems. It takes user history behaviors as inputs and learns user and item latent embeddings for candidate generation. In the literature, conventional methods suffer from two problems. First, a user has multiple embeddings to reflect various interests, and such number is fixed. However, taking into account different levels of user activeness, a fixed number of interest embeddings is sub-optimal. For example, for less active users, they may need fewer embeddings to represent their interests compared to active users. Second, the negative samples are often generated by strategies with unobserved supervision, and similar items could have different labels. Such a problem is termed as class collision. In this paper, we aim to advance the typical two-tower DNN candidate generation model. Specifically, an Adaptive Interest Selection Layer is designed to learn the number of user embeddings adaptively in an end-to-end way, according to the level of their activeness. Furthermore, we propose a Prototypical Contrastive Learning Module to tackle the class collision problem introduced by negative sampling. Extensive experimental evaluations show that the proposed scheme remarkably outperforms competitive baselines on multiple benchmarks. | Ningning Li, Qunwei Li, Xichen Ding, Shaohu Chen, Wenliang Zhong | Ant Grp, Beijing, Peoples R China; Ant Grp, Hangzhou, Peoples R China |
|  |  [Personalized Federated Recommendation via Joint Representation Learning, User Clustering, and Model Adaptation](https://doi.org/10.1145/3511808.3557668) |  | 0 | Federated recommendation applies federated learning techniques in recommendation systems to help protect user privacy by exchanging models instead of raw user data between user devices and the central server. Due to the heterogeneity in user's attributes and local data, attaining personalized models is critical to help improve the federated recommendation performance. In this paper, we propose a Graph Neural Network based Personalized Federated Recommendation (PerFedRec) framework via joint representation learning, user clustering, and model adaptation. Specifically, we construct a collaborative graph and incorporate attribute information to jointly learn the representation through a federated GNN. Based on these learned representations, we cluster users into different user groups and learn personalized models for each cluster. Then each user learns a personalized model by combining the global federated model, the cluster-level federated model, and the user's fine-tuned local model. To alleviate the heavy communication burden, we intelligently select a few representative users (instead of randomly picked users) from each cluster to participate in training. Experiments on real-world datasets show that our proposed method achieves superior performance over existing methods. | Sichun Luo, Yuanzhang Xiao, Linqi Song | City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; Univ Hawaii Manoa, Hawaii Adv Wireless Technol Inst, Honolulu, HI USA |
|  |  [See Clicks Differently: Modeling User Clicking Alternatively with Multi Classifiers for CTR Prediction](https://doi.org/10.1145/3511808.3557694) |  | 0 | Many recommender systems optimize click through rates (CTRs) as one of their core goals, and it further breaks down to predicting each item's click probability for a user (user-item click probability) and recommending the top ones to this particular user. User-item click probability is then estimated as a single term, and the basic assumption is that the user has different preferences over items. This is presumably true, but from real-world data, we observe that some people are naturally more active in clicking on items while some are not. This intrinsic tendency contributes to their user-item click probabilities. Besides this, when a user sees a particular item she likes, the click probability for this item increases due to this user-item preference. Therefore, instead of estimating the user-item click probability directly, we break it down into two finer attributes: user's intrinsic tendency of clicking and user-item preference. Inspired by studies that emphasize item features for overall enhancements and research progress in multi-task learning, we for the first time design a Multi Classifier Click Rate prediction model (MultiCR) to better exploit item-level information by building a separate classifier for each item. Furthermore, in addition to utilizing static user features, we learn implicit connections between user's item preferences and the often-overlooked indirect user behaviors (e.g., click histories from other services within the app). In a common new-campaign/new-service scenario, MultiCR outperforms various baselines in large-scale offline and online experiments and demonstrates good resilience when the amount of training data decreases. | Shiwei Lyu, Hongbo Cai, Chaohe Zhang, Shuai Ling, Yue Shen, Xiaodong Zeng, Jinjie Gu, Guannan Zhang, Haipeng Zhang | Peking Univ, Beijing, Peoples R China; Ant Grp, Hangzhou, Peoples R China; Shanghaitech Univ, Shanghai, Peoples R China |
|  |  [FwSeqBlock: A Field-wise Approach for Modeling Behavior Representation in Sequential Recommendation](https://doi.org/10.1145/3511808.3557601) |  | 0 | Modeling users' historical behaviors is an essential task in many industrial recommender systems. The user interest representation, in previous works, is obtained through the following paradigm: concrete behaviors are firstly embedded as low-dimensional behavior representations, which are then aggregated conditioning on the target item for final user interest representation. Most existing researches focus on the aggregation process that explores the intrinsic structure of the behavior sequences. However, the quality of behavior representation is largely ignored. In this paper, we present a pluggable module, FwSeqBlock, to enhance the expressiveness of behavior representations. Specifically, FwSeqBlock introduces the multiplicative operation among users' historical behaviors and the target item, where a field memory unit is designed to dynamically identify the dominant features from the behavior sequence and filter out the noise. Extensive experiments validate that FwSeqBlock consistently generates higher-quality user representations compared with competitive methods. Besides, online A/B testing reports a 4.46% improvement in Click-Through Rate (CTR), confirming the effectiveness of the proposed method. | Hao Qian, Qintong Wu, Minghao Li, Zhengwei Wu, Zhiqiang Zhang, Jun Zhou, Lihong Gu, Jinjie Gu | Ant Grp, Hangzhou, Peoples R China |
|  |  [AdaSparse: Learning Adaptively Sparse Structures for Multi-Domain Click-Through Rate Prediction](https://doi.org/10.1145/3511808.3557541) |  | 0 | Click-through rate (CTR) prediction is a fundamental technique in recommendation and advertising systems. Recent studies have proved that learning a unified model to serve multiple domains is effective to improve the overall performance. However, it is still challenging to improve generalization across domains under limited training data, and hard to deploy current solutions due to computational complexity. In this paper, we propose AdaSparse for multi-domain CTR prediction, which learns adaptively sparse structure for each domain, achieving better generalization across domains with lower computational cost. We introduce domain-aware neuron-level weighting factors to measure the importance of neurons, with that for each domain our model can prune redundant neurons to improve generalization. We further add flexible sparsity regularizations to control the sparsity ratio of learned structures. Offline and online experiments show that AdaSparse outperforms previous multi-domain CTR models significantly. | Xuanhua Yang, Xiaoyu Peng, Penghui Wei, Shaoguo Liu, Liang Wang, Bo Zheng | Alibaba Grp, Beijing, Peoples R China |
|  |  [Revisiting Cold-Start Problem in CTR Prediction: Augmenting Embedding via GAN](https://doi.org/10.1145/3511808.3557684) |  | 0 | Click-through rate (CTR) prediction is one of the core tasks in industrial applications such as online advertising and recommender systems. However, the performance of existing CTR models is hampered by the cold-start users who have very few historical behavior data, given that these models often rely on enough sequential behavior data to learn the embedding vectors. In this paper, we propose a novel framework dubbed GF2 to alleviate the cold-start problem in deep learning based CTR prediction. GF2 augments the embeddings of cold-start users after the embedding layer in the deep CTR model based on the Generative Adversarial Network (GAN), and the obtained generator by GAN can be further fine-tuned locally to enhance the CTR prediction in cold-start settings. GF2 is general for deep CTR models that use embeddings to model the features of users, and it has already been deployed in real-world online display advertising system. Experimental results on two large-scale real-world datasets show that GF2 can significantly improve the prediction performance over three polular deep CTR models. | Xuxin Zhang, Di Wang, Dehong Gao, Wen Jiang, Wei Ning, Yang Zhou, Chen Wang | Huazhong Univ Sci & Technol, Wuhan, Hubei, Peoples R China; Alibaba Grp, Hangzhou, Zhejiang, Peoples R China |
|  |  [X-Vision: Explainable Image Retrieval by Re-Ranking in Semantic Space](https://doi.org/10.1145/3511808.3557187) |  | 0 | We present X-Vision, an explainable AI (XAI) driven image retrieval system based on a re-ranking approach to support non-expert users. We generate textual explanations such as, ''This image is similar to query image in color by Y%, shape by Z%'' along with visual explanations that compare image features. Besides the XAI goal of making AI systems transparent, we address the semantic gap between user's perception and model ranking, which arises in content based image retrieval (CBIR). We attempt to explain the notion of similarity in images in a query-by-example scenario, starting with relatively simple features such as color, texture, objects, background-foreground segments, moving to semantic representations learned from hidden layers of deep networks. The base retrieval model compares the query vector with other image feature vectors to create rankings. This result list is transferred to a semantic feature space that allows rule-based re-rankings. The core contribution of this work is a re-ranking algorithm for generating explanations. Our re-ranking improves retrieval performance (MAP) when compared with a base ranker, a random baseline, and recent CBIR baseline rankers on PASCAL VOC data. We evaluate XAI focused aspects of user trust in an eye-tracker based user study, we find that explanations supported users in the search process and understanding the notion of similarity. | Sayantan Polley, Subhajit Mondal, Venkata Srinath Mannam, Kushagra Kumar, Subhankar Patra, Andreas Nürnberger | Otto von Guericke Univ, Magdeburg, Germany |
|  |  [Time Lag Aware Sequential Recommendation](https://doi.org/10.1145/3511808.3557473) |  | 0 | Although a variety of methods have been proposed for sequential recommendation, it is still far from being well solved partly due to two challenges. First, the existing methods often lack the simultaneous consideration of the global stability and local fluctuation of user preference, which might degrade the learning of a user's current preference. Second, the existing methods often use a scalar based weighting schema to fuse the long-term and short-term preferences, which is too coarse to learn an expressive embedding of current preference. To address the two challenges, we propose a novel model called Time Lag aware Sequential Recommendation (TLSRec), which integrates a hierarchical modeling of user preference and a time lag sensitive fine-grained fusion of the long-term and short-term preferences. TLSRec employs a hierarchical self-attention network to learn users' preference at both global and local time scales, and a neural time gate to adaptively regulate the contributions of the long-term and short-term preferences for the learning of a user's current preference at the aspect level and based on the lag between the current time and the time of the last behavior of a user. The extensive experiments conducted on real datasets verify the effectiveness of TLSRec. | Lihua Chen, Ning Yang, Philip S. Yu | Sichuan Univ, Sch Comp Sci, Chengdu, Sichuan, Peoples R China; Univ Illinois, Dept Comp Sci, Chicago, IL USA |
|  |  [Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for Personalized Micro-Video Recommendation](https://doi.org/10.1145/3511808.3557403) |  | 0 | Micro-video recommendation is attracting global attention and becoming a popular daily service for people of all ages. Recently, Graph Neural Networks-based micro-video recommendation has displayed performance improvement for many kinds of recommendation tasks. However, the existing works fail to fully consider the characteristics of micro-videos, such as the high timeliness of news nature micro-video recommendation and sequential interactions of frequently changed interests. In this paper, a novel Multi-aggregator Time-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed for personalized news nature micro-video recommendation based on sequential sessions, where characteristics of micro-videos are comprehensively studied, users' preference is mined via multi-aggregator, the temporal and dynamic changes of users' preference are captured, and timeliness is considered. Through the comparison with the state-of-the-arts, the experimental results validate the superiority of our MTHGNN model. | Jinkun Han, Wei Li, Zhipeng Cai, Yingshu Li | Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA |
|  |  [Rethinking Conversational Recommendations: Is Decision Tree All You Need?](https://doi.org/10.1145/3511808.3557433) |  | 0 | Conversational recommender systems (CRS) dynamically obtain the users' preferences via multi-turn questions and answers. The existing CRS solutions are widely dominated by deep reinforcement learning algorithms. However, deep reinforcement learning methods are often criticized for lacking interpretability and requiring a large amount of training data to perform. In this paper, we explore a simpler alternative and propose a decision tree based solution to CRS. The underlying challenge in CRS is that the same item can be described differently by different users. We show that decision trees are sufficient to characterize the interactions between users and items, and solve the key challenges in multi-turn CRS: namely which questions to ask, how to rank the candidate items, when to recommend , and how to handle user's negative feedback on the recommendations . Firstly, the training of decision trees enables us to find questions which effectively narrow down the search space. Secondly, by learning embeddings for each item and tree nodes, the candidate items can be ranked based on their similarity to the conversation context encoded by the tree nodes. Thirdly, the diversity of items associated with each tree node allows us to develop an early stopping strategy to decide when to make recommendations. Fourthly, when the user rejects a recommendation, we adaptively choose the next decision tree to improve subsequent questions and recommendations. Extensive experiments on three publicly available benchmark CRS datasets show that our approach provides significant improvement to the state of the art CRS methods. | A. S. M. AhsanUlHaque, Hongning Wang | Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA |
|  |  [AutoMARS: Searching to Compress Multi-Modality Recommendation Systems](https://doi.org/10.1145/3511808.3557242) |  | 0 | Web applications utilize Recommendation Systems (RS) to address the problem of consumer over-choices. Recent works have taken advantage of multi-modality or multi-view, input information (such as user interaction, images, texts, rating scores) to boost recommendation system performance compared with using single-modality information. However, the use of multi-modality input demands much higher computational cost and storage capacity. On the other hand, the real-world RS services usually have strict budgets on both time and space for a good customer experience. As a result, the model efficiency of multi-modality recommendation systems has gained increasing importance. While unfortunately, to the best of our knowledge, there is no existing study of a generic compression framework for multi-modality RS. In this paper, we investigate, for the first time, how to compress a multi-modality recommendation system with a fixed budget. Assuming that input information from different modalities are of unequal importance, a good compression algorithm should learn to automatically allocate different resource budgets to each input, based on their importance in maximally preserving recommendation efficacy. To this end, we leverage the tools of neural architecture search (NAS) and distillation and propose Auto Multi-modAlity Recommendation System (AutoMARS), a unified modality-aware model compression framework dedicated to multi-modality recommendation systems. We demonstrate the effectiveness and generality of AutoMARS by testing it on three different Amazon datasets of various sparsity. AutoMARS demonstrates superior multi-modality compression performance than previous state-of-the-art compression methods. For example on the Amazon Beauty dataset, we achieve on average a 20% higher accuracy over previous state-of-the-art methods, while enjoying 65% reduction over baselines. Codes are available at: https://github.com/VITA-Group/AutoMARS. | Duc Hoang, Haotao Wang, Handong Zhao, Ryan A. Rossi, Sungchul Kim, Kanak Mahadik, Zhangyang Wang | Univ Texas Austin, Austin, TX 78712 USA; Adobe Res, San Jose, CA USA |
|  |  [Memory Bank Augmented Long-tail Sequential Recommendation](https://doi.org/10.1145/3511808.3557391) |  | 0 | The goal of sequential recommendation is to predict the next item that a user would like to interact with, by capturing her dynamic historical behaviors. However, most existing sequential recommendation methods do not focus on solving the long-tail item recommendation problem that is caused by the imbalanced distribution of item data. To solve this problem, we propose a novel sequential recommendation framework, named MASR (i.e., Memory Bank Augmented Long-tail Sequential Recommendation). MASR is an "Open-book" model that combines novel types of memory banks and a retriever-copy network to alleviate the long-tail problem. During inference, the designed retriever-copy network retrieves related sequences from the training samples and copies the useful information as a cue to improve the recommendation performance on tail items. Two designed memory banks provide reference samples to the retriever-copy network by memorizing the historical samples appearing in the training phase. Extensive experiments have been performed on five real-world datasets to demonstrate the effectiveness of the proposed MASR model. The experimental results indicate that MASR consistently outperforms baseline methods in terms of recommendation performance on tail items. | Yidan Hu, Yong Liu, Chunyan Miao, Yuan Miao | Nanyang Technol Univ, Joint NTU UBC Res Ctr Excellence Act Living Elder, Singapore, Singapore; Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore; Victoria Univ, Inst Sustainable Ind & Liveable Cities ISILC, Melbourne, Vic, Australia |
|  |  [Improving Personality Consistency in Conversation by Persona Extending](https://doi.org/10.1145/3511808.3557359) |  | 0 | Endowing chatbots with a consistent personality plays a vital role for agents to deliver human-like interactions. However, existing personalized approaches commonly generate responses in light of static predefined personas depicted with textual description, which may severely restrict the interactivity of human and the chatbot, especially when the agent needs to answer the query excluded in the predefined personas, which is so-called out-of-predefined persona problem (named OOP for simplicity). To alleviate the problem, in this paper we propose a novel retrieval-to-prediction paradigm consisting of two subcomponents, namely, (1) Persona Retrieval Model (PRM), it retrieves a persona from a global collection based on a Natural Language Inference (NLI) model, the inferred persona is consistent with the predefined personas; and (2) Posterior-scored Transformer (PS-Transformer), it adopts a persona posterior distribution that further considers the actual personas used in the ground response, maximally mitigating the gap between training and inferring. Furthermore, we present a dataset called IT-ConvAI2 that first highlights the OOP problem in personalized dialogue. Extensive experiments on both IT-ConvAI2 and ConvAI2 demonstrate that our proposed model yields considerable improvements in both automatic metrics and human evaluations. | Yifan Liu, Wei Wei, Jiayi Liu, Xianling Mao, Rui Fang, Dangyang Chen | Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, CCIIP Lab, Joint Lab HUST & Pingan Property & Casualty Res H, Wuhan, Hubei, Peoples R China; Ping Property & Casualty Insurance Co China Ltd, Wuxi, Jiangsu, Peoples R China; Alibaba Grp, Hangzhou, Zhejiang, Peoples R China; Beijing Inst Technol, Beijing, Peoples R China |
|  |  [HySAGE: A Hybrid Static and Adaptive Graph Embedding Network for Context-Drifting Recommendations](https://doi.org/10.1145/3511808.3557354) |  | 0 | The recent popularity of edge devices and Artificial Intelligent of Things (AIoT) has driven a new wave of contextual recommendations, such as location based Point of Interest (PoI) recommendations and computing resource-aware mobile app recommendations. In many such recommendation scenarios, contexts are drifting over time. For example, in a mobile game recommendation, contextual features like locations, battery, and storage levels of mobile devices are frequently drifting over time. However, most existing graph-based collaborative filtering methods are designed under the assumption of static features. Therefore, they would require frequent retraining and/or yield graphical models burgeoning in sizes, impeding their suitability for context-drifting recommendations. In this work, we propose a specifically tailor-made Hybrid Static and Adaptive Graph Embedding (HySAGE) network for context-drifting recommendations. Our key idea is to disentangle the relatively static user-item interaction and rapidly drifting contextual features. Specifically, our proposed HySAGE network learns a relatively static graph embedding from user-item interaction and an adaptive embedding from drifting contextual features. These embeddings are incorporated into an interest network to generate the user interest in some certain context. We adopt an interactive attention module to learn the interactions among static graph embeddings, adaptive contextual embeddings, and user interest, helping to achieve a better final representation. Extensive experiments on real-world datasets demonstrate that HySAGE significantly improves the performance of the existing state-of-the-art recommendation algorithms. | Sichun Luo, Xinyi Zhang, Yuanzhang Xiao, Linqi Song | City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; Capital Univ Econ & Business, Dept Accounting, Beijing, Peoples R China; Univ Hawaii Manoa, Dept Elect & Comp Engn, Honolulu, HI USA |
|  |  [Rank List Sensitivity of Recommender Systems to Interaction Perturbations](https://doi.org/10.1145/3511808.3557425) |  | 0 | Prediction models can exhibit sensitivity with respect to training data: small changes in the training data can produce models that assign conflicting predictions to individual data points during test time. In this work, we study this sensitivity in recommender systems, where users' recommendations are drastically altered by minor perturbations in other unrelated users' interactions. We introduce a measure of stability for recommender systems, called Rank List Sensitivity (RLS), which measures how rank lists generated by a given recommender system at test time change as a result of a perturbation in the training data. We develop a method, CASPER, which uses cascading effect to identify the minimal and systematical perturbation to induce higher instability in a recommender system. Experiments on four datasets show that recommender models are overly sensitive to minor perturbations introduced randomly or via CASPER - even perturbing one random interaction of one user drastically changes the recommendation lists of all users. Importantly, with CASPER perturbation, the models generate more unstable recommendations for low-accuracy users (i.e., those who receive low-quality recommendations) than high-accuracy ones. | Sejoon Oh, Berk Ustun, Julian J. McAuley, Srijan Kumar | Univ Calif San Diego, San Diego, CA USA; Georgia Inst Technol, Atlanta, GA 30332 USA |
|  |  [Asymmetrical Context-aware Modulation for Collaborative Filtering Recommendation](https://doi.org/10.1145/3511808.3557240) |  | 0 | Modern learnable collaborative filtering recommendation models generate user and item representations by deep learning methods (e.g. graph neural networks) for modeling user-item interactions. However, most of them may still have unsatisfied performances due to two issues. Firstly, some models assume that the representations of users or items are fixed when modeling interactions with different objects. However, a user may have different interests in different items, and an item may also have different attractions to different users. Thus the representations of users and items should depend on their contexts to some extent. Secondly, existing models learn representations for user and item by symmetrical dual methods which have identical or similar operations. Symmetrical methods may fail to sufficiently and reasonably extract the features of user and item as their interaction data have diverse semantic properties. To address the above issues, a novel model called Asymmetrical context-awaRe modulation for collaBorative filtering REcommendation (ARBRE) is proposed. It adopts simplified GNNs on collaborative graphs to capture homogeneous user preferences and item attributes, then designs two asymmetrical context-aware modulation models to learn dynamic user interests and item attractions, respectively. The learned representations from user domain and item domain are input pair-wisely into 4 Multi-Layer Perceptrons in different combinations to model user-item interactions. Experimental results on three real-world datasets demonstrate the superiority of ARBRE over various state-of-the-arts. | Yi Ouyang, Peng Wu, Li Pan | Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China; Shanghai Jiao Tong Univ, Shanghai, Peoples R China |
|  |  [CROLoss: Towards a Customizable Loss for Retrieval Models in Recommender Systems](https://doi.org/10.1145/3511808.3557274) |  | 0 | In large-scale recommender systems, retrieving top N relevant candidates accurately with resource constrain is crucial. To evaluate the performance of such retrieval models, Recall@N, the frequency of positive samples being retrieved in the top N ranking, is widely used. However, most of the conventional loss functions for retrieval models such as softmax cross-entropy and pairwise comparison methods do not directly optimize Recall@N. Moreover, those conventional loss functions cannot be customized for the specific retrieval size N required by each application and thus may lead to sub-optimal performance. In this paper, we proposed the Customizable Recall@N Optimization Loss (CROLoss), a loss function that can directly optimize the Recall@N metrics and is customizable for different choices of N. This proposed CROLoss formulation defines a more generalized loss function space, covering most of the conventional loss functions as special cases. Furthermore, we develop the Lambda method, a gradient-based method that invites more flexibility and can further boost the system performance. We evaluate the proposed CROLoss on two public benchmark datasets. The results show that CROLoss achieves SOTA results over conventional loss functions for both datasets with various choices of retrieval size N. CROLoss has been deployed onto our online E-commerce advertising platform, where a fourteen-day online A/B test demonstrated that CROLoss contributes to a significant business revenue growth of 4.75 | Yongxiang Tang, Wentao Bai, Guilin Li, Xialong Liu, Yu Zhang | Alibaba Grp, Beijing, Peoples R China |
|  |  [Temporal Contrastive Pre-Training for Sequential Recommendation](https://doi.org/10.1145/3511808.3557468) |  | 0 | Recently, pre-training based approaches are proposed to leverage self-supervised signals for improving the performance of sequential recommendation. However, most of existing pre-training recommender systems simply model the historical behavior of a user as a sequence, while lack of sufficient consideration on temporal interaction patterns that are useful for modeling user behavior. In order to better model temporal characteristics of user behavior sequences, we propose a Temporal Contrastive Pre-training method for Sequential Recommendation (TCPSRec for short). Based on the temporal intervals, we consider dividing the interaction sequence into more coherent subsequences, and design temporal pre-training objectives accordingly. Specifically, TCPSRec models two important temporal properties of user behavior, i.e., invariance and periodicity. For invariance, we consider both global invariance and local invariance to capture the long-term preference and short-term intention, respectively. For periodicity, TCPSRec models coarse-grained periodicity and fine-grained periodicity at the subsequence level, which is more stable than modeling periodicity at the item level. By integrating the above strategies, we develop a unified contrastive learning framework with four specially designed pre-training objectives for fusing temporal information into sequential representations. We conduct extensive experiments on six real-world datasets, and the results demonstrate the effectiveness and generalization of our proposed method. | Changxin Tian, Zihan Lin, Shuqing Bian, Jinpeng Wang, Wayne Xin Zhao | Meituan Grp, Beijing, Peoples R China; Beijing Key Lab Big Data Management & Anal Method, Beijing, Peoples R China; Renmin Univ China, Sch Informat, Beijing, Peoples R China |
|  |  [Explanation Guided Contrastive Learning for Sequential Recommendation](https://doi.org/10.1145/3511808.3557317) |  | 0 | Recently, contrastive learning has been applied to the sequential recommendation task to address data sparsity caused by users with few item interactions and items with few user adoptions. Nevertheless, the existing contrastive learning-based methods fail to ensure that the positive (or negative) sequence obtained by some random augmentation (or sequence sampling) on a given anchor user sequence remains to be semantically similar (or different). When the positive and negative sequences turn out to be false positive and false negative respectively, it may lead to degraded recommendation performance. In this work, we address the above problem by proposing Explanation Guided Augmentations (EGA) and Explanation Guided Contrastive Learning for Sequential Recommendation (EC4SRec) model framework. The key idea behind EGA is to utilize explanation method(s) to determine items' importance in a user sequence and derive the positive and negative sequences accordingly. EC4SRec then combines both self-supervised and supervised contrastive learning over the positive and negative sequences generated by EGA operations to improve sequence representation learning for more accurate recommendation results. Extensive experiments on four real-world benchmark datasets demonstrate that EC4SRec outperforms the state-of-the-art sequential recommendation methods and two recent contrastive learning-based sequential recommendation methods, CL4SRec and DuoRec. Our experiments also show that EC4SRec can be easily adapted for different sequence encoder backbones (e.g., GRU4Rec and Caser), and improve their recommendation performance. | Lei Wang, EePeng Lim, Zhiwei Liu, Tianxiang Zhao | Salesforce, San Francisco, CA USA; Singapore Management Univ, Singapore, Singapore; Penn State Univ, University Pk, PA 16802 USA |
|  |  [Multi-level Contrastive Learning Framework for Sequential Recommendation](https://doi.org/10.1145/3511808.3557404) |  | 0 | Sequential recommendation (SR) aims to predict the subsequent behaviors of users by understanding their successive historical behaviors. Recently, some methods for SR are devoted to alleviating the data sparsity problem (i.e., limited supervised signals for training), which take account of contrastive learning to incorporate self-supervised signals into SR. Despite their achievements, it is far from enough to learn informative user/item embeddings due to the inadequacy modeling of complex collaborative information and co-action information, such as user-item relation, user-user relation, and item-item relation. In this paper, we study the problem of SR and propose a novel multi-level contrastive learning framework for sequential recommendation, named MCLSR. Different from the previous contrastive learning-based methods for SR, MCLSR learns the representations of users and items through a cross-view contrastive learning paradigm from four specific views at two different levels (i.e., interest- and feature-level). Specifically, the interest-level contrastive mechanism jointly learns the collaborative information with the sequential transition patterns, and the feature-level contrastive mechanism re-observes the relation between users and items via capturing the co-action information (i.e., co-occurrence). Extensive experiments on four real-world datasets show that the proposed MCLSR outperforms the state-of-the-art methods consistently. | Ziyang Wang, Huoyu Liu, Wei Wei, Yue Hu, XianLing Mao, Shaojian He, Rui Fang, Dangyang Chen | Ping An Property & Casualty Insurance Co China Lt, Wuhan, Peoples R China; Huazhong Univ Sci & Technol, CCIIP Lab, Wuhan, Peoples R China; Beijing Inst Technol, Beijing, Peoples R China; Alibaba Grp, Hangzhou, Peoples R China |
|  |  [Match-Prompt: Improving Multi-task Generalization Ability for Neural Text Matching via Prompt Learning](https://doi.org/10.1145/3511808.3557388) |  | 0 | Text matching is a fundamental technique in both information retrieval and natural language processing. Text matching tasks share the same paradigm that determines the relationship between two given texts. The relationships vary from task to task, e.g. relevance in document retrieval, semantic alignment in paraphrase identification and answerable judgment in question answering. However, the essential signals for text matching remain in a finite scope, i.e. exact matching, semantic matching, and inference matching. Ideally, a good text matching model can learn to capture and aggregate these signals for different matching tasks to achieve competitive performance, while recent state-of-the-art text matching models, e.g. Pre-trained Language Models (PLMs), are hard to generalize. It is because the end-to-end supervised learning on task-specific dataset makes model overemphasize the data sample bias and task-specific signals instead of the essential matching signals, which ruins the generalization of model to different tasks. To overcome this problem, we adopt a specialization-generalization training strategy and refer to it as Match-Prompt. In specialization stage, descriptions of different matching tasks are mapped to only a few prompt tokens. In generalization stage, text matching model explores the essential matching signals by being trained on diverse multiple matching tasks. High diverse matching tasks avoid model fitting the data sample bias on a specific task, so that model can focus on learning the essential matching signals. Meanwhile, the prompt tokens obtained in the first step are added to the corresponding tasks to help the model distinguish different task-specific matching signals, as well as to form the basis prompt tokens for a new matching task. In this paper, we consider five common text matching tasks including document retrieval, open-domain question answering, retrieval-based dialogue, paraphrase identification, and natural language inference. Experimental results on eighteen public datasets show that Match-Prompt can improve multi-task generalization capability of PLMs in text matching and yield better in-domain multi-task, out-of-domain multi-task and new task adaptation performance than multi-task and task-specific models trained by previous fine-tuning paradigm. | Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng | Chinese Acad Sci, Data Intelligence Syst Res Ctr, Inst Comp Technol, Beijing, Peoples R China; Univ Chinese Acad Sci, Beijing, Peoples R China |
|  |  [Disentangling Past-Future Modeling in Sequential Recommendation via Dual Networks](https://doi.org/10.1145/3511808.3557289) |  | 0 | Sequential recommendation (SR) plays an important role in personalized recommender systems because it captures dynamic and diverse preferences from users' real-time increasing behaviors. Unlike the standard autoregressive training strategy, future data (also available during training) has been used to facilitate model training as it provides richer signals about users' current interests and can be used to improve the recommendation quality. However, existing methods suffer from a severe training-inference gap, i.e., both past and future contexts are modeled by the same encoder when training, while only historical behaviors are available during inference. This discrepancy leads to potential performance degradation. To alleviate the training-inference gap, we propose a new framework DualRec, which achieves past-future disentanglement and past-future mutual enhancement by a novel dual network. Specifically, a dual network structure is exploited to model the past and future context separately.And a bi-directional knowledge transferring mechanism enhances the knowledge learnt by the dual network. Extensive experiments on four real-world datasets demonstrate the superiority of our approach over baseline methods. Besides, we demonstrate the compatibility of DualRec by instantiating using different backbones. Further empirical analysis verifies the high utility of modeling future contexts under our DualRec framework. | Hengyu Zhang, Enming Yuan, Wei Guo, Zhicheng He, Jiarui Qin, Huifeng Guo, Bo Chen, Xiu Li, Ruiming Tang | Shanghai Jiao Tong Univ, Shanghai, Peoples R China; Huawei Noahs Ark Lab, Shenzhen, Peoples R China; Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing, Peoples R China; Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China |
|  |  [Towards Understanding the Overfitting Phenomenon of Deep Click-Through Rate Models](https://doi.org/10.1145/3511808.3557479) |  | 0 | Deep learning techniques have been applied widely in industrial recommendation systems. However, far less attention has been paid to the overfitting problem of models in recommendation systems, which, on the contrary, is recognized as a critical issue for deep neural networks. In the context of Click-Through Rate (CTR) prediction, we observe an interesting one-epoch overfitting problem: the model performance exhibits a dramatic degradation at the beginning of the second epoch. Such a phenomenon has been witnessed widely in real-world applications of CTR models. Thereby, the best performance is usually achieved by training with only one epoch. To understand the underlying factors behind the one-epoch phenomenon, we conduct extensive experiments on the production data set collected from the display advertising system of Alibaba. The results show that the model structure, the optimization algorithm with a fast convergence rate, and the feature sparsity are closely related to the one-epoch phenomenon. We also provide a likely hypothesis for explaining such a phenomenon and conduct a set of proof-of-concept experiments. We hope this work can shed light on future research on training more epochs for better performance. | ZhaoYu Zhang, XiangRong Sheng, Yujing Zhang, Biye Jiang, Shuguang Han, Hongbo Deng, Bo Zheng | Nanjing Univ, Nanjing, Peoples R China; Alibaba Grp, Beijing, Peoples R China |
|  |  [MAE4Rec: Storage-saving Transformer for Sequential Recommendations](https://doi.org/10.1145/3511808.3557461) |  | 0 | Sequential recommender systems (SRS) aim to infer the users' preferences from their interaction history and predict items that will be of interest to the users. The majority of SRS models typically incorporate all historical interactions for next-item recommendations. Despite their success, feeding all interactions into the model without filtering may lead to severe practical issues: ( i ) redundant interactions hinder the SRS model from capturing the users' intentions; ( ii ) the computational cost is huge, as the computational complexity is proportional to the length of the interaction sequence; ( iii ) more memory space is necessitated to store all interaction records from all users. To this end, we propose a novel storage-saving SRS framework, MAE4Rec, based on a unidirectional self-attentive mechanism and masked autoencoder. Specifically, in order to lower the storage consumption, MAE4Rec first masks and discards a large percentage of historical interactions, and then infers the next interacted item solely based on the latent representation of unmarked ones. Experiments on two real-world datasets demonstrate that the proposed model achieves competitive performance against state-of-the-art SRS models with more than 40% compression of storage. | Kesen Zhao, Xiangyu Zhao, Zijian Zhang, Muyang Li | City Univ Hong Kong, Hong Kong, Peoples R China; Univ Sydney, Sydney, NSW, Australia |
|  |  [Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR Prediction](https://doi.org/10.1145/3511808.3557082) |  | 0 | Rich user behavior data has been proven to be of great value for Click-Through Rate (CTR) prediction applications, especially in industrial recommender, search, or advertising systems. However, it's non-trivial for real-world systems to make full use of long-term user behaviors due to the strict requirements of online serving time. Most previous works adopt the retrieval-based strategy, where a small number of user behaviors are retrieved first for subsequent attention. However, the retrieval-based methods are sub-optimal and would cause information losses, and it's difficult to balance the effectiveness and efficiency of the retrieval algorithm. In this paper, we propose SDIM (Sampling-based Deep Interest Modeling), a simple yet effective sampling-based end-to-end approach for modeling long-term user behaviors. We sample from multiple hash functions to generate hash signatures of the candidate item and each item in the user behavior sequence, and obtain the user interest by directly gathering behavior items associated with the candidate item with the same hash signature. We show theoretically and experimentally that the proposed method performs on par with standard attention-based models on modeling long-term user behaviors, while being sizable times faster. We also introduce the deployment of SDIM in our system. Specifically, we decouple the behavior sequence hashing, which is the most time-consuming part, from the CTR model by designing a separate module named BSE (Behavior Sequence Encoding). BSE is latency-free for the CTR server, enabling us to model extremely long user behaviors. Both offline and online experiments are conducted to demonstrate the effectiveness of SDIM. SDIM now has been deployed online in the search system of Meituan APP. | Yue Cao, Xiaojiang Zhou, Jiaqi Feng, Peihao Huang, Yao Xiao, Dayao Chen, Sheng Chen | Meituan Inc, Beijing, Peoples R China |
|  |  [UDM: A Unified Deep Matching Framework in Recommender Systems](https://doi.org/10.1145/3511808.3557069) |  | 0 | Due to the large-scale users and items, industrial recommender systems usually consist of two stages, the matching stage and the ranking stage. The matching stage is responsible for retrieving a small fraction of relevant items from the large-scale item pool which are further selected by the ranking stage. Most of the existing deep learning-based matching models focus on the problem of modeling user interest representation by using inner product between user representation and item representation to obtain the user-to-item relevance. However, the item-to-item relevance between user interacted item and target item is not considered in the deep matching models which is computationally prohibitive for large-scale applications. In this paper, we propose a u nified d eep m atching framework called UDM for the matching stage to mitigate this issue. UDM can model the user-to-item relevance and item-to-item relevance simultaneously with the help of an interest extraction module and interest interaction module, respectively. Specifically, the interest extraction module is used as the main network to extract users' multiple interests with multiple vectors based on users' behavior sequences, while the interest interaction module is used as an auxiliary network to supervise the learning of the interest extraction module, which can model the interaction between user interacted items and target item. In the experiments conducted on two public datasets and a large-scale industrial dataset, UDM achieves consistent improvements over state-of-the-art models. Moreover, UDM has been deployed in the operational system of Alibaba. Online A/B testing results further reveal the effectiveness of UDM. To the best of our knowledge, UDM is the first deep matching framework which combines the user-to-item relevance modeling and item-to-item relevance modeling in the same model. | Long Guo, Fei Fang, Binqiang Zhao, Bin Cui | Alibaba Grp, Beijing, Peoples R China; Peking Univ, Sch CS Key Lab High Confidence Software Technol, Beijing, Peoples R China; Alibaba Grp, Hangzhou, Peoples R China |
|  |  [PROPN: Personalized Probabilistic Strategic Parameter Optimization in Recommendations](https://doi.org/10.1145/3511808.3557130) |  | 0 | Real-world recommender systems usually consist of two phases. Predictive models in Phase I provide accurate predictions of users' actions on items, and Phase II is to aggregate the predictions with strategic parameters to make final recommendations, which aim to meet multiple business goals, such as maximizing users' like rate and average engagement time. Though it is important to generate accurate predictions in Phase I, it is also crucial to optimize the strategic parameters in Phase II. Conventional solutions include manually tunning, Bayesian optimization, contextual multi-armed bandit optimization, etc. However, these methods either produce universal strategic parameters for all the users or focus on a deterministic solution, which leads to an undesirable performance. In this paper, we propose a personalized probabilistic solution for strategic parameter optimization. We first formulate the personalized probabilistic optimizing problem and compare its solution with deterministic and context-free solutions theoretically to show its superiority. We then introduce a novel Personalized pRObabilistic strategic parameter optimizing Policy Network (PROPN) to solve the problem. PROPN follows reinforcement learning architecture where a neural network serves as an agent that dynamically adjusts the distributions of strategic parameters for each user. We evaluate our model under the streaming recommendation setting on two public real-world datasets. The results show that our framework outperforms representative baseline methods. | Pengfei He, Haochen Liu, Xiangyu Zhao, Hui Liu, Jiliang Tang | City Univ Hong Kong, Hong Kong, Peoples R China; Michigan State Univ, E Lansing, MI 48824 USA |
|  |  [IntTower: The Next Generation of Two-Tower Model for Pre-Ranking System](https://doi.org/10.1145/3511808.3557072) |  | 0 | Scoring a large number of candidates precisely in several milliseconds is vital for industrial pre-ranking systems. Existing pre-ranking systems primarily adopt the two-tower model since the "user-item decoupling architecture" paradigm is able to balance the efficiency and effectiveness . However, the cost of high efficiency is the neglect of the potential information interaction between user and item towers, hindering the prediction accuracy critically. In this paper, we show it is possible to design a two-tower model that emphasizes both information interactions and inference efficiency. The proposed model, IntTower (short for Interaction enhanced Two-Tower), consists of Light-SE, FE-Block and CIR modules. Specifically, lightweight Light-SE module is used to identify the importance of different features and obtain refined feature representations in each tower. FE-Block module performs fine-grained and early feature interactions to capture the interactive signals between user and item towers explicitly and CIR module leverages a contrastive interaction regularization to further enhance the interactions implicitly. Experimental results on three public datasets show that IntTower outperforms the SOTA pre-ranking models significantly and even achieves comparable performance in comparison with the ranking models. Moreover, we further verify the effectiveness of IntTower on a large-scale advertisement pre-ranking system. The code of IntTower is publicly available https://gitee.com/mindspore/models/tree/master/research/recommend/IntTower. | Xiangyang Li, Bo Chen, Huifeng Guo, Jingjie Li, Chenxu Zhu, Xiang Long, Sujian Li, Yichao Wang, Wei Guo, Longxia Mao, Jinxing Liu, Zhenhua Dong, Ruiming Tang | Huawei Noahs Ark Lab, Montreal, PQ, Canada; Beijing Univ Posts & Telecommun, Beijing, Peoples R China; Huawei Technol Co Ltd, Shenzhen, Peoples R China; Peking Univ, Beijing, Peoples R China; Shanghai Jiao Tong Univ, Shanghai, Peoples R China |
|  |  [Sparse Attentive Memory Network for Click-through Rate Prediction with Long Sequences](https://doi.org/10.1145/3511808.3557095) |  | 0 | Sequential recommendation predicts users' next behaviors with their historical interactions. Recommending with longer sequences improves recommendation accuracy and increases the degree of personalization. As sequences get longer, existing works have not yet addressed the following two main challenges. Firstly, modeling long-range intra-sequence dependency is difficult with increasing sequence lengths. Secondly, it requires efficient memory and computational speeds. In this paper, we propose a Sparse Attentive Memory (SAM) network for long sequential user behavior modeling. SAM supports efficient training and real-time inference for user behavior sequences with lengths on the scale of thousands. In SAM, we model the target item as the query and the long sequence as the knowledge database, where the former continuously elicits relevant information from the latter. SAM simultaneously models targetsequence dependencies and long-range intra-sequence dependencies with O(L) complexity and O(1) number of sequential updates, which can only be achieved by the self-attention mechanism with O(L-2) complexity. Extensive empirical results demonstrate that our proposed solution is effective not only in long user behavior modeling but also on short sequences modeling. Implemented on sequences of length 1000, SAM is successfully deployed on one of the largest international E-commerce platforms. This inference time is within 30ms, with a substantial 7.30% click-through rate improvement for the online A/B test. To the best of our knowledge, it is the first end-to-end long user sequence modeling framework that models intra-sequence and target-sequence dependencies with the aforementioned degree of efficiency and successfully deployed on a large-scale real-time industrial recommender system. | Qianying Lin, WenJi Zhou, Yanshi Wang, Qing Da, QingGuo Chen, Bing Wang | Alibaba Grp, Hangzhou, Peoples R China |
|  |  [Multi-Faceted Hierarchical Multi-Task Learning for Recommender Systems](https://doi.org/10.1145/3511808.3557140) |  | 0 | There have been many studies on improving the efficiency of shared learning in Multi-Task Learning (MTL). Previous works focused on the "micro" sharing perspective for a small number of tasks, while in Recommender Systems (RS) and many other AI applications, we often need to model a large number of tasks. For example, when using MTL to model various user behaviors in RS, if we differentiate new users and new items from old ones, the number of tasks will increase exponentially with multidimensional relations. This work proposes a Multi-Faceted Hierarchical MTL model (MFH) that exploits the multidimensional task relations in large scale MTLs with a nested hierarchical tree structure. MFH maximizes the shared learning through multi-facets of sharing and improves the performance with heterogeneous task tower design. For the first time, MFH addresses the "macro" perspective of shared learning and defines a "switcher" structure to conceptualize the structures of macro shared learning. We evaluate MFH and SOTA models in a large industry video platform of 10 billion samples and hundreds of millions of monthly active users. Results show that MFH outperforms SOTA MTL models significantly in both offline and online evaluations across all user groups, especially remarkable for new users with an online increase of 9.1% in app time per user and 1.85% in next-day retention rate. MFH currently has been deployed in WeSee, Tencent News, QQ Little World and Tencent Video, several products of Tencent. MFH is especially beneficial to the cold-start problems in RS where new users and new items often suffer from a "local overfitting" phenomenon that we first formalize in this paper. | Junning Liu, Xinjian Li, Bo An, Zijie Xia, Xu Wang | Tencent WXG, Shenzhen, Peoples R China; Nanyang Technol Univ, Singapore, Singapore; Tencent PCG, Shenzhen, Peoples R China |
|  |  [Scenario-Adaptive and Self-Supervised Model for Multi-Scenario Personalized Recommendation](https://doi.org/10.1145/3511808.3557154) |  | 0 | Multi-scenario recommendation is dedicated to retrieve relevant items for users in multiple scenarios, which is ubiquitous in industrial recommendation systems. These scenarios enjoy portions of overlaps in users and items, while the distribution of different scenarios is different. The key point of multi-scenario modeling is to efficiently maximize the use of whole-scenario information and granularly generate adaptive representations both for users and items among multiple scenarios. we summarize three practical challenges which are not well solved for multi-scenario modeling: (1) Lacking of fine-grained and decoupled information transfer controls among multiple scenarios. (2) Insufficient exploitation of entire space samples. (3) Item's multi-scenario representation disentanglement problem. In this paper, we propose a S cenario- A daptive and S elf- S upervised ( SASS ) model to solve the three challenges mentioned above. Specifically, we design a M ulti- L ayer S cenario A daptive T ransfer ( ML-SAT ) module with scenario-adaptive gate units to select and fuse effective transfer information from whole scenario to individual scenario in a quite fine-grained and decoupled way. To sufficiently exploit the power of entire space samples, a two-stage training process including pre-training and fine-tune is introduced. The pre-training stage is based on a scenario-supervised contrastive learning task with the training samples drawn from labeled and unlabeled data spaces. The model is created symmetrically both in user side and item side, so that we can get distinguishing representations of items in different scenarios. Extensive experimental results on public and industrial datasets demonstrate the superiority of the SASS model over state-of-the-art methods. This model also achieves more than 8.0% improvement on Average Watching Time Per User in online A/B tests. SASS has been successfully deployed on multi-scenario short video recommendation platform of Taobao in Alibaba. | Yuanliang Zhang, Xiaofeng Wang, Jinxin Hu, Ke Gao, Chenyi Lei, Fei Fang | Alibaba Grp, Hangzhou, Peoples R China |
|  |  [Dynamic Explicit Embedding Representation for Numerical Features in Deep CTR Prediction](https://doi.org/10.1145/3511808.3557587) |  | 0 | Click-Through Rate (CTR) prediction is a key problem in web search, recommendation systems, and online advertising display. Deep CTR models have achieved good performance due to adoption of the feature embedding and interaction. However, most research has focused on learning better feature interactions, with little attention to embedding representation. In this work, we propose a Dynamic Explicit Embedding Representation (DEER) for numerical features in deep CTR prediction, which can provide explicit and dynamic embedding representation for numerical features. The DEER framework is able to discretize numerical features automatically and dynamically, which can overcome the discontinuity problem in the representation of numeric information. Our methods are tested on two public datasets, and the experimental results show DEER can be applied to various deep CTR models, which also improve the performance effectively. | Yuan Cheng | BOSS Zhipin, Career Sci Lab, Beijing, Peoples R China |
|  |  [Personal Entity, Concept, and Named Entity Linking in Conversations](https://doi.org/10.1145/3511808.3557667) |  | 0 | Building conversational agents that can have natural and knowledge-grounded interactions with humans requires understanding user utterances. Entity Linking (EL) is an effective technique for understanding natural language text and connecting it to external knowledge. It is, however, shown that the existing EL methods developed for annotating documents are suboptimal for conversations, where concepts and personal entities (e.g., "my cars'') are essential for understanding user utterances. In this paper, we introduce a collection and a tool for entity linking in conversations. We provide EL annotations for 1,327 conversational utterances, consisting of links to named entities, concepts, and personal entities. The dataset is used for training our toolkit for conversational entity linking, CREL. Unlike existing EL methods, CREL is developed to identify both named entities and concepts. It also utilizes coreference resolution techniques to identify personal entities and their references to the explicit entity mentions in the conversations. We compare CREL with state-of-the-art techniques and show that it outperforms all existing baselines. | Hideaki Joko, Faegheh Hasibi | Radboud Univ Nijmegen, Nijmegen, Netherlands |
|  |  [SCC - A Test Collection for Search in Chat Conversations](https://doi.org/10.1145/3511808.3557692) |  | 0 | We present SCC, a test collection for evaluating search in chat conversations. Chat applications such as Slack, WhatsApp and Wechat have become popular communication methods. Typical search requirements in these applications revolve around the task of known item retrieval, i.e. find information that the user has previously experienced in their chats. However, the search capabilities of these chat applications are often very basic. Our collection aims to support new research into building effective methods for chat conversations search. We do so by building a collection with 114 known item retrieval topics for searching over 437,893 Slack chat messages. An important aspect when searching through conversations is the unit of indexing (indexing granularity), e.g., it being a single message vs. an entire conversation. To support researchers to investigate this aspect and its influence on retrieval effectiveness, the collection has been processed with conversation disentanglement methods: these mark cohesive segments in which each conversation consists of messages whose senders interact with each other regarding a specific event or topic. This results in a total of 38,955 multi-participant conversations being contained in the collection. Finally, we also provide a set of baselines with related empirical evaluation, including traditional bag-of-words methods and zero-shot neural methods, at both indexing granularity levels. | Ismail Sabei, Ahmed Mourad, Guido Zuccon | Univ Queensland, St Lucia, Qld, Australia |
|  |  [ML-1M++: MovieLens-Compatible Additional Preferences for More Robust Offline Evaluation of Sequential Recommenders](https://doi.org/10.1145/3511808.3557643) |  | 0 | Sequential recommendation is the task of predicting the next interacted item of a target user, given his/her past interaction sequence. Conventionally, sequential recommenders are evaluated offline with the last item in each sequence as the sole correct (relevant) label for the testing example of the corresponding user. However, little is known about how this sparsity of preference data affects the robustness of the offline evaluation's outcomes. To help researchers address this, we collect additional preference data via crowdsourcing. Specifically, we propose an assessment interface tailored to the sequential recommendation task and ask crowd workers to assess the (potential) relevance of each candidate item in MovieLens 1M, a commonly used dataset. Toward establishing a more robust evaluation methodology, we release the collected preference data, which we call ML-1M++, as well as the code of the assessment interface. | Kazutoshi Umemoto | Univ Tokyo, Tokyo, Japan |
|  |  [An Enhanced Gated Graph Neural Network for E-commerce Recommendation](https://doi.org/10.1145/3511808.3557547) |  | 0 | The recommender system for e-commerce aims to recommend appropriate items to online customers in order to drive more views, clicks or purchases on those items. Most existing models incorporate the users' historical behaviors, their profiles, and the item metadata to achieve good performances. However, since more and more people are surfing the Internet without logging in, it is no longer capable to provide accurate recommendations based on the historical data or profiles. To tackle this issue, we propose MentalNet-a mental model for e-commerce recommendation by enhancing the gated Graph Neural Network (GNN) and capturing user intent in a short session. More precisely, MentalNet is composed of two stages: in the first stage, we enhance the gated GNN to take into account the complex graph-level transitions among items, for an improved item representation; In the second stage, we propose a mental model to simulate user intent using item embedding, and then compute item preferences based on each intent. Finally, we empirically demonstrate the effectiveness of the proposed method on three datasets, including the CIKM CUP data, the RecSys Challenge data and a real-world e-commerce dataset in Alibaba Group. | Jihai Zhang, Fangquan Lin, Cheng Yang, Ziqiang Cui | Alibaba Grp, Hangzhou, Peoples R China |
|  |  [LearnShapley: Learning to Predict Rankings of Facts Contribution Based on Query Logs](https://doi.org/10.1145/3511808.3557204) |  | 0 | To explain query results, a recent line of work has proposed to leverage the game-theoretic notion of Shapley values to quantify the contribution of each input fact to each result. Despite significant recent breakthroughs improving the complexity of computing Shapley values in query answering, the computation remains quite costly. To this end, we propose an approach that aims at ranking input facts based on their (hidden) Shapley values. Our method utilizes a repository of queries over the same database for which we do store exact Shapley values. Intuitively, some queries bear similarity in the ways they transform data, and consequently in the contribution of database facts to their outputs. In this manner, given a new query and a query result, we can learn and predict the ranking of contributing facts. Our contributions are three-fold. First, we introduce DBShap, a curated dataset of queries and query results, along with the contributing facts and respective Shapley values. Second, we define the task of predicting the ranking of facts contribution w.r.t a query and query result. Finally, we propose a solution for the prediction task based on BERT. | Dana Arad, Daniel Deutch, Nave Frost | Tel Aviv University, Tel Aviv, Israel; eBay Research, Netanya, Israel |
|  |  [ClozeSearch: A Collocation Retrieval Application to Assist in Scientific Writing](https://doi.org/10.1145/3511808.3557173) |  | 0 | This paper presents a slot-filling retrieval application, ClozeSearch, for searching collocates to assist users in scientific writing. ClozeSearch suggests plausible collocates to fill in user-created slots within the query text. To ease the query formulation, we adapt the autocomplete feature to a slot-filling fashion of querying. Given a query prefix with slots, we select multiple valid terms to replace each slot and then provide complete suggestions based on such hypothetical prefixes. To reduce the search space for sampling the terms, we leveraged histogram pruning. Moreover, we propose two alternatives based on syntactic graph and deep language model for better flexibility in coping with long queries. Experimental results show that our proposed methods outperform the conventional pattern-based matching by a maximum of 0.18 points in F1-score. | Mengru Wang, Omar Alonso | Northeastern Univ, San Jose, CA 95113 USA |
|  |  [Leveraging Automated Search Relevance Evaluation to Improve System Deployment: A Case Study in Healthcare](https://doi.org/10.1145/3511808.3557517) |  | 0 | Over the last year, a digital initiative has been focused on reengineering the search engine for kp.org, a health web portal serving over 12 million members. However, traditional software testing techniques that rely on limited use cases and consistent behavior are neither comprehensive nor specific for capturing complex user search behaviors. To support system deployment, we utilize information retrieval (IR) technologies to monitor search performance, identify areas of improvement and suggest actionable items. In this case study we share industrial experience on building an IR evaluation pipeline and its usage to inform deployment and improve system development. The work emphasizes domain specific challenges, best practices and lessons learned during system deployment in a healthcare setting. It features the ability of IR techniques to strengthen collaboration between data scientists, software engineers and product managers in making data-driven decisions. | Yizhao Ni, Ferosh Jacob, Priya Gopi Achuthan, Hui Wu, Faizan Javed | KP Informat Technol, Kaiser Permanente Digital, Oakland, CA 94612 USA |
|  |  [Deep Learning for Search and Recommendation](https://doi.org/10.1145/3511808.3557493) |  | 0 | In this talk, we will go over the components of personalized search and recommender systems and demonstrate the applications of various deep learning techniques along the way. Search and recommender systems are probably the most prevalent ML powered application across the industry. They share most of the components composition and provide a user a ranked list of items, while there is subtle difference that a search system typically acts passively with a clear user intention in terms of queries and a recommender system acts more proactively. Deep learning has been wildly successful in solving complex tasks such as image recognition, speech recognition, natural language processing and understanding, machine translation, etc. In the area of personalized recommender systems, deep learning has been showing tremendous impact in recent years. Search and recommender systems can be staged roughly in three phases: 1. User and query understanding, where a query or a user profile are processed so that the systems can use the processed information to 2. retrieve all the related items (high recall) and 3. rank the items by the order of the most relevance to the user's intent (high precision). Each phase has its unique challenges but deep learning has been ubiquitously pushing beyond the limit. After walking through the talk, we hope the audience would gain some first-hand experience building a personalized search/recommender system using deep learning techniques. | Wei Liu, Kexin Xie, Linsey Pang, James Bailey, Longbing Cao, Yuxi Zhang | LinkedIn Corp, Mountain View, CA 94085 USA |
|  |  [Enhancing User Behavior Sequence Modeling by Generative Tasks for Session Search](https://doi.org/10.1145/3511808.3557310) |  | 0 | Users' search tasks have become increasingly complicated, requiring multiple queries and interactions with the results. Recent studies have demonstrated that modeling the historical user behaviors in a session can help understand the current search intent. Existing context-aware ranking models primarily encode the current session sequence (from the first behavior to the current query) and compute the ranking score using the high-level representations. However, there is usually some noise in the current session sequence (useless behaviors for inferring the search intent) that may affect the quality of the encoded representations. To help the encoding of the current user behavior sequence, we propose to use a decoder and the information of future sequences and a supplemental query. Specifically, we design three generative tasks that can help the encoder to infer the actual search intent: (1) predicting future queries, (2) predicting future clicked documents, and (3) predicting a supplemental query. We jointly learn the ranking task with these generative tasks using an encoder-decoder structured approach. Extensive experiments on two public search logs demonstrate that our model outperforms all existing baselines, and the designed generative tasks can actually help the ranking task. Besides, additional experiments also show that our approach can be easily applied to various Transformer-based encoder-decoder models and improve their performance. | Haonan Chen, Zhicheng Dou, Yutao Zhu, Zhao Cao, Xiaohua Cheng, JiRong Wen | Huawei, Poisson Lab, Beijing, Peoples R China; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Univ Montreal, Montreal, PQ, Canada; Beijing Key Lab Big Data Management & Anal Method, Beijing, Peoples R China |
|  |  [Will This Online Shopping Session Succeed? Predicting Customer's Purchase Intention Using Embeddings](https://doi.org/10.1145/3511808.3557127) |  | 0 | Customers are increasingly using online channels to buy products. For e-commerce companies, this offers new opportunities to tailor the shopping experience to customers' needs. Therefore, it is of great importance for a company to know their customers' intentions while browsing their webpage. A major challenge is the real-time analysis of a customer's intention during browsing sessions. To this end, a representation of the customer's browsing behavior must be retrieved from their live interactions on the webpage. Typically, characteristic behavioral features are extracted manually based on the knowledge of marketing experts. In this paper, we propose a customer embedding representation that is based on the customer's click-events recorded during browsing sessions. Thus, our approach does not use manually extracted features and is not based on marketing expert domain knowledge, which makes it transferable to different webpages and different online markets. We demonstrate our approach using three different e-commerce datasets to successfully predict whether a customer is going to purchase a specific product. For the prediction, we utilize the customer embedding representations as input for different machine learning models. We compare our approach with existing state-of-the-art approaches for real-time purchase prediction and show that our proposed customer representation with an LSTM predictor outperforms the state-of-the-art approach on all three datasets. Additionally, the creation process of our customers' representation is on average 235 times faster than the creation process of the baseline. | Miguel Alves Gomes, Richard Meyes, Philipp Meisen, Tobias Meisen | Breinify Inc, San Francisco, CA USA; Univ Wuppertal, Chair Technol & Management Digital Transformat, Wuppertal, North Rhine Wes, Germany |
|  |  [Calibrated Conversion Rate Prediction via Knowledge Distillation under Delayed Feedback in Online Advertising](https://doi.org/10.1145/3511808.3557557) |  | 0 | Prevailing calibration methods may fail to generalize well due to the pervasively delayed feedback issue in online advertising. That is, the labels of recent samples are more likely to be inaccurate because of the delayed feedback by users, while the old samples with complete feedback may suffer from the data shift compared to the recent ones. In this paper, we propose to calibrate conversion rate prediction models considering delayed feedback via the knowledge distillation technique. Specifically, we deploy a teacher model modeling by the samples with complete feedback to learn long-term conversion patterns and a student model modeling by the recent data to reduce the impact of data shift. We also devise a distillation loss to buoy the student model to learn from the teacher. Experimental results on two real-world advertising conversion rate prediction datasets demonstrate that our method can provide more calibrated predictions compared with the existing ones. We also exhibit that our method can be extended to different base models. | Yuyao Guo, Haoming Li, Xiang Ao, Min Lu, Dapeng Liu, Lei Xiao, Jie Jiang, Qing He | Tencent, Shenzhen, Peoples R China; Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China |
|  |  [Review-Based Domain Disentanglement without Duplicate Users or Contexts for Cross-Domain Recommendation](https://doi.org/10.1145/3511808.3557434) |  | 0 | A cross-domain recommendation has shown promising results in solving data-sparsity and cold-start problems. Despite such progress, existing methods focus on domain-shareable information (overlapped users or same contexts) for a knowledge transfer, and they fail to generalize well without such requirements. To deal with these problems, we suggest utilizing review texts that are general to most e-commerce systems. Our model (named SER) uses three text analysis modules, guided by a single domain discriminator for disentangled representation learning. Here, we suggest a novel optimization strategy that can enhance the quality of domain disentanglement, and also debilitates detrimental information of a source domain. Also, we extend the encoding network from a single to multiple domains, which has proven to be powerful for review-based recommender systems. Extensive experiments and ablation studies demonstrate that our method is efficient, robust, and scalable compared to the state-of-the-art single and cross-domain recommendation methods. | Yoonhyuk Choi, Jiho Choi, Taewook Ko, Hyungho Byun, ChongKwon Kim | Korea Inst Energy Technol, Naju, South Korea; Seoul Natl Univ, Seoul, South Korea |
|  |  [Multi-Scale User Behavior Network for Entire Space Multi-Task Learning](https://doi.org/10.1145/3511808.3557405) |  | 0 | Modelling the user's multiple behaviors is an essential part of modern e-commerce, whose widely adopted application is to jointly optimize click-through rate (CTR) and conversion rate (CVR) predictions. Most of existing methods overlook the effect of two key characteristics of the user's behaviors: for each item list, (i) contextual dependence refers to that the user's behaviors on any item are not purely determinated by the item itself but also are influenced by the user's previous behaviors (e.g., clicks, purchases) on other items in the same sequence; (ii) multiple time scales means that users are likely to click frequently but purchase periodically. To this end, we develop a new multi-scale user behavior network named H ierarchical r E current R anking O n the E ntire S pace (HEROES) which incorporates the contextual information to estimate the user multiple behaviors in a multi-scale fashion. Concretely, we introduce a hierarchical framework, where the lower layer models the user's engagement behaviors while the upper layer estimates the user's satisfaction behaviors. The proposed architecture can automatically learn a suitable time scale for each layer to capture the dynamic user's behavioral patterns. Besides the architecture, we also introduce the Hawkes process to form a novel recurrent unit which can not only encode the items' features in the context but also formulate the excitation or discouragement from the user's previous behaviors. We further show that HEROES can be extended to build unbiased ranking systems through combinations with the survival analysis technique. Extensive experiments over three large-scale industrial datasets demonstrate the superiority of our model compared with the state-of-the-art methods. characteristics of the user's behaviors: for each item list, (i) contex- tual dependence refers to that the user's behaviors on any item are not purely determinated by the item itself but also are influenced by the user's previous behaviors (e.g., clicks, purchases) on other items in the same sequence; (ii) multiple time scales means that users are likely to click frequently but purchase periodically. To this end, we develop a new multi-scale user behavior network named Hierarchical rEcurrent Ranking On the Entire Space (HEROES) which incorporates the contextual information to estimate the user multiple behaviors in a multi-scale fashion. Concretely, we intro- duce a hierarchical framework, where the lower layer models the user's engagement behaviors while the upper layer estimates the user's satisfaction behaviors. The proposed architecture can auto- matically learn a suitable time scale for each layer to capture the dynamic user's behavioral patterns. Besides the architecture, we also introduce the Hawkes process to form a novel recurrent unit which can not only encode the items' features in the context but also formulate the excitation or discouragement from the user's previous behaviors. We further show that HEROES can be extended to build unbiased ranking systems through combinations with the survival analysis technique. Extensive experiments over three large- scale industrial datasets demonstrate the superiority of our model compared with the state-of-the-art methods. | Jiarui Jin, Xianyu Chen, Weinan Zhang, Yuanbo Chen, Zaifan Jiang, Zekun Zhu, Zhewen Su, Yong Yu | Shanghai Jiao Tong Univ, Shanghai, Peoples R China; Alibaba Grp, Beijing, Peoples R China |
|  |  [Unbiased Learning to Rank with Biased Continuous Feedback](https://doi.org/10.1145/3511808.3557483) |  | 0 | It is a well-known challenge to learn an unbiased ranker with biased feedback. Unbiased learning-to-rank(LTR) algorithms, which are verified to model the relative relevance accurately based on noisy feedback, are appealing candidates and have already been applied in many applications with single categorical labels, such as user click signals. Nevertheless, the existing unbiased LTR methods cannot properly handle continuous feedback, which are essential for many industrial applications, such as content recommender systems. To provide personalized high-quality recommendation results, recommender systems need model both categorical and continuous biased feedback, such as click and dwell time. As unbiased LTR methods could not handle these continuous feedback and pair-wise learning without debiasing often performs worse than point-wise on biased feedback, which is also verified in our experiments, training multiple point-wise rankers to predict the absolute value of multiple objectives and leveraging a distinct shallow tower to estimate and alleviate the impact of position bias has been the mainstream approach in major industrial recommendation applications. However, with such a training paradigm, the optimization target differs a lot from the ranking metrics valuing the relative order of top-ranked items rather than the prediction precision of each item. Moreover, as the existing system tends to recommend more relevant items at higher positions, it is difficult for the shallow tower based methods to precisely attribute the user feedback to the impact of position or relevance. Therefore, there exists an exciting opportunity for us to get enhanced performance if we manage to solve the aforementioned issues. Accordingly, we design a novel unbiased LTR algorithm to tackle the challenges, which innovatively models position bias in the pairwise fashion and introduces the pairwise trust bias to separate the position bias, trust bias, and user relevance explicitly and can work for both continuous and categorical feedback. Experiment results on public benchmark datasets and internal live traffic of a large-scale recommender system at Tencent News show superior results for continuous labels and also competitive performance for categorical labels of the proposed method. | Yi Ren, Hongyan Tang, Siwen Zhu | Tencent, Beijing, Peoples R China |
|  |  [Target Interest Distillation for Multi-Interest Recommendation](https://doi.org/10.1145/3511808.3557464) |  | 0 | Sequential recommendation aims at predicting the next item that the user may be interested in given the historical interaction sequence. Typical neural models derive a single history embedding to represent the user's interests. Moving one step forward, recent studies point out that multiple sequence embeddings can help to better capture multi-faceted user interests. However, when ranking candidate items, these methods usually adopt the greedy inference strategy. This approach uses the best matching interest for each candidate item to calculate the ranking score, neglecting the target interest distribution in different contexts, which might lead to incompatibility with the current user intent. In this paper, we propose to enhance multi-interest recommendation by predicting the target user interest with a separate interest predictor and a specifically designed distillation loss. The proposed framework consists of two modules: the 1) multi-interest extractor to generate multiple embeddings regarding different user interests; and the 2) target-interest predictor to predict the interest distribution in the current context, which will be further utilized to dynamically aggregate multi-interest embeddings. To provide explicit supervision signals to the target-interest predictor, we devise a target-interest distillation loss that uses the similarity between the target item and multi-interest embeddings as the soft label of the target interest. This helps the target-interest predictor to accurately predict the user interest at the inference stage and enhances its generalization ability. Extensive experiments on three real-world datasets show the effectiveness and flexibility of the proposed framework. | Chenyang Wang, Zhefan Wang, Yankai Liu, Yang Ge, Weizhi Ma, Min Zhang, Yiqun Liu, Junlan Feng, Chao Deng, Shaoping Ma | China Mobile Res Inst, Beijing 100084, Peoples R China; Tsinghua Univ, AIR, Beijing 100084, Peoples R China; Tsinghua Univ, DCST, BNRist, Beijing 100084, Peoples R China |
|  |  [Representation Matters When Learning From Biased Feedback in Recommendation](https://doi.org/10.1145/3511808.3557431) |  | 0 | The logged feedback for training recommender systems is usually subject to selection bias, which could not reflect real user preference. Thus, many efforts have been made to learn the de-biased recommender system from biased feedback. However, existing methods for dealing with selection bias are usually affected by the error of propensity weight estimation, have high variance, or assume access to uniform data, which is expensive to be collected in practice. In this work, we address these issues by proposing Learning De-biased Representations (LDR), a framework derived from the representation learning perspective. LDR bridges the gap between propensity weight estimation (WE) and unbiased weighted learning (WL) and provides an end-to-end solution that iteratively conducts WE and WL. We show LDR can effectively alleviate selection bias with bounded variance. We also perform theoretical analysis on the statistical properties of LDR, such as its bias, variance, and generalization performance. Extensive experiments on both semi-synthetic and real-world datasets demonstrate the effectiveness of LDR. | Teng Xiao, Zhengyu Chen, Suhang Wang | Penn State Univ, University Pk, PA 16802 USA; Zhejiang Univ, Hangzhou, Peoples R China |
|  |  [Control-based Bidding for Mobile Livestreaming Ads with Exposure Guarantee](https://doi.org/10.1145/3511808.3557269) |  | 0 | Mobile livestreaming ads are becoming a popular approach for brand promotion and product marketing. However, a large number of advertisers fail to achieve their desired advertising performance due to the lack of ad exposure guarantee in the dynamic advertising environment. In this work, we propose a bidding-based ad delivery algorithm for mobile livestreaming ads that can provide advertisers with bidding strategies for optimizing diverse marketing objectives under general ad performance guaranteed constraints, such as ad exposure and cost-efficiency constraints. By modeling the problem as an online integer programming and applying primal-dual theory, we can derive the bidding strategy from solving the optimal dual variables. The initialization of the dual variables is realized through a deep neural network that captures the complex relation between dual variables and dynamic advertising environments. We further propose a control-based bidding algorithm to adjust the dual variables in an online manner based on the real-time advertising performance feedback and constraints. Experiments on a real-world industrial dataset demonstrate the effectiveness of our bidding algorithm in terms of optimizing marketing objectives and guaranteeing ad constraints. | Haoqi Zhang, Junqi Jin, Zhenzhe Zheng, Fan Wu, Haiyang Xu, Jian Xu | Shanghai Jiao Tong Univ, Shanghai, Peoples R China; Alibaba Grp, Beijing, Peoples R China |
|  |  [Hierarchical Conversational Preference Elicitation with Bandit Feedback](https://doi.org/10.1145/3511808.3557347) |  | 0 | The recent advances of conversational recommendations provide a promising way to efficiently elicit users' preferences via conversational interactions. To achieve this, the recommender system conducts conversations with users, asking their preferences for different items or item categories. Most existing conversational recommender systems for cold-start users utilize a multi-armed bandit framework to learn users' preference in an online manner. However, they rely on a pre-defined conversation frequency for asking about item categories instead of individual items, which may incur excessive conversational interactions that hurt user experience. To enable more flexible questioning about key-terms, we formulate a new conversational bandit problem that allows the recommender system to choose either a key-term or an item to recommend at each round and explicitly models the rewards of these actions. This motivates us to handle a new exploration-exploitation (EE) trade-off between key-term asking and item recommendation, which requires us to accurately model the relationship between key-term and item rewards. We conduct a survey and analyze a real-world dataset to find that, unlike assumptions made in prior works, key-term rewards are mainly affected by rewards of representative items. We propose two bandit algorithms, Hier-UCB and Hier-LinUCB, that leverage this observed relationship and the hierarchical structure between key-terms and items to efficiently learn which items to recommend. We theoretically prove that our algorithm can reduce the regret bound's dependency on the total number of items from previous work. We validate our proposed algorithms and regret bound on both synthetic and real-world data. | Jinhang Zuo, Songwen Hu, Tong Yu, Shuai Li, Handong Zhao, Carlee JoeWong | Shanghai Jiao Tong Univ, Shanghai, Peoples R China; Adobe Res, San Jose, CA USA; Carnegie Mellon Univ, Pittsburgh, PA 15213 USA |
|  |  [Improving Text-based Similar Product Recommendation for Dynamic Product Advertising at Yahoo](https://doi.org/10.1145/3511808.3557129) |  | 0 | Retrieving similar products is a critical functionality required by many e-commerce websites as well as dynamic product advertising systems. Retargeting and Prospecting are two major forms of dynamic product advertising. Typically, after a user interacts with a product on an advertiser website (e.g., Macy's), when the user later visits a website (e.g., yahoo.com) supported by a dynamic product advertising system, the same product may be shown to the user as a Retargeting product ad, while some similar products may be shown to the user as Prospecting product ads on the web page. Similar products can enrich users' ad experience based on users' intent on the Prospecting product ads through which the users interacted. These product ads can also serve as substitutes when Retargeting ad candidates are out of stock. However, it is challenging to retrieve similar products among billions of products in a product catalog efficiently. Deep Siamese models allow efficient retrieval but do not put enough emphasize on key product attributes. To improve the quality of the similar products, we propose to first use a Siamese Transformer-based model to retrieve similar products and then refine them with the attribute "product name" that indicates the type of a product (e.g., running shoes, engagement ring, etc.) for post filtering. We propose a novel product name generation model that fine tunes a pre-trained Transformer-based language model with a sequence to sequence objective. To the best of our knowledge, this is the first work using a generative approach for identifying product attributes. We introduce two applications of the proposed approach for the dynamic product advertising system of Yahoo for Retargeting and Prospecting respectively. Offline evaluation and online A/B testing shows that the proposed approach retrieves high quality similar products, leading to an increase of ad clicks and ad revenue. | Xiao Bai, Lei Duan, Richard Tang, Gaurav Batra, Ritesh Agrawal | Yahoo Res, San Jose, CA 95110 USA; Yahoo, San Jose, CA USA |
|  |  [Addressing Cold Start in Product Search via Empirical Bayes](https://doi.org/10.1145/3511808.3557066) |  | 0 | Cold start is a challenge in product search. Profuse literature addresses related problems such as bias and diversity in search, and cold start is a classic topic in recommender systems research. While search cold start might be seen conceptually as a particular case in such areas, we find that available solutions fail to specifically and practically solve the cold-start problem in product search. The problem is complex as exposing new products may come at the expense of primary business metrics (e.g. revenue), and involves a complex balance between customer satisfaction, seller satisfaction, business performance, short-term gains and long-term value. In this paper, we propose a principled approach to deal with cold start in a large-scale e-commerce search system. We discuss how product ranking is affected by non-behavioral topical relevance and behavioral popularity, and their role in introducing biases that result in cold-start for ranking new products. Our approach applies Empirical Bayes to model behavioral information via non-behavioral signals in terms of priors, and effectively estimate true engagement posterior updates. We report comprehensive offline and online experiments over large datasets that show the effectiveness of our methods to address cold start, and provide further insights. An online A/B test on 50 million queries shows a significant improvement in new product impressions by 13.53% and a significant increase in new product purchase by 11.14%, with overall purchases up by 0.08%, highlighting the empirical effectiveness of the approach. | Cuize Han, Pablo Castells, Parth Gupta, Xu Xu, Vamsi Salaka | Amazon, Madrid, Spain; Amazon, Palo Alto, CA 94301 USA |
|  |  [Adaptive Domain Interest Network for Multi-domain Recommendation](https://doi.org/10.1145/3511808.3557137) |  | 0 | Industrial recommender systems usually hold data from multiple business scenarios and are expected to provide recommendation services for these scenarios simultaneously. In the retrieval step, the topK high-quality items selected from a large number of corpus usually need to be various for multiple scenarios. Take Alibaba display advertising system for example, not only because the behavior patterns of Taobao users are diverse, but also differentiated scenarios' bid prices assigned by advertisers vary significantly. Traditional methods either train models for each scenario separately, ignoring the cross-domain overlapping of user groups and items, or simply mix all samples and maintain a shared model which makes it difficult to capture significant diversities between scenarios. In this paper, we present Adaptive Domain Interest Network(ADIN) that adaptively handles the commonalities and diversities across scenarios, making full use of multi-scenarios data during training. Then the proposed method is able to improve the performance of each business domain by giving various topK candidates for different scenarios during online inference. Specifically, our proposed ADIN models the commonalities and diversities for different domains by shared networks and domain-specific networks, respectively. In addition, we apply the domain-specific batch normalization and design the domain interest adaptation layer for feature-level domain adaptation. A self training strategy is also incorporated to capture label-level connections across domains.ADIN has been deployed in the display advertising system of Alibaba, and obtains 1.8% improvement on advertising revenue. | Yuchen Jiang, Qi Li, Han Zhu, Jinbei Yu, Jin Li, Ziru Xu, Huihui Dong, Bo Zheng | Alibaba Grp, Hangzhou, Zhejiang, Peoples R China |
|  |  [Ensure A/B Test Quality at Scale with Automated Randomization Validation and Sample Ratio Mismatch Detection](https://doi.org/10.1145/3511808.3557087) |  | 0 | eBay's experimentation platform runs hundreds of A/B tests on any given day. The platform integrates with the tracking infrastructure and customer experience servers, provides the sampling service for experiments, and has the responsibility to monitor the progress of each A/B test. There are many challenges especially when it is required to ensure experiment quality at the large scale. We discuss two automated test quality monitoring processes and methodologies, namely randomization validation using population stability index (PSI) and sample ratio mismatch (a.k.a. sample delta) detection using sequential analysis. The automated processes assist the experimentation platform to run high quality and trustworthy tests not only effectively on a large scale, but also efficiently by minimizing false positive monitoring alarms to experimenters. | Keyu Nie, Zezhong Zhang, Bingquan Xu, Ted Tao Yuan | eBay Inc, San Jose, CA 95125 USA |
|  |  [Cross-Domain Product Search with Knowledge Graph](https://doi.org/10.1145/3511808.3557116) |  | 0 | The notion personalization lies on the core of a real-world product search system, whose aim is to understand the user's search intent in a fine-grained level. The existing solutions mainly achieve this purpose through a coarse-grained semantic matching in terms of the query and item's description or the collective click correlations. Besides the issued query, the historical search behaviors of a user would cover lots of her personalized interests, which is a promising avenue to alleviate the semantic gap between users, items and queries. However, as to a specific domain, a user's search behaviors are generally sparse or even unavailable (i.e., cold-start users). How to exploit the search behaviors from the other relevant domain and enable effective fine-grained intent understanding remains largely unexplored for product search. Moreover, the semantic gap could be further aggravated since the properties of an item could evolve over time (e.g., the price adjustment for a mobile phone or the business plan update for a financial item), which is also mainly overlooked by the existing solutions. To this end, we are interested in bridging the semantic gap via a marriage between cross-domain transfer learning and knowledge graph. Specifically, we propose a simple yet effective knowledge graph based information propagation framework for cross-domain product search (named KIPS). In KIPS, we firstly utilize a shared knowledge graph relevant to both source and target domains as a semantic backbone to facilitate the information propagation across domains. Then, we build individual collaborative knowledge graphs to model both long-term interests/characteristics and short-term interests/characteristics of a user/item respectively. In order to harness cross-domain interest correlations, two unsupervised strategies to guide the interest learning and alignment are introduced: maximum mean discrepancy (MMD) and kg-aware contrastive learning. In detail, the MMD is utilized to support a coarse-grained domain alignment over the user's long-term interests across two domains. Then, the kg-aware contrastive learning process conducts a fine-grained interest alignment based on the shared knowledge graph. Experiments over two real-world large-scale datasets demonstrate the effectiveness of KIPS over a series of strong baselines. Our online A/B test also shows substantial performance gain on multiple metrics. Currently, KIPS has been deployed in AliPay for financial product search. Both the code implementation and the two datasets used for evaluation will be released online publicly(1). | Rui Zhu, Yiming Zhao, Wei Qu, Zhongyi Liu, Chenliang Li | Wuhan Univ China, Sch Cyber Sci & Engn, Wuhan, Peoples R China; Ant Grp, Hangzhou, Peoples R China |
|  |  [Intra-session Context-aware Feed Recommendation in Live Systems](https://doi.org/10.1145/3511808.3557618) |  | 0 | Feed recommendation allows users to constantly browse items until feel uninterested and leave the session, which differs from traditional recommendation scenarios. Within a session, user's decision to continue browsing or not substantially affects occurrences of later clicks. However, such type of exposure bias is generally ignored or not explicitly modeled in most feed recommendation studies. In this paper, we model this effect as part of intra-session context, and propose a novel intra-session Context-aware Feed Recommendation (INSCAFER) framework to maximize the total views and total clicks simultaneously. User click and browsing decisions are jointly learned by a multi-task setting, and the intra-session context is encoded by the session-wise exposed item sequence. We deploy our model on Alipay with all key business benchmarks improved. Our method sheds some lights on feed recommendation studies which aim to optimize session-level click and view metrics. | Luo Ji, Gao Liu, Mingyang Yin, Hongxia Yang | Alibaba Grp, DAMO Acad, Hangzhou, Peoples R China |
|  |  [Implicit Session Contexts for Next-Item Recommendations](https://doi.org/10.1145/3511808.3557613) |  | 0 | \noindent Session-based recommender systems capture the short-term interest of a user within a session. Session contexts (i.e., a user's high-level interests or intents within a session) are not explicitly given in most datasets, and implicitly inferring session context as an aggregation of item-level attributes is crude. In this paper, we propose \method, which implicitly contextualizes sessions. \method first generates implicit contexts for sessions by creating a session-item graph, learning graph embeddings, and clustering to assign sessions to contexts. \method then trains a session context predictor and uses the predicted contexts' embeddings to enhance the next-item prediction accuracy. Experiments on four datasets show that \method has superior next-item prediction accuracy than state-of-the-art models. A case study of \method on the Reddit dataset confirms that assigned session contexts are unique and meaningful. | Sejoon Oh, Ankur Bhardwaj, Jongseok Han, Sungchul Kim, Ryan A. Rossi, Srijan Kumar | Georgia Inst Technol, Atlanta, GA 30332 USA; Adobe Res, San Francisco, CA USA |
|  |  [Rethinking Large-scale Pre-ranking System: Entire-chain Cross-domain Models](https://doi.org/10.1145/3511808.3557683) |  | 0 | Industrial systems such as recommender systems and online advertising, have been widely equipped with multi-stage architectures, which are divided into several cascaded modules, including matching, pre-ranking, ranking and re-ranking. As a critical bridge between matching and ranking, existing pre-ranking approaches mainly endure sample selection bias (SSB) problem owing to ignoring the entire-chain data dependence, resulting in sub-optimal performances. In this paper, we rethink pre-ranking system from the perspective of the entire sample space, and propose Entire-chain Cross-domain Models (ECM), which leverage samples from the whole cascaded stages to effectively alleviate SSB problem. Besides, we design a fine-grained neural structure named ECMM to further improve the pre-ranking accuracy. Specifically, we propose a cross-domain multi-tower neural network to comprehensively predict for each stage result, and introduce the sub-networking routing strategy with L0 regularization to reduce computational costs. Evaluations on real-world large-scale traffic logs demonstrate that our pre-ranking models outperform SOTA methods while time consumption is maintained within an acceptable level, which achieves better trade-off between efficiency and effectiveness. | Jinbo Song, Ruoran Huang, Xinyang Wang, Wei Huang, Qian Yu, Mingming Chen, Yafei Yao, Chaosheng Fan, Changping Peng, Zhangang Lin, Jinghe Hu, Jingping Shao | JD Com, Mkt & Commercializat Ctr, Beijing, Peoples R China |
|  |  [Task Similarity Aware Meta Learning for Cold-Start Recommendation](https://doi.org/10.1145/3511808.3557709) |  | 0 | In recommender systems, content-based methods and meta-learning involved methods usually have been adopted to alleviate the item cold-start problem. The former consider utilizing item attributes at the feature level and the latter aim at learning a globally shared initialization for all tasks to achieve fast adaptation with limited data at the task level. However, content-based methods only focus on the similarity of item attributes, ignoring the relationships established by user interactions. And for tasks with different distributions, most meta-learning-based methods are difficult to achieve better performance under a single initialization. To address the limitations mentioned above and combine the strengths of both methods, we propose a Task Similarity Aware Meta-Learning (TSAML) framework from two aspects. Specifically, at the feature level, we simultaneously introduce content information and user-item relationships to exploit task similarity. At the task level, we design an automatic soft clustering module to cluster similar tasks and generate the same initialization for similar tasks. Extensive offline experiments demonstrate that the TSAML framework has superior performance and recommends cold items to preferred users more effectively than other state-of-the-art methods. | Jieyu Yang, Zhaoxin Huan, Yong He, Ke Ding, Liang Zhang, Xiaolu Zhang, Jun Zhou, Linjian Mo | Ant Grp, Hangzhou, Peoples R China |
|  |  [Generative Adversarial Zero-Shot Learning for Cold-Start News Recommendation](https://doi.org/10.1145/3511808.3557335) |  | 0 | News recommendation models extremely rely on the interactive information between users and news articles to personalize the recommendation. Therefore, one of their most serious challenges is the cold-start problem (CSP). Their performance is dropped intensely for new users or new news. Zero-shot learning helps in synthesizing a virtual representation of the missing data in a variety of application tasks. Therefore, it can be a promising solution for CSP to generate virtual interaction behaviors for new users or new news articles. In this paper, we utilize the generative adversarial zero-shot learning in building a framework, namely, GAZRec, which is able to address the CSP caused by purely new users or new news. GAZRec can be flexibly applied to any neural news recommendation model. According to the experimental evaluations, applying the proposed framework to various news recommendation baselines attains a significant AUC improvement of 1% - 21% in different cold start scenarios and 1.2% - 6.6% in the regular situation when both users and news have a few interactions. | Manal A. Alshehri, Xiangliang Zhang | Natl Yang Ming Chiao Tung Univ Hsinchu, Inst Informat Management, Hsinchu 300, Taiwan; Natl Yang Ming Chiao Tung Univ, Inst Management Technol, Hsinchu 300, Taiwan |
|  |  [User Recommendation in Social Metaverse with VR](https://doi.org/10.1145/3511808.3557487) |  | 0 | Social metaverse with VR has been viewed as a paradigm shift for social media. However, most traditional VR social platforms ignore emerging characteristics in a metaverse, thereby failing to boost user satisfaction. In this paper, we explore a scenario of socializing in metaverse with VR, which brings major advantages over conventional social media: 1) leverage flexible display of users' 360-degree viewports to satisfy individual user interests, 2) ensure the user feelings of co-existence, 3) prevent view obstruction to help users find friends in crowds, and 4) support socializing with digital twins. Therefore, we formulate the Co-presence, and Occlusion-aware Metaverse User Recommendation (COMUR) problem to recommend a set of rendered players for users in social metaverse with VR. We prove COMUR is an NP-hard optimization problem and design a dual-module deep graph learning framework (COMURNet) to recommend appropriate users for viewport display. Experimental results on real social metaverse datasets and a user study with Occulus Quest 2 manifest that the proposed model outperforms baseline approaches by at least 36.7% of solution quality. | BingJyue Chen, DeNian Yang | Acad Sinica, Inst Informat Sci, Taipei, Taiwan |
|  |  [Aries: Accurate Metric-based Representation Learning for Fast Top-k Trajectory Similarity Query](https://doi.org/10.1145/3511808.3557239) |  | 0 | With the prevalence of location-based services (LBS), trajectories are being generated rapidly. As is widely used in LBS, top-k trajectory similarity query serves as a key operation, deeply empowering applications such as travel route recommendation and carpooling. Given the rise of deep learning, trajectory representation has been well-proven to speed up this operator. However, existing representation-based computing modes remain two major problems understudied: the low quality of trajectory representation and insufficient support for various trajectory similarity metrics, which make them difficult to apply in practice. Therefore, we propose an Accurate metric-based representation learning approach for fast top-k trajectory similarity query, named Aries. Specifically, Aries has two sophisticated modules: (1) A novel trajectory embedding strategy enhanced by the bidirectional LSTM encoder and spatial attention mechanism, which can extract more precise and comprehensive knowledge. (2) A deep metric learning network aggregating multiple measures for better top-k query. Extensive experiments conducted on real trajectory dataset show that Aries achieves both impressive accuracy and lower training time compared with state-of-the-art solutions. In particular, it achieves 5x-10x speedup and 10%-20% accuracy improvement over Euclidean, Hausdorff, DTW, and EDR measures. Besides, our method can maintain stable performance when handling various scenarios, without repeated training in order to adapt to diverse similarity metrics. | Chunhui Feng, Zhicheng Pan, Junhua Fang, Jiajie Xu, Pengpeng Zhao, Lei Zhao | Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China |
|  |  [ITSM-GCN: Informative Training Sample Mining for Graph Convolutional Network-based Collaborative Filtering](https://doi.org/10.1145/3511808.3557368) |  | 0 | Recently, graph convolutional network (GCN) has become one of the most popular and state-of-the-art collaborative filtering (CF) methods. Existing GCN-based CF studies have made many meaningful and excellent efforts at loss function design and embedding propagation improvement. Despite their successes, we argue that existing methods have not yet properly explored more effective sampling strategy, including both positive sampling and negative sampling. To tackle this limitation, a novel framework named ITSM-GCN is proposed to carry out our designed I nformative T raining S ample M ining (ITSM) sampling strategy for the learning of GCN -based CF models. Specifically, we first adopt and improve the dynamic negative sampling (DNS) strategy, which achieves considerable improvements in both training efficiency and recommendation performance. More importantly, we design two potentially positive training sample mining strategies, namely a similarity-based sampler and score-based sampler, to further enhance GCN-based CF. Extensive experiments show that ITSM-GCN significantly outperforms state-of-the-art GCN-based CF models, including LightGCN, SGL-ED and SimpleX. For example, ITSM-GCN improves on SimpleX by 12.0%, 3.0%, and 1.2% on Recall@20 for Amazon-Books, Yelp2018 and Gowalla, respectively. | Kaiqi Gong, Xiao Song, Senzhang Wang, Songsong Liu, Yong Li | Beihang Univ, Beijing, Peoples R China; Cent South Univ, Changsha, Hunan, Peoples R China |
|  |  [Evolutionary Preference Learning via Graph Nested GRU ODE for Session-based Recommendation](https://doi.org/10.1145/3511808.3557314) |  | 0 | Session-based recommendation (SBR) aims to predict the user's next action based on the ongoing sessions. Recently, there has been an increasing interest in modeling the user preference evolution to capture the fine-grained user interests. While latent user preferences behind the sessions drift continuously over time, most existing approaches still model the temporal session data in discrete state spaces, which are incapable of capturing the fine-grained preference evolution and result in sub-optimal solutions. To this end, we propose Graph Nested GRU ordinary differential equation (ODE), namely GNG-ODE, a novel continuum model that extends the idea of neural ODEs to continuous-time temporal session graphs. The proposed model preserves the continuous nature of dynamic user preferences, encoding both temporal and structural patterns of item transitions into continuous-time dynamic embeddings. As the existing ODE solvers do not consider graph structure change and thus cannot be directly applied to the dynamic graph, we propose a time alignment technique, called t-Alignment, to align the updating time steps of the temporal session graphs within a batch. Empirical results on three benchmark datasets show that GNG-ODE significantly outperforms other baselines. | Jiayan Guo, Peiyan Zhang, Chaozhuo Li, Xing Xie, Yan Zhang, Sunghun Kim | Microsoft Res Asia, Beijing, Peoples R China; Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; Peking Univ, Sch Intelligence Sci & Technol, Beijing, Peoples R China |
|  |  [Gromov-Wasserstein Guided Representation Learning for Cross-Domain Recommendation](https://doi.org/10.1145/3511808.3557338) |  | 0 | Cross-Domain Recommendation (CDR) has attracted increasing attention in recent years as a solution to the data sparsity issue. The fundamental paradigm of prior efforts is to train a mapping function based on the overlapping users/items and then apply it to the knowledge transfer. However, due to the commercial privacy policy and the sensitivity of user data, it is unrealistic to explicitly share the user mapping relations and behavior data. Therefore, in this paper, we consider a more practical cross-domain scenario, where there is no explicit overlap between the source and target domains in terms of users/items. Since the user sets of both domains are drawn from the entire population, there may be commonalities between their user characteristics, resulting in comparable user preference distributions. Thus, without the mapping relations at user level, it is feasible to model this distribution-level relation to transfer knowledge between domains. To this end, we propose a novel framework that improves the effect of representation learning on the target domain by aligning the representation distributions between the source and target domains. In addition, GWCDR can be easily integrated with existing single-domain collaborative filtering methods to achieve cross-domain recommendation. Extensive experiments on two pairs of public bidirectional datasets demonstrate the effectiveness of our proposed framework in enhancing the recommendation performance. | Xinhang Li, Zhaopeng Qiu, Xiangyu Zhao, Zihao Wang, Yong Zhang, Chunxiao Xing, Xian Wu | City Univ Hong Kong, Sch Data Sci, Hong Kong, Peoples R China; Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; Tsinghua Univ, Dept Comp Sci & Techonol, Beijing, Peoples R China; Tencent Jarvis Lab, Beijing, Peoples R China |
|  |  [Spatiotemporal-aware Session-based Recommendation with Graph Neural Networks](https://doi.org/10.1145/3511808.3557458) |  | 0 | Session-based recommendation (SBR) aims to recommend items based on user behaviors in a session. For the online life service platforms, such as Meituan, both the user's location and the current time primarily cause the different patterns and intents in user behaviors. Hence, spatiotemporal context plays a significant role in the recommendation on those platforms, which motivates an important problem of spatiotemporal-aware session-based recommendation (STSBR). Since the spatiotemporal context is introduced, there are two critical challenges: 1) how to capture session-level relations of spatiotemporal context (inter-session view), and 2) how to model the complex user decision-making process at a specific location and time (intra-session view). To address them, we propose a novel solution named STAGE in this paper. Specifically, STAGE first constructs a global information graph to model the multi-level relations among all sessions, and a session decision graph to capture the complex user decision process for each session. STAGE then performs inter-session and intra-session embedding propagation on the constructed graphs with the proposed graph attentive convolution (GAC) to learn representations from the above two perspectives. Finally, the learned representations are combined with spatiotemporal-aware soft-attention for final recommendation. Extensive experiments on two datasets from Meituan demonstrate the superiority of STAGE over state-of-the-art methods. Further studies also verify that each component is effective. | Yinfeng Li, Chen Gao, Xiaoyi Du, Huazhou Wei, Hengliang Luo, Depeng Jin, Yong Li | Meituan Inc, Beijing, Peoples R China; Tsinghua Univ, Beijing, Peoples R China |
|  |  [Efficient Learning with Pseudo Labels for Query Cost Estimation](https://doi.org/10.1145/3511808.3557305) |  | 0 | Query cost estimation, which is to estimate the query plan cost and query execution cost, is of utmost importance to query optimizers. Query plan cost estimation heavily relies on accurate cardinality estimation, and query execution cost estimation gives good hints on query latency, both of which are challenging in database management systems. Despite decades of research, existing studies either over-simplify the models only using histograms and polynomial calculation that leads to inaccurate estimates, or over-complicate them by using cumbersome neural networks with the requirements for large amounts of training data hence poor computational efficiency. Besides, most of the studies ignore the diversity of query plan structures. In this work, we propose a plan-based query cost estimation framework, called Saturn, which can eStimate cardinality and latency accurately and efficiently, for any query plan structures. Saturn first encodes each query plan tree into a compressed vector by using a traversal-based query plan autoencoder to cope with diverse plan structures. The compressed vectors can be leveraged to distinguish different query types, which is highly useful for downstream tasks. Then a pseudo label generator is designed to acquire all cardinality and latency labels with the execution part of the query plans in the training workload, which can significantly reduce the overhead of collecting the real cardinality and latency labels. Finally, a chain-wise transfer learning module is proposed to estimate the cardinality and latency of the query plan in a pipeline paradigm, which further enhances the efficiency. An extensive empirical study on benchmark data offers evidence that Saturn outperforms the state-of-the-art proposals in terms of accuracy, efficiency, and generalizability for query cost estimation. | Shuncheng Liu, Xu Chen, Yan Zhao, Jin Chen, Rui Zhou, Kai Zheng | Aalborg Univ, Aalborg, Denmark; Huawei Technol Co Ltd, Chengdu, Peoples R China; Univ Elect Sci & Technol China, Chengdu, Peoples R China |
|  |  [I Know What You Do Not Know: Knowledge Graph Embedding via Co-distillation Learning](https://doi.org/10.1145/3511808.3557355) |  | 0 | Knowledge graph (KG) embedding seeks to learn vector representations for entities and relations. Conventional models reason over graph structures, but they suffer from the issues of graph incompleteness and long-tail entities. Recent studies have used pre-trained language models to learn embeddings based on the textual information of entities and relations, but they cannot take advantage of graph structures. In the paper, we show empirically that these two kinds of features are complementary for KG embedding. To this end, we propose CoLE, a Co-distillation Learning method for KG Embedding that exploits the complementarity of graph structures and text information. Its graph embedding model employs Transformer to reconstruct the representation of an entity from its neighborhood subgraph. Its text embedding model uses a pre-trained language model to generate entity representations from the soft prompts of their names, descriptions, and relational neighbors. To let the two model promote each other, we propose co-distillation learning that allows them to distill selective knowledge from each other's prediction logits. In our co-distillation learning, each model serves as both a teacher and a student. Experiments on benchmark datasets demonstrate that the two models outperform their related baselines, and the ensemble method CoLE with co-distillation learning advances the state-of-the-art of KG embedding. | Yang Liu, Zequn Sun, Guangyao Li, Wei Hu | Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China |
|  |  [NEST: Simulating Pandemic-like Events for Collaborative Filtering by Modeling User Needs Evolution](https://doi.org/10.1145/3511808.3557407) |  | 0 | We outline a simulation-based study of the effect rapid population-scale concept drifts have on Collaborative Filtering (CF) models. We create a framework for analyzing the effects of macro-trends in population dynamics on the behavior of such models. Our framework characterizes population-scale concept drifts in item preferences and provides a lens to understand the influence events, such as a pandemic, have on CF models. Our experimental results show the initial impact on CF performance at the initial stage of such events, followed by an aggravated population herding effect during the event. The herding introduces a popularity bias that may benefit affected users, but which comes at the expense of a normal user experience. We propose an adaptive ensemble method that can effectively apply optimal algorithms to cope with the change brought about by different stages of the event. | Chenglong Ma, Yongli Ren, Pablo Castells, Mark Sanderson | RMIT Univ, Melbourne, Vic, Australia; Univ Autonoma Madrid, Madrid, Spain |
|  |  [Cross-Network Social User Embedding with Hybrid Differential Privacy Guarantees](https://doi.org/10.1145/3511808.3557278) |  | 0 | Integrating multiple online social networks (OSNs) has important implications for many downstream social mining tasks, such as user preference modelling, recommendation, and link prediction. However, it is unfortunately accompanied by growing privacy concerns about leaking sensitive user information. How to fully utilize the data from different online social networks while preserving user privacy remains largely unsolved. To this end, we propose a Cross-network Social User Embedding framework, namely DP-CroSUE, to learn the comprehensive representations of users in a privacy-preserving way. We jointly consider information from partially aligned social networks with differential privacy guarantees. In particular, for each heterogeneous social network, we first introduce a hybrid differential privacy notion to capture the variation of privacy expectations for heterogeneous data types. Next, to find user linkages across social networks, we make unsupervised user embedding-based alignment in which the user embeddings are achieved by the heterogeneous network embedding technology. To further enhance user embeddings, a novel cross-network GCN embedding model is designed to transfer knowledge across networks through those aligned users. Extensive experiments on three real-world datasets demonstrate that our approach makes a significant improvement on user interest prediction tasks as well as defending user attribute inference attacks from embedding. | Jiaqian Ren, Lei Jiang, Hao Peng, Lingjuan Lyu, Zhiwei Liu, Chaochao Chen, Jia Wu, Xu Bai, Philip S. Yu | Beihang Univ, Sch Cyber Sci & Technol, Beijing, Peoples R China; Zhejiang Univ, Hangzhou 310058, Peoples R China; Salesforce, Palo Alto, CA 94301 USA; Macquarie Univ, Sydney, NSW 2109, Australia; Univ Illinois, Chicago, IL 60607 USA; Chinese Acad Sci, Inst Informat Engn, Res Room 2, Beijing, Peoples R China; Sony AI, Tokyo 1080075, Japan; Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China |
|  |  [Towards Principled User-side Recommender Systems](https://doi.org/10.1145/3511808.3557476) |  | 0 | Traditionally, recommendation algorithms have been designed for service developers. However, recently, a new paradigm called user-side recommender systems has been proposed and they enable web service users to construct their own recommender systems without access to trade-secret data. This approach opens the door to user-defined fair systems even if the official recommender system of the service is not fair. While existing methods for user-side recommender systems have addressed the challenging problem of building recommender systems without using log data, they rely on heuristic approaches, and it is still unclear whether constructing user-side recommender systems is a well-defined problem from theoretical point of view. In this paper, we provide theoretical justification of user-side recommender systems. Specifically, we see that hidden item features can be recovered from the information available to the user, making the construction of user-side recommender system well-defined. However, this theoretically grounded approach is not efficient. To realize practical yet theoretically sound recommender systems, we propose three desirable properties of user-side recommender systems and propose an effective and efficient user-side recommender system, Consul, based on these foundations. We prove that Consul satisfies all three properties, whereas existing user-side recommender systems lack at least one of them. In the experiments, we empirically validate the theory of feature recovery via numerical experiments. We also show that our proposed method achieves an excellent trade-off between effectiveness and efficiency and demonstrate via case studies that the proposed method can retrieve information that the provider's official recommender system cannot. | Ryoma Sato | Kyoto Univ, RIKEN AIP, Kyoto, Japan |
|  |  [Cross-domain Recommendation via Adversarial Adaptation](https://doi.org/10.1145/3511808.3557277) |  | 0 | Data scarcity, e.g., labeled data being either unavailable or too expensive, is a perpetual challenge of recommendation systems. Cross-domain recommendation leverages the label information in the source domain to facilitate the task in the target domain. However, in many real-world cross-domain recommendation systems, the source domain and the target domain are sampled from different data distributions, which obstructs the cross-domain knowledge transfer. In this paper, we propose to specifically align the data distributions between the source domain and the target domain to alleviate imbalanced sample distribution and thus challenge the data scarcity issue in the target domain. Technically, our proposed approach builds an adversarial adaptation (AA) framework to adversarially train the target model together with a pre-trained source model. A domain discriminator plays the two-player minmax game with the target model and guides the target model to learn domain-invariant features that can be transferred across domains. At the same time, the target model is calibrated to learn domain-specific information of the target domain. With such a formulation, the target model not only learns domain-invariant features for knowledge transfer, but also preserves domain-specific information for target recommendation. We apply the proposed method to address the issues of insufficient data and imbalanced sample distribution in real-world Click-Through Rate (CTR)/Conversion Rate (CVR) predictions on a large-scale dataset. Specifically, we formulate our approach as a plug-and-play module to boost existing recommendation systems. Extensive experiments verify that the proposed method is able to significantly improve the prediction performance on the target domain. For instance, our method can boost PLE with a performance improvement of 13.88% in terms of Area Under Curve (AUC) compared with single-domain PLE. | Hongzu Su, Yifei Zhang, Xuejiao Yang, Hua Hua, Shuangyang Wang, Jingjing Li | Tencent, Interact Entertainment Grp, Shenzhen, Peoples R China |
|  |  [Bandit Learning in Many-to-One Matching Markets](https://doi.org/10.1145/3511808.3557248) |  | 0 | An emerging line of research is dedicated to the problem of one-to-one matching markets with bandits, where the preference of one side is unknown and thus we need to match while learning the preference through multiple rounds of interaction. However, in many real-world applications such as online recruitment platform for short-term workers, one side of the market can select more than one participant from the other side, which motivates the study of the many-to-one matching problem. Moreover, the existence of a unique stable matching is crucial to the competitive equilibrium of the market. In this paper, we first introduce a more general new \textit{$\tilde{\alpha}$}-condition to guarantee the uniqueness of stable matching in many-to-one matching problems, which generalizes some established uniqueness conditions such as \textit{SPC} and \textit{Serial Dictatorship}, and recovers the known $\alpha$-condition if the problem is reduced to one-to-one matching. Under this new condition, we design an MO-UCB-D4 algorithm with $O\left(\frac{NK\log(T)}{\Delta^2}\right)$ regret bound, where $T$ is the time horizon, $N$ is the number of agents, $K$ is the number of arms, and $\Delta$ is the minimum reward gap. Extensive experiments show that our algorithm achieves uniform good performances under different uniqueness conditions. | Zilong Wang, Liya Guo, Junming Yin, Shuai Li | PhD student, Shanghai Jiaotong University; Assistant Professor, John Hopcroft Center, Shanghai Jiao Tong University |
|  |  [Leveraging Multiple Types of Domain Knowledge for Safe and Effective Drug Recommendation](https://doi.org/10.1145/3511808.3557380) |  | 0 | Predicting drug combinations according to patients' electronic health records is an essential task in intelligent healthcare systems, which can assist clinicians in ordering safe and effective prescriptions. However, existing work either missed/underutilized the important information lying in the drug molecule structure in drug encoding or has insufficient control over Drug-Drug Interactions (DDIs) rates within the predictions. To address these limitations, we propose CSEDrug, which enhances the drug encoding and DDIs controlling by leveraging multi-faceted drug knowledge, including molecule structures of drugs, Synergistic DDIs (SDDIs), and Antagonistic DDIs (ADDIs). We integrate these types of knowledge into CSEDrug by a graph-based drug encoder and multiple loss functions, including a novel triplet learning loss and a comprehensive DDI controllable loss. We evaluate the performance of CSEDrug in terms of accuracy, effectiveness, and safety on the public MIMIC-III dataset. The experimental results demonstrate that CSEDrug outperforms several state-of-the-art methods and achieves a 2.93% and a 2.77% increase in the Jaccard similarity scores and F1 scores, meanwhile, a 0.68% reduction of the ADDI rate (safer drug combinations), and 0.69% improvement of the SDDI rate (more effective drug combinations). | Jialun Wu, Buyue Qian, Yang Li, Zeyu Gao, Meizhi Ju, Yifan Yang, Yefeng Zheng, Tieliang Gong, Chen Li, Xianli Zhang | Capital Med Univ, Beijing Chaoyang Hosp, Beijing, Peoples R China; Tencent, Shenzhen, Peoples R China; Tencent Jarvis Lab, Shenzhen, Peoples R China; Xi An Jiao Tong Univ, Xian, Peoples R China |
|  |  [FedCDR: Federated Cross-Domain Recommendation for Privacy-Preserving Rating Prediction](https://doi.org/10.1145/3511808.3557320) |  | 0 | The cold-start problem, faced when providing recommendations to newly joined users with no historical interaction record existing in the platform, is one of the most critical problems that negatively impact the performance of a recommendation system. Fortunately, cross-domain recommendation~(CDR) is a promising approach for solving this problem, which can exploit the knowledge of these users from source domains to provide recommendations in the target domain. However, this method requires that the central server has the interaction behaviour data in both domains of all the users, which prevents users from participating due to privacy issues. In this work, we propose FedCDR, a federated learning based cross-domain recommendation system that effectively trains the recommendation model while keeping users' raw data and private user-specific parameters located on their own devices. Unlike existing CDR models, a personal module and a transfer module are designed to adapt to the extremely heterogeneous data on the participating devices. Specifically, the personal module extracts private user features for each user, while the transfer module is responsible for transferring the knowledge between the two domains. Moreover, in order to provide personalized recommendations with less storage and communication costs while effectively protecting privacy, we design a personalized update strategy for each client and a personalized aggregation strategy for the server. In addition, we conduct comprehensive experiments on the representative Amazon 5-cores datasets for three popular rating prediction tasks to evaluate the effectiveness of FedCDR. The results show that FedCDR outperforms the state-of-the-art methods in mean absolute error (MAE) and root mean squared error (RMSE). For example, in task Movie&Music, FedCDR can effectively improve the performance up to 65.83% and 55.45% on MAE and RMSE, respectively, when the new users are in the movie domain. | Meihan Wu, Li Li, Chang Tao, Eric Rigall, Xiaodong Wang, ChengZhong Xu | Natl Univ Def Technol, Changsha, Peoples R China; Ocean Univ China, Qingdao, Peoples R China; Univ Macau, Taipa, Macau, Peoples R China |
|  |  [Large-scale Entity Alignment via Knowledge Graph Merging, Partitioning and Embedding](https://doi.org/10.1145/3511808.3557374) |  | 0 | Entity alignment is a crucial task in knowledge graph fusion. However, most entity alignment approaches have the scalability problem. Recent methods address this issue by dividing large KGs into small blocks for embedding and alignment learning in each. However, such a partitioning and learning process results in an excessive loss of structure and alignment. Therefore, in this work, we propose a scalable GNN-based entity alignment approach to reduce the structure and alignment loss from three perspectives. First, we propose a centrality-based subgraph generation algorithm to recall some landmark entities serving as the bridges between different subgraphs. Second, we introduce self-supervised entity reconstruction to recover entity representations from incomplete neighborhood subgraphs, and design cross-subgraph negative sampling to incorporate entities from other subgraphs in alignment learning. Third, during the inference process, we merge the embeddings of subgraphs to make a single space for alignment search. Experimental results on the benchmark OpenEA dataset and the proposed large DBpedia1M dataset verify the effectiveness of our approach. | Kexuan Xin, Zequn Sun, Wen Hua, Wei Hu, Jianfeng Qu, Xiaofang Zhou | Univ Queensland, Brisbane, Qld, Australia; Nanjing Univ, Nanjing, Peoples R China; Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; Soochow Univ, Suzhou, Peoples R China |
|  |  [Handling RDF Streams: Harmonizing Subgraph Matching, Adaptive Incremental Maintenance, and Matching-free Updates Together](https://doi.org/10.1145/3511808.3557342) |  | 0 | RDF stream processing (RSP) has become a vibrant area of research in the Semantic Web community. There have been efforts to extend RDF data and SPARQL query for representing streaming information and continuous querying functionalities. However, existing solutions will incur significant low throughput due to the recomputation of the results from scratch as the window slides. In this paper, we propose a novel graph-based framework, referred as IncTree(RDF), towards continuous SPARQL query evaluation over RDF data streams. Under the framework, the RDF data streams are modeled as streaming graphs; the SPARQL queries are translated into graph patterns and evaluated via continuous sub-graph pattern-matching over streaming RDF graphs. IncTree(RDF) employs a query-centric auxiliary data structure called TStore to store some intermediate results, which supports fast incremental maintenance. Based on TStore, we can not only avoid re-computing matches of the query but also prune invalid updates. Besides, we define matching-free update, in which subgraph matching calculation can be avoided under this scenario. Extensive experimental results show that IncTreeRDF significantly outperforms existing competitors. | Qianzhen Zhang, Deke Guo, Xiang Zhao, Lailong Luo | Natl Univ Def Technol, Sci & Technol Informat Syst Engn Lab, Changsha, Peoples R China; Natl Univ Def Technol, Lab Big Data & Decis, Changsha, Peoples R China |
|  |  [GBERT: Pre-training User representations for Ephemeral Group Recommendation](https://doi.org/10.1145/3511808.3557330) |  | 0 | Due to the prevalence of group activities on social networks, group recommendations have received an increasing number of attentions. Most group recommendation methods concentrated on dealing with persistent groups, while little attention has paid to ephemeral groups. Ephemeral groups are formed ad-hoc for one-time activities, and therefore they suffer severely from data sparsity and cold-start problems. To deal with such problems, we propose a pre-training and fine-tuning method called GBERT for improved group recommendations, which employs BERT to enhance the expressivity and capture group-specific preferences of members. In the pre-training stage, GBERT employs three pre-training tasks to alleviate data sparsity and cold-start problem, and learn better user representations. In the fine-tuning stage, an influence-based regulation objective is designed to regulate user and group representations by allocating weights according to each member's influence. Extensive experiments on three public datasets demonstrate its superiority over the state-of-the-art methods for ephemeral group recommendations. | Song Zhang, Nan Zheng, Danli Wang | Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Inst Automat, Beijing, Peoples R China |
|  |  [Debiased Balanced Interleaving at Amazon Search](https://doi.org/10.1145/3511808.3557123) |  | 0 | ABSTRACTInterleaving is an online evaluation technique that has shown to be orders of magnitude more sensitive than traditional A/B tests. It presents users with a single merged result of the compared rankings and then attributes user actions back to the evaluated rankers. Different interleaving methods in the literature have their advantages and limitations with respect to unbiasedness, sensitivity, preservation of user experience, and implementation and computation complexity. We propose a new interleaving method that utilizes a counterfactual evaluation framework for credit attribution while sticking to the simple ranking merge policy of balanced interleaving, and formally derive an unbiased estimator for comparing rankers with theoretical guarantees. We then confirm the effectiveness of our method with both synthetic and real experiments. We also discuss practical considerations of bringing different interleaving methods from the literature into a large-scale experiment, and show that our method achieves a favorable tradeoff in implementation and computation complexity while preserving statistical power and reliability. We have successfully implemented our method and produced consistent conclusions at the scale of billions of search queries. We report 10 online experiments that apply our method to e-commerce search, and observe a 60x sensitivity gain over A/B tests. We also find high correlations between our proposed estimator and corresponding A/B metrics, which helps interpret interleaving results in the magnitude of A/B measurements. | Nan Bi, Pablo Castells, Daniel Gilbert, Slava Galperin, Patrick Tardif, Sachin Ahuja | Amazon, Madrid, Spain; Amazon, Palo Alto, CA, USA |
|  |  [Mitigating Biases in Student Performance Prediction via Attention-Based Personalized Federated Learning](https://doi.org/10.1145/3511808.3557108) |  | 0 | Traditional learning-based approaches to student modeling generalize poorly to underrepresented student groups due to biases in data availability. In this paper, we propose a methodology for predicting student performance from their online learning activities that optimizes inference accuracy over different demographic groups such as race and gender. Building upon recent foundations in federated learning, in our approach, personalized models for individual student subgroups are derived from a global model aggregated across all student models via meta-gradient updates that account for subgroup heterogeneity. To learn better representations of student activity, we augment our approach with a self-supervised behavioral pretraining methodology that leverages multiple modalities of student behavior (e.g., visits to lecture videos and participation on forums), and include a neural network attention mechanism in the model aggregation stage. Through experiments on three real-world datasets from online courses, we demonstrate that our approach obtains substantial improvements over existing student modeling baselines in predicting student learning outcomes for all subgroups. Visual analysis of the resulting student embeddings confirm that our personalization methodology indeed identifies different activity patterns within different subgroups, consistent with its stronger inference ability compared with the baselines. | YunWei Chu, Seyyedali Hosseinalipour, Elizabeth Tenorio, Laura M. Cruz Castro, Kerrie A. Douglas, Andrew S. Lan, Christopher G. Brinton | Purdue Univ, W Lafayette, IN 47907 USA; Univ Massachusetts, Amherst, MA USA |
|  |  [STARDOM: Semantic Aware Deep Hierarchical Forecasting Model for Search Traffic Prediction](https://doi.org/10.1145/3511808.3557102) |  | 0 | We study the search traffic forecasting problem for guaranteed search advertising (GSA) application in e-commerce platforms. The consumers express their purchase intents by posing queries to the e-commerce search engine. GSA is a type of guaranteed delivery (GD) advertising strategy, which forecasts the traffic of search queries, and charges the advertisers according to the predicted volumes of search queries the advertisers willing to buy. We employ the time series forecasting method to make the search traffic prediction. Different from existing time series prediction methods, search queries are semantically meaningful, with semantically similar queries possessing similar time series. And they can be grouped according to the brands or categories they belong to, exhibiting hierarchical structures. To fully take advantage of these characteristics, we design a SemanTic AwaRe Deep hierarchical fOrecasting Model (STARDOM for short) which explores the queries' semantic information and the hierarchical structures formed by the queries. Specifically, to exploit hierarchical structure, we propose a reconciliation learning module. It leverages deep learning model to learn the reconciliation relation between the hierarchical series in the latent space automatically, and forces the coherence constraints through a distill reconciliation loss. To exploit semantic information, we propose a semantic representation module and generate semantic aware series embeddings for queries. Extensive experiments are conducted to confirm the effectiveness of the proposed method. | Yucheng Lu, Qiang Ji, Liang Wang, Tianshu Wu, Hongbo Deng, Jian Xu, Bo Zheng | Alibaba Grp, Beijing, Peoples R China |
|  |  [e-CLIP: Large-Scale Vision-Language Representation Learning in E-commerce](https://doi.org/10.1145/3511808.3557067) |  | 0 | Understanding vision and language representations of product content is vital for search and recommendation applications in e-commerce. As a backbone for online shopping platforms and inspired by the recent success in representation learning research, we propose a contrastive learning framework that aligns language and visual models using unlabeled raw product text and images. We present techniques we used to train large-scale representation learning models and share solutions that address domain-specific challenges. We study the performance using our pre-trained model as backbones for diverse downstream tasks, including category classification, attribute extraction, product matching, product clustering, and adult product recognition. Experimental results show that our proposed method outperforms the baseline in each downstream task regarding both single modality and multiple modalities. | Wonyoung Shin, Jonghun Park, Taekang Woo, Yongwoo Cho, Kwangjin Oh, Hwanjun Song | NAVER AI Res, Seongnam, South Korea; NAVER Shopping, Seongnam, South Korea |
|  |  [KEEP: An Industrial Pre-Training Framework for Online Recommendation via Knowledge Extraction and Plugging](https://doi.org/10.1145/3511808.3557106) |  | 0 | An industrial recommender system generally presents a hybrid list that contains results from multiple subsystems. In practice, each subsystem is optimized with its own feedback data to avoid the disturbance among different subsystems. However, we argue that such data usage may lead to sub-optimal online performance because of the data sparsity. To alleviate this issue, we propose to extract knowledge from the super-domain that contains webscale and long-time impression data, and further assist the online recommendation task (downstream task). To this end, we propose a novel industrial KnowlEdge Extraction and Plugging (KEEP) framework, which is a two-stage framework that consists of 1) a supervised pre-training knowledge extraction module on superdomain, and 2) a plug-in network that incorporates the extracted knowledge into the downstream model. This makes it friendly for incremental training of online recommendation. Moreover, we design an efficient empirical approach for KEEP and introduce our hands-on experience during the implementation of KEEP in a largescale industrial system. Experiments conducted on two real-world datasets demonstrate that KEEP can achieve promising results. It is notable that KEEP has also been deployed on the display advertising system in Alibaba, bringing a lift of +5.4% CTR and +4.7% RPM. | Yujing Zhang, Zhangming Chan, Shuhao Xu, Weijie Bian, Shuguang Han, Hongbo Deng, Bo Zheng | Alibaba Grp, Beijing, Peoples R China; Tsinghua Univ, Sch Software, Beijing, Peoples R China |
|  |  [Towards Edge-Cloud Collaborative Machine Learning: A Quality-aware Task Partition Framework](https://doi.org/10.1145/3511808.3557080) |  | 0 | Edge-cloud collaborative tasks with real-world services emerge in recent years and attract worldwide attention. Unfortunately, state-of-the-art edge-cloud collaborative machine-learning services are still not that reliable due to the data heterogeneity on the edge, where we usually have access to a mixed-up training set, which is intrinsically collected from various distributions of underlying tasks. Finding such hidden tasks that need to be revealed from given datasets is called the Task Partition problem. Manual task partition is usually expensive, unscalable, and biased. Accordingly, we propose Quality-aware Task Partition (QTP) problem, in which final tasks are partitioned by the performance of task models. To the best of our knowledge, this work is the first one to study the QTP problem with an emphasis on task quality. We also implement a public service, HiLens on Huawei Cloud, to support the whole process. We develop a polynomial-time algorithm namely the TaskForest algorithm (TForest). TForest shows its superiority based on a case study with 57 real-world cameras. Compared with STOA baselines, TForest has on average 9.2% higher F1-scores and requires 43.1% fewer samples when deploying new cameras. Partial code of the framework has been adopted and released to KubeEdge-Sedna. | Zimu Zheng, Yunzhe Li, Han Song, Lanjun Wang, Fei Xia | Huawei Cloud, Edge Cloud Innovat Lab, Shenzhen, Peoples R China; Huawei Cloud, Enterprise Intelligence Dev Team, Shenzhen, Peoples R China; Tianjin Univ, Sch New Media & Comm, Tianjin, Peoples R China |
|  |  [Unsupervised Question Clarity Prediction through Retrieved Item Coherency](https://doi.org/10.1145/3511808.3557719) |  | 0 | Despite recent progress on conversational systems, they still do not perform smoothly when faced with ambiguous requests. When questions are unclear, conversational systems should have the ability to ask clarifying questions, rather than assuming a particular interpretation or simply responding that they do not understand. While the research community has paid substantial attention to the problem of predicting query ambiguity in traditional search contexts, researchers have paid relatively little attention to predicting when this ambiguity is sufficient to warrant clarification in the context of conversational systems. In this paper, we propose an unsupervised method for predicting the need for clarification. This method is based on the measured coherency of results from an initial answer retrieval step, under the assumption that a less ambiguous query is more likely to retrieve more coherent results when compared to an ambiguous query. We build a graph from retrieved items based on their context similarity, treating measures of graph connectivity as indicators of ambiguity. We evaluate our approach on two open-domain conversational question answering datasets, ClariQ and AmbigNQ, comparing it with neural and non-neural baselines. Our unsupervised approach performs as well as supervised approaches while providing better generalization. | Negar Arabzadeh, Mahsa Seifikar, Charles L. A. Clarke | Univ Waterloo, Waterloo, ON, Canada |
|  |  [Effective Neural Team Formation via Negative Samples](https://doi.org/10.1145/3511808.3557590) |  | 0 | Forming teams of experts who collectively hold a set of required skills and can successfully cooperate is challenging due to the vast pool of feasible candidates with diverse backgrounds, skills, and personalities. Neural models have been proposed to address scalability while maintaining efficacy by learning the distributions of experts and skills from successful teams in the past in order to recommend future teams. However, such models are prone to overfitting when training data suffers from a long-tailed distribution, i.e., few experts have most of the successful collaborations, and the majority has participated sparingly. In this paper, we present an optimization objective that leverages both successful and virtually unsuccessful teams to overcome the long-tailed distribution problem. We propose three negative sampling heuristics that can be seamlessly employed during the training of neural models. We study the synergistic effects of negative samples on the performance of neural models compared to lack thereof on two large-scale benchmark datasets of computer science publications and movies, respectively. Our experiments show that neural models that take unsuccessful teams (negative samples) into account are more efficient and effective in training and inference, respectively. | Arman Dashti, Saeed Samet, Hossein Fani | Univ Windsor, Windsor, ON, Canada |
|  |  [SpCQL: A Semantic Parsing Dataset for Converting Natural Language into Cypher](https://doi.org/10.1145/3511808.3557703) |  | 0 | The Neo4j query language Cypher enables efficient querying for graphs and has become the most popular graph database language. Due to its complexities, semantic parsing (similar to Text-to-SQL) that translates natural language queries to Cypher becomes highly desirable. We propose the first Text-to-CQL dataset, SpCQL, which contains one Neo4j graph database, 10,000 manually annotated natural language queries and the matching Cypher queries (CQL). Correspondingly, based on this dataset, we define a new semantic parsing task Text-to-CQL. The Text-to-CQL task differs from the traditional Text-to-SQL task due to CQL being more flexible and versatile, especially for schema queries, which brings precedented challenges for the translation process. Although current SOTA Text-to-SQL models utilize SQL schema and contents, they do not scale up to large-scale graph databases. Besides, due to the absence of the primary and foreign keys in Cypher, which are essential for the multi-table Text-to-SQL task, existing Text-to-SQL models are rendered ineffective in this new task and have to be adapted to work. We propose three baselines based on the Seq2Seq framework and conduct experiments on the SpCQL dataset. The experiments yield undesirable results for existing models, hence pressing for subsequent research that considers the characteristics of SQL. The dataset is available at https://github.com/Guoaibo/Text-to-CQL. | Aibo Guo, Xinyi Li, Guanchen Xiao, Zhen Tan, Xiang Zhao | Natl Univ Def Technol, Changsha, Hunan, Peoples R China |
|  |  [Stochastic Optimization of Text Set Generation for Learning Multiple Query Intent Representations](https://doi.org/10.1145/3511808.3557666) |  | 0 | Learning multiple intent representations for queries has potential applications in facet generation, document ranking, search result diversification, and search explanation. The state-of-the-art model for this task assumes that there is a sequence of intent representations. In this paper, we argue that the model should not be penalized as long as it generates an accurate and complete set of intent representations. Based on this intuition, we propose a stochastic permutation invariant approach for optimizing such networks. We extrinsically evaluate the proposed approach on a facet generation task and demonstrate significant improvements compared to competitive baselines. Our analysis shows that the proposed permutation invariant approach has the highest impact on queries with more potential intents. | Helia Hashemi, Hamed Zamani, W. Bruce Croft | Univ Massachusetts, Amherst, MA 01003 USA |
|  |  [Causal Intervention for Sentiment De-biasing in Recommendation](https://doi.org/10.1145/3511808.3557558) |  | 0 | Biases and de-biasing in recommender systems have received increasing attention recently. This study focuses on a newly identified bias, i.e., sentiment bias, which is defined as the divergence in recommendation performance between positive users/items and negative users/items. Existing methods typically employ a regularization strategy to eliminate the bias. However, blindly fitting the data without modifying the training procedure would result in a biased model, sacrificing recommendation performance. In this study, we resolve the sentiment bias with causal reasoning. We develop a causal graph to model the cause-effect relationships in recommender systems, in which the sentiment polarity presented by review text acts as a confounder between user/item representations and observed ratings. The existence of confounders inspires us to go beyond conditional probability and embrace causal inference. To that aim, we use causal intervention in model training to remove the negative effect of sentiment bias. Furthermore, during model inference, we adjust the prediction score to produce personalized recommendations. Extensive experiments on five benchmark datasets validate that the deconfounded training can remove the sentiment bias and the inference adjustment is helpful to improve recommendation accuracy. | Ming He, Xin Chen, Xinlei Hu, Changshu Li | Beijing Univ Technol, Beijing, Peoples R China |
|  |  [Deep Presentation Bias Integrated Framework for CTR Prediction](https://doi.org/10.1145/3511808.3557579) |  | 0 | In online advertising, click-through rate (CTR) prediction typically utilizes click data to train models for estimating the probability of a user clicking on an item. However, the different presentations of an item, including its position and contextual items, etc., will affect the user's attention and lead to different click propensities, thus the presentation bias arises. Most previous works generally consider position bias and pay less attention to overall presentation bias including context. Simultaneously, since the final presentation list is unreachable during online inference, the bias independence assumption is adopted so that the debiased relevance can be directly used for ranking. But this assumption is difficult to hold because the click propensity to the item presentation varies with user intent. Therefore, predicted CTR with personalized click propensity rather than debiased relevance should be closer to real CTR. In this work, we propose a Deep Presentation Bias Integrated Framework (DPBIF). With DPBIF, the presentation block containing item and contextual items on the same screen is introduced into user behavior sequence and predicted target item for personalizing the integration of presentation bias caused by different click propensities into CTR prediction network. While avoiding modeling with the independence assumption, the network is capable of estimating multiple integrated CTRs under different presentations for each item. The multiple CTRs are used to transform the ranking problem into an item-to-position assignment problem so that the Kuhn-Munkres (KM) algorithm is employed to optimize the global benefit of the presentation list. Extensive offline experiments and online A/B tests are performed in a real-world system to demonstrate the effectiveness of the proposed framework. | Jianqiang Huang, Xingyuan Tang, Zhe Wang, Shaolin Jia, Yin Bai, Zhiwei Liu, Jia Cheng, Jun Lei, Yan Zhang | Peking Univ, Beijing, Peoples R China; Meituan, Beijing, Peoples R China |
|  |  [GReS: Graphical Cross-domain Recommendation for Supply Chain Platform](https://doi.org/10.1145/3511808.3557607) |  | 0 | Supply Chain Platforms (SCPs) provide downstream industries with raw materials. Compared with traditional e-commerce platforms, data in SCPs is more sparse due to limited user interests. To tackle the data sparsity problem, one can apply Cross-Domain Recommendation (CDR) to improve the recommendation performance of the target domain with the source domain information. However, applying CDR to SCPs directly ignores hierarchical structures of commodities in SCPs, which reduce recommendation performance. In this paper, we take the catering platform as an example and propose GReS, a graphical CDR model. The model first constructs a tree-shaped graph to represent the hierarchy of different nodes of dishes and ingredients, and then applies our proposed Tree2vec method combining GCN and BERT models to embed the graph for recommendations. Experimental results show that GReS significantly outperforms state-of-the-art methods in CDR for SCPs. | Zhiwen Jing, Ziliang Zhao, Yang Feng, Xiaochen Ma, Nan Wu, Shengqiao Kang, Cheng Yang, Yujia Zhang, Hao Guo | Zhejiang Gongshang Univ, Sch Comp & Informat Engn, Hangzhou, Peoples R China; Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan, Peoples R China; Meituan, Beijing, Peoples R China; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China |
|  |  [Debiasing Neighbor Aggregation for Graph Neural Network in Recommender Systems](https://doi.org/10.1145/3511808.3557576) |  | 0 | Graph neural networks (GNNs) have achieved remarkable success in recommender systems by representing users and items based on their historical interactions. However, little attention was paid to GNN's vulnerability to exposure bias: users are exposed to a limited number of items so that a system only learns a biased view of user preference to result in suboptimal recommendation quality. Although inverse propensity weighting is known to recognize and alleviate exposure bias, it usually works on the final objective with the model outputs, whereas GNN can also be biased during neighbor aggregation. In this paper, we propose a simple but effective approach, neighbor aggregation via inverse propensity (NAVIP) for GNNs. Specifically, given a user-item bipartite graph, we first derive propensity score of each user-item interaction in the graph. Then, inverse of the propensity score with Laplacian normalization is applied to debias neighbor aggregation from exposure bias. We validate the effectiveness of our approach through our extensive experiments on two public and Amazon Alexa datasets where the performance enhances up to 14.2%. | Minseok Kim, Jinoh Oh, Jaeyoung Do, Sungjin Lee | Amazon Alexa AI, Seattle, WA 98121 USA |
|  |  [Music4All-Onion - A Large-Scale Multi-faceted Content-Centric Music Recommendation Dataset](https://doi.org/10.1145/3511808.3557656) |  | 0 | When we appreciate a piece of music, it is most naturally because of its content, including rhythmic, tonal, and timbral elements as well as its lyrics and semantics. This suggests that the human affinity for music is inherently content-driven. This kind of information is, however, still frequently neglected by mainstream recommendation models based on collaborative filtering that rely solely on user-item interactions to recommend items to users. A major reason for this neglect is the lack of standardized datasets that provide both collaborative and content information. The work at hand addresses this shortcoming by introducing Music4All-Onion, a large-scale, multi-modal music dataset. The dataset expands the Music4All dataset by including 26 additional audio, video, and metadata characteristics for 109,269 music pieces. In addition, it provides a set of 252,984,396 listening records of 119,140 users, extracted from the online music platform Last.fm, which allows leveraging user-item interactions as well. We organize distinct item content features in an onion model according to their semantics, and perform a comprehensive examination of the impact of different layers of this model (e.g., audio features, user-generated content, and derivative content) on content-driven music recommendation, demonstrating how various content features influence accuracy, novelty, and fairness of music recommendation systems. In summary, with Music4All-Onion, we seek to bridge the gap between collaborative filtering music recommender systems and content-centric music recommendation requirements. | Marta Moscati, Emilia ParadaCabaleiro, Yashar Deldjoo, Eva Zangerle, Markus Schedl | Univ Innsbruck, Innsbruck, Austria; Johannes Kepler Univ Linz, Linz, Austria; Polytech Univ Bari, Bari, Italy |
|  |  [Measuring and Comparing the Consistency of IR Models for Query Pairs with Similar and Different Information Needs](https://doi.org/10.1145/3511808.3557637) |  | 0 | A widespread use of supervised ranking models has necessitated an investigation on how consistent their outputs align with user expectations. While a match between the user expectations and system outputs can be sought at different levels of granularity, we study this alignment for search intent transformation across a pair of queries. Specifically, we propose a consistency metric, which for a given pair of queries - one reformulated from the other with at least one term in common, measures if the change in the set of the top-retrieved documents induced by this reformulation is as per a user's expectation. Our experiments led to a number of observations, such as DRMM (an early interaction based IR model) exhibits better alignment with set-level user expectations, whereas transformer-based neural models (e.g., MonoBERT) agree more consistently with the content and rank-based expectations of overlap. | Procheta Sen, Sourav Saha, Debasis Ganguly, Manisha Verma, Dwaipayan Roy | Indian Inst Sci Educ & Res, Kolkata, India; Amazon, New York, NY USA; Univ Glasgow, Glasgow, Lanark, Scotland; Univ Liverpool, Liverpool, Merseyside, England; Indian Stat Inst, Kolkata, India |
|  |  [MNCM: Multi-level Network Cascades Model for Multi-Task Learning](https://doi.org/10.1145/3511808.3557644) |  | 0 | Recently, multi-task learning based on the deep neural network has been successfully applied in many recommender system scenarios. The prediction quality of current mainstream multi-task models often relies on the extent to which the relationships among tasks are extracted. Much of the prior research work has focused on two important tasks in recommender systems: predicting click-through rate (CTR) and post-click conversion rate (CVR), which rely on sequential user action pattern of impression → click → conversion. Therefore, there exists sequential dependence between CTR and CVR tasks. However, there is no satisfactory solution to explicitly model the sequential dependence among tasks without sacrificing the first task in terms of the design of the model network structure. In this paper, inspired by the Multi-task Network Cascades (MNC) and Adaptive Information Transfer Multi-task (AITM) frameworks, we propose a Multi-level Network Cascades Model (MNCM) based on the pattern of specific and shared experts separation. In MNCM, we introduce two types of information transfer modules: Task-Level Information Transfer Module (TITM) and Expert-Level Information Transfer Module (EITM), which can learn transferred information adaptively from task level and task-specific experts level, respectively, thereby fully capture sequential dependence among tasks. Compared with AITM, MNCM effectively avoids the problem of the first task in a task sequence becoming the sacrificial side of the seesaw phenomenon and contributes to mitigating potential conflicts among tasks. We conduct considerable experiments based on open-source large-scale recommendation datasets. The experimental results demonstrate that MNCM outperforms AITM and the mainstream baseline models in the mixture-experts-bottom pattern and probability-transfer pattern. In addition, we conduct an ablation study on the necessity of introducing two kinds of information transfer modules and verify the effectiveness of this pattern. | Haotian Wu | Beijing Jiaotong Univ, Beijing, Peoples R China |
|  |  [HQANN: Efficient and Robust Similarity Search for Hybrid Queries with Structured and Unstructured Constraints](https://doi.org/10.1145/3511808.3557610) |  | 0 | The in-memory approximate nearest neighbor search (ANNS) algorithms have achieved great success for fast high-recall query processing, but are extremely inefficient when handling hybrid queries with unstructured (i.e., feature vectors) and structured (i.e., related attributes) constraints. In this paper, we present HQANN, a simple yet highly efficient hybrid query processing framework which can be easily embedded into existing proximity graph-based ANNS algorithms. We guarantee both low latency and high recall by leveraging navigation sense among attributes and fusing vector similarity search with attribute filtering. Experimental results on both public and in-house datasets demonstrate that HQANN is 10x faster than the state-of-the-art hybrid ANNS solutions to reach the same recall quality and its performance is hardly affected by the complexity of attributes. It can reach 99% recall@10 in just around 50 microseconds On GLOVE-1.2M with thousands of attribute constraints. | Wei Wu, Junlin He, Yu Qiao, Guoheng Fu, Li Liu, Jin Yu | Kuaishou Technol, Beijing, Peoples R China |
|  |  [Modeling Latent Autocorrelation for Session-based Recommendation](https://doi.org/10.1145/3511808.3557645) |  | 0 | Session-based Recommendation (SBR) aims to predict the next item for the current session, which consists of several clicked items in a short period by an anonymous user. Most of the sequential modeling approaches to SBR are focusing on adopting advanced Deep Neural Networks (DNNs), and these methods require increasingly longer training times. Existing studies have shown that some traditional SBR methods can outperform some DNN-based sequential models, however, few studies have attempted to investigate the effectiveness of traditional methods in recent years. In this paper, we propose a novel and concise SBR model inspired by the basic concept of autocorrelation in the Stochastic Process. Autocorrelation measures the correlation of a process at different moments. Therefore, it is natural to use it to model the correlation of clicked item sequences at different time shifts. Specifically, we use Fast Fourier Transforms (FFT) to compute the autocorrelation and combine it with several linear transformations to enhance the session representation. By this means, our proposed method can learn better session preferences and is more efficient than most DNN-based models. Extensive experiments on two public datasets show that the proposed method outperforms state-of-the-art models in both effectiveness and efficiency. | Xianghong Xu, Kai Ouyang, Liuyin Wang, Jiaxin Zou, Yanxiong Lu, HaiTao Zheng, HongGee Kim | Tsinghua Univ, Shenzhen Int Grad Sch, Shenzhen, Peoples R China; Seoul Natl Univ, Seoul, South Korea; Tencent, WeChat Search Applicat Dept, Beijing, Peoples R China |
|  |  [Visual Encoding and Debiasing for CTR Prediction](https://doi.org/10.1145/3511808.3557721) |  | 0 | Extracting expressive visual features is crucial for accurate Click-Through-Rate (CTR) prediction in visual search advertising systems. Current commercial systems use off-the-shelf visual encoders to facilitate fast online service. However, the extracted visual features are coarse-grained and/or biased. In this paper, we present a visual encoding framework for CTR prediction to overcome these problems. The framework is based on contrastive learning which pulls positive pairs closer and pushes negative pairs apart in the visual feature space. To obtain fine-grained visual features, we present contrastive learning supervised by click-through data to fine-tune the visual encoder. To reduce sample selection bias, firstly we train the visual encoder offline by leveraging both unbiased self-supervision and click supervision signals. Secondly, we incorporate a debiasing network in the online CTR predictor to adjust the visual features by contrasting high impression items with selected, low impression items. We deploy the framework in a mobile E-commerce app. Offline experiments on billion-scale datasets and online experiments demonstrate that the proposed framework can make accurate and unbiased predictions. | Guipeng Xv, Si Chen, Chen Lin, Wanxian Guan, Xingyuan Bu, Xubin Li, Hongbo Deng, Jian Xu, Bo Zheng | Xiamen Univ, Xiamen, Peoples R China; Alibaba Grp, Hangzhou, Peoples R China |
|  |  [Lightweight Unbiased Multi-teacher Ensemble for Review-based Recommendation](https://doi.org/10.1145/3511808.3557629) |  | 0 | Review-based recommender systems (RRS) have received an increasing interest since reviews greatly enhance recommendation quality and interpretability. However, existing RRS suffer from high computational complexity, biased recommendation and poor generalization. The three problems make them inadequate to handle real recommendation scenarios. Previous studies address each issue separately, while none of them consider solving three problems together under a unified framework. This paper presents LUME (a Lightweight Unbiased Multi-teacher Ensemble) for RRS. LUME is a novel framework that addresses the three problems simultaneously. LUME uses multi-teacher ensemble and debiased knowledge distillation to aggregate knowledge from multiple pretrained RRS, and generates a small, unbiased student recommender which generalizes better. Extensive experiments on various real-world benchmarks demonstrate that LUME successfully tackles the three problems and has superior performance than state-of-the-art RRS and knowledge distillation based RS. | Guipeng Xv, Xinyi Liu, Chen Lin, Hui Li, Chenliang Li, Zhenhua Huang | Wuhan Univ, Sch Cyber Sci & Engn, Wuhan, Peoples R China; Xiamen Univ, Sch Informat, Xiamen, Peoples R China; South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China |
|  |  [The SimIIR 2.0 Framework: User Types, Markov Model-Based Interaction Simulation, and Advanced Query Generation](https://doi.org/10.1145/3511808.3557711) |  | 0 | Simulated user retrieval system interactions enable studies with controlled user behavior. To this end, the SimIIR framework offers static, rule-based methods. We present an extended SimIIR 2.0 version with new components for dynamic user type-specific Markov model-based interactions and more realistic query generation. A flexible modularization ensures that the SimIIR 2.0 framework can serve as a platform to implement, combine, and run the growing number of proposed search behavior and query simulation ideas. | Saber Zerhoudi, Sebastian Günther, Kim Plassmeier, Timo Borst, Christin Seifert, Matthias Hagen, Michael Granitzer | ZBW Leibniz Informat Ctr Econ, Kiel, Germany; Martin Luther Univ Halle Wittenberg, Halle, Germany; Univ Passau, Passau, Germany; Univ Duisburg Essen, Duisburg, Germany |
|  |  [A Hyperbolic-to-Hyperbolic User Representation with Multi-aspect for Social Recommendation](https://doi.org/10.1145/3511808.3557532) |  | 0 | Social recommender systems play a key role in solving the problem of information overload. In order to better extract latent hierarchical property in the data, they usually explore the user-user connections and user-item interactions in hyperbolic space. Existing methods resort tangent spaces to realize some operations (e.g., matrix multiplication) on hyperbolic manifolds. However, frequently projecting between the hyperbolic space and the tangent space will destroy the global structure of the manifold and reduce the accuracy of predictions. Besides, decisions made by users are often influenced by multi-aspect potential preferences, which are usually represented as a vector for each user. To this end, we design a novel hyperbolic-to-hyperbolic user representation with multi-aspect social recommender system, namely H2HMSR, which directly works in hyperbolic space. Extensive experiments on three public datasets demonstrate that our model can adequately extract social information of users with multi-aspect preferences and outperforms hyperbolic and Euclidean counterparts. | Hang Zhang, Hao Wang, Guifeng Wang, Jiayu Liu, Qi Liu | Huawei Technol Co Ltd, Shenzhen, Peoples R China; Univ Sci & Technol China, Anhui Prov Key Lab Big Data Anal & Applicat, Hefei, Peoples R China |
|  |  [SoCRATe: A Recommendation System with Limited-Availability Items](https://doi.org/10.1145/3511808.3557208) |  | 0 | We demonstrate SoCRATe, an online system dedicated to providing adaptive recommendations to users when items have limited availability. SoCRATe is relevant to several real-world applications, among which movie and task recommendations. SoCRATe has several appealing features: (i) watching users as they consume recommendations and accounting for user feedback in refining recommendations in the next round; (ii) implementing loss compensation strategies to make up for sub-optimal recommendations, in terms of accuracy, when items have limited availability; (iii) deciding when to re-generate recommendations on a need-based fashion. SoCRATe accommodates real users as well as simulated users to enable testing multiple recommendation choice models. To frame evaluation, SoCRATe introduces a new set of measures that capture recommendation accuracy, user satisfaction and item consumption over time. All these features make SoCRATe unique and able to adapt recommendations to user preferences in a resource-limited setting. A video of SoCRATe is available at https://youtu.be/4wlaScc_rUo. | Davide Azzalini, Fabio Azzalini, Chiara Criscuolo, Tommaso Dolci, Davide Martinenghi, Sihem AmerYahia | Politecn Milan, Milan, Italy; Univ Grenoble Alpes, CNRS, Grenoble, France |
|  |  [CLEAR: A Fully User-side Image Search System](https://doi.org/10.1145/3511808.3557172) |  | 0 | We use many search engines on the Internet in our daily lives. However, they are not perfect. Their scoring function may not model our intent or they may accept only text queries even though we want to carry out a similar image search. In such cases, we need to make a compromise: We continue to use the unsatisfactory service or leave the service. Recently, a new solution, user-side search systems, has been proposed. In this framework, each user builds their own search system that meets their preference with a user-defined scoring function and user-defined interface. Although the concept is appealing, it is still not clear if this approach is feasible in practice. In this demonstration, we show the first fully user-side image search system, CLEAR, which realizes a similar-image search engine for Flickr. The challenge is that Flickr does not provide an official similar image search engine or corresponding API. Nevertheless, CLEAR realizes it fully on a user-side. CLEAR does not use a backend server at all nor store any images or build search indices. It is in contrast to traditional search algorithms that require preparing a backend server and building a search index. Therefore, each user can easily deploy their own CLEAR engine, and the resulting service is custom-made and privacy-preserving. The online demo is available at https://clear.joisino.net. The source code is available at https://github.com/joisino/clear. | Ryoma Sato | Kyoto Univ, RIKEN AIP, Kyoto, Japan |
|  |  [Shoe Size Resolution in Search Queries and Product Listings using Knowledge Graphs](https://doi.org/10.1145/3511808.3557519) |  | 0 | The Fashion domain is one of the most profitable domains in most of the e-commerce shops, shoes being one of the top-selling categories within this domain. When shopping for shoes, one of the most important aspects for the buyers is the shoe size. Shoe size charts differ between different brands, geographical regions, genders and age groups. Not providing some of these details, as a buyer or a seller, could lead to a query intent to inventory mismatch and reduced or wrong search results. Furthermore, buying the wrong shoe size is one of the top reasons for product returns, which causes shipping delays and loss in revenue. To address this issue, we propose an approach for shoe size resolution and normalization in search queries and product listings using Knowledge Graphs. | Petar Ristoski, Aritra Mandal, Simon Becker, Anu Mandalam, Ethan Hart, Sanjika Hewavitharana, Zhe Wu, Qunzhi Zhou | eBay Inc, San Jose, CA 95125 USA |
|  |  [Fairness of Machine Learning in Search Engines](https://doi.org/10.1145/3511808.3557501) |  | 0 | Fairness has gained increasing importance in a variety of AI and machine learning contexts. As one of the most ubiquitous applications of machine learning, search engines mediate much of the information experiences of members of society. Consequently, understanding and mitigating potential algorithmic unfairness in search have become crucial for both users and systems. In this tutorial, we will introduce the fundamentals of fairness in machine learning, for both supervised learning such as classification and ranking, and unsupervised learning such as clustering. We will then present the existing work on fairness in search engines, including the fairness definitions, evaluation metrics, and taxonomies of methodologies. This tutorial will help orient information retrieval researchers to algorithmic fairness, provide an introduction to the growing literature on this topic, and gathering researchers and practitioners interested in this research direction. | Yi Fang, Hongfu Liu, Zhiqiang Tao, Mikhail Yurochkin | Brandeis Univ, Waltham, MA USA; Santa Clara Univ, Santa Clara, CA 95053 USA; Rochester Inst Technol, Rochester, NY 14623 USA; IBM Res, Cambridge, MA USA |
|  |  [UnCommonSense: Informative Negative Knowledge about Everyday Concepts](https://doi.org/10.1145/3511808.3557484) |  | 0 | Commonsense knowledge about everyday concepts is an important asset for AI applications, such as question answering and chatbots. Recently, we have seen an increasing interest in the construction of structured commonsense knowledge bases (CSKBs). An important part of human commonsense is about properties that do not apply to concepts, yet existing CSKBs only store positive statements. Moreover, since CSKBs operate under the open-world assumption, absent statements are considered to have unknown truth rather than being invalid. This paper presents the UNCOMMONSENSE framework for materializing informative negative commonsense statements. Given a target concept, comparable concepts are identified in the CSKB, for which a local closed-world assumption is postulated. This way, positive statements about comparable concepts that are absent for the target concept become seeds for negative statement candidates. The large set of candidates is then scrutinized, pruned and ranked by informativeness. Intrinsic and extrinsic evaluations show that our method significantly outperforms the state-of-the-art. A large dataset of informative negations is released as a resource for future research. | Hiba Arnaout, Simon Razniewski, Gerhard Weikum, Jeff Z. Pan | Univ Edinburgh, Edinburgh, Midlothian, Scotland; Max Planck Inst Informat, Saarbrucken, Germany |
|  |  [Collaborative Image Understanding](https://doi.org/10.1145/3511808.3557260) |  | 0 | Automatically understanding the contents of an image is a highly relevant problem in practice. In e-commerce and social media settings, for example, a common problem is to automatically categorize user-provided pictures. Nowadays, a standard approach is to fine-tune pre-trained image models with application-specific data. Besides images, organizations however often also collect collaborative signals in the context of their application, in particular how users interacted with the provided online content, e.g., in forms of viewing, rating, or tagging. Such signals are commonly used for item recommendation, typically by deriving latent user and item representations from the data. In this work, we show that such collaborative information can be leveraged to improve the classification process of new images. Specifically, we propose a multitask learning framework, where the auxiliary task is to reconstruct collaborative latent item representations. A series of experiments on datasets from e-commerce and social media demonstrates that considering collaborative signals helps to significantly improve the performance of the main task of image classification by up to 9.1%. | Koby Bibas, Oren Sar Shalom, Dietmar Jannach | Univ Klagenfurt, Klagenfurt, Austria; Amazon, Tel Aviv, Israel; Meta, Tel Aviv, Israel |
|  |  [Task Publication Time Recommendation in Spatial Crowdsourcing](https://doi.org/10.1145/3511808.3557466) |  | 0 | The increasing proliferation of networked and geo-positioned mobile devices brings about increased opportunities for Spatial Crowdsourcing (SC), which aims to enable effective location-based task assignment. We propose and study a novel SC framework, namely Task Assignment with Task Publication Time Recommendation. The framework consists of two phases, task publication time recommendation and task assignment. More specifically, the task publication time recommendation phase hybrids different learning models to recommend the suitable publication time for each task to ensure the timely task assignment and completion while reducing the waiting time of the task requester at the SC platform. We use a cross-graph neural network to learn the representations of task requesters by integrating the obtained representations from two semantic spaces and utilize the self-attention mechanism to learn the representations of task-publishing sequences from multiple perspectives. Then a fully connected layer is used to predict suitable task publication time based on the obtained representations. In the task assignment phase, we propose a greedy and a minimum cost maximum flow algorithm to achieve the efficient and the optimal task assignment, respectively. An extensive empirical study demonstrates the effectiveness and efficiency of our framework. | Xuanlei Chen, Yan Zhao, Kai Zheng | Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China; Aalborg Univ, Aalborg, Denmark |
|  |  [Finding Heterophilic Neighbors via Confidence-based Subgraph Matching for Semi-supervised Node Classification](https://doi.org/10.1145/3511808.3557324) |  | 0 | Graph Neural Networks (GNNs) have proven to be powerful in many graph-based applications. However, they fail to generalize well under heterophilic setups, where neighbor nodes have different labels. To address this challenge, we employ a confidence ratio as a hyper-parameter, assuming that some of the edges are disassortative (heterophilic). Here, we propose a two-phased algorithm. Firstly, we determine edge coefficients through subgraph matching using a supplementary module. Then, we apply GNNs with a modified label propagation mechanism to utilize the edge coefficients effectively. Specifically, our supplementary module identifies a certain proportion of task-irrelevant edges based on a given confidence ratio. Using the remaining edges, we employ the widely used optimal transport to measure the similarity between two nodes with their subgraphs. Finally, using the coefficients as supplementary information on GNNs, we improve the label propagation mechanism which can prevent two nodes with smaller weights from being closer. The experiments on benchmark datasets show that our model alleviates over-smoothing and improves performance. | Yoonhyuk Choi, Jiho Choi, Taewook Ko, Hyungho Byun, ChongKwon Kim | Korea Inst Energy Technol, Naju, South Korea; Seoul Natl Univ, Seoul, South Korea |
|  |  [CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks](https://doi.org/10.1145/3511808.3557271) |  | 0 | Knowledge-intensive language tasks (KILT) usually require a large body of information to provide correct answers. A popular paradigm to solve this problem is to combine a search system with a machine reader, where the former retrieves supporting evidences and the latter examines them to produce answers. Recently, the reader component has witnessed significant advances with the help of large-scale pre-trained generative models. Meanwhile most existing solutions in the search component rely on the traditional "index-retrieve-then-rank" pipeline, which suffers from large memory footprint and difficulty in end-to-end optimization. Inspired by recent efforts in constructing model-based IR models, we propose to replace the traditional multi-step search pipeline with a novel single-step generative model, which can dramatically simplify the search process and be optimized in an end-to-end manner. We show that a strong generative retrieval model can be learned with a set of adequately designed pre-training tasks, and be adopted to improve a variety of downstream KILT tasks with further fine-tuning. We name the pre-trained generative retrieval model as CorpusBrain as all information about the corpus is encoded in its parameters without the need of constructing additional index. Empirical results show that CorpusBrain can significantly outperform strong baselines for the retrieval task on the KILT benchmark and establish new state-of-the-art downstream performances. We also show that CorpusBrain works well under zero- and low-resource settings. | Jiangui Chen, Ruqing Zhang, Jiafeng Guo, Yiqun Liu, Yixing Fan, Xueqi Cheng | Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, Dept CS&T, Beijing, Peoples R China; Univ Chinese Acad Sci, CAS Key Lab Network Data Sci & Technol, ICT, CAS, Beijing, Peoples R China |
|  |  [Learn Basic Skills and Reuse: Modularized Adaptive Neural Architecture Search (MANAS)](https://doi.org/10.1145/3511808.3557385) |  | 0 | Human intelligence is able to first learn some basic skills for solving basic problems and then assemble such basic skills into complex skills for solving complex or new problems. For example, the basic skills "dig hole," "put tree," "backfill" and "watering" compose a complex skill "plant a tree". Besides, some basic skills can be reused for solving other problems. For example, the basic skill "dig hole" not only can be used for planting a tree, but also can be used for mining treasures, building a drain, or landfilling. The ability to learn basic skills and reuse them for various tasks is very important for humans because it helps to avoid learning too many skills for solving each individual task, and makes it possible to solve a compositional number of tasks by learning just a few number of basic skills, which saves a considerable amount of memory and computational power in the human brain. We believe that machine intelligence should also capture the ability of learning basic skills and reusing them by composing into complex skills. In computer science language, each basic skill is a "module", which is a reusable network that has a concrete meaning and performs a concrete basic operation. The modules are assembled into a bigger "model" for doing a more complex task. The assembling procedure is adaptive to the input or task, i.e., for a given task, the modules should be assembled into the most suitable model for solving the given task. As a result, different inputs/tasks could have different assembled models. In this work, we take recommender system as an example and propose Modularized Adaptive Neural Architecture Search (MANAS) to demonstrate the above idea. Neural Architecture Search (NAS) has shown its power in discovering superior neural architectures. However, existing NAS mostly focus on searching for a global architecture regardless of the specific input, i.e., the architecture is not adaptive to the input. In this work, we borrow the idea from modularized neural logic reasoning and consider three basic logical operation modules: AND, OR, NOT. Meanwhile, making recommendations for each user is considered as a task. MANAS automatically assembles the logical operation modules into a network architecture tailored for the given user. As a result, a personalized neural architecture is assembled for each user to make recommendations for the user, which means that the resulting neural architecture is adaptive to the model's input (i.e., the user's past behaviors). Experiments on different datasets show that the adaptive architecture assembled by MANAS outperforms static global architectures. Further experiments and empirical analysis provide insights to the effectiveness of MANAS. The code is open-source at https://github.com/TalonCB/MANAS. | Hanxiong Chen, Yunqi Li, He Zhu, Yongfeng Zhang | Rutgers State Univ, New Brunswick, NJ 08901 USA |
|  |  [SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval](https://doi.org/10.1145/3511808.3557456) |  | 0 | Sparse document representations have been widely used to retrieve relevant documents via exact lexical matching. Owing to the pre-computed inverted index, it supports fast ad-hoc search but incurs the vocabulary mismatch problem. Although recent neural ranking models using pre-trained language models can address this problem, they usually require expensive query inference costs, implying the trade-off between effectiveness and efficiency. Tackling the trade-off, we propose a novel uni-encoder ranking model, Sparse retriever using a Dual document Encoder (SpaDE), learning document representation via the dual encoder. Each encoder plays a central role in (i) adjusting the importance of terms to improve lexical matching and (ii) expanding additional terms to support semantic matching. Furthermore, our co-training strategy trains the dual encoder effectively and avoids unnecessary intervention in training each other. Experimental results on several benchmarks show that SpaDE outperforms existing uni-encoder ranking models. | Eunseong Choi, Sunkyung Lee, Minjin Choi, Hyeseon Ko, YoungIn Song, Jongwuk Lee | Naver Corp, Seoul, South Korea; Sungkyunkwan Univ, Seoul, South Korea |
|  |  [Optimal Action Space Search: An Effective Deep Reinforcement Learning Method for Algorithmic Trading](https://doi.org/10.1145/3511808.3557412) |  | 0 | Algorithmic trading is a crucial yet challenging task in the financial domain, where trading decisions are made sequentially from milliseconds to days based on the historical price movements and trading frequency. To model such a sequential decision making process in the dynamic financial markets, Deep Reinforcement Learning (DRL) based methods have been applied and demonstrated their success in finding trading strategies that achieve profitable returns. However, the financial markets are complex imperfect information games with high-level of noise and uncertainties which usually make the exploration policy of DRL less effective. In this paper, we propose an end-to-end DRL method that explores solutions on the whole graph via a probabilistic dynamic programming algorithm. Specifically, we separate the state into environment state and position state, and model the position state transition as a directed acyclic graph. To obtain reliable gradients for model training, we adopt a probabilistic dynamic programming algorithm to explore solutions over the whole graph instead of sampling a path. By avoiding the sampling procedure, we propose an efficient training algorithm and overcome the efficiency problem in most existing DRL methods. Furthermore, our method is compatible with most recurrent neural network architecture, which makes our method easy to implement and very effective in practice. Extensive experiments have been conducted on two real-world stock datasets. Experimental results demonstrate that our method can generate stable trading strategies for both high-frequency and low-frequency trading, significantly outperforming the baseline DRL methods on annualized return and Sharpe ratio. | Zhongjie Duan, Cen Chen, Dawei Cheng, Yuqi Liang, Weining Qian | Tongji Univ, Shanghai, Peoples R China; East China Normal Univ, Shanghai, Peoples R China; Emoney Inc, Seek Data Grp, Shanghai, Peoples R China |
|  |  [GDOD: Effective Gradient Descent using Orthogonal Decomposition for Multi-Task Learning](https://doi.org/10.1145/3511808.3557333) |  | 0 | Multi-task learning (MTL) aims at solving multiple related tasks simultaneously and has experienced rapid growth in recent years. However, MTL models often suffer from performance degeneration with negative transfer due to learning several tasks simultaneously. Some related work attributed the source of the problem is the conflicting gradients. In this case, it is needed to select useful gradient updates for all tasks carefully. To this end, we propose a novel optimization approach for MTL, named GDOD, which manipulates gradients of each task using an orthogonal basis decomposed from the span of all task gradients. GDOD decomposes gradients into task-shared and task-conflict components explicitly and adopts a general update rule for avoiding interference across all task gradients. This allows guiding the update directions depending on the task-shared components. Moreover, we prove the convergence of GDOD theoretically under both convex and non-convex assumptions. Experiment results on several multi-task datasets not only demonstrate the significant improvement of GDOD performed to existing MTL models but also prove that our algorithm outperforms state-of-the-art optimization methods in terms of AUC and Logloss metrics. | Xin Dong, Ruize Wu, Chao Xiong, Hai Li, Lei Cheng, Yong He, Shiyou Qian, Jian Cao, Linjian Mo | Shanghai Jiao Tong Univ, Shanghai, Peoples R China; Ant Grp, Shanghai, Peoples R China; Ant Grp, Hangzhou, Peoples R China |
|  |  [Detecting Significant Differences Between Information Retrieval Systems via Generalized Linear Models](https://doi.org/10.1145/3511808.3557286) |  | 0 | Being able to compare Information Retrieval (IR) systems correctly is pivotal to improving their quality. Among the most popular tools for statistical significance testing, we list t-test and ANOVA that belong to the linear models family. Therefore, given the relevance of linear models for IR evaluation, a great effort has been devoted to studying how to improve them to better compare IR systems. Linear models rely on assumptions that IR experimental observations rarely meet, e.g. about the normality of the data or the linearity itself. Even though linear models are, in general, resilient to violations of their assumptions, departing from them might reduce the effectiveness of the tests. Hence, we investigate the use of the Generalized Linear Model (GLM) framework, a generalization of the traditional linear modelling that relaxes assumptions about the distribution and the shape of the models. To the best of our knowledge, there has been little or no investigation on the use of GLMs for comparing IR system performance. We discuss how GLMs work and how they can be applied in the context of IR evaluation. In particular, we focus on the link function used to build GLMs, which allows for the model to have non-linear shapes. We conduct a thorough experimentation using two TREC collections and several evaluation measures. Overall, we show how the log and logit links are able to identify more and more consistent significant differences (up to 25% more with 50 topics) than the identity link used today and with a comparable, or slightly better, risk of publication bias. | Guglielmo Faggioli, Nicola Ferro, Norbert Fuhr | Univ Duisburg Essen, Essen, Germany; Univ Padua, Padua, Italy |
|  |  [GraTO: Graph Neural Network Framework Tackling Over-smoothing with Neural Architecture Search](https://doi.org/10.1145/3511808.3557337) |  | 0 | Current Graph Neural Networks (GNNs) suffer from the over-smoothing problem, which results in indistinguishable node representations and low model performance with more GNN layers. Many methods have been put forward to tackle this problem in recent years. However, existing tackling over-smoothing methods emphasize model performance and neglect the over-smoothness of node representations. Additional, different approaches are applied one at a time, while there lacks an overall framework to jointly leverage multiple solutions to the over-smoothing challenge. To solve these problems, we propose GraTO, a framework based on neural architecture search to automatically search for GNNs architecture. GraTO adopts a novel loss function to facilitate striking a balance between model performance and representation smoothness. In addition to existing methods, our search space also includes DropAttribute, a novel scheme for alleviating the over-smoothing challenge, to fully leverage diverse solutions. We conduct extensive experiments on six real-world datasets to evaluate GraTo, which demonstrates that GraTo outperforms baselines in the over-smoothing metrics and achieves competitive performance in accuracy. GraTO is especially effective and robust with increasing numbers of GNN layers. Further experiments bear out the quality of node representations learned with GraTO and the effectiveness of model architecture. We make the code of GraTo available at Github (https://github.com/fxsxjtu/GraTO). | Xinshun Feng, Herun Wan, Shangbin Feng, Hongrui Wang, Qinghua Zheng, Jun Zhou, Minnan Luo | Xi An Jiao Tong Univ, Xian, Shaanxi, Peoples R China; Ant Grp, Xian, Shaanxi, Peoples R China; Univ Washington, Seattle, WA USA |
|  |  [KuaiRec: A Fully-observed Dataset and Insights for Evaluating Recommender Systems](https://doi.org/10.1145/3511808.3557220) |  | 0 | The progress of recommender systems is hampered mainly by evaluation as it requires real-time interactions between humans and systems, which is too laborious and expensive. This issue is usually approached by utilizing the interaction history to conduct offline evaluation. However, existing datasets of user-item interactions are partially observed, leaving it unclear how and to what extent the missing interactions will influence the evaluation. To answer this question, we collect a fully-observed dataset from Kuaishou's online environment, where almost all 1,411 users have been exposed to all 3,327 items. To the best of our knowledge, this is the first real-world fully-observed data with millions of user-item interactions. With this unique dataset, we conduct a preliminary analysis of how the two factors - data density and exposure bias - affect the evaluation results of multi-round conversational recommendation. Our main discoveries are that the performance ranking of different methods varies with the two factors, and this effect can only be alleviated in certain cases by estimating missing interactions for user simulation. This demonstrates the necessity of the fully-observed dataset. We release the dataset and the pipeline implementation for evaluation at https://kuairec.com | Chongming Gao, Shijun Li, Wenqiang Lei, Jiawei Chen, Biao Li, Peng Jiang, Xiangnan He, Jiaxin Mao, TatSeng Chua | Univ Sci & Technol China, Hefei, Anhui, Peoples R China; Natl Univ Singapore, Singapore, Singapore; Sichuan Univ, Chengdu, Sichuan, Peoples R China; Renmin Univ China, Beijing, Peoples R China; Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China; Kuaishou Technol Co Ltd, Beijing, Peoples R China |
|  |  [An Uncertainty-Aware Imputation Framework for Alleviating the Sparsity Problem in Collaborative Filtering](https://doi.org/10.1145/3511808.3557236) |  | 0 | Collaborative Filtering (CF) methods for recommender systems commonly suffer from the data sparsity issue. Data imputation has been widely adopted to deal with this issue. However, existing studies have limitations in the sense that both uncertainty and robustness of imputation have not been taken into account, where there is a high risk that the imputed values are likely to be far from the true values. This paper explores a novel imputation framework, named Uncertainty-Aware Multiple Imputation (UA-MI), which can effectively solve the sparsity issue. Given a (sparse) user-item interaction matrix, our key idea is to quantify uncertainty on each missing entry and then the cells with the lowest uncertainty are selectively imputed. Here, we suggest three strategies for measuring uncertainty in missing user-item interactions, each of which is based on sampling, dropout, and ensemble, respectively. They successfully obtain element-wise mean and variance on the missing entries, where the variance helps determine where in the matrix should be imputed and the corresponding mean values are imputed. Experiments show that our UA-MI framework significantly outperformed the existing imputation strategies. | Sunghyun Hwang, DongKyu Chae | Hanyang Univ, Dept Artificial Intelligence, Seoul, South Korea |
|  |  [Accurate Action Recommendation for Smart Home via Two-Level Encoders and Commonsense Knowledge](https://doi.org/10.1145/3511808.3557226) |  | 0 | How can we accurately recommend actions for users to control their devices at home? Action recommendation for smart home has attracted increasing attention due to its potential impact on the markets of Internet of Things (IoT). However, designing an effective action recommender system is challenging because it requires handling context correlations, considering both queried contexts and previous histories of users, and dealing with capricious intentions in history. In this work, we propose SmartSense, an accurate action recommendation method for smart home. For individual action, SmartSense summarizes its device control and temporal contexts in a self-attentive manner, to reflect the importance of the correlation between them. SmartSense then summarizes sequences considering queried contexts in a query-attentive manner to extract the query-related patterns from the sequential actions. SmartSense also transfers the commonsense knowledge from routine data to better handle intentions in action sequences. As a result, SmartSense addresses all three main challenges of action recommendation for smart home, and achieves the state-of-the-art performance giving up to 9.8% higher mAP@1 than the best competitor. | Hyunsik Jeon, Jongjin Kim, Hoyoung Yoon, Jaeri Lee, U Kang | Seoul Natl Univ, Seoul, South Korea |
|  |  [Extracting Drug-drug Interactions from Biomedical Texts using Knowledge Graph Embeddings and Multi-focal Loss](https://doi.org/10.1145/3511808.3557318) |  | 0 | The field of Drug-drug interaction (DDI) aims to detect descriptions of interactions between drugs from biomedical texts. Currently, researchers have extracted DDIs using pre-trained language models such as BERT, which often misclassify two kinds of DDI types, "Effect" and "Int", on the DDIExtraction 2013 corpus because of highly similar expressions. The use of knowledge graphs can alleviate this problem by incorporating different relationships for each, thus allowing them to be distinguished. Thus, we propose a novel framework to integrate the neural network with a knowledge graph, where the features from these components are complementary. Specifically, we take text features at different levels into account in the neural network part. This is done by firstly obtaining a word-level position feature using PubMedBERT together with a convolution neural network, secondly, getting a phrase-level key path feature using a dependency parsing tree, thirdly, using PubMedBERT with an attention mechanism to obtain a sentence-level language feature, and finally, fusing these three kinds of representation into a synthesized feature. We also extract a knowledge feature from a drug knowledge graph which takes just a few minutes to construct, then concatenate the synthesized feature with the knowledge feature, feed the result into a multi-layer perceptron and obtain the result by a softmax classifier. In order to achieve a good integration of the synthesized feature and the knowledge feature, we train the model using a novel multifocal loss function, KGE-MFL, which is based on a knowledge graph embedding. Finally we attain state-of-the-art results on the DDIExtraction 2013 dataset (micro F-score 86.24%) and on the ChemProt dataset (micro F-score 77.75%), which proves our framework to be effective for biomedical relation extraction tasks. In particular, we fill the performance gap (more than 5.57%) between methods that rely on and do not rely on knowledge graph embedding on the DDIExtraction 2013 corpus, when predicting the "Int" type. The implementation code is available at https://github.com/NWU-IPMI/DDIE-KGE-MFL. | Xin Jin, Xia Sun, Jiacheng Chen, Richard F. E. Sutcliffe | Northwest Univ, Sch Informat Sci & Technol, Xian, Shaanxi, Peoples R China |
|  |  [Efficient Optimization of Dominant Set Clustering with Frank-Wolfe Algorithms](https://doi.org/10.1145/3511808.3557306) |  | 0 | We study Frank-Wolfe algorithms - standard, pairwise, and away-steps - for efficient optimization of Dominant Set Clustering. We present a unified and computationally efficient framework to employ the different variants of Frank-Wolfe methods, and we investigate its effectiveness via several experimental studies. In addition, we provide explicit convergence rates for the algorithms in terms of the so-called Frank-Wolfe gap. The theoretical analysis has been specialized to Dominant Set Clustering and covers consistently the different variants. | Carl Johnell, Morteza Haghir Chehreghani | Chalmers Univ Technol, Dept Comp Sci & Engn, Gothenburg, Sweden |
|  |  [Contrastive Representation Learning for Conversational Question Answering over Knowledge Graphs](https://doi.org/10.1145/3511808.3557267) |  | 0 | This paper addresses the task of conversational question answering (ConvQA) over knowledge graphs (KGs). The majority of existing ConvQA methods rely on full supervision signals with a strict assumption of the availability of gold logical forms of queries to extract answers from the KG. However, creating such a gold logical form is not viable for each potential question in a real-world scenario. Hence, in the case of missing gold logical forms, the existing information retrieval-based approaches use weak supervision via heuristics or reinforcement learning, formulating ConvQA as a KG path ranking problem. Despite missing gold logical forms, an abundance of conversational contexts, such as entire dialog history with fluent responses and domain information, can be incorporated to effectively reach the correct KG path. This work proposes a contrastive representation learning-based approach to rank KG paths effectively. Our approach solves two key challenges. Firstly, it allows weak supervision-based learning that omits the necessity of gold annotations. Second, it incorporates the conversational context (entire dialog history and domain information) to jointly learn its homogeneous representation with KG paths to improve contrastive representations for effective path ranking. We evaluate our approach on standard datasets for ConvQA, on which it significantly outperforms existing baselines on all domains and overall. Specifically, in some cases, the Mean Reciprocal Rank (MRR) and Hit@5 ranking metrics improve by absolute 10 and 18 points, respectively, compared to the state-of-the-art performance. | Endri Kacupaj, Kuldeep Singh, Maria Maleshkova, Jens Lehmann | Zerotha Res & Cerence GmbH, Aachen, Germany; Amazon, Seattle, WA USA; Univ Siegen, Siegen, Germany; Univ Bonn, Bonn, Germany |
|  |  [MARIO: Modality-Aware Attention and Modality-Preserving Decoders for Multimedia Recommendation](https://doi.org/10.1145/3511808.3557387) |  | 0 | ABSTRACTWe address the multimedia recommendation problem, which utilizes items' multimodal features, such as visual and textual modalities, in addition to interaction information. While a number of existing multimedia recommender systems have been developed for this problem, we point out that none of these methods individually capture the influence of each modality at the interaction level. More importantly, we experimentally observe that the learning procedures of existing works fail to preserve the intrinsic modality-specific properties of items. To address above limitations, we propose an accurate multimedia recommendation framework, named MARIO, based on modality-aware attention and modality-preserving decoders. MARIO predicts users' preferences by considering the individual influence of each modality on each interaction while obtaining item embeddings that preserve the intrinsic modality-specific properties. The experiments on four real-life datasets demonstrate that MARIO consistently and significantly outperforms seven competitors in terms of the recommendation accuracy: MARIO yields up to 14.61% higher accuracy, compared to the best competitor. | Taeri Kim, YeonChang Lee, Kijung Shin, SangWook Kim | Hanyang University, Seoul, Republic of Korea; KAIST, Seoul, Republic of Korea |
|  |  [Maximum Norm Minimization: A Single-Policy Multi-Objective Reinforcement Learning to Expansion of the Pareto Front](https://doi.org/10.1145/3511808.3557389) |  | 0 | In this paper, we propose Maximum Norm Minimization (MNM), a single-policy Multi-Objective Reinforcement Learning (MORL) algorithm to solve the multi-objective RL problem. The main objective of ourMNMis to provide the Pareto optimal points constituting the Pareto front in the multi-objective space. First, MNM measures distances among the Pareto optimal points in the current Pareto front and then normalizes the distances based on maximum and minimum reward values for each objective in the multi-objective space. Second, MNM identifies the maximum norm, i.e., the maximum value of the normalized Pareto optimal distances. Then MNM seeks to find a new Pareto optimal point, which corresponds to the middle of the two Pareto optimal points constituting the maximum norm. By iterating these two processes, MNM is able to expand and densify the Pareto front with increasing summation of the Pareto front volumes and decreasing mean-squared distance of the Pareto optimal points. To validate the performance of MNM, we provide the experimental results of five complex robotic multi-objective environments. In particular, we compare the performance of MNM with those of other state-of-the-art methods in terms of the summation of volumes and the mean-squared distance of the Pareto optimal points. | Seonjae Lee, MyoungHoon Lee, Jun Moon | Hanyang Univ, Dept Artificial Intelligence, Seoul, South Korea; Hanyang Univ, Res Inst Elect & Comp Engn, Seoul, South Korea |
|  |  [MDGCF: Multi-Dependency Graph Collaborative Filtering with Neighborhood- and Homogeneous-level Dependencies](https://doi.org/10.1145/3511808.3557390) |  | 0 | Due to the success of graph convolutional networks (GCNs) in effectively extracting features in non-Euclidean spaces, GCNs has become the rising star in implicit collaborative filtering. Existing works, while encouraging, typically adopt simple aggregation operation on the user-item bipartite graph to model user and item representations, but neglect to mine the sufficient dependencies between nodes, e.g., the relationships between users/items and their neighbors (or congeners), resulting in inadequate graph representation learning. To address these problems, we propose a novel Multi-Dependency Graph Collaborative Filtering (MDGCF) model, which mines the neighborhood- and homogeneous-level dependencies to enhance the representation power of graph-based CF models. Specifically, for neighborhood-level dependencies, we explicitly consider both popularity score and preference correlation by designing a joint neighborhood-level dependency weight, based on which we construct a neighborhood-level dependencies graph to capture higher-order interaction features. Besides, by adaptively mining the homogeneous-level dependencies among users and items, we construct two homogeneous graphs, based on which we further aggregate features from homogeneous users and items to supplement their representations, respectively. Extensive experiments on three real-world benchmark datasets demonstrate the effectiveness of the proposed MDGCF. Further experiments reveal that our model can capture rich dependencies between nodes for explaining user behaviors. | Guohui Li, Zhiqiang Guo, Jianjun Li, Chaoyang Wang | Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China; Huazhong Univ Sci & Technol, Sch Software Engn, Wuhan, Peoples R China |
|  |  [CoPatE: A Novel Contrastive Learning Framework for Patent Embeddings](https://doi.org/10.1145/3511808.3557270) |  | 0 | Patents are legal rights issued to inventors to protect their inventions for a certain period and play an important role in today's artificial innovation. With the ever-increasing number of patents each year, an effective and efficient patent management and search system is indispensable for determining how different an invention is from prior works from the vast amount of patent data. However, the chnologists are using now is still based on the strategy of traditional keyword-based Boolean, which requires complex bool expressions. This type of strategy leads to poor performance and costs too much labor power to filter in post-processing. To address these issues, we proposed CoPatE: a novel Contrastive Learning Framework for Patent Embeddings to capture the high-level semantics of the large-scale patents, where a patent semantic compression module learns the informative claims to reduce the computational complexity, and a tags auxiliary learning module is to enhance the semantics of a patent from the structure to learn the high-quality patent embeddings. The CoPatE is trained with the patents from USPTO from 2013 to 2020 and tested by the patents from 2021 with the CPC scheme. The experimental results demonstrate that our model achieves a 17.7% increase at Recall@100 compared to the second-best method on the patent retrieval task and achieves 64.5% at Micro-F1 in the patent classification task. | Huahang Li, Shuangyin Li, Yuncheng Jiang, Gansen Zhao | South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China |
|  |  [Dynamic Network Embedding via Temporal Path Adjacency Matrix Factorization](https://doi.org/10.1145/3511808.3557302) |  | 0 | Network embedding has been widely investigated to learn low dimensional nodes representation of networks, and serves for many downstream machine learning tasks. Previous network embedding studies mainly focus on static networks, and cannot adapt well to the characteristics of dynamic networks which are evolving over time. Some works on dynamic network embedding have tried to improve the computation efficiency for incremental updates of embedding vectors, while others have made efforts to utilize temporal information to enhance the quality of embedding vectors. However, few existing works can fulfill both efficiency and quality requirements. In this article, a novel dynamic network embedding model named TPANE (Temporal Path Adjacency Matrix based Network Embedding) is proposed. It employs a new network proximity measure: Temporal Path Adjacency, which is capable of capturing the temporal dependency between edges as well as being incrementally computed in an efficient way. It evaluates the similarity between nodes via the count of temporal paths between them, rather than making random sampling approximation, and adopts matrix factorization to obtain embedding vectors. Link prediction experiments on various real-world dynamic networks have been conducted to show the superior performance of TPANE against other state-of-the-art methods. Time consumption analysis also shows that TPANE is more efficient in incremental updates. | Zhuoming Li, Darong Lai | Southeast Univ, Nanjing, Peoples R China; Southeast University, Nanjing, China |
|  |  [Scattered or Connected? An Optimized Parameter-efficient Tuning Approach for Information Retrieval](https://doi.org/10.1145/3511808.3557445) |  | 0 | Pre-training and fine-tuning have achieved significant advances in the information retrieval (IR). A typical approach is to fine-tune all the parameters of large-scale pre-trained models (PTMs) on downstream tasks. As the model size and the number of tasks increase greatly, such approach becomes less feasible and prohibitively expensive. Recently, a variety of parameter-efficient tuning methods have been proposed in natural language processing (NLP) that only fine-tune a small number of parameters while still attaining strong performance. Yet there has been little effort to explore parameter-efficient tuning for IR. In this work, we first conduct a comprehensive study of existing parameter-efficient tuning methods at both the retrieval and re-ranking stages. Unlike the promising results in NLP, we find that these methods cannot achieve comparable performance to full fine-tuning at both stages when updating less than 1% of the original model parameters. More importantly, we find that the existing methods are just parameter-efficient, but not learning-efficient as they suffer from unstable training and slow convergence. To analyze the underlying reason, we conduct a theoretical analysis and show that the separation of the inserted trainable modules makes the optimization difficult. To alleviate this issue, we propose to inject additional modules alongside the pre-trained models (PTMs) to make the original scattered modules connected. In this way, all the trainable modules can form a pathway to smooth the loss surface and thus help stabilize the training process. Experiments at both retrieval and re-ranking stages show that our method outperforms existing parameter-efficient methods significantly, and achieves comparable or even better performance over full fine-tuning. | Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, Xueqi Cheng | Univ Chinese Acad Sci, CAS Key Lab Network Data Sci & Technol, ICT, CAS, Beijing, Peoples R China |
|  |  [Adaptive Re-Ranking with a Corpus Graph](https://doi.org/10.1145/3511808.3557231) |  | 0 | Search systems often employ a re-ranking pipeline, wherein documents (or passages) from an initial pool of candidates are assigned new ranking scores. The process enables the use of highly-effective but expensive scoring functions that are not suitable for use directly in structures like inverted indices or approximate nearest neighbour indices. However, re-ranking pipelines are inherently limited by the recall of the initial candidate pool; documents that are not identified as candidates for re-ranking by the initial retrieval function cannot be identified. We propose a novel approach for overcoming the recall limitation based on the well-established clustering hypothesis. Throughout the re-ranking process, our approach adds documents to the pool that are most similar to the highest-scoring documents up to that point. This feedback process adapts the pool of candidates to those that may also yield high ranking scores, even if they were not present in the initial pool. It can also increase the score of documents that appear deeper in the pool that would have otherwise been skipped due to a limited re-ranking budget. We find that our Graph-based Adaptive Re-ranking (GAR) approach significantly improves the performance of re-ranking pipelines in terms of precision- and recall-oriented measures, is complementary to a variety of existing techniques (e.g., dense retrieval), is robust to its hyperparameters, and contributes minimally to computational and storage costs. For instance, on the MS MARCO passage ranking dataset, GAR can improve the nDCG of a BM25 candidate pool by up to 8% when applying a monoT5 ranker. | Sean MacAvaney, Nicola Tonellotto, Craig Macdonald | Univ Pisa, Pisa, Italy; Univ Glasgow, Glasgow, Lanark, Scotland |
|  |  [Network Aware Forecasting for eCommerce Supply Planning](https://doi.org/10.1145/3511808.3557408) |  | 0 | A real world supply chain planning starts with the demand forecasting as a key input. In most scenarios, especially in fields like e-commerce where demand patterns are complex and are large scale, demand forecasting is done independent of supply chain constraints. There have been a plethora of methods, old and recent, for generating accurate forecasts. However, to the best of our knowledge, none of the methods take supply chain constraints into account during forecasting. In this paper, we are primarily interested in supply chain aware forecasting methods that does not impose any restrictions on demand forecasting process. We assume that the base forecasts follow a distribution from exponential family and are provided as input to supply chain planning by specifying the distribution form and parameters. With this in mind, following are the contributions of our paper. First, we formulate the supply chain aware forecast improvement of a base forecast as finding the game theoretically optimal parameters satisfying the supply chain constraints. Second, for regular distributions from exponential family, we show that this translates to projecting base forecast onto the (convex) set defined by supply constraints, which is at least as accurate as the base forecasts. Third, we note that using off the shelf convex solvers does not scale for large instances of supply chain, which is typical in e-commerce settings. We propose algorithms that scale better with problem size. We propose a general gradient descent based approach that works across different distributions from exponential family. We also propose a network flow based exact algorithm for Laplace distribution (which relates to mean absolute error, which is the most commonly used metric in forecasting). Finally, we substantiate the theoretical results with extensive experiments on a real life e-commerce data set as well as a range of synthetic data sets. | K. V. M. Naidu, Praveen Gupta, Vaishnavi Gujjula | Flipkart, Bengaluru, India; Indian Inst Technol Madras, Chennai, Tamil Nadu, India |
|  |  [Automatic Meta-Path Discovery for Effective Graph-Based Recommendation](https://doi.org/10.1145/3511808.3557244) |  | 0 | Heterogeneous Information Networks (HINs) are labeled graphs that depict relationships among different types of entities (e.g., users, movies and directors). For HINs, meta-path-based recommenders (MPRs) utilize meta-paths (i.e., abstract paths consisting of node and link types) to predict user preference, and have attracted a lot of attention due to their explainability and performance. We observe that the performance of MPRs is highly sensitive to the meta-paths they use, but existing works manually select the meta-paths from many possible ones. Thus, to discover effective meta-paths automatically, we propose the Reinforcement learning-based Meta-path Selection (RMS) framework. Specifically, we define a vector encoding for meta-paths and design a policy network to extend meta-paths. The policy network is trained based on the results of downstream recommendation tasks and an early stopping approximation strategy is proposed to speed up training. (RMS) is a general model, and it can work with all existing MPRs. We also propose a new MPR called RMS-HRec, which uses an attention mechanism to aggregate information from the meta-paths. We conduct extensive experiments on real datasets. Compared with the manually selected meta-paths, the meta-paths identified by (RMS) consistently improve recommendation quality. Moreover, RMS-HRec outperforms state-of-the-art recommender systems by an average of 7% in hit ratio. The codes and datasets are available on https://github.com/Stevenn9981/RMS-HRec. | Wentao Ning, Reynold Cheng, Jiajun Shen, Nur Al Hasan Haldar, Ben Kao, Xiao Yan, Nan Huo, Wai Kit Lam, Tian Li, Bo Tang | Southern Univ Sci & Technol, Shenzhen, Peoples R China; Univ Western Australia, Perth, Australia; TCL Res, Hong Kong, Peoples R China; Univ Hong Kong, Hong Kong, Peoples R China |
|  |  [SVD-GCN: A Simplified Graph Convolution Paradigm for Recommendation](https://doi.org/10.1145/3511808.3557462) |  | 0 | With the tremendous success of Graph Convolutional Networks (GCNs), they have been widely applied to recommender systems and have shown promising performance. However, most GCN-based methods rigorously stick to a common GCN learning paradigm and suffer from two limitations: (1) the limited scalability due to the high computational cost and slow training convergence; (2) the notorious over-smoothing issue which reduces performance as stacking graph convolution layers. We argue that the above limitations are due to the lack of a deep understanding of GCN-based methods. To this end, we first investigate what design makes GCN effective for recommendation. By simplifying LightGCN, we show the close connection between GCN-based and low-rank methods such as Singular Value Decomposition (SVD) and Matrix Factorization (MF), where stacking graph convolution layers is to learn a low-rank representation by emphasizing (suppressing) components with larger (smaller) singular values. Based on this observation, we replace the core design of GCN-based methods with a flexible truncated SVD and propose a simplified GCN learning paradigm dubbed SVD-GCN, which only exploits K -largest singular vectors for recommendation. To alleviate the over-smoothing issue, we propose a renormalization trick to adjust the singular value gap, resulting in significant improvement. Extensive experiments on three real-world datasets show that our proposed SVD-GCN not only significantly outperforms state-of-the-arts but also achieves over 100x and 10x speedups over LightGCN and MF, respectively. | Shaowen Peng, Kazunari Sugiyama, Tsunenori Mine | Kyushu Univ, Fukuoka, Japan; Kyoto Univ, Kyoto, Japan |
|  |  [PLAID: An Efficient Engine for Late Interaction Retrieval](https://doi.org/10.1145/3511808.3557325) |  | 0 | Pre-trained language models are increasingly important components across multiple information retrieval (IR) paradigms. Late interaction, introduced with the ColBERT model and recently refined in ColBERTv2, is a popular paradigm that holds state-of-the-art status across many benchmarks. To dramatically speed up the search latency of late interaction, we introduce the Performance-optimized Late Interaction Driver (PLAID) engine. Without impacting quality, PLAID swiftly eliminates low-scoring passages using a novel centroid interaction mechanism that treats every passage as a lightweight bag of centroids. PLAID uses centroid interaction as well as centroid pruning, a mechanism for sparsifying the bag of centroids, within a highly-optimized engine to reduce late interaction search latency by up to 7x on a GPU and 45x on a CPU against vanilla ColBERTv2, while continuing to deliver state-of-the-art retrieval quality. This allows the PLAID engine with ColBERTv2 to achieve latency of tens of milliseconds on a GPU and tens or just few hundreds of milliseconds on a CPU at large scale, even at the largest scales we evaluate with 140M passages. | Keshav Santhanam, Omar Khattab, Christopher Potts, Matei Zaharia | Stanford Univ, Stanford, CA 94305 USA |
|  |  [Personalizing Task-oriented Dialog Systems via Zero-shot Generalizable Reward Function](https://doi.org/10.1145/3511808.3557417) |  | 0 | Task-oriented dialog systems enable users to accomplish tasks using natural language. State-of-the-art systems respond to users in the same way regardless of their personalities, although personalizing dialogues can lead to higher levels of adoption and better user experiences. Building personalized dialog systems is an important, yet challenging endeavor, and only a handful of works took on the challenge. Most existing works rely on supervised learning approaches and require laborious and expensive labeled training data for each user profile. Additionally, collecting and labeling data for each user profile is virtually impossible. In this work, we propose a novel framework, P-ToD, to personalize task-oriented dialog systems capable of adapting to a wide range of user profiles in an unsupervised fashion using a zero-shot generalizable reward function. P-ToD uses a pre-trained GPT-2 as a backbone model and works in three phases. Phase one performs task-specific training. Phase two kicks off unsupervised personalization by leveraging the proximal policy optimization algorithm that performs policy gradients guided by the zero-shot generalizable reward function. Our novel reward function can quantify the quality of the generated responses even for unseen profiles. The optional final phase fine-tunes the personalized model using a few labeled training examples. We conduct extensive experimental analysis using the personalized bAbI dialogue benchmark for five tasks and up to 180 diverse user profiles. The experimental results demonstrate that P-ToD, even when it had access to zero labeled examples, outperforms state-of-the-art supervised personalization models and achieves competitive performance on BLEU and ROUGE metrics when compared to a strong fully-supervised GPT-2 baseline. | A. B. Siddique, Muhammad Hasan Maqbool, Kshitija Taywade, Hassan Foroosh | Univ Kentucky, Lexington, KY 40506 USA; Univ Cent Florida, Orlando, FL 32816 USA |
|  |  [Dense Retrieval with Entity Views](https://doi.org/10.1145/3511808.3557285) |  | 0 | Pre-trained language models like BERT have been demonstrated to be both effective and efficient ranking methods when combined with approximate nearest neighbor search, which can quickly match dense representations of queries and documents. However, pre-trained language models alone do not fully capture information about uncommon entities. In this work, we investigate methods for enriching dense query and document representations with entity information from an external source. Our proposed method identifies groups of entities in a text and encodes them into a dense vector representation, which is then used to enrich BERT's vector representation of the text. To handle documents that contain many loosely-related entities, we devise a strategy for creating multiple entity representations that reflect different views of a document. For example, a document about a scientist may cover aspects of her personal life and recent work, which correspond to different views of the entity. In an evaluation on MS MARCO benchmarks, we find that enriching query and document representations in this way yields substantial increases in effectiveness. | Hai Dang Tran, Andrew Yates | Max Planck Inst Informat, Saarbrucken, Germany |
|  |  [Dynamic Hypergraph Learning for Collaborative Filtering](https://doi.org/10.1145/3511808.3557301) |  | 0 | Hypergraph-based collaborative filtering for recommendations has emerged as an important research topic due to its ability to model complex relations among users and items. However, most existing methods typically construct the hypergraph structures using heuristics (e.g., motifs and jump connections) based on existing graphs (e.g., user-item bipartite graphs and social networks). From a learning perspective, we argue that the fixed heuristic topology of hypergraph may become a limitation and thus potentially compromise the recommendation performance. To tackle this issue, we propose a novel dynamic hypergraph learning framework for collaborative filtering (DHLCF), which learns hypergraph structures and makes recommendations collectively in a unified framework. In the hypergraph learning process, we solve two main challenges, i.e., 1) optimization issue and 2) regularization issue. Firstly, we propose a differentiable hypergraph learner to adaptively learn the optimized hypergraph structures dynamically for the hypergraph convolutions during the training process. Secondly, to better regularize dynamic hypergraph learning, we introduce a novel hypergraph learning objective, which forces the learned hypergraphs to retain the original graph topology. Extensive experiments on public datasets from different domains are provided to show that our proposed model significantly outperforms strong baselines. | Chunyu Wei, Jian Liang, Bing Bai, Di Liu | Tencent Inc, Tencent Secur Big Data Lab, Beijing, Peoples R China; Alibaba Grp, Beijing, Peoples R China |
|  |  [Certified Robustness to Word Substitution Ranking Attack for Neural Ranking Models](https://doi.org/10.1145/3511808.3557256) |  | 0 |  | Chen Wu, Ruqing Zhang, Jiafeng Guo, Wei Chen, Yixing Fan, Maarten de Rijke, Xueqi Cheng |  |
|  |  [Contrastive Label Correlation Enhanced Unified Hashing Encoder for Cross-modal Retrieval](https://doi.org/10.1145/3511808.3557265) |  | 0 |  | Hongfa Wu, Lisai Zhang, Qingcai Chen, Yimeng Deng, Joanna Siebert, Yunpeng Han, Zhonghua Li, Dejiang Kong, Zhao Cao |  |
|  |  [A Gumbel-based Rating Prediction Framework for Imbalanced Recommendation](https://doi.org/10.1145/3511808.3557341) |  | 0 |  | Yuexin Wu, Xiaolei Huang |  |
|  |  [Dynamic Causal Collaborative Filtering](https://doi.org/10.1145/3511808.3557300) |  | 0 |  | Shuyuan Xu, Juntao Tan, Zuohui Fu, Jianchao Ji, Shelby Heinecke, Yongfeng Zhang |  |
|  |  [The Interaction Graph Auto-encoder Network Based on Topology-aware for Transferable Recommendation](https://doi.org/10.1145/3511808.3557471) |  | 0 |  | Ruiyun Yu, Kang Yang, Bingyang Guo |  |
|  |  [Evaluating Interpolation and Extrapolation Performance of Neural Retrieval Models](https://doi.org/10.1145/3511808.3557312) |  | 0 |  | Jingtao Zhan, Xiaohui Xie, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, Shaoping Ma |  |
|  |  [Along the Time: Timeline-traced Embedding for Temporal Knowledge Graph Completion](https://doi.org/10.1145/3511808.3557233) |  | 0 |  | Fuwei Zhang, Zhao Zhang, Xiang Ao, Fuzhen Zhuang, Yongjun Xu, Qing He |  |
|  |  [A Simple Meta-path-free Framework for Heterogeneous Network Embedding](https://doi.org/10.1145/3511808.3557223) |  | 0 |  | Rui Zhang, Arthur Zimek, Peter SchneiderKamp |  |
|  |  [DeepVT: Deep View-Temporal Interaction Network for News Recommendation](https://doi.org/10.1145/3511808.3557284) |  | 0 |  | Xuanyu Zhang, Qing Yang, Dongliang Xu |  |
|  |  [Multi-task Learning with Adaptive Global Temporal Structure for Predicting Alzheimer's Disease Progression](https://doi.org/10.1145/3511808.3557406) |  | 0 |  | Menghui Zhou, Yu Zhang, Tong Liu, Yun Yang, Po Yang |  |
|  |  [From Easy to Hard: A Dual Curriculum Learning Framework for Context-Aware Document Ranking](https://doi.org/10.1145/3511808.3557328) |  | 0 |  | Yutao Zhu, JianYun Nie, Yixuan Su, Haonan Chen, Xinyu Zhang, Zhicheng Dou |  |
|  |  [Improving Knowledge-aware Recommendation with Multi-level Interactive Contrastive Learning](https://doi.org/10.1145/3511808.3557358) |  | 0 |  | Ding Zou, Wei Wei, Ziyang Wang, XianLing Mao, Feida Zhu, Rui Fang, Dangyang Chen |  |
|  |  [A Case Study in Educational Recommenders: Recommending Music Partitures at Tomplay](https://doi.org/10.1145/3511808.3557111) |  | 0 |  | Ahmad Ajalloeian, Michalis Vlachos, Johannes Schneider, Alexis Steinmann |  |
|  |  [Generating Persuasive Responses to Customer Reviews with Multi-Source Prior Knowledge in E-commerce](https://doi.org/10.1145/3511808.3557122) |  | 0 |  | Bo Chen, Jiayi Liu, Mieradilijiang Maimaiti, Xing Gao, Ji Zhang |  |
|  |  [Real-time Short Video Recommendation on Mobile Devices](https://doi.org/10.1145/3511808.3557065) |  | 0 |  | Xudong Gong, Qinlin Feng, Yuan Zhang, Jiangling Qin, Weijie Ding, Biao Li, Peng Jiang, Kun Gai |  |
|  |  [BLUTune: Query-informed Multi-stage IBM Db2 Tuning via ML](https://doi.org/10.1145/3511808.3557117) |  | 0 |  | Connor Henderson, Spencer Bryson, Vincent Corvinelli, Parke Godfrey, Piotr Mierzejewski, Jaroslaw Szlichta, Calisto Zuzarte |  |
|  |  [PlatoGL: Effective and Scalable Deep Graph Learning System for Graph-enhanced Real-Time Recommendation](https://doi.org/10.1145/3511808.3557084) |  | 0 |  | Dandan Lin, Shijie Sun, Jingtao Ding, Xuehan Ke, Hao Gu, Xing Huang, Chonggang Song, Xuri Zhang, Lingling Yi, Jie Wen, Chuan Chen |  |
|  |  [Efficient Compression Method for Roadside LiDAR Data](https://doi.org/10.1145/3511808.3557144) |  | 0 |  | Md. Parvez Mollah, Biplob Debnath, Murugan Sankaradas, Srimat Chakradhar, Abdullah Mueen |  |
|  |  [MIC: Model-agnostic Integrated Cross-channel Recommender](https://doi.org/10.1145/3511808.3557081) |  | 0 |  | Ping Nie, Yujie Lu, Shengyu Zhang, Ming Zhao, Ruobing Xie, William Yang Wang, Yi Ren |  |
|  |  [High Availability Framework and Query Fault Tolerance for Hybrid Distributed Database Systems](https://doi.org/10.1145/3511808.3557086) |  | 0 |  | Krishna Kantikiran Pasupuleti, Boris Klots, Vijayakrishnan Nagarajan, Ananthakiran Kandukuri, Nipun Agarwal |  |
|  |  [CTRL: Cooperative Traffic Tolling via Reinforcement Learning](https://doi.org/10.1145/3511808.3557112) |  | 0 |  | Yiheng Wang, Hexi Jin, Guanjie Zheng |  |
|  |  [Learning List-wise Representation in Reinforcement Learning for Ads Allocation with Multiple Auxiliary Tasks](https://doi.org/10.1145/3511808.3557094) |  | 0 |  | Ze Wang, Guogang Liao, Xiaowen Shi, Xiaoxu Wu, Chuheng Zhang, Yongkang Wang, Xingxing Wang, Dong Wang |  |
|  |  [SwiftPruner: Reinforced Evolutionary Pruning for Efficient Ad Relevance](https://doi.org/10.1145/3511808.3557139) |  | 0 |  | Li Lyna Zhang, Youkow Homma, Yujing Wang, Min Wu, Mao Yang, Ruofei Zhang, Ting Cao, Wei Shen |  |
|  |  [Probing the Robustness of Pre-trained Language Models for Entity Matching](https://doi.org/10.1145/3511808.3557673) |  | 0 |  | Mehdi Akbarian Rastaghi, Ehsan Kamalloo, Davood Rafiei |  |
|  |  [SERF: Interpretable Sleep Staging using Embeddings, Rules, and Features](https://doi.org/10.1145/3511808.3557700) |  | 0 |  | Irfan AlHussaini, Cassie S. Mitchell |  |
|  |  [IEEE13-AdvAttack A Novel Dataset for Benchmarking the Power of Adversarial Attacks against Fault Prediction Systems in Smart Electrical Grid](https://doi.org/10.1145/3511808.3557612) |  | 0 |  | Carmelo Ardito, Yashar Deldjoo, Tommaso Di Noia, Eugenio Di Sciascio, Fatemeh Nazary |  |
|  |  [CS-MLGCN: Multiplex Graph Convolutional Networks for Community Search in Multiplex Networks](https://doi.org/10.1145/3511808.3557572) |  | 0 |  | Ali Behrouz, Farnoosh Hashemi |  |
|  |  [Discriminative Language Model via Self-Teaching for Dense Retrieval](https://doi.org/10.1145/3511808.3557582) |  | 0 |  | Lu Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng |  |
|  |  [CFS-MTL: A Causal Feature Selection Mechanism for Multi-task Learning via Pseudo-intervention](https://doi.org/10.1145/3511808.3557559) |  | 0 |  | Zhongde Chen, Ruize Wu, Cong Jiang, Honghui Li, Xin Dong, Can Long, Yong He, Lei Cheng, Linjian Mo |  |
|  |  [LCD: Adaptive Label Correction for Denoising Music Recommendation](https://doi.org/10.1145/3511808.3557625) |  | 0 |  | Quanyu Dai, Yalei Lv, Jieming Zhu, Junjie Ye, Zhenhua Dong, Rui Zhang, ShuTao Xia, Ruiming Tang |  |
|  |  [GFlow-FT: Pick a Child Network via Gradient Flow for Efficient Fine-Tuning in Recommendation Systems](https://doi.org/10.1145/3511808.3557603) |  | 0 |  | Ke Ding, Yong He, Xin Dong, Jieyu Yang, Liang Zhang, Ang Li, Xiaolu Zhang, Linjian Mo |  |
|  |  [MASR: A Model-Agnostic Sparse Routing Architecture for Arbitrary Order Feature Sharing in Multi-Task Learning](https://doi.org/10.1145/3511808.3557635) |  | 0 |  | Xin Dong, Ruize Wu, Chao Xiong, Hai Li, Lei Cheng, Yong He, Shiyou Qian, Jian Cao, Linjian Mo |  |
|  |  [End-to-end Multi-task Learning Framework for Spatio-Temporal Grounding in Video Corpus](https://doi.org/10.1145/3511808.3557596) |  | 0 |  | Yingqi Gao, Zhiling Luo, Shiqian Chen, Wei Zhou |  |
|  |  [Bootstrapped Knowledge Graph Embedding based on Neighbor Expansion](https://doi.org/10.1145/3511808.3557555) |  | 0 |  | Jun Seon Kim, SeongJin Ahn, Myoung Ho Kim |  |
|  |  [Context-aware Traffic Flow Forecasting in New Roads](https://doi.org/10.1145/3511808.3557566) |  | 0 |  | Namhyuk Kim, DongKyu Chae, Jung Ah Shin, SangWook Kim, Duen Horng Chau, Sunghwan Park |  |
|  |  [Is It Enough Just Looking at the Title?: Leveraging Body Text To Enrich Title Words Towards Accurate News Recommendation](https://doi.org/10.1145/3511808.3557619) |  | 0 |  | Taeho Kim, Yungi Kim, YeonChang Lee, WonYong Shin, SangWook Kim |  |
|  |  [Efficient Data Augmentation Policy for Electrocardiograms](https://doi.org/10.1145/3511808.3557591) |  | 0 |  | ByeongTak Lee, YongYeon Jo, SeonYu Lim, Youngjae Song, JoonMyoung Kwon |  |
|  |  [SmartQuery: An Active Learning Framework for Graph Neural Networks through Hybrid Uncertainty Reduction](https://doi.org/10.1145/3511808.3557701) |  | 0 |  | Xiaoting Li, Yuhang Wu, Vineeth Rakesh, Yusan Lin, Hao Yang, Fei Wang |  |
|  |  [Relation-aware Blocking for Scalable Recommendation Systems](https://doi.org/10.1145/3511808.3557682) |  | 0 |  | Huizhi Liang, Zehao Liu, Thanet Markchom |  |
|  |  [Heterogeneous Hypergraph Neural Network for Friend Recommendation with Human Mobility](https://doi.org/10.1145/3511808.3557609) |  | 0 |  | Yongkang Li, Zipei Fan, Jixiao Zhang, Dengheng Shi, Tianqi Xu, Du Yin, Jinliang Deng, Xuan Song |  |
|  |  [JavaScript&Me, A Tool to Support Research into Code Transformation and Browser Security](https://doi.org/10.1145/3511808.3557620) |  | 0 |  | Susana Lima, Ricardo Morla, João Routar |  |
|  |  [Embedding Global and Local Influences for Dynamic Graphs](https://doi.org/10.1145/3511808.3557594) |  | 0 |  | Meng Liu, Jiaming Wu, Yong Liu |  |
|  |  [A Contrastive Pre-training Approach to Discriminative Autoencoder for Dense Retrieval](https://doi.org/10.1145/3511808.3557527) |  | 0 |  | Xinyu Ma, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng |  |
|  |  [Contextualized Formula Search Using Math Abstract Meaning Representation](https://doi.org/10.1145/3511808.3557567) |  | 0 |  | Behrooz Mansouri, Douglas W. Oard, Richard Zanibbi |  |
|  |  [Towards Confidence-aware Calibrated Recommendation](https://doi.org/10.1145/3511808.3557713) |  | 0 |  | Mohammadmehdi Naghiaei, Hossein A. Rahmani, Mohammad Aliannejadi, Nasim Sonboli |  |
|  |  [Plotly.plus, an Improved Dataset for Visualization Recommendation](https://doi.org/10.1145/3511808.3557669) |  | 0 |  | Luca Podo, Paola Velardi |  |
|  |  [Explainable Graph-based Fraud Detection via Neural Meta-graph Search](https://doi.org/10.1145/3511808.3557598) |  | 0 |  | Zidi Qin, Yang Liu, Qing He, Xiang Ao |  |
|  |  [Early Stage Sparse Retrieval with Entity Linking](https://doi.org/10.1145/3511808.3557588) |  | 0 |  | Dahlia Shehata, Negar Arabzadeh, Charles L. A. Clarke |  |
|  |  [Multi-task Generative Adversarial Network for Missing Mobility Data Imputation](https://doi.org/10.1145/3511808.3557654) |  | 0 |  | Meihui Shi, Derong Shen, Yue Kou, Tiezheng Nie, Ge Yu |  |
|  |  [On the Impact of Speech Recognition Errors in Passage Retrieval for Spoken Question Answering](https://doi.org/10.1145/3511808.3557662) |  | 0 |  | Georgios Sidiropoulos, Svitlana Vakulenko, Evangelos Kanoulas |  |
|  |  [Multi-Aspect Embedding of Dynamic Graphs](https://doi.org/10.1145/3511808.3557650) |  | 0 |  | Aimin Sun, Zhiguo Gong |  |
|  |  [Hybrid Transfer in Deep Reinforcement Learning for Ads Allocation](https://doi.org/10.1145/3511808.3557611) |  | 0 |  | Ze Wang, Guogang Liao, Xiaowen Shi, Xiaoxu Wu, Chuheng Zhang, Bingqi Zhu, Yongkang Wang, Xingxing Wang, Dong Wang |  |
|  |  [Disentangled Contrastive Learning for Social Recommendation](https://doi.org/10.1145/3511808.3557583) |  | 0 |  | Jiahao Wu, Wenqi Fan, Jingfan Chen, Shengcai Liu, Qing Li, Ke Tang |  |
|  |  [Balancing Utility and Exposure Fairness for Integrated Ranking with Reinforcement Learning](https://doi.org/10.1145/3511808.3557551) |  | 0 |  | Wei Xia, Weiwen Liu, Yifan Liu, Ruiming Tang |  |
|  |  [Multi-granularity Fatigue in Recommendation](https://doi.org/10.1145/3511808.3557651) |  | 0 |  | Ruobing Xie, Cheng Ling, Shaoliang Zhang, Feng Xia, Leyu Lin |  |
|  |  [Texture BERT for Cross-modal Texture Image Retrieval](https://doi.org/10.1145/3511808.3557710) |  | 0 |  | Zelai Xu, Tan Yu, Ping Li |  |
|  |  [Unanswerable Question Correction and Explanation over Personal Knowledge Base](https://doi.org/10.1145/3511808.3557717) |  | 0 |  | AnZi Yen, HenHsen Huang, HsinHsi Chen |  |
|  |  [Multi-scale Multi-modal Dictionary BERT For Effective Text-image Retrieval in Multimedia Advertising](https://doi.org/10.1145/3511808.3557653) |  | 0 |  | Tan Yu, Jie Liu, Zhipeng Jin, Yi Yang, Hongliang Fei, Ping Li |  |
|  |  [Deep Contrastive Multiview Network Embedding](https://doi.org/10.1145/3511808.3557577) |  | 0 |  | Mengqi Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, Liang Wang |  |
|  |  [WDRASS: A Web-scale Dataset for Document Retrieval and Answer Sentence Selection](https://doi.org/10.1145/3511808.3557678) |  | 0 |  | Zeyu Zhang, Thuy Vu, Sunil Gandhi, Ankit Chadha, Alessandro Moschitti |  |
|  |  [RecBole 2.0: Towards a More Up-to-Date Recommendation Library](https://doi.org/10.1145/3511808.3557680) |  | 0 |  | Wayne Xin Zhao, Yupeng Hou, Xingyu Pan, Chen Yang, Zeyu Zhang, Zihan Lin, Jingsen Zhang, Shuqing Bian, Jiakai Tang, Wenqi Sun, Yushuo Chen, Lanling Xu, Gaowei Zhang, Zhen Tian, Changxin Tian, Shanlei Mu, Xinyan Fan, Xu Chen, JiRong Wen |  |
|  |  [SuGeR: A Subgraph-based Graph Convolutional Network Method for Bundle Recommendation](https://doi.org/10.1145/3511808.3557707) |  | 0 |  | Zhenning Zhang, Boxin Du, Hanghang Tong |  |
|  |  [ranx.fuse: A Python Library for Metasearch](https://doi.org/10.1145/3511808.3557207) |  | 0 |  | Elias Bassani, Luca Romelli |  |
|  |  [Leveraging Scalable Profiling to Learn and Visualize the Latest Trustworthy COVID-19 Medical Research Findings](https://doi.org/10.1145/3511808.3557171) |  | 0 |  | Michael N. Gubanov, Sophie Pavia, Anna Pyayt, William Goble |  |
|  |  [A Real-time Post-processing System for Itinerary Recommendation](https://doi.org/10.1145/3511808.3557190) |  | 0 |  | Linge Jiang, Guiyang Wang, Zhibo Zhu, Binghao Wang, Runsheng Gan, Ziqi Liu, Jun Zhou |  |
|  |  [DBinsight: A Tool for Interactively Understanding the Query Processing Pipeline in RDBMSs](https://doi.org/10.1145/3511808.3557211) |  | 0 |  | Ying Rong, Hui Li, Kankan Zhao, Xiyue Gao, Jiangtao Cui |  |
|  |  [CAVE: Correcting Attribute Values in E-commerce Profiles](https://doi.org/10.1145/3511808.3557161) |  | 0 |  | Kassem Sabeh, Mouna Kacimi, Johann Gamper |  |
|  |  [Approximate and Interactive Processing of Aggregate Queries on Knowledge Graphs: A Demonstration](https://doi.org/10.1145/3511808.3557158) |  | 0 |  | Yuxiang Wang, Arijit Khan, Xiaoliang Xu, Shuzhan Ye, Shihuang Pan, Yuhan Zhou |  |
|  |  [Fifty Shades of Pink: Understanding Color in e-commerce using Knowledge Graphs](https://doi.org/10.1145/3511808.3557513) |  | 0 |  | Lizzie Liang, Sneha Kamath, Petar Ristoski, Qunzhi Zhou, Zhe Wu |  |
|  |  [Geographical Address Models in the Indian e-Commerce](https://doi.org/10.1145/3511808.3557515) |  | 0 |  | Ravindra Babu Tallamraju |  |
|  |  [On the Challenges of Podcast Search at Spotify](https://doi.org/10.1145/3511808.3557518) |  | 0 |  | Mi Tian, Claudia Hauff, Praveen Chandar |  |
|  |  [Rank-Aware Gain-Based Evaluation of Extractive Summarization](https://doi.org/10.1145/3511808.3557821) |  | 0 |  | Mousumi Akter |  |
|  |  [Modeling Turn-Based Sequences for Player Tactic Applications in Badminton Matches](https://doi.org/10.1145/3511808.3557820) |  | 0 |  | WeiYao Wang |  |
|  |  [Self-Supervised Learning for Recommendation](https://doi.org/10.1145/3511808.3557506) |  | 0 |  | Chao Huang, Lianghao Xia, Xiang Wang, Xiangnan He, Dawei Yin |  |
|  |  [Risk-Aware Bid Optimization for Online Display Advertisement](https://doi.org/10.1145/3511808.3557436) |  | 0 |  | Rui Fan, Erick Delage |  |
|  |  [Cascade Variational Auto-Encoder for Hierarchical Disentanglement](https://doi.org/10.1145/3511808.3557254) |  | 0 |  | Fudong Lin, Xu Yuan, Lu Peng, NianFeng Tzeng |  |
|  |  [Domain Adversarial Spatial-Temporal Network: A Transferable Framework for Short-term Traffic Forecasting across Cities](https://doi.org/10.1145/3511808.3557294) |  | 0 |  | Yihong Tang, Ao Qu, Andy H. F. Chow, William H. K. Lam, Sze Chun Wong, Wei Ma |  |
|  |  [RuDi: Explaining Behavior Sequence Models by Automatic Statistics Generation and Rule Distillation](https://doi.org/10.1145/3511808.3557441) |  | 0 |  | Yao Zhang, Yun Xiong, Yiheng Sun, Caihua Shan, Tian Lu, Hui Song, Yangyong Zhu |  |
|  |  [Cascaded Debiasing: Studying the Cumulative Effect of Multiple Fairness-Enhancing Interventions](https://doi.org/10.1145/3511808.3557155) |  | 0 |  | Bhavya Ghai, Mihir Mishra, Klaus Mueller |  |
|  |  [Guided Text-based Item Exploration](https://doi.org/10.1145/3511808.3557141) |  | 0 |  | Behrooz OmidvarTehrani, Aurélien Personnaz, Sihem AmerYahia |  |
|  |  [An Actor-critic Reinforcement Learning Model for Optimal Bidding in Online Display Advertising](https://doi.org/10.1145/3511808.3557064) |  | 0 |  | Congde Yuan, Mengzhuo Guo, Chaoneng Xiang, Shuangyang Wang, Guoqing Song, Qingpeng Zhang |  |
|  |  [QuickSkill: Novice Skill Estimation in Online Multiplayer Games](https://doi.org/10.1145/3511808.3557070) |  | 0 |  | Chaoyun Zhang, Kai Wang, Hao Chen, Ge Fan, Yingjie Li, Lifang Wu, Bingchao Zheng |  |
|  |  [Data Oversampling with Structure Preserving Variational Learning](https://doi.org/10.1145/3511808.3557575) |  | 0 |  | Indu Solomon, Senthilnath Jayavelu, Md Meftahul Ferdaus, Uttam Kumar |  |
|  |  [MLadder: An Online Training System for Machine Learning and Data Science Education](https://doi.org/10.1145/3511808.3557201) |  | 0 |  | Siqi Han, Wanting Li, En Zhang, Jilin Shi, Wei Wang, Xuesong Lu |  |
|  |  [PLASMA: A Semantic Modeling Tool for Domain Experts](https://doi.org/10.1145/3511808.3557184) |  | 0 |  | Alexander Paulus, Andreas Burgdorf, Tristan Langer, André Pomp, Tobias Meisen, Sebastian Pol |  |
|  |  [Implicit User-Generated Content in the Service of Public Health](https://doi.org/10.1145/3511808.3555800) |  | 0 |  | Evgeniy Gabrilovich |  |
|  |  [Exploring and Analyzing Change: The Janus Project](https://doi.org/10.1145/3511808.3555799) |  | 0 |  | Divesh Srivastava, Tobias Bleifuß, Leon Bornemann, Dmitri V. Kalashnikov, Felix Naumann |  |
|  |  [DocSemMap 2.0: Semantic Labeling based on Textual Data Documentations Using Seq2Seq Context Learner](https://doi.org/10.1145/3511808.3557446) |  | 0 |  | Andreas Burgdorf, Alexander Paulus, André Pomp, Tobias Meisen |  |
|  |  [Efficient Trajectory Similarity Computation with Contrastive Learning](https://doi.org/10.1145/3511808.3557308) |  | 0 |  | Liwei Deng, Yan Zhao, Zidan Fu, Hao Sun, Shuncheng Liu, Kai Zheng |  |
|  |  [Weakly-Supervised Online Hashing with Refined Pseudo Tags](https://doi.org/10.1145/3511808.3557488) |  | 0 |  | ChenLu Ding, Xin Luo, XiaoMing Wu, YuWei Zhan, Rui Li, Hui Zhang, XinShun Xu |  |
|  |  [Change Detection for Local Explainability in Evolving Data Streams](https://doi.org/10.1145/3511808.3557257) |  | 0 |  | Johannes Haug, Alexander Braun, Stefan Zürn, Gjergji Kasneci |  |
|  |  [Cross-Domain Aspect Extraction using Transformers Augmented with Knowledge Graphs](https://doi.org/10.1145/3511808.3557275) |  | 0 |  | Phillip Howard, Arden Ma, Vasudev Lal, Ana Paula Simões, Daniel Korat, Oren Pereg, Moshe Wasserblat, Gadi Singer |  |
|  |  [Discovering Fine-Grained Semantics in Knowledge Graph Relations](https://doi.org/10.1145/3511808.3557287) |  | 0 |  | Nitisha Jain, Ralf Krestel |  |
|  |  [Diverse Effective Relationship Exploration for Cooperative Multi-Agent Reinforcement Learning](https://doi.org/10.1145/3511808.3557292) |  | 0 |  | Hao Jiang, Yuntao Liu, Shengze Li, Jieyuan Zhang, Xinhai Xu, Donghong Liu |  |
|  |  [Estimating Causal Effects on Networked Observational Data via Representation Learning](https://doi.org/10.1145/3511808.3557311) |  | 0 |  | Song Jiang, Yizhou Sun |  |
|  |  [Can Adversarial Training benefit Trajectory Representation?: An Investigation on Robustness for Trajectory Similarity Computation](https://doi.org/10.1145/3511808.3557250) |  | 0 |  | Quanliang Jing, Shuo Liu, Xinxin Fan, Jingwei Li, Di Yao, Baoli Wang, Jingping Bi |  |
|  |  [SWAG-Net: Semantic Word-Aware Graph Network for Temporal Video Grounding](https://doi.org/10.1145/3511808.3557463) |  | 0 |  | Sunoh Kim, Taegil Ha, Kimin Yun, Jin Young Choi |  |
|  |  [Semorph: A Morphology Semantic Enhanced Pre-trained Model for Chinese Spam Text Detection](https://doi.org/10.1145/3511808.3557448) |  | 0 |  | Kaiting Lai, Yinong Long, Bowen Wu, Ying Li, Baoxun Wang |  |
|  |  [Sliding Cross Entropy for Self-Knowledge Distillation](https://doi.org/10.1145/3511808.3557453) |  | 0 |  | Hanbeen Lee, Jeongho Kim, Simon S. Woo |  |
|  |  [Frequent Itemset Mining with Local Differential Privacy](https://doi.org/10.1145/3511808.3557327) |  | 0 |  | Junhui Li, Wensheng Gan, Yijie Gui, Yongdong Wu, Philip S. Yu |  |
|  |  [℘-MinHash Algorithm for Continuous Probability Measures: Theory and Application to Machine Learning](https://doi.org/10.1145/3511808.3557413) |  | 0 |  | Ping Li, Xiaoyun Li, Gennady Samorodnitsky |  |
|  |  [GCWSNet: Generalized Consistent Weighted Sampling for Scalable and Accurate Training of Neural Networks](https://doi.org/10.1145/3511808.3557332) |  | 0 |  | Ping Li, Weijie Zhao |  |
|  |  [High-quality Task Division for Large-scale Entity Alignment](https://doi.org/10.1145/3511808.3557352) |  | 0 |  | Bing Liu, Wen Hua, Guido Zuccon, Genghong Zhao, Xia Zhang |  |
|  |  [Cascade-based Echo Chamber Detection](https://doi.org/10.1145/3511808.3557253) |  | 0 |  | Marco Minici, Federico Cinus, Corrado Monti, Francesco Bonchi, Giuseppe Manco |  |
|  |  [Domain-Agnostic Contrastive Representations for Learning from Label Proportions](https://doi.org/10.1145/3511808.3557293) |  | 0 |  | Jay Nandy, Rishi Saket, Prateek Jain, Jatin Chauhan, Balaraman Ravindran, Aravindan Raghuveer |  |
|  |  [RSD: A Reinforced Siamese Network with Domain Knowledge for Early Diagnosis](https://doi.org/10.1145/3511808.3557440) |  | 0 |  | Houxing Ren, Jingyuan Wang, Wayne Xin Zhao |  |
|  |  [Crowdsourced Fact-Checking at Twitter: How Does the Crowd Compare With Experts?](https://doi.org/10.1145/3511808.3557279) |  | 0 |  | Mohammed Saeed, Nicolas Traub, Maelle Nicolas, Gianluca Demartini, Paolo Papotti |  |
|  |  [A Transformer-Based User Satisfaction Prediction for Proactive Interaction Mechanism in DuerOS](https://doi.org/10.1145/3511808.3557224) |  | 0 |  | Wei Shen, Xiaonan He, Chuheng Zhang, Xuyun Zhang, Jian Xie |  |
|  |  [AdaGCL: Adaptive Subgraph Contrastive Learning to Generalize Large-scale Graph Training](https://doi.org/10.1145/3511808.3557228) |  | 0 |  | Yili Wang, Kaixiong Zhou, Rui Miao, Ninghao Liu, Xin Wang |  |
|  |  [Latent Coreset Sampling based Data-Free Continual Learning](https://doi.org/10.1145/3511808.3557375) |  | 0 |  | Zhuoyi Wang, Dingcheng Li, Ping Li |  |
|  |  [Hierarchical Representation for Multi-view Clustering: From Intra-sample to Intra-view to Inter-view](https://doi.org/10.1145/3511808.3557349) |  | 0 |  | Jinghua Yang, Chuan Chen, HongNing Dai, Meng Ding, Lele Fu, Zibin Zheng |  |
|  |  [Scalable Graph Sampling on GPUs with Compressed Graph](https://doi.org/10.1145/3511808.3557443) |  | 0 |  | Hongbo Yin, Yingxia Shao, Xupeng Miao, Yawen Li, Bin Cui |  |
|  |  [Contrastive Domain Adaptation for Early Misinformation Detection: A Case Study on COVID-19](https://doi.org/10.1145/3511808.3557263) |  | 0 |  | Zhenrui Yue, Huimin Zeng, Ziyi Kou, Lanyu Shang, Dong Wang |  |
|  |  [Cross-domain Cross-architecture Black-box Attacks on Fine-tuned Models with Transferred Evolutionary Strategies](https://doi.org/10.1145/3511808.3557276) |  | 0 |  | Yinghua Zhang, Yangqiu Song, Kun Bai, Qiang Yang |  |
|  |  [Adversarial Robustness through Bias Variance Decomposition: A New Perspective for Federated Learning](https://doi.org/10.1145/3511808.3557232) |  | 0 |  | Yao Zhou, Jun Wu, Haixun Wang, Jingrui He |  |
|  |  [Decoupled Hyperbolic Graph Attention Network for Modeling Substitutable and Complementary Item Relationships](https://doi.org/10.1145/3511808.3557281) |  | 0 |  | Zhiheng Zhou, Tao Wang, Linfang Hou, Xinyuan Zhou, Mian Ma, Zhuoye Ding |  |
|  |  [Simulation-Informed Revenue Extrapolation with Confidence Estimate for Scaleup Companies Using Scarce Time-Series Data](https://doi.org/10.1145/3511808.3557110) |  | 0 |  | Lele Cao, Sonja Horn, Vilhelm von Ehrenheim, Richard Anselmo Stahl, Henrik Landgren |  |
|  |  [Hierarchically Constrained Adaptive Ad Exposure in Feeds](https://doi.org/10.1145/3511808.3557103) |  | 0 |  | Dagui Chen, Qi Yan, Chunjie Chen, Zhenzhe Zheng, Yangsu Liu, Zhenjia Ma, Chuan Yu, Jian Xu, Bo Zheng |  |
|  |  [DuMapper: Towards Automatic Verification of Large-Scale POIs with Street Views at Baidu Maps](https://doi.org/10.1145/3511808.3557097) |  | 0 |  | Miao Fan, Jizhou Huang, Haifeng Wang |  |
|  |  [RecipeMind: Guiding Ingredient Choices from Food Pairing to Recipe Completion using Cascaded Set Transformer](https://doi.org/10.1145/3511808.3557092) |  | 0 |  | Mogan Gim, Donghee Choi, Kana Maruyama, Jihun Choi, Hajung Kim, Donghyeon Park, Jaewoo Kang |  |
|  |  [DuIVRS: A Telephonic Interactive Voice Response System for Large-Scale POI Attribute Acquisition at Baidu Maps](https://doi.org/10.1145/3511808.3557131) |  | 0 |  | Jizhou Huang, Haifeng Wang, Shaolei Wang |  |
|  |  [Incorporating Fairness in Large-scale Evacuation Planning](https://doi.org/10.1145/3511808.3557075) |  | 0 |  | Kazi Ashik Islam, Da Qi Chen, Madhav V. Marathe, Henning S. Mortveit, Samarth Swarup, Anil Vullikanti |  |
|  |  [PAVE: Lazy-MDP based Ensemble to Improve Recall of Product Attribute Extraction Models](https://doi.org/10.1145/3511808.3557119) |  | 0 |  | Kushal Kumar, Anoop S. V. K. K. Saladi |  |
|  |  [Billion-user Customer Lifetime Value Prediction: An Industrial-scale Solution from Kuaishou](https://doi.org/10.1145/3511808.3557152) |  | 0 |  | Kunpeng Li, Guangcui Shao, Naijun Yang, Xiao Fang, Yang Song |  |
|  |  [MEMENTO: Neural Model for Estimating Individual Treatment Effects for Multiple Treatments](https://doi.org/10.1145/3511808.3557125) |  | 0 |  | Abhirup Mondal, Anirban Majumder, Vineet Chaoji |  |
|  |  [A Dual Channel Intent Evolution Network for Predicting Period-Aware Travel Intentions at Fliggy](https://doi.org/10.1145/3511808.3557135) |  | 0 |  | Wanjie Tao, ZhangHua Fu, Liangyue Li, Zulong Chen, Hong Wen, Yuanyuan Liu, Qijie Shen, Peilin Chen |  |
|  |  [Marine-tree: A Large-scale Marine Organisms Dataset for Hierarchical Image Classification](https://doi.org/10.1145/3511808.3557634) |  | 0 |  | Tanya BooneSifuentes, Asef Nazari, Imran Razzak, Mohamed Reda Bouadjenek, Antonio RoblesKelly, Daniel Ierodiaconou, Elizabeth S. Oh |  |
|  |  [Deep Ordinal Neural Network for Length of Stay Estimation in the Intensive Care Units](https://doi.org/10.1145/3511808.3557578) |  | 0 |  | Derun Cai, Moxian Song, Chenxi Sun, Baofeng Zhang, Shenda Hong, Hongyan Li |  |
|  |  [DialogID: A Dialogic Instruction Dataset for Improving Teaching Effectiveness in Online Environments](https://doi.org/10.1145/3511808.3557580) |  | 0 |  | Jiahao Chen, Shuyan Huang, Zitao Liu, Weiqi Luo |  |
|  |  [Knowledge Tracing Model with Learning and Forgetting Behavior](https://doi.org/10.1145/3511808.3557622) |  | 0 |  | Mingzhi Chen, Quanlong Guan, Yizhou He, Zhenyu He, Liangda Fang, Weiqi Luo |  |
|  |  [An Empirical Cross Domain-Specific Entity Recognition with Domain Vector](https://doi.org/10.1145/3511808.3557545) |  | 0 |  | Wei Chen, Songqiao Han, Hailiang Huang |  |
|  |  [Trusted Media Challenge Dataset and User Study](https://doi.org/10.1145/3511808.3557715) |  | 0 |  | Weiling Chen, Sheng Lun Benjamin Chua, Stefan Winkler, SeeKiong Ng |  |
|  |  [A Dataset for Burned Area Delineation and Severity Estimation from Satellite Imagery](https://doi.org/10.1145/3511808.3557528) |  | 0 |  | Luca Colomba, Alessandro Farasin, Simone Monaco, Salvatore Greco, Paolo Garza, Daniele Apiletti, Elena Baralis, Tania Cerquitelli |  |
|  |  [MalNet: A Large-Scale Image Database of Malicious Software](https://doi.org/10.1145/3511808.3557533) |  | 0 |  | Scott Freitas, Rahul Duggal, Duen Horng Chau |  |
|  |  [Binary Transformation Method for Multi-Label Stream Classification](https://doi.org/10.1145/3511808.3557553) |  | 0 |  | Ege Berkay Gulcan, Isin Su Ecevit, Fazli Can |  |
|  |  [SciTweets - A Dataset and Annotation Framework for Detecting Scientific Online Discourse](https://doi.org/10.1145/3511808.3557693) |  | 0 |  | Salim Hafid, Sebastian Schellhammer, Sandra Bringay, Konstantin Todorov, Stefan Dietze |  |
|  |  [META-CODE: Community Detection via Exploratory Learning in Topologically Unknown Networks](https://doi.org/10.1145/3511808.3557639) |  | 0 |  | Yu Hou, Cong Tran, WonYong Shin |  |
|  |  [GDA-HIN: A Generalized Domain Adaptive Model across Heterogeneous Information Networks](https://doi.org/10.1145/3511808.3557602) |  | 0 |  | Tiancheng Huang, Ke Xu, Donglin Wang |  |
|  |  [RealGraphGPU: A High-Performance GPU-Based Graph Engine toward Large-Scale Real-World Network Analysis](https://doi.org/10.1145/3511808.3557679) |  | 0 |  | MyungHwan Jang, YunYong Ko, Dongkyu Jeong, JeongMin Park, SangWook Kim |  |
|  |  [MCSCSet: A Specialist-annotated Dataset for Medical-domain Chinese Spelling Correction](https://doi.org/10.1145/3511808.3557636) |  | 0 |  | Wangjie Jiang, Zhihao Ye, Zijing Ou, Ruihui Zhao, Jianguang Zheng, Yi Liu, Bang Liu, Siheng Li, Yujiu Yang, Yefeng Zheng |  |
|  |  [Mining Entry Gates for Points of Interest](https://doi.org/10.1145/3511808.3557642) |  | 0 |  | Tanya Khanna, Abhinav Ganesan, Jose Mathew, Kranthi Mitra Adusimilli |  |
|  |  [A Multi-grained Dataset for News Event Triggered Knowledge Update](https://doi.org/10.1145/3511808.3557537) |  | 0 |  | YuTing Lee, YingJhe Tang, YuChung Cheng, PaiLin Chen, TsaiYen Li, HenHsen Huang |  |
|  |  [An Exploratory Study of Information Cocoon on Short-form Video Platform](https://doi.org/10.1145/3511808.3557548) |  | 0 |  | Nian Li, Chen Gao, Jinghua Piao, Xin Huang, Aizhen Yue, Liang Zhou, Qingmin Liao, Yong Li |  |
|  |  [CNewsTS - A Large-scale Chinese News Dataset with Hierarchical Topic Category and Summary](https://doi.org/10.1145/3511808.3557561) |  | 0 |  | Quanzhi Li, Yingchi Liu, Yang Chao |  |
|  |  [Knowledge Distillation via Hypersphere Features Distribution Transfer](https://doi.org/10.1145/3511808.3557621) |  | 0 |  | Boheng Liu, Tianrui Zhang, Ligang Miao |  |
|  |  [Efficient Non-sampling Expert Finding](https://doi.org/10.1145/3511808.3557592) |  | 0 |  | Hongtao Liu, Zhepeng Lv, Qing Yang, Dongliang Xu, Qiyao Peng |  |
|  |  [Sampling Enclosing Subgraphs for Link Prediction](https://doi.org/10.1145/3511808.3557688) |  | 0 |  | Paul Louis, Shweta Ann Jacob, Amirali SalehiAbari |  |
|  |  [PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python](https://doi.org/10.1145/3511808.3557676) |  | 0 |  | Haiping Lu, Xianyuan Liu, Shuo Zhou, Robert Turner, Peizhen Bai, Raivo E. Koot, Mustafa Chasmai, Lawrence Schobs, Hao Xu |  |
|  |  [ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shot Learning](https://doi.org/10.1145/3511808.3557681) |  | 0 |  | Jaehoon Oh, Sungnyun Kim, Namgyu Ho, JinHwa Kim, Hwanjun Song, SeYoung Yun |  |
|  |  [Cross-domain Prototype Learning from Contaminated Faces via Disentangling Latent Factors](https://doi.org/10.1145/3511808.3557571) |  | 0 |  | Meng Pang, Binghui Wang, Shengbo Chen, Yiuming Cheung, Rong Zou, Wei Huang |  |
|  |  [Do Graph Neural Networks Build Fair User Models? Assessing Disparate Impact and Mistreatment in Behavioural User Profiling](https://doi.org/10.1145/3511808.3557584) |  | 0 |  | Erasmo Purificato, Ludovico Boratto, Ernesto William De Luca |  |
|  |  [Robust Semi-supervised Domain Adaptation against Noisy Labels](https://doi.org/10.1145/3511808.3557685) |  | 0 |  | Can Qin, Yizhou Wang, Yun Fu |  |
|  |  [CStory: A Chinese Large-scale News Storyline Dataset](https://doi.org/10.1145/3511808.3557573) |  | 0 |  | Kaijie Shi, Xiaozhi Wang, Jifan Yu, Lei Hou, Juanzi Li, Jingtong Wu, Dingyu Yong, Jinghui Xiao, Qun Liu |  |
|  |  [A Preliminary Exploration of Extractive Multi-Document Summarization in Hyperbolic Space](https://doi.org/10.1145/3511808.3557538) |  | 0 |  | Mingyang Song, Yi Feng, Liping Jing |  |
|  |  [Robust Time Series Dissimilarity Measure for Outlier Detection and Periodicity Detection](https://doi.org/10.1145/3511808.3557686) |  | 0 |  | Xiaomin Song, Qingsong Wen, Yan Li, Liang Sun |  |
|  |  [Improving Downstream Task Performance by Treating Numbers as Entities](https://doi.org/10.1145/3511808.3557614) |  | 0 |  | Dhanasekar Sundararaman, Vivek Subramanian, Guoyin Wang, Liyan Xu, Lawrence Carin |  |
|  |  [Nonlinear Causal Discovery in Time Series](https://doi.org/10.1145/3511808.3557660) |  | 0 |  | Tianhao Wu, Xingyu Wu, Xin Wang, Shikang Liu, Huanhuan Chen |  |
|  |  [BidH: A Bidirectional Hierarchical Model for Nested Named Entity Recognition](https://doi.org/10.1145/3511808.3557554) |  | 0 |  | Wanyang Xu, Wengen Li, Jihong Guan, Shuigeng Zhou |  |
|  |  [Multiple Instance Learning for Uplift Modeling](https://doi.org/10.1145/3511808.3557655) |  | 0 |  | Yao Zhao, Haipeng Zhang, Shiwei Lyu, Ruiying Jiang, Jinjie Gu, Guannan Zhang |  |
|  |  [A Different VIM: Visualizing Incremental Machine Learning](https://doi.org/10.1145/3511808.3557175) |  | 0 |  | Sikder Tahsin AlAmin, Mohammad Imtiaz Nur, Aisha Farooque, Guoning Chen, Robin Varghese, Carlos Ordonez |  |
|  |  [exML: An Explainable Maximum Likelihood Tool for Proportion Estimation in DNA Data](https://doi.org/10.1145/3511808.3557156) |  | 0 |  | Amit Bergman, Viviane Slon, Daniel Deutch |  |
|  |  [SmartIndex: An Index Advisor with Learned Cost Estimator](https://doi.org/10.1145/3511808.3557163) |  | 0 |  | Jianling Gao, Nan Zhao, Ning Wang, Shuang Hao |  |
|  |  [Visual Exploration of Literature with Argo Scholar](https://doi.org/10.1145/3511808.3557177) |  | 0 |  | Kevin Li, Haoyang Yang, Evan Montoya, Anish Upadhayay, Zhiyan Zhou, Jon SaadFalcon, Duen Horng Chau |  |
|  |  [How Does the Crowd Impact the Model? A Tool for Raising Awareness of Social Bias in Crowdsourced Training Data](https://doi.org/10.1145/3511808.3557178) |  | 0 |  | Periklis Perikleous, Andreas Kafkalias, Zenonas Theodosiou, Pinar Barlas, Evgenia Christoforou, Jahna Otterbacher, Gianluca Demartini, Andreas Lanitis |  |
|  |  [CRUX: Crowdsourced Materials Science Resource and Workflow Exploration](https://doi.org/10.1145/3511808.3557194) |  | 0 |  | Mengying Wang, Hanchao Ma, Abhishek Daundkar, Sheng Guan, Yiyang Bian, Alpi Sehirlioglu, Yinghui Wu |  |
|  |  [ExeKG: Executable Knowledge Graph System for User-friendly Data Analytics](https://doi.org/10.1145/3511808.3557195) |  | 0 |  | Zhuoxun Zheng, Baifan Zhou, Dongzhuoran Zhou, Ahmet Soylu, Evgeny Kharlamov |  |
|  |  [Utilizing Contrastive Learning To Address Long Tail Issue in Product Categorization](https://doi.org/10.1145/3511808.3557522) |  | 0 |  | Lei Chen, Tianqi Wang |  |
|  |  [Intent Disambiguation for Task-oriented Dialogue Systems](https://doi.org/10.1145/3511808.3557516) |  | 0 |  | Andrea Alfieri, Ralf Wolter, Seyyed Hadi Hashemi |  |
|  |  [Synerise Monad - Real-Time Multimodal Behavioral Modeling](https://doi.org/10.1145/3511808.3557521) |  | 0 |  | Jacek Dabrowski, Barbara Rychalska |  |
|  |  [Executable Knowledge Graph for Transparent Machine Learning in Welding Monitoring at Bosch](https://doi.org/10.1145/3511808.3557512) |  | 0 |  | Zhuoxun Zheng, Baifan Zhou, Dongzhuoran Zhou, Ahmet Soylu, Evgeny Kharlamov |  |
|  |  [AIMLAI: Advances in Interpretable Machine Learning and Artificial Intelligence](https://doi.org/10.1145/3511808.3557491) |  | 0 |  | Adrien Bibal, Tassadit Bouadi, Benoît Frénay, Luis Galárraga, José Oramas |  |
|  |  [THECOG 2022 - Transforms In Behavioral And Affective Computing (Revisited)](https://doi.org/10.1145/3511808.3557937) |  | 0 |  | Georgios Drakopoulos, Eleanna Kafeza |  |
|  |  [Applied Machine Learning Methods for Time Series Forecasting](https://doi.org/10.1145/3511808.3557492) |  | 0 |  | Linsey Pang, Wei Liu, Lingfei Wu, Kexin Xie, Stephen Guo, Raghav Chalapathy, Musen Wen |  |
|  |  [How Hybrid Work Will Make Work More Intelligent](https://doi.org/10.1145/3511808.3558585) |  | 0 |  | Jaime Teevan |  |
|  |  [Ensemble Learning Methods for Dirty Data](https://doi.org/10.1145/3511808.3558584) |  | 0 |  | Ling Liu |  |
|  |  [AutoForecast: Automatic Time-Series Forecasting Model Selection](https://doi.org/10.1145/3511808.3557241) |  | 0 |  | Mustafa Abdallah, Ryan A. Rossi, Kanak Mahadik, Sungchul Kim, Handong Zhao, Saurabh Bagchi |  |
|  |  [On Smoothed Explanations: Quality and Robustness](https://doi.org/10.1145/3511808.3557409) |  | 0 |  | Ahmad Ajalloeian, SeyedMohsen MoosaviDezfooli, Michalis Vlachos, Pascal Frossard |  |
|  |  [An Accelerated Doubly Stochastic Gradient Method with Faster Explicit Model Identification](https://doi.org/10.1145/3511808.3557234) |  | 0 |  | Runxue Bao, Bin Gu, Heng Huang |  |
|  |  [KRAF: A Flexible Advertising Framework using Knowledge Graph-Enriched Multi-Agent Reinforcement Learning](https://doi.org/10.1145/3511808.3557373) |  | 0 |  | Jose A. AyalaRomero, Péter Mernyei, Bichen Shi, Diego Mazón |  |
|  |  [Memory Graph with Message Rehearsal for Multi-Turn Dialogue Generation](https://doi.org/10.1145/3511808.3557392) |  | 0 |  | Xiaoyu Cai, Yao Fu, Hong Zhao, Weihao Jiang, Shiliang Pu |  |
|  |  [CASA-Net: A Context-Aware Correlation Convolutional Network for Scale-Adaptive Crack Detection](https://doi.org/10.1145/3511808.3557252) |  | 0 |  | Xin Bi, Shining Zhang, Yu Zhang, Lei Hu, Wei Zhang, Wenjing Niu, Ye Yuan, Guoren Wang |  |
|  |  [Samba: Identifying Inappropriate Videos for Young Children on YouTube](https://doi.org/10.1145/3511808.3557442) |  | 0 |  | Le Binh, Rajat Tandon, Chingis Oinar, Jeffrey Liu, Uma Durairaj, Jiani Guo, Spencer Zahabizadeh, Sanjana Ilango, Jeremy Tang, Fred Morstatter, Simon S. Woo, Jelena Mirkovic |  |
|  |  [Learning to Generalize in Heterogeneous Federated Networks](https://doi.org/10.1145/3511808.3557378) |  | 0 |  | Cen Chen, Tiandi Ye, Li Wang, Ming Gao |  |
|  |  [Imitation Learning to Outperform Demonstrators by Directly Extrapolating Demonstrations](https://doi.org/10.1145/3511808.3557357) |  | 0 |  | Yuanying Cai, Chuheng Zhang, Wei Shen, Xiaonan He, Xuyun Zhang, Longbo Huang |  |
|  |  [Towards Self-supervised Learning on Graphs with Heterophily](https://doi.org/10.1145/3511808.3557478) |  | 0 |  | Jingfan Chen, Guanghui Zhu, Yifan Qi, Chunfeng Yuan, Yihua Huang |  |
|  |  [Efficient Second-Order Optimization for Neural Networks with Kernel Machines](https://doi.org/10.1145/3511808.3557307) |  | 0 |  | Yawen Chen, Yile Chen, Jian Chen, Zeyi Wen, Jin Huang |  |
|  |  [GCF-RD: A Graph-based Contrastive Framework for Semi-Supervised Learning on Relational Databases](https://doi.org/10.1145/3511808.3557331) |  | 0 |  | Runjin Chen, Tong Li, Yanyan Shen, Luyu Qiu, Kaidi Li, Caleb Chen Cao |  |
|  |  [ReLAX: Reinforcement Learning Agent Explainer for Arbitrary Predictive Models](https://doi.org/10.1145/3511808.3557429) |  | 0 |  | Ziheng Chen, Fabrizio Silvestri, Jia Wang, He Zhu, Hongshik Ahn, Gabriele Tolomei |  |
|  |  [Explainable Link Prediction in Knowledge Hypergraphs](https://doi.org/10.1145/3511808.3557316) |  | 0 |  | Zirui Chen, Xin Wang, Chenxu Wang, Jianxin Li |  |
|  |  [An Empirical Study on How People Perceive AI-generated Music](https://doi.org/10.1145/3511808.3557235) |  | 0 |  | Hyeshin Chu, Joohee Kim, Seongouk Kim, Hongkyu Lim, Hyunwook Lee, Seungmin Jin, Jongeun Lee, Taehwan Kim, Sungahn Ko |  |
|  |  [Meta-Path-based Fake News Detection Leveraging Multi-level Social Context Information](https://doi.org/10.1145/3511808.3557394) |  | 0 |  | Jian Cui, Kwanwoo Kim, Seung Ho Na, Seungwon Shin |  |
|  |  [AutoXAI: A Framework to Automatically Select the Most Adapted XAI Solution](https://doi.org/10.1145/3511808.3557247) |  | 0 |  | Robin Cugny, Julien Aligon, Max Chevalier, Geoffrey RomanJimenez, Olivier Teste |  |
|  |  [When Should We Use Linear Explanations?](https://doi.org/10.1145/3511808.3557489) |  | 0 |  | Julien Delaunay, Luis Galárraga, Christine Largouët |  |
|  |  [Inductive Knowledge Graph Reasoning for Multi-batch Emerging Entities](https://doi.org/10.1145/3511808.3557361) |  | 0 |  | Yuanning Cui, Yuxin Wang, Zequn Sun, Wenqiang Liu, Yiqiao Jiang, Kexin Han, Wei Hu |  |
|  |  [Scaling Up Maximal k-plex Enumeration](https://doi.org/10.1145/3511808.3557444) |  | 0 |  | Qiangqiang Dai, RongHua Li, Hongchao Qin, Meihao Liao, Guoren Wang |  |
|  |  [Inferring Sensitive Attributes from Model Explanations](https://doi.org/10.1145/3511808.3557362) |  | 0 |  | Vasisht Duddu, Antoine Boutet |  |
|  |  [Higher-order Clustering and Pooling for Graph Neural Networks](https://doi.org/10.1145/3511808.3557353) |  | 0 |  | Alexandre Duval, Fragkiskos D. Malliaros |  |
|  |  [Federated K-Private Set Intersection](https://doi.org/10.1145/3511808.3557321) |  | 0 |  | Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Salman Avestimehr |  |
|  |  [Smart Contract Scams Detection with Topological Data Analysis on Account Interaction](https://doi.org/10.1145/3511808.3557454) |  | 0 |  | Shuhui Fan, Shaojing Fu, Yuchuan Luo, Haoran Xu, Xuyun Zhang, Ming Xu |  |
|  |  [Few-Shot Relational Triple Extraction with Perspective Transfer Network](https://doi.org/10.1145/3511808.3557323) |  | 0 |  | Junbo Fei, Weixin Zeng, Xiang Zhao, Xuanyi Li, Weidong Xiao |  |
|  |  [MonitorLight: Reinforcement Learning-based Traffic Signal Control Using Mixed Pressure Monitoring](https://doi.org/10.1145/3511808.3557400) |  | 0 |  | Zekuan Fang, Fan Zhang, Ting Wang, Xiang Lian, Mingsong Chen |  |
|  |  [MGMAE: Molecular Representation Learning by Reconstructing Heterogeneous Graphs with A High Mask Ratio](https://doi.org/10.1145/3511808.3557395) |  | 0 |  | Jinjia Feng, Zhen Wang, Yaliang Li, Bolin Ding, Zhewei Wei, Hongteng Xu |  |
|  |  [DP-HORUS: Differentially Private Hierarchical Count Histograms under Untrusted Server](https://doi.org/10.1145/3511808.3557295) |  | 0 |  | Congcong Fu, Hui Li, Jian Lou, Jiangtao Cui |  |
|  |  [Modeling Dynamic Heterogeneous Graph and Node Importance for Future Citation Prediction](https://doi.org/10.1145/3511808.3557398) |  | 0 |  | Hao Geng, Deqing Wang, Fuzhen Zhuang, Xuehua Ming, Chenguang Du, Ting Jiang, Haolong Guo, Rui Liu |  |
|  |  [Consistent, Balanced, and Overlapping Label Trees for Extreme Multi-label Learning](https://doi.org/10.1145/3511808.3557261) |  | 0 |  | Zhiqi Ge, Yuanyuan Guan, Ximing Li, Bo Fu |  |
|  |  [PromptORE - A Novel Approach Towards Fully Unsupervised Relation Extraction](https://doi.org/10.1145/3511808.3557422) |  | 0 |  | PierreYves Genest, PierreEdouard Portier, Elöd EgyedZsigmond, LaurentWalter Goix |  |
|  |  [Robust Recurrent Classifier Chains for Multi-Label Learning with Missing Labels](https://doi.org/10.1145/3511808.3557438) |  | 0 |  | Walter Gerych, Thomas Hartvigsen, Luke Buquicchio, Emmanuel Agu, Elke A. Rundensteiner |  |
|  |  [Spatio-temporal Trajectory Learning using Simulation Systems](https://doi.org/10.1145/3511808.3557457) |  | 0 |  | Daniel Glake, Fabian Panse, Ulfia Lenfers, Thomas Clemen, Norbert Ritter |  |
|  |  [Gromov-Wasserstein Multi-modal Alignment and Clustering](https://doi.org/10.1145/3511808.3557339) |  | 0 |  | Fengjiao Gong, Yuzhou Nie, Hongteng Xu |  |
|  |  [Learning Hypersphere for Few-shot Anomaly Detection on Attributed Networks](https://doi.org/10.1145/3511808.3557377) |  | 0 |  | Qiuyu Guo, Xiang Zhao, Yang Fang, Shiyu Yang, Xuemin Lin, Dian Ouyang |  |
|  |  [KiCi: A Knowledge Importance Based Class Incremental Learning Method for Wearable Activity Recognition](https://doi.org/10.1145/3511808.3557371) |  | 0 |  | Shuai Guo, Yang Gu, Shijie Wen, Yuan Ma, Yiqiang Chen, Jiwei Wang, Chunyu Hu |  |
|  |  [RAGUEL: Recourse-Aware Group Unfairness Elimination](https://doi.org/10.1145/3511808.3557424) |  | 0 |  | Aparajita Haldar, Teddy Cunningham, Hakan Ferhatosmanoglu |  |
|  |  [Bootstrap-based Causal Structure Learning](https://doi.org/10.1145/3511808.3557249) |  | 0 |  | Xianjie Guo, Yujie Wang, Xiaoling Huang, Shuai Yang, Kui Yu |  |
|  |  [Stop&Hop: Early Classification of Irregular Time Series](https://doi.org/10.1145/3511808.3557460) |  | 0 |  | Thomas Hartvigsen, Walter Gerych, Jidapa Thadajarassiri, Xiangnan Kong, Elke A. Rundensteiner |  |
|  |  [Modeling Diverse Chemical Reactions for Single-step Retrosynthesis via Discrete Latent Variables](https://doi.org/10.1145/3511808.3557397) |  | 0 |  | Huarui He, Jie Wang, Yunfei Liu, Feng Wu |  |
|  |  [Prediction-based One-shot Dynamic Parking Pricing](https://doi.org/10.1145/3511808.3557421) |  | 0 |  | Seoyoung Hong, Heejoo Shin, Jeongwhan Choi, Noseong Park |  |
|  |  [Can We Have Both Fish and Bear's Paw?: Improving Performance, Reliability, and both of them for Relation Extraction under Label Shift](https://doi.org/10.1145/3511808.3557251) |  | 0 |  | Yu Hong, Zhixu Li, Jianfeng Qu, Jiaqing Liang, Yi Luo, Miyu Zhang, Yanghua Xiao, Wei Wang |  |
|  |  [One Rating to Rule Them All?: Evidence of Multidimensionality in Human Assessment of Topic Labeling Quality](https://doi.org/10.1145/3511808.3557410) |  | 0 |  | Amin Hosseiny Marani, Joshua Levine, Eric P. S. Baumer |  |
|  |  [Introducing Neural Bag of Whole-Words with ColBERTer: Contextualized Late Interactions using Enhanced Reduction](https://doi.org/10.1145/3511808.3557367) |  | 0 |  | Sebastian Hofstätter, Omar Khattab, Sophia Althammer, Mete Sertkan, Allan Hanbury |  |
|  |  [Towards Federated Learning against Noisy Labels via Local Self-Regularization](https://doi.org/10.1145/3511808.3557475) |  | 0 |  | Xuefeng Jiang, Sheng Sun, Yuwei Wang, Min Liu |  |
|  |  [X-GOAL: Multiplex Heterogeneous Graph Prototypical Contrastive Learning](https://doi.org/10.1145/3511808.3557490) |  | 0 |  | Baoyu Jing, Shengyu Feng, Yuejia Xiang, Xi Chen, Yu Chen, Hanghang Tong |  |
|  |  [Sharper Utility Bounds for Differentially Private Models: Smooth and Non-smooth](https://doi.org/10.1145/3511808.3557451) |  | 0 |  | Yilin Kang, Yong Liu, Jian Li, Weiping Wang |  |
|  |  [FedRN: Exploiting k-Reliable Neighbors Towards Robust Federated Learning](https://doi.org/10.1145/3511808.3557322) |  | 0 |  | Sangmook Kim, Wonyoung Shin, Soohyuk Jang, Hwanjun Song, SeYoung Yun |  |
|  |  [Residual Correction in Real-Time Traffic Forecasting](https://doi.org/10.1145/3511808.3557432) |  | 0 |  | Daejin Kim, Youngin Cho, Dongmin Kim, Cheonbok Park, Jaegul Choo |  |
|  |  [Loyalty-based Task Assignment in Spatial Crowdsourcing](https://doi.org/10.1145/3511808.3557383) |  | 0 |  | Tinghao Lai, Yan Zhao, Weizhu Qian, Kai Zheng |  |
|  |  [Legal Charge Prediction via Bilinear Attention Network](https://doi.org/10.1145/3511808.3557379) |  | 0 |  | Yuquan Le, Yuming Zhao, Meng Chen, Zhe Quan, Xiaodong He, Kenli Li |  |
|  |  [Accelerating CNN via Dynamic Pattern-based Pruning Network](https://doi.org/10.1145/3511808.3557225) |  | 0 |  | Gwanghan Lee, Saebyeol Shin, Simon S. Woo |  |
|  |  [Relational Self-Supervised Learning on Graphs](https://doi.org/10.1145/3511808.3557428) |  | 0 |  | Namkyeong Lee, Dongmin Hyun, Junseok Lee, Chanyoung Park |  |
|  |  [Automated Spatio-Temporal Synchronous Modeling with Multiple Graphs for Traffic Prediction](https://doi.org/10.1145/3511808.3557243) |  | 0 |  | Fuxian Li, Huan Yan, Guangyin Jin, Yue Liu, Yong Li, Depeng Jin |  |
|  |  [Parallel Skyline Processing Using Space Pruning on GPU](https://doi.org/10.1145/3511808.3557414) |  | 0 |  | Chuanwen Li, Yu Gu, Jianzhong Qi, Ge Yu |  |
|  |  [SK2: Integrating Implicit Sentiment Knowledge and Explicit Syntax Knowledge for Aspect-Based Sentiment Analysis](https://doi.org/10.1145/3511808.3557452) |  | 0 |  | Jia Li, Yuyuan Zhao, Zhi Jin, Ge Li, Tao Shen, Zhengwei Tao, Chongyang Tao |  |
|  |  [SPOT: Knowledge-Enhanced Language Representations for Information Extraction](https://doi.org/10.1145/3511808.3557459) |  | 0 |  | Jiacheng Li, Yannis Katsis, Tyler Baldwin, HoCheol Kim, Andrew Bartko, Julian J. McAuley, ChunNan Hsu |  |
|  |  [Multi-agent Transformer Networks for Multimodal Human Activity Recognition](https://doi.org/10.1145/3511808.3557402) |  | 0 |  | Jingcheng Li, Lina Yao, Binghao Li, Xianzhi Wang, Claude Sammut |  |
|  |  [AdaDebunk: An Efficient and Reliable Deep State Space Model for Adaptive Fake News Early Detection](https://doi.org/10.1145/3511808.3557227) |  | 0 |  | Ke Li, Bin Guo, Siyuan Ren, Zhiwen Yu |  |
|  |  [Heterogeneous Graph Attention Network for Drug-Target Interaction Prediction](https://doi.org/10.1145/3511808.3557346) |  | 0 |  | Mei Li, Xiangrui Cai, Linyu Li, Sihan Xu, Hua Ji |  |
|  |  [TrajFormer: Efficient Trajectory Classification with Transformers](https://doi.org/10.1145/3511808.3557481) |  | 0 |  | Yuxuan Liang, Kun Ouyang, Yiwei Wang, Xu Liu, Hongyang Chen, Junbo Zhang, Yu Zheng, Roger Zimmermann |  |
|  |  [Task Assignment with Federated Preference Learning in Spatial Crowdsourcing](https://doi.org/10.1145/3511808.3557465) |  | 0 |  | Jiaxin Liu, Liwei Deng, Hao Miao, Yan Zhao, Kai Zheng |  |
|  |  [DA-Net: Distributed Attention Network for Temporal Knowledge Graph Reasoning](https://doi.org/10.1145/3511808.3557280) |  | 0 |  | Kangzheng Liu, Feng Zhao, Hongxu Chen, Yicong Li, Guandong Xu, Hai Jin |  |
|  |  [Predicting Intraoperative Hypoxemia with Hybrid Inference Sequence Autoencoder Networks](https://doi.org/10.1145/3511808.3557420) |  | 0 |  | Hanyang Liu, Michael Montana, Dingwen Li, Chase Renfroe, Thomas George Kannampallil, Chenyang Lu |  |
|  |  [Unsupervised Hierarchical Graph Pooling via Substructure-Sensitive Mutual Information Maximization](https://doi.org/10.1145/3511808.3557485) |  | 0 |  | Ning Liu, Songlei Jian, Dongsheng Li, Hongzuo Xu |  |
|  |  [HeGA: Heterogeneous Graph Aggregation Network for Trajectory Prediction in High-Density Traffic](https://doi.org/10.1145/3511808.3557345) |  | 0 |  | Shuncheng Liu, Xu Chen, Ziniu Wu, Liwei Deng, Han Su, Kai Zheng |  |
|  |  [Social Graph Transformer Networks for Pedestrian Trajectory Prediction in Complex Social Scenarios](https://doi.org/10.1145/3511808.3557455) |  | 0 |  | Yao Liu, Lina Yao, Binghao Li, Xianzhi Wang, Claude Sammut |  |
|  |  [Are Gradients on Graph Structure Reliable in Gray-box Attacks?](https://doi.org/10.1145/3511808.3557238) |  | 0 |  | Zihan Liu, Yun Luo, Lirong Wu, Siyuan Li, Zicheng Liu, Stan Z. Li |  |
|  |  [Faithful Abstractive Summarization via Fact-aware Consistency-constrained Transformer](https://doi.org/10.1145/3511808.3557319) |  | 0 |  | Yuanjie Lyu, Chen Zhu, Tong Xu, Zikai Yin, Enhong Chen |  |
|  |  [DEMO: Disentangled Molecular Graph Generation via an Invertible Flow Model](https://doi.org/10.1145/3511808.3557217) |  | 0 |  | Changsheng Ma, Qiang Yang, Xin Gao, Xiangliang Zhang |  |
|  |  [Knowledge-Sensed Cognitive Diagnosis for Intelligent Education Platforms](https://doi.org/10.1145/3511808.3557372) |  | 0 |  | Haiping Ma, Manwei Li, Le Wu, Haifeng Zhang, Yunbo Cao, Xingyi Zhang, Xuemin Zhao |  |
|  |  [Towards Robust False Information Detection on Social Networks with Contrastive Learning](https://doi.org/10.1145/3511808.3557477) |  | 0 |  | Guanghui Ma, Chunming Hu, Ling Ge, Junfan Chen, Hong Zhang, Richong Zhang |  |
|  |  [MORN: Molecular Property Prediction Based on Textual-Topological-Spatial Multi-View Learning](https://doi.org/10.1145/3511808.3557401) |  | 0 |  | Runze Ma, Yidan Zhang, Xinye Wang, Zhenyang Yu, Lei Duan |  |
|  |  [Hierarchical Spatio-Temporal Graph Neural Networks for Pandemic Forecasting](https://doi.org/10.1145/3511808.3557350) |  | 0 |  | Yihong Ma, Patrick Gérard, Yijun Tian, Zhichun Guo, Nitesh V. Chawla |  |
|  |  [Jointly Contrastive Representation Learning on Road Network and Trajectory](https://doi.org/10.1145/3511808.3557370) |  | 0 |  | Zhenyu Mao, Ziyue Li, Dedong Li, Lei Bai, Rui Zhao |  |
|  |  [Mining Reaction and Diffusion Dynamics in Social Activities](https://doi.org/10.1145/3511808.3557396) |  | 0 |  | Taichi Murayama, Yasuko Matsubara, Yasushi Sakurai, None None |  |
|  |  [Rationale Aware Contrastive Learning Based Approach to Classify and Summarize Crisis-Related Microblogs](https://doi.org/10.1145/3511808.3557426) |  | 0 |  | Thi Huyen Nguyen, Koustav Rudra |  |
|  |  [Sequence Prediction under Missing Data: An RNN Approach without Imputation](https://doi.org/10.1145/3511808.3557449) |  | 0 |  | Soumen Pachal, Avinash Achar |  |
|  |  [MetaTrader: An Reinforcement Learning Approach Integrating Diverse Policies for Portfolio Optimization](https://doi.org/10.1145/3511808.3557363) |  | 0 |  | Hui Niu, Siyuan Li, Jian Li |  |
|  |  [Analysis of Knowledge Transfer in Kernel Regime](https://doi.org/10.1145/3511808.3557237) |  | 0 |  | Ashkan Panahi, Arman Rahbar, Chiranjib Bhattacharyya, Devdatt P. Dubhashi, Morteza Haghir Chehreghani |  |
|  |  [Malicious Repositories Detection with Adversarial Heterogeneous Graph Contrastive Learning](https://doi.org/10.1145/3511808.3557384) |  | 0 |  | Yiyue Qian, Yiming Zhang, Nitesh V. Chawla, Yanfang Ye, Chuxu Zhang |  |
|  |  [Reinforced Continual Learning for Graphs](https://doi.org/10.1145/3511808.3557427) |  | 0 |  | Appan Rakaraddi, SiewKei Lam, Mahardhika Pratama, Marcus de Carvalho |  |
|  |  [From Known to Unknown: Quality-aware Self-improving Graph Neural Network For Open Set Social Event Detection](https://doi.org/10.1145/3511808.3557329) |  | 0 |  | Jiaqian Ren, Lei Jiang, Hao Peng, Yuwei Cao, Jia Wu, Philip S. Yu, Lifang He |  |
|  |  [Flow-based Perturbation for Cause-effect Inference](https://doi.org/10.1145/3511808.3557326) |  | 0 |  | Shaogang Ren, Ping Li |  |
|  |  [Deep Extreme Mixture Model for Time Series Forecasting](https://doi.org/10.1145/3511808.3557282) |  | 0 |  | Abilasha S, Sahely Bhadra, Ahmed Zaheer Dadarkar, Deepak P |  |
|  |  [Perturbation Effect: A Metric to Counter Misleading Validation of Feature Attribution](https://doi.org/10.1145/3511808.3557418) |  | 0 |  | Ilija Simic, Vedran Sabol, Eduardo E. Veas |  |
|  |  [A Self-supervised Riemannian GNN with Time Varying Curvature for Temporal Graph Learning](https://doi.org/10.1145/3511808.3557222) |  | 0 |  | Li Sun, Junda Ye, Hao Peng, Philip S. Yu |  |
|  |  [Position-aware Structure Learning for Graph Topology-imbalance by Relieving Under-reaching and Over-squashing](https://doi.org/10.1145/3511808.3557419) |  | 0 |  | Qingyun Sun, Jianxin Li, Haonan Yuan, Xingcheng Fu, Hao Peng, Cheng Ji, Qian Li, Philip S. Yu |  |
|  |  [DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture Fleeting Intraday Trading Opportunities](https://doi.org/10.1145/3511808.3557283) |  | 0 |  | Shuo Sun, Wanqi Xue, Rundong Wang, Xu He, Junlei Zhu, Jian Li, Bo An |  |
|  |  [Serpens: Privacy-Preserving Inference through Conditional Separable of Convolutional Neural Networks](https://doi.org/10.1145/3511808.3557450) |  | 0 |  | Longlong Sun, Hui Li, Yanguo Peng, Jiangtao Cui |  |
|  |  [RobustFed: A Truth Inference Approach for Robust Federated Learning](https://doi.org/10.1145/3511808.3557439) |  | 0 |  | Farnaz Tahmasebian, Jian Lou, Li Xiong |  |
|  |  [Temporality- and Frequency-aware Graph Contrastive Learning for Temporal Network](https://doi.org/10.1145/3511808.3557469) |  | 0 |  | Shiyin Tan, Jingyi You, Dongyuan Li |  |
|  |  [Dr. Can See: Towards a Multi-modal Disease Diagnosis Virtual Assistant](https://doi.org/10.1145/3511808.3557296) |  | 0 |  | Abhisek Tiwari, Manisimha Manthena, Sriparna Saha, Pushpak Bhattacharyya, Minakshi Dhar, Sarbajeet Tiwari |  |
|  |  [A Context-Enhanced Generate-then-Evaluate Framework for Chinese Abbreviation Prediction](https://doi.org/10.1145/3511808.3557219) |  | 0 |  | Hanwen Tong, Chenhao Xie, Jiaqing Liang, Qianyu He, Zhiang Yue, Jingping Liu, Yanghua Xiao, Wenguang Wang |  |
|  |  [Adaptive Multi-Source Causal Inference from Observational Data](https://doi.org/10.1145/3511808.3557230) |  | 0 |  | Thanh Vinh Vo, Pengfei Wei, Trong Nghia Hoang, TzeYun Leong |  |
|  |  [Intersection of Parallels as an Early Stopping Criterion](https://doi.org/10.1145/3511808.3557366) |  | 0 |  | Ali Vardasbi, Maarten de Rijke, Mostafa Dehghani |  |
|  |  [Modeling Inter-Dependence Between Time and Mark in Multivariate Temporal Point Processes](https://doi.org/10.1145/3511808.3557399) |  | 0 |  | Govind Waghmare, Ankur Debnath, Siddhartha Asthana, Aakarsh Malhotra |  |
|  |  [ChiQA: A Large Scale Image-based Real-World Question Answering Dataset for Multi-Modal Understanding](https://doi.org/10.1145/3511808.3557258) |  | 0 |  | Bingning Wang, Feiyang Lv, Ting Yao, Jin Ma, Yu Luo, Haijin Liang |  |
|  |  [Generative-Free Urban Flow Imputation](https://doi.org/10.1145/3511808.3557334) |  | 0 |  | Senzhang Wang, Jiyue Li, Hao Miao, Junbo Zhang, Junxing Zhu, Jianxin Wang |  |
|  |  [Interpretable Emotion Analysis Based on Knowledge Graph and OCC Model](https://doi.org/10.1145/3511808.3557365) |  | 0 |  | Shuo Wang, Yifei Zhang, Bochen Lin, Boxun Li |  |
|  |  [Imbalanced Graph Classification via Graph-of-Graph Neural Networks](https://doi.org/10.1145/3511808.3557356) |  | 0 |  | Yu Wang, Yuying Zhao, Neil Shah, Tyler Derr |  |
|  |  [Dynamic Transfer Gaussian Process Regression](https://doi.org/10.1145/3511808.3557303) |  | 0 |  | Pengfei Wei, Xinghua Qu, Wen Song, Zejun Ma |  |
|  |  [RelpNet: Relation-based Link Prediction Neural Network](https://doi.org/10.1145/3511808.3557430) |  | 0 |  | Ensen Wu, Hongyan Cui, Zunming Chen |  |
|  |  [Incorporating Peer Reviews and Rebuttal Counter-Arguments for Meta-Review Generation](https://doi.org/10.1145/3511808.3557360) |  | 0 |  | PoCheng Wu, AnZi Yen, HenHsen Huang, HsinHsi Chen |  |
|  |  [RISE: A Velocity Control Framework with Minimal Impacts based on Reinforcement Learning](https://doi.org/10.1145/3511808.3557435) |  | 0 |  | Yuyang Xia, Shuncheng Liu, Xu Chen, Zhi Xu, Kai Zheng, Han Su |  |
|  |  [MARINA: An MLP-Attention Model for Multivariate Time-Series Analysis](https://doi.org/10.1145/3511808.3557386) |  | 0 |  | Jiandong Xie, Yue Cui, Feiteng Huang, Chao Liu, Kai Zheng |  |
|  |  [AutoQGS: Auto-Prompt for Low-Resource Knowledge-based Question Generation from SPARQL](https://doi.org/10.1145/3511808.3557246) |  | 0 |  | Guanming Xiong, Junwei Bao, Wen Zhao, Youzheng Wu, Xiaodong He |  |
|  |  [Taxonomy-Enhanced Graph Neural Networks](https://doi.org/10.1145/3511808.3557467) |  | 0 |  | Lingjun Xu, Shiyin Zhang, Guojie Song, Junshan Wang, Tianshu Wu, Guojun Liu |  |
|  |  [Traffic Speed Imputation with Spatio-Temporal Attentions and Cycle-Perceptual Training](https://doi.org/10.1145/3511808.3557480) |  | 0 |  | Qianxiong Xu, Sijie Ruan, Cheng Long, Liang Yu, Chen Zhang |  |
|  |  [Evidence-aware Document-level Relation Extraction](https://doi.org/10.1145/3511808.3557313) |  | 0 |  | Tianyu Xu, Wen Hua, Jianfeng Qu, Zhixu Li, Jiajie Xu, An Liu, Lei Zhao |  |
|  |  [Effects of Stubbornness on Opinion Dynamics](https://doi.org/10.1145/3511808.3557304) |  | 0 |  | Wanyue Xu, Liwang Zhu, Jiale Guan, Zuobai Zhang, Zhongzhi Zhang |  |
|  |  [Drive Less but Finish More: Food Delivery based on Multi-Level Workers in Spatial Crowdsourcing](https://doi.org/10.1145/3511808.3557297) |  | 0 |  | Xiaojia Xu, An Liu, Guanfeng Liu, Zhixu Li, Lei Zhao |  |
|  |  [Dissecting Cross-Layer Dependency Inference on Multi-Layered Inter-Dependent Networks](https://doi.org/10.1145/3511808.3557291) |  | 0 |  | Yuchen Yan, Qinghai Zhou, Jinning Li, Tarek F. Abdelzaher, Hanghang Tong |  |
|  |  [Semi-supervised Hypergraph Node Classification on Hypergraph Line Expansion](https://doi.org/10.1145/3511808.3557447) |  | 0 |  | Chaoqi Yang, Ruijie Wang, Shuochao Yao, Tarek F. Abdelzaher |  |
|  |  [GROWN+UP: A "Graph Representation Of a Webpage" Network Utilizing Pre-training](https://doi.org/10.1145/3511808.3557340) |  | 0 |  | Benedict Yeoh, Huijuan Wang |  |
|  |  [Cognize Yourself: Graph Pre-Training via Core Graph Cognizing and Differentiating](https://doi.org/10.1145/3511808.3557259) |  | 0 |  | Tao Yu, Yao Fu, Linghui Hu, Huizhao Wang, Weihao Jiang, Shiliang Pu |  |
|  |  [LTE4G: Long-Tail Experts for Graph Neural Networks](https://doi.org/10.1145/3511808.3557381) |  | 0 |  | Sukwon Yun, Kibum Kim, Kanghoon Yoon, Chanyoung Park |  |
|  |  [Joint Clothes Detection and Attribution Prediction via Anchor-free Framework with Decoupled Representation Transformer](https://doi.org/10.1145/3511808.3557369) |  | 0 |  | Fankai Zeng, Mingbo Zhao, Zhao Zhang, Shanchuan Gao, Lu Cheng |  |
|  |  [Causal Learning Empowered OD Prediction for Urban Planning](https://doi.org/10.1145/3511808.3557255) |  | 0 |  | Jinwei Zeng, Guozhen Zhang, Can Rong, Jingtao Ding, Jian Yuan, Yong Li |  |
|  |  [Interactive Contrastive Learning for Self-Supervised Entity Alignment](https://doi.org/10.1145/3511808.3557364) |  | 0 |  | Kaisheng Zeng, Zhenhao Dong, Lei Hou, Yixin Cao, Minghao Hu, Jifan Yu, Xin Lv, Lei Cao, Xin Wang, Haozhuang Liu, Yi Huang, Junlan Feng, Jing Wan, Juanzi Li, Ling Feng |  |
|  |  [Towards Automated Imbalanced Learning with Deep Hierarchical Reinforcement Learning](https://doi.org/10.1145/3511808.3557474) |  | 0 |  | Daochen Zha, KweiHerng Lai, Qiaoyu Tan, Sirui Ding, Na Zou, Xia Ben Hu |  |
|  |  [TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis](https://doi.org/10.1145/3511808.3557470) |  | 0 |  | Chaoli Zhang, Tian Zhou, Qingsong Wen, Liang Sun |  |
|  |  [Look Twice as Much as You Say: Scene Graph Contrastive Learning for Self-Supervised Image Caption Generation](https://doi.org/10.1145/3511808.3557382) |  | 0 |  | Chunhui Zhang, Chao Huang, Youhuan Li, Xiangliang Zhang, Yanfang Ye, Chuxu Zhang |  |
|  |  [Dismantling Complex Networks by a Neural Model Trained from Tiny Networks](https://doi.org/10.1145/3511808.3557290) |  | 0 |  | Jiazheng Zhang, Bang Wang |  |
|  |  [Disentangled Representation for Long-tail Senses of Word Sense Disambiguation](https://doi.org/10.1145/3511808.3557288) |  | 0 |  | Junwei Zhang, Ruifang He, Fengyu Guo, Jinsong Ma, Mengnan Xiao |  |
|  |  [Contrastive Knowledge Graph Error Detection](https://doi.org/10.1145/3511808.3557264) |  | 0 |  | Qinggang Zhang, Junnan Dong, Keyu Duan, Xiao Huang, Yezi Liu, Linchuan Xu |  |
|  |  [Unsupervised Representation Learning on Attributed Multiplex Network](https://doi.org/10.1145/3511808.3557486) |  | 0 |  | Rui Zhang, Arthur Zimek, Peter SchneiderKamp |  |
|  |  [Automating DBSCAN via Deep Reinforcement Learning](https://doi.org/10.1145/3511808.3557245) |  | 0 |  | Ruitong Zhang, Hao Peng, Yingtong Dou, Jia Wu, Qingyun Sun, Yangyang Li, Jingyi Zhang, Philip S. Yu |  |
|  |  [CPEE: Civil Case Judgment Prediction centering on the Trial Mode of Essential Elements](https://doi.org/10.1145/3511808.3557273) |  | 0 |  | Lili Zhao, Linan Yue, Yanqing An, Yuren Zhang, Jun Yu, Qi Liu, Enhong Chen |  |
|  |  [End-to-end Modularity-based Community Co-partition in Bipartite Networks](https://doi.org/10.1145/3511808.3557309) |  | 0 |  | Cangqi Zhou, Yuxiang Wang, Jing Zhang, Jiqiong Jiang, Dianming Hu |  |
|  |  [MentorGNN: Deriving Curriculum for Pre-Training GNNs](https://doi.org/10.1145/3511808.3557393) |  | 0 |  | Dawei Zhou, Lecheng Zheng, Dongqi Fu, Jiawei Han, Jingrui He |  |
|  |  [D-HYPR: Harnessing Neighborhood Modeling and Asymmetry Preservation for Digraph Representation Learning](https://doi.org/10.1145/3511808.3557344) |  | 0 |  | Honglu Zhou, Advith Chegu, Samuel S. Sohn, Zuohui Fu, Gerard de Melo, Mubbasir Kapadia |  |
|  |  [Robust Node Classification on Graphs: Jointly from Bayesian Label Transition and Topology-based Label Propagation](https://doi.org/10.1145/3511808.3557437) |  | 0 |  | Jun Zhuang, Mohammad Al Hasan |  |
|  |  [Efficient and Effective SPARQL Autocompletion on Very Large Knowledge Graphs](https://doi.org/10.1145/3511808.3557093) |  | 0 |  | Hannah Bast, Johannes Kalmbach, Theresa Klumpp, Florian Kramer, Niklas Schnelle |  |
|  |  [Graph Neural Networks Pretraining Through Inherent Supervision for Molecular Property Prediction](https://doi.org/10.1145/3511808.3557085) |  | 0 |  | Roy Benjamin, Uriel Singer, Kira Radinsky |  |
|  |  [Fooling MOSS Detection with Pretrained Language Models](https://doi.org/10.1145/3511808.3557079) |  | 0 |  | Stella Biderman, Edward Raff |  |
|  |  [A Context-Enhanced Transformer with Abbr-Recover Policy for Chinese Abbreviation Prediction](https://doi.org/10.1145/3511808.3557074) |  | 0 |  | Kaiyan Cao, Deqing Yang, Jingping Liu, Jiaqing Liang, Yanghua Xiao, Feng Wei, Baohua Wu, Quan Lu |  |
|  |  [Numerical Feature Representation with Hybrid N-ary Encoding](https://doi.org/10.1145/3511808.3557090) |  | 0 |  | Bo Chen, Huifeng Guo, Weiwen Liu, Yue Ding, Yunzhe Li, Wei Guo, Yichao Wang, Zhicheng He, Ruiming Tang, Rui Zhang |  |
|  |  [ReLiable: Offline Reinforcement Learning for Tactical Strategies in Professional Basketball Games](https://doi.org/10.1145/3511808.3557105) |  | 0 |  | Xiusi Chen, JyunYu Jiang, Kun Jin, Yichao Zhou, Mingyan Liu, P. Jeffrey Brantingham, Wei Wang |  |
|  |  [Hierarchical Capsule Prediction Network for Marketing Campaigns Effect](https://doi.org/10.1145/3511808.3557099) |  | 0 |  | Zhixuan Chu, Hui Ding, Guang Zeng, Yuchen Huang, Tan Yan, Yulin Kang, Sheng Li |  |
|  |  [Detecting Environmental Violations with Satellite Imagery in Near Real Time: Land Application under the Clean Water Act](https://doi.org/10.1145/3511808.3557104) |  | 0 |  | Ben Chugg, Nicolas Rothbacher, Alex Feng, Xiaoqi Long, Daniel E. Ho |  |
|  |  [Towards Practical Large Scale Non-Linear Semi-Supervised Learning with Balancing Constraints](https://doi.org/10.1145/3511808.3557150) |  | 0 |  | Zhengqing Gao, Huimin Wu, Martin Takác, Bin Gu |  |
|  |  [Towards Fairer Classifier via True Fairness Score Path](https://doi.org/10.1145/3511808.3557109) |  | 0 |  | Bin Gu, Zhou Zhai, Xiang Li, Heng Huang |  |
|  |  [Sentaur: Sensor Observable Data Model for Smart Spaces](https://doi.org/10.1145/3511808.3557147) |  | 0 |  | Peeyush Gupta, Sharad Mehrotra, Shantanu Sharma, Roberto Yus, Nalini Venkatasubramanian |  |
|  |  [DuETA: Traffic Congestion Propagation Pattern Modeling via Efficient Graph Learning for ETA Prediction at Baidu Maps](https://doi.org/10.1145/3511808.3557091) |  | 0 |  | Jizhou Huang, Zhengjie Huang, Xiaomin Fang, Shikun Feng, Xuyi Chen, Jiaxiang Liu, Haitao Yuan, Haifeng Wang |  |
|  |  [Bridging Self-Attention and Time Series Decomposition for Periodic Forecasting](https://doi.org/10.1145/3511808.3557077) |  | 0 |  | Song Jiang, Tahin Syed, Xuan Zhu, Joshua Levy, Boris Aronchik, Yizhou Sun |  |
|  |  [RaDaR: A Real-Word Dataset for AI powered Run-time Detection of Cyber-Attacks](https://doi.org/10.1145/3511808.3557121) |  | 0 |  | Sareena Karapoola, Nikhilesh Singh, Chester Rebeiro, V. Kamakoti |  |
|  |  [An Adaptive Framework for Confidence-constraint Rule Set Learning Algorithm in Large Dataset](https://doi.org/10.1145/3511808.3557088) |  | 0 |  | Meng Li, Lu Yu, YaLin Zhang, Xiaoguang Huang, Qitao Shi, Qing Cui, Xinxing Yang, Longfei Li, Wei Zhu, Yanming Fang, Jun Zhou |  |
|  |  [Cognitive Diagnosis Focusing on Knowledge Concepts](https://doi.org/10.1145/3511808.3557096) |  | 0 |  | Sheng Li, Quanlong Guan, Liangda Fang, Fang Xiao, Zhenyu He, Yizhou He, Weiqi Luo |  |
|  |  [Predicting Multi-level Socioeconomic Indicators from Structural Urban Imagery](https://doi.org/10.1145/3511808.3557153) |  | 0 |  | Tong Li, Shiduo Xin, Yanxin Xi, Sasu Tarkoma, Pan Hui, Yong Li |  |
|  |  [BRIGHT - Graph Neural Networks in Real-time Fraud Detection](https://doi.org/10.1145/3511808.3557136) |  | 0 |  | Mingxuan Lu, Zhichao Han, Susie Xi Rao, Zitao Zhang, Yang Zhao, Yinan Shan, Ramesh Raghunathan, Ce Zhang, Jiawei Jiang |  |
|  |  [Towards Fair Workload Assessment via Homogeneous Order Grouping in Last-mile Delivery](https://doi.org/10.1145/3511808.3557132) |  | 0 |  | Wenjun Lyu, Kexin Zhang, Baoshen Guo, Zhiqing Hong, Guang Yang, Guang Wang, Yu Yang, Yunhuai Liu, Desheng Zhang |  |
|  |  [Observability of SQL Hints in Oracle](https://doi.org/10.1145/3511808.3557124) |  | 0 |  | Krishna Kantikiran Pasupuleti, Dinesh Das, Satyanarayana R. Valluri, Mohamed Zaït |  |
|  |  [Sub-Task Imputation via Self-Labelling to Train Image Moderation Models on Sparse Noisy Data](https://doi.org/10.1145/3511808.3557149) |  | 0 |  | Indraneil Paul, Sumit Negi |  |
|  |  [MOOMIN: Deep Molecular Omics Network for Anti-Cancer Drug Combination Therapy](https://doi.org/10.1145/3511808.3557146) |  | 0 |  | Benedek Rozemberczki, Anna Gogleva, Sebastian Nilsson, Gavin Edwards, Andriy Nikolov, Eliseo Papa |  |
|  |  [PEMP: Leveraging Physics Properties to Enhance Molecular Property Prediction](https://doi.org/10.1145/3511808.3557142) |  | 0 |  | Yuancheng Sun, Yimeng Chen, Weizhi Ma, Wenhao Huang, Kang Liu, Zhiming Ma, WeiYing Ma, Yanyan Lan |  |
|  |  [Selective Tensorized Multi-layer LSTM for Orbit Prediction](https://doi.org/10.1145/3511808.3557138) |  | 0 |  | Youjin Shin, EunJu Park, Simon S. Woo, Okchul Jung, Daewon Chung |  |
|  |  [WARNER: Weakly-Supervised Neural Network to Identify Eviction Filing Hotspots in the Absence of Court Records](https://doi.org/10.1145/3511808.3557128) |  | 0 |  | Maryam Tabar, Wooyong Jung, Amulya Yadav, Owen Wilson Chavez, Ashley Flores, Dongwon Lee |  |
|  |  [Towards an Awareness of Time Series Anomaly Detection Models' Adversarial Vulnerability](https://doi.org/10.1145/3511808.3557073) |  | 0 |  | Shahroz Tariq, Binh M. Le, Simon S. Woo |  |
|  |  [DuARUS: Automatic Geo-object Change Detection with Street-view Imagery for Updating Road Database at Baidu Maps](https://doi.org/10.1145/3511808.3557118) |  | 0 |  | Deguo Xia, Jizhou Huang, Jianzhong Yang, Xiyan Liu, Haifeng Wang |  |
|  |  [DuTraffic: Live Traffic Condition Prediction with Trajectory Data and Street Views at Baidu Maps](https://doi.org/10.1145/3511808.3557151) |  | 0 |  | Deguo Xia, Xiyan Liu, Wei Zhang, Hui Zhao, Chengzhou Li, Weiming Zhang, Jizhou Huang, Haifeng Wang |  |
|  |  [Temporal and Heterogeneous Graph Neural Network for Financial Time Series Prediction](https://doi.org/10.1145/3511808.3557089) |  | 0 |  | Sheng Xiang, Dawei Cheng, Chencheng Shang, Ying Zhang, Yuqi Liang |  |
|  |  [Multi-Agent Reinforcement Learning for Network Load Balancing in Data Center](https://doi.org/10.1145/3511808.3557133) |  | 0 |  | Zhiyuan Yao, Zihan Ding, Thomas H. Clausen |  |
|  |  [Offline Reinforcement Learning for Mobile Notifications](https://doi.org/10.1145/3511808.3557083) |  | 0 |  | Yiping Yuan, Ajith Muralidharan, Preetam Nandy, Miao Cheng, Prakruthi Prabhakar |  |
|  |  [Hierarchical Reinforcement Learning using Gaussian Random Trajectory Generation in Autonomous Furniture Assembly](https://doi.org/10.1145/3511808.3557078) |  | 0 |  | Won Joon Yun, David Mohaisen, Soyi Jung, JongKook Kim, Joongheon Kim |  |
|  |  [Measuring Friendship Closeness: A Perspective of Social Identity Theory](https://doi.org/10.1145/3511808.3557076) |  | 0 |  | Shiqi Zhang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, Bo Tang |  |
|  |  [Network Report: A Structured Description for Network Datasets](https://doi.org/10.1145/3511808.3557115) |  | 0 |  | Xinyi Zheng, Ryan A. Rossi, Nesreen K. Ahmed, Dominik Moritz |  |
|  |  [A Practical Distributed ADMM Solver for Billion-Scale Generalized Assignment Problems](https://doi.org/10.1145/3511808.3557148) |  | 0 |  | Jun Zhou, Feng Qi, Zhigang Hua, Daohong Jian, Ziqi Liu, Hua Wu |  |
|  |  [Breast Cancer Early Detection with Time Series Classification](https://doi.org/10.1145/3511808.3557107) |  | 0 |  | Haoren Zhu, Pengfei Zhao, YiuPong Chan, Hong Kang, Dik Lun Lee |  |
|  |  [Scaling Up Mass-Based Clustering](https://doi.org/10.1145/3511808.3557691) |  | 0 |  | Nidhi Ahlawat, Amit Awekar |  |
|  |  [Improving Imitation Learning by Merging Experts Trajectories](https://doi.org/10.1145/3511808.3557616) |  | 0 |  | Pegah Alizadeh, Aomar Osmani, Sammy Taleb |  |
|  |  [Interpretability of BERT Latent Space through Knowledge Graphs](https://doi.org/10.1145/3511808.3557617) |  | 0 |  | Vito Walter Anelli, Giovanni Maria Biancofiore, Alessandro De Bellis, Tommaso Di Noia, Eugenio Di Sciascio |  |
|  |  [A Mask-based Output Layer for Multi-level Hierarchical Classification](https://doi.org/10.1145/3511808.3557534) |  | 0 |  | Tanya BooneSifuentes, Mohamed Reda Bouadjenek, Imran Razzak, Hakim Hacid, Asef Nazari |  |
|  |  [Predicting Guiding Entities for Entity Aspect Linking](https://doi.org/10.1145/3511808.3557671) |  | 0 |  | Shubham Chatterjee, Laura Dietz |  |
|  |  [Scalable Graph Representation Learning via Locality-Sensitive Hashing](https://doi.org/10.1145/3511808.3557689) |  | 0 |  | Xiusi Chen, JyunYu Jiang, Wei Wang |  |
|  |  [On Positional and Structural Node Features for Graph Neural Networks on Non-attributed Graphs](https://doi.org/10.1145/3511808.3557661) |  | 0 |  | Hejie Cui, Zijie Lu, Pan Li, Carl Yang |  |
|  |  [OpeNTF: A Benchmark Library for Neural Team Formation](https://doi.org/10.1145/3511808.3557526) |  | 0 |  | Arman Dashti, Karan Saxena, Dhwani Patel, Hossein Fani |  |
|  |  [Semi-Supervised Learning with Data Augmentation for Tabular Data](https://doi.org/10.1145/3511808.3557699) |  | 0 |  | JunPeng Fang, Caizhi Tang, Qing Cui, Feng Zhu, Longfei Li, Jun Zhou, Wei Zhu |  |
|  |  [Adaptive Graph Spatial-Temporal Transformer Network for Traffic Forecasting](https://doi.org/10.1145/3511808.3557540) |  | 0 |  | Aosong Feng, Leandros Tassiulas |  |
|  |  [Subspace Co-clustering with Two-Way Graph Convolution](https://doi.org/10.1145/3511808.3557706) |  | 0 |  | Chakib Fettal, Lazhar Labiod, Mohamed Nadif |  |
|  |  [On the Mining of Time Series Data Counterfactual Explanations using Barycenters](https://doi.org/10.1145/3511808.3557663) |  | 0 |  | Soukaïna Filali Boubrahimi, Shah Muhammad Hamdi |  |
|  |  [Local Contrastive Feature Learning for Tabular Data](https://doi.org/10.1145/3511808.3557630) |  | 0 |  | Zhabiz Gharibshah, Xingquan Zhu |  |
|  |  [Fusing Geometric and Scene Information for Cross-View Geo-Localization](https://doi.org/10.1145/3511808.3557633) |  | 0 |  | Siyuan Guo, Tianying Liu, Wengen Li, Jihong Guan, Shuigeng Zhou |  |
|  |  [OpenHGNN: An Open Source Toolkit for Heterogeneous Graph Neural Network](https://doi.org/10.1145/3511808.3557664) |  | 0 |  | Hui Han, Tianyu Zhao, Cheng Yang, Hongyi Zhang, Yaoqi Liu, Xiao Wang, Chuan Shi |  |
|  |  [Long-tail Mixup for Extreme Multi-label Classification](https://doi.org/10.1145/3511808.3557632) |  | 0 |  | Sangwoo Han, Eunseong Choi, Chan Lim, Hyunjung Shim, Jongwuk Lee |  |
|  |  [Unified Knowledge Prompt Pre-training for Customer Service Dialogues](https://doi.org/10.1145/3511808.3557718) |  | 0 |  | Keqing He, Jingang Wang, Chaobo Sun, Wei Wu |  |
|  |  [Semi-supervised Continual Learning with Meta Self-training](https://doi.org/10.1145/3511808.3557698) |  | 0 |  | Stella Ho, Ming Liu, Lan Du, Yunfeng Li, Longxiang Gao, Shang Gao |  |
|  |  [Extreme Systematic Reviews: A Large Literature Screening Dataset to Support Environmental Policymaking](https://doi.org/10.1145/3511808.3557600) |  | 0 |  | Jingwen Hou, Xiaochen Wang, JeanJacques Dubois, R. Byron Rice, Amanda Haddock, Yue Wang |  |
|  |  [Pattern Adaptive Specialist Network for Learning Trading Patterns in Stock Market](https://doi.org/10.1145/3511808.3557665) |  | 0 |  | Huiling Huang, Jianliang Gao, Cong Xu, Xiaoting Ying |  |
|  |  [LGP: Few-Shot Class-Evolutionary Learning on Dynamic Graphs](https://doi.org/10.1145/3511808.3557627) |  | 0 |  | Tiancheng Huang, Feng Zhao, Donglin Wang |  |
|  |  [An Empirical Study on the Membership Inference Attack against Tabular Data Synthesis Models](https://doi.org/10.1145/3511808.3557546) |  | 0 |  | Jihyeon Hyeong, Jayoung Kim, Noseong Park, Sushil Jajodia |  |
|  |  [NILK: Entity Linking Dataset Targeting NIL-linking Cases](https://doi.org/10.1145/3511808.3557659) |  | 0 |  | Anastasiia Iurshina, Jiaxin Pan, Rafika Boutalbi, Steffen Staab |  |
|  |  [AI-Augmented Art Psychotherapy through a Hierarchical Co-Attention Mechanism](https://doi.org/10.1145/3511808.3557542) |  | 0 |  | Seungwan Jin, Hoyoung Choi, Kyungsik Han |  |
|  |  [Commonsense Knowledge Base Completion with Relational Graph Attention Network and Pre-trained Language Model](https://doi.org/10.1145/3511808.3557564) |  | 0 |  | Jinhao Ju, Deqing Yang, Jingping Liu |  |
|  |  [Convolutional Transformer Networks for Epileptic Seizure Detection](https://doi.org/10.1145/3511808.3557568) |  | 0 |  | Nan Ke, Tong Lin, Zhouchen Lin, XiaoHua Zhou, Taoyun Ji |  |
|  |  [Models and Benchmarks for Representation Learning of Partially Observed Subgraphs](https://doi.org/10.1145/3511808.3557647) |  | 0 |  | Dongkwan Kim, Jiho Jin, Jaimeen Ahn, Alice Oh |  |
|  |  [EEG-Oriented Self-Supervised Learning and Cluster-Aware Adaptation](https://doi.org/10.1145/3511808.3557589) |  | 0 |  | Wonjun Ko, HeungIl Suk |  |
|  |  [Neuron Specific Pruning for Communication Efficient Federated Learning](https://doi.org/10.1145/3511808.3557658) |  | 0 |  | Gaurav Kumar, Durga Toshniwal |  |
|  |  [Do Simpler Statistical Methods Perform Better in Multivariate Long Sequence Time-Series Forecasting?](https://doi.org/10.1145/3511808.3557585) |  | 0 |  | Hao Li, Jie Shao, Kewen Liao, Mingjian Tang |  |
|  |  [Cooperative Max-Pressure Enhanced Traffic Signal Control](https://doi.org/10.1145/3511808.3557569) |  | 0 |  | Lin Li, Renbo Li, Yuquan Peng, Chuanming Huang, Jingling Yuan |  |
|  |  [Dual-Augment Graph Neural Network for Fraud Detection](https://doi.org/10.1145/3511808.3557586) |  | 0 |  | Qiutong Li, Yanshen He, Cong Xu, Feng Wu, Jianliang Gao, Zhao Li |  |
|  |  [An Extreme Semi-supervised Framework Based on Transformer for Network Intrusion Detection](https://doi.org/10.1145/3511808.3557549) |  | 0 |  | Yangmin Li, Xinhang Yuan, Wengen Li |  |
|  |  [Invariance Testing and Feature Selection Using Sparse Linear Layers](https://doi.org/10.1145/3511808.3557550) |  | 0 |  | Zukang Liao, Michael Cheung |  |
|  |  [Learning Rate Perturbation: A Generic Plugin of Learning Rate Schedule towards Flatter Local Minima](https://doi.org/10.1145/3511808.3557626) |  | 0 |  | Hengyu Liu, Qiang Fu, Lun Du, Tiancheng Zhang, Ge Yu, Shi Han, Dongmei Zhang |  |
|  |  [ExpertBert: Pretraining Expert Finding](https://doi.org/10.1145/3511808.3557597) |  | 0 |  | Hongtao Liu, Zhepeng Lv, Qing Yang, Dongliang Xu, Qiyao Peng |  |
|  |  [Memory Augmented Graph Learning Networks for Multivariate Time Series Forecasting](https://doi.org/10.1145/3511808.3557638) |  | 0 |  | Xiangyue Liu, Xinqi Lyu, Xiangchi Zhang, Jianliang Gao, Jiamin Chen |  |
|  |  [MomNet: Gender Prediction using Mechanism of Working Memory](https://doi.org/10.1145/3511808.3557649) |  | 0 |  | Sijie Long, Lin Li, Jingling Yuan, Jianquan Liu |  |
|  |  [Meta-Reinforcement Learning for Multiple Traffic Signals Control](https://doi.org/10.1145/3511808.3557640) |  | 0 |  | Yican Lou, Jia Wu, Yunchuan Ran |  |
|  |  [Scalable Multiple Kernel k-means Clustering](https://doi.org/10.1145/3511808.3557690) |  | 0 |  | Yihang Lu, Haonan Xin, Rong Wang, Feiping Nie, Xuelong Li |  |
|  |  [Self-Paced and Discrete Multiple Kernel k-Means](https://doi.org/10.1145/3511808.3557696) |  | 0 |  | Yihang Lu, Xuan Zheng, Jitao Lu, Rong Wang, Feiping Nie, Xuelong Li |  |
|  |  [Urban Region Profiling via Multi-Graph Representation Learning](https://doi.org/10.1145/3511808.3557720) |  | 0 |  | Yan Luo, FuLai Chung, Kai Chen |  |
|  |  [A Prerequisite Attention Model for Knowledge Proficiency Diagnosis of Students](https://doi.org/10.1145/3511808.3557539) |  | 0 |  | Haiping Ma, Jinwei Zhu, Shangshang Yang, Qi Liu, Haifeng Zhang, Xingyi Zhang, Yunbo Cao, Xuemin Zhao |  |
|  |  [Curriculum Contrastive Learning for Fake News Detection](https://doi.org/10.1145/3511808.3557574) |  | 0 |  | Jiachen Ma, Yong Liu, Meng Liu, Meng Han |  |
|  |  [Robustness of Sketched Linear Classifiers to Adversarial Attacks](https://doi.org/10.1145/3511808.3557687) |  | 0 |  | Ananth Mahadevan, Arpit Merchant, Yanhao Wang, Michael Mathioudakis |  |
|  |  [Locality Aware Temporal FMs for Crime Prediction](https://doi.org/10.1145/3511808.3557657) |  | 0 |  | Sameen Mansha, Abdur Rehman, Shaaf Abdullah, Faisal Kamiran, Hongzhi Yin |  |
|  |  [Not All Neighbors are Friendly: Learning to Choose Hop Features to Improve Node Classification](https://doi.org/10.1145/3511808.3557543) |  | 0 |  | Sunil Kumar Maurya, Xin Liu, Tsuyoshi Murata |  |
|  |  [Expressions Causing Differences in Emotion Recognition in Social Networking Service Documents](https://doi.org/10.1145/3511808.3557599) |  | 0 |  | Tsubasa Nakagawa, Shunsuke Kitada, Hitoshi Iyatomi |  |
|  |  [Locality Sensitive Hashing with Temporal and Spatial Constraints for Efficient Population Record Linkage](https://doi.org/10.1145/3511808.3557631) |  | 0 |  | Charini Nanayakkara, Peter Christen |  |
|  |  [GradAlign+: Empowering Gradual Network Alignment Using Attribute Augmentation](https://doi.org/10.1145/3511808.3557605) |  | 0 |  | JinDuk Park, Cong Tran, WonYong Shin, Xin Cao |  |
|  |  [Improving Graph-based Document-Level Relation Extraction Model with Novel Graph Structure](https://doi.org/10.1145/3511808.3557615) |  | 0 |  | Seongsik Park, Dongkeun Yoon, Harksoo Kim |  |
|  |  [GRETEL: Graph Counterfactual Explanation Evaluation Framework](https://doi.org/10.1145/3511808.3557608) |  | 0 |  | Mario Alfonso PradoRomero, Giovanni Stilo |  |
|  |  [CLNews: The First Dataset of the Chilean Social Outbreak for Disinformation Analysis](https://doi.org/10.1145/3511808.3557560) |  | 0 |  | Eliana Providel, Daniel Toro, Fabián Riquelme, Marcelo Mendoza, Eduardo Puraivan |  |
|  |  [Probabilistic Model Incorporating Auxiliary Covariates to Control FDR](https://doi.org/10.1145/3511808.3557672) |  | 0 |  | Lin Qiu, Nils MurrugarraLlerena, Vítor Silva, Lin Lin, Vernon M. Chinchilli |  |
|  |  [A Model-Centric Explainer for Graph Neural Network based Node Classification](https://doi.org/10.1145/3511808.3557535) |  | 0 |  | Sayan Saha, Monidipa Das, Sanghamitra Bandyopadhyay |  |
|  |  [Cost-constrained Minimal Steiner Tree Enumeration](https://doi.org/10.1145/3511808.3557570) |  | 0 |  | Yuya Sasaki |  |
|  |  [Twin Papers: A Simple Framework of Causal Inference for Citations via Coupling](https://doi.org/10.1145/3511808.3557716) |  | 0 |  | Ryoma Sato, Makoto Yamada, Hisashi Kashima |  |
|  |  [Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting](https://doi.org/10.1145/3511808.3557702) |  | 0 |  | Zezhi Shao, Zhao Zhang, Fei Wang, Wei Wei, Yongjun Xu |  |
|  |  [A Graph-based Spatiotemporal Model for Energy Markets](https://doi.org/10.1145/3511808.3557530) |  | 0 |  | Swati Sharma, Srinivasan Iyengar, Shun Zheng, Kshitij Kapoor, Wei Cao, Jiang Bian, Shivkumar Kalyanaraman, John Lemmon |  |
|  |  [PubMed Author-assigned Keyword Extraction (PubMedAKE) Benchmark](https://doi.org/10.1145/3511808.3557675) |  | 0 |  | Jiasheng Sheng, Zelalem Gero, Joyce C. Ho |  |
|  |  [ST-GAT: A Spatio-Temporal Graph Attention Network for Accurate Traffic Speed Prediction](https://doi.org/10.1145/3511808.3557705) |  | 0 |  | Junho Song, Jiwon Son, Donghyuk Seo, Kyungsik Han, Namhyuk Kim, SangWook Kim |  |
|  |  [Targeted Influence with Community and Gender-Aware Seeding](https://doi.org/10.1145/3511808.3557708) |  | 0 |  | Maciej Styczen, BingJyue Chen, YaWen Teng, YvonneAnne Pignolet, Lydia Y. Chen, DeNian Yang |  |
|  |  [Global and Local Feature Interaction with Vision Transformer for Few-shot Image Classification](https://doi.org/10.1145/3511808.3557604) |  | 0 |  | Mingze Sun, Weizhi Ma, Yang Liu |  |
|  |  [Leveraging the Graph Structure of Neural Network Training Dynamics](https://doi.org/10.1145/3511808.3557628) |  | 0 |  | Fatemeh Vahedian, Ruiyu Li, Puja Trivedi, Di Jin, Danai Koutra |  |
|  |  [Towards a Learned Cost Model for Distributed Spatial Join: Data, Code & Models](https://doi.org/10.1145/3511808.3557712) |  | 0 |  | Tin Vu, Alberto Belussi, Sara Migliorini, Ahmed Eldawy |  |
|  |  [Confidence-Guided Learning Process for Continuous Classification of Time Series](https://doi.org/10.1145/3511808.3557565) |  | 0 |  | Chenxi Sun, Moxian Song, Derun Cai, Baofeng Zhang, Shenda Hong, Hongyan Li |  |
|  |  [Self-supervision Meets Adversarial Perturbation: A Novel Framework for Anomaly Detection](https://doi.org/10.1145/3511808.3557697) |  | 0 |  | Yizhou Wang, Can Qin, Rongzhe Wei, Yi Xu, Yue Bai, Yun Fu |  |
|  |  [Efficiently Answering Minimum Reachable Label Set Queries in Edge-Labeled Graphs](https://doi.org/10.1145/3511808.3557593) |  | 0 |  | Yanping Wu, Renjie Sun, Chen Chen, Xiaoyang Wang, Xianming Fu |  |
|  |  [A Multi-granularity Network for Emotion-Cause Pair Extraction via Matrix Capsule](https://doi.org/10.1145/3511808.3557595) |  | 0 |  | Cheng Yang, Zhongwei Zhang, Jie Ding, Wenjun Zheng, Zhiwen Jing, Ying Li |  |
|  |  [Calibrate Automated Graph Neural Network via Hyperparameter Uncertainty](https://doi.org/10.1145/3511808.3557556) |  | 0 |  | Xueying Yang, Jiamian Wang, Xujiang Zhao, Sheng Li, Zhiqiang Tao |  |
|  |  [MetaRule: A Meta-path Guided Ensemble Rule Set Learning for Explainable Fraud Detection](https://doi.org/10.1145/3511808.3557641) |  | 0 |  | Lu Yu, Meng Li, Xiaoguang Huang, Wei Zhu, Yanming Fang, Jun Zhou, Longfei Li |  |
|  |  [Binary Classification with Positive Labeling Sources](https://doi.org/10.1145/3511808.3557552) |  | 0 |  | Jieyu Zhang, Yujing Wang, Yaming Yang, Yang Luo, Alexander Ratner |  |
|  |  [Graph Representation Learning via Adaptive Multi-layer Neighborhood Diffusion Contrast](https://doi.org/10.1145/3511808.3557606) |  | 0 |  | Jijie Zhang, Yan Yang, Yong Liu, Meng Han, Shaowei Yin |  |
|  |  [Selectively Expanding Queries and Documents for News Background Linking](https://doi.org/10.1145/3511808.3557695) |  | 0 |  | Lirong Zhang, Hideo Joho, Sumio Fujita, Haitao Yu |  |
|  |  [Co-Training with Validation: A Generic Framework for Semi-Supervised Relation Extraction](https://doi.org/10.1145/3511808.3557562) |  | 0 |  | Shun Zhang, Xiangkui Lu, Jun Wu |  |
|  |  [KSG: Knowledge and Skill Graph](https://doi.org/10.1145/3511808.3557623) |  | 0 |  | Feng Zhao, Ziqi Zhang, Donglin Wang |  |
|  |  [Dialogue State Tracking Based on Hierarchical Slot Attention and Contrastive Learning](https://doi.org/10.1145/3511808.3557581) |  | 0 |  | Yihao Zhou, Guoshuai Zhao, Xueming Qian |  |
|  |  [Modeling Price Elasticity for Occupancy Prediction in Hotel Dynamic Pricing](https://doi.org/10.1145/3511808.3557646) |  | 0 |  | Fanwei Zhu, Wendong Xiao, Yao Yu, Ziyi Wang, Zulong Chen, Quan Lu, Zemin Liu, Minghui Wu, Shenghua Ni |  |
|  |  [CAPER: Coarsen, Align, Project, Refine - A General Multilevel Framework for Network Alignment](https://doi.org/10.1145/3511808.3557563) |  | 0 |  | Jing Zhu, Danai Koutra, Mark Heimann |  |
|  |  [Molecular Substructure-Aware Network for Drug-Drug Interaction Prediction](https://doi.org/10.1145/3511808.3557648) |  | 0 |  | Xinyu Zhu, Yongliang Shen, Weiming Lu |  |
|  |  [SEERa: A Framework for Community Prediction](https://doi.org/10.1145/3511808.3557529) |  | 0 |  | Soroush Ziaeinejad, Saeed Samet, Hossein Fani |  |
|  |  [Statistical Claim Checking: StatCheck in Action](https://doi.org/10.1145/3511808.3557198) |  | 0 |  | Oana Balalau, Simon Ebel, Théo Galizzi, Ioana Manolescu, Quentin Massonnat, Antoine Deiana, Emilie Gautreau, Antoine Krempf, Thomas Pontillon, Gérald Roux, Joanna Yakin |  |
|  |  [Abstra: Toward Generic Abstractions for Data of Any Model](https://doi.org/10.1145/3511808.3557179) |  | 0 |  | Nelly Barret, Ioana Manolescu, Prajna Upadhyay |  |
|  |  [Federated Data Preparation, Learning, and Debugging in Apache SystemDS](https://doi.org/10.1145/3511808.3557162) |  | 0 |  | Sebastian Baunsgaard, Matthias Boehm, Kevin Innerebner, Mito Kehayov, Florian Lackner, Olga Ovcharenko, Arnab Phani, Tobias Rieger, David Weissteiner, Sebastian Benjamin Wrede |  |
|  |  [CyberWater: An Open Framework for Data and Model Integration in Water Science and Engineering](https://doi.org/10.1145/3511808.3557186) |  | 0 |  | Ranran Chen, Feng Li, Drew Bieger, Fengguang Song, Yao Liang, Daniel Luna, Ryan Young, Xu Liang, Sudhakar Pamidighantam |  |
|  |  [DASH: An Agile Knowledge Graph System Disentangling Demands, Algorithms, Data Resources, and Humans](https://doi.org/10.1145/3511808.3557189) |  | 0 |  | Shaowei Chen, Haoran Wang, Jie Liu, Jiahui Wu |  |
|  |  [GALGO: Scalable Graph Analytics with a Parallel DBMS](https://doi.org/10.1145/3511808.3557164) |  | 0 |  | Wellington Cabrera, Xiantian Zhou, Ladjel Bellatreche, Carlos Ordonez |  |
|  |  [A Platform for Argumentative Zoning Annotation and Scientific Summarization](https://doi.org/10.1145/3511808.3557193) |  | 0 |  | Alaa ElEbshihy, Annisa Maulida Ningtyas, Linda Andersson, Florina Piroi, Andreas Rauber |  |
|  |  [DISCO: Comprehensive and Explainable Disinformation Detection](https://doi.org/10.1145/3511808.3557202) |  | 0 |  | Dongqi Fu, Yikun Ban, Hanghang Tong, Ross Maciejewski, Jingrui He |  |
|  |  [A GPU-based Graph Pattern Mining System](https://doi.org/10.1145/3511808.3557192) |  | 0 |  | Lin Hu, Lei Zou |  |
|  |  [Hockey: A Hybrid PMem-SSD Storage Engine for Analytical Database](https://doi.org/10.1145/3511808.3557165) |  | 0 |  | Yuhang Jia, Huiqi Hu, Xuan Zhou, Weining Qian |  |
|  |  [Flurry: A Fast Framework for Provenance Graph Generation for Representation Learning](https://doi.org/10.1145/3511808.3557200) |  | 0 |  | Maya Kapoor, Joshua Melton, Michael Ridenhour, Thomas Moyer, Siddharth Krishnan |  |
|  |  [System-Auditing, Data Analysis and Characteristics of Cyber Attacks for Big Data Systems](https://doi.org/10.1145/3511808.3557185) |  | 0 |  | Liangyi Huang, Sophia Hall, Fei Shao, Arafath Nihar, Vipin Chaudhary, Yinghui Wu, Roger H. French, Xusheng Xiao |  |
|  |  [MM-evocat: A Tool for Modelling and Evolution Management of Multi-Model Data](https://doi.org/10.1145/3511808.3557180) |  | 0 |  | Pavel Koupil, Jáchym Bártík, Irena Holubová |  |
|  |  [Named Entity-based Question-Answering Pair Generator](https://doi.org/10.1145/3511808.3557209) |  | 0 |  | Aritra Kumar Lahiri, Qinmin Vivian Hu |  |
|  |  [POTATO: exPlainable infOrmation exTrAcTion framewOrk](https://doi.org/10.1145/3511808.3557196) |  | 0 |  | Ádám Kovács, Kinga Gémes, Eszter Iklódi, Gábor Recski |  |
|  |  [Demonstrating SubStrat: A Subset-Based Strategy for Faster AutoML on Large Datasets](https://doi.org/10.1145/3511808.3557160) |  | 0 |  | Teddy Lazebnik, Amit Somech |  |
|  |  [Demonstration of LogicLib: An Expressive Multi-Language Interface over Scalable Datalog System](https://doi.org/10.1145/3511808.3557174) |  | 0 |  | Mingda Li, Jin Wang, Guorui Xiao, Youfu Li, Carlo Zaniolo |  |
|  |  [PRID: An Efficient Pub/Sub Ride Hitching System](https://doi.org/10.1145/3511808.3557213) |  | 0 |  | Yafei Li, Lei Gao, Haobo Sun, Huiling Li, Qingshun Wu |  |
|  |  [TSUPY: Dynamic Climate Network Analysis Library](https://doi.org/10.1145/3511808.3557166) |  | 0 |  | Jinshu Liu, Yunlong Xu, Fatemeh Nargesian, Gourab Ghoshal |  |
|  |  [Sensitivity Review of Large Collections by Identifying and Prioritising Coherent Documents Groups](https://doi.org/10.1145/3511808.3557182) |  | 0 |  | Hitarth Narvala, Graham McDonald, Iadh Ounis |  |
|  |  [PyDHNet: A Python Library for Dynamic Heterogeneous Network Representation Learning and Evaluation](https://doi.org/10.1145/3511808.3557181) |  | 0 |  | Hoang Nguyen, Radin Hamidi Rad, Ebrahim Bagheri |  |
|  |  [CrisICSum: Interpretable Classification and Summarization Platform for Crisis Events from Microblogs](https://doi.org/10.1145/3511808.3557191) |  | 0 |  | Thi Huyen Nguyen, Miroslav Shaltev, Koustav Rudra |  |
|  |  [GALVIS: Visualization Construction through Example-Powered Declarative Programming](https://doi.org/10.1145/3511808.3557159) |  | 0 |  | Leixian Shen, Enya Shen, Zhiwei Tai, Yun Wang, Yuyu Luo, Jianmin Wang |  |
|  |  [LibEpidemic: An Open-source Framework for Modeling Infectious Disease with Bigdata](https://doi.org/10.1145/3511808.3557183) |  | 0 |  | Honghao Shi, Qijian Tian, Jingyuan Wang, Jiawei Cheng |  |
|  |  [TinyRL: Towards Reinforcement Learning on Tiny Embedded Devices](https://doi.org/10.1145/3511808.3557206) |  | 0 |  | Tomasz Szydlo, Prem Prakash Jayaraman, Yinhao Li, Graham Morgan, Rajiv Ranjan |  |
|  |  [FeReD: Federated Reinforcement Learning in the DBMS](https://doi.org/10.1145/3511808.3557203) |  | 0 |  | Sotirios Tzamaras, Radu Ciucanu, Marta Soare, Sihem AmerYahia |  |
|  |  [BED: A Real-Time Object Detection System for Edge Devices](https://doi.org/10.1145/3511808.3557168) |  | 0 |  | Guanchu Wang, Zaid Pervaiz Bhat, Zhimeng Jiang, YiWei Chen, Daochen Zha, Alfredo Costilla Reyes, Afshin Niktash, Mehmet Görkem Ulkar, Osman Erman Okman, Xuanting Cai, Xia Hu |  |
|  |  [Hammer PDF: An Intelligent PDF Reader for Scientific Papers](https://doi.org/10.1145/3511808.3557169) |  | 0 |  | ShengFu Wang, ShuHang Liu, TianYi Che, YiFan Lu, SongXiao Yang, Heyan Huang, XianLing Mao |  |
|  |  [A System for Time Series Feature Extraction in Federated Learning](https://doi.org/10.1145/3511808.3557176) |  | 0 |  | Siqi Wang, Jiashu Li, Mian Lu, Zhao Zheng, Yuqiang Chen, Bingsheng He |  |
|  |  [An In-depth Interactive and Visualized Platform for Evaluating and Analyzing MRC Models](https://doi.org/10.1145/3511808.3557167) |  | 0 |  | Zhijing Wu, Jingliang Fang, Hua Xu, Kai Gao |  |
|  |  [Extensible Database Simulator for Fast Prototyping In-Database Algorithms](https://doi.org/10.1145/3511808.3557205) |  | 0 |  | Yifan Wang, Daisy Zhe Wang |  |
|  |  [FinBot: A Memory-Augmented Intelligent Financial Assistant](https://doi.org/10.1145/3511808.3557199) |  | 0 |  | Yingting Wu, Bingzhu Du, Yongliang Wang, Zihao Wang, Minghui Yang, Yuchi Zhang, Hai Zhao |  |
|  |  [Favorite+: Favorite Tuples Extraction via Regret Minimization](https://doi.org/10.1145/3511808.3557188) |  | 0 |  | Min Xie, Yang Liu |  |
|  |  [gCBO: A Cost-based Optimizer for Graph Databases](https://doi.org/10.1145/3511808.3557197) |  | 0 |  | Linglin Yang, Lei Yang, Yue Pang, Lei Zou |  |
|  |  [eDental: Managing Your Dental Care in Diet Diaries](https://doi.org/10.1145/3511808.3557215) |  | 0 |  | Kaiping Zheng, Thao Nguyen, Changshuo Liu, Charlene Enhui Goh, Beng Chin Ooi |  |
|  |  [Ledgit: A Service to Diagnose Illicit Addresses on Blockchain using Multi-modal Unsupervised Learning](https://doi.org/10.1145/3511808.3557212) |  | 0 |  | Xiaoying Zhi, Yash Satsangi, Sean J. Moran, Shaltiel Eloul |  |
|  |  [ScheRe: Schema Reshaping for Enhancing Knowledge Graph Construction](https://doi.org/10.1145/3511808.3557214) |  | 0 |  | Dongzhuoran Zhou, Baifan Zhou, Zhuoxun Zheng, Ahmet Soylu, Ognjen Savkovic, Egor V. Kostylev, Evgeny Kharlamov |  |
|  |  [Simulating Complex Problems Inside a Database](https://doi.org/10.1145/3511808.3557520) |  | 0 |  | Giancarlo Fissore, Nikolaos Vasiloglou |  |
|  |  [Building Next Best Action Engines for B2C and B2B Use Cases](https://doi.org/10.1145/3511808.3557511) |  | 0 |  | Ilya Katsov |  |
|  |  [Sequence-Driven Analytics and Prediction](https://doi.org/10.1145/3511808.3557822) |  | 0 |  | Usman Ahmed |  |
|  |  [Building Natural Language Processing Applications with EasyNLP](https://doi.org/10.1145/3511808.3557510) |  | 0 |  | Chengyu Wang, Minghui Qiu, Jun Huang |  |
|  |  [C-Cast: A Real-Time Forecasting Model for a Controlled Sequence](https://doi.org/10.1145/3511808.3557817) |  | 0 |  | Ren Fujiwara |  |
|  |  [Causal Relationship over Knowledge Graphs](https://doi.org/10.1145/3511808.3557818) |  | 0 |  | Hao Huang |  |
|  |  [Identify Relevant Entities Through Text Understanding](https://doi.org/10.1145/3511808.3557819) |  | 0 |  | Pooja Oza |  |
|  |  [Mining of Real-world Hypergraphs: Patterns, Tools, and Generators](https://doi.org/10.1145/3511808.3557505) |  | 0 |  | Geon Lee, Jaemin Yoo, Kijung Shin |  |
|  |  [Graph-based Management and Mining of Blockchain Data](https://doi.org/10.1145/3511808.3557502) |  | 0 |  | Arijit Khan, Cuneyt Gurcan Akcora |  |
|  |  [Information Extraction from Social Media: A Hands-on Tutorial on Tasks, Data, and Open Source Tools](https://doi.org/10.1145/3511808.3557503) |  | 0 |  | Shubhanshu Mishra, Rezvaneh Rezapour, Jana Diesner |  |
|  |  [Tutorial on Deep Learning Interpretation: A Data Perspective](https://doi.org/10.1145/3511808.3557500) |  | 0 |  | Zhou Yang, Ninghao Liu, Xia Ben Hu, Fang Jin |  |
|  |  [Learning and Mining with Noisy Labels](https://doi.org/10.1145/3511808.3557504) |  | 0 |  | Masashi Sugiyama, Tongliang Liu, Bo Han, Yang Liu, Gang Niu |  |
|  |  [PAS: Privacy Algorithms in Systems](https://doi.org/10.1145/3511808.3557494) |  | 0 |  | Philip S. Yu, Olivera Kotevska, Tyler Derr |  |

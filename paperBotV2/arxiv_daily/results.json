{
  "2510.06999v1": {
    "title": "Towards Reliable Retrieval in RAG Systems for Large Legal Datasets",
    "url": "https://www.alphaxiv.org/abs/2510.06999v1",
    "arxiv_id": "2510.06999v1",
    "authors": "Markus Reuter, Tobias Lingenberg, Rūta Liepiņa, Francesca Lagioia, Marco Lippi, Giovanni Sartor, Andrea Passerini, Burcu Sayin",
    "categories": "cs.CL, cs.IR, I.2.7; H.3.3; K.5.0",
    "pub_date": "2025-10-08 13:22:20",
    "ori_summary": "Retrieval-Augmented Generation (RAG) is a promising approach to mitigate hallucinations in Large Language Models (LLMs) for legal applications, but its reliability is critically dependent on the accuracy of the retrieval step. This is particularly challenging in the legal domain, where large databases of structurally similar documents often cause retrieval systems to fail. In this paper, we address this challenge by first identifying and quantifying a critical failure mode we term Document-Level Retrieval Mismatch (DRM), where the retriever selects information from entirely incorrect source documents. To mitigate DRM, we investigate a simple and computationally efficient technique which we refer to as Summary-Augmented Chunking (SAC). This method enhances each text chunk with a document-level synthetic summary, thereby injecting crucial global context that would otherwise be lost during a standard chunking process. Our experiments on a diverse set of legal information retrieval tasks show that SAC greatly reduces DRM and, consequently, also improves text-level retrieval precision and recall. Interestingly, we find that a generic summarization strategy outperforms an approach that incorporates legal expert domain knowledge to target specific legal elements. Our work provides evidence that this practical, scalable, and easily integrable technique enhances the reliability of RAG systems when applied to large-scale legal document datasets.",
    "summary": "论文研究法律领域RAG系统中检索不可靠的核心问题，核心思想是通过文档级合成摘要增强文本分块，为每个片段注入全局上下文信息来解决文档级检索错配问题。",
    "translation": "面向大型法律数据集的RAG系统可靠检索研究",
    "relevance_score": 8,
    "reasoning": "该论文聚焦于RAG（检索增强生成）系统的可靠检索问题，这直接关系到搜索和推荐系统的核心能力。RAG技术作为LLM的关键应用，在提升检索准确性和可靠性方面的进展可直接应用于搜索系统的文档检索和推荐系统的候选生成，属于'直接LLM应用'范畴。",
    "rerank_relevance_score": 8,
    "rerank_reasoning": "该论文直接针对RAG系统中的检索可靠性问题，这是搜索和推荐系统的核心挑战，提出的摘要增强分块方法对处理大规模异构数据具有通用参考价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06987v1": {
    "title": "Spiral Model Technique For Data Science & Machine Learning Lifecycle",
    "url": "https://www.alphaxiv.org/abs/2510.06987v1",
    "arxiv_id": "2510.06987v1",
    "authors": "Rohith Mahadevan",
    "categories": "cs.LG, cs.IR, cs.SE",
    "pub_date": "2025-10-08 13:11:58",
    "ori_summary": "Analytics play an important role in modern business. Companies adapt data science lifecycles to their culture to seek productivity and improve their competitiveness among others. Data science lifecycles are fairly an important contributing factor to start and end a project that are data dependent. Data science and Machine learning life cycles comprises of series of steps that are involved in a project. A typical life cycle states that it is a linear or cyclical model that revolves around. It is mostly depicted that it is possible in a traditional data science life cycle to start the process again after reaching the end of cycle. This paper suggests a new technique to incorporate data science life cycle to business problems that have a clear end goal. A new technique called spiral technique is introduced to emphasize versatility, agility and iterative approach to business processes.",
    "summary": "",
    "translation": "数据科学与机器学习生命周期的螺旋模型技术",
    "relevance_score": 2,
    "reasoning": "该论文主要关注数据科学和机器学习的生命周期管理方法（螺旋模型），属于通用的MLOps或开发流程范畴。虽然机器学习是推荐系统、搜索和广告的基础技术，但本文聚焦于开发流程而非核心算法、架构创新或直接应用，与当前关注的LLM技术、Transformer进展、推荐系统核心算法等焦点领域关联度较低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06924v1": {
    "title": "Ethical AI prompt recommendations in large language models using collaborative filtering",
    "url": "https://www.alphaxiv.org/abs/2510.06924v1",
    "arxiv_id": "2510.06924v1",
    "authors": "Jordan Nelson, Almas Baimagambetov, Konstantinos Avgerinakis, Nikolaos Polatidis",
    "categories": "cs.IR",
    "pub_date": "2025-10-08 12:03:21",
    "ori_summary": "As large language models (LLMs) shape AI development, ensuring ethical prompt recommendations is crucial. LLMs offer innovation but risk bias, fairness issues, and accountability concerns. Traditional oversight methods struggle with scalability, necessitating dynamic solutions. This paper proposes using collaborative filtering, a technique from recommendation systems, to enhance ethical prompt selection. By leveraging user interactions, it promotes ethical guidelines while reducing bias. Contributions include a synthetic dataset for prompt recommendations and the application of collaborative filtering. The work also tackles challenges in ethical AI, such as bias mitigation, transparency, and preventing unethical prompt engineering.",
    "summary": "",
    "translation": "基于协同过滤的大型语言模型伦理AI提示推荐",
    "relevance_score": 1,
    "reasoning": "该论文明确涉及伦理AI主题，这属于被明确排除的非技术性话题范畴。虽然提到了协同过滤和LLM技术，但核心焦点是伦理方面的提示推荐，与当前关注的推荐系统、搜索或广告中的技术进展无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06888v1": {
    "title": "M3Retrieve: Benchmarking Multimodal Retrieval for Medicine",
    "url": "https://www.alphaxiv.org/abs/2510.06888v1",
    "arxiv_id": "2510.06888v1",
    "authors": "Arkadeep Acharya, Akash Ghosh, Pradeepika Verma, Kitsuchart Pasupa, Sriparna Saha, Priti Singh",
    "categories": "cs.IR, cs.AI",
    "pub_date": "2025-10-08 11:08:47",
    "ori_summary": "With the increasing use of RetrievalAugmented Generation (RAG), strong retrieval models have become more important than ever. In healthcare, multimodal retrieval models that combine information from both text and images offer major advantages for many downstream tasks such as question answering, cross-modal retrieval, and multimodal summarization, since medical data often includes both formats. However, there is currently no standard benchmark to evaluate how well these models perform in medical settings. To address this gap, we introduce M3Retrieve, a Multimodal Medical Retrieval Benchmark. M3Retrieve, spans 5 domains,16 medical fields, and 4 distinct tasks, with over 1.2 Million text documents and 164K multimodal queries, all collected under approved licenses. We evaluate leading multimodal retrieval models on this benchmark to explore the challenges specific to different medical specialities and to understand their impact on retrieval performance. By releasing M3Retrieve, we aim to enable systematic evaluation, foster model innovation, and accelerate research toward building more capable and reliable multimodal retrieval systems for medical applications. The dataset and the baselines code are available in this github page https://github.com/AkashGhosh/M3Retrieve.",
    "summary": "",
    "translation": "M3Retrieve：面向医学领域的多模态检索基准测试",
    "relevance_score": 1,
    "reasoning": "该论文明确聚焦于医学领域的多模态检索基准测试，这属于明确的无关主题范畴（医学或其他领域特定应用）。虽然多模态检索技术本身在推荐系统和搜索中有潜在应用，但论文的医学领域限定使其与当前关注的通用推荐系统、搜索和广告技术完全无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06838v1": {
    "title": "Crossing Domains without Labels: Distant Supervision for Term Extraction",
    "url": "https://www.alphaxiv.org/abs/2510.06838v1",
    "arxiv_id": "2510.06838v1",
    "authors": "Elena Senger, Yuri Campbell, Rob van der Goot, Barbara Plank",
    "categories": "cs.IR, cs.CL",
    "pub_date": "2025-10-08 10:02:40",
    "ori_summary": "Automatic Term Extraction (ATE) is a critical component in downstream NLP tasks such as document tagging, ontology construction and patent analysis. Current state-of-the-art methods require expensive human annotation and struggle with domain transfer, limiting their practical deployment. This highlights the need for more robust, scalable solutions and realistic evaluation settings. To address this, we introduce a comprehensive benchmark spanning seven diverse domains, enabling performance evaluation at both the document- and corpus-levels. Furthermore, we propose a robust LLM-based model that outperforms both supervised cross-domain encoder models and few-shot learning baselines and performs competitively with its GPT-4o teacher on this benchmark. The first step of our approach is generating psuedo-labels with this black-box LLM on general and scientific domains to ensure generalizability. Building on this data, we fine-tune the first LLMs for ATE. To further enhance document-level consistency, oftentimes needed for downstream tasks, we introduce lightweight post-hoc heuristics. Our approach exceeds previous approaches on 5/7 domains with an average improvement of 10 percentage points. We release our dataset and fine-tuned models to support future research in this area.",
    "summary": "",
    "translation": "无标签跨域：用于术语提取的远监督方法",
    "relevance_score": 3,
    "reasoning": "该论文关注术语提取的远监督方法，这属于信息提取技术，可能在搜索系统中用于查询理解和文档处理。然而，它主要涉及跨域迁移学习，与推荐系统、广告或核心LLM技术的直接关联较弱，应用潜力有限。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06823v1": {
    "title": "Exposing Citation Vulnerabilities in Generative Engines",
    "url": "https://www.alphaxiv.org/abs/2510.06823v1",
    "arxiv_id": "2510.06823v1",
    "authors": "Riku Mochizuki, Shusuke Komatsu, Souta Noguchi, Kazuto Ataka",
    "categories": "cs.CR, cs.CL, cs.IR",
    "pub_date": "2025-10-08 09:47:48",
    "ori_summary": "We analyze answers generated by generative engines (GEs) from the perspectives of citation publishers and the content-injection barrier, defined as the difficulty for attackers to manipulate answers to user prompts by placing malicious content on the web. GEs integrate two functions: web search and answer generation that cites web pages using large language models. Because anyone can publish information on the web, GEs are vulnerable to poisoning attacks. Existing studies of citation evaluation focus on how faithfully answer content reflects cited sources, leaving unexamined which web sources should be selected as citations to defend against poisoning attacks. To fill this gap, we introduce evaluation criteria that assess poisoning threats using the citation information contained in answers. Our criteria classify the publisher attributes of citations to estimate the content-injection barrier thereby revealing the threat of poisoning attacks in current GEs. We conduct experiments in political domains in Japan and the United States (U.S.) using our criteria and show that citations from official party websites (primary sources) are approximately \\(25\\%\\)--\\(45\\%\\) in the U.S. and \\(60\\%\\)--\\(65\\%\\) in Japan, indicating that U.S. political answers are at higher risk of poisoning attacks. We also find that sources with low content-injection barriers are frequently cited yet are poorly reflected in answer content. To mitigate this threat, we discuss how publishers of primary sources can increase exposure of their web content in answers and show that well-known techniques are limited by language differences.",
    "summary": "",
    "translation": "揭示生成式引擎中的引用漏洞",
    "relevance_score": 2,
    "reasoning": "该论文主要关注生成式引擎的引用漏洞问题，这属于LLM评估和可信度范畴，属于被排除的\"Hallucination, Evaluation benchmarks, or other purely NLP-centric topics\"。虽然生成式引擎可能用于搜索，但论文焦点是引用漏洞而非搜索/推荐/广告的核心技术或应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06805v1": {
    "title": "Overview of the Plagiarism Detection Task at PAN 2025",
    "url": "https://www.alphaxiv.org/abs/2510.06805v1",
    "arxiv_id": "2510.06805v1",
    "authors": "André Greiner-Petter, Maik Fröbe, Jan Philip Wahle, Terry Ruas, Bela Gipp, Akiko Aizawa, Martin Potthast",
    "categories": "cs.CL, cs.IR",
    "pub_date": "2025-10-08 09:33:26",
    "ori_summary": "The generative plagiarism detection task at PAN 2025 aims at identifying automatically generated textual plagiarism in scientific articles and aligning them with their respective sources. We created a novel large-scale dataset of automatically generated plagiarism using three large language models: Llama, DeepSeek-R1, and Mistral. In this task overview paper, we outline the creation of this dataset, summarize and compare the results of all participants and four baselines, and evaluate the results on the last plagiarism detection task from PAN 2015 in order to interpret the robustness of the proposed approaches. We found that the current iteration does not invite a large variety of approaches as naive semantic similarity approaches based on embedding vectors provide promising results of up to 0.8 recall and 0.5 precision. In contrast, most of these approaches underperform significantly on the 2015 dataset, indicating a lack in generalizability.",
    "summary": "",
    "translation": "PAN 2025抄袭检测任务综述",
    "relevance_score": 1,
    "reasoning": "该论文聚焦于抄袭检测任务，这属于内容原创性验证和文本相似度计算的范畴，与推荐系统、搜索或广告的核心技术进展无关。抄袭检测主要应用于学术诚信、内容审核等场景，不涉及用户行为建模、个性化推荐、搜索排序或广告投放等关键技术领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06732v1": {
    "title": "Are LLMs Reliable Rankers? Rank Manipulation via Two-Stage Token Optimization",
    "url": "https://www.alphaxiv.org/abs/2510.06732v1",
    "arxiv_id": "2510.06732v1",
    "authors": "Tiancheng Xing, Jerry Li, Yixuan Du, Xiyang Hu",
    "categories": "cs.CL, cs.AI, cs.IR",
    "pub_date": "2025-10-08 07:40:40",
    "ori_summary": "Large language models (LLMs) are increasingly used as rerankers in information retrieval, yet their ranking behavior can be steered by small, natural-sounding prompts. To expose this vulnerability, we present Rank Anything First (RAF), a two-stage token optimization method that crafts concise textual perturbations to consistently promote a target item in LLM-generated rankings while remaining hard to detect. Stage 1 uses Greedy Coordinate Gradient to shortlist candidate tokens at the current position by combining the gradient of the rank-target with a readability score; Stage 2 evaluates those candidates under exact ranking and readability losses using an entropy-based dynamic weighting scheme, and selects a token via temperature-controlled sampling. RAF generates ranking-promoting prompts token-by-token, guided by dual objectives: maximizing ranking effectiveness and preserving linguistic naturalness. Experiments across multiple LLMs show that RAF significantly boosts the rank of target items using naturalistic language, with greater robustness than existing methods in both promoting target items and maintaining naturalness. These findings underscore a critical security implication: LLM-based reranking is inherently susceptible to adversarial manipulation, raising new challenges for the trustworthiness and robustness of modern retrieval systems. Our code is available at: https://github.com/glad-lab/RAF.",
    "summary": "论文研究LLM作为重排序器的可靠性问题，核心方法是提出两阶段令牌优化技术，通过生成自然语言扰动来操纵LLM的排名结果。",
    "translation": "大语言模型是可靠的排序器吗？通过两阶段令牌优化实现排序操纵",
    "relevance_score": 9,
    "reasoning": "该论文直接探讨LLMs在排序任务中的可靠性问题，这是搜索和推荐系统的核心应用场景。两阶段令牌优化技术可能揭示LLM排序的脆弱性，对构建可靠的搜索和推荐系统具有重要实践意义。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文直接研究LLM在搜索重排序中的安全漏洞，揭示了对抗性攻击对推荐系统可信度的重大威胁。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06728v1": {
    "title": "Reproducing and Extending Causal Insights Into Term Frequency Computation in Neural Rankers",
    "url": "https://www.alphaxiv.org/abs/2510.06728v1",
    "arxiv_id": "2510.06728v1",
    "authors": "Cile van Marken, Roxana Petcu",
    "categories": "cs.IR",
    "pub_date": "2025-10-08 07:29:31",
    "ori_summary": "Neural ranking models have shown outstanding performance across a variety of tasks, such as document retrieval, re-ranking, question answering and conversational retrieval. However, the inner decision process of these models remains largely unclear, especially as models increase in size. Most interpretability approaches, such as probing, focus on correlational insights rather than establishing causal relationships. The paper 'Axiomatic Causal Interventions for Reverse Engineering Relevance Computation in Neural Retrieval Models' by Chen et al. addresses this gap by introducing a framework for activation patching - a causal interpretability method - in the information retrieval domain, offering insights into how neural retrieval models compute document relevance. The study demonstrates that neural ranking models not only capture term-frequency information, but also that these representations can be localized to specific components of the model, such as individual attention heads or layers. This paper aims to reproduce the findings by Chen et al. and to further explore the presence of pre-defined retrieval axioms in neural IR models. We validate the main claims made by Chen et al., and extend the framework to include an additional term-frequency axiom, which states that the impact of increasing query term frequency on document ranking diminishes as the frequency becomes higher. We successfully identify a group of attention heads that encode this axiom and analyze their behavior to give insight into the inner decision-making process of neural ranking models.",
    "summary": "",
    "translation": "复现并扩展神经排序器中词频计算的因果洞察",
    "relevance_score": 7,
    "reasoning": "该论文涉及神经排序器中的词频计算机制，直接关联搜索领域的核心排序技术。对词频计算的因果分析有助于理解神经排序器的工作原理，可为搜索排序模型的解释性和改进提供重要技术洞察。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06658v1": {
    "title": "Can We Hide Machines in the Crowd? Quantifying Equivalence in LLM-in-the-loop Annotation Tasks",
    "url": "https://www.alphaxiv.org/abs/2510.06658v1",
    "arxiv_id": "2510.06658v1",
    "authors": "Jiaman He, Zikang Leng, Dana McKay, Damiano Spina, Johanne R. Trippas",
    "categories": "cs.IR",
    "pub_date": "2025-10-08 05:17:33",
    "ori_summary": "Many evaluations of large language models (LLMs) in text annotation focus primarily on the correctness of the output, typically comparing model-generated labels to human-annotated ``ground truth'' using standard performance metrics. In contrast, our study moves beyond effectiveness alone. We aim to explore how labeling decisions -- by both humans and LLMs -- can be statistically evaluated across individuals. Rather than treating LLMs purely as annotation systems, we approach LLMs as an alternative annotation mechanism that may be capable of mimicking the subjective judgments made by humans. To assess this, we develop a statistical evaluation method based on Krippendorff's $\\alpha$, paired bootstrapping, and the Two One-Sided t-Tests (TOST) equivalence test procedure. This evaluation method tests whether an LLM can blend into a group of human annotators without being distinguishable. We apply this approach to two datasets -- MovieLens 100K and PolitiFact -- and find that the LLM is statistically indistinguishable from a human annotator in the former ($p = 0.004$), but not in the latter ($p = 0.155$), highlighting task-dependent differences. It also enables early evaluation on a small sample of human data to inform whether LLMs are suitable for large-scale annotation in a given application.",
    "summary": "",
    "translation": "我们能否将机器隐藏在人群中？量化LLM在环标注任务中的等价性",
    "relevance_score": 2,
    "reasoning": "该论文主要关注LLM在数据标注任务中的等价性评估，这属于LLM评估和标注质量范畴。虽然涉及LLM技术，但论文焦点是标注任务本身而非在推荐系统、搜索或广告中的具体应用，且没有明确指向这些领域的潜在应用场景。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06657v1": {
    "title": "LLM-Powered Nuanced Video Attribute Annotation for Enhanced Recommendations",
    "url": "https://www.alphaxiv.org/abs/2510.06657v1",
    "arxiv_id": "2510.06657v1",
    "authors": "Boyuan Long, Yueqi Wang, Hiloni Mehta, Mick Zomnir, Omkar Pathak, Changping Meng, Ruolin Jia, Yajun Peng, Dapeng Hong, Xia Wu, Mingyan Gao, Onkar Dalal, Ningren Han",
    "categories": "cs.IR",
    "pub_date": "2025-10-08 05:17:17",
    "ori_summary": "This paper presents a case study on deploying Large Language Models (LLMs) as an advanced \"annotation\" mechanism to achieve nuanced content understanding (e.g., discerning content \"vibe\") at scale within a large-scale industrial short-form video recommendation system. Traditional machine learning classifiers for content understanding face protracted development cycles and a lack of deep, nuanced comprehension. The \"LLM-as-annotators\" approach addresses these by significantly shortening development times and enabling the annotation of subtle attributes. This work details an end-to-end workflow encompassing: (1) iterative definition and robust evaluation of target attributes, refined by offline metrics and online A/B testing; (2) scalable offline bulk annotation of video corpora using LLMs with multimodal features, optimized inference, and knowledge distillation for broad application; and (3) integration of these rich annotations into the online recommendation serving system, for example, through personalized restrict retrieval. Experimental results demonstrate the efficacy of this approach, with LLMs outperforming human raters in offline annotation quality for nuanced attributes and yielding significant improvements of user participation and satisfied consumption in online A/B tests. The study provides insights into designing and scaling production-level LLM pipelines for rich content evaluation, highlighting the adaptability and benefits of LLM-generated nuanced understanding for enhancing content discovery, user satisfaction, and the overall effectiveness of modern recommendation systems.",
    "summary": "论文研究如何解决推荐系统中传统内容理解方法开发周期长、缺乏深度理解的问题，核心思想是部署LLM作为高级标注机制，通过端到端工作流程实现大规模视频内容的细粒度属性标注和集成。",
    "translation": "基于大语言模型的细粒度视频属性标注用于增强推荐系统",
    "relevance_score": 9,
    "reasoning": "该论文直接应用LLM技术进行视频属性标注，这属于'直接LLM应用'范畴。细粒度的视频属性标注可以显著提升推荐系统的特征工程质量，为视频推荐、搜索排序和广告定向提供更丰富的上下文信息，从而直接增强推荐效果。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文直接应用LLM技术解决推荐系统中的内容理解难题，通过LLM作为标注器实现细粒度属性标注，完全符合直接LLM应用和核心领域进展的关注点。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.07318v1": {
    "title": "Artificial Hippocampus Networks for Efficient Long-Context Modeling",
    "url": "https://www.alphaxiv.org/abs/2510.07318v1",
    "arxiv_id": "2510.07318v1",
    "authors": "Yunhao Fang, Weihao Yu, Shu Zhong, Qinghao Ye, Xuehan Xiong, Lai Wei",
    "categories": "cs.CL, cs.AI, cs.LG",
    "pub_date": "2025-10-08 17:59:55",
    "ori_summary": "Long-sequence modeling faces a fundamental trade-off between the efficiency of compressive fixed-size memory in RNN-like models and the fidelity of lossless growing memory in attention-based Transformers. Inspired by the Multi-Store Model in cognitive science, we introduce a memory framework of artificial neural networks. Our method maintains a sliding window of the Transformer's KV cache as lossless short-term memory, while a learnable module termed Artificial Hippocampus Network (AHN) recurrently compresses out-of-window information into a fixed-size compact long-term memory. To validate this framework, we instantiate AHNs using modern RNN-like architectures, including Mamba2, DeltaNet, and Gated DeltaNet. Extensive experiments on long-context benchmarks LV-Eval and InfiniteBench demonstrate that AHN-augmented models consistently outperform sliding window baselines and achieve performance comparable or even superior to full-attention models, while substantially reducing computational and memory requirements. For instance, augmenting the Qwen2.5-3B-Instruct with AHNs reduces inference FLOPs by 40.5% and memory cache by 74.0%, while improving its average score on LV-Eval (128k sequence length) from 4.41 to 5.88. Code is available at: https://github.com/ByteDance-Seed/AHN.",
    "summary": "该论文研究长序列建模中效率与保真度的权衡问题，核心思想是结合滑动窗口无损短期记忆与可学习人工海马体网络压缩长期记忆的混合记忆框架，实现高效的长上下文建模。",
    "translation": "人工海马体网络用于高效长上下文建模",
    "relevance_score": 8,
    "reasoning": "该论文提出的人工海马体网络专注于高效长上下文建模，直接属于'使能Transformer技术'范畴，涉及Transformer架构的效率改进。在推荐系统和搜索领域，这种高效长上下文建模技术可以显著提升用户行为序列建模、长期兴趣捕捉和复杂上下文理解的能力，具有明确的实用价值。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文提出的混合记忆架构直接解决了长序列建模的核心效率问题，其人工海马体网络概念对Transformer架构的效率优化具有重要价值，与推荐和搜索系统的长上下文处理需求高度相关。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.07315v1": {
    "title": "Vibe Checker: Aligning Code Evaluation with Human Preference",
    "url": "https://www.alphaxiv.org/abs/2510.07315v1",
    "arxiv_id": "2510.07315v1",
    "authors": "Ming Zhong, Xiang Zhou, Ting-Yun Chang, Qingze Wang, Nan Xu, Xiance Si, Dan Garrette, Shyam Upadhyay, Jeremiah Liu, Jiawei Han, Benoit Schillings, Jiao Sun",
    "categories": "cs.CL, cs.AI, cs.LG, cs.SE",
    "pub_date": "2025-10-08 17:59:19",
    "ori_summary": "Large Language Models (LLMs) have catalyzed vibe coding, where users leverage LLMs to generate and iteratively refine code through natural language interactions until it passes their vibe check. Vibe check is tied to real-world human preference and goes beyond functionality: the solution should feel right, read cleanly, preserve intent, and remain correct. However, current code evaluation remains anchored to pass@k and captures only functional correctness, overlooking the non-functional instructions that users routinely apply. In this paper, we hypothesize that instruction following is the missing piece underlying vibe check that represents human preference in coding besides functional correctness. To quantify models' code instruction following capabilities with measurable signals, we present VeriCode, a taxonomy of 30 verifiable code instructions together with corresponding deterministic verifiers. We use the taxonomy to augment established evaluation suites, resulting in Vibe Checker, a testbed to assess both code instruction following and functional correctness. Upon evaluating 31 leading LLMs, we show that even the strongest models struggle to comply with multiple instructions and exhibit clear functional regression. Most importantly, a composite score of functional correctness and instruction following correlates the best with human preference, with the latter emerging as the primary differentiator on real-world programming tasks. Our work identifies core factors of the vibe check, providing a concrete path for benchmarking and developing models that better align with user preferences in coding.",
    "summary": "",
    "translation": "Vibe Checker：将代码评估与人类偏好对齐",
    "relevance_score": 1,
    "reasoning": "该论文标题明确聚焦于代码评估和人类偏好对齐，这属于编程辅助和代码生成领域，与推荐系统、搜索或广告的核心技术无关。即使考虑LLM技术，该研究主要针对代码质量评估这一特定应用场景，在RecSys/Search/Ads领域缺乏直接的应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07309v1": {
    "title": "Agent Bain vs. Agent McKinsey: A New Text-to-SQL Benchmark for the Business Domain",
    "url": "https://www.alphaxiv.org/abs/2510.07309v1",
    "arxiv_id": "2510.07309v1",
    "authors": "Yue Li, Ran Tao, Derek Hommel, Yusuf Denizay Dönder, Sungyong Chang, David Mimno, Unso Eun Seo Jo",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 17:57:35",
    "ori_summary": "In the business domain, where data-driven decision making is crucial, text-to-SQL is fundamental for easy natural language access to structured data. While recent LLMs have achieved strong performance in code generation, existing text-to-SQL benchmarks remain focused on factual retrieval of past records. We introduce CORGI, a new benchmark specifically designed for real-world business contexts. CORGI is composed of synthetic databases inspired by enterprises such as Doordash, Airbnb, and Lululemon. It provides questions across four increasingly complex categories of business queries: descriptive, explanatory, predictive, and recommendational. This challenge calls for causal reasoning, temporal forecasting, and strategic recommendation, reflecting multi-level and multi-step agentic intelligence. We find that LLM performance drops on high-level questions, struggling to make accurate predictions and offer actionable plans. Based on execution success rate, the CORGI benchmark is about 21\\% more difficult than the BIRD benchmark. This highlights the gap between popular LLMs and the need for real-world business intelligence. We release a public dataset and evaluation framework, and a website for public submissions.",
    "summary": "",
    "translation": "Agent Bain vs. Agent McKinsey：面向商业领域的新型文本到SQL基准测试",
    "relevance_score": 2,
    "reasoning": "该论文主要关注文本到SQL转换的基准测试，属于数据库查询领域的特定应用。虽然文本到SQL技术理论上可以应用于搜索系统的查询理解，但论文聚焦于商业咨询领域的基准比较，与推荐系统、搜索排名或广告的核心技术关联度较低，且未涉及LLM在推荐/搜索/广告中的直接应用或架构创新。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07300v1": {
    "title": "Think Natively: Unlocking Multilingual Reasoning with Consistency-Enhanced Reinforcement Learning",
    "url": "https://www.alphaxiv.org/abs/2510.07300v1",
    "arxiv_id": "2510.07300v1",
    "authors": "Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Kaiyu Huang, Yufeng Chen, Jinan Xu, Jie Zhou",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 17:55:02",
    "ori_summary": "Large Reasoning Models (LRMs) have achieved remarkable performance on complex reasoning tasks by adopting the \"think-then-answer\" paradigm, which enhances both accuracy and interpretability. However, current LRMs exhibit two critical limitations when processing non-English languages: (1) They often struggle to maintain input-output language consistency; (2) They generally perform poorly with wrong reasoning paths and lower answer accuracy compared to English. These limitations significantly degrade the user experience for non-English speakers and hinder the global deployment of LRMs. To address these limitations, we propose M-Thinker, which is trained by the GRPO algorithm that involves a Language Consistency (LC) reward and a novel Cross-lingual Thinking Alignment (CTA) reward. Specifically, the LC reward defines a strict constraint on the language consistency between the input, thought, and answer. Besides, the CTA reward compares the model's non-English reasoning paths with its English reasoning path to transfer its own reasoning capability from English to non-English languages. Through an iterative RL procedure, our M-Thinker-1.5B/7B models not only achieve nearly 100% language consistency and superior performance on two multilingual benchmarks (MMATH and PolyMath), but also exhibit excellent generalization on out-of-domain languages.",
    "summary": "",
    "translation": "原生思考：通过一致性增强强化学习解锁多语言推理能力",
    "relevance_score": 3,
    "reasoning": "该论文主要关注多语言推理和强化学习的一致性增强，属于纯粹的NLP技术范畴。虽然强化学习可能在某些推荐系统中应用，但该论文专注于多语言推理，与推荐系统、搜索或广告的核心技术关联度较低。没有明确展示这些技术在推荐、搜索或广告领域的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07293v1": {
    "title": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs",
    "url": "https://www.alphaxiv.org/abs/2510.07293v1",
    "arxiv_id": "2510.07293v1",
    "authors": "Peize He, Zichen Wen, Yubo Wang, Yuxuan Wang, Xiaoqian Liu, Jiajie Huang, Zehui Lei, Zhuangcheng Gu, Xiangqi Jin, Jiabing Yang, Kai Li, Zhifei Liu, Weijia Li, Cunxiang Wang, Conghui He, Linfeng Zhang",
    "categories": "cs.SD, cs.AI, cs.CL, eess.AS",
    "pub_date": "2025-10-08 17:50:16",
    "ori_summary": "Processing long-form audio is a major challenge for Large Audio Language models (LALMs). These models struggle with the quadratic cost of attention ($O(N^2)$) and with modeling long-range temporal dependencies. Existing audio benchmarks are built mostly from short clips and do not evaluate models in realistic long context settings. To address this gap, we introduce AudioMarathon, a benchmark designed to evaluate both understanding and inference efficiency on long-form audio. AudioMarathon provides a diverse set of tasks built upon three pillars: long-context audio inputs with durations ranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of 2,250 to 7,500 audio tokens, respectively, full domain coverage across speech, sound, and music, and complex reasoning that requires multi-hop inference. We evaluate state-of-the-art LALMs and observe clear performance drops as audio length grows. We also study acceleration techniques and analyze the trade-offs of token pruning and KV cache eviction. The results show large gaps across current LALMs and highlight the need for better temporal reasoning and memory-efficient architectures. We believe AudioMarathon will drive the audio and multimodal research community to develop more advanced audio understanding models capable of solving complex audio tasks.",
    "summary": "",
    "translation": "AudioMarathon：面向音频大语言模型的长上下文音频理解与效率的综合基准",
    "relevance_score": 2,
    "reasoning": "该论文主要关注音频领域的基准测试和长上下文理解，属于特定模态（音频）的评估工作。虽然涉及LLM效率，但其核心焦点是音频理解而非推荐系统、搜索或广告应用。音频模态与RecSys/Search/Ads的核心技术栈关联度较低，缺乏明确的跨模态应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07290v1": {
    "title": "On the Convergence of Moral Self-Correction in Large Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.07290v1",
    "arxiv_id": "2510.07290v1",
    "authors": "Guangliang Liu, Haitao Mao, Bochuan Cao, Zhiyu Xue, Xitong Zhang, Rongrong Wang, Kristen Marie Johnson",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 17:46:27",
    "ori_summary": "Large Language Models (LLMs) are able to improve their responses when instructed to do so, a capability known as self-correction. When instructions provide only a general and abstract goal without specific details about potential issues in the response, LLMs must rely on their internal knowledge to improve response quality, a process referred to as intrinsic self-correction. The empirical success of intrinsic self-correction is evident in various applications, but how and why it is effective remains unknown. Focusing on moral self-correction in LLMs, we reveal a key characteristic of intrinsic self-correction: performance convergence through multi-round interactions; and provide a mechanistic analysis of this convergence behavior. Based on our experimental results and analysis, we uncover the underlying mechanism of convergence: consistently injected self-correction instructions activate moral concepts that reduce model uncertainty, leading to converged performance as the activated moral concepts stabilize over successive rounds. This paper demonstrates the strong potential of moral self-correction by showing that it exhibits a desirable property of converged performance.",
    "summary": "",
    "translation": "论大型语言模型中道德自我修正的收敛性",
    "relevance_score": 1,
    "reasoning": "该论文关注LLM的道德自我修正和收敛性，这属于伦理和价值观对齐范畴，与用户指定的无关主题（伦理、公平性等非技术性话题）直接冲突。论文内容纯粹关注LLM的内在道德属性，没有展示任何在推荐系统、搜索或广告领域的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07284v1": {
    "title": "Online Rubrics Elicitation from Pairwise Comparisons",
    "url": "https://www.alphaxiv.org/abs/2510.07284v1",
    "arxiv_id": "2510.07284v1",
    "authors": "MohammadHossein Rezaei, Robert Vacareanu, Zihao Wang, Clinton Wang, Yunzhong He, Afra Feyza Akyürek",
    "categories": "cs.CL, cs.AI, cs.LG",
    "pub_date": "2025-10-08 17:44:59",
    "ori_summary": "Rubrics provide a flexible way to train LLMs on open-ended long-form answers where verifiable rewards are not applicable and human preferences provide coarse signals. Prior work shows that reinforcement learning with rubric-based rewards leads to consistent gains in LLM post-training. Most existing approaches rely on rubrics that remain static over the course of training. Such static rubrics, however, are vulnerable to reward-hacking type behaviors and fail to capture emergent desiderata that arise during training. We introduce Online Rubrics Elicitation (OnlineRubrics), a method that dynamically curates evaluation criteria in an online manner through pairwise comparisons of responses from current and reference policies. This online process enables continuous identification and mitigation of errors as training proceeds. Empirically, this approach yields consistent improvements of up to 8% over training exclusively with static rubrics across AlpacaEval, GPQA, ArenaHard as well as the validation sets of expert questions and rubrics. We qualitatively analyze the elicited criteria and identify prominent themes such as transparency, practicality, organization, and reasoning.",
    "summary": "",
    "translation": "基于成对比较的在线评分标准获取",
    "relevance_score": 2,
    "reasoning": "该论文主要关注从成对比较中获取评分标准，这属于偏好学习的一般方法，与推荐系统有一定相关性。然而，论文没有明确涉及LLM技术、Transformer架构或异构数据建模，且在线评分标准获取的应用范围较广，不专门针对RecSys/Search/Ads领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07248v1": {
    "title": "Don't Adapt Small Language Models for Tools; Adapt Tool Schemas to the Models",
    "url": "https://www.alphaxiv.org/abs/2510.07248v1",
    "arxiv_id": "2510.07248v1",
    "authors": "Jonggeun Lee, Woojung Song, Jongwook Han, Haesung Pyun, Yohan Jo",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 17:16:07",
    "ori_summary": "Small language models (SLMs) offer significant computational advantages for tool-augmented AI systems, yet they struggle with tool-use tasks, particularly in selecting appropriate tools and identifying correct parameters. A common failure mode is schema misalignment: models hallucinate plausible but non-existent tool names that reflect naming conventions internalized during pretraining but absent from the provided tool schema. Rather than forcing models to adapt to arbitrary schemas, we propose adapting schemas to align with models' pretrained knowledge. We introduce PA-Tool (Pretraining-Aligned Tool Schema Generation), a training-free method that leverages peakedness-a signal from contamination detection indicating pretraining familiarity-to automatically rename tool components. By generating multiple candidates and selecting those with highest output concentration across samples, PA-Tool identifies pretrain-aligned naming patterns. Experiments on MetaTool and RoTBench show improvements of up to 17% points, with schema misalignment errors reduced by 80%. PA-Tool enables small models to approach state-of-the-art performance while maintaining computational efficiency for adaptation to new tools without retraining. Our work demonstrates that schema-level interventions can unlock the tool-use potential of resource-efficient models by adapting schemas to models rather than models to schemas.",
    "summary": "该论文研究小语言模型在工具使用任务中的模式对齐问题，核心思想是通过分析预训练熟悉度来自动重命名工具组件，使工具模式适配模型知识而非强制模型适配工具模式。",
    "translation": "不要为工具适配小型语言模型；而应将工具模式适配到模型",
    "relevance_score": 8,
    "reasoning": "这篇论文关注工具使用和模式适配，这是搜索和推荐系统中LLM应用的核心技术。通过将工具模式适配到小型模型，可以显著提升搜索查询理解、推荐工具调用和广告检索的效率，直接适用于资源受限的推荐和搜索部署场景。",
    "rerank_relevance_score": 8,
    "rerank_reasoning": "该论文提出通过适配工具模式而非模型来解决SLM工具使用问题，这一范式转换对推荐系统和搜索中的工具集成具有直接应用价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.07243v1": {
    "title": "LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM Evaluation",
    "url": "https://www.alphaxiv.org/abs/2510.07243v1",
    "arxiv_id": "2510.07243v1",
    "authors": "Joseph Enguehard, Morgane Van Ermengem, Kate Atkinson, Sujeong Cha, Arijit Ghosh Chowdhury, Prashanth Kallur Ramaswamy, Jeremy Roghair, Hannah R Marlowe, Carina Suzana Negreanu, Kitty Boxall, Diana Mincu",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 17:10:47",
    "ori_summary": "Evaluating large language model (LLM) outputs in the legal domain presents unique challenges due to the complex and nuanced nature of legal analysis. Current evaluation approaches either depend on reference data, which is costly to produce, or use standardized assessment methods, both of which have significant limitations for legal applications. Although LLM-as-a-Judge has emerged as a promising evaluation technique, its reliability and effectiveness in legal contexts depend heavily on evaluation processes unique to the legal industry and how trustworthy the evaluation appears to the human legal expert. This is where existing evaluation methods currently fail and exhibit considerable variability. This paper aims to close the gap: a) we break down lengthy responses into 'Legal Data Points' (LDPs), self-contained units of information, and introduce a novel, reference-free evaluation methodology that reflects how lawyers evaluate legal answers; b) we demonstrate that our method outperforms a variety of baselines on both our proprietary dataset and an open-source dataset (LegalBench); c) we show how our method correlates more closely with human expert evaluations and helps improve inter-annotator agreement; and finally d) we open source our Legal Data Points for a subset of LegalBench used in our experiments, allowing the research community to replicate our results and advance research in this vital area of LLM evaluation on legal question-answering.",
    "summary": "",
    "translation": "LeMAJ（法律大语言模型即法官）：连接法律推理与大语言模型评估",
    "relevance_score": 2,
    "reasoning": "该论文专注于法律领域的LLM应用和评估，属于特定领域应用而非核心推荐系统、搜索或广告技术。虽然涉及LLM评估，但这是纯粹的法律领域应用，没有展示在推荐/搜索/广告领域的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07242v1": {
    "title": "Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense",
    "url": "https://www.alphaxiv.org/abs/2510.07242v1",
    "arxiv_id": "2510.07242v1",
    "authors": "Leitian Tao, Ilia Kulikov, Swarnadeep Saha, Tianlu Wang, Jing Xu, Yixuan Li, Jason E Weston, Ping Yu",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 17:09:41",
    "ori_summary": "Post-training for reasoning of large language models (LLMs) increasingly relies on verifiable rewards: deterministic checkers that provide 0-1 correctness signals. While reliable, such binary feedback is brittle--many tasks admit partially correct or alternative answers that verifiers under-credit, and the resulting all-or-nothing supervision limits learning. Reward models offer richer, continuous feedback, which can serve as a complementary supervisory signal to verifiers. We introduce HERO (Hybrid Ensemble Reward Optimization), a reinforcement learning framework that integrates verifier signals with reward-model scores in a structured way. HERO employs stratified normalization to bound reward-model scores within verifier-defined groups, preserving correctness while refining quality distinctions, and variance-aware weighting to emphasize challenging prompts where dense signals matter most. Across diverse mathematical reasoning benchmarks, HERO consistently outperforms RM-only and verifier-only baselines, with strong gains on both verifiable and hard-to-verify tasks. Our results show that hybrid reward design retains the stability of verifiers while leveraging the nuance of reward models to advance reasoning.",
    "summary": "",
    "translation": "混合强化学习：当奖励稀疏时，采用密集策略更优",
    "relevance_score": 2,
    "reasoning": "该论文主要关注强化学习中奖励稀疏性问题的技术改进，属于纯粹的强化学习研究领域。虽然强化学习在推荐系统中偶有应用，但论文标题未表明与推荐系统、搜索或广告的具体关联，也未涉及LLM、Transformer架构或多模态建模等当前关注的核心技术方向。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07239v1": {
    "title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts",
    "url": "https://www.alphaxiv.org/abs/2510.07239v1",
    "arxiv_id": "2510.07239v1",
    "authors": "Christos Ziakas, Nicholas Loo, Nishita Jain, Alessandra Russo",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 17:06:20",
    "ori_summary": "Automated red-teaming has emerged as a scalable approach for auditing Large Language Models (LLMs) prior to deployment, yet existing approaches lack mechanisms to efficiently adapt to model-specific vulnerabilities at inference. We introduce Red-Bandit, a red-teaming framework that adapts online to identify and exploit model failure modes under distinct attack styles (e.g., manipulation, slang). Red-Bandit post-trains a set of parameter-efficient LoRA experts, each specialized for a particular attack style, using reinforcement learning that rewards the generation of unsafe prompts via a rule-based safety model. At inference, a multi-armed bandit policy dynamically selects among these attack-style experts based on the target model's response safety, balancing exploration and exploitation. Red-Bandit achieves state-of-the-art results on AdvBench under sufficient exploration (ASR@10), while producing more human-readable prompts (lower perplexity). Moreover, Red-Bandit's bandit policy serves as a diagnostic tool for uncovering model-specific vulnerabilities by indicating which attack styles most effectively elicit unsafe behaviors.",
    "summary": "",
    "translation": "红队-Bandit：通过Bandit引导的LoRA专家进行LLM红队测试的测试时适应",
    "relevance_score": 2,
    "reasoning": "这篇论文主要关注LLM红队测试（安全测试）和测试时适应，这属于安全评估领域，与推荐系统、搜索或广告的核心技术无关。虽然提到了LoRA技术，但其应用场景是安全测试而非推荐/搜索/广告系统的改进，因此相关性很低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07238v1": {
    "title": "When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation",
    "url": "https://www.alphaxiv.org/abs/2510.07238v1",
    "arxiv_id": "2510.07238v1",
    "authors": "Xunyi Jiang, Dingyi Chang, Julian McAuley, Xin Xu",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 17:06:07",
    "ori_summary": "The rapid evolution of large language models (LLMs) and the real world has outpaced the static nature of widely used evaluation benchmarks, raising concerns about their reliability for evaluating LLM factuality. While substantial works continue to rely on the popular but old benchmarks, their temporal misalignment with real-world facts and modern LLMs, and their effects on LLM factuality evaluation remain underexplored. Therefore, in this work, we present a systematic investigation of this issue by examining five popular factuality benchmarks and eight LLMs released across different years. An up-to-date fact retrieval pipeline and three metrics are tailored to quantify benchmark aging and its impact on LLM factuality evaluation. Experimental results and analysis illustrate that a considerable portion of samples in the widely used factuality benchmarks are outdated, leading to unreliable assessments of LLM factuality. We hope our work can provide a testbed to assess the reliability of a benchmark for LLM factuality evaluation and inspire more research on the benchmark aging issue. Codes are available in https://github.com/JiangXunyi/BenchAge.",
    "summary": "",
    "translation": "当基准老化：通过大语言模型事实性评估的时间错位",
    "relevance_score": 1,
    "reasoning": "该论文关注LLM事实性评估和基准老化问题，这属于纯粹的NLP评估基准范畴，与我的关注点无关。论文没有涉及推荐系统、搜索或广告的核心进展，也没有展示任何在Transformer架构效率、LLM应用或异构数据建模方面的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07233v1": {
    "title": "LAD-RAG: Layout-aware Dynamic RAG for Visually-Rich Document Understanding",
    "url": "https://www.alphaxiv.org/abs/2510.07233v1",
    "arxiv_id": "2510.07233v1",
    "authors": "Zhivar Sourati, Zheng Wang, Marianne Menglin Liu, Yazhe Hu, Mengqing Guo, Sujeeth Bharadwaj, Kyu Han, Tao Sheng, Sujith Ravi, Morteza Dehghani, Dan Roth",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 17:02:04",
    "ori_summary": "Question answering over visually rich documents (VRDs) requires reasoning not only over isolated content but also over documents' structural organization and cross-page dependencies. However, conventional retrieval-augmented generation (RAG) methods encode content in isolated chunks during ingestion, losing structural and cross-page dependencies, and retrieve a fixed number of pages at inference, regardless of the specific demands of the question or context. This often results in incomplete evidence retrieval and degraded answer quality for multi-page reasoning tasks. To address these limitations, we propose LAD-RAG, a novel Layout-Aware Dynamic RAG framework. During ingestion, LAD-RAG constructs a symbolic document graph that captures layout structure and cross-page dependencies, adding it alongside standard neural embeddings to yield a more holistic representation of the document. During inference, an LLM agent dynamically interacts with the neural and symbolic indices to adaptively retrieve the necessary evidence based on the query. Experiments on MMLongBench-Doc, LongDocURL, DUDE, and MP-DocVQA demonstrate that LAD-RAG improves retrieval, achieving over 90% perfect recall on average without any top-k tuning, and outperforming baseline retrievers by up to 20% in recall at comparable noise levels, yielding higher QA accuracy with minimal latency.",
    "summary": "",
    "translation": "LAD-RAG：面向视觉丰富文档理解的布局感知动态检索增强生成",
    "relevance_score": 2,
    "reasoning": "该论文主要关注视觉丰富文档理解，属于文档处理领域而非推荐系统、搜索或广告的核心技术。虽然RAG技术本身在搜索中有应用，但该工作的布局感知和视觉文档焦点使其与我的关注领域关联度较低，缺乏明确的推荐/搜索/广告应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07231v1": {
    "title": "Benchmarking LLM Causal Reasoning with Scientifically Validated Relationships",
    "url": "https://www.alphaxiv.org/abs/2510.07231v1",
    "arxiv_id": "2510.07231v1",
    "authors": "Donggyu Lee, Sungwon Park, Yerin Hwang, Hyunwoo Oh, Hyoshin Kim, Jungwon Kim, Meeyoung Cha, Sangyoon Park, Jihee Kim",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 17:00:49",
    "ori_summary": "Causal reasoning is fundamental for Large Language Models (LLMs) to understand genuine cause-and-effect relationships beyond pattern matching. Existing benchmarks suffer from critical limitations such as reliance on synthetic data and narrow domain coverage. We introduce a novel benchmark constructed from casually identified relationships extracted from top-tier economics and finance journals, drawing on rigorous methodologies including instrumental variables, difference-in-differences, and regression discontinuity designs. Our benchmark comprises 40,379 evaluation items covering five task types across domains such as health, environment, technology, law, and culture. Experimental results on eight state-of-the-art LLMs reveal substantial limitations, with the best model achieving only 57.6\\% accuracy. Moreover, model scale does not consistently translate to superior performance, and even advanced reasoning models struggle with fundamental causal relationship identification. These findings underscore a critical gap between current LLM capabilities and demands of reliable causal reasoning in high-stakes applications.",
    "summary": "",
    "translation": "基于科学验证关系的LLM因果推理基准测试",
    "relevance_score": 2,
    "reasoning": "该论文主要关注LLM因果推理的基准测试和评估，这属于纯粹的NLP评估基准范畴，与我的核心关注点无关。虽然因果推理在推荐系统中可能有潜在应用，但该论文的重点是基准测试而非实际应用，且没有明确指向推荐、搜索或广告领域的特定应用场景。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07230v1": {
    "title": "Customer-R1: Personalized Simulation of Human Behaviors via RL-based LLM Agent in Online Shopping",
    "url": "https://www.alphaxiv.org/abs/2510.07230v1",
    "arxiv_id": "2510.07230v1",
    "authors": "Ziyi Wang, Yuxuan Lu, Yimeng Zhang, Jing Huang, Dakuo Wang",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 17:00:25",
    "ori_summary": "Simulating step-wise human behavior with Large Language Models (LLMs) has become an emerging research direction, enabling applications in various practical domains. While prior methods, including prompting, supervised fine-tuning (SFT), and reinforcement learning (RL), have shown promise in modeling step-wise behavior, they primarily learn a population-level policy without conditioning on a user's persona, yielding generic rather than personalized simulations. In this work, we pose a critical question: how can LLM agents better simulate personalized user behavior? We introduce Customer-R1, an RL-based method for personalized, step-wise user behavior simulation in online shopping environments. Our policy is conditioned on an explicit persona, and we optimize next-step rationale and action generation via action correctness reward signals. Experiments on the OPeRA dataset emonstrate that Customer-R1 not only significantly outperforms prompting and SFT-based baselines in next-action prediction tasks, but also better matches users' action distribution, indicating higher fidelity in personalized behavior simulation.",
    "summary": "该论文研究如何让LLM代理更好地模拟个性化用户行为。核心方法是提出基于强化学习的Customer-R1框架，通过显式用户画像条件化和动作正确性奖励信号来优化逐步行为生成。",
    "translation": "Customer-R1：基于强化学习的LLM智能体在在线购物中实现个性化人类行为模拟",
    "relevance_score": 9,
    "reasoning": "该论文直接结合了RL-based LLM Agent技术来模拟在线购物场景中的个性化用户行为，这属于'Direct LLM Applications'范畴。通过模拟真实用户行为，该技术可以显著改进推荐系统和搜索系统的用户建模与个性化服务，具有明确的RecSys应用价值。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文直接针对个性化用户行为模拟这一推荐系统核心问题，提出基于强化学习的LLM代理方法，完美契合个性化推荐和LLM应用的研究重点。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.07227v1": {
    "title": "Where to Begin: Efficient Pretraining via Subnetwork Selection and Distillation",
    "url": "https://www.alphaxiv.org/abs/2510.07227v1",
    "arxiv_id": "2510.07227v1",
    "authors": "Arjun Krishnakumar, Rhea Sanjay Sukthanker, Hannan Javed Mahadik, Gabriela Kadlecová, Vladyslav Moroshan, Timur Carstensen, Frank Hutter, Aaron Klein",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 16:57:46",
    "ori_summary": "Small Language models (SLMs) offer an efficient and accessible alternative to Large Language Models (LLMs), delivering strong performance while using far fewer resources. We introduce a simple and effective framework for pretraining SLMs that brings together three complementary ideas. First, we identify structurally sparse sub-network initializations that consistently outperform randomly initialized models of similar size under the same compute budget. Second, we use evolutionary search to automatically discover high-quality sub-network initializations, providing better starting points for pretraining. Third, we apply knowledge distillation from larger teacher models to speed up training and improve generalization. Together, these components make SLM pretraining substantially more efficient: our best model, discovered using evolutionary search and initialized with LLM weights, matches the validation perplexity of a comparable Pythia SLM while requiring 9.2x fewer pretraining tokens. We release all code and models at https://github.com/whittle-org/whittle/, offering a practical and reproducible path toward cost-efficient small language model development at scale.",
    "summary": "研究如何高效预训练小型语言模型；核心方法是通过结构稀疏子网络初始化、进化搜索和知识蒸馏来优化预训练起点和效率。",
    "translation": "从何处开始：通过子网络选择与蒸馏实现高效预训练",
    "relevance_score": 8,
    "reasoning": "该论文聚焦于高效预训练技术，属于'使能LLM技术'范畴。子网络选择与蒸馏方法可显著降低LLM预训练成本，这对于需要频繁更新模型的推荐系统和搜索系统具有直接应用价值，能够加速模型迭代并降低计算开销。",
    "rerank_relevance_score": 7,
    "rerank_reasoning": "该论文提出的子网络选择和蒸馏方法直接针对LLM效率优化，对推荐系统中的模型部署和资源优化具有重要参考价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.07226v1": {
    "title": "Machines in the Crowd? Measuring the Footprint of Machine-Generated Text on Reddit",
    "url": "https://www.alphaxiv.org/abs/2510.07226v1",
    "arxiv_id": "2510.07226v1",
    "authors": "Lucio La Cava, Luca Maria Aiello, Andrea Tagarelli",
    "categories": "cs.SI, cs.CL, cs.CY, physics.soc-ph",
    "pub_date": "2025-10-08 16:57:45",
    "ori_summary": "Generative Artificial Intelligence is reshaping online communication by enabling large-scale production of Machine-Generated Text (MGT) at low cost. While its presence is rapidly growing across the Web, little is known about how MGT integrates into social media environments. In this paper, we present the first large-scale characterization of MGT on Reddit. Using a state-of-the-art statistical method for detection of MGT, we analyze over two years of activity (2022-2024) across 51 subreddits representative of Reddit's main community types such as information seeking, social support, and discussion. We study the concentration of MGT across communities and over time, and compared MGT to human-authored text in terms of social signals it expresses and engagement it receives. Our very conservative estimate of MGT prevalence indicates that synthetic text is marginally present on Reddit, but it can reach peaks of up to 9% in some communities in some months. MGT is unevenly distributed across communities, more prevalent in subreddits focused on technical knowledge and social support, and often concentrated in the activity of a small fraction of users. MGT also conveys distinct social signals of warmth and status giving typical of language of AI assistants. Despite these stylistic differences, MGT achieves engagement levels comparable than human-authored content and in a few cases even higher, suggesting that AI-generated text is becoming an organic component of online social discourse. This work offers the first perspective on the MGT footprint on Reddit, paving the way for new investigations involving platform governance, detection strategies, and community dynamics.",
    "summary": "",
    "translation": "群体中的机器？衡量机器生成文本在Reddit上的足迹",
    "relevance_score": 2,
    "reasoning": "该论文主要关注检测和衡量社交媒体上的机器生成内容，这属于内容安全和技术检测范畴。虽然涉及文本生成技术，但缺乏与推荐系统、搜索或广告排名的直接关联，也没有展示这些技术在核心领域的新应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07221v1": {
    "title": "How much speech data is necessary for ASR in African languages? An evaluation of data scaling in Kinyarwanda and Kikuyu",
    "url": "https://www.alphaxiv.org/abs/2510.07221v1",
    "arxiv_id": "2510.07221v1",
    "authors": "Benjamin Akera, Evelyn Nafula, Patrick Walukagga, Gilbert Yiga, John Quinn, Ernest Mwebaze",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 16:55:28",
    "ori_summary": "The development of Automatic Speech Recognition (ASR) systems for low-resource African languages remains challenging due to limited transcribed speech data. While recent advances in large multilingual models like OpenAI's Whisper offer promising pathways for low-resource ASR development, critical questions persist regarding practical deployment requirements. This paper addresses two fundamental concerns for practitioners: determining the minimum data volumes needed for viable performance and characterizing the primary failure modes that emerge in production systems. We evaluate Whisper's performance through comprehensive experiments on two Bantu languages: systematic data scaling analysis on Kinyarwanda using training sets from 1 to 1,400 hours, and detailed error characterization on Kikuyu using 270 hours of training data. Our scaling experiments demonstrate that practical ASR performance (WER < 13\\%) becomes achievable with as little as 50 hours of training data, with substantial improvements continuing through 200 hours (WER < 10\\%). Complementing these volume-focused findings, our error analysis reveals that data quality issues, particularly noisy ground truth transcriptions, account for 38.6\\% of high-error cases, indicating that careful data curation is as critical as data volume for robust system performance. These results provide actionable benchmarks and deployment guidance for teams developing ASR systems across similar low-resource language contexts. We release accompanying and models see https://github.com/SunbirdAI/kinyarwanda-whisper-eval",
    "summary": "",
    "translation": "非洲语言自动语音识别需要多少语音数据？基尼亚卢旺达语和基库尤语数据规模扩展评估",
    "relevance_score": 1,
    "reasoning": "该论文专注于非洲语言的自动语音识别（ASR）数据需求评估，属于语音处理领域。虽然语音识别在技术上与搜索相关，但论文明确聚焦于非洲语言的特定数据需求，没有涉及推荐系统、广告或搜索的核心技术进展，也没有讨论LLM或Transformer架构的潜在应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07213v1": {
    "title": "Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.07213v1",
    "arxiv_id": "2510.07213v1",
    "authors": "Chengzhi Zhong, Fei Cheng, Qianying Liu, Yugo Murawaki, Chenhui Chu, Sadao Kurohashi",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 16:46:57",
    "ori_summary": "Large language models exhibit strong multilingual capabilities despite limited exposure to non-English data. Prior studies show that English-centric large language models map multilingual content into English-aligned representations at intermediate layers and then project them back into target-language token spaces in the final layer. From this observation, we hypothesize that this cross-lingual transition is governed by a small and sparse set of dimensions, which occur at consistent indices across the intermediate to final layers. Building on this insight, we introduce a simple, training-free method to identify and manipulate these dimensions, requiring only as few as 50 sentences of either parallel or monolingual data. Experiments on a multilingual generation control task reveal the interpretability of these dimensions, demonstrating that the interventions in these dimensions can switch the output language while preserving semantic content, and that it surpasses the performance of prior neuron-based approaches at a substantially lower cost.",
    "summary": "",
    "translation": "语言存在于稀疏维度：面向大语言模型的可解释高效多语言控制",
    "relevance_score": 7,
    "reasoning": "该论文涉及LLM的多语言控制和稀疏维度，属于核心LLM技术的进步。稀疏表示和高效控制机制在推荐系统和搜索中有直接应用潜力，可用于多语言用户建模、跨语言内容理解和高效的个性化服务部署，特别是在处理多语言用户查询和内容时。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.07203v1": {
    "title": "Sunflower: A New Approach To Expanding Coverage of African Languages in Large Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.07203v1",
    "arxiv_id": "2510.07203v1",
    "authors": "Benjamin Akera, Evelyn Nafula Ouma, Gilbert Yiga, Patrick Walukagga, Phionah Natukunda, Trevor Saaka, Solomon Nsumba, Lilian Teddy Nabukeera, Joel Muhanguzi, Imran Sekalala, Nimpamya Janat Namara, Engineer Bainomugisha, Ernest Mwebaze, John Quinn",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 16:35:53",
    "ori_summary": "There are more than 2000 living languages in Africa, most of which have been bypassed by advances in language technology. Current leading LLMs exhibit strong performance on a number of the most common languages (e.g. Swahili or Yoruba), but prioritise support for the languages with the most speakers first, resulting in piecemeal ability across disparate languages. We contend that a regionally focussed approach is more efficient, and present a case study for Uganda, a country with high linguistic diversity. We describe the development of Sunflower 14B and 32B, a pair of models based on Qwen 3 with state of the art comprehension in the majority of all Ugandan languages. These models are open source and can be used to reduce language barriers in a number of important practical applications.",
    "summary": "",
    "translation": "向日葵：一种在大型语言模型中扩展非洲语言覆盖范围的新方法",
    "relevance_score": 2,
    "reasoning": "该论文主要关注多语言能力扩展，特别是非洲语言的覆盖范围，这属于LLM基础能力的改进。虽然多语言能力对于全球化的推荐和搜索系统有一定价值，但该工作更偏向于语言覆盖的广度扩展，而非核心架构或效率改进，与当前关注的Transformer架构进展、推荐系统核心算法或异构数据建模的直接关联性较弱。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07178v1": {
    "title": "Biasless Language Models Learn Unnaturally: How LLMs Fail to Distinguish the Possible from the Impossible",
    "url": "https://www.alphaxiv.org/abs/2510.07178v1",
    "arxiv_id": "2510.07178v1",
    "authors": "Imry Ziv, Nur Lan, Emmanuel Chemla, Roni Katzir",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 16:17:13",
    "ori_summary": "Are large language models (LLMs) sensitive to the distinction between humanly possible languages and humanly impossible languages? This question is taken by many to bear on whether LLMs and humans share the same innate learning biases. Previous work has attempted to answer it in the positive by comparing LLM learning curves on existing language datasets and on \"impossible\" datasets derived from them via various perturbation functions. Using the same methodology, we examine this claim on a wider set of languages and impossible perturbations. We find that in most cases, GPT-2 learns each language and its impossible counterpart equally easily, in contrast to previous claims. We also apply a more lenient condition by testing whether GPT-2 provides any kind of separation between the whole set of natural languages and the whole set of impossible languages. By considering cross-linguistic variance in various metrics computed on the perplexity curves, we show that GPT-2 provides no systematic separation between the possible and the impossible. Taken together, these perspectives show that LLMs do not share the human innate biases that shape linguistic typology.",
    "summary": "",
    "translation": "无偏见语言模型学习不自然：LLMs如何无法区分可能与不可能",
    "relevance_score": 2,
    "reasoning": "该论文主要关注语言模型的偏见问题和区分可能/不可能的能力，这属于纯粹的LLM评估和基准测试范畴。虽然LLM评估可能间接影响推荐/搜索系统，但论文标题明确聚焦于LLM的内在学习缺陷而非实际应用，且属于被排除的'评估基准'和'纯粹NLP主题'类别。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07177v1": {
    "title": "CARPAS: Towards Content-Aware Refinement of Provided Aspects for Summarization in Large Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.07177v1",
    "arxiv_id": "2510.07177v1",
    "authors": "Yong-En Tian, Yu-Chien Tang, An-Zi Yen, Wen-Chih Peng",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 16:16:46",
    "ori_summary": "Aspect-based summarization has attracted significant attention for its ability to generate more fine-grained and user-aligned summaries. While most existing approaches assume a set of predefined aspects as input, real-world scenarios often present challenges where these given aspects may be incomplete, irrelevant, or entirely missing from the document. Users frequently expect systems to adaptively refine or filter the provided aspects based on the actual content. In this paper, we initiate this novel task setting, termed Content-Aware Refinement of Provided Aspects for Summarization (CARPAS), with the aim of dynamically adjusting the provided aspects based on the document context before summarizing. We construct three new datasets to facilitate our pilot experiments, and by using LLMs with four representative prompting strategies in this task, we find that LLMs tend to predict an overly comprehensive set of aspects, which often results in excessively long and misaligned summaries. Building on this observation, we propose a preliminary subtask to predict the number of relevant aspects, and demonstrate that the predicted number can serve as effective guidance for the LLMs, reducing the inference difficulty, and enabling them to focus on the most pertinent aspects. Our extensive experiments show that the proposed approach significantly improves performance across all datasets. Moreover, our deeper analyses uncover LLMs' compliance when the requested number of aspects differs from their own estimations, establishing a crucial insight for the deployment of LLMs in similar real-world applications.",
    "summary": "",
    "translation": "CARPAS：面向大语言模型摘要任务的内容感知提供方面细化",
    "relevance_score": 2,
    "reasoning": "该论文主要关注大语言模型在摘要生成任务中的内容感知技术，属于纯粹的LLM应用范畴。虽然摘要技术在某些搜索场景中可能有间接应用，但论文本身没有明确展示在推荐系统、搜索或广告中的直接应用潜力，与当前关注的核心领域相关性较弱。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07175v1": {
    "title": "Quantifying Data Contamination in Psychometric Evaluations of LLMs",
    "url": "https://www.alphaxiv.org/abs/2510.07175v1",
    "arxiv_id": "2510.07175v1",
    "authors": "Jongwook Han, Woojung Song, Jonggeun Lee, Yohan Jo",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 16:16:20",
    "ori_summary": "Recent studies apply psychometric questionnaires to Large Language Models (LLMs) to assess high-level psychological constructs such as values, personality, moral foundations, and dark traits. Although prior work has raised concerns about possible data contamination from psychometric inventories, which may threaten the reliability of such evaluations, there has been no systematic attempt to quantify the extent of this contamination. To address this gap, we propose a framework to systematically measure data contamination in psychometric evaluations of LLMs, evaluating three aspects: (1) item memorization, (2) evaluation memorization, and (3) target score matching. Applying this framework to 21 models from major families and four widely used psychometric inventories, we provide evidence that popular inventories such as the Big Five Inventory (BFI-44) and Portrait Values Questionnaire (PVQ-40) exhibit strong contamination, where models not only memorize items but can also adjust their responses to achieve specific target scores.",
    "summary": "",
    "translation": "量化大语言模型心理测量评估中的数据污染",
    "relevance_score": 1,
    "reasoning": "该论文关注LLM评估中的数据污染问题，这属于纯粹的评估基准研究，与您的核心关注点（推荐系统、搜索、广告的技术进展及LLM应用）无关。论文内容涉及评估方法论而非实际技术应用，属于您明确排除的无关主题范畴。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07173v1": {
    "title": "NurseLLM: The First Specialized Language Model for Nursing",
    "url": "https://www.alphaxiv.org/abs/2510.07173v1",
    "arxiv_id": "2510.07173v1",
    "authors": "Md Tawkat Islam Khondaker, Julia Harrington, Shady Shehata",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 16:15:06",
    "ori_summary": "Recent advancements in large language models (LLMs) have significantly transformed medical systems. However, their potential within specialized domains such as nursing remains largely underexplored. In this work, we introduce NurseLLM, the first nursing-specialized LLM tailored for multiple choice question-answering (MCQ) tasks. We develop a multi-stage data generation pipeline to build the first large scale nursing MCQ dataset to train LLMs on a broad spectrum of nursing topics. We further introduce multiple nursing benchmarks to enable rigorous evaluation. Our extensive experiments demonstrate that NurseLLM outperforms SoTA general-purpose and medical-specialized LLMs of comparable size on different benchmarks, underscoring the importance of a specialized LLM for the nursing domain. Finally, we explore the role of reasoning and multi-agent collaboration systems in nursing, highlighting their promise for future research and applications.",
    "summary": "",
    "translation": "NurseLLM：首个面向护理领域的专用语言模型",
    "relevance_score": 1,
    "reasoning": "该论文专注于医疗护理领域的专用语言模型开发，属于明确的医疗领域应用。这与我的关注点完全无关，我的关注点仅限于推荐系统、搜索和广告领域的技术进展，以及在这些领域中应用的LLM和Transformer技术。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07169v1": {
    "title": "More Data or Better Data? A Critical Analysis of Data Selection and Synthesis for Mathematical Reasoning",
    "url": "https://www.alphaxiv.org/abs/2510.07169v1",
    "arxiv_id": "2510.07169v1",
    "authors": "Yike Zhao, Simin Guo, Ziqing Yang, Shifan Han, Dahua Lin, Fei Tan",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 16:07:26",
    "ori_summary": "The reasoning capabilities of Large Language Models (LLMs) play a critical role in many downstream tasks, yet depend strongly on the quality of training data. Despite various proposed data construction methods, their practical utility in real-world pipelines remains underexplored. In this work, we conduct a comprehensive analysis of open-source datasets and data synthesis techniques for mathematical reasoning, evaluating them under a unified pipeline designed to mirror training and deployment scenarios. We further distill effective data selection strategies and identify practical methods suitable for industrial applications. Our findings highlight that structuring data in more interpretable formats, or distilling from stronger models often outweighs simply scaling up data volume. This study provides actionable guidance for integrating training data to enhance LLM capabilities, supporting both cost-effective data curation and scalable model enhancement. We hope this work will inspire further research on how to balance \"more data\" versus \"better data\" for real-world reasoning tasks.",
    "summary": "",
    "translation": "更多数据还是更好数据？数学推理中数据选择与合成的关键分析",
    "relevance_score": 2,
    "reasoning": "该论文主要关注数学推理领域的数据选择与合成问题，属于特定领域的数据处理研究。虽然数据质量对推荐系统和搜索有普遍重要性，但论文聚焦于数学推理这一与RecSys/Search/Ads核心领域无关的特定应用场景，缺乏明确的跨领域应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07167v1": {
    "title": "Reasoning for Hierarchical Text Classification: The Case of Patents",
    "url": "https://www.alphaxiv.org/abs/2510.07167v1",
    "arxiv_id": "2510.07167v1",
    "authors": "Lekang Jiang, Wenjun Sun, Stephan Goetz",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 16:06:04",
    "ori_summary": "Hierarchical text classification (HTC) assigns documents to multiple levels of a pre-defined taxonomy. Automated patent subject classification represents one of the hardest HTC scenarios because of domain knowledge difficulty and a huge number of labels. Prior approaches only output a flat label set, which offers little insight into the reason behind predictions. Therefore, we propose Reasoning for Hierarchical Classification (RHC), a novel framework that reformulates HTC as a step-by-step reasoning task to sequentially deduce hierarchical labels. RHC trains large language models (LLMs) in two stages: a cold-start stage that aligns outputs with chain-of-thought (CoT) reasoning format and a reinforcement learning (RL) stage to enhance multi-step reasoning ability. RHC demonstrates four advantages in our experiments. (1) Effectiveness: RHC surpasses previous baselines and outperforms the supervised fine-tuning counterparts by approximately 3% in accuracy and macro F1. (2) Explainability: RHC produces natural-language justifications before prediction to facilitate human inspection. (3) Scalability: RHC scales favorably with model size with larger gains compared to standard fine-tuning. (4) Applicability: Beyond patents, we further demonstrate that RHC achieves state-of-the-art performance on other widely used HTC benchmarks, which highlights its broad applicability.",
    "summary": "",
    "translation": "分层文本分类的推理机制：以专利为例",
    "relevance_score": 2,
    "reasoning": "该论文专注于专利领域的分层文本分类任务，这属于特定领域的文档分类问题。虽然文本分类技术可能间接应用于搜索系统中的文档组织，但论文的核心焦点是专利这一特定领域的分层分类，与推荐系统、搜索或广告的核心进展关联度很低，且未涉及LLM、Transformer架构或异构数据统一建模等关键技术方向。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07147v1": {
    "title": "A Multi-Agent Framework for Stateful Inference-Time Search",
    "url": "https://www.alphaxiv.org/abs/2510.07147v1",
    "arxiv_id": "2510.07147v1",
    "authors": "Arshika Lalan, Rajat Ghosh, Aditya Kolsur, Debojyoti Dutta",
    "categories": "cs.LG, cs.AI, cs.CL, cs.MA, cs.SE",
    "pub_date": "2025-10-08 15:48:41",
    "ori_summary": "Recent work explores agentic inference-time techniques to perform structured, multi-step reasoning. However, stateless inference often struggles on multi-step tasks due to the absence of persistent state. Moreover, task-specific fine-tuning or instruction-tuning often achieve surface-level code generation but remain brittle on tasks requiring deeper reasoning and long-horizon dependencies. To address these limitations, we propose stateful multi-agent evolutionary search, a training-free framework that departs from prior stateless approaches by combining (i) persistent inference-time state, (ii) adversarial mutation, and (iii) evolutionary preservation. We demonstrate its effectiveness in automated unit test generation through the generation of edge cases. We generate robust edge cases using an evolutionary search process, where specialized agents sequentially propose, mutate, and score candidates. A controller maintains persistent state across generations, while evolutionary preservation ensures diversity and exploration across all possible cases. This yields a generalist agent capable of discovering robust, high-coverage edge cases across unseen codebases. Experiments show our stateful multi-agent inference framework achieves substantial gains in coverage over stateless single-step baselines, evaluated on prevalent unit-testing benchmarks such as HumanEval and TestGenEvalMini and using three diverse LLM families - Llama, Gemma, and GPT. These results indicate that combining persistent inference-time state with evolutionary search materially improves unit-test generation.",
    "summary": "",
    "translation": "一种用于有状态推理时搜索的多智能体框架",
    "relevance_score": 3,
    "reasoning": "该论文涉及推理时搜索和多智能体框架，可能对搜索系统有一定相关性。然而，标题没有明确说明与推荐系统、搜索或广告的具体应用，也没有提到LLMs或Transformer架构，因此相关性有限。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07141v1": {
    "title": "Comparing human and language models sentence processing difficulties on complex structures",
    "url": "https://www.alphaxiv.org/abs/2510.07141v1",
    "arxiv_id": "2510.07141v1",
    "authors": "Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 15:42:49",
    "ori_summary": "Large language models (LLMs) that fluently converse with humans are a reality - but do LLMs experience human-like processing difficulties? We systematically compare human and LLM sentence comprehension across seven challenging linguistic structures. We collect sentence comprehension data from humans and five families of state-of-the-art LLMs, varying in size and training procedure in a unified experimental framework. Our results show LLMs overall struggle on the target structures, but especially on garden path (GP) sentences. Indeed, while the strongest models achieve near perfect accuracy on non-GP structures (93.7% for GPT-5), they struggle on GP structures (46.8% for GPT-5). Additionally, when ranking structures based on average performance, rank correlation between humans and models increases with parameter count. For each target structure, we also collect data for their matched baseline without the difficult structure. Comparing performance on the target vs. baseline sentences, the performance gap observed in humans holds for LLMs, with two exceptions: for models that are too weak performance is uniformly low across both sentence types, and for models that are too strong the performance is uniformly high. Together, these reveal convergence and divergence in human and LLM sentence comprehension, offering new insights into the similarity of humans and LLMs.",
    "summary": "",
    "translation": "比较人类和语言模型在复杂结构上的句子处理困难",
    "relevance_score": 2,
    "reasoning": "该论文主要关注语言模型与人类在句子处理困难方面的比较，属于纯NLP基准评估范畴。虽然涉及语言模型分析，但缺乏明确的推荐系统、搜索或广告应用场景，且更偏向认知科学和模型评估，而非实际应用技术。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07118v1": {
    "title": "TRIM: Token-wise Attention-Derived Saliency for Data-Efficient Instruction Tuning",
    "url": "https://www.alphaxiv.org/abs/2510.07118v1",
    "arxiv_id": "2510.07118v1",
    "authors": "Manish Nagaraj, Sakshi Choudhary, Utkarsh Saxena, Deepak Ravikumar, Kaushik Roy",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 15:11:04",
    "ori_summary": "Instruction tuning is essential for aligning large language models (LLMs) to downstream tasks and commonly relies on large, diverse corpora. However, small, high-quality subsets, known as coresets, can deliver comparable or superior results, though curating them remains challenging. Existing methods often rely on coarse, sample-level signals like gradients, an approach that is computationally expensive and overlooks fine-grained features. To address this, we introduce TRIM (Token Relevance via Interpretable Multi-layer Attention), a forward-only, token-centric framework. Instead of using gradients, TRIM operates by matching underlying representational patterns identified via attention-based \"fingerprints\" from a handful of target samples. Such an approach makes TRIM highly efficient and uniquely sensitive to the structural features that define a task. Coresets selected by our method consistently outperform state-of-the-art baselines by up to 9% on downstream tasks and even surpass the performance of full-data fine-tuning in some settings. By avoiding expensive backward passes, TRIM achieves this at a fraction of the computational cost. These findings establish TRIM as a scalable and efficient alternative for building high-quality instruction-tuning datasets.",
    "summary": "",
    "translation": "TRIM：基于逐词注意力推导显著性的数据高效指令微调",
    "relevance_score": 6,
    "reasoning": "该论文提出通过注意力机制识别关键token进行数据高效指令微调，属于Enabling LLM Tech范畴。这种数据高效微调技术可应用于推荐系统和搜索中的用户意图理解与个性化响应生成，通过减少训练数据需求来降低计算成本。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.07105v1": {
    "title": "Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples via Meta-Learning",
    "url": "https://www.alphaxiv.org/abs/2510.07105v1",
    "arxiv_id": "2510.07105v1",
    "authors": "Taylor Sorensen, Yejin Choi",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 14:59:24",
    "ori_summary": "Many natural language processing (NLP) tasks involve subjectivity, ambiguity, or legitimate disagreement between annotators. In this paper, we outline our system for modeling human variation. Our system leverages language models' (LLMs) in-context learning abilities, along with a two-step meta-learning training procedure for 1) post-training on many datasets requiring in-context learning and 2) specializing the model via in-context meta-learning to the particular data distribution of interest. We also evaluate the performance of our system submission to the Learning With Disagreements (LeWiDi) competition, where it was the overall winner on both tasks. Additionally, we perform an ablation study to measure the importance of each system component. We find that including rater examples in-context is crucial for our system's performance, dataset-specific fine-tuning is helpful on the larger datasets, post-training on other in-context datasets is helpful on one of the competition datasets, and that performance improves with model scale.",
    "summary": "",
    "translation": "Opt-ICL在LeWiDi-2025：通过元学习最大化来自评分者示例的上下文信号",
    "relevance_score": 3,
    "reasoning": "该论文关注于通过元学习优化上下文学习（ICL），这属于LLM核心技术的效率改进，可能应用于推荐系统或搜索中的少样本学习场景。然而，标题中提到的LeWiDi-2025和评分者示例暗示其可能更偏向评估基准或特定NLP任务，而非直接面向RecSys/Search/Ads应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07098v1": {
    "title": "TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription",
    "url": "https://www.alphaxiv.org/abs/2510.07098v1",
    "arxiv_id": "2510.07098v1",
    "authors": "Guo Yutong, Wanying Wang, Yue Wu, Zichen Miao, Haoyu Wang",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 14:56:42",
    "ori_summary": "Table Visual Question Answering (Table VQA) is typically addressed by large vision-language models (VLMs). While such models can answer directly from images, they often miss fine-grained details unless scaled to very large sizes, which are computationally prohibitive, especially for mobile deployment. A lighter alternative is to have a small VLM perform OCR and then use a large language model (LLM) to reason over structured outputs such as Markdown tables. However, these representations are not naturally optimized for LLMs and still introduce substantial errors. We propose TALENT (Table VQA via Augmented Language-Enhanced Natural-text Transcription), a lightweight framework that leverages dual representations of tables. TALENT prompts a small VLM to produce both OCR text and natural language narration, then combines them with the question for reasoning by an LLM. This reframes Table VQA as an LLM-centric multimodal reasoning task, where the VLM serves as a perception-narration module rather than a monolithic solver. Additionally, we construct ReTabVQA, a more challenging Table VQA dataset requiring multi-step quantitative reasoning over table images. Experiments show that TALENT enables a small VLM-LLM combination to match or surpass a single large VLM at significantly lower computational cost on both public datasets and ReTabVQA.",
    "summary": "",
    "translation": "TALENT：通过增强语言的自然文本转录实现表格视觉问答",
    "relevance_score": 2,
    "reasoning": "该论文主要关注表格视觉问答（Table VQA），这属于视觉语言模型在特定领域的应用。虽然涉及多模态建模，但其应用场景（表格VQA）与推荐系统、搜索或广告的核心业务没有直接关联，且没有明确展示在异构数据统一建模方面的通用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07096v1": {
    "title": "Making Machines Sound Sarcastic: LLM-Enhanced and Retrieval-Guided Sarcastic Speech Synthesis",
    "url": "https://www.alphaxiv.org/abs/2510.07096v1",
    "arxiv_id": "2510.07096v1",
    "authors": "Zhu Li, Yuqing Zhang, Xiyuan Gao, Shekhar Nayak, Matt Coler",
    "categories": "cs.CL, cs.SD, eess.AS",
    "pub_date": "2025-10-08 14:53:48",
    "ori_summary": "Sarcasm is a subtle form of non-literal language that poses significant challenges for speech synthesis due to its reliance on nuanced semantic, contextual, and prosodic cues. While existing speech synthesis research has focused primarily on broad emotional categories, sarcasm remains largely unexplored. In this paper, we propose a Large Language Model (LLM)-enhanced Retrieval-Augmented framework for sarcasm-aware speech synthesis. Our approach combines (1) semantic embeddings from a LoRA-fine-tuned LLaMA 3, which capture pragmatic incongruity and discourse-level cues of sarcasm, and (2) prosodic exemplars retrieved via a Retrieval Augmented Generation (RAG) module, which provide expressive reference patterns of sarcastic delivery. Integrated within a VITS backbone, this dual conditioning enables more natural and contextually appropriate sarcastic speech. Experiments demonstrate that our method outperforms baselines in both objective measures and subjective evaluations, yielding improvements in speech naturalness, sarcastic expressivity, and downstream sarcasm detection.",
    "summary": "",
    "translation": "让机器听起来讽刺：LLM增强与检索引导的讽刺语音合成",
    "relevance_score": 1,
    "reasoning": "该论文专注于语音合成中的讽刺表达生成，属于纯语音领域，与推荐系统、搜索或广告中的排序和建模任务无关。虽然涉及LLM技术，但其应用方向是语音生成而非RecSys/Search/Ads的核心问题，属于被排除的纯语音主题。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07091v1": {
    "title": "The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas",
    "url": "https://www.alphaxiv.org/abs/2510.07091v1",
    "arxiv_id": "2510.07091v1",
    "authors": "Baixuan Xu, Tianshi Zheng, Zhaowei Wang, Hong Ting Tsang, Weiqi Wang, Tianqing Fang, Yangqiu Song",
    "categories": "cs.AI, cs.CL",
    "pub_date": "2025-10-08 14:47:40",
    "ori_summary": "Enabling LLMs to effectively operate long-horizon task which requires long-term planning and multiple interactions is essential for open-world autonomy. Conventional methods adopt planning with actions where a executable action list would be provided as reference. However, this action representation choice would be impractical when the environment action space is combinatorial exploded (e.g., open-ended real world). This naturally leads to a question: As environmental action space scales, what is the optimal action representation for long-horizon agents? In this paper, we systematically study the effectiveness of two different action representations. The first one is conventional planning with actions (PwA) which is predominantly adopted for its effectiveness on existing benchmarks. The other one is planning with schemas (PwS) which instantiate an action schema into action lists (e.g., \"move [OBJ] to [OBJ]\" -> \"move apple to desk\") to ensure concise action space and reliable scalability. This alternative is motivated by its alignment with human cognition and its compliance with environment-imposed action format restriction. We propose cognitive bandwidth perspective as a conceptual framework to qualitatively understand the differences between these two action representations and empirically observe a representation-choice inflection point between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve as evidence of the need for scalable representations. We further conduct controlled experiments to study how the location of this inflection point interacts with different model capacities: stronger planning proficiency shifts the inflection rightward, whereas better schema instantiation shifts it leftward. Finally, noting the suboptimal performance of PwS agents, we provide an actionable guide for building more capable PwS agents for better scalable autonomy.",
    "summary": "",
    "translation": "认知带宽瓶颈：将长视野智能体从动作规划转向图式规划",
    "relevance_score": 3,
    "reasoning": "该论文主要关注智能体规划中的认知效率问题，属于强化学习和智能体研究的范畴。虽然长视野规划在推荐系统中可能有潜在应用（如长期用户参与度优化），但论文标题未明确指向推荐、搜索或广告领域，也未涉及LLM、Transformer架构或异构数据建模等核心技术。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07083v1": {
    "title": "All Claims Are Equal, but Some Claims Are More Equal Than Others: Importance-Sensitive Factuality Evaluation of LLM Generations",
    "url": "https://www.alphaxiv.org/abs/2510.07083v1",
    "arxiv_id": "2510.07083v1",
    "authors": "Miriam Wanner, Leif Azzopardi, Paul Thomas, Soham Dan, Benjamin Van Durme, Nick Craswell",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 14:40:33",
    "ori_summary": "Existing methods for evaluating the factuality of large language model (LLM) responses treat all claims as equally important. This results in misleading evaluations when vital information is missing or incorrect as it receives the same weight as peripheral details, raising the question: how can we reliably detect such differences when there are errors in key information? Current approaches that measure factuality tend to be insensitive to omitted or false key information. To investigate this lack of sensitivity, we construct VITALERRORS, a benchmark of 6,733 queries with minimally altered LLM responses designed to omit or falsify key information. Using this dataset, we demonstrate the insensitivities of existing evaluation metrics to key information errors. To address this gap, we introduce VITAL, a set of metrics that provide greater sensitivity in measuring the factuality of responses by incorporating the relevance and importance of claims with respect to the query. Our analysis demonstrates that VITAL metrics more reliably detect errors in key information than previous methods. Our dataset, metrics, and analysis provide a foundation for more accurate and robust assessment of LLM factuality.",
    "summary": "",
    "translation": "所有声称皆平等，但某些声称更为平等：面向LLM生成内容的重要性敏感性事实性评估",
    "relevance_score": 1,
    "reasoning": "该论文专注于LLM生成内容的事实性评估和幻觉检测，这属于纯粹的NLP评估基准范畴，与您关注的推荐系统、搜索或广告核心技术无关。论文内容涉及LLM生成质量评估，而非在推荐、搜索或广告领域的实际应用或架构改进。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07081v1": {
    "title": "Accelerating Diffusion LLM Inference via Local Determinism Propagation",
    "url": "https://www.alphaxiv.org/abs/2510.07081v1",
    "arxiv_id": "2510.07081v1",
    "authors": "Fanheng Kong, Jingyuan Zhang, Yahui Liu, Zirui Wu, Yu Tian, Victoria W., Guorui Zhou",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 14:39:34",
    "ori_summary": "Diffusion large language models (dLLMs) represent a significant advancement in text generation, offering parallel token decoding capabilities. However, existing open-source implementations suffer from quality-speed trade-offs that impede their practical deployment. Conservative sampling strategies typically decode only the most confident token per step to ensure quality (i.e., greedy decoding), at the cost of inference efficiency due to repeated redundant refinement iterations--a phenomenon we term delayed decoding. Through systematic analysis of dLLM decoding dynamics, we characterize this delayed decoding behavior and propose a training-free adaptive parallel decoding strategy, named LocalLeap, to address these inefficiencies. LocalLeap is built on two fundamental empirical principles: local determinism propagation centered on high-confidence anchors and progressive spatial consistency decay. By applying these principles, LocalLeap identifies anchors and performs localized relaxed parallel decoding within bounded neighborhoods, achieving substantial inference step reduction through early commitment of already-determined tokens without compromising output quality. Comprehensive evaluation on various benchmarks demonstrates that LocalLeap achieves 6.94$\\times$ throughput improvements and reduces decoding steps to just 14.2\\% of the original requirement, achieving these gains with negligible performance impact. The source codes are available at: https://github.com/friedrichor/LocalLeap.",
    "summary": "",
    "translation": "通过局部确定性传播加速扩散大语言模型推理",
    "relevance_score": 2,
    "reasoning": "该论文主要关注扩散模型与LLM结合的推理加速技术，属于LLM效率优化的范畴。虽然推理加速技术可能间接应用于推荐/搜索系统的部署优化，但论文标题明确聚焦于扩散LLM这一特定架构，与当前关注的RecSys/Search/Ads核心领域及Transformer架构进展关联度较低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07074v1": {
    "title": "LuxInstruct: A Cross-Lingual Instruction Tuning Dataset For Luxembourgish",
    "url": "https://www.alphaxiv.org/abs/2510.07074v1",
    "arxiv_id": "2510.07074v1",
    "authors": "Fred Philippy, Laura Bernardy, Siwen Guo, Jacques Klein, Tegawendé F. Bissyandé",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 14:35:59",
    "ori_summary": "Instruction tuning has become a key technique for enhancing the performance of large language models, enabling them to better follow human prompts. However, low-resource languages such as Luxembourgish face severe limitations due to the lack of high-quality instruction datasets. Traditional reliance on machine translation often introduces semantic misalignment and cultural inaccuracies. In this work, we address these challenges by creating a cross-lingual instruction tuning dataset for Luxembourgish, without resorting to machine-generated translations into it. Instead, by leveraging aligned data from English, French, and German, we build a high-quality dataset that preserves linguistic and cultural nuances. We provide evidence that cross-lingual instruction tuning not only improves representational alignment across languages but also the model's generative capabilities in Luxembourgish. This highlights how cross-lingual data curation can avoid the common pitfalls of machine-translated data and directly benefit low-resource language development.",
    "summary": "",
    "translation": "LuxInstruct：面向卢森堡语的跨语言指令微调数据集",
    "relevance_score": 1,
    "reasoning": "该论文专注于为低资源语言卢森堡语构建指令微调数据集，属于特定语言NLP应用。这与推荐系统、搜索或广告的核心技术进展、Transformer架构改进或异构数据建模均无直接关联，且不涉及任何在RecSys/Search/Ads领域的潜在应用场景。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07061v1": {
    "title": "Revisiting Metric Reliability for Fine-grained Evaluation of Machine Translation and Summarization in Indian Languages",
    "url": "https://www.alphaxiv.org/abs/2510.07061v1",
    "arxiv_id": "2510.07061v1",
    "authors": "Amir Hossein Yari, Kalmit Kulkarni, Ahmad Raza Khan, Fajri Koto",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 14:27:02",
    "ori_summary": "While automatic metrics drive progress in Machine Translation (MT) and Text Summarization (TS), existing metrics have been developed and validated almost exclusively for English and other high-resource languages. This narrow focus leaves Indian languages, spoken by over 1.5 billion people, largely overlooked, casting doubt on the universality of current evaluation practices. To address this gap, we introduce ITEM, a large-scale benchmark that systematically evaluates the alignment of 26 automatic metrics with human judgments across six major Indian languages, enriched with fine-grained annotations. Our extensive evaluation, covering agreement with human judgments, sensitivity to outliers, language-specific reliability, inter-metric correlations, and resilience to controlled perturbations, reveals four central findings: (1) LLM-based evaluators show the strongest alignment with human judgments at both segment and system levels; (2) outliers exert a significant impact on metric-human agreement; (3) in TS, metrics are more effective at capturing content fidelity, whereas in MT, they better reflect fluency; and (4) metrics differ in their robustness and sensitivity when subjected to diverse perturbations. Collectively, these findings offer critical guidance for advancing metric design and evaluation in Indian languages.",
    "summary": "",
    "translation": "重新审视印度语言机器翻译与摘要细粒度评估中的度量可靠性",
    "relevance_score": 1,
    "reasoning": "该论文专注于机器翻译和摘要任务的评估基准与度量可靠性研究，属于纯粹的NLP评估领域。论文内容涉及印度语言的多语言评估，与推荐系统、搜索或广告的核心技术进展、LLM使能技术或Transformer架构改进均无直接关联，也不涉及异构数据的统一建模。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07060v1": {
    "title": "Does Local News Stay Local?: Online Content Shifts in Sinclair-Acquired Stations",
    "url": "https://www.alphaxiv.org/abs/2510.07060v1",
    "arxiv_id": "2510.07060v1",
    "authors": "Miriam Wanner, Sophia Hager, Anjalie Field",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 14:27:00",
    "ori_summary": "Local news stations are often considered to be reliable sources of non-politicized information, particularly local concerns that residents care about. Because these stations are trusted news sources, viewers are particularly susceptible to the information they report. The Sinclair Broadcast group is a broadcasting company that has acquired many local news stations in the last decade. We investigate the effects of local news stations being acquired by Sinclair: how does coverage change? We use computational methods to investigate changes in internet content put out by local news stations before and after being acquired by Sinclair and in comparison to national news outlets. We find that there is clear evidence that local news stations report more frequently on national news at the expense of local topics, and that their coverage of polarizing national topics increases.",
    "summary": "",
    "translation": "地方新闻是否保持本地化？：辛克莱收购电视台后的在线内容转变",
    "relevance_score": 1,
    "reasoning": "该论文研究媒体收购对地方新闻内容的影响，属于媒体研究领域，与推荐系统、搜索或广告的核心技术进展无关。内容转变分析不涉及LLM技术、Transformer架构或异构数据建模，也没有展示在RecSys/Search/Ads领域的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07048v1": {
    "title": "Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.07048v1",
    "arxiv_id": "2510.07048v1",
    "authors": "Yuntao Gui, James Cheng",
    "categories": "cs.CL, cs.AI, I.2.7",
    "pub_date": "2025-10-08 14:16:20",
    "ori_summary": "Despite their remarkable natural language understanding capabilities, Large Language Models (LLMs) have been underutilized for retrieval tasks. We present Search-R3, a novel framework that addresses this limitation by adapting LLMs to generate search embeddings as a direct output of their reasoning process. Our approach exploits LLMs' chain-of-thought capabilities, allowing them to produce more effective embeddings by reasoning step-by-step through complex semantic analyses. We implement this through three complementary mechanisms. (1) a supervised learning stage enables the model's ability to produce quality embeddings, (2) a reinforcement learning (RL) methodology that optimizes embedding generation alongside reasoning, and (3) a specialized RL environment that efficiently handles evolving embedding representations without requiring complete corpus re-encoding at each training iteration. Our extensive evaluations on diverse benchmarks demonstrate that Search-R3 significantly outperforms prior methods by unifying the reasoning and embedding generation processes. This integrated post-training approach represents a substantial advancement in handling complex knowledge-intensive tasks that require both sophisticated reasoning and effective information retrieval. Project page: https://github.com/ytgui/Search-R3",
    "summary": "论文研究如何让大语言模型直接生成搜索嵌入向量；核心方法是利用链式推理过程，通过监督学习和强化学习联合优化，将复杂语义分析转化为高质量的检索嵌入。",
    "translation": "Search-R3：在大型语言模型中统一推理与嵌入生成",
    "relevance_score": 9,
    "reasoning": "该论文标题直接涉及在LLM中统一推理和嵌入生成，这属于'直接LLM应用'和'使能LLM技术'范畴。统一推理和嵌入生成对于搜索和推荐系统至关重要，可以同时处理语义理解和向量表示，显著提升检索和排序性能。这种技术可以直接应用于搜索查询理解、文档嵌入生成和推荐系统的多任务学习。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文直接统一LLM推理与检索嵌入生成，完全契合搜索领域核心需求，是LLM在检索任务中的直接应用突破。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.07037v1": {
    "title": "Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.07037v1",
    "arxiv_id": "2510.07037v1",
    "authors": "Rajvee Sheth, Samridhi Raj Sinha, Mahavir Patil, Himanshu Beniwal, Mayank Singh",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 14:04:14",
    "ori_summary": "Code-switching (CSW), the alternation of languages and scripts within a single utterance, remains a fundamental challenge for multiling ual NLP, even amidst the rapid advances of large language models (LLMs). Most LLMs still struggle with mixed-language inputs, limited CSW datasets, and evaluation biases, hindering deployment in multilingual societies. This survey provides the first comprehensive analysis of CSW-aware LLM research, reviewing \\total{unique_references} studies spanning five research areas, 12 NLP tasks, 30+ datasets, and 80+ languages. We classify recent advances by architecture, training strategy, and evaluation methodology, outlining how LLMs have reshaped CSW modeling and what challenges persist. The paper concludes with a roadmap emphasizing the need for inclusive datasets, fair evaluation, and linguistically grounded models to achieve truly multilingual intelligence. A curated collection of all resources is maintained at https://github.com/lingo-iitgn/awesome-code-mixing/.",
    "summary": "",
    "translation": "超越单语假设：大语言模型时代下的代码转换自然语言处理综述",
    "relevance_score": 2,
    "reasoning": "这篇论文主要关注代码转换自然语言处理，这是NLP领域的一个专门分支，涉及多种语言混合使用的场景。虽然大语言模型被提及，但论文的核心焦点是代码转换这一特定NLP任务，与推荐系统、搜索或广告的核心技术进展没有直接关联。代码转换处理在主流推荐、搜索和广告应用中的实际价值有限，因此相关性较低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07024v1": {
    "title": "Mining the Mind: What 100M Beliefs Reveal About Frontier LLM Knowledge",
    "url": "https://www.alphaxiv.org/abs/2510.07024v1",
    "arxiv_id": "2510.07024v1",
    "authors": "Shrestha Ghosh, Luca Giordano, Yujia Hu, Tuan-Phong Nguyen, Simon Razniewski",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 13:48:38",
    "ori_summary": "LLMs are remarkable artifacts that have revolutionized a range of NLP and AI tasks. A significant contributor is their factual knowledge, which, to date, remains poorly understood, and is usually analyzed from biased samples. In this paper, we take a deep tour into the factual knowledge (or beliefs) of a frontier LLM, based on GPTKB v1.5 (Hu et al., 2025a), a recursively elicited set of 100 million beliefs of one of the strongest currently available frontier LLMs, GPT-4.1. We find that the models' factual knowledge differs quite significantly from established knowledge bases, and that its accuracy is significantly lower than indicated by previous benchmarks. We also find that inconsistency, ambiguity and hallucinations are major issues, shedding light on future research opportunities concerning factual LLM knowledge.",
    "summary": "",
    "translation": "挖掘心智：从1亿条信念中揭示前沿大语言模型的知识边界",
    "relevance_score": 3,
    "reasoning": "该论文主要关注LLM知识边界的探索和信念分析，属于LLM评估和理解范畴，而非直接的技术进步或应用。虽然涉及前沿LLM，但缺乏明确的效率提升、架构创新或RecSys/Search/Ads应用潜力，与当前关注点关联较弱。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07019v1": {
    "title": "Native Hybrid Attention for Efficient Sequence Modeling",
    "url": "https://www.alphaxiv.org/abs/2510.07019v1",
    "arxiv_id": "2510.07019v1",
    "authors": "Jusen Du, Jiaxi Hu, Tao Zhang, Weigao Sun, Yu Cheng",
    "categories": "cs.CL, cs.AI, cs.LG",
    "pub_date": "2025-10-08 13:44:57",
    "ori_summary": "Transformers excel at sequence modeling but face quadratic complexity, while linear attention offers improved efficiency but often compromises recall accuracy over long contexts. In this work, we introduce Native Hybrid Attention (NHA), a novel hybrid architecture of linear and full attention that integrates both intra \\& inter-layer hybridization into a unified layer design. NHA maintains long-term context in key-value slots updated by a linear RNN, and augments them with short-term tokens from a sliding window. A single \\texttt{softmax attention} operation is then applied over all keys and values, enabling per-token and per-head context-dependent weighting without requiring additional fusion parameters. The inter-layer behavior is controlled through a single hyperparameter, the sliding window size, which allows smooth adjustment between purely linear and full attention while keeping all layers structurally uniform. Experimental results show that NHA surpasses Transformers and other hybrid baselines on recall-intensive and commonsense reasoning tasks. Furthermore, pretrained LLMs can be structurally hybridized with NHA, achieving competitive accuracy while delivering significant efficiency gains. Code is available at https://github.com/JusenD/NHA.",
    "summary": "研究Transformer序列建模的二次复杂度问题，核心方法是设计Native Hybrid Attention混合架构，通过线性RNN维护长期上下文和滑动窗口补充短期token，在统一层中实现线性与全注意力的自适应融合。",
    "translation": "原生混合注意力机制用于高效序列建模",
    "relevance_score": 8,
    "reasoning": "该论文聚焦于注意力机制的效率改进，这直接属于'Enabling Transformer Tech'范畴。高效的注意力机制可以显著提升推荐系统和搜索系统中序列建模的性能，特别是在处理长用户行为序列时能够降低计算成本并提高推理速度。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文提出Native Hybrid Attention架构，直接在Transformer效率优化核心领域进行创新，通过线性RNN与滑动窗口注意力混合设计解决长序列建模效率问题，对推荐系统和搜索中的序列建模具有直接应用价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.07000v1": {
    "title": "Pragyaan: Designing and Curating High-Quality Cultural Post-Training Datasets for Indian Languages",
    "url": "https://www.alphaxiv.org/abs/2510.07000v1",
    "arxiv_id": "2510.07000v1",
    "authors": "Neel Prabhanjan Rachamalla, Aravind Konakalla, Gautam Rajeev, Ashish Kulkarni, Chandra Khatri, Shubham Agarwal",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 13:23:45",
    "ori_summary": "The effectiveness of Large Language Models (LLMs) depends heavily on the availability of high-quality post-training data, particularly instruction-tuning and preference-based examples. Existing open-source datasets, however, often lack multilingual coverage, cultural grounding, and suffer from task diversity gaps that are especially pronounced for Indian languages. We introduce a human-in-the-loop pipeline that combines translations with synthetic expansion to produce reliable and diverse Indic post-training data. Using this pipeline, we curate two datasets: Pragyaan-IT (22.5K) and Pragyaan-Align (100K) across 10 Indian languages covering 13 broad and 56 sub-categories, leveraging 57 diverse datasets. Our dataset protocol incorporates several often-overlooked dimensions and emphasize task diversity, multi-turn dialogue, instruction fidelity, safety alignment, and preservation of cultural nuance, providing a foundation for more inclusive and effective multilingual LLMs.",
    "summary": "",
    "translation": "Pragyaan：为印度语言设计和策划高质量文化后训练数据集",
    "relevance_score": 2,
    "reasoning": "该论文主要关注特定语言（印度语言）的文化数据集构建，属于数据工程领域。虽然高质量数据集可能间接支持多语言LLM开发，但论文焦点局限于特定文化背景的语言数据，与推荐系统、搜索或广告的核心技术进展没有直接关联，也没有明确涉及Transformer架构改进或异构数据建模。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06994v1": {
    "title": "RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning",
    "url": "https://www.alphaxiv.org/abs/2510.06994v1",
    "arxiv_id": "2510.06994v1",
    "authors": "Artur Horal, Daniel Pina, Henrique Paz, Iago Paulo, João Soares, Rafael Ferreira, Diogo Tavares, Diogo Glória-Silva, João Magalhães, David Semedo",
    "categories": "cs.CR, cs.CL",
    "pub_date": "2025-10-08 13:18:42",
    "ori_summary": "This paper presents the vision, scientific contributions, and technical details of RedTWIZ: an adaptive and diverse multi-turn red teaming framework, to audit the robustness of Large Language Models (LLMs) in AI-assisted software development. Our work is driven by three major research streams: (1) robust and systematic assessment of LLM conversational jailbreaks; (2) a diverse generative multi-turn attack suite, supporting compositional, realistic and goal-oriented jailbreak conversational strategies; and (3) a hierarchical attack planner, which adaptively plans, serializes, and triggers attacks tailored to specific LLM's vulnerabilities. Together, these contributions form a unified framework -- combining assessment, attack generation, and strategic planning -- to comprehensively evaluate and expose weaknesses in LLMs' robustness. Extensive evaluation is conducted to systematically assess and analyze the performance of the overall system and each component. Experimental results demonstrate that our multi-turn adversarial attack strategies can successfully lead state-of-the-art LLMs to produce unsafe generations, highlighting the pressing need for more research into enhancing LLM's robustness.",
    "summary": "",
    "translation": "RedTWIZ：通过自适应攻击规划实现多样化大语言模型红队测试",
    "relevance_score": 2,
    "reasoning": "该论文专注于大语言模型的安全测试和对抗攻击，属于红队测试领域。虽然涉及LLM技术，但主要关注模型安全性和鲁棒性评估，与推荐系统、搜索或广告的核心技术进展没有直接关联，也不属于效率提升或架构创新等使能技术范畴。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06975v1": {
    "title": "VelLMes: A high-interaction AI-based deception framework",
    "url": "https://www.alphaxiv.org/abs/2510.06975v1",
    "arxiv_id": "2510.06975v1",
    "authors": "Muris Sladić, Veronica Valeros, Carlos Catania, Sebastian Garcia",
    "categories": "cs.CR, cs.AI, cs.CL",
    "pub_date": "2025-10-08 13:00:23",
    "ori_summary": "There are very few SotA deception systems based on Large Language Models. The existing ones are limited only to simulating one type of service, mainly SSH shells. These systems - but also the deception technologies not based on LLMs - lack an extensive evaluation that includes human attackers. Generative AI has recently become a valuable asset for cybersecurity researchers and practitioners, and the field of cyber-deception is no exception. Researchers have demonstrated how LLMs can be leveraged to create realistic-looking honeytokens, fake users, and even simulated systems that can be used as honeypots. This paper presents an AI-based deception framework called VelLMes, which can simulate multiple protocols and services such as SSH Linux shell, MySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus VelLMes offers a variety of choices for deception design based on the users' needs. VelLMes is designed to be attacked by humans, so interactivity and realism are key for its performance. We evaluate the generative capabilities and the deception capabilities. Generative capabilities were evaluated using unit tests for LLMs. The results of the unit tests show that, with careful prompting, LLMs can produce realistic-looking responses, with some LLMs having a 100% passing rate. In the case of the SSH Linux shell, we evaluated deception capabilities with 89 human attackers. The results showed that about 30% of the attackers thought that they were interacting with a real system when they were assigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH Linux shell honeypot on the Internet to capture real-life attacks. Analysis of these attacks showed us that LLM honeypots simulating Linux shells can perform well against unstructured and unexpected attacks on the Internet, responding correctly to most of the issued commands.",
    "summary": "",
    "translation": "VelLMes：一种基于人工智能的高交互性欺骗框架",
    "relevance_score": 1,
    "reasoning": "该论文标题涉及AI欺骗框架，属于安全、伦理相关领域，与当前关注的推荐系统、搜索广告核心技术进展、Transformer架构改进以及LLM直接应用等焦点完全无关。欺骗框架技术没有在推荐、搜索或广告领域的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06974v1": {
    "title": "Probing Social Identity Bias in Chinese LLMs with Gendered Pronouns and Social Groups",
    "url": "https://www.alphaxiv.org/abs/2510.06974v1",
    "arxiv_id": "2510.06974v1",
    "authors": "Geng Liu, Feng Li, Junjie Mu, Mengxiao Zhu, Francesco Pierri",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 13:00:12",
    "ori_summary": "Large language models (LLMs) are increasingly deployed in user-facing applications, raising concerns about their potential to reflect and amplify social biases. We investigate social identity framing in Chinese LLMs using Mandarin-specific prompts across ten representative Chinese LLMs, evaluating responses to ingroup (\"We\") and outgroup (\"They\") framings, and extending the setting to 240 social groups salient in the Chinese context. To complement controlled experiments, we further analyze Chinese-language conversations from a corpus of real interactions between users and chatbots. Across models, we observe systematic ingroup-positive and outgroup-negative tendencies, which are not confined to synthetic prompts but also appear in naturalistic dialogue, indicating that bias dynamics might strengthen in real interactions. Our study provides a language-aware evaluation framework for Chinese LLMs, demonstrating that social identity biases documented in English generalize cross-linguistically and intensify in user-facing contexts.",
    "summary": "",
    "translation": "基于性别代词和社会群体探究中文大语言模型中的社会身份偏见",
    "relevance_score": 1,
    "reasoning": "该论文专注于LLM中的偏见检测和评估，属于公平性和伦理范畴，这在您的无关主题列表中明确排除。虽然涉及LLM技术，但研究的是社会身份偏见而非核心架构进步或推荐/搜索/广告应用，没有展示在您关注领域中的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06965v1": {
    "title": "EDUMATH: Generating Standards-aligned Educational Math Word Problems",
    "url": "https://www.alphaxiv.org/abs/2510.06965v1",
    "arxiv_id": "2510.06965v1",
    "authors": "Bryan R. Christ, Penelope Molitz, Jonathan Kropko, Thomas Hartvigsen",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 12:53:06",
    "ori_summary": "Math word problems (MWPs) are critical K-12 educational tools, and customizing them to students' interests and ability levels can increase learning outcomes. However, teachers struggle to find time to customize MWPs for each student given large class sizes and increasing burnout. We propose that LLMs can support math education by generating MWPs customized to student interests and math education standards. To this end, we use a joint human expert-LLM judge approach to evaluate over 11,000 MWPs generated by open and closed LLMs and develop the first teacher-annotated dataset for standards-aligned educational MWP generation. We show the value of our data by using it to train a 12B open model that matches the performance of larger and more capable open models. We also use our teacher-annotated data to train a text classifier that enables a 30B open LLM to outperform existing closed baselines without any training. Next, we show our models' MWPs are more similar to human-written MWPs than those from existing models. We conclude by conducting the first study of customized LLM-generated MWPs with grade school students, finding they perform similarly on our models' MWPs relative to human-written MWPs but consistently prefer our customized MWPs.",
    "summary": "",
    "translation": "EDUMATH：生成符合标准的数学教育应用题",
    "relevance_score": 1,
    "reasoning": "该论文专注于教育领域的数学应用题生成，属于特定领域的内容生成应用。这与推荐系统、搜索或广告的核心技术进展、使能技术或直接应用完全无关，也不涉及异构数据的统一建模。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06961v1": {
    "title": "Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation",
    "url": "https://www.alphaxiv.org/abs/2510.06961v1",
    "arxiv_id": "2510.06961v1",
    "authors": "Vaibhav Srivastav, Steven Zheng, Eric Bezzam, Eustache Le Bihan, Nithin Koluguri, Piotr Żelasko, Somshubra Majumdar, Adel Moumen, Sanchit Gandhi",
    "categories": "cs.CL, cs.AI, cs.SD, eess.AS",
    "pub_date": "2025-10-08 12:44:51",
    "ori_summary": "Despite rapid progress, ASR evaluation remains saturated with short-form English, and efficiency is rarely reported. We present the Open ASR Leaderboard, a fully reproducible benchmark and interactive leaderboard comparing 60+ open-source and proprietary systems across 11 datasets, including dedicated multilingual and long-form tracks. We standardize text normalization and report both word error rate (WER) and inverse real-time factor (RTFx), enabling fair accuracy-efficiency comparisons. For English transcription, Conformer encoders paired with LLM decoders achieve the best average WER but are slower, while CTC and TDT decoders deliver much better RTFx, making them attractive for long-form and offline use. Whisper-derived encoders fine-tuned for English improve accuracy but often trade off multilingual coverage. All code and dataset loaders are open-sourced to support transparent, extensible evaluation.",
    "summary": "",
    "translation": "开放ASR排行榜：迈向可复现和透明的多语言及长语音识别评估",
    "relevance_score": 1,
    "reasoning": "该论文专注于语音识别（ASR）的评估基准和排行榜，属于纯语音技术领域，与搜索、推荐或广告系统没有直接关联。语音识别虽然可以作为某些应用的输入模块，但论文本身不涉及任何推荐系统、搜索技术、广告排名或Transformer架构的进展。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06953v1": {
    "title": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces",
    "url": "https://www.alphaxiv.org/abs/2510.06953v1",
    "arxiv_id": "2510.06953v1",
    "authors": "Minju Gwak, Guijin Son, Jaehyung Kim",
    "categories": "cs.AI, cs.CL",
    "pub_date": "2025-10-08 12:37:04",
    "ori_summary": "The Uniform Information Density (UID) hypothesis suggests that effective communication maintains a stable flow of information. In this work, we revisit this principle in the context of large language model (LLM) reasoning traces, asking whether step-level uniformity reflects reasoning quality. To this end, we propose an entropy-based stepwise information density metric and introduce two complementary measures of uniformity, local and global uniformity scores. Across the experiments on six different reasoning benchmarks, we find that step-level uniformity not only provides a strong theoretical lens but also yields practical performance benefits; for example, selecting reasoning traces with more uniform information density at the step-level improves accuracy by 10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals that correct reasoning traces tend to avoid sharp information density spikes, while incorrect traces exhibit irregular information bursts. These results demonstrate that UID-inspired information density measures outperform alternative internal signals as predictors of reasoning quality. Results highlight the uniformity of the information density as a robust diagnostic and selection criterion for building more reliable and accurate reasoning systems.",
    "summary": "",
    "translation": "重新审视LLM推理轨迹中的均匀信息密度假设",
    "relevance_score": 2,
    "reasoning": "该论文主要研究LLM推理过程中的信息密度分布假设，属于LLM内部工作机制的理论分析。虽然涉及LLM推理，但缺乏明确的推荐系统、搜索或广告应用场景的直接关联。该研究更偏向于LLM认知科学和基础机制探索，而非面向实际应用的使能技术。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06917v1": {
    "title": "SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.06917v1",
    "arxiv_id": "2510.06917v1",
    "authors": "Cheng-Han Chiang, Xiaofei Wang, Linjie Li, Chung-Ching Lin, Kevin Lin, Shujie Liu, Zhendong Wang, Zhengyuan Yang, Hung-yi Lee, Lijuan Wang",
    "categories": "cs.CL, eess.AS",
    "pub_date": "2025-10-08 11:48:59",
    "ori_summary": "Current large language models (LLMs) and spoken language models (SLMs) begin thinking and taking actions only after the user has finished their turn. This prevents the model from interacting during the user's turn and can lead to high response latency while it waits to think. Consequently, thinking after receiving the full input is not suitable for speech-to-speech interaction, where real-time, low-latency exchange is important. We address this by noting that humans naturally \"think while listening.\" In this paper, we propose SHANKS, a general inference framework that enables SLMs to generate unspoken chain-of-thought reasoning while listening to the user input. SHANKS streams the input speech in fixed-duration chunks and, as soon as a chunk is received, generates unspoken reasoning based on all previous speech and reasoning, while the user continues speaking. SHANKS uses this unspoken reasoning to decide whether to interrupt the user and to make tool calls to complete the task. We demonstrate that SHANKS enhances real-time user-SLM interaction in two scenarios: (1) when the user is presenting a step-by-step solution to a math problem, SHANKS can listen, reason, and interrupt when the user makes a mistake, achieving 37.1% higher interruption accuracy than a baseline that interrupts without thinking; and (2) in a tool-augmented dialogue, SHANKS can complete 56.9% of the tool calls before the user finishes their turn. Overall, SHANKS moves toward models that keep thinking throughout the conversation, not only after a turn ends. Animated illustrations of Shanks can be found at https://d223302.github.io/SHANKS/",
    "summary": "",
    "translation": "SHANKS：语音语言模型的同步听觉与思考",
    "relevance_score": 2,
    "reasoning": "该论文主要关注语音语言模型的听觉与思考同步处理，属于语音处理领域。虽然语音交互在搜索系统中可能有潜在应用，但论文标题本身没有明确指向推荐系统、搜索或广告的核心技术需求，也没有涉及Transformer架构改进或异构数据处理等当前关注的重点方向。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06915v1": {
    "title": "LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling",
    "url": "https://www.alphaxiv.org/abs/2510.06915v1",
    "arxiv_id": "2510.06915v1",
    "authors": "Zecheng Tang, Baibei Ji, Quantong Qiu, Haitian Wang, Xiaobo Liang, Juntao Li, Min Zhang",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 11:48:16",
    "ori_summary": "Reward model (RM) plays a pivotal role in aligning large language model (LLM) with human preferences. As real-world applications increasingly involve long history trajectories, e.g., LLM agent, it becomes indispensable to evaluate whether a model's responses are not only high-quality but also grounded in and consistent with the provided context. Yet, current RMs remain confined to short-context settings and primarily focus on response-level attributes (e.g., safety or helpfulness), while largely neglecting the critical dimension of long context-response consistency. In this work, we introduce Long-RewardBench, a benchmark specifically designed for long-context RM evaluation, featuring both Pairwise Comparison and Best-of-N tasks. Our preliminary study reveals that even state-of-the-art generative RMs exhibit significant fragility in long-context scenarios, failing to maintain context-aware preference judgments. Motivated by the analysis of failure patterns observed in model outputs, we propose a general multi-stage training strategy that effectively scales arbitrary models into robust Long-context RMs (LongRMs). Experiments show that our approach not only substantially improves performance on long-context evaluation but also preserves strong short-context capability. Notably, our 8B LongRM outperforms much larger 70B-scale baselines and matches the performance of the proprietary Gemini 2.5 Pro model.",
    "summary": "",
    "translation": "LongRM：揭示并突破奖励建模的上下文边界",
    "relevance_score": 7,
    "reasoning": "该论文聚焦于奖励建模的上下文边界问题，这属于LLM技术中的核心进展（奖励建模是RLHF的关键组件）。在推荐系统和搜索领域，奖励建模技术可直接应用于优化用户反馈信号，通过突破上下文边界限制，能够处理更长的用户历史序列和复杂上下文特征，从而提升个性化推荐和搜索结果的质量。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06889v1": {
    "title": "MeXtract: Light-Weight Metadata Extraction from Scientific Papers",
    "url": "https://www.alphaxiv.org/abs/2510.06889v1",
    "arxiv_id": "2510.06889v1",
    "authors": "Zaid Alyafeai, Maged S. Al-Shaibani, Bernard Ghanem",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 11:12:28",
    "ori_summary": "Metadata plays a critical role in indexing, documenting, and analyzing scientific literature, yet extracting it accurately and efficiently remains a challenging task. Traditional approaches often rely on rule-based or task-specific models, which struggle to generalize across domains and schema variations. In this paper, we present MeXtract, a family of lightweight language models designed for metadata extraction from scientific papers. The models, ranging from 0.5B to 3B parameters, are built by fine-tuning Qwen 2.5 counterparts. In their size family, MeXtract achieves state-of-the-art performance on metadata extraction on the MOLE benchmark. To further support evaluation, we extend the MOLE benchmark to incorporate model-specific metadata, providing an out-of-domain challenging subset. Our experiments show that fine-tuning on a given schema not only yields high accuracy but also transfers effectively to unseen schemas, demonstrating the robustness and adaptability of our approach. We release all the code, datasets, and models openly for the research community.",
    "summary": "",
    "translation": "MeXtract：从科学论文中轻量级元数据提取",
    "relevance_score": 2,
    "reasoning": "该论文专注于科学论文的元数据提取，属于文档处理和信息提取的通用技术领域。虽然元数据提取在搜索系统中可能有间接应用，但该工作没有明确涉及推荐系统、广告或搜索的核心技术，也没有与LLM、Transformer架构或异构数据建模建立直接联系，因此相关性较低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06870v1": {
    "title": "$λ$-GRPO: Unifying the GRPO Frameworks with Learnable Token Preferences",
    "url": "https://www.alphaxiv.org/abs/2510.06870v1",
    "arxiv_id": "2510.06870v1",
    "authors": "Yining Wang, Jinman Zhao, Chuangxin Zhao, Shuhao Guan, Gerald Penn, Shinan Liu",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 10:39:07",
    "ori_summary": "Reinforcement Learning with Human Feedback (RLHF) has been the dominant approach for improving the reasoning capabilities of Large Language Models (LLMs). Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has simplified this paradigm by replacing the reward and value models with rule-based verifiers. A prominent example is Group Relative Policy Optimization (GRPO). However, GRPO inherently suffers from a length bias, since the same advantage is uniformly assigned to all tokens of a response. As a result, longer responses distribute the reward over more tokens and thus contribute disproportionately to gradient updates. Several variants, such as DAPO and Dr. GRPO, modify the token-level aggregation of the loss, yet these methods remain heuristic and offer limited interpretability regarding their implicit token preferences. In this work, we explore the possibility of allowing the model to learn its own token preference during optimization. We unify existing frameworks under a single formulation and introduce a learnable parameter $\\lambda$ that adaptively controls token-level weighting. We use $\\lambda$-GRPO to denote our method, and we find that $\\lambda$-GRPO achieves consistent improvements over vanilla GRPO and DAPO on multiple mathematical reasoning benchmarks. On Qwen2.5 models with 1.5B, 3B, and 7B parameters, $\\lambda$-GRPO improves average accuracy by $+1.9\\%$, $+1.0\\%$, and $+1.7\\%$ compared to GRPO, respectively. Importantly, these gains come without any modifications to the training data or additional computational cost, highlighting the effectiveness and practicality of learning token preferences.",
    "summary": "论文研究GRPO框架在LLM强化学习中的长度偏差问题，核心思想是引入可学习参数λ来自适应控制token级权重，统一现有方法并让模型在优化过程中学习自身的token偏好。",
    "translation": "λ-GRPO：通过可学习令牌偏好统一GRPO框架",
    "relevance_score": 8,
    "reasoning": "该论文提出了一种新的强化学习优化框架，通过引入可学习的令牌偏好来统一GRPO方法。虽然涉及强化学习，但GRPO框架在LLM对齐和优化中具有重要作用，可直接应用于搜索和推荐系统中的序列生成优化、个性化内容排序以及广告文案生成的质量控制。",
    "rerank_relevance_score": 8,
    "rerank_reasoning": "该论文提出可学习token偏好的RL优化方法，直接改进LLM训练框架，对搜索推荐系统的模型优化有重要参考价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06866v1": {
    "title": "Unlocking Latent Discourse Translation in LLMs Through Quality-Aware Decoding",
    "url": "https://www.alphaxiv.org/abs/2510.06866v1",
    "arxiv_id": "2510.06866v1",
    "authors": "Wafaa Mohammed, Vlad Niculae, Chrysoula Zerva",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 10:37:17",
    "ori_summary": "Large language models (LLMs) have emerged as strong contenders in machine translation.Yet, they still struggle to adequately handle discourse phenomena, such as pronoun resolution and lexical cohesion at the document level. In this study, we thoroughly investigate the discourse phenomena performance of LLMs in context-aware translation. We demonstrate that discourse knowledge is encoded within LLMs and propose the use of quality-aware decoding (QAD) to effectively extract this knowledge, showcasing its superiority over other decoding approaches through comprehensive analysis. Furthermore, we illustrate that QAD enhances the semantic richness of translations and aligns them more closely with human preferences.",
    "summary": "",
    "translation": "通过质量感知解码解锁大语言模型中的潜在话语翻译能力",
    "relevance_score": 2,
    "reasoning": "该论文主要关注LLM中的翻译能力改进，属于纯粹的NLP应用领域。虽然提到了质量感知解码技术，但其应用场景局限于话语翻译，与推荐系统、搜索或广告的核心技术需求没有直接关联。解码技术本身可能有一些通用性，但论文的特定应用方向使其与当前关注点相关性较低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06847v1": {
    "title": "OpenJAI-v1.0: An Open Thai Large Language Model",
    "url": "https://www.alphaxiv.org/abs/2510.06847v1",
    "arxiv_id": "2510.06847v1",
    "authors": "Pontakorn Trakuekul, Attapol T. Rutherford, Jullajak Karnjanaekarin, Narongkorn Panitsrisit, Sumana Sumanakul",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 10:12:56",
    "ori_summary": "We introduce OpenJAI-v1.0, an open-source large language model for Thai and English, developed from the Qwen3-14B model. Our work focuses on boosting performance on practical tasks through carefully curated data across three key use cases: instruction following, long-context understanding, and tool use. Evaluation results show that OpenJAI-v1.0 improves on the capabilities of its base model and outperforms other leading open-source Thai models on a diverse suite of benchmarks, while avoiding catastrophic forgetting. OpenJAI-v1.0 is publicly released as another alternative NLP resource for the Thai AI community.",
    "summary": "",
    "translation": "OpenJAI-v1.0：一个开源的泰语大语言模型",
    "relevance_score": 2,
    "reasoning": "该论文主要介绍一个特定语言（泰语）的大语言模型，属于基础模型开发范畴。虽然LLM技术本身与推荐系统/搜索/广告领域相关，但该论文聚焦于特定语言模型而非核心架构创新或直接应用，因此相关性较低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06843v1": {
    "title": "SID: Multi-LLM Debate Driven by Self Signals",
    "url": "https://www.alphaxiv.org/abs/2510.06843v1",
    "arxiv_id": "2510.06843v1",
    "authors": "Xuhang Chen, Zhifan Song, Deyi Ji, Shuo Gao, Lanyun Zhu",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 10:10:11",
    "ori_summary": "Large Language Models (LLMs) have exhibited impressive capabilities across diverse application domains. Recent work has explored Multi-LLM Agent Debate (MAD) as a way to enhance performance by enabling multiple LLMs to discuss and refine responses iteratively. Nevertheless, existing MAD methods predominantly focus on utilizing external structures, such as debate graphs, using LLM-as-a-Judge, while neglecting the application of self signals, such as token logits and attention, that arise during generation. This omission leads to redundant computation and potential performance degradation. In this paper, we shift the focus to the self signals of multi-LLM debate and introduce a Self-Signals Driven Multi-LLM Debate (SID), which leverages two types of self-signals: model-level confidence and token-level semantic focus, to adaptively guide the debate process. Our approach enables high-confidence agents to exit early at the model level and compress the redundant debate contents based on the attention mechanism. We evaluate our method on various LLMs and Multimodal LLMs across multiple challenging benchmarks. Experimental results demonstrate that our method not only outperforms existing MAD techniques in accuracy but also reduces token consumption, highlighting the effectiveness of utilizing self signals in enhancing both the performance and efficiency of multi-agent debate systems. Our code will be available at~\\href{https://github.com/xuhang2019/SID}{\\texttt{https://github.com/xuhang2019/SID}}.",
    "summary": "",
    "translation": "SID：基于自我信号驱动的多LLM辩论",
    "relevance_score": 7,
    "reasoning": "该论文提出多LLM辩论框架，属于核心LLM技术的进步。在推荐系统、搜索和广告中，这种多模型辩论机制可用于提升内容理解、用户意图识别和排序决策的准确性，通过集成多个LLM的推理能力来减少错误并提高系统鲁棒性。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06841v1": {
    "title": "GAMBIT+: A Challenge Set for Evaluating Gender Bias in Machine Translation Quality Estimation Metrics",
    "url": "https://www.alphaxiv.org/abs/2510.06841v1",
    "arxiv_id": "2510.06841v1",
    "authors": "Giorgos Filandrianos, Orfeas Menis Mastromichalakis, Wafaa Mohammed, Giuseppe Attanasio, Chrysoula Zerva",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 10:09:03",
    "ori_summary": "Gender bias in machine translation (MT) systems has been extensively documented, but bias in automatic quality estimation (QE) metrics remains comparatively underexplored. Existing studies suggest that QE metrics can also exhibit gender bias, yet most analyses are limited by small datasets, narrow occupational coverage, and restricted language variety. To address this gap, we introduce a large-scale challenge set specifically designed to probe the behavior of QE metrics when evaluating translations containing gender-ambiguous occupational terms. Building on the GAMBIT corpus of English texts with gender-ambiguous occupations, we extend coverage to three source languages that are genderless or natural-gendered, and eleven target languages with grammatical gender, resulting in 33 source-target language pairs. Each source text is paired with two target versions differing only in the grammatical gender of the occupational term(s) (masculine vs. feminine), with all dependent grammatical elements adjusted accordingly. An unbiased QE metric should assign equal or near-equal scores to both versions. The dataset's scale, breadth, and fully parallel design, where the same set of texts is aligned across all languages, enables fine-grained bias analysis by occupation and systematic comparisons across languages.",
    "summary": "",
    "translation": "GAMBIT+：用于评估机器翻译质量评估指标中性别偏见的挑战集",
    "relevance_score": 1,
    "reasoning": "该论文专注于机器翻译质量评估中的性别偏见评估，这属于公平性和伦理范畴，明确列在无关主题中。虽然涉及评估指标，但核心关注点是偏见检测而非技术改进，与推荐系统、搜索或广告的技术进展无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06826v1": {
    "title": "Mid-Training of Large Language Models: A Survey",
    "url": "https://www.alphaxiv.org/abs/2510.06826v1",
    "arxiv_id": "2510.06826v1",
    "authors": "Kaixiang Mo, Yuxin Shi, Weiwei Weng, Zhiqiang Zhou, Shuman Liu, Haibo Zhang, Anxiang Zeng",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 09:49:37",
    "ori_summary": "Large language models (LLMs) are typically developed through large-scale pre-training followed by task-specific fine-tuning. Recent advances highlight the importance of an intermediate mid-training stage, where models undergo multiple annealing-style phases that refine data quality, adapt optimization schedules, and extend context length. This stage mitigates diminishing returns from noisy tokens, stabilizes convergence, and expands model capability in late training. Its effectiveness can be explained through gradient noise scale, the information bottleneck, and curriculum learning, which together promote generalization and abstraction. Despite widespread use in state-of-the-art systems, there has been no prior survey of mid-training as a unified paradigm. We introduce the first taxonomy of LLM mid-training spanning data distribution, learning-rate scheduling, and long-context extension. We distill practical insights, compile evaluation benchmarks, and report gains to enable structured comparisons across models. We also identify open challenges and propose avenues for future research and practice.",
    "summary": "论文研究LLM训练过程中间阶段的系统化优化问题，核心思想是通过数据质量精炼、优化调度调整和上下文扩展等多阶段退火式训练，提升模型泛化能力和抽象能力。",
    "translation": "大型语言模型中期训练：综述",
    "relevance_score": 8,
    "reasoning": "这篇关于LLM中期训练的综述直接属于'使能LLM技术'范畴，涵盖了LLM训练过程中的核心进展。中期训练技术（如持续预训练、领域适应）对于在推荐、搜索和广告系统中高效定制和部署LLM至关重要，能够显著提升模型在特定业务场景下的性能表现。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文系统化研究LLM训练中的中间阶段优化，直接关联Transformer架构效率与LLM核心技术进步，对推荐系统等应用的模型能力扩展具有重要参考价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06825v1": {
    "title": "Adaptive Tool Generation with Models as Tools and Reinforcement Learning",
    "url": "https://www.alphaxiv.org/abs/2510.06825v1",
    "arxiv_id": "2510.06825v1",
    "authors": "Chenpeng Wang, Xiaojie Cheng, Chunye Wang, Linfeng Yang, Lei Zhang",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 09:48:50",
    "ori_summary": "Tool-augmented language models have demonstrated strong capabilities, but their reliance on live API access creates scalability and reliability challenges during training and deployment. We propose MTR, a simulation-first training framework for tool-augmented reasoning. Instead of relying on live APIs, MTR learns from complete ReAct traces with schema-validated, simulated observations. Our approach operates through a multi-agent architecture where a ToolMaker generates task-specific, OpenAI-compatible tool interfaces, an AutoAgent produces structured think-act-observe sequences, and a ToolActor simulates realistic responses. Training proceeds in two stages: Stage-1 Supervised Fine-Tuning (SFT) teaches 'trace grammar' from complete reasoning sequences; Stage-2 Group Relative Policy Optimization (GRPO) optimizes strategy with a composite trace reward that balances answer correctness and internal consistency. Across four multi-hop QA benchmarks (HotpotQA, MuSiQue, 2WikiMultiHopQA, Bamboogle), MTR attains competitive Exact Match (EM) scores to live-API systems and excels on reasoning-intensive tasks, suggesting that effective tool reasoning can be learned from structured traces without live interactions.",
    "summary": "",
    "translation": "基于模型即工具与强化学习的自适应工具生成",
    "relevance_score": 6,
    "reasoning": "该论文涉及使用强化学习进行工具生成，这在推荐系统或搜索中具有潜在应用，例如动态生成个性化推荐工具或优化搜索策略。然而，由于未明确提及具体应用领域，且可能偏向通用AI工具生成，因此相关性中等。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06811v1": {
    "title": "BlackboxNLP-2025 MIB Shared Task: Exploring Ensemble Strategies for Circuit Localization Methods",
    "url": "https://www.alphaxiv.org/abs/2510.06811v1",
    "arxiv_id": "2510.06811v1",
    "authors": "Philipp Mondorf, Mingyang Wang, Sebastian Gerstner, Ahmad Dawar Hakimi, Yihong Liu, Leonor Veloso, Shijia Zhou, Hinrich Schütze, Barbara Plank",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 09:39:40",
    "ori_summary": "The Circuit Localization track of the Mechanistic Interpretability Benchmark (MIB) evaluates methods for localizing circuits within large language models (LLMs), i.e., subnetworks responsible for specific task behaviors. In this work, we investigate whether ensembling two or more circuit localization methods can improve performance. We explore two variants: parallel and sequential ensembling. In parallel ensembling, we combine attribution scores assigned to each edge by different methods-e.g., by averaging or taking the minimum or maximum value. In the sequential ensemble, we use edge attribution scores obtained via EAP-IG as a warm start for a more expensive but more precise circuit identification method, namely edge pruning. We observe that both approaches yield notable gains on the benchmark metrics, leading to a more precise circuit identification approach. Finally, we find that taking a parallel ensemble over various methods, including the sequential ensemble, achieves the best results. We evaluate our approach in the BlackboxNLP 2025 MIB Shared Task, comparing ensemble scores to official baselines across multiple model-task combinations.",
    "summary": "",
    "translation": "BlackboxNLP-2025 MIB共享任务：探索电路定位方法的集成策略",
    "relevance_score": 1,
    "reasoning": "该论文聚焦于电路定位方法的集成策略，属于模型可解释性/分析领域，与推荐系统、搜索或广告的核心技术进展无关。虽然涉及NLP模型分析，但缺乏在推荐/搜索/广告领域的直接应用潜力，属于纯粹的NLP分析任务。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06800v1": {
    "title": "FURINA: A Fully Customizable Role-Playing Benchmark via Scalable Multi-Agent Collaboration Pipeline",
    "url": "https://www.alphaxiv.org/abs/2510.06800v1",
    "arxiv_id": "2510.06800v1",
    "authors": "Haotian Wu, Shufan Jiang, Chios Chen, Yiyang Feng, Hehai Lin, Heqing Zou, Yao Shu, Yanran Li, Chengwei Qin",
    "categories": "cs.CL, cs.AI, cs.HC, cs.MA",
    "pub_date": "2025-10-08 09:30:36",
    "ori_summary": "As large language models (LLMs) advance in role-playing (RP) tasks, existing benchmarks quickly become obsolete due to their narrow scope, outdated interaction paradigms, and limited adaptability across diverse application scenarios. To address this gap, we introduce FURINA-Builder, a novel multi-agent collaboration pipeline that automatically constructs fully customizable RP benchmarks at any scale. It enables evaluation of arbitrary characters across diverse scenarios and prompt formats, as the first benchmark builder in RP area for adaptable assessment. FURINA-Builder simulates dialogues between a test character and other characters drawn from a well-constructed character-scene pool, while an LLM judge selects fine-grained evaluation dimensions and adjusts the test character's responses into final test utterances. Using this pipeline, we build FURINA-Bench, a new comprehensive role-playing benchmark featuring both established and synthesized test characters, each assessed with dimension-specific evaluation criteria. Human evaluation and preliminary separability analysis justify our pipeline and benchmark design. We conduct extensive evaluations of cutting-edge LLMs and find that o3 and DeepSeek-R1 achieve the best performance on English and Chinese RP tasks, respectively. Across all models, established characters consistently outperform synthesized ones, with reasoning capabilities further amplifying this disparity. Interestingly, we observe that model scale does not monotonically reduce hallucinations. More critically, for reasoning LLMs, we uncover a novel trade-off: reasoning improves RP performance but simultaneously increases RP hallucinations. This trade-off extends to a broader Pareto frontier between RP performance and reliability for all LLMs. These findings demonstrate the effectiveness of FURINA-Builder and the challenge posed by FURINA-Bench.",
    "summary": "",
    "translation": "FURINA：通过可扩展多智能体协作流程实现完全可定制的角色扮演基准",
    "relevance_score": 2,
    "reasoning": "该论文主要关注多智能体协作的角色扮演基准测试，属于对话系统和评估领域。虽然多智能体系统在理论上有潜在的推荐系统应用（如模拟用户交互），但论文标题明确聚焦于角色扮演基准，与推荐、搜索或广告的核心技术进展缺乏直接关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06782v1": {
    "title": "GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting",
    "url": "https://www.alphaxiv.org/abs/2510.06782v1",
    "arxiv_id": "2510.06782v1",
    "authors": "Kaichun Yang, Jian Chen",
    "categories": "cs.HC, cs.CL, cs.CV",
    "pub_date": "2025-10-08 09:09:29",
    "ori_summary": "We present a quantitative evaluation to understand the effect of zero-shot large-language model (LLMs) and prompting uses on chart reading tasks. We asked LLMs to answer 107 visualization questions to compare inference accuracies between the agentic GPT-5 and multimodal GPT-4V, for difficult image instances, where GPT-4V failed to produce correct answers. Our results show that model architecture dominates the inference accuracy: GPT5 largely improved accuracy, while prompt variants yielded only small effects. Pre-registration of this work is available here: https://osf.io/u78td/?view_only=6b075584311f48e991c39335c840ded3; the Google Drive materials are here:https://drive.google.com/file/d/1ll8WWZDf7cCNcfNWrLViWt8GwDNSvVrp/view.",
    "summary": "",
    "translation": "GPT-5模型纠正了GPT-4V的图表读取错误，而非通过提示工程",
    "relevance_score": 3,
    "reasoning": "该论文主要关注多模态模型的错误纠正能力，属于VLM范畴，但与推荐系统、搜索或广告的异构数据统一建模关联较弱。虽然涉及模型迭代改进，但未明确展示在RecSys/Search/Ads中的直接应用潜力，如处理用户行为序列与上下文特征的模态融合。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06780v1": {
    "title": "Foundations of LLM Knowledge Materialization: Termination, Reproducibility, Robustness",
    "url": "https://www.alphaxiv.org/abs/2510.06780v1",
    "arxiv_id": "2510.06780v1",
    "authors": "Luca Giordano, Simon Razniewski",
    "categories": "cs.CL, cs.AI",
    "pub_date": "2025-10-08 09:03:58",
    "ori_summary": "Large Language Models (LLMs) encode substantial factual knowledge, yet measuring and systematizing this knowledge remains challenging. Converting it into structured format, for example through recursive extraction approaches such as the GPTKB methodology (Hu et al., 2025b), is still underexplored. Key open questions include whether such extraction can terminate, whether its outputs are reproducible, and how robust they are to variations. We systematically study LLM knowledge materialization using miniGPTKBs (domain-specific, tractable subcrawls), analyzing termination, reproducibility, and robustness across three categories of metrics: yield, lexical similarity, and semantic similarity. We experiment with four variations (seed, language, randomness, model) and three illustrative domains (from history, entertainment, and finance). Our findings show (i) high termination rates, though model-dependent; (ii) mixed reproducibility; and (iii) robustness that varies by perturbation type: high for seeds and temperature, lower for languages and models. These results suggest that LLM knowledge materialization can reliably surface core knowledge, while also revealing important limitations.",
    "summary": "论文研究LLM知识结构化提取的核心挑战，核心方法是系统分析知识提取过程的终止性、可复现性和鲁棒性，揭示LLM知识提取的可靠性边界。",
    "translation": "大语言模型知识物化的基础：终止性、可复现性与鲁棒性",
    "relevance_score": 8,
    "reasoning": "该论文聚焦LLM知识物化的基础性质，直接属于'Enabling LLM Tech'范畴。这些基础性质（终止性、可复现性、鲁棒性）对于构建可靠的推荐和搜索系统至关重要，能够确保LLM在商业应用中产生一致且可信的结果，从而提升用户体验和系统可靠性。",
    "rerank_relevance_score": 7,
    "rerank_reasoning": "该论文系统研究LLM知识提取的终止性、可复现性和鲁棒性，直接关联LLM技术在推荐系统等领域的知识应用基础。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06774v1": {
    "title": "Adaptive LLM-Symbolic Reasoning via Dynamic Logical Solver Composition",
    "url": "https://www.alphaxiv.org/abs/2510.06774v1",
    "arxiv_id": "2510.06774v1",
    "authors": "Lei Xu, Pierre Beckmann, Marco Valentino, André Freitas",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 08:57:16",
    "ori_summary": "Neuro-symbolic NLP methods aim to leverage the complementary strengths of large language models and formal logical solvers. However, current approaches are mostly static in nature, i.e., the integration of a target solver is predetermined at design time, hindering the ability to employ diverse formal inference strategies. To address this, we introduce an adaptive, multi-paradigm, neuro-symbolic inference framework that: (1) automatically identifies formal reasoning strategies from problems expressed in natural language; and (2) dynamically selects and applies specialized formal logical solvers via autoformalization interfaces. Extensive experiments on individual and multi-paradigm reasoning tasks support the following conclusions: LLMs are effective at predicting the necessary formal reasoning strategies with an accuracy above 90 percent. This enables flexible integration with formal logical solvers, resulting in our framework outperforming competing baselines by 27 percent and 6 percent compared to GPT-4o and DeepSeek-V3.1, respectively. Moreover, adaptive reasoning can even positively impact pure LLM methods, yielding gains of 10, 5, and 6 percent on zero-shot, CoT, and symbolic CoT settings with GPT-4o. Finally, although smaller models struggle with adaptive neuro-symbolic reasoning, post-training offers a viable path to improvement. Overall, this work establishes the foundations for adaptive LLM-symbolic reasoning, offering a path forward for unifying material and formal inferences on heterogeneous reasoning challenges.",
    "summary": "该论文研究静态神经符号方法无法灵活运用多样化形式推理策略的问题，核心思想是构建自适应多范式推理框架，通过LLM自动识别自然语言问题所需的形式推理策略，并动态选择和组合专用逻辑求解器进行自动形式化推理。",
    "translation": "基于动态逻辑求解器组合的自适应大语言模型符号推理",
    "relevance_score": 8,
    "reasoning": "该论文涉及LLM与符号推理的结合，属于核心LLM技术进步。动态逻辑求解器组合可增强LLM的推理能力，在搜索系统中能提升复杂查询理解与答案准确性，在推荐系统中可改善多约束条件下的个性化推荐逻辑。这种增强的符号推理能力对处理用户复杂意图和多维度偏好具有直接应用价值。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文提出的动态逻辑求解器组合框架直接属于LLM符号推理前沿技术，在推荐搜索系统中对复杂用户意图理解和多模态推理具有重要应用价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06761v1": {
    "title": "Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration",
    "url": "https://www.alphaxiv.org/abs/2510.06761v1",
    "arxiv_id": "2510.06761v1",
    "authors": "Zhi Zhang, Yan Liu, Zhejing Hu, Gong Chen, Sheng-hua Zhong, Jiannong Cao",
    "categories": "cs.AI, cs.CL",
    "pub_date": "2025-10-08 08:40:58",
    "ori_summary": "Automating the end-to-end scientific research process poses a fundamental challenge: it requires both evolving high-level plans that are novel and sound, and executing these plans correctly amidst dynamic and uncertain conditions. To address this bilevel challenge, we propose a novel Double-Loop Multi-Agent (DLMA) framework to solve the given research problem automatically. The leader loop, composed of professor agents, is responsible for evolving research plans. It employs an evolutionary algorithm through involvement, improvement, and integration meetings to iteratively generate and refine a pool of research proposals, exploring the solution space effectively. The follower loop, composed of doctoral student agents, is responsible for executing the best-evolved plan. It dynamically adjusts the plan during implementation via pre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is well-supported by contextual and external observations. Extensive experiments on benchmarks like ACLAward and Laboratory show that DLMA generates research papers that achieve state-of-the-art scores in automated evaluation, significantly outperforming strong baselines. Ablation studies confirm the critical roles of both loops, with evolution driving novelty and execution ensuring soundness.",
    "summary": "",
    "translation": "通过双循环多智能体协作演进与执行研究计划",
    "relevance_score": 2,
    "reasoning": "该论文主要关注多智能体协作的研究计划制定与执行，属于通用AI系统架构范畴。虽然多智能体系统在理论上可能应用于推荐或搜索中的复杂决策流程，但论文标题未明确涉及推荐系统、搜索、广告或相关的Transformer/LLM技术，与当前关注点的直接关联性较弱。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06750v1": {
    "title": "Gold-Switch: Training-Free Superposition of Slow- and Fast- Thinking LLMs",
    "url": "https://www.alphaxiv.org/abs/2510.06750v1",
    "arxiv_id": "2510.06750v1",
    "authors": "Jaeseong Lee, Dayoung Kwon, seung-won hwang",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 08:17:57",
    "ori_summary": "Large Reasoning Models (LRMs) excel in structured tasks by emulating deliberate human reasoning but often suffer from overthinking, degrading performance and wasting resources. One possible baseline is to deploy both LLM and LRM, then route input by predicting whether it requires reasoning and may cause overthinking. However, deploying multiple models can be costly or impractical. We propose a superposed deployment strategy with a lightweight, training-free regulation to optimize inference by switching one model on and off. Instead of routing, we selectively unlearn from LRM at inference, scaling down computation while preserving reasoning. By analyzing the cumulative energy of singular values, we identify optimal low-rank projections to adjust reasoning just right.",
    "summary": "论文研究大型推理模型在结构化任务中因过度思考导致的性能下降和资源浪费问题。核心方法是提出无需训练的叠加部署策略，通过分析奇异值累积能量识别最优低秩投影，在推理时选择性调控模型计算强度。",
    "translation": "Gold-Switch：免训练叠加慢思考与快思考大语言模型",
    "relevance_score": 8,
    "reasoning": "该论文提出的免训练叠加慢思考与快思考LLM的方法属于核心LLM技术进展，通过结合不同推理速度的模型实现效率与性能的平衡。这种技术在推荐系统和搜索中具有直接应用潜力，可以用于构建分层推理系统，在资源受限时使用快速模型进行初步筛选，在关键决策时切换到慢速高精度模型，从而优化计算资源分配和响应延迟。",
    "rerank_relevance_score": 8,
    "rerank_reasoning": "该论文提出无需训练的动态推理优化方法，通过低秩投影选择性调控模型计算，直接提升LLM推理效率，与Transformer架构优化和LLM应用高度相关。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06749v1": {
    "title": "A Formal Framework for Fluency-based Multi-Reference Evaluation in Grammatical Error Correction",
    "url": "https://www.alphaxiv.org/abs/2510.06749v1",
    "arxiv_id": "2510.06749v1",
    "authors": "Eitan Klinger, Zihao Huang, Tran Minh Nguyen, Emma Jayeon Park, Yige Chen, Yang Gu, Qingyu Gao, Siliang Liu, Mengyang Qiu, Jungyeul Park",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 08:15:44",
    "ori_summary": "Evaluating grammatical error correction requires metrics that reflect the diversity of valid human corrections rather than privileging a single reference. Existing frameworks, largely edit-based and English-centric, rely on rigid alignments between system and reference edits, limiting their applicability in multilingual and generative settings. This paper introduces a formal framework for \\textit{fluency-based multi-reference evaluation}, framing $n$-gram similarity as an aggregation problem over multiple legitimate corrections. Within this formulation, we instantiate GLEU through four aggregation strategies--\\textsc{select-best}, \\textsc{simple-average}, \\textsc{weighted-average}, and \\textsc{merged-counts}--and analyze their properties of boundedness, monotonicity, and sensitivity to reference variation. Empirical results on Czech, Estonian, Ukrainian, and Chinese corpora show that these strategies capture complementary aspects of fluency and coverage. The framework unifies multi-reference evaluation into a principled, fluency-oriented approach that incorporates linguistic diversity without penalizing legitimate variation.",
    "summary": "",
    "translation": "基于流畅度的多参考评估在语法错误纠正中的形式化框架",
    "relevance_score": 1,
    "reasoning": "该论文专注于语法错误纠正的评估方法，属于纯粹的NLP评估基准范畴，与推荐系统、搜索或广告的核心技术无关。论文内容涉及多参考评估和流畅度指标，这些在您的关注领域中没有任何直接应用或技术启发性。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06747v1": {
    "title": "TWIST: Training-free and Label-free Short Text Clustering through Iterative Vector Updating with LLMs",
    "url": "https://www.alphaxiv.org/abs/2510.06747v1",
    "arxiv_id": "2510.06747v1",
    "authors": "I-Fan Lin, Faegheh Hasibi, Suzan Verberne",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 08:05:39",
    "ori_summary": "In this paper, we propose a training-free and label-free method for short text clustering that can be used on top of any existing embedder. In the context of customer-facing chatbots, companies are dealing with large amounts of user utterances that need to be clustered according to their intent. In these commercial settings, no labeled data is typically available, and the number of clusters is not known. Our method is based on iterative vector updating: it constructs sparse vectors based on representative texts, and then iteratively refines them through LLM guidance. Our method achieves comparable or superior results to state-of-the-art methods that use contrastive learning, but without assuming prior knowledge of clusters or labels. Experiments on diverse datasets and smaller LLMs show that our method is model agnostic and can be applied to any embedder, with relatively small LLMs, and different clustering methods. We also show that our method scales to large datasets, reducing the computational cost of the LLM. These low-resource, adaptable settings and the scalability of our method make it more aligned with real-world scenarios than existing clustering methods.",
    "summary": "",
    "translation": "TWIST：通过大语言模型迭代向量更新的免训练与免标签短文本聚类",
    "relevance_score": 6,
    "reasoning": "该论文提出了一种免训练和免标签的短文本聚类方法，通过LLMs进行迭代向量更新，这属于核心LLM技术的进展。该方法在推荐系统或搜索中有潜在应用，例如用于用户查询聚类、内容分类或用户兴趣发现，以提升个性化推荐或搜索结果的组织。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06743v1": {
    "title": "Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities",
    "url": "https://www.alphaxiv.org/abs/2510.06743v1",
    "arxiv_id": "2510.06743v1",
    "authors": "Maria Levchenko",
    "categories": "cs.CV, cs.AI, cs.CL, 68T50",
    "pub_date": "2025-10-08 08:01:40",
    "ori_summary": "Digital humanities scholars increasingly use Large Language Models for historical document digitization, yet lack appropriate evaluation frameworks for LLM-based OCR. Traditional metrics fail to capture temporal biases and period-specific errors crucial for historical corpus creation. We present an evaluation methodology for LLM-based historical OCR, addressing contamination risks and systematic biases in diplomatic transcription. Using 18th-century Russian Civil font texts, we introduce novel metrics including Historical Character Preservation Rate (HCPR) and Archaic Insertion Rate (AIR), alongside protocols for contamination control and stability testing. We evaluate 12 multimodal LLMs, finding that Gemini and Qwen models outperform traditional OCR while exhibiting over-historicization: inserting archaic characters from incorrect historical periods. Post-OCR correction degrades rather than improves performance. Our methodology provides digital humanities practitioners with guidelines for model selection and quality assessment in historical corpus digitization.",
    "summary": "",
    "translation": "评估大语言模型在历史文档OCR中的应用：数字人文领域的方法论框架",
    "relevance_score": 1,
    "reasoning": "该论文专注于历史文档OCR在数字人文领域的应用，属于特定领域应用而非核心推荐系统、搜索或广告技术。论文内容涉及文档识别和人文研究，与LLM在RecSys/Search/Ads中的核心进展、架构改进或直接应用无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06738v1": {
    "title": "AWM: Accurate Weight-Matrix Fingerprint for Large Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.06738v1",
    "arxiv_id": "2510.06738v1",
    "authors": "Boyi Zeng, Lin Chen, Ziwei He, Xinbing Wang, Zhouhan Lin",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 07:51:11",
    "ori_summary": "Protecting the intellectual property of large language models (LLMs) is crucial, given the substantial resources required for their training. Consequently, there is an urgent need for both model owners and third parties to determine whether a suspect LLM is trained from scratch or derived from an existing base model. However, the intensive post-training processes that models typically undergo-such as supervised fine-tuning, extensive continued pretraining, reinforcement learning, multi-modal extension, pruning, and upcycling-pose significant challenges to reliable identification. In this work, we propose a training-free fingerprinting method based on weight matrices. We leverage the Linear Assignment Problem (LAP) and an unbiased Centered Kernel Alignment (CKA) similarity to neutralize the effects of parameter manipulations, yielding a highly robust and high-fidelity similarity metric. On a comprehensive testbed of 60 positive and 90 negative model pairs, our method demonstrates exceptional robustness against all six aforementioned post-training categories while exhibiting a near-zero risk of false positives. By achieving perfect scores on all classification metrics, our approach establishes a strong basis for reliable model lineage verification. Moreover, the entire computation completes within 30s on an NVIDIA 3090 GPU. The code is available at https://github.com/LUMIA-Group/AWM.",
    "summary": "论文研究LLM知识产权保护中的模型溯源问题，核心方法是通过权重矩阵指纹和线性分配问题构建训练无关的鲁棒相似度度量，以识别模型是否源自现有基础模型。",
    "translation": "AWM：面向大语言模型的精确权重矩阵指纹方法",
    "relevance_score": 8,
    "reasoning": "该论文提出的大语言模型权重矩阵指纹技术属于核心LLM技术进展，对于推荐系统、搜索和广告领域具有重要应用价值。精确的权重指纹可用于模型版权保护、模型溯源和模型完整性验证，在工业级推荐和广告系统中确保模型部署的安全性和可靠性。",
    "rerank_relevance_score": 3,
    "rerank_reasoning": "该论文专注于LLM知识产权保护技术，与推荐系统、搜索广告的核心算法进步关联较弱，仅在模型安全验证方面有间接价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06730v1": {
    "title": "PTEB: Towards Robust Text Embedding Evaluation via Stochastic Paraphrasing at Evaluation Time with LLMs",
    "url": "https://www.alphaxiv.org/abs/2510.06730v1",
    "arxiv_id": "2510.06730v1",
    "authors": "Manuel Frank, Haithem Afli",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 07:37:19",
    "ori_summary": "Current evaluations of sentence embedding models typically rely on static test beds such as the Massive Text Embedding Benchmark (MTEB). While invaluable, repeated tuning on a fixed suite can inflate reported performance and obscure real-world robustness. We introduce the Paraphrasing Text Embedding Benchmark (PTEB), a dynamic protocol that stochastically generates meaning-preserving paraphrases at evaluation time and aggregates results across multiple runs. Using a cost-efficient LLM-based method grounded in semantic textual similarity gold ratings, we show that LLMs generate token-diverse but semantically preserving, paraphrases. Across 7 MTEB tasks, we validate our hypothesis that the performance of sentence encoders is sensitive to changes in token space even when semantics remain fixed. We also observe that smaller models are not disproportionately affected relative to larger ones. Our results are statistically robust over multiple runs and we extended our experiments to 3 multilingual datasets covering 10 languages. More generally, we aim to propose a new evaluation paradigm in NLP that relies less on static, pre-defined benchmarks but shifts towards dynamic, stochastic evaluation leveraging eval-time compute.",
    "summary": "",
    "translation": "PTEB：通过LLM在评估时进行随机复述实现鲁棒文本嵌入评估",
    "relevance_score": 3,
    "reasoning": "该论文主要关注文本嵌入的评估方法，属于LLM评估技术范畴。虽然文本嵌入在搜索和推荐中有应用，但本文聚焦于评估基准本身而非直接应用。其潜在应用包括改进搜索和推荐系统中的嵌入质量评估，但相关性较为间接。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06727v1": {
    "title": "Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management",
    "url": "https://www.alphaxiv.org/abs/2510.06727v1",
    "arxiv_id": "2510.06727v1",
    "authors": "Miao Lu, Weiwei Sun, Weihua Du, Zhan Ling, Xuesong Yao, Kang Liu, Jiecao Chen",
    "categories": "cs.CL, cs.AI, cs.LG",
    "pub_date": "2025-10-08 07:29:22",
    "ori_summary": "We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with \\underline{SU}mmarization augmented \\underline{P}olicy \\underline{O}ptimization (\\texttt{SUPO}), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that \\texttt{SUPO} significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, \\texttt{SUPO} can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit.",
    "summary": "论文研究LLM在多轮工具使用中的上下文长度瓶颈问题，核心思想是通过LLM生成的摘要压缩工具使用历史，保留任务相关信息，并开发端到端策略梯度方法同时优化工具使用行为和摘要策略。",
    "translation": "基于端到端摘要化上下文管理的可扩展LLM多轮强化学习",
    "relevance_score": 8,
    "reasoning": "该论文涉及LLM多轮强化学习的高效扩展，这属于'Enabling LLM Tech'范畴，对推荐系统和搜索中的对话式交互有直接应用潜力。基于摘要的上下文管理技术可以显著提升多轮推荐和搜索对话中的上下文处理效率，减少计算开销同时保持对话连贯性。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文直接针对LLM在多轮交互中的上下文管理瓶颈，提出了端到端的摘要增强RL训练框架，与LLM在推荐搜索系统中的长序列处理需求高度相关。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06719v1": {
    "title": "Differentially Private Synthetic Text Generation for Retrieval-Augmented Generation (RAG)",
    "url": "https://www.alphaxiv.org/abs/2510.06719v1",
    "arxiv_id": "2510.06719v1",
    "authors": "Junki Mori, Kazuya Kakizaki, Taiki Miyagawa, Jun Sakuma",
    "categories": "cs.CR, cs.CL, cs.LG",
    "pub_date": "2025-10-08 07:15:50",
    "ori_summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by grounding them in external knowledge. However, its application in sensitive domains is limited by privacy risks. Existing private RAG methods typically rely on query-time differential privacy (DP), which requires repeated noise injection and leads to accumulated privacy loss. To address this issue, we propose DP-SynRAG, a framework that uses LLMs to generate differentially private synthetic RAG databases. Unlike prior methods, the synthetic text can be reused once created, thereby avoiding repeated noise injection and additional privacy costs. To preserve essential information for downstream RAG tasks, DP-SynRAG extends private prediction, which instructs LLMs to generate text that mimics subsampled database records in a DP manner. Experiments show that DP-SynRAG achieves superior performanec to the state-of-the-art private RAG systems while maintaining a fixed privacy budget, offering a scalable solution for privacy-preserving RAG.",
    "summary": "",
    "translation": "用于检索增强生成(RAG)的差分隐私合成文本生成",
    "relevance_score": 2,
    "reasoning": "虽然RAG技术在搜索和推荐系统中具有应用潜力，但该论文的核心焦点是差分隐私，这属于明确的无关主题范畴。论文标题明确将隐私保护作为主要技术，而不是专注于检索增强生成本身的算法改进或架构创新。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06706v1": {
    "title": "XLSR-Kanformer: A KAN-Intergrated model for Synthetic Speech Detection",
    "url": "https://www.alphaxiv.org/abs/2510.06706v1",
    "arxiv_id": "2510.06706v1",
    "authors": "Phuong Tuan Dat, Tran Huy Dat",
    "categories": "cs.SD, cs.CL, eess.AS",
    "pub_date": "2025-10-08 06:58:58",
    "ori_summary": "Recent advancements in speech synthesis technologies have led to increasingly sophisticated spoofing attacks, posing significant challenges for automatic speaker verification systems. While systems based on self-supervised learning (SSL) models, particularly the XLSR-Conformer architecture, have demonstrated remarkable performance in synthetic speech detection, there remains room for architectural improvements. In this paper, we propose a novel approach that replaces the traditional Multi-Layer Perceptron (MLP) in the XLSR-Conformer model with a Kolmogorov-Arnold Network (KAN), a powerful universal approximator based on the Kolmogorov-Arnold representation theorem. Our experimental results on ASVspoof2021 demonstrate that the integration of KAN to XLSR-Conformer model can improve the performance by 60.55% relatively in Equal Error Rate (EER) LA and DF sets, further achieving 0.70% EER on the 21LA set. Besides, the proposed replacement is also robust to various SSL architectures. These findings suggest that incorporating KAN into SSL-based models is a promising direction for advances in synthetic speech detection.",
    "summary": "",
    "translation": "XLSR-Kanformer：一种集成KAN的合成语音检测模型",
    "relevance_score": 1,
    "reasoning": "该论文专注于合成语音检测，属于语音处理领域，与我的核心关注点（推荐系统、搜索、广告）没有直接关联。语音检测技术本身在推荐、搜索或广告领域缺乏明确的应用场景，因此相关性极低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06700v1": {
    "title": "How Language Models Conflate Logical Validity with Plausibility: A Representational Analysis of Content Effects",
    "url": "https://www.alphaxiv.org/abs/2510.06700v1",
    "arxiv_id": "2510.06700v1",
    "authors": "Leonardo Bertolazzi, Sandro Pezzelle, Raffaelle Bernardi",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 06:48:08",
    "ori_summary": "Both humans and large language models (LLMs) exhibit content effects: biases in which the plausibility of the semantic content of a reasoning problem influences judgments regarding its logical validity. While this phenomenon in humans is best explained by the dual-process theory of reasoning, the mechanisms behind content effects in LLMs remain unclear. In this work, we address this issue by investigating how LLMs encode the concepts of validity and plausibility within their internal representations. We show that both concepts are linearly represented and strongly aligned in representational geometry, leading models to conflate plausibility with validity. Using steering vectors, we demonstrate that plausibility vectors can causally bias validity judgements, and vice versa, and that the degree of alignment between these two concepts predicts the magnitude of behavioral content effects across models. Finally, we construct debiasing vectors that disentangle these concepts, reducing content effects and improving reasoning accuracy. Our findings advance understanding of how abstract logical concepts are represented in LLMs and highlight representational interventions as a path toward more logical systems.",
    "summary": "",
    "translation": "语言模型如何混淆逻辑有效性与合理性：内容效应的表征分析",
    "relevance_score": 2,
    "reasoning": "该论文主要研究语言模型在逻辑推理和内容合理性方面的混淆问题，这属于LLM评估和推理能力的范畴。虽然涉及LLM表征分析，但其焦点是逻辑推理的认知偏差，与推荐系统、搜索或广告中的实际应用关联较弱，更偏向NLP基础研究而非实际应用导向。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06695v1": {
    "title": "Learning to Rewrite Prompts for Bootstrapping LLMs on Downstream Tasks",
    "url": "https://www.alphaxiv.org/abs/2510.06695v1",
    "arxiv_id": "2510.06695v1",
    "authors": "Qinhao Zhou, Xiang Xiang, Kun He, John E. Hopcroft",
    "categories": "cs.CL, cs.AI, cs.LG, eess.AS",
    "pub_date": "2025-10-08 06:40:06",
    "ori_summary": "In recent years, the growing interest in Large Language Models (LLMs) has significantly advanced prompt engineering, transitioning from manual design to model-based optimization. Prompts for LLMs generally comprise two components: the \\textit{instruction}, which defines the task or objective, and the \\textit{input}, which is tailored to the instruction type. In natural language generation (NLG) tasks such as machine translation, the \\textit{input} component is particularly critical, while the \\textit{instruction} component tends to be concise. Existing prompt engineering methods primarily focus on optimizing the \\textit{instruction} component for general tasks, often requiring large-parameter LLMs as auxiliary tools. However, these approaches exhibit limited applicability for tasks like machine translation, where the \\textit{input} component plays a more pivotal role. To address this limitation, this paper introduces a novel prompt optimization method specifically designed for machine translation tasks. The proposed approach employs a small-parameter model trained using a back-translation-based strategy, significantly reducing training overhead for single-task optimization while delivering highly effective performance. With certain adaptations, this method can also be extended to other downstream tasks.",
    "summary": "",
    "translation": "学习重写提示以引导LLM在下游任务上进行自举学习",
    "relevance_score": 7,
    "reasoning": "该论文属于'直接LLM应用'范畴，专注于通过提示重写技术优化LLM在下游任务上的性能。在搜索和推荐系统中，这种方法可以显著提升查询理解、意图识别和个性化提示优化的效果，从而提高系统整体性能。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06677v1": {
    "title": "Incremental Summarization for Customer Support via Progressive Note-Taking and Agent Feedback",
    "url": "https://www.alphaxiv.org/abs/2510.06677v1",
    "arxiv_id": "2510.06677v1",
    "authors": "Yisha Wu, Cen, Zhao, Yuanpei Cao, Xiaoqing Su, Yashar Mehdad, Mindy Ji, Claire Na Cheng",
    "categories": "cs.CL, cs.AI, cs.LG",
    "pub_date": "2025-10-08 06:05:58",
    "ori_summary": "We introduce an incremental summarization system for customer support agents that intelligently determines when to generate concise bullet notes during conversations, reducing agents' context-switching effort and redundant review. Our approach combines a fine-tuned Mixtral-8x7B model for continuous note generation with a DeBERTa-based classifier to filter trivial content. Agent edits refine the online notes generation and regularly inform offline model retraining, closing the agent edits feedback loop. Deployed in production, our system achieved a 3% reduction in case handling time compared to bulk summarization (with reductions of up to 9% in highly complex cases), alongside high agent satisfaction ratings from surveys. These results demonstrate that incremental summarization with continuous feedback effectively enhances summary quality and agent productivity at scale.",
    "summary": "",
    "translation": "基于渐进式笔记记录与客服反馈的客户支持增量摘要生成",
    "relevance_score": 2,
    "reasoning": "该论文主要关注客户支持场景下的增量摘要生成，属于内容生成和对话系统的应用范畴。虽然客户支持与推荐/搜索系统有一定关联，但论文焦点是文本摘要而非核心推荐/搜索/广告的排序或建模技术，因此相关性较低。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06670v1": {
    "title": "PIKA: Expert-Level Synthetic Datasets for Post-Training Alignment from Scratch",
    "url": "https://www.alphaxiv.org/abs/2510.06670v1",
    "arxiv_id": "2510.06670v1",
    "authors": "Shangjian Yin, Shining Liang, Wenbiao Ding, Yuli Qian, Zhouxing Shi, Hongzhi Li, Yutao Xie",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 05:47:37",
    "ori_summary": "Reinforcement Learning from Human Feedback (RLHF) has become a cornerstone for aligning large language models (LLMs). However, its effectiveness depends on high-quality instruction data. Most existing alignment datasets are either private or require costly human annotation, which limits reproducibility and scalability. Even with Reinforcement Learning from AI Feedback (RLAIF), concerns about data quality remain. Moreover, it is unclear how much data is actually required to fine-tune a base model into a strong instruction-following model. Current approaches often rely on over 300k examples even at the supervised fine-tuning (SFT) stage, yet they still underperform compared to proprietary models, creating barriers for academic and resource-limited communities. To address this gap, we introduce PiKa, a data-efficient family of expert-level alignment datasets. In particular, the PiKa-SFT dataset uses only 30k SFT examples, far fewer than state-of-the-art datasets like Magpie. Through evaluations by fine-tuning Llama-3-8B-Base on PiKa and other public datasets, we show that PiKa-SFT outperforms models trained on much larger data. On AlpacaEval 2.0 and Arena-Hard benchmarks, PiKa-SFT fine-tuning even surpasses the official Llama-3-8B-Instruct model trained on over 10 million proprietary examples. We further extend our study by training the Qwen2.5 series (0.5B to 7B) on PiKa-SFT, achieving consistent gains. These findings demonstrate that high-quality alignment can be achieved with significantly less data, offering a scalable path for open-source LLM alignment. Code and data: https://github.com/SJY8460/PiKa.",
    "summary": "该论文研究如何解决LLM对齐过程中高质量指令数据稀缺和成本高昂的问题，其核心方法是开发数据高效的专家级对齐数据集PiKa，通过少量高质量合成数据实现与大规模数据相当的对齐效果。",
    "translation": "PIKA：从零开始用于后训练对齐的专家级合成数据集",
    "relevance_score": 8,
    "reasoning": "该论文涉及LLM后训练对齐的合成数据生成，这属于'使能LLM技术'范畴。高质量的合成数据集可以显著改进推荐系统和搜索中的LLM对齐，例如生成更相关的推荐理由或更准确的搜索查询理解，从而提升用户体验和系统性能。",
    "rerank_relevance_score": 8,
    "rerank_reasoning": "该论文专注于高质量对齐数据集的生成方法，直接关联LLM后训练对齐技术，对推荐和搜索系统中的模型优化具有重要参考价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06664v1": {
    "title": "ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability Memory",
    "url": "https://www.alphaxiv.org/abs/2510.06664v1",
    "arxiv_id": "2510.06664v1",
    "authors": "Yunzhong Xiao, Yangmin Li, Hewei Wang, Yunlong Tang, Zora Zhiruo Wang",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 05:32:31",
    "ori_summary": "Agents utilizing tools powered by large language models (LLMs) or vision-language models (VLMs) have demonstrated remarkable progress in diverse tasks across text and visual modalities. Unlike traditional tools such as calculators, which give deterministic outputs, neural tools perform uncertainly across task scenarios. While different tools for a task may excel in varied scenarios, existing agents typically rely on fixed tools, thus limiting the flexibility in selecting the most suitable tool for specific tasks. In contrast, humans snowball their understanding of the capabilities of different tools by interacting with them, and apply this knowledge to select the optimal tool when solving a future task. To build agents that similarly benefit from this process, we propose ToolMem that enables agents to develop memories of tool capabilities from previous interactions, by summarizing their strengths and weaknesses and storing them in memory; at inference, the agent can retrieve relevant entries from ToolMem, and select the best tool to solve individual tasks more accurately. We evaluate ToolMem on learning varied text generation and text-to-image generation neural tools. Compared to no-memory, generic agents, we find ToolMem-augmented agents predict tool performance 14.8% and 28.7% more accurately across text and multimodal generation scenarios. Moreover, ToolMem facilitates optimal tool selection among multiple choices by 21% and 24% absolute increases in respective scenarios.",
    "summary": "",
    "translation": "ToolMem：通过可学习的工具能力记忆增强多模态智能体",
    "relevance_score": 3,
    "reasoning": "该论文主要关注多模态智能体的工具使用能力增强，属于智能体技术范畴。虽然工具记忆机制可能对推荐系统或搜索中的工具调用有启发意义，但论文焦点是多模态智能体而非具体的推荐/搜索/广告应用，且未明确涉及Transformer架构改进或LLM在推荐领域的直接应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06652v1": {
    "title": "Aligning Large Language Models via Fully Self-Synthetic Data",
    "url": "https://www.alphaxiv.org/abs/2510.06652v1",
    "arxiv_id": "2510.06652v1",
    "authors": "Shangjian Yin, Zhepei Wei, Xinyu Zhu, Wei-Lin Chen, Yu Meng",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 05:07:45",
    "ori_summary": "Traditional reinforcement learning from human feedback (RLHF) for large language models (LLMs) relies on expensive human-annotated datasets, while Reinforcement Learning from AI Feedback (RLAIF) also incurs significant costs, requiring the collection of diverse prompts and corresponding responses, often necessitating external reward models or proprietary models like GPT-4 to annotate preference pairs. In this work, we introduce Self-Alignment Optimization (SAO), a fully self-synthetic framework for LLM alignment, where all training data, including prompts (i.e., user queries), responses, and preferences, are generated by the model itself. Specifically, SAO first instructs the LLM to engage in persona role-play and generate diverse prompts and responses, which are then self-evaluated for preference optimization. Extensive experiments demonstrate that SAO effectively enhances the model's chat capabilities on standard benchmarks like AlpacaEval~2.0, while maintaining strong performance on downstream objective tasks (e.g., question-answering, math reasoning). Our work provides a practical solution for self-improvement in aligning LLMs, and the code for reproducing our results is available at: https://github.com/SJY8460/SAO.",
    "summary": "论文研究LLM对齐依赖昂贵人工标注数据的问题，核心思想是通过角色扮演让模型自生成多样化的提示、响应和偏好数据，实现完全自合成的对齐优化。",
    "translation": "基于完全自生成数据的大语言模型对齐",
    "relevance_score": 8,
    "reasoning": "该论文涉及大语言模型对齐技术，属于'赋能LLM技术'范畴。自生成数据对齐方法可显著降低高质量对齐数据的获取成本，这对于推荐、搜索和广告系统中需要大量用户交互数据进行模型优化的场景具有重要应用价值，能够提升模型在特定领域的表现和安全性。",
    "rerank_relevance_score": 8,
    "rerank_reasoning": "该论文提出的完全自合成对齐框架直接解决了LLM对齐中的成本问题，其自生成提示、响应和偏好的方法对推荐和搜索系统的LLM应用具有重要参考价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06640v1": {
    "title": "A Comparative Analysis of Contextual Representation Flow in State-Space and Transformer Architectures",
    "url": "https://www.alphaxiv.org/abs/2510.06640v1",
    "arxiv_id": "2510.06640v1",
    "authors": "Nhat M. Hoang, Do Xuan Long, Cong-Duy Nguyen, Min-Yen Kan, Luu Anh Tuan",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 04:46:11",
    "ori_summary": "State Space Models (SSMs) have recently emerged as efficient alternatives to Transformer-Based Models (TBMs) for long-sequence processing, offering linear scaling and lower memory use. Yet, how contextual information flows across layers and tokens in these architectures remains understudied. We present the first unified, token- and layer-level analysis of representation propagation in SSMs and TBMs. Using centered kernel alignment, stability metrics, and probing, we characterize how representations evolve within and across layers. We find a key divergence: TBMs rapidly homogenize token representations, with diversity reemerging only in later layers, while SSMs preserve token uniqueness early but converge to homogenization deeper. Theoretical analysis and parameter randomization further reveal that oversmoothing in TBMs stems from architectural design, whereas in SSMs it arises mainly from training dynamics. These insights clarify the inductive biases of both architectures and inform future model and training designs for long-context reasoning.",
    "summary": "该论文研究状态空间模型和Transformer架构中上下文表示传播的核心差异问题，核心发现是Transformer通过架构设计导致早期表示同质化而状态空间模型通过训练动态实现深层同质化，揭示了两种架构不同的归纳偏倚。",
    "translation": "状态空间与Transformer架构中上下文表示流的对比分析",
    "relevance_score": 8,
    "reasoning": "该论文直接研究Transformer架构的表示流特性，属于'Enabling Transformer Tech'范畴。通过对比状态空间模型与Transformer的上下文表示机制，可能揭示更高效的注意力替代方案或架构改进，这些进展可直接应用于提升推荐系统和搜索中的序列建模效率与性能。",
    "rerank_relevance_score": 9,
    "rerank_reasoning": "该论文深入分析Transformer架构的表示传播机制，直接关联Transformer技术进展，对理解模型内部工作原理和优化架构设计具有重要价值。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06605v1": {
    "title": "Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation",
    "url": "https://www.alphaxiv.org/abs/2510.06605v1",
    "arxiv_id": "2510.06605v1",
    "authors": "Shuo Shao, Yiming Li, Hongwei Yao, Yifei Chen, Yuchen Yang, Zhan Qin",
    "categories": "cs.CR, cs.AI, cs.CL",
    "pub_date": "2025-10-08 03:27:38",
    "ori_summary": "The substantial investment required to develop Large Language Models (LLMs) makes them valuable intellectual property, raising significant concerns about copyright protection. LLM fingerprinting has emerged as a key technique to address this, which aims to verify a model's origin by extracting an intrinsic, unique signature (a \"fingerprint\") and comparing it to that of a source model to identify illicit copies. However, existing black-box fingerprinting methods often fail to generate distinctive LLM fingerprints. This ineffectiveness arises because black-box methods typically rely on model outputs, which lose critical information about the model's unique parameters due to the usage of non-linear functions. To address this, we first leverage Fisher Information Theory to formally demonstrate that the gradient of the model's input is a more informative feature for fingerprinting than the output. Based on this insight, we propose ZeroPrint, a novel method that approximates these information-rich gradients in a black-box setting using zeroth-order estimation. ZeroPrint overcomes the challenge of applying this to discrete text by simulating input perturbations via semantic-preserving word substitutions. This operation allows ZeroPrint to estimate the model's Jacobian matrix as a unique fingerprint. Experiments on the standard benchmark show ZeroPrint achieves a state-of-the-art effectiveness and robustness, significantly outperforming existing black-box methods.",
    "summary": "",
    "translation": "字里行间：基于零阶梯度估计实现可靠黑盒大语言模型指纹识别",
    "relevance_score": 2,
    "reasoning": "该论文主要关注黑盒LLM指纹识别技术，属于模型安全与识别领域，与推荐系统、搜索或广告的核心技术进展关联度较低。虽然涉及LLM技术，但其应用方向偏向安全识别而非推荐/搜索/广告的核心算法改进或架构创新。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06594v1": {
    "title": "Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?",
    "url": "https://www.alphaxiv.org/abs/2510.06594v1",
    "arxiv_id": "2510.06594v1",
    "authors": "Sri Durga Sai Sowmya Kadali, Evangelos E. Papalexakis",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 02:55:31",
    "ori_summary": "Jailbreaking large language models (LLMs) has emerged as a pressing concern with the increasing prevalence and accessibility of conversational LLMs. Adversarial users often exploit these models through carefully engineered prompts to elicit restricted or sensitive outputs, a strategy widely referred to as jailbreaking. While numerous defense mechanisms have been proposed, attackers continuously develop novel prompting techniques, and no existing model can be considered fully resistant. In this study, we investigate the jailbreak phenomenon by examining the internal representations of LLMs, with a focus on how hidden layers respond to jailbreak versus benign prompts. Specifically, we analyze the open-source LLM GPT-J and the state-space model Mamba2, presenting preliminary findings that highlight distinct layer-wise behaviors. Our results suggest promising directions for further research on leveraging internal model dynamics for robust jailbreak detection and defense.",
    "summary": "",
    "translation": "LLM内部层是否揭示用于越狱检测的模式？",
    "relevance_score": 2,
    "reasoning": "该论文主要关注LLM安全性和越狱检测，这属于安全相关主题，在无关主题列表中明确排除。虽然涉及LLM内部机制分析，但核心焦点是安全检测而非推荐系统、搜索或广告的应用。没有明显的技术可以应用于排名或个性化系统。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06579v1": {
    "title": "TinyScientist: An Interactive, Extensible, and Controllable Framework for Building Research Agents",
    "url": "https://www.alphaxiv.org/abs/2510.06579v1",
    "arxiv_id": "2510.06579v1",
    "authors": "Haofei Yu, Keyang Xuan, Fenghai Li, Kunlun Zhu, Zijie Lei, Jiaxun Zhang, Ziheng Qi, Kyle Richardson, Jiaxuan You",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 02:18:57",
    "ori_summary": "Automatic research with Large Language Models (LLMs) is rapidly gaining importance, driving the development of increasingly complex workflows involving multi-agent systems, planning, tool usage, code execution, and human-agent interaction to accelerate research processes. However, as more researchers and developers begin to use and build upon these tools and platforms, the complexity and difficulty of extending and maintaining such agentic workflows have become a significant challenge, particularly as algorithms and architectures continue to advance. To address this growing complexity, TinyScientist identifies the essential components of the automatic research workflow and proposes an interactive, extensible, and controllable framework that easily adapts to new tools and supports iterative growth. We provide an open-source codebase, an interactive web demonstration, and a PyPI Python package to make state-of-the-art auto-research pipelines broadly accessible to every researcher and developer.",
    "summary": "",
    "translation": "TinyScientist：一个用于构建研究型智能体的交互式、可扩展且可控框架",
    "relevance_score": 2,
    "reasoning": "该论文主要关注构建研究型智能体的通用框架，与推荐系统、搜索或广告的核心技术进展无关。虽然框架技术可能间接应用于自动化研究流程，但缺乏明确的RecSys/Search/Ads应用场景或技术关联，且不属于指定的关注领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06559v1": {
    "title": "The Algebra of Meaning: Why Machines Need Montague More Than Moore's Law",
    "url": "https://www.alphaxiv.org/abs/2510.06559v1",
    "arxiv_id": "2510.06559v1",
    "authors": "Cheonkam Jeong, Sungdo Kim, Jewoo Park",
    "categories": "cs.CL, cs.AI, cs.LO",
    "pub_date": "2025-10-08 01:22:26",
    "ori_summary": "Contemporary language models are fluent yet routinely mis-handle the types of meaning their outputs entail. We argue that hallucination, brittle moderation, and opaque compliance outcomes are symptoms of missing type-theoretic semantics rather than data or scale limitations. Building on Montague's view of language as typed, compositional algebra, we recast alignment as a parsing problem: natural-language inputs must be compiled into structures that make explicit their descriptive, normative, and legal dimensions under context. We present Savassan, a neuro-symbolic architecture that compiles utterances into Montague-style logical forms and maps them to typed ontologies extended with deontic operators and jurisdictional contexts. Neural components extract candidate structures from unstructured inputs; symbolic components perform type checking, constraint reasoning, and cross-jurisdiction mapping to produce compliance-aware guidance rather than binary censorship. In cross-border scenarios, the system \"parses once\" (e.g., defect claim(product x, company y)) and projects the result into multiple legal ontologies (e.g., defamation risk in KR/JP, protected opinion in US, GDPR checks in EU), composing outcomes into a single, explainable decision. This paper contributes: (i) a diagnosis of hallucination as a type error; (ii) a formal Montague-ontology bridge for business/legal reasoning; and (iii) a production-oriented design that embeds typed interfaces across the pipeline. We outline an evaluation plan using legal reasoning benchmarks and synthetic multi-jurisdiction suites. Our position is that trustworthy autonomy requires compositional typing of meaning, enabling systems to reason about what is described, what is prescribed, and what incurs liability within a unified algebra of meaning.",
    "summary": "",
    "translation": "意义的代数：为何机器需要蒙塔古而非摩尔定律",
    "relevance_score": 2,
    "reasoning": "该论文标题暗示关注语义理解和形式语义学（蒙塔古语义），这与LLM中的意义表示相关，但未明确涉及推荐系统、搜索或广告的具体应用。虽然语义理解是LLM的基础能力，但标题更偏向理论语言学而非实际应用，与当前关注的直接应用或架构改进关联较弱。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06557v1": {
    "title": "The Markovian Thinker",
    "url": "https://www.alphaxiv.org/abs/2510.06557v1",
    "arxiv_id": "2510.06557v1",
    "authors": "Milad Aghajohari, Kamran Chitsaz, Amirhossein Kazemnejad, Sarath Chandar, Alessandro Sordoni, Aaron Courville, Siva Reddy",
    "categories": "cs.LG, cs.AI, cs.CL",
    "pub_date": "2025-10-08 01:18:13",
    "ori_summary": "Reinforcement learning (RL) has recently become a strong recipe for training reasoning LLMs that produce long chains of thought (LongCoT). Yet the standard RL \"thinking environment\", where the state is the prompt plus all prior reasoning tokens, makes the state unbounded and forces attention-based policies to pay quadratic compute as thoughts lengthen. We revisit the environment itself. We propose Markovian Thinking, a paradigm in which the policy advances reasoning while conditioning on a constant-size state, decoupling thinking length from context size. As an immediate consequence this yields linear compute with constant memory. We instantiate this idea with Delethink, an RL environment that structures reasoning into fixed-size chunks. Within each chunk, the model thinks as usual; at the boundary, the environment resets the context and reinitializes the prompt with a short carryover. Through RL, the policy learns to write a textual state near the end of each chunk sufficient for seamless continuation of reasoning after reset. Trained in this environment, an R1-Distill 1.5B model reasons in 8K-token chunks yet thinks up to 24K tokens, matching or surpassing LongCoT-RL trained with a 24K budget. With test-time scaling, Delethink continues to improve where LongCoT plateaus. The effect of linear compute is substantial: we empirically estimate at 96K average thinking length LongCoT-RL costs 27 H100-months vs. 7 for Delethink. Analysis at RL initialization shows off-the-shelf reasoning models (1.5B-120B) often sample Markovian traces zero-shot across diverse benchmarks, providing positive samples that make RL effective at scale. Our results show that redesigning the thinking environment is a powerful lever: it enables very long reasoning without quadratic overhead and opens a path toward efficient, scalable reasoning LLMs.",
    "summary": "",
    "translation": "马尔可夫思考者",
    "relevance_score": 2,
    "reasoning": "该标题暗示了马尔可夫过程在决策或推理中的应用，可能与序列建模相关，这在推荐系统和搜索中用于用户行为序列分析。然而，缺乏具体的技术细节或与Transformer、LLM或推荐系统核心进展的直接联系，使其相关性较低且不确定。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06552v1": {
    "title": "Flipping the Dialogue: Training and Evaluating User Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.06552v1",
    "arxiv_id": "2510.06552v1",
    "authors": "Tarek Naous, Philippe Laban, Wei Xu, Jennifer Neville",
    "categories": "cs.CL",
    "pub_date": "2025-10-08 01:04:36",
    "ori_summary": "Conversations with LMs involve two participants: a human user leading the conversation, and an LM assistant responding to the user's request. To satisfy this specific role, LMs are post-trained to be helpful assistants -- optimized to produce exhaustive and well-structured responses, free of ambiguity and grammar errors. User utterances, on the other hand, are rarely perfected, with each user phrasing requests in unique ways, sometimes putting in partial effort at each turn and refining on the fly. To evaluate LM performance in realistic settings, prior work simulated users in multi-turn conversations, often prompting an LLM originally trained to be a helpful assistant to act as a user. However, we show that assistant LMs make for poor user simulators, with the surprising finding that better assistants yield worse simulators. Instead, we introduce purpose-built User Language Models (User LMs) - models post-trained to simulate human users in multi-turn conversations. Through various evaluations, we show how User LMs align better with human behavior and achieve better simulation robustness than existing simulation methods. When leveraging User LMs to simulate coding and math conversations, the performance of a strong assistant (GPT-4o) drops from 74.6% to 57.4%, confirming that more realistic simulation environments lead to assistant struggles as they fail to cope with the nuances of users in multi-turn setups.",
    "summary": "研究多轮对话中用户模拟不真实的问题，核心方法是专门训练用户语言模型来模拟人类用户的真实对话行为，而非使用助手模型反向模拟。",
    "translation": "翻转对话：训练与评估用户语言模型",
    "relevance_score": 8,
    "reasoning": "该论文聚焦于用户语言模型的训练与评估，直接属于'直接LLM应用'范畴，对推荐系统、搜索和广告中的用户建模具有重要价值。通过专门训练用户语言模型，可以更好地理解用户意图、偏好和行为模式，从而提升个性化推荐、搜索相关性和广告定向的准确性。",
    "rerank_relevance_score": 7,
    "rerank_reasoning": "该论文提出专门训练用户语言模型来模拟真实对话场景，这对搜索和推荐系统中用户交互建模具有直接应用价值，核心方法创新与多轮对话评估相关。",
    "is_filtered": false,
    "is_fine_ranked": true
  },
  "2510.06548v1": {
    "title": "From Acceleration to Saturation: Scaling Behavior of Bootstrapped Language Model Pretraining",
    "url": "https://www.alphaxiv.org/abs/2510.06548v1",
    "arxiv_id": "2510.06548v1",
    "authors": "Seng Pei Liew, Takuya Kato",
    "categories": "cs.CL, cs.LG",
    "pub_date": "2025-10-08 00:59:33",
    "ori_summary": "Bootstrapped pretraining, i.e., the reuse of a pretrained base model for further pretraining, such as continual pretraining or model growth, is promising at reducing the cost of training language models from scratch. However, its effectiveness remains unclear, especially when applied to overtrained base models. In this work, we empirically study the scaling behavior of bootstrapped pretraining and find that its scaling efficiency diminishes in a predictable manner: The scaling exponent with respect to second-stage pretraining tokens decreases logarithmically with the number of tokens used to pretrain the base model. The joint dependence on first- and second-stage tokens is accurately modeled by a simple scaling law. Such saturation effect reveals a fundamental trade-off in multi-stage pretraining strategies: the more extensively a model is pretrained, the less additional benefit bootstrapping provides. Our findings provide practical insights for efficient language model training and raise important considerations for the reuse of overtrained models.",
    "summary": "",
    "translation": "从加速到饱和：自举语言模型预训练的缩放行为",
    "relevance_score": 8,
    "reasoning": "该论文研究语言模型预训练的缩放行为，属于'Enabling LLM Tech'范畴，探讨LLM训练动态和缩放规律。理解预训练缩放行为对于优化RecSys/Search/Ads中的LLM部署至关重要，可以帮助确定模型规模与性能的平衡点，指导实际应用中的模型选择策略。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.07319v1": {
    "title": "Temporal Prompting Matters: Rethinking Referring Video Object Segmentation",
    "url": "https://www.alphaxiv.org/abs/2510.07319v1",
    "arxiv_id": "2510.07319v1",
    "authors": "Ci-Siang Lin, Min-Hung Chen, I-Jieh Liu, Chien-Yi Wang, Sifei Liu, Yu-Chiang Frank Wang",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 17:59:57",
    "ori_summary": "Referring Video Object Segmentation (RVOS) aims to segment the object referred to by the query sentence in the video. Most existing methods require end-to-end training with dense mask annotations, which could be computation-consuming and less scalable. In this work, we rethink the RVOS problem and aim to investigate the key to this task. Based on existing foundation segmentation models, we decompose the RVOS task into referring, video, and segmentation factors, and propose a Temporal Prompt Generation and Selection (Tenet) framework to address the referring and video factors while leaving the segmentation problem to foundation models. To efficiently adapt image-based foundation segmentation models to referring video object segmentation, we leverage off-the-shelf object detectors and trackers to produce temporal prompts associated with the referring sentence. While high-quality temporal prompts could be produced, they can not be easily identified from confidence scores. To tackle this issue, we propose Prompt Preference Learning to evaluate the quality of the produced temporal prompts. By taking such prompts to instruct image-based foundation segmentation models, we would be able to produce high-quality masks for the referred object, enabling efficient model adaptation to referring video object segmentation. Experiments on RVOS benchmarks demonstrate the effectiveness of the Tenet framework.",
    "summary": "",
    "translation": "时序提示至关重要：重新思考参考视频对象分割",
    "relevance_score": 1,
    "reasoning": "这篇论文专注于计算机视觉中的视频对象分割任务，属于纯粹的视觉领域研究。虽然涉及时序建模，但该技术主要应用于视频理解场景，与推荐系统、搜索或广告中的排序、用户建模等核心任务没有直接关联。论文内容不涉及任何推荐、搜索或广告相关的技术应用场景。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07317v1": {
    "title": "Quantum-enhanced Computer Vision: Going Beyond Classical Algorithms",
    "url": "https://www.alphaxiv.org/abs/2510.07317v1",
    "arxiv_id": "2510.07317v1",
    "authors": "Natacha Kuete Meli, Shuteng Wang, Marcel Seelbach Benkner, Michele Sasdelli, Tat-Jun Chin, Tolga Birdal, Michael Moeller, Vladislav Golyanik",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 17:59:51",
    "ori_summary": "Quantum-enhanced Computer Vision (QeCV) is a new research field at the intersection of computer vision, optimisation theory, machine learning and quantum computing. It has high potential to transform how visual signals are processed and interpreted with the help of quantum computing that leverages quantum-mechanical effects in computations inaccessible to classical (i.e. non-quantum) computers. In scenarios where existing non-quantum methods cannot find a solution in a reasonable time or compute only approximate solutions, quantum computers can provide, among others, advantages in terms of better time scalability for multiple problem classes. Parametrised quantum circuits can also become, in the long term, a considerable alternative to classical neural networks in computer vision. However, specialised and fundamentally new algorithms must be developed to enable compatibility with quantum hardware and unveil the potential of quantum computational paradigms in computer vision. This survey contributes to the existing literature on QeCV with a holistic review of this research field. It is designed as a quantum computing reference for the computer vision community, targeting computer vision students, scientists and readers with related backgrounds who want to familiarise themselves with QeCV. We provide a comprehensive introduction to QeCV, its specifics, and methodologies for formulations compatible with quantum hardware and QeCV methods, leveraging two main quantum computational paradigms, i.e. gate-based quantum computing and quantum annealing. We elaborate on the operational principles of quantum computers and the available tools to access, program and simulate them in the context of QeCV. Finally, we review existing quantum computing tools and learning materials and discuss aspects related to publishing and reviewing QeCV papers, open challenges and potential social implications.",
    "summary": "",
    "translation": "量子增强计算机视觉：超越经典算法",
    "relevance_score": 1,
    "reasoning": "该论文聚焦于量子计算在计算机视觉领域的应用，属于纯粹的视觉研究方向。虽然标题提到'超越经典算法'，但内容明确限定在计算机视觉领域，与推荐系统、搜索或广告的核心技术没有直接关联。量子计算在视觉领域的进展目前难以转化为推荐/搜索/广告系统的实际应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07316v1": {
    "title": "Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers",
    "url": "https://www.alphaxiv.org/abs/2510.07316v1",
    "arxiv_id": "2510.07316v1",
    "authors": "Gangwei Xu, Haotong Lin, Hongcheng Luo, Xianqi Wang, Jingfeng Yao, Lianghui Zhu, Yuechuan Pu, Cheng Chi, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Sida Peng, Xin Yang",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 17:59:33",
    "ori_summary": "This paper presents Pixel-Perfect Depth, a monocular depth estimation model based on pixel-space diffusion generation that produces high-quality, flying-pixel-free point clouds from estimated depth maps. Current generative depth estimation models fine-tune Stable Diffusion and achieve impressive performance. However, they require a VAE to compress depth maps into latent space, which inevitably introduces \\textit{flying pixels} at edges and details. Our model addresses this challenge by directly performing diffusion generation in the pixel space, avoiding VAE-induced artifacts. To overcome the high complexity associated with pixel-space generation, we introduce two novel designs: 1) Semantics-Prompted Diffusion Transformers (SP-DiT), which incorporate semantic representations from vision foundation models into DiT to prompt the diffusion process, thereby preserving global semantic consistency while enhancing fine-grained visual details; and 2) Cascade DiT Design that progressively increases the number of tokens to further enhance efficiency and accuracy. Our model achieves the best performance among all published generative models across five benchmarks, and significantly outperforms all other models in edge-aware point cloud evaluation.",
    "summary": "",
    "translation": "基于语义提示扩散变换器的像素级完美深度估计",
    "relevance_score": 2,
    "reasoning": "该论文主要关注计算机视觉中的深度估计任务，属于纯粹的视觉技术范畴。虽然使用了变换器架构，但其应用场景（深度估计）与推荐系统、搜索或广告没有直接关联，也不涉及处理异构数据或多模态建模。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07313v1": {
    "title": "WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation",
    "url": "https://www.alphaxiv.org/abs/2510.07313v1",
    "arxiv_id": "2510.07313v1",
    "authors": "Zezhong Qian, Xiaowei Chi, Yuming Li, Shizun Wang, Zhiyuan Qin, Xiaozhu Ju, Sirui Han, Shanghang Zhang",
    "categories": "cs.CV, cs.RO",
    "pub_date": "2025-10-08 17:59:08",
    "ori_summary": "Wrist-view observations are crucial for VLA models as they capture fine-grained hand-object interactions that directly enhance manipulation performance. Yet large-scale datasets rarely include such recordings, resulting in a substantial gap between abundant anchor views and scarce wrist views. Existing world models cannot bridge this gap, as they require a wrist-view first frame and thus fail to generate wrist-view videos from anchor views alone. Amid this gap, recent visual geometry models such as VGGT emerge with geometric and cross-view priors that make it possible to address extreme viewpoint shifts. Inspired by these insights, we propose WristWorld, the first 4D world model that generates wrist-view videos solely from anchor views. WristWorld operates in two stages: (i) Reconstruction, which extends VGGT and incorporates our Spatial Projection Consistency (SPC) Loss to estimate geometrically consistent wrist-view poses and 4D point clouds; (ii) Generation, which employs our video generation model to synthesize temporally coherent wrist-view videos from the reconstructed perspective. Experiments on Droid, Calvin, and Franka Panda demonstrate state-of-the-art video generation with superior spatial consistency, while also improving VLA performance, raising the average task completion length on Calvin by 3.81% and closing 42.4% of the anchor-wrist view gap.",
    "summary": "",
    "translation": "WristWorld：通过4D世界模型生成腕部视角用于机器人操作",
    "relevance_score": 1,
    "reasoning": "该论文专注于机器人操作和4D世界模型生成，属于纯粹的机器人视觉领域。虽然涉及生成模型技术，但没有任何与推荐系统、搜索或广告相关的潜在应用场景，完全超出了您关注的领域范围。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07310v1": {
    "title": "MATRIX: Mask Track Alignment for Interaction-aware Video Generation",
    "url": "https://www.alphaxiv.org/abs/2510.07310v1",
    "arxiv_id": "2510.07310v1",
    "authors": "Siyoon Jin, Seongchan Kim, Dahyun Chung, Jaeho Lee, Hyunwook Choi, Jisu Nam, Jiyoung Kim, Seungryong Kim",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 17:57:38",
    "ori_summary": "Video DiTs have advanced video generation, yet they still struggle to model multi-instance or subject-object interactions. This raises a key question: How do these models internally represent interactions? To answer this, we curate MATRIX-11K, a video dataset with interaction-aware captions and multi-instance mask tracks. Using this dataset, we conduct a systematic analysis that formalizes two perspectives of video DiTs: semantic grounding, via video-to-text attention, which evaluates whether noun and verb tokens capture instances and their relations; and semantic propagation, via video-to-video attention, which assesses whether instance bindings persist across frames. We find both effects concentrate in a small subset of interaction-dominant layers. Motivated by this, we introduce MATRIX, a simple and effective regularization that aligns attention in specific layers of video DiTs with multi-instance mask tracks from the MATRIX-11K dataset, enhancing both grounding and propagation. We further propose InterGenEval, an evaluation protocol for interaction-aware video generation. In experiments, MATRIX improves both interaction fidelity and semantic alignment while reducing drift and hallucination. Extensive ablations validate our design choices. Codes and weights will be released.",
    "summary": "",
    "translation": "MATRIX：面向交互感知视频生成的掩码轨迹对齐方法",
    "relevance_score": 2,
    "reasoning": "该论文专注于视频生成中的掩码轨迹对齐技术，属于计算机视觉领域的特定应用。虽然标题提到\"交互感知\"，但这主要针对视频中的物体交互，与推荐系统、搜索或广告中的用户交互建模没有直接关联。该技术缺乏明确的路径应用于异构数据处理或推荐系统架构中。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07302v1": {
    "title": "SpecGuard: Spectral Projection-based Advanced Invisible Watermarking",
    "url": "https://www.alphaxiv.org/abs/2510.07302v1",
    "arxiv_id": "2510.07302v1",
    "authors": "Inzamamul Alam, Md Tanvir Islam, Khan Muhammad, Simon S. Woo",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 17:56:21",
    "ori_summary": "Watermarking embeds imperceptible patterns into images for authenticity verification. However, existing methods often lack robustness against various transformations primarily including distortions, image regeneration, and adversarial perturbation, creating real-world challenges. In this work, we introduce SpecGuard, a novel watermarking approach for robust and invisible image watermarking. Unlike prior approaches, we embed the message inside hidden convolution layers by converting from the spatial domain to the frequency domain using spectral projection of a higher frequency band that is decomposed by wavelet projection. Spectral projection employs Fast Fourier Transform approximation to transform spatial data into the frequency domain efficiently. In the encoding phase, a strength factor enhances resilience against diverse attacks, including adversarial, geometric, and regeneration-based distortions, ensuring the preservation of copyrighted information. Meanwhile, the decoder leverages Parseval's theorem to effectively learn and extract the watermark pattern, enabling accurate retrieval under challenging transformations. We evaluate the proposed SpecGuard based on the embedded watermark's invisibility, capacity, and robustness. Comprehensive experiments demonstrate the proposed SpecGuard outperforms the state-of-the-art models. To ensure reproducibility, the full code is released on \\href{https://github.com/inzamamulDU/SpecGuard_ICCV_2025}{\\textcolor{blue}{\\textbf{GitHub}}}.",
    "summary": "",
    "translation": "SpecGuard：基于频谱投影的先进隐形水印技术",
    "relevance_score": 1,
    "reasoning": "该论文专注于数字水印技术，属于信息安全领域，与推荐系统、搜索或广告的核心技术无关。即使考虑水印在内容保护中的应用，这仍然属于隐私/安全范畴，属于明确的无关主题。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07277v1": {
    "title": "Evaluating Fundus-Specific Foundation Models for Diabetic Macular Edema Detection",
    "url": "https://www.alphaxiv.org/abs/2510.07277v1",
    "arxiv_id": "2510.07277v1",
    "authors": "Franco Javier Arellano, José Ignacio Orlando",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 17:41:02",
    "ori_summary": "Diabetic Macular Edema (DME) is a leading cause of vision loss among patients with Diabetic Retinopathy (DR). While deep learning has shown promising results for automatically detecting this condition from fundus images, its application remains challenging due the limited availability of annotated data. Foundation Models (FM) have emerged as an alternative solution. However, it is unclear if they can cope with DME detection in particular. In this paper, we systematically compare different FM and standard transfer learning approaches for this task. Specifically, we compare the two most popular FM for retinal images--RETFound and FLAIR--and an EfficientNet-B0 backbone, across different training regimes and evaluation settings in IDRiD, MESSIDOR-2 and OCT-and-Eye-Fundus-Images (OEFI). Results show that despite their scale, FM do not consistently outperform fine-tuned CNNs in this task. In particular, an EfficientNet-B0 ranked first or second in terms of area under the ROC and precision/recall curves in most evaluation settings, with RETFound only showing promising results in OEFI. FLAIR, on the other hand, demonstrated competitive zero-shot performance, achieving notable AUC-PR scores when prompted appropriately. These findings reveal that FM might not be a good tool for fine-grained ophthalmic tasks such as DME detection even after fine-tuning, suggesting that lightweight CNNs remain strong baselines in data-scarce environments.",
    "summary": "",
    "translation": "评估用于糖尿病性黄斑水肿检测的眼底特异性基础模型",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学领域（糖尿病性黄斑水肿检测）和计算机视觉应用（眼底图像分析），与搜索、推荐或广告系统完全无关。基础模型虽然涉及LLM相关技术，但应用场景严格限定在医疗诊断领域，属于明确排除的医学应用范畴。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07249v1": {
    "title": "TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation",
    "url": "https://www.alphaxiv.org/abs/2510.07249v1",
    "arxiv_id": "2510.07249v1",
    "authors": "Jiaben Chen, Zixin Wang, Ailing Zeng, Yang Fu, Xueyang Yu, Siyuan Cen, Julian Tanke, Yihang Chen, Koichi Saito, Yuki Mitsufuji, Chuang Gan",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 17:16:09",
    "ori_summary": "In this work, we present TalkCuts, a large-scale dataset designed to facilitate the study of multi-shot human speech video generation. Unlike existing datasets that focus on single-shot, static viewpoints, TalkCuts offers 164k clips totaling over 500 hours of high-quality human speech videos with diverse camera shots, including close-up, half-body, and full-body views. The dataset includes detailed textual descriptions, 2D keypoints and 3D SMPL-X motion annotations, covering over 10k identities, enabling multimodal learning and evaluation. As a first attempt to showcase the value of the dataset, we present Orator, an LLM-guided multi-modal generation framework as a simple baseline, where the language model functions as a multi-faceted director, orchestrating detailed specifications for camera transitions, speaker gesticulations, and vocal modulation. This architecture enables the synthesis of coherent long-form videos through our integrated multi-modal video generation module. Extensive experiments in both pose-guided and audio-driven settings show that training on TalkCuts significantly enhances the cinematographic coherence and visual appeal of generated multi-shot speech videos. We believe TalkCuts provides a strong foundation for future work in controllable, multi-shot speech video generation and broader multimodal learning.",
    "summary": "",
    "translation": "TalkCuts：用于多镜头人类语音视频生成的大规模数据集",
    "relevance_score": 1,
    "reasoning": "该论文专注于语音视频生成，属于纯粹的视觉和语音生成领域，与推荐系统、搜索或广告的核心技术无关。虽然涉及大规模数据集，但应用场景仅限于视频生成，没有明显的推荐、搜索或广告应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07217v1": {
    "title": "GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation",
    "url": "https://www.alphaxiv.org/abs/2510.07217v1",
    "arxiv_id": "2510.07217v1",
    "authors": "Wen Ye, Zhaocheng Liu, Yuwei Gui, Tingyu Yuan, Yunyue Su, Bowen Fang, Chaoyang Zhao, Qiang Liu, Liang Wang",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 16:51:52",
    "ori_summary": "Text-to-image synthesis has made remarkable progress, yet accurately interpreting complex and lengthy prompts remains challenging, often resulting in semantic inconsistencies and missing details. Existing solutions, such as fine-tuning, are model-specific and require training, while prior automatic prompt optimization (APO) approaches typically lack systematic error analysis and refinement strategies, resulting in limited reliability and effectiveness. Meanwhile, test-time scaling methods operate on fixed prompts and on noise or sample numbers, limiting their interpretability and adaptability. To solve these, we introduce a flexible and efficient test-time prompt optimization strategy that operates directly on the input text. We propose a plug-and-play multi-agent system called GenPilot, integrating error analysis, clustering-based adaptive exploration, fine-grained verification, and a memory module for iterative optimization. Our approach is model-agnostic, interpretable, and well-suited for handling long and complex prompts. Simultaneously, we summarize the common patterns of errors and the refinement strategy, offering more experience and encouraging further exploration. Experiments on DPG-bench and Geneval with improvements of up to 16.9% and 5.7% demonstrate the strong capability of our methods in enhancing the text and image consistency and structural coherence of generated images, revealing the effectiveness of our test-time prompt optimization strategy. The code is available at https://github.com/27yw/GenPilot.",
    "summary": "",
    "translation": "GenPilot：一种用于图像生成中测试时提示优化的多智能体系统",
    "relevance_score": 2,
    "reasoning": "该论文主要关注图像生成的提示优化，属于AIGC和内容生成领域，与我的核心关注点（推荐系统、搜索、广告）相关性很低。虽然提到了多智能体系统和提示优化技术，但这些技术没有明确的推荐/搜索/广告应用场景，属于纯粹的LLM内容生成范畴。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07206v1": {
    "title": "EigenScore: OOD Detection using Covariance in Diffusion Models",
    "url": "https://www.alphaxiv.org/abs/2510.07206v1",
    "arxiv_id": "2510.07206v1",
    "authors": "Shirin Shoushtari, Yi Wang, Xiao Shi, M. Salman Asif, Ulugbek S. Kamilov",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 16:42:20",
    "ori_summary": "Out-of-distribution (OOD) detection is critical for the safe deployment of machine learning systems in safety-sensitive domains. Diffusion models have recently emerged as powerful generative models, capable of capturing complex data distributions through iterative denoising. Building on this progress, recent work has explored their potential for OOD detection. We propose EigenScore, a new OOD detection method that leverages the eigenvalue spectrum of the posterior covariance induced by a diffusion model. We argue that posterior covariance provides a consistent signal of distribution shift, leading to larger trace and leading eigenvalues on OOD inputs, yielding a clear spectral signature. We further provide analysis explicitly linking posterior covariance to distribution mismatch, establishing it as a reliable signal for OOD detection. To ensure tractability, we adopt a Jacobian-free subspace iteration method to estimate the leading eigenvalues using only forward evaluations of the denoiser. Empirically, EigenScore achieves SOTA performance, with up to 5% AUROC improvement over the best baseline. Notably, it remains robust in near-OOD settings such as CIFAR-10 vs CIFAR-100, where existing diffusion-based methods often fail.",
    "summary": "",
    "translation": "EigenScore：基于扩散模型中协方差的分布外检测",
    "relevance_score": 2,
    "reasoning": "该论文主要关注扩散模型中的分布外检测技术，属于计算机视觉领域的特定应用。虽然扩散模型是生成模型的一种，但该工作专注于检测异常样本，与推荐系统、搜索或广告中的核心排名、用户建模或内容理解任务没有直接关联。其技术方法（协方差分析）在当前形式下难以转化为推荐/搜索领域的实际应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07191v1": {
    "title": "Resolution scaling governs DINOv3 transfer performance in chest radiograph classification",
    "url": "https://www.alphaxiv.org/abs/2510.07191v1",
    "arxiv_id": "2510.07191v1",
    "authors": "Soroosh Tayebi Arasteh, Mina Shaigan, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn",
    "categories": "cs.CV, cs.AI, cs.LG",
    "pub_date": "2025-10-08 16:25:04",
    "ori_summary": "Self-supervised learning (SSL) has advanced visual representation learning, but its value in chest radiography, a high-volume imaging modality with fine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSL models through Gram-anchored self-distillation. Whether these design choices improve transfer learning for chest radiography has not been systematically tested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across seven datasets (n>814,000). Two representative backbones were evaluated: ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and 1024x1024 pixels. We additionally assessed frozen features from a 7B model. The primary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2 achieved comparable performance on adult datasets. Increasing resolution to 512x512 yielded consistent improvements for DINOv3 over both DINOv2 and ImageNet. In contrast, results in pediatric cohort showed no differences across initializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models using frozen DINOv3-7B features underperformed relative to fully finetuned 86-89M-parameter backbones, highlighting the importance of domain adaptation. Scaling to 1024x1024 did not further improve accuracy. Resolution-related gains were most evident for boundary-dependent and small focal abnormalities. In chest radiography, higher input resolution is critical for leveraging the benefits of modern self-supervised models. 512x512 pixels represent a practical upper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest performance, while larger inputs offer minimal return on cost. Clinically, these findings support use of finetuned, mid-sized backbones at 512x512 for chest radiograph interpretation, with the greatest gains expected in detecting subtle or boundary-centered lesions relevant to emergency and critical care settings.",
    "summary": "",
    "translation": "分辨率缩放主导DINOv3在胸部X光片分类中的迁移性能",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学影像（胸部X光片）分类，这属于明确的无关主题（医疗领域特定应用）。虽然DINOv3是视觉基础模型，但论文的应用场景与推荐系统、搜索或广告完全无关，且没有证据表明其技术有跨领域应用的潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07190v1": {
    "title": "MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized Multi-view Performer Synthesis",
    "url": "https://www.alphaxiv.org/abs/2510.07190v1",
    "arxiv_id": "2510.07190v1",
    "authors": "Yihao Zhi, Chenghong Li, Hongjie Liao, Xihe Yang, Zhengwentai Sun, Jiahao Chang, Xiaodong Cun, Wensen Feng, Xiaoguang Han",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 16:24:22",
    "ori_summary": "Recent breakthroughs in video generation, powered by large-scale datasets and diffusion techniques, have shown that video diffusion models can function as implicit 4D novel view synthesizers. Nevertheless, current methods primarily concentrate on redirecting camera trajectory within the front view while struggling to generate 360-degree viewpoint changes. In this paper, we focus on human-centric subdomain and present MV-Performer, an innovative framework for creating synchronized novel view videos from monocular full-body captures. To achieve a 360-degree synthesis, we extensively leverage the MVHumanNet dataset and incorporate an informative condition signal. Specifically, we use the camera-dependent normal maps rendered from oriented partial point clouds, which effectively alleviate the ambiguity between seen and unseen observations. To maintain synchronization in the generated videos, we propose a multi-view human-centric video diffusion model that fuses information from the reference video, partial rendering, and different viewpoints. Additionally, we provide a robust inference procedure for in-the-wild video cases, which greatly mitigates the artifacts induced by imperfect monocular depth estimation. Extensive experiments on three datasets demonstrate our MV-Performer's state-of-the-art effectiveness and robustness, setting a strong model for human-centric 4D novel view synthesis.",
    "summary": "",
    "translation": "MV-Performer：驯服视频扩散模型以实现忠实且同步的多视角表演者合成",
    "relevance_score": 2,
    "reasoning": "这篇论文主要关注视频扩散模型和多视角视频合成，属于计算机视觉和内容生成领域。虽然标题中提到'表演者合成'可能暗示人物生成，但这更偏向纯粹的视觉内容生成，与推荐系统、搜索或广告中的排序和个性化任务没有明确的直接关联。该技术可能适用于广告创意生成，但这属于明确排除的非技术性广告话题。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07181v1": {
    "title": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics",
    "url": "https://www.alphaxiv.org/abs/2510.07181v1",
    "arxiv_id": "2510.07181v1",
    "authors": "Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng, Shanghang Zhang",
    "categories": "cs.RO, cs.AI, cs.CV",
    "pub_date": "2025-10-08 16:20:23",
    "ori_summary": "Vision-Language Models (VLMs) have shown remarkable capabilities in spatial reasoning, yet they remain fundamentally limited to qualitative precision and lack the computational precision required for real-world robotics. Current approaches fail to leverage metric cues from depth sensors and camera calibration, instead reducing geometric problems to pattern recognition tasks that cannot deliver the centimeter-level accuracy essential for robotic manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel framework that transforms VLMs from perceptual estimators to geometric computers by enabling them to generate and execute precise geometric computations through external tools. Rather than attempting to internalize complex geometric operations within neural networks, TIGeR empowers models to recognize geometric reasoning requirements, synthesize appropriate computational code, and invoke specialized libraries for exact calculations. To support this paradigm, we introduce TIGeR-300K, a comprehensive tool-invocation-oriented dataset covering point transformations, pose estimation, trajectory generation, and spatial compatibility verification, complete with tool invocation sequences and intermediate computations. Through a two-stage training pipeline combining supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with our proposed hierarchical reward design, TIGeR achieves SOTA performance on geometric reasoning benchmarks while demonstrating centimeter-level precision in real-world robotic manipulation tasks.",
    "summary": "",
    "translation": "TIGeR：用于机器人的视觉语言模型中工具集成的几何推理",
    "relevance_score": 1,
    "reasoning": "该论文专注于机器人领域的视觉语言模型和几何推理，属于纯粹的机器人应用。虽然涉及视觉语言模型技术，但应用场景是机器人控制而非推荐系统、搜索或广告领域，与我的关注焦点完全无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07143v1": {
    "title": "Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods",
    "url": "https://www.alphaxiv.org/abs/2510.07143v1",
    "arxiv_id": "2510.07143v1",
    "authors": "Chenfei Liao, Wensong Wang, Zichen Wen, Xu Zheng, Yiyu Wang, Haocong He, Yuanhuiyi Lyu, Lutao Jiang, Xin Zou, Yuqian Fu, Bin Ren, Linfeng Zhang, Xuming Hu",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 15:44:28",
    "ori_summary": "Recent endeavors to accelerate inference in Multimodal Large Language Models (MLLMs) have primarily focused on visual token compression. The effectiveness of these methods is typically assessed by measuring the accuracy drop on established benchmarks, comparing model performance before and after compression. However, these benchmarks are originally designed to assess the perception and reasoning capabilities of MLLMs, rather than to evaluate compression techniques. As a result, directly applying them to visual token compression introduces a task mismatch. Strikingly, our investigation reveals that simple image downsampling consistently outperforms many advanced compression methods across multiple widely used benchmarks. Through extensive experiments, we make the following observations: (i) Current benchmarks are noisy for the visual token compression task. (ii) Down-sampling is able to serve as a data filter to evaluate the difficulty of samples in the visual token compression task. Motivated by these findings, we introduce VTC-Bench, an evaluation framework that incorporates a data filtering mechanism to denoise existing benchmarks, thereby enabling fairer and more accurate assessment of visual token compression methods. All data and code are available at https://github.com/Chenfei-Liao/VTC-Bench.",
    "summary": "",
    "translation": "我们是否使用了正确的基准：视觉令牌压缩方法的评估框架",
    "relevance_score": 3,
    "reasoning": "该论文关注视觉令牌压缩方法的评估框架，虽然压缩技术可能间接应用于推荐或搜索系统中的特征表示，但它主要针对视觉模态而非文本或序列数据。对于异构数据建模的VLM类比，其相关性有限，因为焦点是评估而非架构创新或直接应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07135v1": {
    "title": "Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.07135v1",
    "arxiv_id": "2510.07135v1",
    "authors": "Karim El Khoury, Maxime Zanella, Christophe De Vleeschouwer, Benoit Macq",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 15:29:48",
    "ori_summary": "Remote Sensing Vision-Language Models (RSVLMs) have shown remarkable potential thanks to large-scale pretraining, achieving strong zero-shot performance on various tasks. However, their ability to generalize in low-data regimes, such as few-shot learning, remains insufficiently explored. In this work, we present the first structured benchmark for evaluating few-shot adaptation methods on RSVLMs. We conduct comprehensive experiments across ten remote sensing scene classification datasets, applying five widely used few-shot adaptation strategies to three state-of-the-art RSVLMs with varying backbones. Our findings reveal that models with similar zero-shot performance can exhibit markedly different behavior under few-shot adaptation, with some RSVLMs being inherently more amenable to such adaptation than others. The variability of performance and the absence of a clear winner among existing methods highlight the need for the development of more robust methods for few-shot adaptation tailored to RS. To facilitate future research, we provide a reproducible benchmarking framework and open-source code to systematically evaluate RSVLMs under few-shot conditions. The source code is publicly available on Github: https://github.com/elkhouryk/fewshot_RSVLMs",
    "summary": "",
    "translation": "遥感视觉语言模型的少样本适应基准",
    "relevance_score": 2,
    "reasoning": "该论文专注于遥感领域的视觉语言模型基准测试，属于特定的计算机视觉应用领域，与推荐系统、搜索或广告的核心技术相关性较弱。虽然视觉语言模型的少样本学习概念在理论上可能启发多模态推荐系统，但遥感这一特定领域限制了其在RecSys/Search/Ads中的直接应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07134v1": {
    "title": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking",
    "url": "https://www.alphaxiv.org/abs/2510.07134v1",
    "arxiv_id": "2510.07134v1",
    "authors": "Jiahang Liu, Yunpeng Qi, Jiazhao Zhang, Minghan Li, Shaoan Wang, Kui Wu, Hanjing Ye, Hong Zhang, Zhibo Chen, Fangwei Zhong, Zhizheng Zhang, He Wang",
    "categories": "cs.RO, cs.AI, cs.CV",
    "pub_date": "2025-10-08 15:29:17",
    "ori_summary": "Embodied Visual Tracking (EVT) is a fundamental ability that underpins practical applications, such as companion robots, guidance robots and service assistants, where continuously following moving targets is essential. Recent advances have enabled language-guided tracking in complex and unstructured scenes. However, existing approaches lack explicit spatial reasoning and effective temporal memory, causing failures under severe occlusions or in the presence of similar-looking distractors. To address these challenges, we present TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances embodied visual tracking with two key modules, a spatial reasoning mechanism and a Target Identification Memory (TIM). The reasoning module introduces a Chain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative position and encodes it as a compact polar-coordinate token for action prediction. Guided by these spatial priors, the TIM employs a gated update strategy to preserve long-horizon target memory, ensuring spatiotemporal consistency and mitigating target loss during extended occlusions. Extensive experiments show that TrackVLA++ achieves state-of-the-art performance on public benchmarks across both egocentric and multi-camera settings. On the challenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading approach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong zero-shot generalization, enabling robust real-world tracking in dynamic and occluded scenarios.",
    "summary": "",
    "translation": "TrackVLA++：在具身视觉跟踪中释放视觉语言模型的推理与记忆能力",
    "relevance_score": 2,
    "reasoning": "该论文主要关注具身视觉跟踪中的视觉语言模型能力提升，属于计算机视觉和机器人领域。虽然涉及视觉语言模型技术，但其应用场景（具身视觉跟踪）与推荐系统、搜索或广告领域没有直接关联，且论文焦点是机器人导航和跟踪任务，而非异构数据统一建模。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07129v1": {
    "title": "Graph Conditioned Diffusion for Controllable Histopathology Image Generation",
    "url": "https://www.alphaxiv.org/abs/2510.07129v1",
    "arxiv_id": "2510.07129v1",
    "authors": "Sarah Cechnicka, Matthew Baugh, Weitong Zhang, Mischa Dombrowski, Zhe Li, Johannes C. Paetzold, Candice Roufosse, Bernhard Kainz",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 15:26:08",
    "ori_summary": "Recent advances in Diffusion Probabilistic Models (DPMs) have set new standards in high-quality image synthesis. Yet, controlled generation remains challenging, particularly in sensitive areas such as medical imaging. Medical images feature inherent structure such as consistent spatial arrangement, shape or texture, all of which are critical for diagnosis. However, existing DPMs operate in noisy latent spaces that lack semantic structure and strong priors, making it difficult to ensure meaningful control over generated content. To address this, we propose graph-based object-level representations for Graph-Conditioned-Diffusion. Our approach generates graph nodes corresponding to each major structure in the image, encapsulating their individual features and relationships. These graph representations are processed by a transformer module and integrated into a diffusion model via the text-conditioning mechanism, enabling fine-grained control over generation. We evaluate this approach using a real-world histopathology use case, demonstrating that our generated data can reliably substitute for annotated patient data in downstream segmentation tasks. The code is available here.",
    "summary": "",
    "translation": "用于可控组织病理学图像生成的图条件扩散模型",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学领域的组织病理学图像生成，这属于明确的无关主题（医学/生物学应用）。虽然扩散模型是重要的生成技术，但该工作专门针对医疗图像，没有显示出与推荐系统、搜索或广告的直接相关性。生成模型技术本身可能有间接价值，但具体应用领域使其与当前关注点无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07126v1": {
    "title": "Validation of Various Normalization Methods for Brain Tumor Segmentation: Can Federated Learning Overcome This Heterogeneity?",
    "url": "https://www.alphaxiv.org/abs/2510.07126v1",
    "arxiv_id": "2510.07126v1",
    "authors": "Jan Fiszer, Dominika Ciupek, Maciej Malawski",
    "categories": "cs.CV, cs.DC",
    "pub_date": "2025-10-08 15:21:53",
    "ori_summary": "Deep learning (DL) has been increasingly applied in medical imaging, however, it requires large amounts of data, which raises many challenges related to data privacy, storage, and transfer. Federated learning (FL) is a training paradigm that overcomes these issues, though its effectiveness may be reduced when dealing with non-independent and identically distributed (non-IID) data. This study simulates non-IID conditions by applying different MRI intensity normalization techniques to separate data subsets, reflecting a common cause of heterogeneity. These subsets are then used for training and testing models for brain tumor segmentation. The findings provide insights into the influence of the MRI intensity normalization methods on segmentation models, both training and inference. Notably, the FL methods demonstrated resilience to inconsistently normalized data across clients, achieving the 3D Dice score of 92%, which is comparable to a centralized model (trained using all data). These results indicate that FL is a solution to effectively train high-performing models without violating data privacy, a crucial concern in medical applications. The code is available at: https://github.com/SanoScience/fl-varying-normalization.",
    "summary": "",
    "translation": "脑肿瘤分割中多种归一化方法的验证：联邦学习能否克服这种异质性？",
    "relevance_score": 1,
    "reasoning": "该论文明确涉及联邦学习和医学图像分割（脑肿瘤），这两个主题都在不相关主题列表中。虽然提到了归一化方法，但上下文是医学领域的特定应用，与推荐系统、搜索或广告没有明显关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07119v1": {
    "title": "MoRe: Monocular Geometry Refinement via Graph Optimization for Cross-View Consistency",
    "url": "https://www.alphaxiv.org/abs/2510.07119v1",
    "arxiv_id": "2510.07119v1",
    "authors": "Dongki Jung, Jaehoon Choi, Yonghan Lee, Sungmin Eum, Heesung Kwon, Dinesh Manocha",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 15:11:32",
    "ori_summary": "Monocular 3D foundation models offer an extensible solution for perception tasks, making them attractive for broader 3D vision applications. In this paper, we propose MoRe, a training-free Monocular Geometry Refinement method designed to improve cross-view consistency and achieve scale alignment. To induce inter-frame relationships, our method employs feature matching between frames to establish correspondences. Rather than applying simple least squares optimization on these matched points, we formulate a graph-based optimization framework that performs local planar approximation using the estimated 3D points and surface normals estimated by monocular foundation models. This formulation addresses the scale ambiguity inherent in monocular geometric priors while preserving the underlying 3D structure. We further demonstrate that MoRe not only enhances 3D reconstruction but also improves novel view synthesis, particularly in sparse view rendering scenarios.",
    "summary": "",
    "translation": "MoRe：通过图优化实现跨视角一致性的单目几何细化",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉中的单目几何细化和跨视角一致性，属于纯粹的3D视觉领域。虽然提到了图优化技术，但该技术在此上下文中的使用与推荐系统、搜索或广告中的图神经网络应用有本质区别，没有明确的潜在应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07115v1": {
    "title": "Enhancing Concept Localization in CLIP-based Concept Bottleneck Models",
    "url": "https://www.alphaxiv.org/abs/2510.07115v1",
    "arxiv_id": "2510.07115v1",
    "authors": "Rémi Kazmierczak, Steve Azzolin, Eloïse Berthier, Goran Frehse, Gianni Franchi",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 15:07:16",
    "ori_summary": "This paper addresses explainable AI (XAI) through the lens of Concept Bottleneck Models (CBMs) that do not require explicit concept annotations, relying instead on concepts extracted using CLIP in a zero-shot manner. We show that CLIP, which is central in these techniques, is prone to concept hallucination, incorrectly predicting the presence or absence of concepts within an image in scenarios used in numerous CBMs, hence undermining the faithfulness of explanations. To mitigate this issue, we introduce Concept Hallucination Inhibition via Localized Interpretability (CHILI), a technique that disentangles image embeddings and localizes pixels corresponding to target concepts. Furthermore, our approach supports the generation of saliency-based explanations that are more interpretable.",
    "summary": "",
    "translation": "增强基于CLIP的概念瓶颈模型中的概念定位能力",
    "relevance_score": 3,
    "reasoning": "虽然CLIP作为视觉语言模型与VLM类比有潜在关联，但该论文主要关注概念瓶颈模型中的概念定位问题，这更偏向于计算机视觉中的可解释性研究。在推荐/搜索/广告领域的直接应用潜力有限，除非概念定位能明确用于理解用户行为序列或上下文特征中的关键概念。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07089v1": {
    "title": "DADO: A Depth-Attention framework for Object Discovery",
    "url": "https://www.alphaxiv.org/abs/2510.07089v1",
    "arxiv_id": "2510.07089v1",
    "authors": "Federico Gonzalez, Estefania Talavera, Petia Radeva",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 14:46:34",
    "ori_summary": "Unsupervised object discovery, the task of identifying and localizing objects in images without human-annotated labels, remains a significant challenge and a growing focus in computer vision. In this work, we introduce a novel model, DADO (Depth-Attention self-supervised technique for Discovering unseen Objects), which combines an attention mechanism and a depth model to identify potential objects in images. To address challenges such as noisy attention maps or complex scenes with varying depth planes, DADO employs dynamic weighting to adaptively emphasize attention or depth features based on the global characteristics of each image. We evaluated DADO on standard benchmarks, where it outperforms state-of-the-art methods in object discovery accuracy and robustness without the need for fine-tuning.",
    "summary": "",
    "translation": "DADO：一种用于目标发现的深度注意力框架",
    "relevance_score": 2,
    "reasoning": "该论文提出了一种结合深度信息和注意力机制的目标发现框架，属于计算机视觉领域。虽然注意力机制是Transformer的核心组件，但该工作专注于纯粹的视觉目标发现问题，没有明确展示在推荐系统、搜索或广告中的潜在应用。其技术路线更偏向基础视觉研究，与当前关注的LLM技术、推荐系统核心进展或异构数据统一建模缺乏直接关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07077v1": {
    "title": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications",
    "url": "https://www.alphaxiv.org/abs/2510.07077v1",
    "arxiv_id": "2510.07077v1",
    "authors": "Kento Kawaharazuka, Jihoon Oh, Jun Yamada, Ingmar Posner, Yuke Zhu",
    "categories": "cs.RO, cs.AI, cs.CV, cs.LG",
    "pub_date": "2025-10-08 14:38:25",
    "ori_summary": "Amid growing efforts to leverage advances in large language models (LLMs) and vision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models have recently gained significant attention. By unifying vision, language, and action data at scale, which have traditionally been studied separately, VLA models aim to learn policies that generalise across diverse tasks, objects, embodiments, and environments. This generalisation capability is expected to enable robots to solve novel downstream tasks with minimal or no additional task-specific data, facilitating more flexible and scalable real-world deployment. Unlike previous surveys that focus narrowly on action representations or high-level model architectures, this work offers a comprehensive, full-stack review, integrating both software and hardware components of VLA systems. In particular, this paper provides a systematic review of VLAs, covering their strategy and architectural transition, architectures and building blocks, modality-specific processing techniques, and learning paradigms. In addition, to support the deployment of VLAs in real-world robotic applications, we also review commonly used robot platforms, data collection strategies, publicly available datasets, data augmentation methods, and evaluation benchmarks. Throughout this comprehensive survey, this paper aims to offer practical guidance for the robotics community in applying VLAs to real-world robotic systems. All references categorized by training approach, evaluation method, modality, and dataset are available in the table on our project website: https://vla-survey.github.io .",
    "summary": "",
    "translation": "面向机器人技术的视觉-语言-动作模型：迈向实际应用的研究综述",
    "relevance_score": 3,
    "reasoning": "该论文主要关注机器人技术领域的视觉-语言-动作模型，虽然涉及多模态建模概念，但其核心应用场景是机器人控制而非推荐系统、搜索或广告。虽然多模态融合的思想可能与VLM类比异质数据的理念有微弱关联，但缺乏明确的RecSys/Search/Ads应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07058v1": {
    "title": "Concept Retrieval -- What and How?",
    "url": "https://www.alphaxiv.org/abs/2510.07058v1",
    "arxiv_id": "2510.07058v1",
    "authors": "Ori nizan, Oren Shrout, Ayellet Tal",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 14:26:18",
    "ori_summary": "A concept may reflect either a concrete or abstract idea. Given an input image, this paper seeks to retrieve other images that share its central concepts, capturing aspects of the underlying narrative. This goes beyond conventional retrieval or clustering methods, which emphasize visual or semantic similarity. We formally define the problem, outline key requirements, and introduce appropriate evaluation metrics. We propose a novel approach grounded in two key observations: (1) While each neighbor in the embedding space typically shares at least one concept with the query, not all neighbors necessarily share the same concept with one another. (2) Modeling this neighborhood with a bimodal Gaussian distribution uncovers meaningful structure that facilitates concept identification. Qualitative, quantitative, and human evaluations confirm the effectiveness of our approach. See the package on PyPI: https://pypi.org/project/coret/",
    "summary": "",
    "translation": "概念检索——检索什么以及如何检索？",
    "relevance_score": 8,
    "reasoning": "概念检索直接关系到搜索和推荐系统的核心功能，特别是在理解用户查询意图和内容语义方面。这种技术可以应用于改进搜索相关性、增强推荐系统的语义理解能力，以及提升广告定向的精准度。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.07053v1": {
    "title": "Introspection in Learned Semantic Scene Graph Localisation",
    "url": "https://www.alphaxiv.org/abs/2510.07053v1",
    "arxiv_id": "2510.07053v1",
    "authors": "Manshika Charvi Bissessur, Efimia Panagiotaki, Daniele De Martini",
    "categories": "cs.LG, cs.AI, cs.CV, cs.RO, I.2.10; I.2.9; I.4.8; I.5.2; I.5.1",
    "pub_date": "2025-10-08 14:21:45",
    "ori_summary": "This work investigates how semantics influence localisation performance and robustness in a learned self-supervised, contrastive semantic localisation framework. After training a localisation network on both original and perturbed maps, we conduct a thorough post-hoc introspection analysis to probe whether the model filters environmental noise and prioritises distinctive landmarks over routine clutter. We validate various interpretability methods and present a comparative reliability analysis. Integrated gradients and Attention Weights consistently emerge as the most reliable probes of learned behaviour. A semantic class ablation further reveals an implicit weighting in which frequent objects are often down-weighted. Overall, the results indicate that the model learns noise-robust, semantically salient relations about place definition, thereby enabling explainable registration under challenging visual and structural variations.",
    "summary": "",
    "translation": "习得语义场景图定位中的自省机制",
    "relevance_score": 1,
    "reasoning": "该论文关注计算机视觉领域的场景图定位和自省机制，属于纯粹的视觉研究方向。虽然场景图在概念上涉及语义理解，但论文标题明确聚焦于视觉场景定位任务，与推荐系统、搜索或广告的核心技术需求缺乏直接关联。没有证据表明该技术有潜在的应用于RecSys/Search/Ads领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07041v1": {
    "title": "U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking",
    "url": "https://www.alphaxiv.org/abs/2510.07041v1",
    "arxiv_id": "2510.07041v1",
    "authors": "Fenghe Tang, Chengqi Dong, Wenxin Ma, Zikang Xu, Heqin Zhu, Zihang Jiang, Rongsheng Wang, Yuhao Wang, Chenxu Wu, Shaohua Kevin Zhou",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 14:06:17",
    "ori_summary": "Over the past decade, U-Net has been the dominant architecture in medical image segmentation, leading to the development of thousands of U-shaped variants. Despite its widespread adoption, there is still no comprehensive benchmark to systematically evaluate their performance and utility, largely because of insufficient statistical validation and limited consideration of efficiency and generalization across diverse datasets. To bridge this gap, we present U-Bench, the first large-scale, statistically rigorous benchmark that evaluates 100 U-Net variants across 28 datasets and 10 imaging modalities. Our contributions are threefold: (1) Comprehensive Evaluation: U-Bench evaluates models along three key dimensions: statistical robustness, zero-shot generalization, and computational efficiency. We introduce a novel metric, U-Score, which jointly captures the performance-efficiency trade-off, offering a deployment-oriented perspective on model progress. (2) Systematic Analysis and Model Selection Guidance: We summarize key findings from the large-scale evaluation and systematically analyze the impact of dataset characteristics and architectural paradigms on model performance. Based on these insights, we propose a model advisor agent to guide researchers in selecting the most suitable models for specific datasets and tasks. (3) Public Availability: We provide all code, models, protocols, and weights, enabling the community to reproduce our results and extend the benchmark with future methods. In summary, U-Bench not only exposes gaps in previous evaluations but also establishes a foundation for fair, reproducible, and practically relevant benchmarking in the next decade of U-Net-based segmentation models. The project can be accessed at: https://fenghetan9.github.io/ubench. Code is available at: https://github.com/FengheTan9/U-Bench.",
    "summary": "",
    "translation": "U-Bench：通过100种变体基准测试全面理解U-Net",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉领域的U-Net架构基准测试，属于纯粹的视觉研究范畴。U-Net主要用于图像分割任务，与推荐系统、搜索或广告的核心技术领域没有直接关联，也不涉及LLM、Transformer或异构数据建模等关键技术方向。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07018v1": {
    "title": "Sharpness-Aware Data Generation for Zero-shot Quantization",
    "url": "https://www.alphaxiv.org/abs/2510.07018v1",
    "arxiv_id": "2510.07018v1",
    "authors": "Dung Hoang-Anh, Cuong Pham Trung Le, Jianfei Cai, Thanh-Toan Do",
    "categories": "cs.LG, cs.CV",
    "pub_date": "2025-10-08 13:43:39",
    "ori_summary": "Zero-shot quantization aims to learn a quantized model from a pre-trained full-precision model with no access to original real training data. The common idea in zero-shot quantization approaches is to generate synthetic data for quantizing the full-precision model. While it is well-known that deep neural networks with low sharpness have better generalization ability, none of the previous zero-shot quantization works considers the sharpness of the quantized model as a criterion for generating training data. This paper introduces a novel methodology that takes into account quantized model sharpness in synthetic data generation to enhance generalization. Specifically, we first demonstrate that sharpness minimization can be attained by maximizing gradient matching between the reconstruction loss gradients computed on synthetic and real validation data, under certain assumptions. We then circumvent the problem of the gradient matching without real validation set by approximating it with the gradient matching between each generated sample and its neighbors. Experimental evaluations on CIFAR-100 and ImageNet datasets demonstrate the superiority of the proposed method over the state-of-the-art techniques in low-bit quantization settings.",
    "summary": "",
    "translation": "面向零样本量化的锐度感知数据生成",
    "relevance_score": 2,
    "reasoning": "该论文主要关注模型量化技术，虽然量化在推荐系统和搜索中有部署效率的应用潜力，但论文标题明确聚焦于零样本场景下的数据生成方法，这更偏向于通用模型压缩而非特定于推荐/搜索/广告领域的核心进展。量化技术本身属于边缘相关的基础设施优化，但缺乏明确的领域应用连接。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.07008v1": {
    "title": "Bayesian Modelling of Multi-Year Crop Type Classification Using Deep Neural Networks and Hidden Markov Models",
    "url": "https://www.alphaxiv.org/abs/2510.07008v1",
    "arxiv_id": "2510.07008v1",
    "authors": "Gianmarco Perantoni, Giulio Weikmann, Lorenzo Bruzzone",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 13:33:32",
    "ori_summary": "The temporal consistency of yearly land-cover maps is of great importance to model the evolution and change of the land cover over the years. In this paper, we focus the attention on a novel approach to classification of yearly satellite image time series (SITS) that combines deep learning with Bayesian modelling, using Hidden Markov Models (HMMs) integrated with Transformer Encoder (TE) based DNNs. The proposed approach aims to capture both i) intricate temporal correlations in yearly SITS and ii) specific patterns in multiyear crop type sequences. It leverages the cascade classification of an HMM layer built on top of the TE, discerning consistent yearly crop-type sequences. Validation on a multiyear crop type classification dataset spanning 47 crop types and six years of Sentinel-2 acquisitions demonstrates the importance of modelling temporal consistency in the predicted labels. HMMs enhance the overall performance and F1 scores, emphasising the effectiveness of the proposed approach.",
    "summary": "",
    "translation": "基于深度神经网络和隐马尔可夫模型的多年作物类型分类贝叶斯建模",
    "relevance_score": 1,
    "reasoning": "该论文聚焦于农业领域的作物分类问题，使用深度神经网络和隐马尔可夫模型进行时序建模。这属于特定领域应用（农业遥感），与推荐系统、搜索或广告的核心技术进展没有直接关联，也不涉及LLM、Transformer架构或异构数据统一建模等当前关注的技术方向。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06988v1": {
    "title": "No MoCap Needed: Post-Training Motion Diffusion Models with Reinforcement Learning using Only Textual Prompts",
    "url": "https://www.alphaxiv.org/abs/2510.06988v1",
    "arxiv_id": "2510.06988v1",
    "authors": "Girolamo Macaluso, Lorenzo Mandelli, Mirko Bicchierai, Stefano Berretti, Andrew D. Bagdanov",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 13:12:10",
    "ori_summary": "Diffusion models have recently advanced human motion generation, producing realistic and diverse animations from textual prompts. However, adapting these models to unseen actions or styles typically requires additional motion capture data and full retraining, which is costly and difficult to scale. We propose a post-training framework based on Reinforcement Learning that fine-tunes pretrained motion diffusion models using only textual prompts, without requiring any motion ground truth. Our approach employs a pretrained text-motion retrieval network as a reward signal and optimizes the diffusion policy with Denoising Diffusion Policy Optimization, effectively shifting the model's generative distribution toward the target domain without relying on paired motion data. We evaluate our method on cross-dataset adaptation and leave-one-out motion experiments using the HumanML3D and KIT-ML datasets across both latent- and joint-space diffusion architectures. Results from quantitative metrics and user studies show that our approach consistently improves the quality and diversity of generated motions, while preserving performance on the original distribution. Our approach is a flexible, data-efficient, and privacy-preserving solution for motion adaptation.",
    "summary": "",
    "translation": "无需动作捕捉：仅使用文本提示通过强化学习对后训练运动扩散模型进行优化",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉领域的运动生成和扩散模型，与推荐系统、搜索或广告的核心技术领域无关。虽然提到了强化学习，但应用于运动生成而非推荐/搜索/广告场景，且不涉及Transformer架构或LLM技术在这些领域的应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06982v1": {
    "title": "Revisiting Mixout: An Overlooked Path to Robust Finetuning",
    "url": "https://www.alphaxiv.org/abs/2510.06982v1",
    "arxiv_id": "2510.06982v1",
    "authors": "Masih Aminbeidokhti, Heitor Rapela Medeiros, Eric Granger, Marco Pedersoli",
    "categories": "cs.LG, cs.CV",
    "pub_date": "2025-10-08 13:07:50",
    "ori_summary": "Finetuning vision foundation models often improves in-domain accuracy but comes at the cost of robustness under distribution shift. We revisit Mixout, a stochastic regularizer that intermittently replaces finetuned weights with their pretrained reference, through the lens of a single-run, weight-sharing implicit ensemble. This perspective reveals three key levers that govern robustness: the \\emph{masking anchor}, \\emph{resampling frequency}, and \\emph{mask sparsity}. Guided by this analysis, we introduce GMixout, which (i) replaces the fixed anchor with an exponential moving-average snapshot that adapts during training, and (ii) regulates masking period via an explicit resampling-frequency hyperparameter. Our sparse-kernel implementation updates only a small fraction of parameters with no inference-time overhead, enabling training on consumer-grade GPUs. Experiments on benchmarks covering covariate shift, corruption, and class imbalance, ImageNet / ImageNet-LT, DomainNet, iWildCam, and CIFAR100-C, GMixout consistently improves in-domain accuracy beyond zero-shot performance while surpassing both Model Soups and strong parameter-efficient finetuning baselines under distribution shift.",
    "summary": "",
    "translation": "重新审视Mixout：一条被忽视的通往鲁棒微调的路径",
    "relevance_score": 8,
    "reasoning": "Mixout是一种正则化技术，通过随机混合预训练和微调参数来防止过拟合，这对于在推荐系统、搜索和广告中微调LLM至关重要。该方法通过提高模型泛化能力，可以显著提升在用户行为序列、上下文特征等异构数据上的性能，类似于VLM中处理多模态数据的方式。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06973v1": {
    "title": "Addressing the ID-Matching Challenge in Long Video Captioning",
    "url": "https://www.alphaxiv.org/abs/2510.06973v1",
    "arxiv_id": "2510.06973v1",
    "authors": "Zhantao Yang, Huangji Wang, Ruili Feng, Han Zhang, Yuting Hu, Shangwen Zhu, Junyan Li, Yu Liu, Fan Cheng",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 12:59:21",
    "ori_summary": "Generating captions for long and complex videos is both critical and challenging, with significant implications for the growing fields of text-to-video generation and multi-modal understanding. One key challenge in long video captioning is accurately recognizing the same individuals who appear in different frames, which we refer to as the ID-Matching problem. Few prior works have focused on this important issue. Those that have, usually suffer from limited generalization and depend on point-wise matching, which limits their overall effectiveness. In this paper, unlike previous approaches, we build upon LVLMs to leverage their powerful priors. We aim to unlock the inherent ID-Matching capabilities within LVLMs themselves to enhance the ID-Matching performance of captions. Specifically, we first introduce a new benchmark for assessing the ID-Matching capabilities of video captions. Using this benchmark, we investigate LVLMs containing GPT-4o, revealing key insights that the performance of ID-Matching can be improved through two methods: 1) enhancing the usage of image information and 2) increasing the quantity of information of individual descriptions. Based on these insights, we propose a novel video captioning method called Recognizing Identities for Captioning Effectively (RICE). Extensive experiments including assessments of caption quality and ID-Matching performance, demonstrate the superiority of our approach. Notably, when implemented on GPT-4o, our RICE improves the precision of ID-Matching from 50% to 90% and improves the recall of ID-Matching from 15% to 80% compared to baseline. RICE makes it possible to continuously track different individuals in the captions of long videos.",
    "summary": "",
    "translation": "解决长视频字幕生成中的ID匹配挑战",
    "relevance_score": 2,
    "reasoning": "该论文主要关注视频字幕生成中的技术挑战，属于计算机视觉和自然语言处理的交叉领域。虽然视频内容理解在推荐系统中可能有潜在应用，但论文焦点是字幕生成而非推荐、搜索或广告的核心问题，与当前关注点的直接关联性较弱。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06969v1": {
    "title": "Learning Global Representation from Queries for Vectorized HD Map Construction",
    "url": "https://www.alphaxiv.org/abs/2510.06969v1",
    "arxiv_id": "2510.06969v1",
    "authors": "Shoumeng Qiu, Xinrun Li, Yang Long, Xiangyang Xue, Varun Ojha, Jian Pu",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 12:56:08",
    "ori_summary": "The online construction of vectorized high-definition (HD) maps is a cornerstone of modern autonomous driving systems. State-of-the-art approaches, particularly those based on the DETR framework, formulate this as an instance detection problem. However, their reliance on independent, learnable object queries results in a predominantly local query perspective, neglecting the inherent global representation within HD maps. In this work, we propose \\textbf{MapGR} (\\textbf{G}lobal \\textbf{R}epresentation learning for HD \\textbf{Map} construction), an architecture designed to learn and utilize a global representations from queries. Our method introduces two synergistic modules: a Global Representation Learning (GRL) module, which encourages the distribution of all queries to better align with the global map through a carefully designed holistic segmentation task, and a Global Representation Guidance (GRG) module, which endows each individual query with explicit, global-level contextual information to facilitate its optimization. Evaluations on the nuScenes and Argoverse2 datasets validate the efficacy of our approach, demonstrating substantial improvements in mean Average Precision (mAP) compared to leading baselines.",
    "summary": "",
    "translation": "基于查询学习全局表示用于矢量化高精地图构建",
    "relevance_score": 2,
    "reasoning": "该论文专注于高精地图构建的计算机视觉任务，虽然涉及查询学习和全局表示学习技术，但其应用领域与推荐系统、搜索或广告无关。论文的技术方法（如查询学习）在理论上可能对序列建模有启发，但缺乏明确的RecSys/Search/Ads应用连接。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06967v1": {
    "title": "Generating Surface for Text-to-3D using 2D Gaussian Splatting",
    "url": "https://www.alphaxiv.org/abs/2510.06967v1",
    "arxiv_id": "2510.06967v1",
    "authors": "Huanning Dong, Fan Li, Ping Kuang, Jianwen Min",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 12:54:57",
    "ori_summary": "Recent advancements in Text-to-3D modeling have shown significant potential for the creation of 3D content. However, due to the complex geometric shapes of objects in the natural world, generating 3D content remains a challenging task. Current methods either leverage 2D diffusion priors to recover 3D geometry, or train the model directly based on specific 3D representations. In this paper, we propose a novel method named DirectGaussian, which focuses on generating the surfaces of 3D objects represented by surfels. In DirectGaussian, we utilize conditional text generation models and the surface of a 3D object is rendered by 2D Gaussian splatting with multi-view normal and texture priors. For multi-view geometric consistency problems, DirectGaussian incorporates curvature constraints on the generated surface during optimization process. Through extensive experiments, we demonstrate that our framework is capable of achieving diverse and high-fidelity 3D content creation.",
    "summary": "",
    "translation": "使用2D高斯泼溅生成文本到3D的表面",
    "relevance_score": 1,
    "reasoning": "该论文专注于文本到3D生成和3D表面重建，属于计算机图形学和3D视觉领域。虽然涉及生成技术，但主要关注3D几何生成而非推荐系统、搜索或广告应用。该工作与异构数据建模、Transformer架构或LLM在推荐/搜索中的直接应用没有明显关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06955v1": {
    "title": "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization",
    "url": "https://www.alphaxiv.org/abs/2510.06955v1",
    "arxiv_id": "2510.06955v1",
    "authors": "Masih Aminbeidokhti, Heitor Rapela Medeiros, Eric Granger, Marco Pedersoli",
    "categories": "cs.LG, cs.CV",
    "pub_date": "2025-10-08 12:37:56",
    "ori_summary": "Ensembling fine-tuned models initialized from powerful pre-trained weights is a common strategy to improve robustness under distribution shifts, but it comes with substantial computational costs due to the need to train and store multiple models. Dropout offers a lightweight alternative by simulating ensembles through random neuron deactivation; however, when applied to pre-trained models, it tends to over-regularize and disrupt critical representations necessary for generalization. In this work, we investigate Mixout, a stochastic regularization technique that provides an alternative to Dropout for domain generalization. Rather than deactivating neurons, Mixout mitigates overfitting by probabilistically swapping a subset of fine-tuned weights with their pre-trained counterparts during training, thereby maintaining a balance between adaptation and retention of prior knowledge. Our study reveals that achieving strong performance with Mixout on domain generalization benchmarks requires a notably high masking probability of 0.9 for ViTs and 0.8 for ResNets. While this may seem like a simple adjustment, it yields two key advantages for domain generalization: (1) higher masking rates more strongly penalize deviations from the pre-trained parameters, promoting better generalization to unseen domains; and (2) high-rate masking substantially reduces computational overhead, cutting gradient computation by up to 45% and gradient memory usage by up to 90%. Experiments across five domain generalization benchmarks, PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet, using ResNet and ViT architectures, show that our approach, High-rate Mixout, achieves out-of-domain accuracy comparable to ensemble-based methods while significantly reducing training costs.",
    "summary": "",
    "translation": "高比率混合丢弃：重新审视混合丢弃以实现鲁棒领域泛化",
    "relevance_score": 3,
    "reasoning": "该论文主要关注领域泛化的正则化技术（Mixout），属于通用的深度学习优化方法。虽然领域泛化在推荐系统中可能有间接应用（如处理新用户/物品的冷启动问题），但论文本身并未明确针对RecSys/Search/Ads领域，且不属于核心LLM/Transformer架构进展或直接应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06952v1": {
    "title": "OBJVanish: Physically Realizable Text-to-3D Adv. Generation of LiDAR-Invisible Objects",
    "url": "https://www.alphaxiv.org/abs/2510.06952v1",
    "arxiv_id": "2510.06952v1",
    "authors": "Bing Li, Wuqi Wang, Yanan Zhang, Jingzheng Li, Haigen Min, Wei Feng, Xingyu Zhao, Jie Zhang, Qing Guo",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 12:35:35",
    "ori_summary": "LiDAR-based 3D object detectors are fundamental to autonomous driving, where failing to detect objects poses severe safety risks. Developing effective 3D adversarial attacks is essential for thoroughly testing these detection systems and exposing their vulnerabilities before real-world deployment. However, existing adversarial attacks that add optimized perturbations to 3D points have two critical limitations: they rarely cause complete object disappearance and prove difficult to implement in physical environments. We introduce the text-to-3D adversarial generation method, a novel approach enabling physically realizable attacks that can generate 3D models of objects truly invisible to LiDAR detectors and be easily realized in the real world. Specifically, we present the first empirical study that systematically investigates the factors influencing detection vulnerability by manipulating the topology, connectivity, and intensity of individual pedestrian 3D models and combining pedestrians with multiple objects within the CARLA simulation environment. Building on the insights, we propose the physically-informed text-to-3D adversarial generation (Phy3DAdvGen) that systematically optimizes text prompts by iteratively refining verbs, objects, and poses to produce LiDAR-invisible pedestrians. To ensure physical realizability, we construct a comprehensive object pool containing 13 3D models of real objects and constrain Phy3DAdvGen to generate 3D objects based on combinations of objects in this set. Extensive experiments demonstrate that our approach can generate 3D pedestrians that evade six state-of-the-art (SOTA) LiDAR 3D detectors in both CARLA simulation and physical environments, thereby highlighting vulnerabilities in safety-critical applications.",
    "summary": "",
    "translation": "OBJVanish：物理可实现的文本到3D对抗生成激光雷达不可见物体",
    "relevance_score": 1,
    "reasoning": "该论文专注于文本到3D生成和激光雷达不可见物体的对抗生成，属于计算机视觉和3D生成领域。虽然涉及生成技术，但主要关注物理世界中的3D对象生成和传感器规避，与推荐系统、搜索或广告的核心技术需求没有直接关联，也不属于Transformer架构改进或LLM应用范畴。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06928v1": {
    "title": "IAR2: Improving Autoregressive Visual Generation with Semantic-Detail Associated Token Prediction",
    "url": "https://www.alphaxiv.org/abs/2510.06928v1",
    "arxiv_id": "2510.06928v1",
    "authors": "Ran Yi, Teng Hu, Zihan Su, Lizhuang Ma",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 12:08:21",
    "ori_summary": "Autoregressive models have emerged as a powerful paradigm for visual content creation, but often overlook the intrinsic structural properties of visual data. Our prior work, IAR, initiated a direction to address this by reorganizing the visual codebook based on embedding similarity, thereby improving generation robustness. However, it is constrained by the rigidity of pre-trained codebooks and the inaccuracies of hard, uniform clustering. To overcome these limitations, we propose IAR2, an advanced autoregressive framework that enables a hierarchical semantic-detail synthesis process. At the core of IAR2 is a novel Semantic-Detail Associated Dual Codebook, which decouples image representations into a semantic codebook for global semantic information and a detail codebook for fine-grained refinements. It expands the quantization capacity from a linear to a polynomial scale, significantly enhancing expressiveness. To accommodate this dual representation, we propose a Semantic-Detail Autoregressive Prediction scheme coupled with a Local-Context Enhanced Autoregressive Head, which performs hierarchical prediction-first the semantic token, then the detail token-while leveraging a local context window to enhance spatial coherence. Furthermore, for conditional generation, we introduce a Progressive Attention-Guided Adaptive CFG mechanism that dynamically modulates the guidance scale for each token based on its relevance to the condition and its temporal position in the generation sequence, improving conditional alignment without sacrificing realism. Extensive experiments demonstrate that IAR2 sets a new state-of-the-art for autoregressive image generation, achieving a FID of 1.50 on ImageNet. Our model not only surpasses previous methods in performance but also demonstrates superior computational efficiency, highlighting the effectiveness of our structured, coarse-to-fine generation strategy.",
    "summary": "",
    "translation": "IAR2：通过语义-细节关联的令牌预测改进自回归视觉生成",
    "relevance_score": 1,
    "reasoning": "该论文专注于视觉生成领域的自回归模型改进，属于纯粹的视觉生成技术。虽然提到了令牌预测，但这是针对视觉内容的生成，与推荐系统、搜索或广告中的排名、检索或用户建模没有直接关联。该技术没有明显的潜在应用场景于RecSys/Search/Ads领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06926v1": {
    "title": "Label-frugal satellite image change detection with generative virtual exemplar learning",
    "url": "https://www.alphaxiv.org/abs/2510.06926v1",
    "arxiv_id": "2510.06926v1",
    "authors": "Hichem Sahbi",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 12:07:35",
    "ori_summary": "Change detection is a major task in remote sensing which consists in finding all the occurrences of changes in multi-temporal satellite or aerial images. The success of existing methods, and particularly deep learning ones, is tributary to the availability of hand-labeled training data that capture the acquisition conditions and the subjectivity of the user (oracle). In this paper, we devise a novel change detection algorithm, based on active learning. The main contribution of our work resides in a new model that measures how important is each unlabeled sample, and provides an oracle with only the most critical samples (also referred to as virtual exemplars) for further labeling. These exemplars are generated, using an invertible graph convnet, as the optimum of an adversarial loss that (i) measures representativity, diversity and ambiguity of the data, and thereby (ii) challenges (the most) the current change detection criteria, leading to a better re-estimate of these criteria in the subsequent iterations of active learning. Extensive experiments show the positive impact of our label-efficient learning model against comparative methods.",
    "summary": "",
    "translation": "基于生成式虚拟范例学习的标签节约型卫星图像变化检测",
    "relevance_score": 1,
    "reasoning": "该论文专注于卫星图像变化检测，属于纯粹的计算机视觉领域，与推荐系统、搜索或广告没有直接关联。虽然涉及生成式学习技术，但应用场景（卫星图像）和核心问题（变化检测）都超出了您关注的技术领域范围。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06907v1": {
    "title": "Angular Constraint Embedding via SpherePair Loss for Constrained Clustering",
    "url": "https://www.alphaxiv.org/abs/2510.06907v1",
    "arxiv_id": "2510.06907v1",
    "authors": "Shaojie Zhang, Ke Chen",
    "categories": "cs.LG, cs.AI, cs.CV",
    "pub_date": "2025-10-08 11:43:20",
    "ori_summary": "Constrained clustering integrates domain knowledge through pairwise constraints. However, existing deep constrained clustering (DCC) methods are either limited by anchors inherent in end-to-end modeling or struggle with learning discriminative Euclidean embedding, restricting their scalability and real-world applicability. To avoid their respective pitfalls, we propose a novel angular constraint embedding approach for DCC, termed SpherePair. Using the SpherePair loss with a geometric formulation, our method faithfully encodes pairwise constraints and leads to embeddings that are clustering-friendly in angular space, effectively separating representation learning from clustering. SpherePair preserves pairwise relations without conflict, removes the need to specify the exact number of clusters, generalizes to unseen data, enables rapid inference of the number of clusters, and is supported by rigorous theoretical guarantees. Comparative evaluations with state-of-the-art DCC methods on diverse benchmarks, along with empirical validation of theoretical insights, confirm its superior performance, scalability, and overall real-world effectiveness. Code is available at \\href{https://github.com/spherepaircc/SpherePairCC/tree/main}{our repository}.",
    "summary": "",
    "translation": "基于SpherePair损失的角约束嵌入用于约束聚类",
    "relevance_score": 2,
    "reasoning": "该论文主要关注约束聚类中的嵌入技术，虽然嵌入方法在推荐系统中用于表示学习有一定应用，但论文聚焦于角约束和聚类任务，与当前关注的LLM技术、Transformer架构进展、直接LLM应用或VLM类比等核心领域关联较弱。其潜在应用仅限于基础的表示学习，对推荐/搜索/广告领域的直接影响有限。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06887v1": {
    "title": "Lung Infection Severity Prediction Using Transformers with Conditional TransMix Augmentation and Cross-Attention",
    "url": "https://www.alphaxiv.org/abs/2510.06887v1",
    "arxiv_id": "2510.06887v1",
    "authors": "Bouthaina Slika, Fadi Dornaika, Fares Bougourzi, Karim Hammoudi",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 11:08:34",
    "ori_summary": "Lung infections, particularly pneumonia, pose serious health risks that can escalate rapidly, especially during pandemics. Accurate AI-based severity prediction from medical imaging is essential to support timely clinical decisions and optimize patient outcomes. In this work, we present a novel method applicable to both CT scans and chest X-rays for assessing lung infection severity. Our contributions are twofold: (i) QCross-Att-PVT, a Transformer-based architecture that integrates parallel encoders, a cross-gated attention mechanism, and a feature aggregator to capture rich multi-scale features; and (ii) Conditional Online TransMix, a custom data augmentation strategy designed to address dataset imbalance by generating mixed-label image patches during training. Evaluated on two benchmark datasets, RALO CXR and Per-COVID-19 CT, our method consistently outperforms several state-of-the-art deep learning models. The results emphasize the critical role of data augmentation and gated attention in improving both robustness and predictive accuracy. This approach offers a reliable, adaptable tool to support clinical diagnosis, disease monitoring, and personalized treatment planning. The source code of this work is available at https://github.com/bouthainas/QCross-Att-PVT.",
    "summary": "",
    "translation": "基于条件TransMix增强与交叉注意力Transformer的肺部感染严重程度预测",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学领域的肺部感染预测应用，属于明确的医疗领域特定应用。虽然使用了Transformer架构，但其应用场景与推荐系统、搜索或广告完全无关，且没有展示任何在RecSys/Search/Ads领域的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06876v1": {
    "title": "HARP-NeXt: High-Speed and Accurate Range-Point Fusion Network for 3D LiDAR Semantic Segmentation",
    "url": "https://www.alphaxiv.org/abs/2510.06876v1",
    "arxiv_id": "2510.06876v1",
    "authors": "Samir Abou Haidar, Alexandre Chariot, Mehdi Darouich, Cyril Joly, Jean-Emmanuel Deschaud",
    "categories": "cs.CV, cs.RO",
    "pub_date": "2025-10-08 10:46:07",
    "ori_summary": "LiDAR semantic segmentation is crucial for autonomous vehicles and mobile robots, requiring high accuracy and real-time processing, especially on resource-constrained embedded systems. Previous state-of-the-art methods often face a trade-off between accuracy and speed. Point-based and sparse convolution-based methods are accurate but slow due to the complexity of neighbor searching and 3D convolutions. Projection-based methods are faster but lose critical geometric information during the 2D projection. Additionally, many recent methods rely on test-time augmentation (TTA) to improve performance, which further slows the inference. Moreover, the pre-processing phase across all methods increases execution time and is demanding on embedded platforms. Therefore, we introduce HARP-NeXt, a high-speed and accurate LiDAR semantic segmentation network. We first propose a novel pre-processing methodology that significantly reduces computational overhead. Then, we design the Conv-SE-NeXt feature extraction block to efficiently capture representations without deep layer stacking per network stage. We also employ a multi-scale range-point fusion backbone that leverages information at multiple abstraction levels to preserve essential geometric details, thereby enhancing accuracy. Experiments on the nuScenes and SemanticKITTI benchmarks show that HARP-NeXt achieves a superior speed-accuracy trade-off compared to all state-of-the-art methods, and, without relying on ensemble models or TTA, is comparable to the top-ranked PTv3, while running 24$\\times$ faster. The code is available at https://github.com/SamirAbouHaidar/HARP-NeXt",
    "summary": "",
    "translation": "HARP-NeXt：用于3D LiDAR语义分割的高速精确范围-点融合网络",
    "relevance_score": 1,
    "reasoning": "该论文专注于3D LiDAR语义分割，属于纯粹的3D视觉领域，与推荐系统、搜索或广告没有直接关联。论文内容涉及传感器数据处理和点云分析，这些技术在自动驾驶和机器人领域有应用，但在RecSys/Search/Ads领域缺乏明确的适用场景。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06871v1": {
    "title": "SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models",
    "url": "https://www.alphaxiv.org/abs/2510.06871v1",
    "arxiv_id": "2510.06871v1",
    "authors": "Huahui Yi, Kun Wang, Qiankun Li, Miao Yu, Liang Lin, Gongli Xi, Hao Wu, Xuming Hu, Kang Li, Yang Liu",
    "categories": "cs.LG, cs.CV",
    "pub_date": "2025-10-08 10:39:12",
    "ori_summary": "Multimodal Large Reasoning Models (MLRMs) demonstrate impressive cross-modal reasoning but often amplify safety risks under adversarial or unsafe prompts, a phenomenon we call the \\textit{Reasoning Tax}. Existing defenses mainly act at the output level and do not constrain the reasoning process, leaving models exposed to implicit risks. In this paper, we propose SaFeR-VLM, a safety-aligned reinforcement learning framework that embeds safety directly into multimodal reasoning. The framework integrates four components: (I) QI-Safe-10K, a curated dataset emphasizing safety-critical and reasoning-sensitive cases; (II) safety-aware rollout, where unsafe generations undergo reflection and correction instead of being discarded; (III) structured reward modeling with multi-dimensional weighted criteria and explicit penalties for hallucinations and contradictions; and (IV) GRPO optimization, which reinforces both safe and corrected trajectories. This unified design shifts safety from a passive safeguard to an active driver of reasoning, enabling scalable and generalizable safety-aware reasoning. SaFeR-VLM further demonstrates robustness against both explicit and implicit risks, supporting dynamic and interpretable safety decisions beyond surface-level filtering. SaFeR-VLM-3B achieves average performance $70.13$ and $78.97$ on safety and helpfulness across six benchmarks, surpassing both same-scale and $>10\\times$ larger models such as Skywork-R1V3-38B, Qwen2.5VL-72B, and GLM4.5V-106B. Remarkably, SaFeR-VLM-7B benefits from its increased scale to surpass GPT-5-mini and Gemini-2.5-Flash by \\num{6.47} and \\num{16.76} points respectively on safety metrics, achieving this improvement without any degradation in helpfulness performance. Our codes are available at https://github.com/HarveyYi/SaFeR-VLM.",
    "summary": "",
    "translation": "SaFeR-VLM：面向多模态模型的安全感知细粒度推理",
    "relevance_score": 2,
    "reasoning": "该论文主要关注多模态模型的安全性和推理能力，属于VLM安全评估领域。虽然涉及多模态模型，但其核心焦点是安全约束和推理验证，与推荐系统、搜索或广告中的异构数据建模、效率提升或直接应用关联较弱。安全主题属于明确的无关范畴，且论文未展示在推荐/搜索/广告场景下的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06858v1": {
    "title": "Explaining raw data complexity to improve satellite onboard processing",
    "url": "https://www.alphaxiv.org/abs/2510.06858v1",
    "arxiv_id": "2510.06858v1",
    "authors": "Adrien Dorise, Marjorie Bellizzi, Adrien Girard, Benjamin Francesconi, Stéphane May",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 10:26:02",
    "ori_summary": "With increasing processing power, deploying AI models for remote sensing directly onboard satellites is becoming feasible. However, new constraints arise, mainly when using raw, unprocessed sensor data instead of preprocessed ground-based products. While current solutions primarily rely on preprocessed sensor images, few approaches directly leverage raw data. This study investigates the effects of utilising raw data on deep learning models for object detection and classification tasks. We introduce a simulation workflow to generate raw-like products from high-resolution L1 imagery, enabling systemic evaluation. Two object detection models (YOLOv11s and YOLOX-S) are trained on both raw and L1 datasets, and their performance is compared using standard detection metrics and explainability tools. Results indicate that while both models perform similarly at low to medium confidence thresholds, the model trained on raw data struggles with object boundary identification at high confidence levels. It suggests that adapting AI architectures with improved contouring methods can enhance object detection on raw images, improving onboard AI for remote sensing.",
    "summary": "",
    "translation": "解释原始数据复杂性以改进卫星星上处理",
    "relevance_score": 1,
    "reasoning": "该论文专注于卫星数据处理和星上处理优化，属于遥感领域的特定应用。这与推荐系统、搜索或广告的核心领域进展、LLM技术、Transformer架构或异构数据统一建模均无直接关联。卫星数据处理的技术方法难以转化应用于RecSys/Search/Ads领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06855v1": {
    "title": "Online Generic Event Boundary Detection",
    "url": "https://www.alphaxiv.org/abs/2510.06855v1",
    "arxiv_id": "2510.06855v1",
    "authors": "Hyungrok Jung, Daneul Kim, Seunggyun Lim, Jeany Son, Jonghyun Choi",
    "categories": "cs.CV, eess.IV",
    "pub_date": "2025-10-08 10:23:45",
    "ori_summary": "Generic Event Boundary Detection (GEBD) aims to interpret long-form videos through the lens of human perception. However, current GEBD methods require processing complete video frames to make predictions, unlike humans processing data online and in real-time. To bridge this gap, we introduce a new task, Online Generic Event Boundary Detection (On-GEBD), aiming to detect boundaries of generic events immediately in streaming videos. This task faces unique challenges of identifying subtle, taxonomy-free event changes in real-time, without the access to future frames. To tackle these challenges, we propose a novel On-GEBD framework, Estimator, inspired by Event Segmentation Theory (EST) which explains how humans segment ongoing activity into events by leveraging the discrepancies between predicted and actual information. Our framework consists of two key components: the Consistent Event Anticipator (CEA), and the Online Boundary Discriminator (OBD). Specifically, the CEA generates a prediction of the future frame reflecting current event dynamics based solely on prior frames. Then, the OBD measures the prediction error and adaptively adjusts the threshold using statistical tests on past errors to capture diverse, subtle event transitions. Experimental results demonstrate that Estimator outperforms all baselines adapted from recent online video understanding models and achieves performance comparable to prior offline-GEBD methods on the Kinetics-GEBD and TAPOS datasets.",
    "summary": "",
    "translation": "在线通用事件边界检测",
    "relevance_score": 2,
    "reasoning": "该论文专注于通用事件边界检测，属于计算机视觉或时序分析领域，与推荐系统、搜索或广告的核心技术关联较弱。虽然事件检测在理论上可能用于理解用户行为序列，但缺乏明确的RecSys/Search/Ads应用场景，且不涉及LLM、Transformer架构或异构数据建模等关键技术。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06842v1": {
    "title": "Continual Action Quality Assessment via Adaptive Manifold-Aligned Graph Regularization",
    "url": "https://www.alphaxiv.org/abs/2510.06842v1",
    "arxiv_id": "2510.06842v1",
    "authors": "Kanglei Zhou, Qingyi Pan, Xingxing Zhang, Hubert P. H. Shum, Frederick W. B. Li, Xiaohui Liang, Liyuan Wang",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 10:09:47",
    "ori_summary": "Action Quality Assessment (AQA) quantifies human actions in videos, supporting applications in sports scoring, rehabilitation, and skill evaluation. A major challenge lies in the non-stationary nature of quality distributions in real-world scenarios, which limits the generalization ability of conventional methods. We introduce Continual AQA (CAQA), which equips AQA with Continual Learning (CL) capabilities to handle evolving distributions while mitigating catastrophic forgetting. Although parameter-efficient fine-tuning of pretrained models has shown promise in CL for image classification, we find it insufficient for CAQA. Our empirical and theoretical analyses reveal two insights: (i) Full-Parameter Fine-Tuning (FPFT) is necessary for effective representation learning; yet (ii) uncontrolled FPFT induces overfitting and feature manifold shift, thereby aggravating forgetting. To address this, we propose Adaptive Manifold-Aligned Graph Regularization (MAGR++), which couples backbone fine-tuning that stabilizes shallow layers while adapting deeper ones with a two-step feature rectification pipeline: a manifold projector to translate deviated historical features into the current representation space, and a graph regularizer to align local and global distributions. We construct four CAQA benchmarks from three datasets with tailored evaluation protocols and strong baselines, enabling systematic cross-dataset comparison. Extensive experiments show that MAGR++ achieves state-of-the-art performance, with average correlation gains of 3.6% offline and 12.2% online over the strongest baseline, confirming its robustness and effectiveness. Our code is available at https://github.com/ZhouKanglei/MAGRPP.",
    "summary": "",
    "translation": "基于自适应流形对齐图正则化的持续动作质量评估",
    "relevance_score": 2,
    "reasoning": "该论文主要关注动作质量评估，属于计算机视觉和时序分析领域，与推荐系统、搜索或广告的核心技术没有直接关联。虽然图正则化技术在某些推荐场景中可能有应用，但论文的持续学习和动作质量评估焦点使其更偏向于视频分析和行为识别领域，而非我们关注的推荐、搜索或广告技术。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06829v1": {
    "title": "Lattice-allocated Real-time Line Segment Feature Detection and Tracking Using Only an Event-based Camera",
    "url": "https://www.alphaxiv.org/abs/2510.06829v1",
    "arxiv_id": "2510.06829v1",
    "authors": "Mikihiro Ikura, Arren Glover, Masayoshi Mizuno, Chiara Bartolozzi",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 09:52:35",
    "ori_summary": "Line segment extraction is effective for capturing geometric features of human-made environments. Event-based cameras, which asynchronously respond to contrast changes along edges, enable efficient extraction by reducing redundant data. However, recent methods often rely on additional frame cameras or struggle with high event rates. This research addresses real-time line segment detection and tracking using only a modern, high-resolution (i.e., high event rate) event-based camera. Our lattice-allocated pipeline consists of (i) velocity-invariant event representation, (ii) line segment detection based on a fitting score, (iii) and line segment tracking by perturbating endpoints. Evaluation using ad-hoc recorded dataset and public datasets demonstrates real-time performance and higher accuracy compared to state-of-the-art event-only and event-frame hybrid baselines, enabling fully stand-alone event camera operation in real-world settings.",
    "summary": "",
    "translation": "仅使用事件相机的网格分配实时线段特征检测与跟踪",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉中的事件相机技术和线段特征检测，属于纯粹的视觉处理领域。虽然提到了实时跟踪，但这是针对视觉特征而非推荐系统、搜索或广告中的用户行为跟踪，与当前关注的LLM技术、推荐系统核心进展或Transformer架构改进完全无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06827v1": {
    "title": "StyleKeeper: Prevent Content Leakage using Negative Visual Query Guidance",
    "url": "https://www.alphaxiv.org/abs/2510.06827v1",
    "arxiv_id": "2510.06827v1",
    "authors": "Jaeseok Jeong, Junho Kim, Gayoung Lee, Yunjey Choi, Youngjung Uh",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 09:50:34",
    "ori_summary": "In the domain of text-to-image generation, diffusion models have emerged as powerful tools. Recently, studies on visual prompting, where images are used as prompts, have enabled more precise control over style and content. However, existing methods often suffer from content leakage, where undesired elements of the visual style prompt are transferred along with the intended style. To address this issue, we 1) extend classifier-free guidance (CFG) to utilize swapping self-attention and propose 2) negative visual query guidance (NVQG) to reduce the transfer of unwanted contents. NVQG employs negative score by intentionally simulating content leakage scenarios that swap queries instead of key and values of self-attention layers from visual style prompts. This simple yet effective method significantly reduces content leakage. Furthermore, we provide careful solutions for using a real image as visual style prompts. Through extensive evaluation across various styles and text prompts, our method demonstrates superiority over existing approaches, reflecting the style of the references, and ensuring that resulting images match the text prompts. Our code is available \\href{https://github.com/naver-ai/StyleKeeper}{here}.",
    "summary": "",
    "translation": "StyleKeeper：使用负向视觉查询引导防止内容泄露",
    "relevance_score": 2,
    "reasoning": "该论文主要关注内容保护和防止泄露，这属于安全领域而非推荐系统、搜索或广告的核心技术。虽然标题提到视觉查询，但焦点是防止内容泄漏，这与我的关注点中的核心领域进展、LLM技术或Transformer架构无关。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06820v1": {
    "title": "Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking",
    "url": "https://www.alphaxiv.org/abs/2510.06820v1",
    "arxiv_id": "2510.06820v1",
    "authors": "Mitchell Keren Taraday, Shahaf Wagner, Chaim Baskin",
    "categories": "cs.CV, cs.LG",
    "pub_date": "2025-10-08 09:46:09",
    "ori_summary": "Multimodal retrieval still leans on embedding-based models like CLIP for fast vector search over pre-computed image embeddings. Yet, unlike text retrieval, where joint-encoder rerankers are standard, comparable vision--language rerankers are largely absent. We find that seminal joint encoders such as BLIP are severely bottlenecked by an expensive visual feature-extraction stage, preventing practical deployment at scale. Motivated by this bottleneck, we introduce EDJE, an Efficient Discriminative Joint Encoder that precomputes vision tokens offline and compresses them via a lightweight attention-based adapter, so online inference runs only a compact joint encoder over a small set of visual tokens plus the text. EDJE preserves strong retrieval performance while drastically reducing storage and online compute, enabling high-throughput inference. Specifically, EDJE processes 50k image--text pairs/second while requiring 49kB of disk storage per image, matching prior art on Flickr (zero-shot) and COCO (fine-tuned) retrieval. The implementation and checkpoints will be made publicly available shortly.",
    "summary": "",
    "translation": "面向大规模视觉语言重排序的高效判别式联合编码器",
    "relevance_score": 7,
    "reasoning": "该论文涉及视觉语言联合编码技术，属于VLM类比异质数据处理的范畴，可应用于搜索中的多模态重排序场景。虽然核心是视觉语言模型，但其联合编码架构和重排序方法可直接迁移到处理用户行为序列与上下文特征的异质数据融合问题。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06809v1": {
    "title": "VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance",
    "url": "https://www.alphaxiv.org/abs/2510.06809v1",
    "arxiv_id": "2510.06809v1",
    "authors": "Teng Wang, Haojun Jiang, Yuxuan Wang, Zhenguo Sun, Shiji Song, Gao Huang",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 09:38:30",
    "ori_summary": "Echocardiography is a critical tool for detecting heart diseases. Recently, ultrasound foundation models have demonstrated remarkable capabilities in cardiac ultrasound image analysis. However, obtaining high-quality ultrasound images is a prerequisite for accurate diagnosis. Due to the exceptionally high operational difficulty of cardiac ultrasound, there is a shortage of highly skilled personnel, which hinders patients from receiving timely examination services. In this paper, we aim to adapt the medical knowledge learned by foundation models from vast datasets to the probe guidance task, which is designed to provide real-time operational recommendations for junior sonographers to acquire high-quality ultrasound images. Moreover, inspired by the practice where experts optimize action decisions based on past explorations, we meticulously design a parameter-efficient Vision-Action Adapter (VA-Adapter) to enable foundation model's image encoder to encode vision-action sequences, thereby enhancing guidance performance. With built-in sequential reasoning capabilities in a compact design, the VA-Adapter enables a pre-trained ultrasound foundation model to learn precise probe adjustment strategies by fine-tuning only a small subset of parameters. Extensive experiments demonstrate that the VA-Adapter can surpass strong probe guidance models. Our code will be released after acceptance.",
    "summary": "",
    "translation": "VA-Adapter：将超声基础模型适配到超声心动图探头引导任务",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学超声成像领域的特定应用——超声心动图探头引导，属于医疗影像的范畴。这与搜索、推荐、广告系统以及相关的LLM/Transformer技术完全无关，也不涉及任何异构数据处理或多模态建模在商业系统中的应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06802v1": {
    "title": "Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity",
    "url": "https://www.alphaxiv.org/abs/2510.06802v1",
    "arxiv_id": "2510.06802v1",
    "authors": "Islomjon Shukhratov, Sergey Gorinsky",
    "categories": "cs.GR, cs.CV",
    "pub_date": "2025-10-08 09:31:29",
    "ori_summary": "Capturing and rendering three-dimensional (3D) objects in real time remain a significant challenge, yet hold substantial potential for applications in augmented reality, digital twin systems, remote collaboration and prototyping. We present an end-to-end pipeline that leverages 3D Gaussian Splatting (3D GS) to enable rapid acquisition and interactive rendering of real-world objects using a mobile device, cloud processing and a local computer. Users scan an object with a smartphone video, upload it for automated 3D reconstruction, and visualize it interactively in Unity at an average of 150 frames per second (fps) on a laptop. The system integrates mobile capture, cloud-based 3D GS and Unity rendering to support real-time telepresence. Our experiments show that the pipeline processes scans in approximately 10 minutes on a graphics processing unit (GPU) achieving real-time rendering on the laptop.",
    "summary": "",
    "translation": "捕捉与交互：基于高斯泼溅技术在Unity中实现快速3D物体采集与渲染",
    "relevance_score": 1,
    "reasoning": "该论文专注于3D计算机视觉中的物体采集和渲染技术，使用高斯泼溅方法在Unity引擎中实现。这与推荐系统、搜索或广告的核心领域完全无关，也不涉及任何可能应用于这些领域的LLM或Transformer技术。该研究纯粹属于3D视觉和图形学范畴，没有任何明显的推荐/搜索/广告应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06791v1": {
    "title": "Extreme Amodal Face Detection",
    "url": "https://www.alphaxiv.org/abs/2510.06791v1",
    "arxiv_id": "2510.06791v1",
    "authors": "Changlin Song, Yunzhong Hou, Michael Randall Barnes, Rahul Shome, Dylan Campbell",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 09:22:03",
    "ori_summary": "Extreme amodal detection is the task of inferring the 2D location of objects that are not fully visible in the input image but are visible within an expanded field-of-view. This differs from amodal detection, where the object is partially visible within the input image, but is occluded. In this paper, we consider the sub-problem of face detection, since this class provides motivating applications involving safety and privacy, but do not tailor our method specifically to this class. Existing approaches rely on image sequences so that missing detections may be interpolated from surrounding frames or make use of generative models to sample possible completions. In contrast, we consider the single-image task and propose a more efficient, sample-free approach that makes use of the contextual cues from the image to infer the presence of unseen faces. We design a heatmap-based extreme amodal object detector that addresses the problem of efficiently predicting a lot (the out-of-frame region) from a little (the image) with a selective coarse-to-fine decoder. Our method establishes strong results for this new task, even outperforming less efficient generative approaches.",
    "summary": "",
    "translation": "极端非模态人脸检测",
    "relevance_score": 2,
    "reasoning": "该论文专注于计算机视觉中的人脸检测任务，属于纯粹的视觉技术范畴，与推荐系统、搜索或广告的核心领域进展没有直接关联。虽然人脸检测在特定广告场景中可能有应用，但论文标题未表明任何与LLM技术、Transformer架构或异构数据统一建模相关的潜在应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06784v1": {
    "title": "Bionetta: Efficient Client-Side Zero-Knowledge Machine Learning Proving",
    "url": "https://www.alphaxiv.org/abs/2510.06784v1",
    "arxiv_id": "2510.06784v1",
    "authors": "Dmytro Zakharov, Oleksandr Kurbatov, Artem Sdobnov, Lev Soukhanov, Yevhenii Sekhin, Vitalii Volovyk, Mykhailo Velykodnyi, Mark Cherepovskyi, Kyrylo Baibula, Lasha Antadze, Pavlo Kravchenko, Volodymyr Dubinin, Yaroslav Panasenko",
    "categories": "cs.CR, cs.CV",
    "pub_date": "2025-10-08 09:10:32",
    "ori_summary": "In this report, we compare the performance of our UltraGroth-based zero-knowledge machine learning framework Bionetta to other tools of similar purpose such as EZKL, Lagrange's deep-prove, or zkml. The results show a significant boost in the proving time for custom-crafted neural networks: they can be proven even on mobile devices, enabling numerous client-side proving applications. While our scheme increases the cost of one-time preprocessing steps, such as circuit compilation and generating trusted setup, our approach is, to the best of our knowledge, the only one that is deployable on the native EVM smart contracts without overwhelming proof size and verification overheads.",
    "summary": "",
    "translation": "Bionetta：高效的客户端零知识机器学习证明",
    "relevance_score": 1,
    "reasoning": "该论文涉及零知识证明和客户端机器学习，这属于隐私和安全领域，明确列在无关主题中。虽然提到了机器学习，但核心焦点是隐私保护技术，与推荐系统、搜索或广告的核心技术进展没有直接关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06783v1": {
    "title": "TTRV: Test-Time Reinforcement Learning for Vision Language Models",
    "url": "https://www.alphaxiv.org/abs/2510.06783v1",
    "arxiv_id": "2510.06783v1",
    "authors": "Akshit Singh, Shyam Marjit, Wei Lin, Paul Gavrikov, Serena Yeung-Levy, Hilde Kuehne, Rogerio Feris, Sivan Doveh, James Glass, M. Jehanzeb Mirza",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 09:10:31",
    "ori_summary": "Existing methods for extracting reward signals in Reinforcement Learning typically rely on labeled data and dedicated training splits, a setup that contrasts with how humans learn directly from their environment. In this work, we propose TTRV to enhance vision language understanding by adapting the model on the fly at inference time, without the need for any labeled data. Concretely, we enhance the Group Relative Policy Optimization (GRPO) framework by designing rewards based on the frequency of the base model's output, while inferring on each test sample multiple times. Further, we also propose to control the diversity of the model's output by simultaneously rewarding the model for obtaining low entropy of the output empirical distribution. Our approach delivers consistent gains across both object recognition and visual question answering (VQA), with improvements of up to 52.4% and 29.8%, respectively, and average boosts of 24.6% and 10.0% across 16 datasets.Remarkably, on image recognition, TTRV applied to InternVL 8B surpasses GPT-4o by an average of 2.3% over 8 benchmarks, while remaining highly competitive on VQA, demonstrating that test-time reinforcement learning can match or exceed the strongest proprietary models. Finally, we find many interesting properties of test-time RL for VLMs: for example, even in extremely data-constrained scenarios, where adaptation is performed on a single randomly chosen unlabeled test example, TTRV still yields non-trivial improvements of up to 5.5% in recognition tasks.",
    "summary": "",
    "translation": "TTRV：视觉语言模型的测试时强化学习",
    "relevance_score": 2,
    "reasoning": "虽然该论文涉及视觉语言模型和强化学习，但主要关注测试时强化学习在VLM中的应用，这与推荐系统、搜索或广告的直接相关性较弱。强化学习组件没有明确展示在推荐/搜索/广告排名任务中的应用潜力，视觉模态的焦点也超出了指定的异构数据建模范围。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06769v1": {
    "title": "A deep multiple instance learning approach based on coarse labels for high-resolution land-cover mapping",
    "url": "https://www.alphaxiv.org/abs/2510.06769v1",
    "arxiv_id": "2510.06769v1",
    "authors": "Gianmarco Perantoni, Lorenzo Bruzzone",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 08:50:39",
    "ori_summary": "The quantity and the quality of the training labels are central problems in high-resolution land-cover mapping with machine-learning-based solutions. In this context, weak labels can be gathered in large quantities by leveraging on existing low-resolution or obsolete products. In this paper, we address the problem of training land-cover classifiers using high-resolution imagery (e.g., Sentinel-2) and weak low-resolution reference data (e.g., MODIS -derived land-cover maps). Inspired by recent works in Deep Multiple Instance Learning (DMIL), we propose a method that trains pixel-level multi-class classifiers and predicts low-resolution labels (i.e., patch-level classification), where the actual high-resolution labels are learned implicitly without direct supervision. This is achieved with flexible pooling layers that are able to link the semantics of the pixels in the high-resolution imagery to the low-resolution reference labels. Then, the Multiple Instance Learning (MIL) problem is re-framed in a multi-class and in a multi-label setting. In the former, the low-resolution annotation represents the majority of the pixels in the patch. In the latter, the annotation only provides us information on the presence of one of the land-cover classes in the patch and thus multiple labels can be considered valid for a patch at a time, whereas the low-resolution labels provide us only one label. Therefore, the classifier is trained with a Positive-Unlabeled Learning (PUL) strategy. Experimental results on the 2020 IEEE GRSS Data Fusion Contest dataset show the effectiveness of the proposed framework compared to standard training strategies.",
    "summary": "",
    "translation": "基于粗粒度标签的高分辨率土地覆盖测绘深度多示例学习方法",
    "relevance_score": 1,
    "reasoning": "该论文专注于遥感领域的土地覆盖测绘应用，属于地理信息系统的特定领域研究。虽然涉及深度学习和多示例学习技术，但论文内容与推荐系统、搜索或广告的核心领域进展、LLM技术、Transformer架构或异构数据统一建模均无直接关联，属于明确的无关主题范畴。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06757v1": {
    "title": "Transforming Noise Distributions with Histogram Matching: Towards a Single Denoiser for All",
    "url": "https://www.alphaxiv.org/abs/2510.06757v1",
    "arxiv_id": "2510.06757v1",
    "authors": "Sheng Fu, Junchao Zhang, Kailun Yang",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 08:34:50",
    "ori_summary": "Supervised Gaussian denoisers exhibit limited generalization when confronted with out-of-distribution noise, due to the diverse distributional characteristics of different noise types. To bridge this gap, we propose a histogram matching approach that transforms arbitrary noise towards a target Gaussian distribution with known intensity. Moreover, a mutually reinforcing cycle is established between noise transformation and subsequent denoising. This cycle progressively refines the noise to be converted, making it approximate the real noise, thereby enhancing the noise transformation effect and further improving the denoising performance. We tackle specific noise complexities: local histogram matching handles signal-dependent noise, intrapatch permutation processes channel-related noise, and frequency-domain histogram matching coupled with pixel-shuffle down-sampling breaks spatial correlation. By applying these transformations, a single Gaussian denoiser gains remarkable capability to handle various out-of-distribution noises, including synthetic noises such as Poisson, salt-and-pepper and repeating pattern noises, as well as complex real-world noises. Extensive experiments demonstrate the superior generalization and effectiveness of our method.",
    "summary": "",
    "translation": "通过直方图匹配变换噪声分布：迈向适用于所有场景的单一去噪器",
    "relevance_score": 2,
    "reasoning": "该论文主要关注图像去噪中的噪声分布变换技术，属于计算机视觉领域的特定应用。虽然去噪技术在某些边缘场景下可能对推荐或搜索中的噪声数据处理有间接启发，但缺乏明确的直接应用场景和与Transformer架构、LLM技术或推荐系统核心问题的直接关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06754v1": {
    "title": "UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene",
    "url": "https://www.alphaxiv.org/abs/2510.06754v1",
    "arxiv_id": "2510.06754v1",
    "authors": "Christian Maurer, Snehal Jauhri, Sophie Lueth, Georgia Chalvatzaki",
    "categories": "cs.RO, cs.CV",
    "pub_date": "2025-10-08 08:30:26",
    "ori_summary": "Comprehensive visual, geometric, and semantic understanding of a 3D scene is crucial for successful execution of robotic tasks, especially in unstructured and complex environments. Additionally, to make robust decisions, it is necessary for the robot to evaluate the reliability of perceived information. While recent advances in 3D neural feature fields have enabled robots to leverage features from pretrained foundation models for tasks such as language-guided manipulation and navigation, existing methods suffer from two critical limitations: (i) they are typically scene-specific, and (ii) they lack the ability to model uncertainty in their predictions. We present UniFField, a unified uncertainty-aware neural feature field that combines visual, semantic, and geometric features in a single generalizable representation while also predicting uncertainty in each modality. Our approach, which can be applied zero shot to any new environment, incrementally integrates RGB-D images into our voxel-based feature representation as the robot explores the scene, simultaneously updating uncertainty estimation. We evaluate our uncertainty estimations to accurately describe the model prediction errors in scene reconstruction and semantic feature prediction. Furthermore, we successfully leverage our feature predictions and their respective uncertainty for an active object search task using a mobile manipulator robot, demonstrating the capability for robust decision-making.",
    "summary": "",
    "translation": "UniFField：一种适用于任意场景的可泛化统一神经特征场，用于处理视觉、语义和空间不确定性",
    "relevance_score": 3,
    "reasoning": "该论文主要关注计算机视觉中的神经特征场和不确定性建模，属于纯粹的视觉技术范畴。虽然标题提到'语义不确定性'，但没有明确表明与推荐系统、搜索或广告的直接关联。这种技术可能作为底层特征提取器，但缺乏明确的RecSys/Search/Ads应用场景说明。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06751v1": {
    "title": "OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot",
    "url": "https://www.alphaxiv.org/abs/2510.06751v1",
    "arxiv_id": "2510.06751v1",
    "authors": "Junhan Zhu, Hesong Wang, Mingluo Su, Zefang Wang, Huan Wang",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 08:19:15",
    "ori_summary": "Large-scale text-to-image diffusion models, while powerful, suffer from prohibitive computational cost. Existing one-shot network pruning methods can hardly be directly applied to them due to the iterative denoising nature of diffusion models. To bridge the gap, this paper presents OBS-Diff, a novel one-shot pruning framework that enables accurate and training-free compression of large-scale text-to-image diffusion models. Specifically, (i) OBS-Diff revitalizes the classic Optimal Brain Surgeon (OBS), adapting it to the complex architectures of modern diffusion models and supporting diverse pruning granularity, including unstructured, N:M semi-structured, and structured (MHA heads and FFN neurons) sparsity; (ii) To align the pruning criteria with the iterative dynamics of the diffusion process, by examining the problem from an error-accumulation perspective, we propose a novel timestep-aware Hessian construction that incorporates a logarithmic-decrease weighting scheme, assigning greater importance to earlier timesteps to mitigate potential error accumulation; (iii) Furthermore, a computationally efficient group-wise sequential pruning strategy is proposed to amortize the expensive calibration process. Extensive experiments show that OBS-Diff achieves state-of-the-art one-shot pruning for diffusion models, delivering inference acceleration with minimal degradation in visual quality.",
    "summary": "",
    "translation": "OBS-Diff：一次性精准剪枝扩散模型",
    "relevance_score": 1,
    "reasoning": "该论文专注于扩散模型的模型压缩技术，属于纯粹的生成式AI优化领域。虽然扩散模型在AIGC中有广泛应用，但论文内容仅限于模型剪枝效率提升，与推荐系统、搜索或广告的核心技术领域没有直接关联，也不涉及Transformer架构改进或异构数据建模。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06746v1": {
    "title": "DeRainMamba: A Frequency-Aware State Space Model with Detail Enhancement for Image Deraining",
    "url": "https://www.alphaxiv.org/abs/2510.06746v1",
    "arxiv_id": "2510.06746v1",
    "authors": "Zhiliang Zhu, Tao Zeng, Tao Yang, Guoliang Luo, Jiyong Zeng",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 08:05:11",
    "ori_summary": "Image deraining is crucial for improving visual quality and supporting reliable downstream vision tasks. Although Mamba-based models provide efficient sequence modeling, their limited ability to capture fine-grained details and lack of frequency-domain awareness restrict further improvements. To address these issues, we propose DeRainMamba, which integrates a Frequency-Aware State-Space Module (FASSM) and Multi-Directional Perception Convolution (MDPConv). FASSM leverages Fourier transform to distinguish rain streaks from high-frequency image details, balancing rain removal and detail preservation. MDPConv further restores local structures by capturing anisotropic gradient features and efficiently fusing multiple convolution branches. Extensive experiments on four public benchmarks demonstrate that DeRainMamba consistently outperforms state-of-the-art methods in PSNR and SSIM, while requiring fewer parameters and lower computational costs. These results validate the effectiveness of combining frequency-domain modeling and spatial detail enhancement within a state-space framework for single image deraining.",
    "summary": "",
    "translation": "DeRainMamba：一种用于图像去雨的频率感知状态空间模型与细节增强方法",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉领域的图像去雨任务，属于纯粹的图像处理应用。虽然提到了状态空间模型（Mamba），但其应用场景和核心技术创新都局限于视觉领域，与推荐系统、搜索或广告的排名和建模需求没有直接关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06694v1": {
    "title": "SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis",
    "url": "https://www.alphaxiv.org/abs/2510.06694v1",
    "arxiv_id": "2510.06694v1",
    "authors": "Jipeng Lyu, Jiahua Dong, Yu-Xiong Wang",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 06:39:33",
    "ori_summary": "Persistent dynamic scene modeling for tracking and novel-view synthesis remains challenging due to the difficulty of capturing accurate deformations while maintaining computational efficiency. We propose SCas4D, a cascaded optimization framework that leverages structural patterns in 3D Gaussian Splatting for dynamic scenes. The key idea is that real-world deformations often exhibit hierarchical patterns, where groups of Gaussians share similar transformations. By progressively refining deformations from coarse part-level to fine point-level, SCas4D achieves convergence within 100 iterations per time frame and produces results comparable to existing methods with only one-twentieth of the training iterations. The approach also demonstrates effectiveness in self-supervised articulated object segmentation, novel view synthesis, and dense point tracking tasks.",
    "summary": "",
    "translation": "SCas4D：用于提升持久4D新视角合成的结构级联优化",
    "relevance_score": 1,
    "reasoning": "该论文专注于4D新视角合成和计算机视觉中的结构优化，属于纯粹的视觉技术领域。论文内容涉及4D场景重建和视图合成，与推荐系统、搜索或广告的核心技术栈没有直接关联，也不涉及Transformer架构、LLM技术或异构数据处理等当前关注领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06687v1": {
    "title": "Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion",
    "url": "https://www.alphaxiv.org/abs/2510.06687v1",
    "arxiv_id": "2510.06687v1",
    "authors": "Jie Luo, Yuxuan Jiang, Xin Jin, Mingyu Liu, Yihui Fan",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 06:15:06",
    "ori_summary": "Semantic segmentation serves as a cornerstone of scene understanding in autonomous driving but continues to face significant challenges under complex conditions such as occlusion. Light field and LiDAR modalities provide complementary visual and spatial cues that are beneficial for robust perception; however, their effective integration is hindered by limited viewpoint diversity and inherent modality discrepancies. To address these challenges, the first multimodal semantic segmentation dataset integrating light field data and point cloud data is proposed. Based on this dataset, we proposed a multi-modal light field point-cloud fusion segmentation network(Mlpfseg), incorporating feature completion and depth perception to segment both camera images and LiDAR point clouds simultaneously. The feature completion module addresses the density mismatch between point clouds and image pixels by performing differential reconstruction of point-cloud feature maps, enhancing the fusion of these modalities. The depth perception module improves the segmentation of occluded objects by reinforcing attention scores for better occlusion awareness. Our method outperforms image-only segmentation by 1.71 Mean Intersection over Union(mIoU) and point cloud-only segmentation by 2.38 mIoU, demonstrating its effectiveness.",
    "summary": "",
    "translation": "基于光场与激光雷达融合的语义分割算法",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉领域的语义分割技术，结合光场和激光雷达两种传感器数据。虽然涉及多模态融合，但这属于纯粹的视觉感知研究，没有展示与推荐系统、搜索或广告的明确关联，也不涉及LLM或Transformer架构的进展。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06679v1": {
    "title": "DreamOmni2: Multimodal Instruction-based Editing and Generation",
    "url": "https://www.alphaxiv.org/abs/2510.06679v1",
    "arxiv_id": "2510.06679v1",
    "authors": "Bin Xia, Bohao Peng, Yuechen Zhang, Junjia Huang, Jiyang Liu, Jingyao Li, Haoru Tan, Sitong Wu, Chengyao Wang, Yitong Wang, Xinglong Wu, Bei Yu, Jiaya Jia",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 06:07:14",
    "ori_summary": "Recent advancements in instruction-based image editing and subject-driven generation have garnered significant attention, yet both tasks still face limitations in meeting practical user needs. Instruction-based editing relies solely on language instructions, which often fail to capture specific editing details, making reference images necessary. Meanwhile, subject-driven generation is limited to combining concrete objects or people, overlooking broader, abstract concepts. To address these challenges, we propose two novel tasks: multimodal instruction-based editing and generation. These tasks support both text and image instructions and extend the scope to include both concrete and abstract concepts, greatly enhancing their practical applications. We introduce DreamOmni2, tackling two primary challenges: data creation and model framework design. Our data synthesis pipeline consists of three steps: (1) using a feature mixing method to create extraction data for both abstract and concrete concepts, (2) generating multimodal instruction-based editing training data using the editing and extraction models, and (3) further applying the extraction model to create training data for multimodal instruction-based editing. For the framework, to handle multi-image input, we propose an index encoding and position encoding shift scheme, which helps the model distinguish images and avoid pixel confusion. Additionally, we introduce joint training with the VLM and our generation/editing model to better process complex instructions. In addition, we have proposed comprehensive benchmarks for these two new tasks to drive their development. Experiments show that DreamOmni2 has achieved impressive results. Models and codes will be released.",
    "summary": "",
    "translation": "DreamOmni2：基于多模态指令的编辑与生成",
    "relevance_score": 2,
    "reasoning": "该论文主要关注多模态内容的生成和编辑，属于纯粹的AIGC和内容生成领域，与推荐系统、搜索或广告的核心排名任务无关。虽然标题提到多模态，但缺乏将异构数据作为不同模态进行统一建模的具体联系，无法直接应用于RecSys/Search/Ads的核心技术挑战。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06673v1": {
    "title": "Heptapod: Language Modeling on Visual Signals",
    "url": "https://www.alphaxiv.org/abs/2510.06673v1",
    "arxiv_id": "2510.06673v1",
    "authors": "Yongxin Zhu, Jiawei Chen, Yuanzhe Chen, Zhuo Chen, Dongya Jia, Jian Cong, Xiaobin Zhuang, Yuping Wang, Yuxuan Wang",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 05:54:46",
    "ori_summary": "We introduce Heptapod, an image autoregressive model that adheres to the foundational principles of language modeling. Heptapod employs \\textbf{causal attention}, \\textbf{eliminates reliance on CFG}, and \\textbf{eschews the trend of semantic tokenizers}. Our key innovation is \\textit{next 2D distribution prediction}: a causal Transformer with reconstruction-focused visual tokenizer, learns to predict the distribution over the entire 2D spatial grid of images at each timestep. This learning objective unifies the sequential modeling of autoregressive framework with the holistic self-supervised learning of masked autoencoding, enabling the model to capture comprehensive image semantics via generative training. On the ImageNet generation benchmark, Heptapod achieves an FID of $2.70$, significantly outperforming previous causal autoregressive approaches. We hope our work inspires a principled rethinking of language modeling on visual signals and beyond.",
    "summary": "",
    "translation": "Heptapod：基于视觉信号的语言建模",
    "relevance_score": 8,
    "reasoning": "该论文涉及视觉-语言建模，与'VLM类比处理异构数据'焦点高度相关，将视觉信号作为模态进行语言建模。这种多模态方法可以类比于推荐/搜索系统中处理用户行为序列和上下文特征等异构数据，为统一建模提供技术启示。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": false,
    "is_fine_ranked": false
  },
  "2510.06669v1": {
    "title": "Automated Neural Architecture Design for Industrial Defect Detection",
    "url": "https://www.alphaxiv.org/abs/2510.06669v1",
    "arxiv_id": "2510.06669v1",
    "authors": "Yuxi Liu, Yunfeng Ma, Yi Tang, Min Liu, Shuai Jiang, Yaonan Wang",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 05:37:59",
    "ori_summary": "Industrial surface defect detection (SDD) is critical for ensuring product quality and manufacturing reliability. Due to the diverse shapes and sizes of surface defects, SDD faces two main challenges: intraclass difference and interclass similarity. Existing methods primarily utilize manually designed models, which require extensive trial and error and often struggle to address both challenges effectively. To overcome this, we propose AutoNAD, an automated neural architecture design framework for SDD that jointly searches over convolutions, transformers, and multi-layer perceptrons. This hybrid design enables the model to capture both fine-grained local variations and long-range semantic context, addressing the two key challenges while reducing the cost of manual network design. To support efficient training of such a diverse search space, AutoNAD introduces a cross weight sharing strategy, which accelerates supernet convergence and improves subnet performance. Additionally, a searchable multi-level feature aggregation module (MFAM) is integrated to enhance multi-scale feature learning. Beyond detection accuracy, runtime efficiency is essential for industrial deployment. To this end, AutoNAD incorporates a latency-aware prior to guide the selection of efficient architectures. The effectiveness of AutoNAD is validated on three industrial defect datasets and further applied within a defect imaging and detection platform. Code will be available at https://github.com/Yuxi104/AutoNAD.",
    "summary": "",
    "translation": "面向工业缺陷检测的自动化神经网络架构设计",
    "relevance_score": 1,
    "reasoning": "该论文专注于工业缺陷检测这一计算机视觉应用领域，与推荐系统、搜索或广告的核心技术无关。虽然涉及自动化架构设计，但属于特定领域应用而非通用的Transformer架构效率或LLM技术进展，无法应用于RecSys/Search/Ads领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06646v1": {
    "title": "The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators",
    "url": "https://www.alphaxiv.org/abs/2510.06646v1",
    "arxiv_id": "2510.06646v1",
    "authors": "Mansi Sakarvadia, Kareem Hegazy, Amin Totounferoush, Kyle Chard, Yaoqing Yang, Ian Foster, Michael W. Mahoney",
    "categories": "cs.LG, cs.AI, cs.CV",
    "pub_date": "2025-10-08 04:59:56",
    "ori_summary": "A core challenge in scientific machine learning, and scientific computing more generally, is modeling continuous phenomena which (in practice) are represented discretely. Machine-learned operators (MLOs) have been introduced as a means to achieve this modeling goal, as this class of architecture can perform inference at arbitrary resolution. In this work, we evaluate whether this architectural innovation is sufficient to perform \"zero-shot super-resolution,\" namely to enable a model to serve inference on higher-resolution data than that on which it was originally trained. We comprehensively evaluate both zero-shot sub-resolution and super-resolution (i.e., multi-resolution) inference in MLOs. We decouple multi-resolution inference into two key behaviors: 1) extrapolation to varying frequency information; and 2) interpolating across varying resolutions. We empirically demonstrate that MLOs fail to do both of these tasks in a zero-shot manner. Consequently, we find MLOs are not able to perform accurate inference at resolutions different from those on which they were trained, and instead they are brittle and susceptible to aliasing. To address these failure modes, we propose a simple, computationally-efficient, and data-driven multi-resolution training protocol that overcomes aliasing and that provides robust multi-resolution generalization.",
    "summary": "",
    "translation": "机器学习算子中零样本超分辨率的虚假承诺",
    "relevance_score": 2,
    "reasoning": "该论文主要讨论机器学习算子中的零样本超分辨率问题，这属于计算机视觉领域的图像处理技术。虽然超分辨率在理论上可能用于广告创意生成或内容增强，但这属于被排除的无关主题范畴，且没有明确指向推荐系统、搜索或广告排名的直接应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06638v1": {
    "title": "StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering",
    "url": "https://www.alphaxiv.org/abs/2510.06638v1",
    "arxiv_id": "2510.06638v1",
    "authors": "Zhihao Wen, Wenkang Wei, Yuan Fang, Xingtong Yu, Hui Zhang, Weicheng Zhu, Xin Zhang",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 04:37:53",
    "ori_summary": "Knowledge-based Visual Question Answering (KVQA) requires models to ground entities in images and reason over factual knowledge. We study its implicit-knowledge variant, IK-KVQA, where a multimodal large language model (MLLM) is the sole knowledge source, without external retrieval. Yet, MLLMs lack explicit reasoning supervision and produce inconsistent justifications, and generalize poorly after standard supervised fine-tuning (SFT). We present StaR-KVQA (Structured Reasoning Traces for IK-KVQA), which supervises structured traces - dual symbolic relation paths plus path-grounded natural-language explanations - so that reasoning becomes transparent and verifiable. With one open-source MLLM, StaR-KVQA constructs and selects path-grounded reasoning traces to form a trace-enriched dataset, then fine-tunes via structured self-distillation to align generation with supervision; no external retrievers, verifiers, or curated knowledge bases (KBs) are used, traces are built offline, and inference is a single autoregressive pass. Across benchmarks, StaR-KVQA improves both accuracy and interpretability, achieving up to +11.3% higher answer accuracy on OK-VQA over the strongest baseline while exhibiting robust cross-domain generalization.",
    "summary": "",
    "translation": "StaR-KVQA：面向隐式知识视觉问答的结构化推理轨迹",
    "relevance_score": 2,
    "reasoning": "该论文专注于视觉问答任务，属于纯视觉或多模态领域，与推荐系统、搜索或广告的核心技术无关。虽然标题提到结构化推理轨迹，但应用场景局限于视觉问答，没有显示出在推荐、搜索或广告领域的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06637v1": {
    "title": "Control-Augmented Autoregressive Diffusion for Data Assimilation",
    "url": "https://www.alphaxiv.org/abs/2510.06637v1",
    "arxiv_id": "2510.06637v1",
    "authors": "Prakhar Srivastava, Farrin Marouf Sofian, Francesco Immorlano, Kushagra Pandey, Stephan Mandt",
    "categories": "cs.LG, cs.AI, cs.CV",
    "pub_date": "2025-10-08 04:37:32",
    "ori_summary": "Despite recent advances in test-time scaling and finetuning of diffusion models, guidance in Auto-Regressive Diffusion Models (ARDMs) remains underexplored. We introduce an amortized framework that augments pretrained ARDMs with a lightweight controller network, trained offline by previewing future ARDM rollouts and learning stepwise controls that anticipate upcoming observations under a terminal cost objective. We evaluate this framework in the context of data assimilation (DA) for chaotic spatiotemporal partial differential equations (PDEs), a setting where existing methods are often computationally prohibitive and prone to forecast drift under sparse observations. Our approach reduces DA inference to a single forward rollout with on-the-fly corrections, avoiding expensive adjoint computations and/or optimizations during inference. We demonstrate that our method consistently outperforms four state-of-the-art baselines in stability, accuracy, and physical fidelity across two canonical PDEs and six observation regimes. We will release code and checkpoints publicly.",
    "summary": "",
    "translation": "用于数据同化的控制增强自回归扩散模型",
    "relevance_score": 3,
    "reasoning": "该论文涉及扩散模型和数据同化技术，属于生成模型领域。虽然扩散模型在推荐系统中可用于生成用户交互序列或增强数据，但论文标题未明确表明与推荐、搜索或广告系统的直接关联。数据同化主要应用于物理科学领域，其技术迁移到推荐系统的路径不够清晰。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06635v1": {
    "title": "StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance",
    "url": "https://www.alphaxiv.org/abs/2510.06635v1",
    "arxiv_id": "2510.06635v1",
    "authors": "Yunpeng Gong, Sihan Lan, Can Yang, Kunpeng Xu, Min Jiang",
    "categories": "cs.LG, cs.CV",
    "pub_date": "2025-10-08 04:37:04",
    "ori_summary": "Symbolic regression aims to find interpretable analytical expressions by searching over mathematical formula spaces to capture underlying system behavior, particularly in scientific modeling governed by physical laws. However, traditional methods lack mechanisms for extracting structured physical priors from time series observations, making it difficult to capture symbolic expressions that reflect the system's global behavior. In this work, we propose a structure-aware symbolic regression framework, called StruSR, that leverages trained Physics-Informed Neural Networks (PINNs) to extract locally structured physical priors from time series data. By performing local Taylor expansions on the outputs of the trained PINN, we obtain derivative-based structural information to guide symbolic expression evolution. To assess the importance of expression components, we introduce a masking-based attribution mechanism that quantifies each subtree's contribution to structural alignment and physical residual reduction. These sensitivity scores steer mutation and crossover operations within genetic programming, preserving substructures with high physical or structural significance while selectively modifying less informative components. A hybrid fitness function jointly minimizes physics residuals and Taylor coefficient mismatch, ensuring consistency with both the governing equations and the local analytical behavior encoded by the PINN. Experiments on benchmark PDE systems demonstrate that StruSR improves convergence speed, structural fidelity, and expression interpretability compared to conventional baselines, offering a principled paradigm for physics-grounded symbolic discovery.",
    "summary": "",
    "translation": "StruSR：具有物理信息泰勒引导的结构感知符号回归",
    "relevance_score": 1,
    "reasoning": "该论文专注于符号回归和物理信息引导，属于数学建模和科学计算领域。这与推荐系统、搜索或广告的核心技术栈没有直接关联，也不涉及Transformer架构、LLM技术或异构数据建模等当前关注领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06629v1": {
    "title": "Unsupervised Backdoor Detection and Mitigation for Spiking Neural Networks",
    "url": "https://www.alphaxiv.org/abs/2510.06629v1",
    "arxiv_id": "2510.06629v1",
    "authors": "Jiachen Li, Bang Wu, Xiaoyu Xia, Xiaoning Liu, Xun Yi, Xiuzhen Zhang",
    "categories": "cs.CR, cs.CV, cs.LG",
    "pub_date": "2025-10-08 04:25:35",
    "ori_summary": "Spiking Neural Networks (SNNs) have gained increasing attention for their superior energy efficiency compared to Artificial Neural Networks (ANNs). However, their security aspects, particularly under backdoor attacks, have received limited attention. Existing defense methods developed for ANNs perform poorly or can be easily bypassed in SNNs due to their event-driven and temporal dependencies. This paper identifies the key blockers that hinder traditional backdoor defenses in SNNs and proposes an unsupervised post-training detection framework, Temporal Membrane Potential Backdoor Detection (TMPBD), to overcome these challenges. TMPBD leverages the maximum margin statistics of temporal membrane potential (TMP) in the final spiking layer to detect target labels without any attack knowledge or data access. We further introduce a robust mitigation mechanism, Neural Dendrites Suppression Backdoor Mitigation (NDSBM), which clamps dendritic connections between early convolutional layers to suppress malicious neurons while preserving benign behaviors, guided by TMP extracted from a small, clean, unlabeled dataset. Extensive experiments on multiple neuromorphic benchmarks and state-of-the-art input-aware dynamic trigger attacks demonstrate that TMPBD achieves 100% detection accuracy, while NDSBM reduces the attack success rate from 100% to 8.44%, and to 2.81% when combined with detection, without degrading clean accuracy.",
    "summary": "",
    "translation": "脉冲神经网络的非监督后门检测与缓解",
    "relevance_score": 1,
    "reasoning": "该论文专注于脉冲神经网络（SNN）的安全性和后门攻击检测，属于网络安全和模型安全领域。这与我的核心关注点（推荐系统、搜索、广告中的LLM技术、Transformer架构和异构数据建模）完全无关，且安全主题被明确列为不相关话题。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06621v1": {
    "title": "FEAorta: A Fully Automated Framework for Finite Element Analysis of the Aorta From 3D CT Images",
    "url": "https://www.alphaxiv.org/abs/2510.06621v1",
    "arxiv_id": "2510.06621v1",
    "authors": "Jiasong Chen, Linchen Qian, Ruonan Gong, Christina Sun, Tongran Qin, Thuy Pham, Caitlin Martin, Mohammad Zafar, John Elefteriades, Wei Sun, Liang Liang",
    "categories": "eess.IV, cs.CE, cs.CV, cs.LG",
    "pub_date": "2025-10-08 04:00:46",
    "ori_summary": "Aortic aneurysm disease ranks consistently in the top 20 causes of death in the U.S. population. Thoracic aortic aneurysm is manifested as an abnormal bulging of thoracic aortic wall and it is a leading cause of death in adults. From the perspective of biomechanics, rupture occurs when the stress acting on the aortic wall exceeds the wall strength. Wall stress distribution can be obtained by computational biomechanical analyses, especially structural Finite Element Analysis. For risk assessment, probabilistic rupture risk of TAA can be calculated by comparing stress with material strength using a material failure model. Although these engineering tools are currently available for TAA rupture risk assessment on patient specific level, clinical adoption has been limited due to two major barriers: labor intensive 3D reconstruction current patient specific anatomical modeling still relies on manual segmentation, making it time consuming and difficult to scale to a large patient population, and computational burden traditional FEA simulations are resource intensive and incompatible with time sensitive clinical workflows. The second barrier was successfully overcome by our team through the development of the PyTorch FEA library and the FEA DNN integration framework. By incorporating the FEA functionalities within PyTorch FEA and applying the principle of static determinacy, we reduced the FEA based stress computation time to approximately three minutes per case. Moreover, by integrating DNN and FEA through the PyTorch FEA library, our approach further decreases the computation time to only a few seconds per case. This work focuses on overcoming the first barrier through the development of an end to end deep neural network capable of generating patient specific finite element meshes of the aorta directly from 3D CT images.",
    "summary": "",
    "translation": "FEAorta：基于3D CT图像的主动脉有限元分析全自动化框架",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学影像分析和生物力学模拟，属于医疗领域的特定应用。标题中提到的3D CT图像、主动脉分析和有限元分析都与推荐系统、搜索或广告的核心技术领域完全无关，不涉及任何Transformer架构、LLM技术或推荐系统相关的进展。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06619v1": {
    "title": "MSITrack: A Challenging Benchmark for Multispectral Single Object Tracking",
    "url": "https://www.alphaxiv.org/abs/2510.06619v1",
    "arxiv_id": "2510.06619v1",
    "authors": "Tao Feng, Tingfa Xu, Haolin Qin, Tianhao Li, Shuaihao Han, Xuyang Zou, Zhan Lv, Jianan Li",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 03:56:36",
    "ori_summary": "Visual object tracking in real-world scenarios presents numerous challenges including occlusion, interference from similar objects and complex backgrounds-all of which limit the effectiveness of RGB-based trackers. Multispectral imagery, which captures pixel-level spectral reflectance, enhances target discriminability. However, the availability of multispectral tracking datasets remains limited. To bridge this gap, we introduce MSITrack, the largest and most diverse multispectral single object tracking dataset to date. MSITrack offers the following key features: (i) More Challenging Attributes-including interference from similar objects and similarity in color and texture between targets and backgrounds in natural scenarios, along with a wide range of real-world tracking challenges; (ii) Richer and More Natural Scenes-spanning 55 object categories and 300 distinct natural scenes, MSITrack far exceeds the scope of existing benchmarks. Many of these scenes and categories are introduced to the multispectral tracking domain for the first time; (iii) Larger Scale-300 videos comprising over 129k frames of multispectral imagery. To ensure annotation precision, each frame has undergone meticulous processing, manual labeling and multi-stage verification. Extensive evaluations using representative trackers demonstrate that the multispectral data in MSITrack significantly improves performance over RGB-only baselines, highlighting its potential to drive future advancements in the field. The MSITrack dataset is publicly available at: https://github.com/Fengtao191/MSITrack.",
    "summary": "",
    "translation": "MSITrack：面向多光谱单目标跟踪的挑战性基准",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉中的多光谱目标跟踪基准，属于纯粹的视觉技术领域。论文内容涉及目标跟踪和基准测试，与推荐系统、搜索或广告的核心技术没有直接关联，也没有展示在异构数据处理方面的潜在应用价值。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06612v1": {
    "title": "A Bridge from Audio to Video: Phoneme-Viseme Alignment Allows Every Face to Speak Multiple Languages",
    "url": "https://www.alphaxiv.org/abs/2510.06612v1",
    "arxiv_id": "2510.06612v1",
    "authors": "Zibo Su, Kun Wei, Jiahua Li, Xu Yang, Cheng Deng",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 03:46:39",
    "ori_summary": "Speech-driven talking face synthesis (TFS) focuses on generating lifelike facial animations from audio input. Current TFS models perform well in English but unsatisfactorily in non-English languages, producing wrong mouth shapes and rigid facial expressions. The terrible performance is caused by the English-dominated training datasets and the lack of cross-language generalization abilities. Thus, we propose Multilingual Experts (MuEx), a novel framework featuring a Phoneme-Guided Mixture-of-Experts (PG-MoE) architecture that employs phonemes and visemes as universal intermediaries to bridge audio and video modalities, achieving lifelike multilingual TFS. To alleviate the influence of linguistic differences and dataset bias, we extract audio and video features as phonemes and visemes respectively, which are the basic units of speech sounds and mouth movements. To address audiovisual synchronization issues, we introduce the Phoneme-Viseme Alignment Mechanism (PV-Align), which establishes robust cross-modal correspondences between phonemes and visemes. In addition, we build a Multilingual Talking Face Benchmark (MTFB) comprising 12 diverse languages with 95.04 hours of high-quality videos for training and evaluating multilingual TFS performance. Extensive experiments demonstrate that MuEx achieves superior performance across all languages in MTFB and exhibits effective zero-shot generalization to unseen languages without additional training.",
    "summary": "",
    "translation": "从音频到视频的桥梁：音素-视位对齐使每张脸能够说多种语言",
    "relevance_score": 1,
    "reasoning": "该论文专注于音频-视频模态对齐和跨语言语音同步，属于计算机视觉和多媒体处理领域。虽然涉及多模态学习，但其核心应用是语音驱动的面部动画和跨语言视频生成，与推荐系统、搜索或广告中的异构数据处理没有直接关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06611v1": {
    "title": "Self-supervised Physics-guided Model with Implicit Representation Regularization for Fast MRI Reconstruction",
    "url": "https://www.alphaxiv.org/abs/2510.06611v1",
    "arxiv_id": "2510.06611v1",
    "authors": "Jingran Xu, Yuanyuan Liu, Yanjie Zhu",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 03:40:40",
    "ori_summary": "Magnetic Resonance Imaging (MRI) is a vital clinical diagnostic tool, yet its widespread application is limited by prolonged scan times. Fast MRI reconstruction techniques effectively reduce acquisition duration by reconstructing high-fidelity MR images from undersampled k-space data. In recent years, deep learning-based methods have demonstrated remarkable progress in this field, with self-supervised and unsupervised learning approaches proving particularly valuable in scenarios where fully sampled data are difficult to obtain. This paper proposes a novel zero-shot self-supervised reconstruction framework named UnrollINR, which enables scan-specific MRI reconstruction without relying on external training data. The method adopts a physics-guided unrolled iterative reconstruction architecture and introduces Implicit Neural Representation (INR) as a regularization prior to effectively constrain the solution space. By combining a deep unrolled structure with the powerful implicit representation capability of INR, the model's interpretability and reconstruction performance are enhanced. Experimental results demonstrate that even at a high acceleration rate of 10, UnrollINR achieves superior reconstruction performance compared to the supervised learning method, validating the superiority of the proposed method.",
    "summary": "",
    "translation": "基于隐式表示正则化的自监督物理引导模型用于快速MRI重建",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学影像（MRI）重建，属于医疗领域的特定应用，与推荐系统、搜索或广告领域完全无关。论文中的自监督学习和表示正则化技术虽然具有技术价值，但缺乏在RecSys/Search/Ads领域的潜在应用场景。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06601v1": {
    "title": "AIM 2025 Challenge on Real-World RAW Image Denoising",
    "url": "https://www.alphaxiv.org/abs/2510.06601v1",
    "arxiv_id": "2510.06601v1",
    "authors": "Feiran Li, Jiacheng Li, Marcos V. Conde, Beril Besbinar, Vlad Hosu, Daisuke Iso, Radu Timofte",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 03:22:42",
    "ori_summary": "We introduce the AIM 2025 Real-World RAW Image Denoising Challenge, aiming to advance efficient and effective denoising techniques grounded in data synthesis. The competition is built upon a newly established evaluation benchmark featuring challenging low-light noisy images captured in the wild using five different DSLR cameras. Participants are tasked with developing novel noise synthesis pipelines, network architectures, and training methodologies to achieve high performance across different camera models. Winners are determined based on a combination of performance metrics, including full-reference measures (PSNR, SSIM, LPIPS), and non-reference ones (ARNIQA, TOPIQ). By pushing the boundaries of camera-agnostic low-light RAW image denoising trained on synthetic data, the competition promotes the development of robust and practical models aligned with the rapid progress in digital photography. We expect the competition outcomes to influence multiple domains, from image restoration to night-time autonomous driving.",
    "summary": "",
    "translation": "AIM 2025真实世界RAW图像去噪挑战赛",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉领域的图像去噪技术，属于纯粹的视觉处理任务。虽然图像质量在推荐和搜索系统中可能作为辅助特征，但该论文本身不涉及推荐系统、搜索或广告的核心技术，也没有与LLM、Transformer架构或异构数据建模相关的直接联系。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06596v1": {
    "title": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation",
    "url": "https://www.alphaxiv.org/abs/2510.06596v1",
    "arxiv_id": "2510.06596v1",
    "authors": "Ayush Zenith, Arnold Zumbrun, Neel Raut, Jing Lin",
    "categories": "cs.CV, cs.AI, cs.IT, cs.LG, math.IT",
    "pub_date": "2025-10-08 03:01:26",
    "ori_summary": "The performance of machine learning models depends heavily on training data. The scarcity of large-scale, well-annotated datasets poses significant challenges in creating robust models. To address this, synthetic data generated through simulations and generative models has emerged as a promising solution, enhancing dataset diversity and improving the performance, reliability, and resilience of models. However, evaluating the quality of this generated data requires an effective metric. This paper introduces the Synthetic Dataset Quality Metric (SDQM) to assess data quality for object detection tasks without requiring model training to converge. This metric enables more efficient generation and selection of synthetic datasets, addressing a key challenge in resource-constrained object detection tasks. In our experiments, SDQM demonstrated a strong correlation with the mean Average Precision (mAP) scores of YOLOv11, a leading object detection model, while previous metrics only exhibited moderate or weak correlations. Additionally, it provides actionable insights for improving dataset quality, minimizing the need for costly iterative training. This scalable and efficient metric sets a new standard for evaluating synthetic data. The code for SDQM is available at https://github.com/ayushzenith/SDQM",
    "summary": "",
    "translation": "SDQM：用于目标检测数据集评估的合成数据质量度量",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉领域的目标检测和合成数据质量评估，与推荐系统、搜索或广告的核心领域进展无关。虽然合成数据生成技术可能在其他领域有应用，但该论文的特定焦点是视觉目标检测，没有明确的联系或潜在应用指向推荐系统、搜索或广告领域。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06592v1": {
    "title": "Adaptive Stain Normalization for Cross-Domain Medical Histology",
    "url": "https://www.alphaxiv.org/abs/2510.06592v1",
    "arxiv_id": "2510.06592v1",
    "authors": "Tianyue Xu, Yanlin Wu, Abhai K. Tripathi, Matthew M. Ippolito, Benjamin D. Haeffele",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 02:53:28",
    "ori_summary": "Deep learning advances have revolutionized automated digital pathology analysis. However, differences in staining protocols and imaging conditions can introduce significant color variability. In deep learning, such color inconsistency often reduces performance when deploying models on data acquired under different conditions from the training data, a challenge known as domain shift. Many existing methods attempt to address this problem via color normalization but suffer from several notable drawbacks such as introducing artifacts or requiring careful choice of a template image for stain mapping. To address these limitations, we propose a trainable color normalization model that can be integrated with any backbone network for downstream tasks such as object detection and classification. Based on the physics of the imaging process per the Beer-Lambert law, our model architecture is derived via algorithmic unrolling of a nonnegative matrix factorization (NMF) model to extract stain-invariant structural information from the original pathology images, which serves as input for further processing. Experimentally, we evaluate the method on publicly available pathology datasets and an internally curated collection of malaria blood smears for cross-domain object detection and classification, where our method outperforms many state-of-the-art stain normalization methods. Our code is available at https://github.com/xutianyue/BeerLaNet.",
    "summary": "",
    "translation": "用于跨域医学组织学的自适应染色归一化",
    "relevance_score": 1,
    "reasoning": "这篇论文专注于医学图像处理中的染色归一化技术，属于医学领域的特定应用。虽然涉及跨域适应，但完全聚焦于医学组织学这一与推荐系统、搜索或广告无关的专业领域。该技术没有明显的潜力应用于推荐系统、搜索或广告的核心问题。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06590v1": {
    "title": "Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer",
    "url": "https://www.alphaxiv.org/abs/2510.06590v1",
    "arxiv_id": "2510.06590v1",
    "authors": "Ziyuan Huang, DanDan Zheng, Cheng Zou, Rui Liu, Xiaolong Wang, Kaixiang Ji, Weilong Chai, Jianxin Sun, Libin Wang, Yongjie Lv, Taozhi Huang, Jiajia Liu, Qingpei Guo, Ming Yang, Jingdong Chen, Jun Zhou",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 02:50:14",
    "ori_summary": "Visual tokenization remains a core challenge in unifying visual understanding and generation within the autoregressive paradigm. Existing methods typically employ tokenizers in discrete latent spaces to align with the tokens from large language models, where the quantization errors can limit semantic expressiveness and degrade the capability of vision-language understanding. To address this, we introduce MingTok, a new family of visual tokenizers with a continuous latent space, for unified autoregressive generation and understanding. While understanding tasks favor discriminative high-dimensional features, generation tasks prefer compact low-level codes. Thus, to reconcile these competing demands, MingTok adopts a three-stage sequential architecture involving low-level encoding, semantic expansion, and visual reconstruction. Built on top of it, Ming-UniVision eliminates the need for task-specific visual representations, and unifies diverse vision-language tasks under a single autoregrsssive prediction paradigm. By formulating both understanding and generation as next-token prediction in a shared continuous space, it seamlessly supports multi-round, in-context tasks such as iterative understanding, generation and editing. Empirically, we find that using a unified continuous visual representation reconciles the competing requirements on the tokenizers by the understanding and generation tasks, thereby leading to state-of-the-art level performance across both domains. We hope our findings will facilitate unified visual tokenization in the continuous domain. Inference code and model weights are released to benefit community.",
    "summary": "",
    "translation": "Ming-UniVision：基于统一连续分词器的联合图像理解与生成",
    "relevance_score": 2,
    "reasoning": "该论文主要关注视觉领域的统一建模（图像理解与生成），属于纯粹的视觉研究方向。虽然标题中提到'统一分词器'概念，但核心应用场景是计算机视觉而非推荐系统、搜索或广告领域。该技术缺乏明确的跨模态应用潜力，无法直接服务于异构数据处理或推荐排序任务。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06584v1": {
    "title": "Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation",
    "url": "https://www.alphaxiv.org/abs/2510.06584v1",
    "arxiv_id": "2510.06584v1",
    "authors": "Justin Cheung, Samuel Savine, Calvin Nguyen, Lin Lu, Alhassan S. Yasin",
    "categories": "cs.CV, q-bio.TO",
    "pub_date": "2025-10-08 02:27:09",
    "ori_summary": "Deep learning models which perform well on images from their training distribution can degrade substantially when applied to new distributions. If a CT scanner introduces a new artifact not present in the training labels, the model may misclassify the images. Although modern CT scanners include design features which mitigate these artifacts, unanticipated or difficult-to-mitigate artifacts can still appear in practice. The direct solution of labeling images from this new distribution can be costly. As a more accessible alternative, this study evaluates domain adaptation as an approach for training models that maintain classification performance despite new artifacts, even without corresponding labels. We simulate ring artifacts from detector gain error in sinogram space and evaluate domain adversarial neural networks (DANN) against baseline and augmentation-based approaches on the OrganAMNIST abdominal CT dataset. Our results demonstrate that baseline models trained only on clean images fail to generalize to images with ring artifacts, and traditional augmentation with other distortion types provides no improvement on unseen artifact domains. In contrast, the DANN approach successfully maintains high classification accuracy on ring artifact images using only unlabeled artifact data during training, demonstrating the viability of domain adaptation for artifact robustness. The domain-adapted model achieved classification performance on ring artifact test data comparable to models explicitly trained with labeled artifact images, while also showing unexpected generalization to uniform noise. These findings provide empirical evidence that domain adaptation can effectively address distribution shift in medical imaging without requiring expensive expert labeling of new artifact distributions, suggesting promise for deployment in clinical settings where novel artifacts may emerge.",
    "summary": "",
    "translation": "通过领域自适应改进CT深度学习模型的伪影鲁棒性，无需标记伪影图像",
    "relevance_score": 1,
    "reasoning": "该论文专注于医学CT图像领域的深度学习模型鲁棒性改进，属于医学影像处理范畴。虽然涉及领域自适应技术，但其应用场景（CT图像伪影）与推荐系统、搜索或广告领域完全无关，且没有明显的跨领域应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06582v1": {
    "title": "Through the Perspective of LiDAR: A Feature-Enriched and Uncertainty-Aware Annotation Pipeline for Terrestrial Point Cloud Segmentation",
    "url": "https://www.alphaxiv.org/abs/2510.06582v1",
    "arxiv_id": "2510.06582v1",
    "authors": "Fei Zhang, Rob Chancia, Josie Clapp, Amirhossein Hassanzadeh, Dimah Dera, Richard MacKenzie, Jan van Aardt",
    "categories": "cs.CV, cs.RO",
    "pub_date": "2025-10-08 02:25:59",
    "ori_summary": "Accurate semantic segmentation of terrestrial laser scanning (TLS) point clouds is limited by costly manual annotation. We propose a semi-automated, uncertainty-aware pipeline that integrates spherical projection, feature enrichment, ensemble learning, and targeted annotation to reduce labeling effort, while sustaining high accuracy. Our approach projects 3D points to a 2D spherical grid, enriches pixels with multi-source features, and trains an ensemble of segmentation networks to produce pseudo-labels and uncertainty maps, the latter guiding annotation of ambiguous regions. The 2D outputs are back-projected to 3D, yielding densely annotated point clouds supported by a three-tier visualization suite (2D feature maps, 3D colorized point clouds, and compact virtual spheres) for rapid triage and reviewer guidance. Using this pipeline, we build Mangrove3D, a semantic segmentation TLS dataset for mangrove forests. We further evaluate data efficiency and feature importance to address two key questions: (1) how much annotated data are needed and (2) which features matter most. Results show that performance saturates after ~12 annotated scans, geometric features contribute the most, and compact nine-channel stacks capture nearly all discriminative power, with the mean Intersection over Union (mIoU) plateauing at around 0.76. Finally, we confirm the generalization of our feature-enrichment strategy through cross-dataset tests on ForestSemantic and Semantic3D. Our contributions include: (i) a robust, uncertainty-aware TLS annotation pipeline with visualization tools; (ii) the Mangrove3D dataset; and (iii) empirical guidance on data efficiency and feature importance, thus enabling scalable, high-quality segmentation of TLS point clouds for ecological monitoring and beyond. The dataset and processing scripts are publicly available at https://fz-rit.github.io/through-the-lidars-eye/.",
    "summary": "",
    "translation": "基于激光雷达视角：面向地面点云分割的特征增强与不确定性感知标注流程",
    "relevance_score": 1,
    "reasoning": "该论文专注于激光雷达点云分割的标注流程，属于纯粹的计算机视觉和3D视觉领域，与推荐系统、搜索或广告的核心技术无关。即使考虑特征增强和不确定性感知技术，其应用场景局限于地面点云处理，没有明显的推荐/搜索/广告应用潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06564v1": {
    "title": "HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution",
    "url": "https://www.alphaxiv.org/abs/2510.06564v1",
    "arxiv_id": "2510.06564v1",
    "authors": "Qiongyang Hu, Wenyang Liu, Wenbin Zou, Yuejiao Su, Lap-Pui Chau, Yi Wang",
    "categories": "cs.CV, cs.AI",
    "pub_date": "2025-10-08 01:32:52",
    "ori_summary": "Existing deep learning approaches for image super-resolution, particularly those based on CNNs and attention mechanisms, often suffer from structural inflexibility. Although graph-based methods offer greater representational adaptability, they are frequently impeded by excessive computational complexity. To overcome these limitations, this paper proposes the Heterogeneous Subgraph Network (HSNet), a novel framework that efficiently leverages graph modeling while maintaining computational feasibility. The core idea of HSNet is to decompose the global graph into manageable sub-components. First, we introduce the Constructive Subgraph Set Block (CSSB), which generates a diverse set of complementary subgraphs. Rather than relying on a single monolithic graph, CSSB captures heterogeneous characteristics of the image by modeling different relational patterns and feature interactions, producing a rich ensemble of both local and global graph structures. Subsequently, the Subgraph Aggregation Block (SAB) integrates the representations embedded across these subgraphs. Through adaptive weighting and fusion of multi-graph features, SAB constructs a comprehensive and discriminative representation that captures intricate interdependencies. Furthermore, a Node Sampling Strategy (NSS) is designed to selectively retain the most salient features, thereby enhancing accuracy while reducing computational overhead. Extensive experiments demonstrate that HSNet achieves state-of-the-art performance, effectively balancing reconstruction quality with computational efficiency. The code will be made publicly available.",
    "summary": "",
    "translation": "HSNet：用于单图像超分辨率的异质子图网络",
    "relevance_score": 1,
    "reasoning": "该论文专注于计算机视觉领域的单图像超分辨率任务，属于纯粹的视觉处理技术。虽然涉及异质网络架构，但其应用场景和核心方法完全局限于图像处理领域，与推荐系统、搜索或广告的排名任务没有任何直接或间接的关联。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06541v1": {
    "title": "Cluster Paths: Navigating Interpretability in Neural Networks",
    "url": "https://www.alphaxiv.org/abs/2510.06541v1",
    "arxiv_id": "2510.06541v1",
    "authors": "Nicholas M. Kroeger, Vincent Bindschaedler",
    "categories": "cs.CV, cs.LG",
    "pub_date": "2025-10-08 00:41:09",
    "ori_summary": "While modern deep neural networks achieve impressive performance in vision tasks, they remain opaque in their decision processes, risking unwarranted trust, undetected biases and unexpected failures. We propose cluster paths, a post-hoc interpretability method that clusters activations at selected layers and represents each input as its sequence of cluster IDs. To assess these cluster paths, we introduce four metrics: path complexity (cognitive load), weighted-path purity (class alignment), decision-alignment faithfulness (predictive fidelity), and path agreement (stability under perturbations). In a spurious-cue CIFAR-10 experiment, cluster paths identify color-based shortcuts and collapse when the cue is removed. On a five-class CelebA hair-color task, they achieve 90% faithfulness and maintain 96% agreement under Gaussian noise without sacrificing accuracy. Scaling to a Vision Transformer pretrained on ImageNet, we extend cluster paths to concept paths derived from prompting a large language model on minimal path divergences. Finally, we show that cluster paths can serve as an effective out-of-distribution (OOD) detector, reliably flagging anomalous samples before the model generates over-confident predictions. Cluster paths uncover visual concepts, such as color palettes, textures, or object contexts, at multiple network depths, demonstrating that cluster paths scale to large vision models while generating concise and human-readable explanations.",
    "summary": "",
    "translation": "簇路径：神经网络可解释性导航",
    "relevance_score": 2,
    "reasoning": "该论文主要关注神经网络的可解释性方法，这属于通用机器学习范畴而非特定于推荐系统、搜索或广告领域。虽然神经网络可解释性在模型调试中有一定价值，但论文标题没有表明其与Transformer架构、LLM技术或推荐系统核心算法的直接关联，也没有展示在异构数据处理方面的潜在应用。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  },
  "2510.06529v1": {
    "title": "VUGEN: Visual Understanding priors for GENeration",
    "url": "https://www.alphaxiv.org/abs/2510.06529v1",
    "arxiv_id": "2510.06529v1",
    "authors": "Xiangyi Chen, Théophane Vallaeys, Maha Elbayad, John Nguyen, Jakob Verbeek",
    "categories": "cs.CV",
    "pub_date": "2025-10-08 00:04:47",
    "ori_summary": "Recent advances in Vision-Language Models (VLMs) have enabled unified understanding across text and images, yet equipping these models with robust image generation capabilities remains challenging. Existing approaches often rely on reconstruction-oriented autoencoders or complex bridging mechanisms, leading to misalignment between understanding and generation representations, or architectural complexity. In this work, we propose VUGEN, a novel framework that explicitly leverages VLM's pretrained visual understanding priors for efficient and high-quality image generation. Our approach first transforms the high-dimensional latent space of the VLM's native vision encoder into a lower-dimensional, tractable distribution that maximally preserves visual information. The VLM is then trained to sample within this reduced latent space, ensuring alignment with its visual understanding capabilities. Finally, a dedicated pixel decoder maps these generated latents back to the image space. We find that a VAE-free pixel diffusion decoder to be on par or better than commonly used complex latent diffusion decoders that internally rely on VAE latents. Extensive experiments demonstrate that VUGEN achieves superior image generation performance, improving DPG Bench from 71.17 to 74.32 and FID from 11.86 to 9.06 on COCO, while fully preserving the VLM's original understanding capabilities.",
    "summary": "",
    "translation": "VUGEN：用于生成的视觉理解先验",
    "relevance_score": 2,
    "reasoning": "该论文标题表明其专注于视觉理解和生成任务，属于纯粹的视觉-语言模型领域。虽然提到了生成能力，但这更接近AIGC和内容生成范畴，而非推荐系统、搜索或广告中的直接应用。没有明显证据表明该技术具有在异构数据建模或推荐系统应用方面的潜力。",
    "rerank_relevance_score": 0,
    "rerank_reasoning": "",
    "is_filtered": true,
    "is_fine_ranked": false
  }
}